
Im folgenden Abschnitt wird beschrieben, wie der betrachtete Datensatz in eine sinnvolle indizierbare Form
gebracht wird. Zunächst wird in \autoref{sec:preprosselection} ein
Überblick über die Auswahl der Fremdsoftware gegeben. Anschließend werden in
\autoref{sec:components} die einzelnen Schritte der Verarbeitung betrachtet.



\section{Auswahl}\label{sec:preprosselection}

Es existieren einige Toolboxen, die die Extraktion von Text und Meta-
Informationen vornehmen können.  Aufgrund der Wahl der
Programmiersprache Java (siehe \autoref{ch:intro}) wurde dazu das
\tika Toolkit
in Betracht gezogen. Es bietet einfach gestaltete Schnittstellen zu
Open Source Libraries um je nach Datenformat eine geeignete
Datenextraktion vorzunehmen. Neben PDFs lassen sich auch DOCs, Power
Point Präsentationen und Bilder (OCR) ansprechen. Die Komponente der
PDF-Extraktion, \pdfbox, lässt sich auch außerhalb von Tika nutzen.
Die Paper-Auswahl besteht überwiegend aus PDFs\footnote{1595 PDFs,
  11 Docs und 1 HTML}, deswegen wurde \pdfbox ausgewählt, um einen-Overhead zu
vermeiden. Bei der Zunahme von weiteren Formaten lässt sich der Code
leicht mit entsprechenden \tika - Methoden austauschen.

Bei der Untersuchung des Datensatzes wird deutlich, dass nur ein
geringer Anteil an Papern korrekte Meta-Informationen angegeben werden. Um
Titel aus den Texten zu extrahieren wurde deswegen Docear
PdfDataExtractor\footnote{Link:
  \url{https://www.docear.org/tag/pdf-title-extraction/}}
eingesetzt. Die Software sucht, neben weitern Heuristiken, auf der
ersten Seite des Artikels nach langen zusammenhängenden Wortsequenzen.




\section{Komponenten}\label{sec:components}
In den folgenden Abschnitten werden die einzelnen Schritte der
Vorverarbeitung kurz dargelegt. Dabei liegt der Fokus auf der
Extraktion bzw. die Gewinnung der Meta-Daten.

\subsection{Meta-Daten-Extraktion}\label{sec:pdfextraction}

Sind die Daten extrahiert, so wird zunächst überprüft, ob der Titel der
Meta-Daten unzulässige Zeichen enthält oder eine unzulässige Länge
hat. Ist dies nicht der Fall, wird mit Docear PdfDataExtractor
versucht, im Text einen validen Titel zu finden. Valide Titel
werden an eine Schnittstelle der Digital Bibliography \& Library
Project (DBLP)\footnote{Link zu DBLP: \url{http://dblp.uni-trier.de/}}
gesendet und mit der dort vorliegenden Datenbank verglichen. Die Attribute des Artikels mit
der höchsten Übereinstimmung (Score) werden für den aktuellen
Artikel übernommen. Es besteht die Möglichkeit, den Datensatz als
XML-Datei lokal zu durchsuchen und mit weiteren Daten anzureichern.
In \autoref{sec:heuristic-title-search} soll weiter darauf
eingegangen werden.
Konnte nach wie vor kein valider Titel entnommen
werden, wird eine Zeichenkette festgelegter Länge als Heuristik für
den Title angenommen. In diesem Fall wird eine Named Entity
Recognition auf den ersten Wörtern des Artikel-Textes gefahren, um mögliche
Autoren zu finden. Hierzu wird Apache OpenNLP verwendet\footnote{Link zu
  OpenNLP: \url{https://opennlp.apache.org/}}.

Aufgrund der vergleichsweise geringen Anzahl an Papern werden die
Artikel-Daten einzeln als XML-Files gespeichert. Das erleichtert die
Überprüfung während der Entwicklungsphase. Das Haupt-Element
article enthält die Elemente 
\begin{itemize}
\item metaData mit title, authors, publificationDate, refCount und
\item textElements mit abstract und fullText. 
\end{itemize}

Um die von der ASCII Codierung abweichende Zeichen korrekt darzustellen,
werden die Text-Elemente  als nicht interpretierte Zeichen (CDATA) gespeichert.
Zusätzlichen werden fileName, filePath sowie parseTime festgehalten,
die in der weiteren Verarbeitung benötigt werden. 

\subsection{Heuristische Titel Suche}\label{sec:heuristic-title-search}

Die extrahierten Daten zeigen auch nach den in \autoref{sec:pdfextraction}
beschriebenen Schritten ein nicht zufriedenstellendes Ergebnis. Im folgenden soll eine heuristische
Titel Suche vorgestellt werden\footnote{Vorschlag: Martin Potthast.}, die den Text mit Attributen einer
vorliegenden Meta-Daten Kollektion vergleicht. Der Algorithmus
folgt der Annahme, dass die Meta-Daten mit der höchsten Übereinstimmung
die korrekten sein müssen, wenn diese als Vergleichsdaten
vorliegen. Als Daten-Quelle wurde zum einen eine Auswahl an Papern des DBLP, die in relevanten Journalen erscheinen\footnote{$\rightarrow$ auf
  Tabelle verweisen.} und eine bereits vorhandene Auswertung von
Zitations-Analysen\footnote{wie zitiere ich denn den Herren?}
zusammengefasst. Der Algorithmus durchläuft je extrahiertem 
Artikel die folgende Prozedur:

Eine vorgegebene Anzahl an Wörtern des Artikels wird als zu
vergleichender Text gespeichert. Während der Stax-Parser über die
Meta-Daten-Kollektion läuft, werden die Elemente als aktuelles 
Artikel-Objekt gespeichert. Es wird ein Score berechnet, der eine
mögliche Übereinstimmung anzeigen soll. Enthält der entsprechende Text Wörter der
Attribute Titel, Autoren oder Publikations-Zeitpunkt, erhält der Artikel Punkte. Genaue Übereinstimmung des
Titels bzw. der Autoren erhalten zusätzliche Boni, die relativ zur
Länge der Attribute berechnet werden\footnote{Titel: 50, Autoren:
  30}. Der Artikel mit der höchsten Punktzahl wird akzeptiert. Da
nicht garantiert werden kann, dass die korrekte Artikel Daten gefunden
werden, muss der Score einen Schwellwert überschreiten.

\subsection{Referenz-Analyse}\label{sec:reference-analysis}






%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../arbeit"
%%% End:
