Effect Of Feature Selection, Synthetic Minority Over-sampling 
(SMOTE) And Under-sampling On Class imbalance Classification
 
Nadeem Qazi 
Faculty of Engineering Science and Technology 
IQRA University Pakistan 
Email:Nadeemhqazi@yahoo.com 
Kamran Raza 
Faculty of Engineering Science and Technology 
IQRA University Pakistan 
Email:Kraza@iqra.edu.pk 
 
Abstract—Accurate identification of network intrusions is 
one of the biggest challenges of Network Intrusion Detection 
(NID) systems. In recent years Machine learning 
classification techniques have been used to precisely identify 
network intrusion. However, the multi class distribution in 
network intrusion detection system has found to be highly 
skewed, leading to classification accuracy problem due to 
class imbalance data set. The work presented in this paper 
not only explores the role of the attribute selection in 
improving classification accuracy but also investigates the 
problem of class imbalance using the Synthetic Minority 
Over-sampling (SMOTE) and under sampling of major 
classes. The classification performance is then evaluated 
over several types of classifiers. The outcome of this work is 
that for the class imbalance data set the under-sampling 
technique is more effective than SMOTE in detecting minor 
classes. It has also found during this research work that the 
decision tree algorithms (JRIP) and Naïve Bayes are more 
accurate classifiers as compared to the Radial basis neural 
network and support vector machine. However no single 
algorithm can be used for the classification of multiclass and 
it is proposed in this research work that combination of 
classifier consisting of Naïve Bayes and JRIP could be used 
for the classification of minor classes in an imbalance class 
data set of intrusion detection system. 
Keywords: Class imbalance, Feature Selection, Network 
intrusion, Support Vector Machines 
I. INTRODUCTION 
    The cyber attack may not affect a private person 
severely but it is a serious threat to professional 
companies and government organization. For example in 
early 2009 a intruder infiltrated the US power grid1 with a 
malware that was capable of shutting down the entire grid 
The bad news is that this network threats according to the 
survey by CERT/CC (Computer Emergency Response 
Team/Coordination Center) has been increasing 
exponentially and thus demands high attention for their 
identification and proper handling and thus role of 
intrusion detection system is highly critical for the health 
of networks.  
    An Intrusion Detection System (IDS) may be defined 
as a system that detects hostile activities in a network by 
identifying a set of malicious actions that compromise the 
integrity confidentiality and availability of information 
resources.   It is classified as Network based intrusion 
detection (NID) and Host-based IDS. The network-based 
IDS is known as a pattern recognition problem in which 
network traffic patterns are classified as either normal or 
abnormal. The traditional approaches for network-based 
IDS are Signature-Based, which is manual and highly 
susceptible to human error. Moreover, cannot detect 
emerging cyber threats. However  in the recent years a 
new approach i.e., Machine-Learning/Data-Mining has 
been successfully used for NID. Machine learning 
techniques have been employed as intrusion classifier to 
automatically perform intrusion from a training set with 
example of user behavior or network traffic. This avoid 
any need to formulate any human expert knowledge in to 
the rule .These techniques broadly defines two methods of 
the intrusion detection i.e. anomaly detection and misuse. 
Anomaly detects an intrusion through the pattern 
deviating from established normal behavior of the 
intrusion. One of the advantages of the anomaly detection 
is the ability of detecting new attacks however this 
approach is reported to have more chance of issuing false 
positives [11].  On the other hand misuse method is a 
reverse methodology which identifies the abnormal 
behavior first and identifies any other behavior normal.  
A. Class imbalance 
    The machine learning based intrusion detection process 
starts from collection of the network data having several 
attributes followed by a labeling process during which 
each instance in the data is labeled as normal or intrusion 
and than an appropriate learning algorithm is trained over 
the labeled data. However, it has been found that 
normally the distribution of these labels are skewed, 
which creates unequal representation of classes in the 
training data sets. This unbalance in the instances of the 
2012 14th International Conference on Modelling and Simulation
978-0-7695-4682-7/12 $26.00 © 2012 IEEE
DOI 10.1109/UKSim.2012.116
145
classes leads to one of the challenging problem named as 
class imbalance problem in binary or multi classification 
process. In imbalance data set the class having more 
number of instances is called as major class while the one 
having relatively less number of instances are termed as 
minor class. In such situation some of the classifier are 
biased towards the major class(es) [3][9][11]  and 
therefore  show poor classification rates on minor classes. 
It is also possible that classifier predicts everything as 
major class and simply ignores the minor class and yields 
a misleading higher overall accuracy [16]. This 
challenging problem is appeared in almost every other 
real world machine learning applications. Network 
intrusion detection, video surveillance oil spills detection, 
diagnoses of medical conditions and text categorization 
are some of the examples cited in [3]. There has been lost 
of research in the class imbalance problem by several 
domain including medicine [6], bioinformatics [2], text 
recognition [5], credit scoring [20]intrusion and fraud 
detection [9].  
    The research work presented in this paper aims to 
investigate the effect of feature selection and sampling 
techniques on the imbalance classification data sets.  The 
hypothesis is based on the fact that classification accuracy 
of the classifier is the function of the appropriate features 
used to identify the pattern and class imbalanced problem 
can be handled by manipulating the number of major and 
minor classes. Therefore in this research several methods 
of attribute selection are explored and classification 
accuracy is investigated by under sampling of major 
classes and synthetic over sampling of minor classes. The 
rest of the paper is organized as follow: next section starts 
with the description of KDD Cup 99 Data set used in the 
experiments followed by the research objectives. The 
fourth section describes experimental set up and feature 
selection strategy followed by the classifiers performance 
measure. The sixth section describes the experimental 
results with detail analysis. Finally, the conclusion is 
drawn  in last section of the paper. 
B. KDD CUPP99 Data Set 
     The researchers investigating the anomaly detection 
method for network intrusion system has widely used the 
KDDP cup 1999 data set . It is prepared by [17] based on 
data captured in DARPA 98 IDS evaluation program. 
Although The KDD cup data set suffers from some of the 
problems as described by [10] but due to the lack of any 
other publicly available data set for network intrusion this 
data set may be used as effective benchmark to help 
researchers compare different intrusion detection method. 
It consists of nine weeks of raw TCP dump data for a 
local -area network simulating a typical U.S Air Force 
LAN. The KDD Cup 99 data set consists of both nominal 
and numeric data having 42 feature attributes as presented 
in the This data contains one type of normal data and 24 
different types of attacks that are broadly categorized in 
four groups of imbalance group of classes namely DOS, 
Probes,U2R and R2L as shown in Table 1.0. 
1. Denial of Service attack(DOS):  is an attack in which 
legitimate user is denied to access the machine due to 
either false too busy resource or too heavy memory 
usage as induced by the attacker. 
2. User to Root Attack (U2R) : These attacks  obtain 
root access to the system through exploitation of  
vulnerabilities in operating systems 
3. Remote to Local Attack(R2L) : occurs when an 
illegitimate user attains the role on machine as local 
user. 
4. Probing attack : is an attempt to gather information 
about a network of computers for the apparent 
purpose of circumventing its security controls. 
    The researchers have proposed four different solutions 
which are sampling training data, feature selections and 
stacking of the classifiers for final improved 
classification. There are several techniques available for 
the data sampling of which the under-sampling, over 
sampling and advance sampling have been more 
commonly used by the researchers [19]. The over-
sampling is a non –heuristic  technique  simply replicates 
the number of the instances of the minor class but it has 
disadvantage of producing more chance of over-fitting 
and it may take more time if the original data set is fairly 
large but imbalance.   The under-sampling techniques on 
the other hand down sized the major class randomly 
however they have risk of eliminating the important data 
sets. On the other hand several over-sampling technique 
use heuristic to generate synthetic minority classes using 
SMOTE. SMOTE does not replicate rather it generates 
new minor classes using interpolation thus avoid chance 
of over-fitting. Researchers have used Artificial Neural 
Network and decision tree  on class imbalanced data set 
however they  have been found to learn poorly from 
imbalanced data as they are biased towards the major 
class [11].One of the new trend in dealing the class 
imbalance is the use of the classifier combination: 
146
Random forest [19], boosting [7] and expert mixture[3] 
are the examples of the such techniques.  
II. RESEARCH WORK OBJECTIVE 
    The available dataset of KDD Cup 99 has more than 
five million records however it has been observed during 
the literature review that different subset of this data has 
been used by the researchers and surprisingly have 
reported conflict results for example ANN as reported by 
[22] were unable to detect U2R and R2L but the work 
done by  [1] found comparatively high detection rate  for 
U2R and R2L. This and other discrepancies like this are 
mainly because of choice of data subset. Therefore in this 
study all the distinct instances were taken for classifier 
evaluation .  As can be seen from the table 2.0  this data 
contains very small percentage of the rare classes  i.e. 
RLA and URA are 0.8% and 0.04 5% respectively 
whereas major class have large set of instances   
Researchers so far have been using all the attributes of 
this data[13].Therefore One of main objective was to 
study the effect of the feature selection in model 
development and accuracy. Following objectives were set 
for the this work: 
i. What role feature selection could play in 
classifying multiple class imbalance, 
ii. Which of the sampling techniques  i.e. over 
sampling of minor classes (SMOTE) and under 
sampling of major classes  for the class 
imbalance could effectively be used in network 
intrusion? 
iii. Which of the machine learning classifiers can 
best be used for intrusion detection and 
classification? 
 
III. EXPERIMENTAL SETUP 
    All of the experiments were performed using 64 bit 
windows operating system installed a notebook PC 
having Intel Core i5 CPU and 4 GB of RAM. Open 
source machine learning package - WEKA 3.6.4 was used 
to investigate the behavior of several learning algorithms 
to handle the class imbalance problem. This machine 
learning tool is a java based collection of machine 
learning algorithms related to preprocessing, feature 
selection, classification, regression, clustering, association 
rules and visualization. This empirical study deals only 
with feature selection and classification algorithms.  
IV. FEATURE SELECTION 
    Feature Selection is one of the importance step in 
developing a model especially an empirical model. It not 
Table 1.0 
NUMBER OF INSTANCES IN EACH CLASS 
Class 
Label 
Number 
of 
Instances 
Percentage 
Normal 86483 72.5 
Dos 30162 25.3 
probes 1509 1.26 
RLA 998 0.8 
URA 52 0.04 
Total 119204 100 
 
only reduces the dimensionality of the data but also 
enables the classifier to operate faster and accurately. The 
KDD cup data set contains 42 attributes , it is 
computationally effective if only important attributes 
effecting on the multiple class should be considered for 
the model building. A two step method of feature 
selection is adopted in this research. In the first step a set 
of feature based on a search method is selected, the 
selected features in the second step were than evaluated 
using a evaluation function. For better result accuracy 
more than one type of search method were used.   Genetic 
Search algorithm was used in the first step for feature 
selection and then selected features were evaluated 
considering their predictive ability and degree of 
redundancy between them. 
TABLE 2.0 SELECTED FEATURES 
 
Feature  Feature Description 
1 Duration in second 
3 service network 
4 flag 
5 src_bytes 
6 dst_bytes  
8 wrong_fragment 
10  hot 
11 num_failed_logins 
12  logged_in 
13 num_compromised  
22 is_guest_login 
23 count 
24 srv_count 
25 serror_rate  
147
26 srv_serror_rate 
29 same_srv_rate 
33 dst_host_srv_count 
34 dst_host_same_srv_rate 
38 dst_host_serror_rate 
39 srv_serror_rate  
 
Those subset of features was selected that have shown 
high correlation with the class label but less degree of 
correlation among themselves. This was achieved by 
using cfsSubsetEval   attribute evaluator as provided by 
WEKA  software. 
    The feature selection was also made using the rank 
algorithm. The features were evaluated using two 
statistical measures i.e. info gain and gain ratio.   These 
three algorithms produced a set of twenty attributes based 
on the info gain, gain ration and rank. It was decided to 
select those attributed which were recommended by at 
least two of the above algorithms. The feature selected by 
this process is presented in Table 3.0 . It can be seen from 
Table 2.0 that  on the basis of info gain values feature 
representing protocol_ type does should not be used for 
network intrusion classification rather than it is number of 
the source and destination bytes transferred between 
source and destination that effect much on the type of the 
intrusion class and hence should be observed for network 
intrusion detection.  
V. CLASSIFIER SELECTION 
    After the Selection of the best features two sampling 
techniques were studied for nine different classifiers. 
Since there is very less amount of rare classes are present 
in data set so the major classes were under sampled and 
30% of total instances of major classes (i.e. normal and 
Dos)  were taken while the number of the instances of the 
minor classes were kept same. A set of 10 classifiers were 
then used to classify this data for model development with 
10 fold validation.  
In second approach the (Synthetic Minority Oversampling 
Technique) SMOTE techniques was used. SMOTE is a 
combination of informed oversampling of minority class 
with random under sampling of majority class. It 
calculates first the K-nearest neighbors classes and then 
randomly select any of these algorithms, it then generates 
Synthetic samples along the lines joining the minority 
sample and its selected neighbors. After preprocessing the 
Data with SMOTE 10 different classifiers were used for 
model developments. All of these classifiers were 
evaluated using 10 fold cross validation. The classifiers 
performance of all the classifiers under the two sampling 
techniques were than evaluated using the confusion 
matrix discussed in next section. 
 
VI. CLASSIFIERS PERFORMANCE MEASURE 
    The number of instances predicted by a classifier is 
usually described in confusion matrix. It contains number 
of instances recognized by the classifier as True positiv 
(TP), False Negative (FN), False Positive (FP) and True 
Negative (TN). 
Where, 
TP: Corresponds to the number of positive examples 
correctly predicted by classifier 
FN: Corresponds to the number of positive examples 
wrongly predicted as negative by classifier 
FP: Corresponds to the number of negative examples 
wrongly predicted as positive by classifier 
TN: Corresponds to the number of negative examples 
correctly predicted as positive by classifier. 
 
VII. RESULT AND ANALYSIS. 
    The performance of all the classifiers under sampling 
of major classes and under sampling of minor classes 
using SMOTE is compared in Table 3.0. The performance 
criterion is based on  the TP rate from the  confusion 
matrix.  It can be seen from the table that the sampling 
techniques used in this research i.e. the under sampling of 
the major class and over sampling of the minor class does 
not affect classification of major classes as all classifiers 
has classified the major classes i.e. normal and Dos with 
TP rate of more than 95%. However the effect of these 
two sampling technique can be observed in classification 
of minor classes. The TP rate of the minor classes was 
found to increase when classifiers are used with under 
sampling technique of major class. It is also visible for the 
result that unlike [11] decision tree Cj48 has significantly 
identified the minor classes. However It can be infer from 
this table that not a single classifier can be used to classify 
all the intrusion classes irrespective of sampling technique 
being used. For example it can be seen that classes having 
greater instance such as DOS and normal was effectively 
identified at higher TP rate of more than 97% by SMO, 
RBF, Naive-Bayes, Multi classifier bagging and JRipp. 
On the basis of the Accuracy SMO algorithm showed 
98% over accuracy but failed to detect the minor class of 
U2R  with TP rate of under 50% accuracy rate under both 
the sampling technique. Similarly multiclass classifier   
was also failed in detecting URL with TP rate of  36% 
and 56%  for the both used sampling technique. JRipper 
had shown greater tendency of identifying U2L with 
accuracy of 78% TP rate when preprocessed with the 
under sampling technique slightly better than SMOTE 
result. Similarly the under-sampling technique also 
produced better accuracy with  Navie Bayes classifier as  
it identified the U2L with 90% TP rate however failed to 
identify the other minorclass RLA with just TP rate of  
3%.  Therefore it can be seen from this result that there 
148
was not a single classifier that was able to identify all the 
classes including both rare and major classes having TP 
rate more than 90%. However the among all the tested 
classifier JRIPP classifier algorithm has  shown greater 
TP rate  97% and 73%  for  RLA and URA respectively 
along with the more than 90% TP rate for other 
majorclasses. Naïve Bayes showed greater TP rate (90%) 
for other minor class i.e URL. This can also be seen from 
the Figure 1.0 showing the precisions of the classifiers in 
indentifying the different type network intrusion. Looking 
at the result it is proposed that a combination of model 
could be used to identify all the attacks both minor and 
major classes with the TP rate of more than 90 %. Based 
on values of TP and FP   NavieBayes classifier along with 
the JRIP is recommended as best combination to obtained 
the robust model to classify all the classes especially the 
minor classes with greater efficiency.  
 
VIII. CONCLUSION 
    The research work presented in this paper reveals that 
the sampling of the intrusion data only effects the 
classification of minor classes not the major classes, and 
under sampling of the major classes produced more 
accurate identification of the minor classes as compared 
to SMOTE. The decision tree algorithms (i.e., JRip) along 
with Nave Bayes are more effective in the identification 
of the minor classes as compared to the RBF and support 
vector machine algorithms. Moreover, we found that no 
single algorithm can be used for the classification of 
multiclass data of network intrusions. However, the 
combination of the classifiers i.e., Nave Bayes and JRip 
could be used for the classification of minor classes of 
imbalance class data of network intrusion detection. 
Therefore, we recommend a combination of two 
classifiers consisting of Nave Bayes and JRip to classify 
all the classes especially the minor classes with great 
accuracy. In future, we will work to develop a model by 
aggregating these two classifier models using linear 
weight estimation techniques. 
 
 
Figure 1.0 Precision of Classifiers 
 
TABLE 3.0 
TP RATE OF CLASSIFIERS UNDER TWO DIFFERENT SAMPLING TECHNIQUES 
 
 Intrusion Type 
 Normal DoS Probe R2L U2R 
TP Rate Sampling Technique Sampling 
Technique 
Sampling 
Technique 
Sampling 
Technique 
Sampling Technique 
 SMOTE U_Samp SMOT
E 
U_Sam
p 
SMOT
E 
U_Sa
mp 
SMOT
E 
U_Sam
p 
SMOTE U_Samp 
Cj48 0.999 0.999 0.999 0.987 0.926 0.952 0.969 0.988 0.615 0.735 
JRip 1 0.999 .999 0.998 0.906 0.948 0.972 0.974 0.635 0.768 
Bagging .999 1 1 1 0.893 0.949 0.968 0.971 0.558 0.638 
SMO 0.996 0.996 0.983 0.994 0.775 0.861 0.833 0.883 0.442 0.508 
RBF 0.979 0.981 0.977 0.974 0.394 0.393 0.171 0.468 0 0 
Naïve 
Bayes 
.922 0.952 0.964 0.96 .202 0.641 0.373 0.372 0.827 0.91 
Multi 
Class 
0.996 0.996 .992 0.997 0.653 0.88 0.882 0.503 0.365 0.558 
Random 
forest 
1 0.999 0.998 0.995 0.937 0.961 0.975 0.827 0.673 0.978 
 
 
 
149
 
 
REFERENCES 
 
[1] A.H. Sung and S. Mukkamala. “Identifying (2003) “Important 
Features for Intrusion Detection Using Support Vector Machines 
and Neural Networks”. Proceedings of the 2003 Symposium on 
Applications and the Internet, pages 209–216. 
[2] Ali Al-Shahib1, Rainer Breitling, and David Gilbert1,(2005),”new 
feature selection method for protein function prediction”, 
International Journal of Neural Systems 15 (4) : 259- 275 
[3] A. Estabrooks and N. Japkowicz. “A Mixture-of-Experts 
Framework for Learning from Imbalanced DataSets” , (2001). In 
Proceedings of the 4th International Conference on Advances in 
Intelligent Data Analysis, pages 34–43, London, UK.  
[4] BBC.Spies ’infiltrate US power grid’, 
2009c,http://news.bbc.co.uk/1/hi/technology/7990997.stm” 
[5] E. Stamatatos.( 2008) “Using text sampling to handle the class 
imbalance problem”, , Information Processing and Management, 
44, pp.790–799. 
[6] G. Cohen, M. Hilario, H. Sax, S. Hugonnet and A. 
Geissbuhler.(2006) “Learning from imbalanced data in surveillance 
of nosocomial infection, Artificial Intelligence in Medicine, 37, 
pp.7–18. 
[7] H. Guo and H.L. (2004)“Viktor. Learning from imbalanced data 
sets with boosting and data generation:. SIGKDD Explorations 
Newsletter,.  6, pp. 30–39. ISSN 1931-0145. 
[8] C. Kruegel, F. Valeur and G. Vigna.( 2004) “Intrusion Detection 
and Correlation: Challenges and Solutions”. Springer-Verlag Telos, 
35, pp. 27–30 
[9] D.A. Cieslak, N.V. Chawla and A. Striegel. (2006),”Combating 
Imbalance in Network Intrusion Datasets.”,In IEEE Int. Conf. on 
Granual Computing, ,. 
[10] J. McHugh, “Testing intrusion detection systems: (2000) “a critique 
of the 1998 and 1999 darpa intrusion detection system evaluations 
as performed by lincoln laboratory,” ACM Transactions on 
Information and System Security, vol. 3, no. 4, pp. 262–294,. 
[11] N.V. Chawla (2003). C4.5 and Imbalanced Data sets: Investigating 
the effect of sampling method, probabilistic estimate, and decision 
tree structure. In ICMLWorkshop on Learning from Imbalanced 
Datasets II,. 
[12] P. Dokas, L. Ertoz, V. Kumar, A. Lazarevic, J. Srivastava and P. 
Tan (2002), Tan.” In Proceedings of the NSF Workshop on Next 
Generation Data Mining” , Baltimore, MD, pp. 221-224 
[13] R.A. Kemmerer and G. Vigna. (2002). Intrusion Detection: A Brief 
History and Overview. Computer, 35, 27–30 
[14] S. J. Stolfo, W. Fan, W. Lee, A. Prodromidis, and P. K. Chan, 
(2000)“Costbased modeling for fraud and intrusion detection: 
Results from the jam project,” discex, vol. 02, p. 11-30. 
[15] S. Kotsiantis, D. Kanellopoulos and P. Pintelas. (2006). “Handling 
imbalanced datasets: A review.” GESTS International Transactions 
on Computer Science and Engineering, 30, 25–36. 
[16] T.M. Khoshgoftaar, M. Golawala and J. van Hulse.(2007) “An 
Empirical Study of Learning from Imbalanced Data Using Random 
Forest”. In ICTAI ’07: Proceedings of the 19th IEEE International 
Conference on Tools with Artificial Intelligence - Vol.2 (ICTAI 
2007), pages 310–317.  
[17] Xinjian Guo, Yilong Yin1, Cailing Dong, Gongping Yang, 
Guangtong Zhou (2008) “On the class Imbalance Ptoblem,” Fourth 
International Conference on Natural Computation  
[18] T.M. Khoshgoftaar, M. Golawala and J. van Hulse. An Empirical 
Study of Learning from Imbalanced Data Using Random Forest. In 
ICTAI ’07: Proceedings of the 19th IEEE International Conference 
on Tools with Artificial Intelligence - Vol.2 (ICTAI 2007), pages 
310–317, Washington, DC, USA, 2007. IEEE Computer Society. 
ISBN 0-7695-3015-X. 
[19] Xinjian Guo, Yilong Yin1, Cailing Dong, Gongping Yang, 
Guangtong Zhou On the class Imbalance Ptoblem, Fourth 
International Conference on Natural Computation 2008 
[20] Y-M. Huang, C-M. Hung and H.C. Jiau. Evaluation of neural 
networks and data mining methods on a credit assessment task for 
class imbalance problem. 2006.,Real World Applications, 7, 720–
747. 
[21] Y. Chen, Y. Li, X-Q. Cheng and L. Guo. Survey and Taxonomy of 
Feature Selection Algorithms in Intrusion Detection System. In 
Information Security and Cryptology, pages 153–167. Springer, 
2006. 
[22] Z.S. Pan, S.C. Chen, G.B Hu and D.Q. Zhang. Hybrid Neural 
Network and C4.5 for Misuse Detection. In Machine Learning and 
Cybernetics, pages 2463–2467. 












150
