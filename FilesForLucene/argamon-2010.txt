Chapter 5
The Rest of the Story: Finding Meaning
in Stylistic Variation
Shlomo Argamon and Moshe Koppel
Abstract The computational analysis of the style of natural language texts, compu-
tational stylistics, seeks to develop automated methods to (1) effectively distinguish
texts with one stylistic character from those of another, and (2) give a meaningful
representation of the differences between textual styles. Such methods have many
potential applications in areas including criminal and national security forensics,
customer relations management, spam/scam filtering, and scholarly research. In this
chapter, we propose a framework for research in computational stylistics, based
on a functional model of the communicative act. We illustrate the utility of this
framework via several case studies.
5.1 Introduction
When we speak of the “style” of a work, we may be referring to any one (or several)
of a diverse set of concepts. We have seen, for example, views of style as being an
individual’s personal, historically-influenced mode of artistic expression (Chap. 1,
by Cohen), a concept organizing how observers tend to interpret a work (Chap. 2,
by Stiny), a means of conveying emotion (Chap. 3, by Dannenberg), and a means of
implicitly contextualizing a work as part of a certain genre (Chap. 4, by Reiter and
Williams).
In this chapter, we will explore textual style, via the automated analysis of written
texts, known as computational stylistics. In this effort, we have two primary goals:
(a) to develop methods to automatically distinguish texts with a certain stylistic
character from those of another, and (b) to distill an interpretable representation of
the difference between such stylistic characters. We ultimately seek an inclusive
view of the nature of style, endeavoring to cover the individual style of a genius
as well as the generic style of a collective, style’s communicative functions as well
S. Argamon (B)
Department of Computer Science, Illinois Institute of Technology, Chicago, IL 60645, USA
e-mail: argamon@iit.edu
S. Argamon et al. (eds.), The Structure of Style,
DOI 10.1007/978-3-642-12337-5_5, C© Springer-Verlag Berlin Heidelberg 2010
79
80 S. Argamon and M. Koppel
as its social determinants, and the intentions of the author as well as the potential
reactions of the reader.
We approach this question from semantic and pragmatic perspectives, taking the
“style” of a text to cover the broad range of meanings that lie beyond what is conven-
tionally thought of as the text’s “content”. Such content may be thought of as the
“denotational meaning” of the text, roughly covered by the proverbial “Six Ws”:
Who, What, Where, Why, When, and How. By “style”, then, we mean pretty much
everything else that we can know from a text about the communicative act that it
embodies. The basic idea is that the text’s style may be defined as the particular way
in which the author chose to express her desired content, from among a very large
space of possible ways of doing so. We may broadly contrast, therefore, the manner
or method of a text (style) from what the text is about (content). It is important to
keep in mind that any stylistic characterization is essentially counterfactual, in that
a particular style gains its meaning by virtue of its difference from other styles that
might have been chosen instead.
Style, thus construed, includes interpersonal aspects of meaning such as affect,
sociolinguistic categories such as genre and register, idiolectic aspects such as
author identity and personality, and specifics of the individual speech act such as
the medium of transmission and the purpose of the text. These notions relate the
details of a text’s construction to its larger context, as fleshed out in Sect. 5.2 below.
These form a rather diverse set of characteristics; we argue that they can be usefully
considered together for the purposes of computational textual analysis.
The diversity of stylistic textual characteristics is reflected in the large number
of possible applications for style analysis that are already being explored. Current
areas of application include authorship attribution and profiling [5, 14, 22, 31, 60,
80, 84, 96, 98], genre-based text classification and retrieval [36, 57, 58], sentiment
analysis [88, 99], and spam/scam filtering [1, 67, 89]. Other potential applications
include criminal and national security forensics [24, 82], mining of customer feed-
back [18, 81], and aiding humanities scholarship [7, 51, 53, 75]. Automated stylistic
analysis thus promises new tools that may help with the ever-increasing number of
texts available in all topics and application domains.
In this chapter we present a framework for research in computational stylistics
based on a model of the communication act, in which stylistic analysis is framed as
the task of figuring out the determinative aspects of that act from a text, as opposed
to figuring out its denotative meaning. We then consider three specific case studies:
profiling the age and sex of an author, verifying authorship of disputed texts, and
analyzing differences in scientific reasoning based on linguistic clues. These case
studies show some of the range of what can now be done as well as point towards
future research and applications.
5.1.1 Features
Perhaps the key issue in computational stylistic analysis is the choice of textual fea-
tures to use for modeling documents’ styles. While topic-based text categorization
typically work well using models based on “bags of content words”, style is more
5 The Rest of the Story: Finding Meaning in Stylistic Variation 81
elusive. We start from the intuitive notion that style is indicated by features repre-
senting the author’s choice of one mode of expression from a set of equivalent modes
for a given content. At the surface level, this may be seen in the specific choices
of words, syntactic structures, discourse strategies, and so forth in a document.
The underlying causes of such variation are similarly heterogeneous, including the
genre, register, or purpose of the text, as well as the educational background, social
status, and personality of the author and audience. What all these kinds of variation
have in common, though, is an independence from the “topic” or “content” of the
text, which may be considered to be those objects and events that it refers to (as
well as their properties and relations as described in the text). Furthermore, textual
features of style (as opposed to content) tend to function mostly in the aggregate—
no single occurrence of a word or syntactic structure indicates style, but rather an
aggregate preference for certain choices in a text rather than others.
Most work on computational stylistics to date has been based on hand-selected
sets of content-independent features such as function words [75, 84, 100], parts-
of-speech and syntactic structures [96], and clause/sentence complexity mea-
sures [29, 105]; such features have been catalogued in surveys by Karlgren [57],
Juola [56], and Koppel et al. [64]. While new developments in machine learning and
computational linguistics have enabled larger numbers of features to be generated
for stylistic analysis, it is still difficult to articulate strong linguistic motivations
for any preferred input feature set that relates it directly to particular stylistic con-
cerns. Rather, the general methodology that has developed is to find as large a set of
content-independent textual features as possible and use them as input to a generic
learning algorithm (preferably one resistant to overfitting, and possibly including
some feature selection). Some interesting and effective feature sets have been found
in this way, such as [57, 65]; function words have also proven to be surprisingly
effective on their own [5, 11, 80].
In the long term, however, a clear foundation in a linguistic theory of meaning
will be needed to gain true insight into the nature of the stylistic dimension(s) under
study. One effort in that direction is the development of linguistic-functional fea-
ture sets for analyzing texts, such as that presented in Sect. 5.3.3 below. As will be
discussed, differences between classes of texts in usage of these features will often
have direct linguistic interpretations in terms of their different communication func-
tions. Such an understanding can help elucidate the nature and causes of stylistic
differences between texts created in different contexts and circumstances.
We should note that at times textual features that mainly indicate topic (e.g.,
“content words”) may be useful for a form of “stylistic discrimination”. This is a
fine point, but we distinguish based on the goal of the analysis. If the goal is to
characterize aspects of the text essentially extraneous to its denotation, then even if
this analysis examines (say) variation in preferences between words like “king” and
“love” (certainly content-bearing), we may say that our analysis has a fundamental
relation to style. Certainly in non-textual media, such as music and (abstract) art, the
concept of the ‘denotation’ of a work as opposed to its stylistic content is vague to
nonexistent. We will thus examine content-related features in some of our analyses
of style, while remaining wary of potential methodological pitfalls.
82 S. Argamon and M. Koppel
5.1.2 Overview
Our goal in this chapter is to provide an initial framework for such study, and show
how some useful insights can be gleaned from computational stylistic analyses.
After outlining a model of the communicative act as a framework for research in
computational stylistics (Sect. 5.2), we describe a general computational frame-
work for stylistic analysis of texts (Sect. 5.3). We then discuss three case studies
using these methods: profiling blog authors by age and sex (Sect. 5.4), verifying
the authorship of a single disputed text (Sect. 5.5), and analyzing scientific writing
to see how writing style may reflect diversity in scientific methodology (Sect. 5.6).
Finally, we discuss how these various results all contribute to the overall research
framework we are developing, and what we believe the next fruitful steps to be in
this work.
5.2 Style and the Communicative Act
To develop a meaningful characterization of stylistic variation, as derived from com-
putational analysis of texts, we first discuss the nature of the “communicative act”
which a text embodies. This is by way of conceiving a “generative model” for pur-
poses of stylistic analysis; our research goals will be to extract information about
the specific processes that generated a certain text or set of texts. The idea is that
among the components of the communicative act, we can tease apart the aspects of
what we call “style”. We seek therefore to model how various factors constituting
the communicative act influence (in various ways) the composition of a text. Given
such a “generative” model, the goal of computational stylistics is to determine, to the
extent possible, the unobserved features of a communicative act from its observed
product—the text. Again, by “stylistic” we mean those aspects that are (relatively)
independent1 of the chosen “content”.
Figure 5.1 depicts the fundamental elements of the communicative act. The most
basic influences on the character of any communicative act are its participants: the
Author (equivalently, the “writer” or “speaker”) who is the source of the text, and the
Audience (equivalently, the “reader”, “listener”, or “recipient”) to whom the text is
conveyed. Of course, when analyzing a non-conversational text, the text itself gives
no possible access to the nature of the actual Audience, hence we are interested in
the Audience that the Author had in mind; it is that intended Audience to which we
must refer. The identities and characteristics of the Author and Audience can affect
the nature of the text communicated between them—hence the classical stylistics
problem of authorship attribution, for example.
1 We note that insofar as preferences for certain topics may be intimately related to other aspects of
the communicative act that we consider within the purview of style, variation in content variables
may be a legitimate and useful object of study. In particular, see the discussion in Sect. 5.4.
5 The Rest of the Story: Finding Meaning in Stylistic Variation 83
Author Audience
Medium
Context
(ontology, ideology, intertext)
Content
Purpose
Text
Fig. 5.1 Schematic diagram of the communicative act
Three other elements are also directly implicated in the composition of the text.
First, a text is seen to encode some Content, normally conceived of as some sort of
propositional content denoted by the text. For example, the declarative clause “The
red book is on the table,” denotes the proposition that a book which is red and whose
identity is assumed known, is on a table whose identity is also assumed known;
the propositional meaning of questions or requests is trickier (and still debated by
semanticists), but for our purposes questions can be thought of as underspecified
propositions and requests can be thought of as representing potential future events.
For example, the request “Please give me the book,” represents a possible future
event of the Audience giving a book, whose identity is known, to the Author.
Second, in addition to such propositional Content, the Purpose of the communi-
cation affects the form of the text, by expressing its Content in a speech act designed
to accomplish that purpose [13, 94]. Thus, in the previous example, the form of the
imperative sentence is dictated by its Purpose as a request. So we see that the Pur-
pose specifies, to some extent, the grammatical and rhetorical form of the text. The
overall form and texture of an essay geared to informing a student about the effects
of monetary policy on inflation will differ noticeably from that of one geared to
convincing voters of the advantages of a particular policy, even though the Content
of both may be very similar.
Third, the Medium through which the text is expressed can affect its composition
in both overt and subtle ways. To take two modern extremes, the Medium of a book
affords greater possibilities of depth and options for variety of expression than does
the Medium of an instant message (IM), while the implicit intimacy and speed of
sending an IM offers possibilities that writing a book may lack. Certainly, texts in
these two Media are distinguishable based on a few key surface features (e.g., text
length, certain abbreviations, syntactic “well-formedness”).
Finally, in addition to these five direct influences on the character of a particular
text, we must also consider the larger Context in which the communicative act takes
place. This includes its direct social context, the organization(s) or institution(s)
sanctioning the communication, which may impose constraints on the form of the
text (in an extreme case, through specific editorial guidelines). We may also consider
84 S. Argamon and M. Koppel
the less-direct influence imposed by the context of the enclosing culture, as medi-
ated through various overlapping communities: communities of practice [52, 101],
formed of people engaged together in a given activity (e.g., a project team, or a
club), communities of association, formed of people sharing location and resources
(e.g., a neighborhood), and discourse communities [48, 97], comprising groups of
people with a shared textual history.
Without entering into existing debates on the exact nature of such communal
groupings, their relationships with each other, and their precise influences on textual
form, we may identify (in a neutral fashion) three mediating factors for context’s
effect on the form of communicative act realized as a text. First, we identify the
role of ontology, or a theory of what is [28, 43, 44]. Different cultural contexts may
entail different commitments to the sorts of objects that exist, how they are referred
to in the language, and the taxonomic relationships that may obtain between them.
Examples of ontological differences include, for example, the variation in food
items available in different regions, and in other everyday items—modern urbanites
are more likely to have reference to automobile care than farm animal care. As well,
specialized fields such as science or metaphysics may reify certain abstract concepts
and processes, treating them as tangible objects in their discourse.
Second, we consider the role of an ideology, which establishes a set of possible
social roles and assumed relationships between them of prestige and of power [71].
It is the ideological context that provides the background for the interpersonal rela-
tionship(s) between the Author and the Audience which affects the nature of the text,
in terms of its formality, politeness, level(s) of epistemic commitment, and so on.
Third, we must also consider the intertext, or background of all pre- and co-
existing texts that may have influenced the composition of the text under consider-
ation. This may be by direct quotation or citation, by the incorporation of similar
thematic elements or rhetorical structures, or by the use of particular phraseology.
Much or even most such intertextual reference may not be conscious, but rather
incorporation of textual elements “floating” in a background knowledge of a body
of texts. A community of discourse is distinguished primarily by its having a par-
ticular intertextual history to which its texts make reference; prime examples are
traditional religious communities whose texts often refer back to the community’s
acknowledged canonical religious texts.
In terms of this model (cf. Fig. 5.1), the goal of an inclusive stylistic analysis
is, given a text, to glean as much as possible about the various components of the
communicative act it embodies, apart from its denotative Content (we will term
these the stylistic facets of the act). Thus, authorship attribution and profiling, iden-
tifying the genre of a text (i.e., its purpose and place in some community), and
determining social power relations realized in a body of texts thus all involve forms
of stylistic analysis in our terms. Certainly there are correlations between these
different facets—particular authors will have idiosyncratic topical preferences, cer-
tain topics are largely embedded in communal discourses that come with particular
stylistic commitments (e.g., scholarly disciplines), different media may be more or
less appropriate for various types of content or purpose, and so on. Furthermore,
how a text expresses its purpose, for example, depends on its particular content and
5 The Rest of the Story: Finding Meaning in Stylistic Variation 85
context. Thus no one stylistic facet can be considered entirely in isolation apart from
all the others. However, in the context of a specific research question, one or another
facet may be usefully considered in relative isolation, provided that appropriate cau-
tion be exercised in drawing general conclusions. In particular, although preferences
for certain topics would typically be considered content rather than style, they may,
in appropriate circumstances, be taken as stylistic as well. This is when such topical
preferences are (a) strongly correlated with certain communicative circumstances
(e.g., author characteristics, or particular ideologies), and (b) have semantic associ-
ations with those same circumstances.
The model described above cannot be considered in a vacuum, and is closely
related to systemic functional models of register, context, and culture, such as those
discussed by Martin [71], Halliday [46], Gregory [42], and Fawcett [34], among
others. For example, in terms of systemic register theory, our notion of Content
parallels Halliday’s “field” (though Ontology is also relevant), while the conjunc-
tion of Author and Audience determines Gregory’s “personal tenor” (included with
Purpose in Halliday’s “tenor”), and the Medium is essentially the “mode”. Genre
effects are embedded in our model as as realizations of different Purposes within a
discourse community (or community of practice); the communal dimension fore-
grounds aspects of Context in genre analysis—as Halliday and Martin (among
others) have noted, ideology is a key player in the construction of genre. Note
that we are not proposing here any new linguistic theory of these phenomena, but
merely suggest a model that is useful for organizing research on automated style
analysis.
The three case studies discussed below in this chapter examine several different
stylistic facets and their interrelationships within this framework. First, we exam-
ine aspects of the Author, considering textual correlates of the age and sex of blog
authors; as we will see this also implicates Content and Context. Our second case
study deals with other aspects of the Author, in examining how to verify the author-
ship of a disputed text; this also potentially involves Purpose, insofar as deception
may be involved. Finally, we consider two results in analyzing scientific writing to
seek textual correlates of different scientific methodologies. This involves the inter-
action between Content and Purpose, within particular disciplinary Contexts. Before
discussing these case studies, however, we will first describe the main methods of
computational stylistics.
5.3 Computational Stylistics
Research in computational stylistics seeks effective models of language style by
applying machine learning algorithms to stylistically meaningful features. The roots
of the field go back to the studies of Mendenhall [83] and Mascol [73, 74] in
the late 19th century on the use of word-length statistics for determining author-
ship. In the 20th century, the foundations of such “stylometric analysis” were
further advanced by Yule’s statistical studies of word-length and part-of-speech
86 S. Argamon and M. Koppel
distributions in literary prose [105, 106], and Mosteller and Wallace’s authorship
study of The Federalist Papers [84], based on a Bayesian analysis of function word
frequencies. Due to the high cost of computing and analyzing such features before
the wide availability of powerful computers, stylometrics researchers had, until
recently, traditionally sought relatively simple statistically valid models of stylistic
distinctions, based on a small number (dozens, at most) of easily-computed textual
statistics, such as word-frequencies [84], phrase-type frequencies [14], or sentence-
complexity [106].
5.3.1 Text Classification
Recent research on machine learning techniques for text classification, however,
has developed more sophisticated learning algorithms which can use combina-
tions of many thousands of features to classify documents according to topic (see
Sebastiani’s [95] excellent survey). Working systems that have been developed use
a variety of modern machine learning techniques such as Naïve Bayes [68, 69],
Winnow [27], and Support Vector Machines [55]. Recent work on applying machine
learning and statistical methods for text classification to stylometric features for
style analysis has achieved useful techniques for authorship attribution [4, 8, 96],
genre analysis [12, 19, 33, 75], and other applications [41, 51, 61].
Text categorization is a key problem in the field of machine learning [95]. The
task is, given two or more classes of ‘training’ documents, to find some formula (a
“classification model”) that reflects statistical differences between the classes and
can be used to classify new documents. For example, we might wish to classify
a document as being about one of a number of possible known topics, as having
been written by a man or a woman, as having been written by one of a given set of
candidate authors and so forth.
Figure 5.2 depicts the basic architecture of a text categorization system in which
we are given examples of two classes of documents, Class A and Class B. The first
step, document representation, involves defining a set of text features which might
potentially be useful for categorizing texts in a given corpus (for example, words
that are neither too common nor too rare) and then representing each text as a vector
in which entries represent (some non-decreasing function of) the frequency of each
feature in the text. Optionally, one may then use various criteria for reducing the
dimension of the feature vectors [37, 104].
Once documents have been represented as vectors, there are a number of learning
algorithms that can be used to construct models that distinguish between vectors
representing documents in Class A and vectors representing documents in Class B.
Yang [103] compares and assesses some of the most promising algorithms, which
include k-nearest-neighbor, neural nets, Winnow, Support Vector Machines, etc.
One particular class of learned model which is easy to understand and analyze, and
which we use here, is the linear separator. The basic idea is that each feature xi is
assigned a weight wci for each possible text class c; these weights collectively form
5 The Rest of the Story: Finding Meaning in Stylistic Variation 87
Significant
Features
Classification
Model
Labeled
Feature Vectors
:
:
:
<x1,…,xN> = B
<x1,…,xN> = B
<x1,…,xN> = B
<x1,…,xN> = A
<x1,…,xN> = A
<x1,…,xN> = A
:
:
Machine
Learning
Text Classification
A
B
Text
cleaning;
Natural
language
processing;
Feature
extraction
Test
Unlabeled
Feature Vectors
<x1,…,xN>
<x1,…,xN>
<x1,…,xN>
…
:
Classification
Accuracy
Fig. 5.2 Generic text categorization system architecture. Training texts from categories “A” and
“B” are first processed to clean extraneous material (such as HTML), compute linguistic features
(parts-of-speech or syntactic phrases), and compute feature frequencies. The resulting labeled vec-
tors are fed into a machine learning algorithm that creates a classification model that can then be
applied to test documents to evaluate accuracy. The model can also (in many cases) be examined
to determine which features are most significant for classification
several weight vectors wc. The dot-product of weight vector wc with a text’s feature
vector x gives the text’s score for class c; the class with the highest score is assigned
to the text.
A number of different methods with somewhat different properties are currently
used for computing such linear text classification models. Naïve Bayes [69, 79] is
a computationally efficient method which computes an optimal classification model
based on strong statistical assumptions, primarily that feature frequencies are condi-
tionally independent of each other given the output class. While these assumptions
are nearly never satisfied for real problems, in practice the method often works quite
well. Another popular method is that of Support Vector Machines (SVMs) [54], in
which optimization techniques are used to find a weight vector defining a hyper-
plane separating the classes maximizing the distance between positive and nega-
tive examples, as measured perpendicular to that hyperplane. Though training them
is often computationally expensive, SVMs have the important property of being
able to learn well in the presence of very many irrelevant features (resistance to
overfitting). Extensions of the Winnow algorithm [70] have also been used for text
classification [27]. This algorithm uses multiplicative updating of model weights to
quickly home in on those features which are relevant to the classification problem
and discard those which are not. A fourth method of growing importance is Bayesian
logistic regression [38], in which a zero-mean Bayesian prior distribution on the
model parameters is used to reduce its dimensionality, and so reduce the risk of
88 S. Argamon and M. Koppel
overfitting. In general, many learning algorithms will give similar performance for
any given text categorization task, provided that features are chosen well.
5.3.2 Classical Features
For stylistic text classification, learning algorithms which do not require feature
independence and are robust to presence of irrelevant features (such as Winnow,
SVMs, and Bayesian logistic regression), all tend to work well. The main current
research issue in the field, therefore, is the question of what kinds of textual features
are good style discriminators, especially with the use of algorithms that can effec-
tively deal with very large numbers of such features. Features for stylistic discrim-
ination must be invariant as to topic but vary with the specific stylistic dimension
under study.
Our results and those of others [5, 8, 36, 41] have shown that using just relative
frequencies of several hundred function words often gives excellent results. The
intuition behind the use of function words for stylistic analysis is that due to their
high frequency in the language and highly grammaticalized nature, they are unlikely
to be subject to conscious control by the author. At the same time, their frequencies
are seen to vary greatly amongst different authors and genres of text. However, the
highly reductionistic nature of such features seems unsatisfying, as it can be difficult
at times to distill real insights into the underlying nature of stylistic variations.
Adding syntactic features can be advantageous as well, both for efficacy and for
developing understanding. A simple method for that has been used for syntactic
stylistic analysis is to use as features the frequencies of short sequences of parts-of-
speech (nouns, verbs, and the like); such parts-of-speech (POS) can be assigned to
words in a text with upwards of 95% accuracy. Various researchers [14, 66, 96] have
used POS n-grams for authorship attribution; they have also been used for genre
analysis [10] and determining author sex [61]. Full syntactic parsing has also been
applied with some success. Some work has shown [30, 35] that syntactic features
can help for texts such as e-mails, which are highly informal and relatively short.
Often a great deal of insight into the underlying stylistic dimension being studied
can also be found by using content-related features, as we will see in some of the
case studies below.
5.3.3 Functional Lexical Features
A novel feature set that we have recently developed is based on Systemic Func-
tional Grammar (SFG), a functional approach to linguistic analysis [47]. The idea
is to model explicitly functionally-relevant distinctions in language use. SFG mod-
els the grammar of a language by a network of choices of meanings that can be
expressed [76], and so all lexical and structural choices are represented as the
realizations of particular semantic and contextual meanings. The theory takes a
5 The Rest of the Story: Finding Meaning in Stylistic Variation 89
primarily sociological view of language, and has developed largely in the context
of its use by applied linguists for literary/genre analysis and for studying language
learning. (See Butler [23] for an excellent overview of SFG and its relation to other
functional linguistic theories.)
Briefly put, SFG construes language as a set of interlocking choices for express-
ing meanings, with more general choices constraining the possible specific choices.
A choice at one level may open up further choices at other levels, choices that may
not otherwise be possible. For example, English does not allow one to distinguish
between masculine and feminine third-person plural nominal references—only the
pronoun “they/them” is available (see the partial system network for English pro-
nouns in Fig. 5.3). Furthermore, any specific choice of lexical item or syntactic
structure is determined by choices from multiple systems at once, as, e.g., the choice
between “I” and “me” is determined by the independent choice of grammatical case
placing the pronoun as either a syntactic subject or object, respectively.
For our purposes, it suffices to assign attributes to relevant lexical items, where
each such attribute takes on a value from a system taxonomy defined by SFG. For
simplicity, we require that each such taxonomy be represented as a tree, with a
single root and with each entry condition either a single option or a conjunction
of options. This simplifies computational issues, though it only approximates the
full SFG representation which essentially allows system networks to be general
AND/OR graphs; see [76] for a full discussion.
Personal
Pronoun
Singular
Plural
Third
Second
First
Reflexive
Objective
Nominal
Neuter
Feminine
Masculine
Person
Case
Number
“you”
“he”
“she”
“it”
“I”
“me”
“myself”
“we”“they”
Fig. 5.3 Partial system network for English personal pronouns. Note that choices are made simul-
taneously for each of case, person, and number, and some combinations give rise to other possible
choices
90 S. Argamon and M. Koppel
To compute textual features based on such a taxonomy, we first build a lexi-
con of various lexical items representing different nodes within such the taxonomy.
Numeric features for a given text may then be computed based on the lexical items
occuring in it, where each feature is the relative frequency of some option O1 with
respect to some other option O2. Given a text d, we define Nd(O1) to be the number
of occurrences lexical items in d with type O1, similarly we define Nd(O1, O2) to
be of occurrences with both types O1 and O2. Then the relative frequency of O1
with respect to O2 is defined as
RFd(O1|O2) = Nd(O1, O2)
Nd(O2)
The key point here is that the frequency of sibling options relative to their shared
parent allows direct comparison of how different texts prefer to express the parent
via its different options.
This leads to a straightforward “variational” interpretation of a linear classifica-
tion model, in which certain nodes in the taxonomy correspond to features indi-
cating one document class, and other nodes to features indicating the other docu-
ment class. The idea then is to find all oppositions , where an opposition is defined
as a pair of sibling nodes where one indicates one class and the other indicates
the other class. To take a simple example, if PRONOUN-NUMBER/Singular (i.e.,
RFd(Singular|PRONOUN-NUMBER)) is indicative of class A and PRONOUN-
NUMBER/Plural of class B, we would have the opposition:
Condition Class A Class B
PRONOUN-NUMBER Singular Plural
Oppositions given by such analysis provide direct information about linguistic dif-
ferences between two document classes, in that the two classes have differing pref-
erences about what sorts of entities are referred to by pronouns. In the example,
Class A contains relatively more reference to singular individuals, whereas Class B
contains relatively more references to collectives.
The remainder of this subsection outlines the main system networks which we
have used for analyzing textual style. They are divided into three categories, denot-
ing the general “stylistic goals” that these textual features relate to: Cohesion, refer-
ring to how a text is constructed to “hang together”, Assessment, meaning how a text
construes propositions as statements of belief, obligation, or necessity, contextual-
izing them in the larger discourse, and Appraisal, how the text adjudges the quality
of various objects or events. The relevant taxonomies are only summarized here due
to space considerations; a fuller description can be found in [9].
5 The Rest of the Story: Finding Meaning in Stylistic Variation 91
5.3.3.1 Cohesion
Cohesion refers to linguistic resources that enable language to connect to its larger
context, both textual and extratextual [45]. Such resources include a wide variety
of referential modalities (pronominal reference, deictic expressions, ellipsis, and
more), as well as lexical repetition and variation, and different ways of linking
clauses together. How an author uses these various cohesive resources is an indi-
cation of how the author organizes concepts and relates them to each other. Within
cohesion, we consider here only conjunctions, which are easiest to deal with com-
putationally. Automated coreference resolution [16, 87], for example, is a difficult
unsolved problem.
Words and phrases that conjoin clauses (such as “and”, “while”, and “in other
words”) are organized in SFG in the CONJUNCTION system network. Types of
CONJUNCTION serve to link a clause with its textual context, by denoting how
the given clause expands on some aspect of its preceding context [76, pp. 519–528].
The three top-level options of CONJUNCTION are Elaboration, Extension, and
Enhancement, defined as:
• Elaboration: Deepening the content in its context by exemplification or refocus-
ing (for example, in other words, i.e.);
• Extension: Adding new related information, perhaps contrasting with the current
information (and, furthermore, on the other hand);
• Enhancement: Qualifying the context by circumstance or logical connection (and
then, because, similarly).
5.3.3.2 Assessment
Generally speaking, assessment may be defined as “contextual qualification of the
epistemic or rhetorical status of events or propositions represented in a text”. Exam-
ples include assessment of the likelihood of a proposition, the typicality of an event,
the desirability of some fact, or its scope of validity. Two important systems in
SFG that address assessment are MODALITY, enabling expression of typicality
and necessity of some fact or event, and COMMENT, enabling assessment of the
writer’s stance with respect to an assertion in the text.
The system of MODALITY enables one to qualify events or entities in the text
according to their likelihood, typicality, or necessity. Syntactically, MODALITY
may be realized in a text through a modal verb (e.g., “can”, “might”, “should”,
“must”), an adverbial adjunct (e.g., “probably”, “preferably”), or use of a projec-
tive clause (e.g., “I think that . . .”, “It is necessary that . . .”). Each word or phrase
expressing MODALITY has a value for each of four attributes:
• Type: What kind of modality is being expressed?
– Modalization: How “typical” is it? (probably, seldom)
– Modulation: How “necessary” is it? (ought to, allowable)
• Value: What degree of the relevant modality scale is being averred?
92 S. Argamon and M. Koppel
– Median: The “normal” amount. (likely, usually)
– Outer: An extreme (either high or low) amount. (maybe, always)
• Orientation: Relation of the modality expressed to the speaker/writer.
– Objective: Modality expressed irrespective of the speaker/writer. (maybe,
always)
– Subjective: Modality expressed relative to the speaker/writer. (We think . . ., I
require . . .)
• Manifestation: How is the modal assessment related to the event being assessed?
– Implicit: Modality realized ‘in-line’ by an adjunct or modal auxiliary. (prefer-
ably . . ., maybe..)
– Explicit: Modality realized by a projective verb, with the nested clause being
assessed. (It is preferable . . ., It is possible..)
The system of COMMENT provides a resource for the writer to “comment”
on the status of a message with respect to textual and interactive context in
a discourse. Comments are usually realized as adjuncts in a clause and may
appear initially, medially, or finally. We use the eight categories of COMMENT
listed by Matthiessen [76]: Admissive, message is an admission (e.g., “we con-
cur . . .”), Assertive, emphasis of reliability (e.g., “Certainly . . .”), Desiderative,
desirability of the content (e.g., “Unfortunately . . .”), Evaluative, judgment of the
actors involved (e.g., “Sensibly . . .”), Predictive, coherence with predictions (e.g.,
“As expected . . .”), Presumptive, dependence on other assumptions (e.g., “I sup-
pose . . .”), Tentative, assessing the message as tentative (e.g., “Tentatively . . .”), and
Validative, assessing scope of validity (e.g., “In general . . .”).
5.3.3.3 Appraisal
Finally, appraisal denotes how language is used to adopt or express an attitude
of some kind towards some target [72]. For example, in “I found the movie quite
monotonous”, the speaker adopts a negative Attitude (“monotonous”) towards “the
movie” (the appraised object). Note that attitudes come in different types; for
example, “monotonous” describes an inherent quality of the appraised object, while
“loathed” would describe an emotional reaction of the writer. The overall type and
orientation of appraisal expressed in the text about an object gives a picture of how
the writer wishes the reader to view it (modulo sarcasm, of course). To date, we
have developed a lexicon [20] for appraisal adjectives as well as relevant modifiers
(such as “very” or “sort of”). The two main attributes of appraisal, as used in this
work, are Attitude, giving the kind of appraisal being expressed, and Orientation,
giving whether the appraisal is positive (good, beautiful, nice) or negative (bad,
ugly, evil). (There are also other attributes of appraisal, discussed in the Appendix.)
The three main types of Attitude are: affect, relating to the speaker/writers emo-
tional state (e.g., “happy”, “sad”), appreciation, expressing evaluation of supposed
5 The Rest of the Story: Finding Meaning in Stylistic Variation 93
intrinsic qualities of an object (e.g., “tall”, “complex”), and judgment, expressing
social evaluation (e.g., “brave”, “cowardly”).
5.4 Case Study: Author Profiling
In our first case study, we analyze a large corpus of blogs to see to what extent
writing style and topic preferences vary with age and sex of the author [6], and
what this variation may tell us. The main stylistic facet from our framework that is
addressed, therefore, is the Author, with the relation between Author and Content
implicated as well. More subtly implicated are the contextual ontology and ideology,
as they inform the societal roles played by individuals of different ages and sexes.
However, we do not yet here have the tools to address these aspects directly, and
must leave tantalizing questions for future research.
The weblog, or blog, has emerged as a very popular medium for textual self-
expression in recent years—in April 2007, the Technorati blog aggregation site
was tracking over 70 million blogs, which even so constitute only a fraction of
the whole. Blogs therefore constitute a particularly rich data source for authorship
profiling, particularly as many have user-provided profiles of their authors. We note
that blogs per se have their own distinctive stylistic characteristics, and come in
multiple genres, including “personal journals” reporting the (more or less) daily life
of the blogger, “filters” which present sets of links to selected web-documents to
readers, and “knowledge-logs” which host discourse about a project or activity [49].
In this study, we applied two different machine-learning algorithms to age and
sex classification: Bayesian multinomial logistic regression (BMR [38]) and multi-
class balanced real-valued Winnow (WIN [27, 70]), to construct classification mod-
els for author age and for author sex.
5.4.1 The Corpus
The corpus for this study included all blogs on blogger.com in mid-August 2004
that had both author-provided indication of sex and age and at least 200 occurrences
of common English words. The unit of analysis was the collected writing of each
blogger from the blog’s inception date until harvest; we do not distinguish between
different posts by a given blogger. Each blog was labeled for sex and age based
on the blogger’s self-identification. For purposes of analysis, formatting and non-
English text was removed from each blog. To enable reliable age categorization
(since a blog can span several years of writing), all blogs for boundary ages (ages
18–22 and 28–32) were removed. Each blogger was categorized by age at time of
harvest: “10s” (ages 13–17), “20s” (ages 23–27) and “30s” (ages 33–47), and also
by sex: “male” and “female”. To decouple sex from age effects, the numbers of
blogs of each sex within each age category were equalized by randomly deleting
surplus blogs from the larger sex category. The final corpus contained 19320 blogs
94 S. Argamon and M. Koppel
(8240 in 10s, 8086 in 20s, and 2994 in 30s), comprising a total of 681288 posts and
over 140 million words; there were 35 posts and 7300 words per blog on average.
Each blog was represented by a vector containing the frequencies in it of 377 pre-
identified function words as well as of the 1000 words with highest information gain
for age and sex, respectively (as computed on the holdout set). These latter comprise
essentially those content words most correlated with the age and sex categories.
We consider content words here to see to what aspects of content choice may be
influenced by the Context-based facets of author age and sex.
5.4.2 Classification Accuracy
Classification accuracies under ten-fold cross-validation for author age (over all
three age classes) were 77.4% (BMR) and 75.0% (WIN). Results for author sex
were accuracies of 79.3% (BMR) and 80.5% (WIN), consistent with classification
studies on author sex in other corpora [5, 31]. When one takes into account that self-
identified sex and age information by bloggers may often inaccurate and that blogs
commonly include much quoted text, these results might be considered surprisingly
high, clearly showing that author sex and age are indicated by word usage.
5.4.3 Significant Features
What may such differences in language use tell us, however? First, consider the
1000 most frequent words in the corpus overall and how different classes of bloggers
differ in their use. These 1000 words contain 323 different function words and 677
different content words, accounting for 59.4 and 21.7%, respectively, of all word
occurrences. In order to understand underlying patterns of language variation, we
considered naturally occurring word classes.
Function words, the most directly stylistic features considered here, can be
divided straightforwardly into a number of grammatical classes, such as Personal-
Pronouns, Articles, Conjunctions, and so forth. For content words, a straightforward
way to identify natural word classes for a given corpus is to perform factor analysis.
A maximum likelihood factor analysis with equimax rotation and Kaiser normaliza-
tion [39] on the rate of use of each of the 677 most frequent content words yields
twenty coherent factors that depict different content-related themes, each containing
between 13 and 32 words. We assigned intuitive names to the factors: Conversa-
tion, AtHome, Family, Time, Work, PastActions, Games, Internet, Location, Fun,
Food/Clothes, Poetic, Books/Movies, Religion, Romance, Swearing, Politics, Music,
School, Business.
5.4.3.1 Age
Frequencies of the twenty factors’ usage for each age, as well as the same data for
function words broken down by parts of speech, indicate meaningful differences in
5 The Rest of the Story: Finding Meaning in Stylistic Variation 95
both content and style among bloggers of different ages. Among function words,
use of PersonalPronouns, Conjunctions, and AuxiliaryVerbs decreases (p < 0.001)
with age, while use of Articles and Prepositions increases (p < 0.001) with age.
Among the twenty “content-based” factors, use of words associated with Family,
Religion, Politics, Business, and Internet increases (p < 0.001) with age, while use
of words associated with Conversation, AtHome, Fun, Romance, Music, School,
and Swearing decreases (p < 0.001) with age. Use of other factors either doesn’t
vary monotonically or shows no significant differences.
The function word and content word effects noted here are highly correlated: use
of multiple regressions indicates that controlling for style effects essentially elimi-
nates content effects and vice versa. This is not surprising, as we would expect these
feature clusters to be correlated. The function-word features indicate that blogs by
younger authors have a more interpersonal-oriented focus as against a more objec-
tivized focus in blogs by older authors. The semantic character of the distinguishing
factors shows a similar distinction between a focus on personal thoughts, feelings,
and actions, and a focus on external social issues and the outside world.
Two notes of caution about interpreting these results are in order, however. We
must not ignore the fact that since this study is synchronic, we cannot separate gen-
erational effects from age effects. Moreover, since there are many fewer older blog-
gers, they may represent an atypical demographic as early adopters of technology.
5.4.3.2 Sex
Similarly distinctive feature groupings were found when considering author sex.
Among function words, Articles and Prepositions are used more (p < 0.001) by
male bloggers, while PersonalPronouns, Conjunctions, and AuxiliaryVerbs are used
more (p< 0.001) by female bloggers. These results are virtually identical to our pre-
vious results showing textual correlates of male and female authorship in English-
language published fiction and non-fiction from the British National Corpus [5].
Among the “content-based” factors, Religion, Politics, Business, and Internet,
are used more (p < 0.001) by male bloggers, while the factors Conversation, AtH-
ome, Fun, Romance, and Swearing are used more (p < 0.001) by female bloggers.
As in the case of age, multiple regression indicates that controlling for style effects
essentially eliminates content effects and vice versa.
5.4.3.3 Correlating Age and Sex
It is immediately apparent that with just three exceptions, the textual features that
distinguis older from younger bloggers are just those that distinguish male from
female bloggers, and vice versa. The sole exceptions to this pattern are Family, used
more by older bloggers and by females, Music, used more by younger bloggers and
by males, and School, for which there is no significant difference between male and
female usage.
These results therefore suggest a single underlying factor distinguishing inner-
and outer-directed communication (both style and topic) that can explain both
96 S. Argamon and M. Koppel
sex-linked and age-linked variation in language use. The findings thus serve to link
earlier observations regarding age-linked and sex-linked writing variation that have
not previously been connected. Previous studies investigating gender and language
have shown gender-linked differences along dimensions of involvedness [5, 19] and
contextualization [50]. Other studies have found age-linked differences in the imme-
diacy and informality of writing [90]. We suggest that these two sets of results are
closely related.
To properly elucidate the meaning of these findings, more extensive research is
needed to look at larger and more varied corpora to see how consistently author age
and sex are linked to inner-directed and outer-directed communication feature sets.
For example, recent results on sex-linked variation in 18th to 20th century French
literature [3] appear to support the generality of this result. As more texts in differ-
ent languages from different cultures and from different historical periods become
available, we should be able to compare more directly the constellations of features
that indicate author sex and age in different milieus. The use of functional lexical
features in this work may be crucial, as this will enable meaningful comparison of
feature sets between different languages—specific lexical items may not always be
comparable, due to the frequent lack of exact unambiguous translations.
5.5 Case Study: Authorship Verification
The second problem we consider is that of authorship verification [62, 63]. In the
authorship verification problem, we are given examples of the writing of a single
author and are asked to determine if given texts were or were not written by this
author. This question also involves the Author, but specifically personal style as
compared with those of all other potential authors, and also potentially aspects of
the Purpose of the text, insofar as deception may be an issue.
As a categorization problem, verification is significantly more difficult than attri-
bution and little, if any, work has been performed on it in the learning community.
When we wish to determine if a text was written by one of several known authors,
it is sufficient to use their respective known writings, to construct a model distin-
guishing them, and to test the unknown text against the model [21, 84, 92, 100]. If,
on the other hand, we need to determine if a text was written by Author A or not, it
is very difficult, if not impossible, to assemble an exhaustive, or even representative,
sample of not-A. The situation in which we suspect that a given author may have
written some text but do not have an exhaustive list of alternative candidates is a
common one.
The particular authorship verification problem we will consider here is a genuine
literary conundrum. We are given two nineteenth century collections of Jewish rab-
binic responsa written in a combination of Hebrew and Aramaic. The first, RP (Rav
Pe‘alim) includes 509 documents authored by an Iraqi rabbinic scholar known as
Ben Ish Chai. The second, TL (Torah Lishmah) includes 524 documents that Ben
Ish Chai, claims to have found in an archive. There is ample historical reason to
5 The Rest of the Story: Finding Meaning in Stylistic Variation 97
believe that he in fact authored the manuscript but did not wish to take credit for it
for personal reasons [17]. What do the texts tell us?
The first thing we do is to find four more collections of responsa written by four
other authors working in roughly the same area during (very) roughly the same
period. These texts are Zivhei Zedeq (ZZ; Iraq, nineteenth century), Sho’el veN-
ish’al (SN; Tunisia, nineteenth century), Darhei No‘am (DN; Egypt, seventeenth
century), and Ginat Veradim (GV; Egypt, seventeenth century). We begin by check-
ing whether we are able to distinguish one collection from another using standard
text categorization techniques. We select a list of lexical features as follows: the 200
most frequent words in the corpus are selected and all those that are deemed content-
words are eliminated manually. We are left with 130 features. After pre-processing
the text as in the previous experiment, we constructed vectors of length 130 in which
each element represented the relative frequency (normalized by document length)
of each feature. We then used Balanced Winnow as our learner to distinguish pair-
wise between the various collections. Five-fold cross-validation experiments yield
accuracy of greater than 95% for each pair. In particular, we are able to distinguish
between RP and TL with accuracy of 98.5%.
One might thus be led to conclude that RP and TL are by different authors. It is
still possible, however, that in fact only a small number of features are doing all the
work of distinguishing between them. The situation in which an author will use a
small number of features in a consistently different way between works is typical.
These differences might result from thematic differences between the works, from
differences in genre or purpose, from chronological stylistic drift, or from deliberate
attempts by the author to mask his or her identity.
In order to test whether the differences found between RP and TL reflect rel-
atively shallow differences that can be expected between two works of the same
author or reflect deeper differences that can be expected between two different
authors, we invented a new technique that we call unmasking [62, 63] that works
as follows. We begin by learning models to distinguish TL from each of the other
authors including RP. As noted, such models are quite effective. In each case, we
then eliminate the five highest-weighted features and learn a new model. We iterate
this procedure ten times. The depth of difference between a given pair can then be
gauged by the rate with which results degrade as good features are eliminated.
The results (shown in Fig. 5.4) could not be more glaring. For TL versus each
author other than RP, we are able to distinguish with gradually degrading effective-
ness as the best features are dropped. But for TL versus RP, the effectiveness of
the models drops right off a shelf. This indicates that just a few features, possibly
deliberately inserted as a ruse or possibly a function of slightly differing purposes
assigned to the works, distinguish between the works. We have shown elsewhere
[63], that the evidence offered in Fig. 5.4 is sufficient to conclude that the author of
RP and TL are one and the same: Ben Ish Chai.
For example, the frequency (per 10000 words) of the word zeh [= this] in RP
is 80 and in TL is 116. A cursory glance at the texts is enough to establish why
this is the case: the author of TL ended every responsum with the phrase vehayah
zeh shalom [= this shall be farewell], thus artificially inflating the frequency of these
98 S. Argamon and M. Koppel
Fig. 5.4 Accuracy (y-axis) on training data of learned models comparing TL to other collections
as best features are eliminated, five per iteration (x-axis). Dotted line on bottom is RP vs. TL
words. Indeed the presence or absence of this phrase alone is enough to allow highly
accurate classification of a given responsum as either RP or TL. Once features of this
sort are eliminated, however, the works become indistinguishable—a phenomenon
which does not occur when we compare TL to each of the other collections. In other
words, many features can be used to distinguish TL from works in our corpus other
than RP, but only a few distinguish TL from RP. Most features distribute similarly
in RP and TL. A wonderfully illustrative example of this is the abbreviation vkhu’
[= etc.], the respective frequencies of which in the various corpora are as follows:
TL:29 RP:28 SV:4 GV:4 DN:41 ZZ:77. Note that this similarity is unlikely to be due
to regional and chronological dependencies, since GV and DN have widely differing
values, though they were both written in seventeenth century Egypt.
Further experiments with the unmasking technique [63] indicate that the method
can be used succesfully for authorship verification over a range of genres and lan-
guages. Future analyses may examine the nature of the artificially added features
in such cases of deceptive authorship, and ask what, if any, generalizations may be
made about their nature. In some cases, these “deception features” may be based on
general principles (choosing a distinctive new “signature line”, for example). Alter-
natively, the deceptive author may intentionally choose words and catch-phrases
associated with other sociological groups to mislead the reader (such as a conser-
vative Republican author referring to themself as “pro-choice”, thus constructing a
deceptive persona as a liberal Democrat). Thus work on such deceptive texts will be
5 The Rest of the Story: Finding Meaning in Stylistic Variation 99
important, as we work towards developing methods and corpora that enable us to
directly examine influences of ideology and ontology on textual construction.
5.6 Case Study: Scientific Rhetoric and Methodology
A third type of texts that we have studied are peer-reviewed scientific articles [2, 9].
Our motivation in doing so is to see what, if any, stylistic realization there may be
to likely methodological differences between different scientific fields. Our analysis
here thus relates to questions of genre, specifically to the interaction between the
facets of Content and Purpose within a certain disciplinary Context. By restricting
our attention away from content-bearing features (as discussed below), we seek to
find clues about Purpose and perhaps Ideology as independent of the clearly diverse
Ontologies assumed in different fields.
Each scientific field forms a distinct community of discourse, with a shared tex-
tual history in textbooks and the scientific literature; each is also a community of
practice (or an intertwined collection of several), in that scientists in a given field
undertake similar/related research activities in the pursuit of communally-defined
research goals. For these reasons, we might indeed expect that the language used
in articles from one discipline differ from those in another; our goal is to verify
this intuition, and to see if analysis of any differences found can shed any light on
how scientists in different fields construe their arguments in different ways and for
different purposes.
5.6.1 Scientific Methodologies
In the early study of the history and philosophy of science, it was generally assumed
that there was a particular “Scientific Method” which informed scientific investi-
gations (as opposed to less-reliable speculative methods). This method (variously
formulated) was modelled essentially on the theoretico-experimental practices of
physics, and tended to devalue sciences such as geology and paleontology, in which
different sorts of reasoning were typically necessary [59, 78, 93]. In recent years,
however, historians and philosophers of science have begun to distinguish between
experimental sciences such as physics, which attempt to formulate general predic-
tive laws, and so rely heavily on repeatable series of controlled experiments which
test hypotheses, and historical sciences such as geology, which study specific con-
tigent past phenomena in an attempt to find unifying explanations for effects caused
by those phenomena [25, 32, 77, 78, 93]. Reasoning in historical sciences, it is said,
consists largely of ‘synthetic’ reconstructive reasoning (retrodiction), as compared
with more explicitly predictive reasoning from causes to possible effects charac-
teristic of experimental science [15, 32, 40, 102]. We summarize here results of
our earlier studies [2, 9] on articles in several fields of experimental and historical
100 S. Argamon and M. Koppel
Table 5.1 Journals used in the studies, giving number of articles per journal in the corpus and the
average length (in words) per article
Journal # Art. Avg. length
H1 Journal of Geology 93 4891
H2 Journal of Metamorphic Geology 108 5024
H3 Biological Journal of the Linnean Society 191 4895
H4 Human Evolution 169 4223
H5 Palaeontologia Electronica 111 4132
H6 Quaternary Research 113 2939
E1 Physics Letters A 132 2339
E2 Physical Review Let. 114 2545
E3 Journal of Physical Chemistry A 121 4865
E4 Journal of Physical Chemistry B 71 5269
E5 Heterocycles 231 3580
E6 Tetrahedron 151 5057
sciences, which show how analysis of style differences can give insights into how
scientific rhetoric reflects methodological differences among the sciences.
The two studies we will discuss analyze a corpus of recent (2003) articles drawn
from twelve peer-reviewed journals in both historical and experimental sciences; the
numbers of articles used from each journal and their average (preprocessed) lengths
in words are given in Table 5.1. They are:
Journal of Geology (geology, historical) includes research on the full range
of geological principles including geophysics, geochemistry, sedimentology,
geomorphology, petrology, plate tectonics, volcanology, structural geology,
mineralogy, and planetary sciences.
Journal of Metamorphic Geology (geology, historical) focuses on metamorphic
studies,2 from the scale of individual crystals to that of lithospheric plates.
Biological Journal of the Linnean Society (evolutionary biology, historical)
publishes work on organic evolution in a broad sense, particularly research
unifying concepts of evolutionary biology with evidence from genetics, sys-
tematics, biogeography, or ecology.
Journal of Human Evolution (evolutionary biology, historical) covers all
aspects of human evolution, including both work on human/primate fossils
and comparative studies of living species.
Palaeontologia Electronica (paleontology, historical) publishes papers in all
branches of paleontology as well as related biological or paleontologically-
related disciplines.
Quaternary Research (paleontology, historical) publishes research in diverse
areas in the earth and biological sciences which examine the Quaternary
2 Metamorphism refers to changes in mineral assemblage and texture in rocks that have been sub-
jected to temperatures and pressures different from those under which they originally formed.
5 The Rest of the Story: Finding Meaning in Stylistic Variation 101
period of the Earth’s history (from roughly 1.6 million years ago to the
present).
Physics Letters A (physics, experimental) publishes research in a wide range
of areas, including : condensed matter physics, theoretical physics, nonlinear
science, statistical physics, mathematical and computational physics, atomic,
molecular and cluster physics, plasma and fluid physics, optics, biological
physics and nanoscience.
Physical Review Letters (physics, experimental) also covers a wide range of
physics research, including: gravitation and astrophysics, elementary parti-
cles and fields, nuclear physics, atomic, molecular, and optical physics, non-
linear dynamics, fluid dynamics, plasma and beam physics, and condensed
matter physics.
Journal of Physical Chemistry A (physical chemistry, experimental) publishes
chemical research at the level of molecules (including dynamics, spec-
troscopy, gaseous clusters, molecular beams, kinetics, atmospheric and envi-
ronmental physical chemistry, molecular structure, bonding, quantum chem-
istry, and general theory).
Journal of Physical Chemistry B (physical chemistry, experimental) publishes
research on materials (including nanostructures, micelles, macro-molecules,
statistical mechanics and thermodynamics of condensed matter, biophysical
chemistry, and general physical chemistry), as well as studies on the structure
and properties of surfaces and interfaces.
Heterocycles (organic chemistry, experimental) publishes research in the areas
of organic, pharmaceutical, analytical, and medicinal chemistry of hetero-
cyclic compounds.
Tetrahedron (organic chemistry, experimental) publishes general experimental
and theoretical research results in the field of organic chemistry and applica-
tions in related disciplines especially bio-organic chemistry.
5.6.2 Experimental and Historical Science
The first study we will discuss compares writing styles between experimental and
historical science journals [2]. We first considered if a difference between the types
of science could be identified, examining the 10-fold cross-validation accuracy of
models built by an SVM (SMO with a linear kernel [91]) for classifying articles as
“experimental” or “historical”, using SFL features of EXPANSION, COMMENT,
and MODALITY over the entire corpus of articles from 12 journals. Average accu-
racy was 81.6%. To calibrate results, we then ran the same discrimination test for all
462 different partitions of the twelve journals into two groups of six journals each.
This gave a mean accuracy of only 65.4% (range 55.4–81.6%), indicating that the
division into experimental and historical sciences is well supported by differences
in style between writing in different journals.
Given this result, we can now consider what consistent pattern of distinguishing
features, if any, emerges. That is, what features can be said to consistently indicate
102 S. Argamon and M. Koppel
either historical or experimental science articles? To do this, we used all training data
for each pair of a historical science journal with an experimental science journal (36
pairs in all), and ranked the features by their weight for one or the other journal in
the weight vector computed by the SMO learning algorithm. We summarize here
the main results; for more detail, see [2].
First, in the system of EXPANSION, we see an opposition between Exten-
sion, which is an indicator for historical science articles, and Enhancement,
an indicator for experimental science articles. This implies that historical sci-
ence articles generally have a higher density of separate informational items,
whereas experimental science articles tend to have fewer discrete information items,
though the information items they do have may have their meaning deepened
or qualified by informationally-related clauses. This may reflect differing princi-
ples of rhetorical organization—experimental scientists preferring a single coher-
ent “story line” focused on enhancements of a small number of focal proposi-
tions, with historical scientists preferring a multifocal “landscape” of connected
propositions. This supports the hypothesis that contrasts contextual examination
of various and highly unique entities by historical science with a more univer-
salist, hence narrowly focused, examination of generic entities by experimental
science.
Further support for such methodological distinctions between kinds of science
are further supported by preferences for types of COMMENT. Validative and Admis-
sive Comments are indicators for historical science articles compared to a very
strong consistent indication of Predictive Comments for experimental science arti-
cles. The latter result is a clear consequence of the experimental scientist’s focus
on predictive accuracyx. Historical sciencex, on the other hand, evinces a rhetorical
need (via Validative Comments) to explicitly delineate the scope of validity of dif-
ferent assertions, likely as a consequence of synthetic thinking [15] about complex
and ambiguous webs of past causation [25]. An Admissive comment marks a clause
as the opinion (perhaps strongly held) of the author; this too appears indicative of a
more hedged and explicitly comparative argumentation style.
Finally, we may consider some aspects of variation in expressions of MODALITY
between the two classes of articles. The primary opposition is in modality Type.
Experimental science writing has a preference for using Modulation (assessing what
“must” or “is able” to happen), which is consistent with a focus on prediction and
manipulation of nature. Concurrently, historical science writing shows a preference
for Modalization (assessing “likelihood” or “usuality”), consistent with the outlook
of an observer who usually cannot directly manipulate or replicate outcomes, and
so (i) cannot make unqualified statements of what must (or must not) happen, and
(ii) uses therefore the method of “multiple working hypotheses”.
These results show how variations in language use between articles from differ-
ent disciplines can be directly linked with the particular modes of reasoning posited
by philosophers for these different kinds of science. Stylistic text analysis thus can
lend some empirical weight to the argument for a multiplicity of methods in science,
rather than a single monolithic “scientific method”.
5 The Rest of the Story: Finding Meaning in Stylistic Variation 103
5.6.3 Geology and Paleontology
In another study [9], we consider if stylistic differences between articles in geo-
logical and paleontological journals may be found, and if so, what they may mean.
As above, we applied the SMO system to learn classification models and measured
accuracy by 10-fold cross-validation. We found that using Conjunction, Modality,
and Assessment features resulted in low classification accuracies (all below 68%),
while Appraisal features gave a higher 77.4%. Using function words together with
all the systemic feature types gave the highest accuracy of 87.5%, higher than using
just function words at 84.9% (p < 0.05). Together, these results indicate that
while paleontology and geology have similar preferences for rhetorical structure
(measured by Conjunction) and epistemic commitments (measured by Assessment),
there are definite stylistic differences, a portion of which relate to the use of evalua-
tive language.
To understand better the differences between geological and paleontological lan-
guage, we next consider oppositions among the top twenty systemic features from
the model constructed for the two article classes using the full feature set, shown
in Table 5.2. Appraisal is the most important, yielding the largest boost in clas-
sification power, as noted above, and accordingly generating many highly ranked
oppositions. ORIENTATION is most important overall—geologists appear to pre-
fer Positive appraisal, while paleontologists prefer Negative. This opposition is also
seen within JUDGEMENT and ATTITUDE. Such appraisal often appears when
describing the results of the current, or of previous, research. Geology appears to
prefer positive appraisal, stressing the cooperative and incremental nature of the
research enterprise, as in, e.g., “. . . collectively and consistently point to a single
conclusion . . .” On the other hand, paleontology tends to prefer negative orientation,
seeming to stress inadequacies of the evidence or of previous work, as, for example,
in, “. . . records are unfortunately much more fragmented . . .”. As well, we see cases
where a researcher will discredit previous work based on new evidence, as in “. . . the
approach taken is fundamentally flawed.” It seems that, in a sense, geologists more
often express positive views of previous work as they often apparently view their
work as adding to it, while paleontologists are more often negative, seeing them-
selves as replacing old ‘truths’ with new ones.
Next, oppositions in APPRECIATION indicate a distinction between a geologi-
cal focus on Reaction (i.e., the effect of the object on an observer) and a paleonto-
logical focus on Composition (i.e., qualities of how the object is put together). This
may indicate that paleontologists are more concerned with analyzing configurations
of complex, multi-part entities (fossils of various sorts), whereas geologists tend
somewhat towards more qualitative evaluations of specimens.
A similar distinction is seen in SOCIALSANCTION and in COMMENT. In
SOCIALSANCTION, we see geologists more concerned with Propriety, i.e., how a
methodology or a piece of evidence may fit with others, whereas paleontologists are
more concerned with Veracity, in terms of how reliable particular methods or bits of
evidence are on their own.
104 S. Argamon and M. Koppel
Table 5.2 Oppositions from the twenty highest-ranked systemic features in geology and paleon-
tology articles, from the model learned using function words plus all systemic features
Condition Geology Paleontology
ORIENTATION Positive Negative
JUDGEMENT/SocialEsteem ORIENT/Positive ORIENT/Negative
JUDGEMENT/SocialSanction ORIENT/Positive ORIENT/Negative
ATTITUDE/Judgement ORIENT/Positive ORIENT/Negative
ATTITUDE/Affect ORIENT/Positive ORIENT/Negative
APPRECIATION ReactionQuality CompositionComplexity
ReactionImpact CompositionBalance
SOCIALSANCTION Propriety Veracity
COMMENT Assertive Validative
Desiderative Presumptive
ENHANCEMENT SpatioTemporal CausalConditional
Similarly, we see two COMMENT types descriptive of geological prose:
Assertive COMMENTs (e.g., “There is surely more to it . . .”), and Desiderative
COMMENTs (e.g., “In doing so, we hope to deduce”), which is consistent with
the apparent focus of geologists on ‘fitting in’ noted above. Paleontologists, on the
other hand, tend more to use Validative COMMENTs, expanding or contracting
the scope of validity of a claim (e.g., “Holocene shells generally lack . . .”), and
Presumptive COMMENTs, evaluating new claims in light of general background
knowledge (e.g., “. . . which apparently are linked with . . .”).
Finally, the single opposition we find within the CONJUNCTION system is
in ENHANCEMENT, where geology prefers SpatioTemporal, while paleontology
prefers CausalConditional. Geological uses of SpatioTemporal conjunction tend to
describe rock configurations and development over time, as well as discourse orga-
nization (in a sort of descriptive “story-line”). Paleontologists, however, are more
often explicit about hypothesized causal links between specimens and historical
events (as in, e.g., “. . . perhaps as a result of migration . . .”).
5.7 Discussion
In this chapter we have presented a view of style as the semantics of the diverse
non-denotational aspects of the communicative act that the text realizes. This view
subsumes previous work in computational stylistics, such as authorship attribution
and genre analysis, as well as suggesting possible new avenues for research, such as
automatic detection of rhetorical purpose, or identification of ideological facets, as
encoded in a given text.
In this framework, there are three fundamental questions to be addressed by a
computational stylistic analysis:
1. Is there indeed an identifiable stylistic distinction between the text categories of
interest? This question can be answered by machine learning as we do here,
or by related statistical techniques such as discriminant analysis or principal
5 The Rest of the Story: Finding Meaning in Stylistic Variation 105
components analysis [22]. If reliable discrimination of out-of-sample documents
can be achieved, then we can legitimately claim to have found a real distinction.
(The significance of the results compared to other possible partitions may need
to be evaluated as well, of course.)
2. What are the textual features most characteristic each of the different classes of
interest? These may be identified by examining the learned classification models
(as here), or by other techniques such as finding high information-gain features or
the like. Examination of these features should reveal if the distinction identified is
indeed stylistic in nature, or if it is primarily content-based (in which case possi-
ble stylistic significance of topic variation should be considered). Also, different
methods for choosing features may give different results; a possible reliability
check is to see if these different feature sets are mostly the same, or if they are
fundamentally different. If the latter, then this difference should be explained.
3. How do these “indicator features” relate to the fundamental facets of commu-
nication that are involved in the stylistic question being considered? Do these
features fall into well-defined categories based on linguistic or sociological cri-
teria? If they can be so organized, then we must see to what extent such group-
ings accord with the distinctions we might expect between the texts based on
the differences in the facets involved in their production. So when we see that
(roughly speaking) women use an “involved” style and men an “informative”
style, we ought to relate this discovery both to variation between men and women
in the typical Content they write about and also to any documented differences
in how maleness and femaleness are construed in the underlying Context of the
discourse. This may be a very involved process, of course, and may require may
analyses of multiple corpora to answer this question with real depth and certainty.
This methodology is exemplified in this chapter by three relatively focused case
studies. While there is certainly a great deal more work to be done, the analyses and
their results enable some general conclusions, and demonstrate the usefulness of our
framework for understanding style.
5.7.1 Case Studies
Each of the three case studies presented here serves to isolate certain stylistic
facets for investigation. Overall, they show how discrimination analysis of con-
trolled corpora with properly chosen feature sets enables semantic/pragmatic char-
acterization of stylistic differences between groups of text that can be linked back
to significant differences in facets of the relevant communicative acts. The case
studies, taken together, address primarily the facets of Author, Purpose, Con-
tent, and Context (specifically ideology and to a lesser extent ontology), with
some consideration of the effects of Medium on textual style. More system-
atic study relating textual effects of these facets, together with Audience and
a more complete treatment of Medium and Context, is certainly needed. Yet
106 S. Argamon and M. Koppel
even these relatively focused analyses point towards some general conclusions
about communication style.
Our first case study shows that the text of a blog carries reliable cues as to both
the age and sex of its author. These results directly bear on influences of the Author
facet on textual style. Less obviously, these results also appertain to the ideology
underlying the text, insofar as age and sex are socially-relevant categories of being.
Our main finding is that the main textual influence of both age and sex of the author
is variation between more inwardly-directed (younger, female) and more externally-
directed (older, male) textual foci. For the case of gender, our results are consistent
both with common stereotypes and with other research on language and gender (e.g.,
[26, 61, 85, 86]). There is less work on the influence of age on language use, though
our results are consistent with results showing a correlation between increasing age
and more focus on future events as opposed to less focus on past events and first-
person reference [90]. The connection between gender and age evident in our results
may indicate a fundamental aspect of how the constructions of gender and age in
our culture’s ideology are linked, though more work will be needed to elucidate the
nature of any such connection.
The second case study we discuss here shows how deceptive features inserted
by the Author can be filtered out, to achieve more reliable authorship attribution.
The fact that such a technique works is strong evidence that there are fundamental
invariants in authorial style. Our admittedly anecdotal examination of the deceptive
features that the unmasking technique filters out gives us reason to believe that
stylistic deception is on a rather coarse level, involving words and phrases with
specific semantic and pragmatic features that the author can consciously recognize
as not occurring in his own writing. But more subtle grammatical constructions
(such as the use of the Hebrew for “etc.” in the texts we examined) will give the
author away.
The third case study we examined looks not at authorship, but at issues of dis-
ciplinary genres in journal articles from different sciences. There, our focus was
on analyzing how differences in scientific methodology, i.e., differences in Purpose
and Context (mainly ideology), show up in the linguistic construction of the texts
of different kinds of science. Our results show first of all that experimental and
historical science articles have clearly distinct characteristic writing styles. Fur-
thermore, we see how these styles are directly linkable to meaningful, previously-
posited, methodological differences between the kinds of science, in terms of pref-
erences for certain cohesion strategies and modal assessments. These indicate that
the main methodological differences are in questions of focus and of evidentiary
reasoning.
More fine-grained distinctions can also be observed, as in our comparison
of geological and paleontological articles. Here we too saw clear stylistic dis-
tinctions between the fields, but the meaningful distinguishing features were
mainly in Appraisal, indicating that methodological differences between the fields
likely lie more in the relationship construed between the researcher and their
“knowledge base”, whether consisting of prior research results or newly observed
evidence.
5 The Rest of the Story: Finding Meaning in Stylistic Variation 107
5.7.2 Future Directions
In our view, a key research goal for computational stylistics is the development of
feature sets which both enable effective stylistic classification and also allow mean-
ingful characterization of the relevant textual styles. The functional lexical feature
set described in this chapter is a first step towards this goal. The idea is that function-
ally meaningful taxonomies of computable features allow discovery of meaningful
oppositions between sets of texts; these oppositions in turn give insight into the
various underlying causes of the stylistic differences, in terms of (e.g.) different
Author characteristics or Purposes.
Developing more extensive and sophisticated such feature sets is but the begin-
ning, though, as relating these features to specific aspects of the communicative act
is non-trivial in general. A key problem is that the textual realizations of these differ-
ent aspects overlap in the text. For example, pronoun use is known to be affected by
characteristics of a text’s Author, its Purpose, and its Medium (cf. [6, 19]). How to
properly deal with these complex interdependencies remains a central open research
question. The question is crucial for applications such as authorship attribution,
where it is necessary to determine whether a stylistic difference between two texts
is due to differing authorship or whether it may be due to differences in genre
or purpose. Progress on this question will require the development of larger and
more complex corpora including texts of many different types by many different
authors.
Our breakdown of the communicative act into component influences may also
prove fruitful for organizing stylistic analyses in expressive media other than text.
The fact that characteristics of the Author and Audience influence style are clear in
all media, though the specific expressive correlates and relevant characteristics may
vary. Harold Cohen, in Chap. 1, has forcefully made the point that understanding
an artist’s choice of Medium for a particular artistic Purpose are essential to a true
understanding of artistic style. Similarly, aspects of musical style can be best under-
stood by relating them to Purposive goals of eliciting emotional responses, as dis-
cussed by Dubnov in Chap. 7, or of serving particular social functions (accompany-
ing dances or the like). Context is also relevant—in all media, the artistic/expressive
history and background, the analogue of the intertext, is certainly a major influence
on style; social ideology is an important influence; and more-or-less elaborated
medium-specific ontologies may also be relevant. We suggest therefore that this
schema, or something like it, could serve as a framework to integrate, to some extent,
work on stylistic analysis in disparate media.
References
1. Androutsopoulos I, Koutsias J, Chandrinos K, Paliouras G, Spyropoulos C (2000) An eval-
uation of Naive Bayesian anti-spam filtering. In: Proceedings of the workshop on machine
learning in the New Information Age, Barcelona.
108 S. Argamon and M. Koppel
2. Argamon S, Dodick J, Chase P (2008) Language use reflects scientific methodology: a
corpus-based study of peer-reviewed journal articles. Scientometrics 75(2):203–238
3. Argamon S, Goulain J-B, Horton R, Olsen M (2009) Vive la différence! text mining gen-
der difference in French literature. Digital Humanit Q 3(2). http://digitalhumanities.org/
dhq/vol/3/2/
4. Argamon S, Koppel M, Avneri G (1998) Routing documents according to style. In: Proceed-
ings of int’l workshop on innovative internet information systems, Pisa, Italy
5. Argamon S, Koppel M, Fine J, Shimony AR (2003) Gender, genre, and writing style in formal
written texts. Text 23(3):321–346
6. Argamon S, Koppel M, Pennebaker JW, Schler J (2007) Mining the blogosphere: age,
gender and the varieties of self-expression. First Monday, 12(9). http://firstmonday.org/
issues/issue12_9/argamon/index.html
7. Argamon S, Olsen M (2006) Toward meaningful computing. Commun ACM 49(4):33–35
8. Argamon S, Šarić M, Stein SS (2003) Style mining of electronic messages for multiple
author discrimination. In: Proceedings of ACM conference on knowledge discovery and
data mining
9. Argamon S, Whitelaw C, Chase P, Dhawle S, Garg N, Hota SR, Levitan S (2007) Stylistic
text classification using functional lexical features. J Am Soc Inf Sci 58(6):802–822
10. Argamon S, Koppel M, Avneri G (1998) Routing documents according to style. In: First
international workshop on innovative information systems, Pisa
11. Argamon S, Levitan S (2005) Measuring the usefulness of function words for authorship
attribution. In: Proceedings of the 2005 ACH/ALLC conference, Victoria, BC, Jun 2005
12. Argamon-Engelson S, Koppel M, Avneri G (1998) Style-based text categorization: what
newspaper am i reading? In: Proceedings of AAAI workshop on learning for text catego-
rization, Madison, WI, pp 1–4
13. Austin JL (1976) How to do things with words. Oxford University Press, Oxford
14. Harald Baayen R, van Halteren H, Tweedie F (1996) Outside the cave of shadows: using
syntactic annotation to enhance authorship attribution. Lit Linguist Comput 7:91–109
15. Baker VR (1996) The pragmatic routes of American quaternary geology and geomorphology.
Geomorphology 16:197–215
16. Bean D, Riloff E (2004) Unsupervised learning of contextual role knowledge for coreference
resolution. Proceedings of HLT/NAACL, Boston, MA, pp 297–304
17. Ben-David YL (2002) Shevet mi-Yehudah (in Hebrew). No publisher listed, Jerusalem
18. Berry MJ, Linoff G (1997) Data Mining techniques: for marketing, sales, and customer sup-
port. Wiley, New York, NY
19. Biber D (1995) Dimensions of register variation: a cross-linguistic comparison. Cambridge
University Press, Cambridge
20. Bloom K, Garg N, Argamon S (2007) Extracting appraisal expressions. In: HLT/NAACL
2007, Rochester, NY, April 2007
21. Burrows J (2002) ‘Delta’: a measure of stylistic difference and a guide to likely authorship.
Lit Linguis Comput 17(3):267–287
22. Burrows JF (1987) Computation into criticism: a study of Jane Austen’s novels and an exper-
iment in method. Clarendon, Oxford
23. Butler CS (2003) Structure and function: a guide to three major structural-functional theories.
John Benjamins, Amsterdam
24. Chaski CE (1999) Linguistic authentication and reliability. In: National conference on sci-
ence and the law, National Institute of Justice, San Diego, CA
25. Cleland CE (2002) Methodological and epistemic differences between historical science and
experimental science. Philos Sci 69(3):447–451
26. Coates J (2004) Women, men and language: a sociolinguistic account of gender differences
in language. Pearson Education, New York, NY
27. Dagan I, Karov Y, Roth D (1997) Mistake-driven learning in text categorization. In: Cardie
C, Weischedel R (eds) Proceedings of EMNLP-97, 2nd conference on empirical methods in
5 The Rest of the Story: Finding Meaning in Stylistic Variation 109
natural language processing, Providence, US, 1997. Association for Computational Linguis-
tics, Morristown, TN pp 55–63
28. D’Andrade RG (1995) The development of cognitive anthropology. Cambridge University
Press, Cambridge
29. de Vel O (2000) Mining e-mail authorship. In: Workshop on text mining, ACM international
conference on knowledge discovery and data mining, Boston, MA
30. de Vel O, Anderson A, Corney M, Mohay G (2001) Mining email content for author identi-
fication forensics. ACM SIGMOD Rec 30(4):55–64
31. de Vel O, Corney M, Anderson A, Mohay G (2002) Language and gender author cohort anal-
ysis of e-mail for computer forensics. In: Proceedings of digital forensic research workshop,
Syracuse, NY
32. Diamond J (2002) Guns, germs and steel: the fates of human societies. W.W. Norton, New
York, NY
33. Dimitrova M, Finn A, Kushmerick N, Smyth B (2002) Web genre visualization. In: Proceed-
ings of the conference on human factors in computing systems, Minneapolis, MN
34. Fawcett RP (1980) Cognitive linguistics and social interaction: towards an integrated model
of a systemic functional grammar and the other components of a communicating mind. John
Benjamins, Amsterdam
35. Feiguina O, Hirst G (2007) Authorship attribution for small texts: literary and forensic
experiments. In: Proceedings of the conference of the international association of forensic
linguistics, Seattle, WA
36. Finn A, Kushmerick N, Smyth B (2002) Genre classification and domain transfer for infor-
mation filtering. In: Crestani F, Girolami M, van Rijsbergen CJ (eds) Proceedings of ECIR-
02, 24th European colloquium on information retrieval research, Glasgow, Springer, Heidel-
berg, DE
37. Forman G (2003) An extensive empirical study of feature selection metrics for text classifi-
cation. J Mac Learn Res 3(7–8):1289–1305
38. Genkin A, Lewis DD, Madigan D (2006) Large-scale Bayesian logistic regression for text
categorization. Technometrics 49(3):291–304
39. Gorsuch RL (1983) Factor analysis. L. Erlbaum, Hillsdale, NJ
40. Gould SJ (1986) Evolution and the triumph of homology, or, why history matters. Am Sci
Jan.–Feb.:60–69
41. Graham N, Hirst G (2003) Segmenting a document by stylistic character. In: Workshop on
computational approaches to style analysis and synthesis, 18th international joint conference
on artificial intelligence, Acapulco
42. Gregory M (1967) Aspects of varieties differentiation. J Linguist 3:177–198
43. Gumperz JJ, Levinson SC (1996) Rethinking linguistic relativity. Cambridge University
Press, Cambridge
44. Hacking I (2002) Historical ontology. Harvard University Press, Cambridge, MA
45. Halliday MAK, Hasan R (1976) Cohesion in English. Longman, London
46. Halliday MAK (1978) Language as social semiotic: the social interpretation of language and
meaning. Edward Arnold, London
47. Halliday MAK (1994) Introduction to functional grammar, 2nd edn. Edward Arnold,
London
48. Harris J (1989) The idea of community in the study of writing. Coll Compos Commun
40(1):11–22
49. Herring SC, Scheidt LA, Bonus S, Wright E (2004) Bridging the gap: a genre analysis of
weblogs. In: Proceedings of the 37th Hawai’i international conference on system sciences
(HICSS-37), IEEE Computer Society, Los Alamitos, CA
50. Heylighen F, Dewaele JM (2002) Variation in the contextuality of language: an empirical
measure. Found Sci 7(3):293–340
51. Holmes DI (1998) The evolution of stylometry in humanities scholarship. Lit Linguis Comp
13(3):111–117
110 S. Argamon and M. Koppel
52. Holmes J, Meyerhoff M (2000) The community of practice: theories and methodologies in
language and gender research. Lang Soc 28(02):173–183
53. Hoover D (2002) Frequent word sequences and statistical stylistics. Lit Linguis Comput
17:157–180
54. Joachims T (1999) Making large-scale SVM learning practical. In: Schölkopf B, Burges C,
Smola A (eds) Advances in Kernel methods—support vector learning. MIT, Cambridge, MA
55. Joachims T (1998) Text categorization with support vector machines: learning with many
relevant features. In: Nédellec C, Rouveirol C (eds) Proceedings of ECML-98, 10th European
conference on machine learning, number 1398, Chemnitz, DE. Springer, Heidelberg, DE
pp 137–142
56. Juola P (2008) Authorship attribution. Found trends Inf Retr 1(3):233–334
57. Karlgren J (2000) Stylistic experiments for information retrieval. PhD thesis, SICS
58. Kessler B, Nunberg G, Schütze H (1997) Automatic detection of text genre. In: Cohen PR,
Wahlster W (eds) Proceedings of the 35 annual meeting of the association for computational
linguistics and 8th conference of the European chapter of the association for computational
linguistics, Association for Computational Linguistics, Somerset, NJ, pp 32–38
59. Kitcher P (1993) The advancement of science. Oxford University Press, New York, NY
60. Kjell B, Frieder O (1992) Visualization of literary style. In: IEEE international conference
on systems, man and cybernetics, Chicago, IL, pp 656–661
61. Koppel M, Argamon S, Shimoni AR (2003) Automatically categorizing written texts by
author gender. Lit Linguist Comput 17(4):401–412
62. Koppel M, Mughaz D, Schler J (2004) Text categorization for authorship verification. In:
Proceedings of 8th Symposium on artificial intelligence and mathematics, Fort Lauderdale,
FL
63. Koppel M, Schler J (2004) Authorship verification as a one-class classification problem. In:
Proceedings of Int’l conference on machine learning, Banff, AB
64. Koppel M, Schler J, Argamon S (2008) Computational methods in authorship attribution. J
Am Soc Inf Sci Technol 60(1):9–26
65. Koppel M, Akiva N, Dagan I (2003) A corpus-independent feature set for style-based text
categorization. In: Workshop on computational approaches to style analysis and synthesis,
18th international joint conference on artificial intelligence, Acapulco
66. Kukushkina OV, Polikarpov AA, Khmelev DV (2001) Using literal and grammatical statistics
for authorship attribution. Prob Inf Trans 37(2):172–184
67. Kushmerick N (1999) Learning to remove internet advertisement. In: Etzioni O, Müller JP,
Bradshaw JM (eds) Proceedings of the 3rd international conference on autonomous agents
(Agents’99), ACM Press, Seattle, WA, pp 175–181
68. Lang K (1995) NewsWeeder: learning to filter netnews. In: Proceedings of the 12th
international conference on machine learning, Morgan Kaufmann, San Mateo, CA,
pp 331–339
69. Lewis DD (1998) Naive (Bayes) at forty: the independence assumption in information
retrieval. Proceedings of ECML-98, 10th European conference on machine Learning, 1998,
Berlin, Springer, Heidelburg, pp 4–15
70. Littlestone N (1987) Learning when irrelevant attributes abound. In: Proceedings of the 28th
annual symposium on foundations of computer science, October 1987, Los Angeles, CA,
pp 68–77
71. Martin JR (1992) English text: system and structure. Benjamin’s, Amsterdam
72. Martin JR, White PRR (2005) The language of evaluation: appraisal in English. Palgrave,
London
73. Mascol C (1888) Curves of Pauline and Pseudo-Pauline style I. Unitarian Rev 30:452–460
74. Mascol C (1888) Curves of Pauline and Pseudo-Pauline style II. Unitarian Rev 30:539–546
75. Matthews RAJ, Merriam TVN (1997) Distinguishing literary styles using neural networks,
chapter 8. IOP publishing and Oxford University Press, Oxford
5 The Rest of the Story: Finding Meaning in Stylistic Variation 111
76. Matthiessen C (1995) Lexico-grammatical cartography: English systems. International Lan-
guage Sciences Publishers, Tokyo
77. Mayr E (1976) Evolution and the diversity of life. Harvard University Press, Cambridge, MA
78. Mayr E (1985) How biology differs from the physical sciences. In: Evolution at the cross-
roads: the new biology and the new philosophy of science, MIT, Cambridge, pp 43–46
79. McCallum A, Nigam K (1998) A comparison of event models for Naive Bayes text classifi-
cation. AAAI-98 workshop on learning for text categorization, 752, pp 41–48
80. McEnery A, Oakes M (2000) Authorship studies/textual statistics, Marcel Dekker, New York,
NY, pp 234–248
81. McKinney V, Yoon K, Zahedi FM (2002) The measurement of web-customer satisfaction:
an expectation and disconfirmation approach. Info Sys Res 13(3):296–315
82. McMenamin G (2002) Forensic linguistics: advances in forensic stylistics. CRC press
83. Mendenhall TC (1887) Characteristic curves of composition. Science 9(214s):237–246
84. Mosteller F, Wallace DL (1964) Inference and disputed authorship: the federalist. Series in
behavioral science: quantitative methods edition. Addison-Wesley, Reading, MA
85. Mulac A, Lundell TL (1986) Linguistic contributors to the gender-linked language effect. J
Lang Soc Psychol 5(2):81
86. Newman ML, Groom CJ, Handelman LD, Pennebaker JW (2008) Gender Differences in
language use: an analysis of 14,000 text samples. Discourse Process 45(3):211–236
87. Ng V (2004) Learning noun phrase anaphoricity to improve coreference resolution: issues in
representation and optimization. Proceedings of the 42nd annual meeting of the association
for computational linguistics (ACL), Barcelona, pp 152–159
88. Pang B, Lee L, Vaithyanathan S (2002) Thumbs up? sentiment classification using machine
learning techniques. In: Proceedings of EMNLP conference on empirical methods in natural
language processing, Philadelphia, PA, pp 79–86
89. Patrick J (2004) The scamseek project: text mining for financial scams on the internet.
In: Simoff SJ, Williams GJ (eds) Proceedings of 3rd Australasian data mining conference,
Carins, pp 33–38
90. Pennebaker JW, Mehl MR, Niederhoffer K (2003) Psychological aspects of natural language
use: our words, our selves. Ann Rev Psychol 54:547–577
91. Platt J (1998) Sequential minimal optimization: a fast algorithm for training support vector
machines. Microsoft research technical report MSR-TR-98-14, Redmond, WA
92. Rudman J (1997) The state of authorship attribution studies: some problems and solutions.
Comput Human 31(4):351–365
93. Rudolph JL, Stewart J (1998) Evolution and the nature of science: on the historical discord
and its implication for education. J Res Sci Teach 35:1069–1089
94. Searle JR (1989) Expression and meaning: studies in the theory of speech acts. Cambridge
University Press, Cambridge
95. Sebastiani F (2002) Machine learning in automated text categorization. ACM Comput Surv
34(1)
96. Stamatatos E, Fakotakis N, Kokkinakis GK (2000) Automatic text categorization in terms of
genre, author. Comput Linguist 26(4):471–495
97. Swales JM (1990) Genre analysis. Cambridge University Press, Cambridge
98. Torvik VI, Weeber M, Swanson DR, Smalheiser NR (2005) A probabilistic similarity metric
for Medline records: a model for author name disambiguation. J Am Soc Inf Sci Technol,
56(2):140–158
99. Turney PD (2002) Thumbs up or thumbs down? semantic orientation applied to unsuper-
vised classification of reviews. In: Proceedings 40th annual meeting of the ACL (ACL’02),
Philadelphia, PA, pp 417–424
100. Tweedie F, Singh S, Holmes D (1996) Neural network applications in stylometry: the feder-
alist papers. Comput Human 30(1):1–10
101. Wenger E (1999) Communities of practice: learning, meaning, and identity. Cambridge Uni-
versity Press, Cambridge
112 S. Argamon and M. Koppel
102. Whewell W (1837) History of the inductive sciences. John W. Parker, London
103. Yang Y (1999) An evaluation of statistical approaches to text categorization. Inf Retr
1(1):69–90
104. Yang Y, Pedersen JO (1997) A Comparative study on feature selection in text categoriza-
tion. Proceedings of the 14th international conference on machine learning table of contents,
Nashville, TN, pp 412–420
105. Yule GU (1994) Statistical study of literary vocabulary. Cambridge University Press,
Cambridge
106. Yule GU (1938) On sentence length as a statistical characteristic of style in prose with appli-
cation to two cases of disputed authorship. Biometrika 30:363–390
