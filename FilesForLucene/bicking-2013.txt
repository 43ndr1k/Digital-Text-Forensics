Syntaktische Identifizierung von
Lobbyeinflüssen auf die
EU-Datenschutz-Grundverordnung
Studienarbeit
Humboldt-Universität zu Berlin
Mathematisch-Naturwissenschaftliche Fakultät II
Institut für Informatik
bearbeitet von: Frank Bicking
Betreuer: Prof. Dr. Ulf Leser
Prof. Dr. Björn Scheuermann
Florian Tschorsch
Datum: 12. Dezember 2013
Inhaltsverzeichnis
1. Einleitung 4
1.1. Motivation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4
1.2. Zielstellung . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4
1.3. Idee . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5
1.4. Aufbau der Arbeit . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5
2. Verwandte Arbeiten 6
2.1. LobbyPlag . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6
2.2. Plagiaterkennung . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6
2.2.1. Klassifikation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7
2.2.2. N-Gramme . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7
3. Grundlagen 10
3.1. Invertierter Index . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10
3.1.1. Präfixbäume . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10
3.1.2. Compact Tries . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12
3.1.3. Burst Tries . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12
3.2. Bewertungsmetriken . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13
3.2.1. TF-IDF-Maß . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13
3.2.2. Matching von N-Grammen . . . . . . . . . . . . . . . . . . . . . . 14
3.2.3. Gesamtscore für Fundstellen . . . . . . . . . . . . . . . . . . . . . . 14
3.2.4. Ranking von Dokumenten . . . . . . . . . . . . . . . . . . . . . . . 14
3.3. Intervallbäume . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15
3.4. Clustering . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16
3.4.1. UPGMA-Algorithmus . . . . . . . . . . . . . . . . . . . . . . . . . 16
3.4.2. Ähnlichkeitsmaß . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18
4. Implementierung 20
4.1. Konvertieren von PDF-Dokumenten . . . . . . . . . . . . . . . . . . . . . 20
4.2. Zerlegung in Wörter . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20
4.3. Erzeugen von N-Grammen . . . . . . . . . . . . . . . . . . . . . . . . . . . 21
4.4. Indexierung und Vergleich . . . . . . . . . . . . . . . . . . . . . . . . . . . 21
2
4.5. Benutzeroberfläche . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22
4.5.1. Färbung der Fundstellen . . . . . . . . . . . . . . . . . . . . . . . . 22
4.5.2. Clustering . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24
5. Auswertung 25
5.1. Textmaterial . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25
5.2. Fundstellen . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25
5.2.1. Einmalige Fundstellen . . . . . . . . . . . . . . . . . . . . . . . . . 28
5.2.2. Textpassagen . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28
5.2.3. Einmalige Textpassagen . . . . . . . . . . . . . . . . . . . . . . . . 31
5.2.4. Lange Textpassagen . . . . . . . . . . . . . . . . . . . . . . . . . . 31
5.2.5. Einfluss der Parameter . . . . . . . . . . . . . . . . . . . . . . . . . 32
5.3. Kategorisierung der Dokumente . . . . . . . . . . . . . . . . . . . . . . . . 33
5.4. Clustering . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34
5.4.1. Clustering nach Vokabular . . . . . . . . . . . . . . . . . . . . . . 35
5.4.2. Clustering nach Fundstellen . . . . . . . . . . . . . . . . . . . . . . 35
6. Zusammenfassung und Ausblick 37
Literatur 39
A. Anhang 42
A.1. Clustering nach Vokabular . . . . . . . . . . . . . . . . . . . . . . . . . . . 42
A.2. Clustering nach Fundstellen . . . . . . . . . . . . . . . . . . . . . . . . . . 45
A.3. Kurzanleitung zu LawPlag . . . . . . . . . . . . . . . . . . . . . . . . . . . 48
3
1. Einleitung
1.1. Motivation
Auf der Ebene der Europäischen Union entsteht derzeit eine neue Datenschutz-Grund-
verordnung mit dem Ziel, den Datenschutz innerhalb aller Mitgliedsstaaten zu harmoni-
sieren. Sie soll die im Jahr 1995 veröffentlichte Richtlinie 95/46/EG ablösen, die derzeit
die Grundlage für die Datenschutzgesetze in den einzelnen Staaten bildet. In Deutschland
wurde sie im Jahr 2001 durch ein Bundesgesetz (BGBl. I Nr. 23 S. 904) ausgestaltet. Beglei-
tend zu diesem Gesetzgebungsverfahren hatte die Europäische Kommission staatliche und
nichtstaatliche Einrichtungen und Organisationen, Unternehmen, aber auch interessierte
Bürger anhand von vorgegebenen Fragenkatalogen zur Stellungnahme aufgefordert. Seit
Mai 2009 fanden mehrere solcher Konsultationen statt [EC09b] [EC09a] [EC10a] [EC10b]
[EC11], die zum Teil nichtöffentlich waren. Bis zum Januar 2011 gingen insgesamt 532
öffentlich einsehbare Dokumente ein. Im Januar 2012 übergab die EU-Kommission ihren
fertiggestellten Gesetzentwurf [EC12] zur weiteren Ausgestaltung an das Europäische
Parlament und den Rat der Europäischen Union. Federführend ist der parlamentarische
Ausschuss für Binnenmarkt und Verbraucherschutz. Auch hier gingen Änderungsvor-
schläge zahlreicher Interessenvertreter ein, die dem Wortlaut des Kommissionsvorschlags
meist gewünschte eigene Fassungen mit entsprechenden Begründungen gegenüberstellten
[Lob13b]. Im Februar 2013 machte der Wiener Jurastudent Max Schrems darauf auf-
merksam, dass einzelne Parlamentsabgeordnete diese Änderungsvorschläge zum Teil eins
zu eins in den Gesetzestext übernommen hatten [Sch13].
1.2. Zielstellung
Thema dieser Arbeit ist die Fragestellung, inwieweit sich mit syntaktischen Mitteln
feststellen lässt, ob die ursprünglichen Konsultationen einen Einfluss auf den Entwurfstext
der EU-Kommission hatten. Zur Beantwortung wurde eine Java-Anwendung entwickelt,
die Dokumente einliest, mit einem Zieldokument vergleicht, anhand der Gemeinsamkeiten
4
bewertet und in eine Hierarchie einordnet. Fundstellen wurden in einer graphischen
Benutzeroberfläche hervorgehoben und nachverfolgbar gemacht.
1.3. Idee
Für das Zieldokument wurden N-Gramme einer frei konfigurierbaren Länge ermittelt. Die
potentiellen Quelldokumente wurden in einem invertierten Index erfasst. Für den Vergleich
wurde in diesem Index nach den einzelnen Wörtern jedes N-Gramms gesucht. Traten
diese in einem bestimmten Abstand zueinander innerhalb eines Quelldokuments auf, so
galt eine Fundstelle als identifiziert. Anhand des TF-IDF-Maßes wurde die Relevanz
der Fundstellen bewertet. Aus diesen Bewertungen ergab sich für jedes Dokument ein
Gesamtscore und damit eine Rangfolge für die Übereinstimmung mit dem Gesetzentwurf.
1.4. Aufbau der Arbeit
Im zweiten Kapitel wird mit LobbyPlag zunächst ein existierendes Projekt vorgestellt,
das sich mit dem Einfluss von Interessenvertretern auf die Datenschutz-Grundverordnung
beschäftigt. Grundlagen zur Plagiaterkennung werden beschrieben und eine Abgrenzung
des in dieser Arbeit gewählten Ansatzes vorgenommen. Kapitel 3 stellt Datenstrukturen
für die Indexierung von Termen in einem Dokumentkorpus vor, definiert Maße für die
Bewertung der Relevanz von Fundstellen und erläutert den Clustering-Algorithmus und
das zugrunde liegende Ähnlichkeitsmaß. Das vierte Kapitel widmet sich der implemen-
tierten Vorgehensweise beim Einlesen, Indexieren und Vergleichen sowie der graphischen
Darstellung der Dokumente. Nach einer Auswertung der Fundstellen und des Clusterings
in Kapitel 5 schließt die Arbeit mit einer Zusammenfassung und einem Ausblick.
5
2. Verwandte Arbeiten
2.1. LobbyPlag
Nach den Aufdeckungen durch Schrems schufen der Journalist Richard Gutjahr und
Marco Maas vom Unternehmen OpenDataCity die Crowdsourcing-Plattform LobbyPlag
[Lob13c]. Crowdsourcing hat sich als Begriff für das Auslagern aufwändiger Aufgaben
an ehrenamtlich tätige Internetnutzer eingebürgert. Vorbild waren ähnliche Websites,
auf denen die Dissertationen öffentlicher Personen auf mögliche Plagiate untersucht
wurden. LobbyPlag möchte herausfinden, inwieweit das neue Datenschutzgesetz nicht aus
der Feder von Parlamentariern stammt, sondern von Organisationen und Unternehmen
mit unterstellten Eigeninteressen. Hierzu werden die Vorschläge aus Lobbypapieren
den dazugehörigen Passagen im Gesetzestext gegenübergestellt und verglichen, um
Änderungen entsprechend zu kennzeichnen.
Im Unterschied zu den von LobbyPlag nachgewiesenen Kopien ganzer Textpassagen
[Lob13a] konnte bei den Stellungnahmen an die EU-Kommission, die Gegenstand dieser
Arbeit waren, jedoch nicht davon ausgegangen werden, Übereinstimmungen in diesem
Ausmaß zu finden. Der Öffentlichkeit lag vor 2012 kein entsprechender Entwurf vor, auf
den sich Einsendungen hätten stützen können. Ebensowenig waren die Kommentare
im Rahmen der Konsultationen als konkrete Gesetzestexte formuliert, die einfach hät-
ten übernommen werden können. Vielmehr war zu erwarten, dass es beim Versuch der
Beantwortung der Frage, welche Dokumente prägend für die Entstehung des Kommissi-
onsentwurfs waren, auf einzelne Formulierungen oder Begriffe ankommen wird, die nur in
bestimmten Dokumenten auftauchen. Ähnlichkeiten in der Wortwahl könnten dann als
Hinweis darauf interpretiert werden, dass die inhaltlichen Forderungen dieser Dokumente
ihren Weg in die EU-Verordnung gefunden haben.
2.2. Plagiaterkennung
Aus rein technischer Sicht kann die Suche nach inhaltlichen Übernahmen als ein Plagiat-
erkennungsproblem angesehen werden, bei dem von außen an den Gesetzgeber herange-
6
tragene Stellungnahmen und Empfehlungen als potentielle Quellen aufgefasst werden,
während Gesetzentwurf, eingebrachte Änderungen, oder das fertige Gesetz das Zieldo-
kument bilden. Der Begriff des Plagiats ist dabei insofern schwierig, eine juristische
Bewertung außen vor gelassen, als dass eine Übernahme von Texten von Seiten der
Interessenvertreter natürlich gewollt war und nicht zwingend negativ zu bewerten ist.
Bei dem vorliegenden Text kann daher nicht von einem möglichen Plagiat gesprochen
werden. Dennoch können Methoden aus der Plagiatsuche eine Grundlage bilden.
2.2.1. Klassifikation
Aufgaben der Plagiaterkennung lassen sich in zwei Kategorien aufteilen [Pot+10]:
• Beim intrinsischen Erkennen von Plagiaten liegt lediglich ein verdächtiges Dokument
vor, anhand dessen Charakteristika bestimmt werden soll, ob es von mehr als
einem Autor verfasst wurde. Hierzu kann der Text in Abschnitte unterteilt und
diese einer vergleichenden Analyse des Schreibstils unterzogen werden [ZES06].
Alternativ lässt sich intrinsische Plagiaterkennung als binäres Klassifikationsproblem
auffassen, das Dokumente in Plagiate und Nichtplagiate zu unterteilen versucht.
Dies kann beispielsweise mit Hilfe von Support Vector Machines und geeigneter
Kernel geschehen [Bao+04].
• Extrinsische Plagiatsuche dagegen beschäftigt sich mit der Identifizierung plagiierter
Textstellen in einem Dokument anhand einer Sammlung von Quellen, wie es in
dieser Arbeit der Fall war.
Alternativ zur inhaltsbasierten Auswertung können Plagiate, speziell im Bereich akade-
mischer Arbeiten, anhand einer Zitationsanalyse erkannt werden, die Dokumente auf
Vorkommen und Reihenfolge referenzierter Werke hin untersucht [GB10]. Während das
hier betrachtete Textmaterial nicht der strengen Struktur solcher Arbeiten mit entspre-
chenden Bibliographien folgt, wäre es vorstellbar, referenzierte Gesetze (z.B. „95/46/EG“)
durch Part-of-speech Tagging zu identifizieren und nach übereinstimmenden Sequenzen
zu suchen. Dies war jedoch nicht Gegenstand dieser Arbeit.
2.2.2. N-Gramme
Für die extrinsische Plagiaterkennung beschreiben Potthast et al. [Pot+10] die im
Rahmen eines Wettbewerbs häufig eingesetzte Vorgehensweise, für die zu vergleichenden
Dokumente Mengen von N-Grammen zu ermitteln und auf diesen Fingerabdrücken eine
Ähnlichkeitsfunktion anzuwenden, um Kandidaten für eine nähere Untersuchung zu
7
rapid technological developments have brought new
rapid technological developments
technological developments have
developments have brought
have brought new
Tabelle 2.1.: N-Gramme (Beispiel)
bestimmen. N-Gramme entstehen durch überlappendes Zusammenfassen von jeweils N
konsekutiven Buchstaben oder Wörtern. Tabelle 2.1 zeigt dies an einem Beispiel für N = 3
Wörter. Dieser Ansatz ist erfolgversprechend, da unabhängige Dokumente eine geringe
Menge an gemeinsamen N-Grammen besitzen, während bei Plagiaten davon ausgegangen
werden kann, dass bestimmte Formulierungen oder sogar ganze Sätze direkt aus der Quelle
übernommen worden sind [BCR09]. Aus den in Frage kommenden Quellen werden anhand
der N-Gramme konkrete Fundstellen ausfindig gemacht, wobei aus Effizienzgründen häufig
ein invertierter Index zum Einsatz kommt, wie es auch in dieser Arbeit der Fall war.
Hilfreiche Techniken sind das Sortieren der Wörter, um N-Gramme abzugleichen, die
sich lediglich in der Reihenfolge unterscheiden, das Entfernen von inhaltlich irrelevanten
Stoppwörtern sowie Stemming zur Reduzierung des Vokabulars.
Bei der Plagiatkerkennung werden diese Fundstellen anschließend mit Hilfe von Heu-
ristiken zusammengefasst, um komplette Abschnitte identifizieren zu können. Dieser
Aspekt trat im Rahmen dieser Arbeit in den Hintergrund, da es, wie in Abschnitt 2.1
erläutert, erwartungsgemäß mehr auf einzelne Begriffe und Formulierungen ankam, die
aus unterschiedlichen Quellen in den Gesetzestext geflossen sein könnten. Existierende
Plagiaterkennungssoftware hätte die Schwelle an dieser Stelle womöglich von vornherein
zu hoch angesetzt und im schlechtesten Fall keine Ergebnisse zurückgeliefert.
Lyon et al. [LMD01] erläutern Grundlagen zu N-Grammen, führen Containment und
Resemblance als Maße für die Übereinstimmung ein und diskutieren ihre Ergebnisse auf
Basis von Trigrammen anhand mehrerer Korpora. Anstelle dieser Maße kam in dieser
Arbeit TF-IDF zum Einsatz, um Fundstellen in ihrer Relevanz bewerten zu können.
Barrón-Cedeño und Rosso [BCR09] analysieren Plagiatsuche mit N-Grammen für
unterschiedliche Werte von N und kommen für ihre Testdaten zu dem Ergebnis, dass
N = {2, 3} die besten Ergebnisse liefere, wobei Bigramme den Recall und Trigramme die
Precision begünstigen. Monogramme finden einen hohen Anteil an Plagiaten, erzeugen
aber aufgrund der Tatsache, dass häufig das gesamte Vokabular eines Satzes im jeweiligen
Quelldokument vorkomme, zu viele False Positives. Für N ≥ 4 leide der Recall aufgrund
8
umgestellter oder neu hinzugefügter Wörter. Mangels Gold-Standard konnten diese
Maßzahlen für den im Rahmen dieser Arbeit betrachteten Textkorpus nicht berechnet
werden. Die entstandene Software erlaubt es, mit unterschiedlichen Werten von N zu
experimentieren.
In einem späteren Artikel stellen Barrón-Cedeño et al. [BC+10] einen ebenfalls auf
N-Grammen basierenden, aber lediglich die Länge der Wörter berücksichtigenden Ansatz
vor, der den Aufwand im Hinblick auf Zeit- und Platzkomplexität deutlich verringert.
Stamatatos [Sta11] nutzt N-Gramme von Stoppwörtern, die sich besonders zum Aufdecken
von Plagiaten eignen, bei denen die Satzstruktur übernommen, aber einzelne Wörter
durch Synonyme ersetzt wurden. Da diese Herangehensweise auf die Erkennung ganzer
Textpassagen abzielt, blieb sie im Rahmen dieser Arbeit unberücksichtigt.
9
3. Grundlagen
3.1. Invertierter Index
Im Rahmen dieser Arbeit wurde ein Zieldokument, der Gesetzentwurf der Kommission,
anhand von N-Grammen mit einer Vielzahl von potentiellen Quellen verglichen. Zu
diesem Zweck kam ein invertierter Index zum Einsatz, der ein effizientes Auffinden
einzelner Wörter, in diesem Zusammenhang auch als Terme bezeichnet, innerhalb eines
Dokumentkorpus ermöglicht. Hierzu werden die einzelnen Dokumente anhand von Wort-
grenzen in Terme zerlegt, die in den invertierten Index aufgenommen werden. Jedem
Term werden Identifikatoren für die Dokumente zugeordnet, in denen der jeweilige Term
vorkommt. Um Dokumente mit den gesuchten Termen nicht nur zu identifizieren, sondern
die konkreten Fundstellen ermitteln können, müssen während des Indexierungsprozesses
zusätzlich die genauen Positionen innerhalb der Dokumente in Form von Start- und
Endoffset erfasst werden. Dabei kann ein Term innerhalb eines Dokuments mehrfach
auftreten. Während die Indexstruktur mit den Termen zur effizienten Bestimmung des
benötigten Datenblocks im Hauptspeicher verbleiben sollte, kann für diese Zusatzdaten
kann ein Auslagern auf Sekundärspeicher erforderlich sein. Bei den im Rahmen dieser
Arbeit aufgetretenen Größenordnungen war dies jedoch nicht erforderlich.
Kandidaten für Datenstrukturen zur Erfassung von Termen sind u.a. Hashtabellen,
binäre Suchbäume, Skip Lists und Präfixbäume. Für die typischen Anwendungsgebiete
wird meist gefordert, dass ein Index eine sortierte Traversierung der aufgenommenen
Zeichenfolgen ermöglicht. Dies ist insbesondere für Bereichsanfragen oder Suchen nach
Präfixen vonnöten. Auf Hashfunktionen basierende Datenstrukturen scheiden daher trotz
ihrer positiven Laufzeiteigenschaften aus [HZW02]. Im Folgenden werden die für diese
Arbeit relevanten Datenstrukturen näher erläutert.
3.1.1. Präfixbäume
Ein Präfixbaum oder Trie ist eine Datenstruktur zum sortierten Erfassen von Zeichenket-
ten. Eine Zeichenkette oder String der Länge k ist dabei definiert als eine Aneinanderrei-
hung s = e1 . . . ek von k Elementen eines gemeinsamen Alphabets A mit ei ∈ A. Ein Präfix
10
t
te
ten
n
e
tr
tre
tree
e
e
tri
trie
e
i
try
y
r
t
Abbildung 3.1.: Trie
von s ist ein Teil dieser Zeichenkette e1 . . . ej mit j ≤ k. Knoten in einem Präfixbaum
enthalten eine Menge von Zeigern, die unterschiedliche Buchstaben repräsentieren und
auf weitere Unterknoten verweisen. Ausgehend vom Wurzelknoten, welcher der leeren
Zeichenfolge entspricht, repräsentiert jeder weitere Knoten ein längeres Präfix innerhalb
einer Zeichenfolge. Ein Pfad von h Kanten durch einen Präfixbaum repräsentiert daher,
wie in Abbildung 3.1 beispielhaft gezeigt, eine Zeichenkette der Länge h. Eine bestimmtes
Präfix kann gefunden werden, indem Zeichen für Zeichen den entsprechenden Kanten
gefolgt wird. Neu einzufügende Strings werden an den Knoten angehängt, der das längste
bereits vorhandene Präfix dieser Zeichenkette repräsentiert. Die Zeitkomplexität dieser
Operationen hängt daher von der Länge der gesuchten Zeichenkette ab.
Die Knoten eines Präfixbaums können zusätzliche Metadaten aufnehmen, die jedem
mit dem Knoten abschließendem String zugeordnet werden. Für einen invertierten Index
handelt es sich dabei um Verweise auf die Postings, sprich die zugeordneten Dokumente.
Dies gilt nicht ausschließlich für Blätter, sondern für alle Knoten, da Wörter Präfixe
anderer Wörter sein können.
Für die Implementierung eines Knotens existieren mehrere Varianten. So können die
Zeiger etwa durch ein Array der Länge des zugrunde liegenden Alphabets erfasst werden,
also beispielsweise 26 Einträgen für die Buchstaben a bis z, wobei unterschiedliche Groß-
und Kleinschreibung unberücksichtigt bleibt. Dies erlaubt es, den nächsten Knoten in
O (1) zu bestimmen, ist jedoch mit einem entsprechenden Platzverbrauch verbunden.
11
t
ten
en
tr
tree
ee
trie
ie
try
y
r
t
Abbildung 3.2.: Compact Trie
3.1.2. Compact Tries
Compact Tries verringern den Speicherbedarf, indem sie, wie in Abbildung 3.2 zu sehen,
Knoten eliminieren, die lediglich eine ausgehende Kante beinhalten, und stattdessen der
Kante des Elternknoten mehrere aufeinander folgende Zeichen zuweisen.
3.1.3. Burst Tries
Der in der Implementierung genutzte invertierte Index wird von der Java-Library Lu-
cene bereitgestellt [Luc13a] und basiert auf Burst Tries [HZW02]. Diese Datenstruktur
erfasst zu einem aufzunehmenden Wort lediglich einen Präfix bis zu einer bestimm-
ten Länge k in einem Access Trie genannten Präfixbaum mit Array-basierten Knoten.
Der Rest der Zeichenfolge wird schließlich ohne sie weiter zu zerlegen in einer ande-
ren, Container genannten sortierten Datenstruktur gespeichert. Namensgebend ist der
Bursting-Algorithmus, dessen Einsatz beim Einfügen neuer Zeichenketten notwendig
werden kann. Wird ein Container als zu ineffizient eingestuft, dann wird aus den ersten
Zeichen aller enthaltenen Elemente ein neuer Knoten im Access Trie gebildet. Dieser
verweist auf neu zu erstellende Container, auf welche die Restzeichenfolgen anhand
des ersten Zeichens aufgeteilt werden, während der vorherige Container entfernt wird.
Die vom Access Trie aufgenommene Präfixlänge erhöht sich damit auf k + 1. Für eine
Diskussion der möglichen Datenstrukturen für Container, darunter verkettete Listen,
binäre Suchbäume und Splay Trees, sowie mögliche Heuristiken, die zur Einstufung ihrer
Effizienz zum Einsatz kommen können, sei auf den Originalartikel [HZW02] verwiesen.
12
3.2. Bewertungsmetriken
Wichtiger Bestandteil der entwickelten Anwendung ist eine Bewertung von Fundstellen.
So erfahren Wörter eine stärkere Gewichtung, wenn sie ausschließlich in einer geringen
Anzahl von Quelldokumenten vorkommen. Derartige Fundstellen sind entscheidend für
die Zielstellung dieser Arbeit, da sie sich als Hinweis darauf interpretieren lassen, welche
Dokumente stärkeren inhaltlichen Einfluss auf die Gesetzgebung gehabt haben könnten.
Analog dazu sollen Formulierungen schwächer gewichtet werden, die in einem großen Pro-
zentsatz von Dokumenten des Gesamtkorpus auftreten und daher aus beliebigen Quellen
stammen können. Im hier verwendeten Material wären dies beispielsweise „processing of
personal data“ oder „European Data Protection Board“. Gleiches gilt für gängige Idiome
wie „in case of“ oder „in so far as“, wobei die genannten Beispiele durch Herausfiltern
von Stoppwörtern von vornherein ausgeschlossen werden können.
3.2.1. TF-IDF-Maß
Die Bewertungen basieren auf der im Information Retrieval verwendeten TF-IDF-Metrik,
die sich aus den Kriterien Termfrequenz und inverser Dokumentfrequenz zusammensetzt
[MRS08] [Luc13b]. Die Termfrequenz TF (t, d) steht für die Vorkommenshäufigkeit eines
Suchbegriffs t innerhalb eines betrachteten Dokuments d. Je höher dieser Wert, desto
relevanter ist ein Begriff für das jeweilige Dokument. Die inverse Dokumentfrequenz
IDF (t) eines Terms berechnet sich aus der Gesamtzahl der durchsuchten Dokumente
geteilt durch die Anzahl an Dokumenten, in der ein gesuchter Begriff auftaucht. Sie
ist damit ein Maß für die Seltenheit eines Terms im gesamten Dokumentkorpus D, die
ebenfalls zur Relevanz eines Suchterms beiträgt. In der Praxis wird dieser Quotient meist
wie folgt normalisiert:
IDF (t) = 1 + log
( |D|
|d ∈ D : t ∈ d|+ 1
)
(3.1)
Das TF-IDF-Maß eines Terms t in Bezug auf ein Dokument d wird aus dem Produkt
beider Kennzahlen berechnet. TF-IDF bildet somit ein Relevanzranking, wobei höhere
Werte für relevantere Fundstellen stehen.
TFIDF (t, d) = TF (t, d) · IDF (t) (3.2)
13
3.2.2. Matching von N-Grammen
Da im Rahmen dieser Arbeit nach N-Grammen gesucht wurden, die aus mehreren Termen
t1 bis tN bestehen, wurden gefundene Terme nur dann berücksichtigt, wenn sie innerhalb
eines bestimmten Abstands k ≥ N zueinander im Quelldokument auftauchen. Dabei
müssen alle Terme des gesuchten N-Gramms gefunden werden, zusätzlich kann jedoch eine
frei bestimmbare Anzahl s = k −N weiterer Wörter auftreten. Dies trägt dem Umstand
Rechnung, dass bei der Übernahme von Inhalten aus einem Dokument möglicherweise
Wörter ausgelassen wurden. Innerhalb der für den invertierten Index eingesetzten Software
Lucene, siehe Abschnitt 4.4, wird s auch als Slop bezeichnet. Ob die Reihenfolge der
einzelnen Terme dem originalen N-Gramm entsprechen muss, kann der entstandenen
Software ebenso als Parameter vorgegeben werden.
3.2.3. Gesamtscore für Fundstellen
Der Gesamtscore für ein gefundenes N-Gramm ergibt sich schließlich aus der Summe der
TF-IDF-Werte der einzelnen Suchbegriffe. Zusätzlich fließt der Abstand als Kriterium in
das Bewertungsmaß ein, wobei jede Fundstelle f ihren eigenen Wert für k hat:
Score(t1 . . . tN , f, d) = N(d)
(
1
kf + 1
)
N∑
n=1
TFIDF (tn, d) (3.3)
N(d) steht dabei für einen Normalisierungsfaktor, der bereits beim Indexieren für jedes
Dokument auf Basis der Anzahl der unterschiedlichen enthaltenen Terme berechnet wird,
um Dokumente mit vielen Wiederholungen nicht unnötig hoch zu bewerten:
N(d) = 1√
|t ∈ d|
(3.4)
3.2.4. Ranking von Dokumenten
Der Gesamtscore eines Dokuments misst die Ähnlichkeit zum Zieldokument und berechnet
sich aus der Summe der Scores über sämtliche Fundstellen aller gesuchten N-Gramme:
Score(d) =
∑
t1...tN
∑
f∈d
Score(t1 . . . tN , f, d) (3.5)
Durch Sortieren der Dokumente nach diesen Werten ergibt sich ein Ranking. Dabei
erhalten die Dokumente mit den nach obigem Modell relevantesten Fundstellen die höchs-
ten Scores. Dokumente mit einem Score von Null verfügen über keine Übereinstimmungen
mit dem Zieldokument.
14
3.3. Intervallbäume
Da die Dokumente für diese Arbeit in ein einfaches Textformat umgewandelt wurden,
lassen sich Fundstellen als Intervalle zwischen dem ersten und letzten Zeichen erfassen,
deren Positionen als Offset, d.h. der Anzahl von Zeichen zum Textanfang eindeutig defi-
niert sind. Für die entstandene Benutzeroberfläche ergab sich zum einen die Anforderung,
siehe Abschnitt 4.5.1, die für den Anwender sichtbaren Fundstellen identifizieren zu
können, wobei dieser sichtbare Bereich ebenfalls durch ein Intervall repräsentiert wird.
Eine Fundstelle [a, b] gehört genau dann zum angezeigten Bereich [x, y], wenn sich die
dazugehörigen Intervalle überschneiden:
[a, b] ∩ [x, y]⇔ (a ≤ y) ∧ (b ≥ x) (3.6)
Zum zweiten sollten Benutzerinteraktionen mit dem Text einer konkreten Fundstelle
zugeordnet werden können, etwa durch Mausklick auf ein bestimmtes Zeichen an Position
x innerhalb des Textes. Dies lässt sich als Anfrage nach allen Fundstellen behandeln,
die sich mit dem Intervall [x, x] überschneiden. Da sich mehrere Fundstellen überlappen
können, wird jeweils die Fundstelle mit dem höchsten Score ausgewählt.
Um die zu einem Dokument ermittelten n Fundstellen nicht für jede derartige Anfrage
mit linearer Zeitkomplexität O (n) durchsuchen zu müssen, werden sie in einem Inter-
vallbaum [Lei+01] erfasst. Bei dieser Datenstruktur handelt es sich um einen binären
Suchbaum, bei dem die Anfangsposition a eines Intervalls [a, b] als Vergleichskriterium
verwendet wird. Zusätzlich wird zu jedem Element die größte Endposition bmax aller Un-
terknoten erfasst. Anfragen nach allen mit einem gegebenen Intervall [x, y] überlappenden
Elementen beginnen beim Wurzelknoten und durchsuchen den jeweils linken und rechten
Teilbaum. Dabei werden diejenigen linken Teilbäume verworfen, die sich aufgrund von
a + bmax < x links vom gesuchten Intervall befinden. Analog werden diejenigen rechten
Teilbäume ausgespart, die rechts außerhalb der Suchanfrage liegen.
Die Höhe eines solchen binären Baums und damit die Zeitkomplexität einer Suche
nach dem Knoten, der alle eine Suchanfrage überschneidenden Intervalle enthält, lässt
sich durch geeignete Annotationen der Knoten und darauf basierende Rotationsregeln
beim Einfügen und Entfernen von Elementen auf O (log (n)) beschränken. Für in der
Praxis übliche Umsetzungen von binären Bäumen sei auf AVL- und Rot-Schwarz-Bäume
verwiesen. Im Rahmen dieser Arbeit wurde auf eine Implementierung aus dem CoreNLP-
Projekt der Stanford University1 zurückgegriffen.
1http://nlp.stanford.edu/software/corenlp.shtml
15
3.4. Clustering
Neben den Übereinstimmungen einzelner Quellen mit dem Zieldokument ist von Interesse,
welche Lobbypapiere untereinander Gemeinsamkeiten aufweisen. Aus diesen ließen sich
Vermutungen darüber ableiten, welche Interessenvertreter ähnliche Forderungen vertreten
oder sich womöglich sogar inhaltlich abgestimmt haben. Um dies zu visualisieren, bieten
sich hierarchische Clusteringverfahren an, die Objekte basierend auf einem Ähnlich-
keitskriterium in eine Baumstruktur einordnen. Die Distanz zwischen zwei Baumknoten
spiegelt dabei den Abstand zwischen zwei Objekten wider. Objekte entsprechen hier den
zu clusternden Dokumenten.
3.4.1. UPGMA-Algorithmus
Aufgrund der einfachen Implementierbarkeit fiel die Wahl auf das UPGMA-Verfahren
(Unweighted Pair Group Method with Arithmetic Mean) [SM58]. Für N Objekte wird
hierzu eine Ähnlichkeitsmatrix M mit N × N Elementen aufgebaut. Ähnlichkeit ist
symmetrisch definiert, so dass für ein Paar von Objekten a 6= b die Einträge Ma,b
und Mb,a identisch sind. Einträge für a = b entlang der Hauptdiagonalen werden nicht
berücksichtigt. Für die Berechnung der Ähnlichkeitswerte sei auf Abschnitt 3.4.2 verwiesen.
Tabelle 3.1 dient als Ausgangspunkt für die folgende Erläuterung des Algorithmus und
enthält Werte 0 ≤Ma,b ≤ 1 für fünf Objekte. Die Skalierung hat dabei keine Auswirkung
auf die Funktionsweise. Entscheidend ist lediglich, dass höhere Werte für ähnlichere Paare
stehen.
b
a 1 2 3 4 5
1 0.61 0.79 0.27 0.06
2 0.61 0.08 0.78 0.27
3 0.79 0.08 0.91 0.84
4 0.27 0.78 0.91 0.20
5 0.06 0.27 0.84 0.20
Tabelle 3.1.: Ähnlichkeitsmatrix (Beispiel)
Der UPGMA-Algorithmus arbeitet agglomerativ, beginnt also damit, jedem Objekt
einen eigenen Knoten und damit Cluster zuzuweisen. Dem Beispiel von fünf Dokumenten
folgend illustriert dies Abbildung 3.3.
16
1 2 3 4 5
Abbildung 3.3.: Clustering, Ausgangssituation
In der Ähnlichkeitsmatrix wird nun der Eintrag Ma,b mit dem maximalen Ähnlichkeits-
wert gesucht. Aufgrund der Symmetrie müssen hierzu nur Einträge a < b berücksichtigt
werden. Im Beispiel handelt es sich dabei um M3,4. In der Clustering-Hierarchie wird
daraufhin, wie in Abbildung 3.4 zu sehen, für die Knoten a und b ein neuer Elternknoten
c hinzugefügt, der einen aus beiden Teilclustern gebildeten Cluster repräsentiert. Da
die Ähnlichkeit invers proportional zum Abstand ist, kann sie als Kantenlänge erfasst
werden, je nach gewünschter Skalierung etwa als 1−Ma,b oder 1Ma,b .
1 2 3 4 5
c
Abbildung 3.4.: Clustering nach Zusammenführen der Knoten 3 und 4
Aus der Ähnlichkeitsmatrix werden anschließend beide Knoten entfernt und durch
einen neues Objekt für den Knoten c ersetzt. Dessen Ähnlichkeitswerte zu jedem in der
neuen Matrix M ′ verbleibenden Objekt d 6= c berechnen sich aus dem arithmetischen
Mittelwert der ursprünglichen Einträge Md,a und Md,b:
M ′c,d = M ′d,c =
Md,a + Md,b
2 (3.7)
Die Beispielmatrix ändert sich dadurch wie folgt:
b
a 1 2 c 5
1 0.61 0.53 0.06
2 0.61 0.43 0.27
c 0.53 0.43 0.52
5 0.06 0.27 0.52
Tabelle 3.2.: Ähnlichkeitsmatrix nach Zusammenführen von 3 und 4
Die Suche nach dem höchsten Ähnlichkeitswert, gefolgt von den beschriebenen Ope-
rationen, wird nun so lange wiederholt, bis die Matrix eine Größe von 1 × 1 erreicht
17
b
a d c 5
d 0.48 0.17
c 0.48 0.52
5 0.17 0.52
(a) d = 1 ∪ 2
→
b
a d e
d 0.32
e 0.32
(b) e = c ∪ 5
→
b
a f
f
(c) f = d ∪ e
Tabelle 3.3.: Ähnlichkeitsmatrix, Fortsetzung
hat, d.h. nur noch ein Objekt enthält. Im Beispiel sind 1 und 2 die nächsten zusam-
menzuführenden Knoten. Die nachfolgenden Belegungen der Ähnlichkeitsmatrix können
Tabelle 3.3 entnommen werden. Die abschließende Clustering-Hierarchie für das Beispiel
ist in Abbildung 3.5 dargestellt.
1 2 3 4 5
cd
e
f
Abbildung 3.5.: Ergebnis des Clustering-Algorithmus
3.4.2. Ähnlichkeitsmaß
Zur Bestimmung der Ähnlichkeit zweier Dokumente findet im Information Retrieval das
Vektorraum-Modell Anwendung, das Dokumente als Vektoren repräsentiert, in denen
jedes Element wt,d für das Auftreten eines von n Termen im jeweiligen Dokument d steht:
vd = (w1,d, . . . , wn,d) (3.8)
Die einzelnen Komponenten werden auch als Termgewichte bezeichnet, die aus dem TF-
IDF-Maß, d.h. dem Produkt aus Termfrequenz und inverser Dokumentfrequenz berechnet
werden:
wt,d = TF (t, d) · IDF (t) (3.9)
Die Ähnlichkeit zwischen zwei Dokumenten d1 und d2 ergibt sich aus dem Cosinus des
Winkels ihrer Vektoren, auch Cosine Similarity genannt [Hua08]:
18
sim(d1, d2) = cos(vd1 , vd2) =
vd1 · vd2
|vd1 ||vd2 |
(3.10)
Dabei repräsentiert vd1 ·vd2 das Skalarprodukt der beiden Vektoren und |vd| =
√∑
w2t,d
das euklidische Längenmaß. In der Praxis wird die Größe der Vektoren und damit die
Kosten für die Berechnung zumeist durch eine Vorauswahl der für den Dokumentkorpus
relevantesten Terme begrenzt, wofür die Dokumentfrequenz als Kriterium naheliegt.
Da für diese Arbeit der Vergleich von Quelldokumenten mit einem Zieldokument im
Vordergrund stand, hat es sich alternativ angeboten, zur Bestimmung der Ähnlichkeit
zweier Dokumente nur Fundstellen zu berücksichtigen, die beide mit dem Zieldokument
gemeinsam haben. In der entstandenen Software lässt sich zwischen beiden Varianten
umschalten. Die zugrunde liegende Ähnlichkeitsmatrix beginnt hierzu mit Nullwerten.
Während der Suche nach N-Grammen (siehe Abschnitt 4.4) werden die berechneten
Bewertungen für Fundstellen, die in mehreren Quelldokumenten auftauchen, jeweils
paarweise in der Matrix hinzuaddiert. Ihr Wertebereich ist somit im Unterschied zum
Vektorraum-Modell nach oben offen.
19
4. Implementierung
Die Umsetzung erfolgte in Form einer Java-Anwendung namens LawPlag.
4.1. Konvertieren von PDF-Dokumenten
Die zu vergleichenden Dokumente lagen im Portable Document Format vor. PDF wird
durch ISO/IEC 32000-1:2008 spezifiziert und für Publikationen auf EU-Plattformen in
Version 1.5 verwendet [EC13]. Unter Verwendung der Java-Library Apache PDFBox 1
wurden die Dokumente zunächst in ein einfaches UTF-16-Textformat konvertiert. Für
ein schnelleres Einlesen bei der nächsten Verwendung der Anwendung wurden diese
Textdaten zusätzlich zu den PDF-Dateien im Dateisystem abgespeichert.
4.2. Zerlegung in Wörter
Im Folgenden wird skizziert, wie aus Dokumenten Wörter und schließlich N-Gramme
erzeugt wurden. Dieser Teil der Software basiert auf Apache Lucene 2, einer OpenSource-
Library für die Volltextsuche in Dokumenten. Genutzt wurden enthaltene Komponenten
für das Zerlegen von Dokumenten in Wörter sowie deren Erfassung und spätere Suche in
einem Burst-Trie-basierten invertierten Index.
Lucene liest Textdaten als einen Datenstrom von sogenannten Token ein, die zu Beginn
aus einzelnen Zeichen bestehen. Auf diesen Datenstrom können hintereinander geschaltet
mehrere Filter angewandt werden. Diese können als Funktionen verstanden werden, die
einen eingehenden Datenstrom modifizieren und an den nächsten Filter weitergeben. In
einem ersten Schritt werden Zeichen basierend auf einem im Unicode-Standard veran-
kerten Regelwerk[Dav12] zu Wörtern zusammengefasst und Leerzeichen sowie sonstige
Satzzeichen verworfen. Da die erste Komponente, Analyzer genannt, zunächst nur ein-
zelne Zeichen als Eingabe erhält, muss sie die gesehenen Zeichen vermerken, um bei
Auftauchen eines Trennzeichens das entsprechende Wort als Ausgabe erzeugen zu können.
1http://pdfbox.apache.org/
2http://lucene.apache.org/
20
Entscheidend ist an dieser Stelle, dass dem Datenstrom zu jedem Wort die ursprüngliche
Position im Originaldokument als Metadatum hinzugefügt wird. Wortanfang und -ende
identifizieren später die Fundstellen innerhalb eines Dokuments.
Die so erzeugten Wörter durchliefen nun einige weitere Filter. Zunächst wurden durch
einen LowerCaseFilter die Zeichen sämtlicher Wörter in Kleinbuchstaben umgesetzt.
In einem zweiten Schritt werden Stoppwörter anhand einer für die englische Sprache
vorgegebenen Menge erkannt und in der Form verworfen, dass sie nicht an den nächsten
Filter weitergegeben werden. Konkret handelte es sich dabei um:
a, an, and, are, as, at, be, but, by, for, if, in, into, is, it, no, not, of, on, or,
such, that, the, their, then, there, these, they, this, to, was, will und with.
Anschließend wurde der ebenfalls als Teil von Lucene implementierte Porter-Stemmer-
Algorithmus auf die erzeugten Wörter angewandt.
4.3. Erzeugen von N-Grammen
Anhand der so ermittelten Wörter können nun optional in einem letzten Schritt N-Gramme
erzeugt werden. Dies geschah, wie im folgenden Abschnitt begründet wird, lediglich für das
Zieldokument, jedoch nicht für die Quelldokumente. Zum Einsatz kam dabei ein weiterer
Token-Filter, der die letzten N − 1 gesehenen Wörter zwischenspeichert und sobald die
ersten N − 1 Wörter bekannt sind damit beginnt, jedes eingehende Wort zusammen mit
seinen Vorgängern zu einem N-Gramm zusammenzufassen und auszugeben. Hierzu werden
sie getrennt durch Leerzeichen zu einer gemeinsamen Zeichenfolge zusammengefasst.
Die Position dieses N-Gramms im Originaltext ergibt sich schließlich aus der zuvor in
Metadaten erfassten Anfangsposition des ersten Wortes und dem Ende des letzten Wortes
und wird zusammen mit einer ID des jeweiligen Dokuments im invertierten Index erfasst.
Der Wert von N kann innerhalb des Programms über einen Einstellungsdialog angepasst
werden.
4.4. Indexierung und Vergleich
Kernstück der Software ist der Algorithmus zum Auffinden der Übereinstimmungen
zwischen den einzelnen Quellen und dem Zieldokument. Entgegen der ursprünglich
geplanten Vorgehensweise, die Quellen in N-Gramme zu unterteilen und als Anfragen an
das Zieldokument zu stellen, hat sich die umgekehrte Richtung als zielführender erwiesen.
Sie folgt dem bei Lucene gängigen Muster, eine Vielzahl von Dokumenten in einen
21
gemeinsamen Index einzulesen und Anfragen an diesen zu stellen. Die N-Gramme des
Zieldokuments in den Quellen zu suchen ermöglicht zudem eine direkte Vergleichbarkeit
der für die Quelldokumente ermittelten Scores auf Basis des in Abschnitt 3.2.1 definierten
TF-IDF-Maßes. Darüber hinaus konnte die Möglichkeit geschaffen werden, Fundstellen
ausgehend vom Zieldokument in mehrere Quelldokumente zurückzuverfolgen. Hierzu
wurden für das Zieldokument nach dem oben beschriebenen Verfahren alle N-Gramme
ermittelt und mit einer Identifikationsnummer versehen.
Quelldokumente wurden in Wörter unterteilt und in einem gemeinsamen invertierten
Index erfasst, wobei die Positionsangaben mitgespeichert wurden. Der Such-Algorithmus
läuft in einer äußeren Schleife über sämtliche N-Gramme des Zieldokuments, sucht im
Index der Quelldokumente nach den einzelnen Wörtern und ermittelt anhand deren
Positionen, ob sie entsprechend der vorgenommenen Einstellungen zu einer Fundstelle
zusammengefasst werden können. Ein Parameter ist dabei die Anzahl eingefügter, nicht
zum N-Gramm gehörenden Wörter, in Abschnitt 3.2.1 als k bezeichnet. Darüber hinaus
kann festgelegt werden, ob die Reihenfolge des N-Gramms eingehalten werden muss, oder
ob die einzelnen Wörter in beliebiger Reihenfolger auftauchen dürfen. Zur Identifizierung
von Fundstellen kam eine eigene Erweiterung der im Paket org.apache.lucene.search.spans
enthaltenen Klassen zum Einsatz, die neben der Position des Wortes im Dokument auch
die genauen Positionen von erstem und letztem Zeichen einer Fundstelle zurückliefern.
Für das jeweils gefundene Dokument wurde daraufhin der Score um den TF-IDF-Wert
der Fundstelle erhöht.
4.5. Benutzeroberfläche
Die Benutzeroberfläche basiert auf der Swing-API. Sie listet sämtliche eingelesenen
Quelldokumente auf und stellt nach Auswahl eines Dokuments Quell- und Zieldokument
nebeneinander dar. Abbildung 4.1 zeigt, wie in beiden Dokumenten die übereinstimmen-
den Fundstellen entsprechend ihrer Gewichtung hervorgehoben werden. Rechts neben den
Dokumenten befindet sich jeweils eine Leiste, die einen Überblick über die Fundstellen
bietet. Diese dienen gleichzeitig als Sprungmarken, um per Mausklick zur jeweiligen
Position im Dokument scrollen zu können.
4.5.1. Färbung der Fundstellen
Zur Darstellung der Dokumente in einem einfachen Textformat wurde die Swing-Kompo-
nente JTextArea [Ora11b] genutzt, die sich von der abstrakten Basisklasse JTextCompo-
nent ableitet. Anhand des Laufzeitverhaltens stellte sich heraus, dass deren Highlighter
22
Abbildung 4.1.: Gegenüberstellung von Dokumenten in LawPlag
zum Einfärben von Text nicht auf Hervorhebungen in den aufgetretenen Größenordnun-
gen im drei- bis vierstelligen Bereich vorbereitet ist. Eine Überprüfung der OpenJDK-
Implementierung der verantwortlichen Methode paintLayeredHighlights innerhalb der
Klasse DefaultHighlighter bestätigte die Vermutung, dass für den zu zeichnenden Text
sämtliche Intervalle auf Schnittmengen überprüft werden. Dieser Umstand fiel insbeson-
dere beim zeilenweisen Scrollen durch einen langsamen Bildaufbau auf. Daher wurde der
Standard-Highlighter durch eine eigene Implementierung ersetzt, welche die einzufärben-
den Abschnitte für den zeichnenden Bereich direkt bei der Ausgabe von Text ermittelt.
Dies geschieht anhand der vom Datenmodell aufgebauten Interval Trees.
Für die Wahl der Hintergrundfarbe wird anhand der Dokumentfrequenz des jeweiligen
N-Gramms ein Score 0 < s ≤ 1 berechnet. Die Wahl des natürlichen Logarithmus war
dabei eher willkürlich, erzeugte aber optisch gute Ergebnisse.
s(N −Gramm) = 1
ln (DF (N −Gramm) + e− 1) (4.1)
Um die Farbintensität anhand des Scores zu bestimmen, muss ein Farbwert zwischen
der gewünschten Hintergrundfarbe für Fundstellen mit dem höchsten Score s = 1 und
der Hintergrundfarbe der Textkomponente bestimmt werden. Die von Swing verwendeten
Farben basieren auf dem additiven sRGB-Farbraum und lassen sich daher in Komponenten
für Rot, Grün und Blau, sowie einem optionalen Alpha-Kanal aufteilen. Jede Komponente
kann dabei entweder als Gleitkommazahl zwischen 0 und 1 oder als 8-Bit-Integer im
Bereich 0 bis 255 angesehen werden [Ora11a].
C = (R, G, B, A) (4.2)
23
Abbildung 4.2.: Auflistung der Dokumente in LawPlag
Der Alpha-Kanal wird in LawPlag immer auf den höchsten Wert gesetzt, um deckend
zu zeichnen, da sich überlappende Fundstellen sonst in ihrer Farbintensität verstärken
würden. Um jede Textstelle mit der jeweils höchsten Bewertung anzuzeigen, werden die
ermittelten Fundstellen aufsteigend nach ihrem Score sortiert und in dieser Reihenfolge
deckend übereinander gezeichnet.
Um zwei RGB-Farbwerte mit unterschiedlichen Anteilen miteinander zu vermischen,
werden die gewichteten Mittelwerte der einzelnen Komponenten gebildet. Der Parameter
s entspricht in diesem Fall dem für die Fundstelle berechneten Score.
CM [R, G, B] = s · C1[R, G, B] + (1− s) · C2[R, G, B]
CM [A] = 255
(4.3)
Für C1 wird die für Hervorhebungen zu verwendende Farbe eingesetzt. C2 wird mit
der Hintergrundfarbe der Textkomponente belegt.
4.5.2. Clustering
Der in Abschnitt 3.4.1 erläuterte Clustering-Algorithmus baut anhand des Vokabulars oder
gemeinsamer Fundstellen einen binären Baum auf den Quelldokumenten auf. Um diesen
ohne überschneidende Kanten darzustellen, wird eine Inorder-Traversierung durchgeführt
und Dokumente in den Blattknoten fortlaufend nummeriert. Daraus ergibt sich eine
Sortierreihenfolge, in welche die Auflistung der Dokumente zur Anzeige des Clusterings
durch einen Mausklick auf den dazugehörigen Spaltenkopf gebracht werden kann. Der
Screenshot in Abbildung 4.2 zeigt dies auszugsweise.
24
5. Auswertung
5.1. Textmaterial
Im Rahmen dieser Arbeit beschränkt sich die Auswertung auf die Kommentare, die
während der Konsultationen der EU-Kommission eingegangen sind. Diese Dokumente
können auf den Seiten der jeweiligen Konsultationen heruntergeladen werden, die in
Abschnitt 1.1 verlinkt sind. Nicht berücksichtigt wurden hingegen Lobbyanträge an
Parlamentarier, die nach Veröffentlichung des Kommissionstextes eingereicht wurden und
sich meist mit konkreten Forderungen auf diesen bezogen. Derartige Abschnitte durch die
Software unterscheiden zu lassen war demzufolge nicht erforderlich. Für eine inhaltliche
Auseinandersetzung mit diesen Dokumenten sei auf die in Abschnitt 2.1 vorgestellte
Plattform LobbyPlag verwiesen.
Zieldokument bildete der 119 Seiten starke abschließende Gesetzesvorschlag der EU-
Kommission [EC12]. Obwohl dieser in allen 23 gegenwärtig innerhalb der EU anerkannten
Amts- und Arbeitssprachen vorlag, stand hier nur die englischsprachige Fassung im
Fokus. Mit 410 von 532 Dokumenten war ein Großteil der Stellungnahmen ebenfalls
auf Englisch eingereicht worden, erkennbar an Dateinamen in der Form ∗_en.pdf. Für
die verbleibenden Texte wäre denkbar gewesen, sie mit der Fassung in ihrer Sprache zu
vergleichen oder sie automatisch übersetzen zu lassen.
17 PDF-Dokumente fielen beim Einlesen als unbrauchbar auf, da die einzelnen Seiten in
Form von Rastergrafiken gespeichert waren. Dies hätte eine Texterkennung nötig gemacht,
worauf an dieser Stelle verzichtet wurde. Für die Auswertung wurden demzufolge 393
Dokumente berücksichtigt.
5.2. Fundstellen
Ergebnisse für unterschiedlich lange N-Gramme können Tabelle 5.1 entnommen werden.
Die Parameter wurden dabei streng gewählt; eingefügte Wörter ebenso wie Vertau-
schungen nicht berücksichtigt. Die erste Spalte gibt die Gesamtzahl der N-Gramme im
Zieldokument an. Für N = 1 entspricht diese der Anzahl unterschiedlicher Wörter nach
25
N-Gramme Fundstellen Dokumente
N gesamt gefunden gesamt einmalig gesamt einmalig
1 2 156 1 895 592 129 65 393 53
2 15 540 7 817 133 541 2 052 391 304
3 22 542 3 405 33 415 1 336 374 266
4 25 855 1 607 10 016 739 343 191
5 27 498 869 4 559 451 322 115
6 28 429 551 2 768 305 288 65
7 28 976 394 1 809 229 275 49
8 29 314 295 1 125 174 218 34
9 29 564 231 706 141 102 28
10 29 768 181 523 111 65 23
11 29 938 143 422 86 56 15
12 30 081 116 342 71 46 7
13 30 201 99 282 64 32 5
14 30 307 88 240 59 27 4
15 30 392 79 206 55 26 3
16 30 455 71 173 52 24 3
17 30 502 64 142 49 22 3
18 30 541 58 113 46 22 3
19 30 571 52 84 43 15 3
20 30 597 47 63 40 5 3
21 30 619 42 54 37 5 3
22 30 637 38 47 34 5 3
23 30 652 34 40 31 5 3
24 30 666 30 33 28 4 2
25 30 680 28 29 27 3 2
26 30 693 26 26 26 2 2
27 30 705 24 24 24 1 1
28 30 716 23 23 23 1 1
...
...
...
...
...
...
...
50 30 829 1 1 1 1 1
51 30 832 0 0 0 0 0
Tabelle 5.1.: Gefundene N-Gramme und Dokumente
26
50 100 150 200 250 300 350 4000
100
200
300
400
500
600
700
800
900
Dokumente
Fu
nd
st
el
le
n
N = 3
N = 4
N = 5
Abbildung 5.1.: Fundstellen nach Dokumenten
Fundstellen
Dokument Score gesamt einmalig
dpoq 10,804 151 48
nbc universal 8,653 112 18
art29 wp and wppj 7,353 351 138
task force copyright 6,676 99 38
gonzalez fuster gloria 6,478 105 36
ebu 5,528 61 20
european privacy association 4,328 182 62
minjust lv 4,274 41 14
ccbe 3,572 81 32
gsma europe 3,396 95 36
Tabelle 5.2.: Dokumente mit den höchsten Scores
27
Anwendung von Stemming, welches das Vokabular von 3081 Wörtern um 30 Prozent
verringerte. Den nachfolgenden Spalten kann entnommen werden, wie viele N-Gramme
in den Quellen gefunden wurden und auf wie viele Fundstellen und Dokumente sie
sich jeweils verteilten. Abbildung 5.1 stellt dar, wie sich die Fundstellen für ausgwählte
N ∈ {3, 4, 5} auf die untersuchten Dokumente verteilen. Dabei sind die Dokumente jeweils
nach absteigender Anzahl an Fundstellen sortiert. Tabelle 5.2 listet die Dokumente mit
den zehn höchsten Scores für 4-Gramme auf.
5.2.1. Einmalige Fundstellen
Einmalige Fundstellen sind solche, die in nur einer Quelle auftraten, und können somit
bevorzugt Ausgangspunkt für die Recherche nach inhaltlich relevanten Übereinstim-
mungen sein. Dies gilt insbesondere für einzelne Wörter sowie längere N-Gramme, mit
denen sich deren Anzahl auf ein überschaubares Maß verringert. Unter den 65 einmaligen
Einzelbegriffen fanden sich 24 Zahlen- und Datumsangaben, die sich allesamt als zufäl-
lig herausstellten. Fünf weitere entstanden durch Possessivformen (z.B. „member’s“),
die durch den Lucene-Stemmer überraschenderweise nicht weiter verkürzt wurden. Die
umliegenden Textabschnitte konnten jedoch nicht in einen inhaltlichen Zusammenhang
gebracht werden. So handelte es sich bei vier weiteren Wörtern beispielsweise um Namen
aus einem Gerichtsurteil, auf das sich die Vorbemerkungen im Gesetzentwurf bezogen.
5.2.2. Textpassagen
In den einzelnen Quelldokumenten gefundene N-Gramme können sich überlappen. Wie das
Ergebnis ausfiel, wenn diese Fundstellen als zusammenhängende Textpassagen betrachtet
wurden, stellt Tabelle 5.3 dar. Für den in der ersten Spalte angegebenen Wert von N
geben die darauf folgenden Spalten an, wieviele Textpassagen mit der im Spaltenkopf
angegebenen Länge von k ≥ N Wörtern gefunden wurden. Zuvor aussortierte Stoppwörter
wurden dabei weiterhin nicht mitgezählt. Für 4-Gramme kann beispielsweise aus der
Kombination der Tabellen 5.1 und 5.3 entnommen werden, dass sich die insgesamt 10 016
Fundstellen zu 4 943 einzelnen Textpassagen verbinden ließen, wobei 3 131 Fundstellen
alleinstehend blieben. Während sich die Anzahl der längeren Textpassagen bis N = 4
mit dem jeweils nächstgrößeren N noch signifikant verringerte, bestand sie darüber
überwiegend nur noch aus den Textpassagen mit der Länge N − 1, die nicht mehr
berücksichtigt wurden.
28
Länge der Textpassage in Wörtern
N 2 3 4 5 6 7 8 9 10 ≥ 11 Summe
2 35 356 11 711 8 453 3 928 2 470 1 384 834 622 444 850 66 052
3 11 684 4 168 1 040 737 524 367 176 94 238 19 028
4 3 131 638 329 265 283 106 43 148 4 943
5 698 244 270 249 80 26 107 1 674
6 252 256 233 78 24 92 935
7 260 234 79 24 80 677
8 233 81 22 79 415
9 82 21 78 181
10 21 78 99
11 78 78
12 59 59
13 41 41
14 33 33
15 32 32
16 30 30
17 28 28
18 28 28
19 20 20
20 9 9
21 7 7
22 7 7
23 7 7
24 4 4
25 3 3
26 2 2
27 1 1
...
...
...
50 1 1
51 0 0
Tabelle 5.3.: Gefundene Textpassagen
29
Länge der Textpassage in Wörtern
N 2 3 4 5 6 7 8 9 10 ≥ 11 Summe
2 2 095 52 26 6 5 1 1 2 186
3 1 022 69 26 18 4 3 5 3 8 1 158
4 401 46 23 8 7 6 4 13 508
5 142 31 16 7 6 7 13 222
6 64 23 8 8 3 15 121
7 40 7 9 6 15 77
8 17 8 8 15 48
9 15 8 16 39
10 13 17 30
11 20 20
12 11 11
13 8 8
14 6 6
15 5 5
16 5 5
17 5 5
18 5 5
19 5 5
20 5 5
21 4 4
22 4 4
23 4 4
24 2 2
25 2 2
26 2 2
27 1 1
...
...
...
50 1 1
51 0 0
Tabelle 5.4.: Textpassagen aus einmaligen Fundstellen
30
5.2.3. Einmalige Textpassagen
Tabelle 5.4 zeigt zum Vergleich die Anzahl von Textpassagen, die sich aus einmaligen
Fundstellen zusammensetzten. Diese hatten einen durchschnittlichen Anteil von zehn
Prozent. Auffällig bei der Gegenüberstellung beider Tabellen ist der Anteil an Fundstellen,
die genau der Länge des ursprünglich gesuchten N-Gramms entsprachen und damit nicht
Teil einer längeren Textpassage waren. Dieser lag zum Beispiel für N = 3 über alle
N-Gramme bei 61 Prozent, für einmalige Fundstellen dagegen bei 88 Prozent. Durfte
ein N-Gramm in maximal drei bzw. fünf Dokumenten auftauchen, auf eine gesonderte
Ausgabe der dazugehörigen Tabellen wurde an dieser Stelle verzichtet, dann blieb der
Anteil von Textpassagen mit drei Wörtern Länge mit 85 bzw. 83 Prozent ähnlich hoch.
Bei den seltenen und damit inhaltlich interessanteren Fundstellen handelte es sich somit
eher um kürzere Textpassagen.
5.2.4. Lange Textpassagen
Um herauszufinden, welche inhaltlichen Gemeinsamkeiten hinter längeren identifizierten
Textpassagen steckten, wurde ein Vergleich mit N-Grammen der Länge 8 durchgeführt
und die Fundstellen manuell gesichtet. Dabei blieben 192 von 410 Quellen ohne Überein-
stimmungen mit dem Zieldokument und erhielten daher gemäß der in Abschnitt 3.2.4
definierten Berechnungsgrundlage einen Score von Null. Für weitere 138 Dokumente
handelte es sich bei den Fundstellen lediglich um die meist in Form von Betreffzeilen über-
nommenen Titel der Konsultation, auf die im Kommissionstext auf Seite 3 rückblickend
Bezug genommen wird. Für diese Quellen wurden aufgrund der hohen Dokumentfrequen-
zen dieser Titel durchweg die geringsten Scores berechnet. Leichte Abweichungen in den
Werten ergaben sich lediglich aus den Termfrequenzen in den jeweiligen Dokumenten.
Mindestens 61 Dokumente enthielten Bezüge auf die aktuelle Datenschutzrichtlinie
95/46/EC, die sich auch im Kommissionsentwurf wiederfanden. Besonders hervor stach
dabei das Antwortschreiben von NBC Universal auf die ersten Konsultationen [EC09a],
das für 5 ≤ N ≤ 8 mit dem höchsten Score aller Dokumente bewertet wurde. Auch
für 4-Gramme und Trigramme fand sich das NBC-Dokument mit Rang 2 bzw. 4 noch
unter den am höchsten bewerteten. Dessen maßgebliche inhaltliche Übereinstimmung mit
dem Kommissionstext stellte jedoch ein Vollzitat des 176 Wörter umfassenden Artikels
7 der Vorgängerrichtlinie dar, der mit einigen Änderungen in Artikel 6 der Neufassung
übernommen wurde. Nach testweiser Entfernung dieser Textpassage rangierte es für
4 ≤ N ≤ 8 immerhin noch auf Rang 10 bzw. 11, fiel bei Trigrammen aber bereits auf
Rang 25 ab.
31
Deutlich seltener wurde aus anderen Rechtsnormen zitiert, darunter aus der EU-Grund-
rechtecharta, der E-Commerce-Richtlinie 2000/31/EG und der Datenschutzrichtlinie für
elektronische Kommunikation 2002/58/EG. Auffällig war eine Passage aus dem Urteil des
Europäischen Gerichtshofs in der Rechtssache C-73/07 über die Auslegung des Begriffs
„Journalismus“. Zitiert in der Antwort der Europäischen Rundfunkunion (EBU) auf [EC11]
fand es sich, wohlgemerkt ohne gesonderte Kennzeichnung, in den Erwägungsgründen des
Gesetzentwurfs wieder, wobei über einen kausalen Zusammenhang, sprich eine gezielte
Übernahme aus dieser Quelle, nur spekuliert werden kann:
In order to take account of the importance of the right to freedom of
expression in every democratic society, it is necessary, first, to interpret
notions relating to that freedom, such as journalism, broadly.
Als Beispiel für eine Textstelle, bei der es sich tatsächlich um eine wortwörtliche
Übernahme aus einer Quelle handeln könnte, sei Punkt 18 der Antwort der deutschen
Bundesregierung auf [EC11] herausgegriffen:
The Federal Government is in favour of specific rules for the processing of
personal data in the employment sector. [. . .]
Im Kommissionstext fand sich diese Formulierung in Erwägungsgrund 124 wieder, der
Mitgliedsstaaten beim Arbeitnehmerdatenschutz Gesetzgebungskompetenz zugesteht:
The general principles on the protection of individuals with regard to the
processing of personal data should also be applicable to the employment
context. Therefore, in order to regulate the processing of employees’ personal
data in the employment context, Member States should be able, within the
limits of this Regulation, to adopt by law specific rules for the processing of
personal data in the employment sector.
Bei den allermeisten Übereinstimmungen längerer Textpassagen handelt es sich jedoch
um Inhalte aus gemeinsamen Quellen. Dies bestätigt den in Abschnitt 2.2.2 begründeten
Ansatz, nicht mit Übernahmen ganzer Sätze aus den Konsultationstexten zu rechnen,
sondern einzelne Formulierungen und Begriffe in den Vordergrund zu stellen.
5.2.5. Einfluss der Parameter
Über die Länge der N-Gramme hinaus unterlagen das Indexieren und der Vergleich von
Quellen und Zieldokument drei weiteren Parametern. Tabelle 5.5 zeigt, wie sich diese
32
Parameter
Dokumente Textpassagen Stemming Umordnungen Einfügungen gesamt
339 4 312
344 5 046 +17% +17%
360 9 581 +122% +122%
362 10 565 +109% +10% +145%
343 4 943 +15% +15%
346 6 007 +19% +22% +39%
362 13 452 +40% +172% +212%
364 14 512 +37% +142% +8% +237%
Tabelle 5.5.: Einfluss der Parameter auf Textpassagen
in unterschiedlichen Kombinationen auf die Fundstellen auswirkten. Die Prozentzahlen
innerhalb eines Blocks beziehen sich dabei auf die leere Zelle im jeweiligen Block darüber,
die dafür steht, dass die dazugehörige Option nicht aktiv war. Grundlage waren N-
Gramme der Länge vier. In den Quelldokumenten überlappende Fundstellen wurden zu
Textpassagen zusammengefasst und gezählt.
Die Anzahl der 4-Gramme im Zieldokument reduzierte sich durch Stemming von
26 172 auf 25 855 nur geringfügig. Je nach Kombination mit anderen Parametern erhöhte
Stemming jedoch die Anzahl der gefundenen Textpassagen um 15 bis 40 Prozent. Die
Reihenfolge der Wörter innerhalb der Fundstellen zu ignorieren verdoppelte bis ver-
dreifachte die Ergebnismenge. Einfügungen von maximal einem nicht zum N-Gramm
gehörenden Wort zu tolerieren lieferte ein Mehr von 8 bis 22 Prozent an Textpassagen.
Miteinander kombiniert konnten die Parameter den Ergebnisraum mehr als verdreifachen.
Eine allgemeingültige Empfehlung für die Parametrisierung lässt sich aus diesen Zahlen
jedoch nicht ableiten, denn mit steigender Toleranz gegenüber Änderungen kann auch
der Anteil relevanter Ergebnisse sinken.
5.3. Kategorisierung der Dokumente
Die EU-Kommission kategorisiert eingegangene Dokumente anhand ihrer Absender in
vier Kategorien: Bürger, registrierte Organisationen, nicht registrierte Organisationen
und Behörden. Registrierung bezieht sich auf die Eintragung in ein Transparenzregister,
mit der sich Organisationen zur Einhaltung ethischer Grundsätze verpflichten [EU13]. Ta-
belle 5.6 kann entnommen werden, wie sich Fundstellen und Bewertungen der Dokumente
33
Dokumente Textpassagen
Kategorie gesamt gefunden  Score gesamt Schnitt
Behörden 29 22 2,431 524 18,1
Bürger 94 50 1,095 375 4,0
Organisationen (registriert) 160 152 1,334 2 477 15,5
Organisationen (nicht registriert) 127 119 1,334 1 567 12,3
Tabelle 5.6.: Auswertung der Dokumente nach Kategorien
auf Basis von 4-Grammen auf diese Kategorien verteilten. Für eine Vergleichbarkeit der
Scores war dabei zu beachten, dass die Dokumente aller Kategorien gemeinsam analysiert
werden müssen, da die in die Berechnung eingehenden inversen Dokumentfrequenzen
der einzelnen Terme, siehe Abschnitt 3.2, vom Gesamtkorpus abhängen. Auffällig ist
die hohe Bewertung für Einsendungen von Behörden, die gegenüber dem Durchschnitt
der restlichen Dokumente fast doppelt so hoch ausfiel. Diese Abweichung sollte jedoch
aufgrund der vergleichsweise geringen Stichprobengröße von nur 22 Dokumenten, die
inhaltliche Übereinstimmungen mit dem Zieldokument aufwiesen, mit Vorsicht bedacht
werden. Kommentare von Bürgern hatten die geringsten inhaltlichen Schnittmengen mit
dem Gesetzentwurf. Fast die Hälfte blieb ohne Fundstelle. Ein wesentlicher Unterschied
zwischen registrierten und nicht registrierten Organisationen konnte nicht ausgemacht
werden. Während erstere durchschnittlich 25 Prozent mehr Fundstellen enthielten, wur-
den die Dokumente beider Kategorien im Schnitt gleich bewertet. Ob sich aus diesen
Zahlen schließen lässt, dass die inhaltlichen Forderungen von Behörden bevorzugt berück-
sichtigt wurden, oder ob sie lediglich die relevanteren Themen aufgegriffen hatten und
zielgerichteter verfasst waren, wird nur durch eine inhaltliche Analyse zu klären sein.
5.4. Clustering
Die im vorangegangenen Abschnitt betrachtete Einteilung nach Art des Absenders ist
eine sehr grobe. Von Interesse ist vielmehr, wie sich die Interessenvertreter inhaltlich
gruppieren lassen und welche Gruppen dabei die größeren Übereinstimmungen mit dem
Gesetzentwurf aufweisen.
34
5.4.1. Clustering nach Vokabular
Zu diesem Zweck wurde zunächst durch den in Abschnitt 3.4.1 beschriebenen UPGMA-
Algorithmus ein hierarchisches Clustering anhand der 1 000 häufigsten Wörter im ge-
samten Dokumentkorpus berechnet. Um relevante Teilcluster zu identifizieren, wurde
diese Hierarchie in pre-order traversiert. Bei Clustern mit zehn oder weniger enthalte-
nen Dokumenten wurde diese Tiefensuche jeweils abgebrochen und die dazugehörigen
Dokumente sowie deren durchschnittliche Bewertung erfasst. Unberücksichtigt blieben
21 Dokumente, die lediglich einem bestehenden Cluster von zehn oder mehr Elementen
zugeordnet wurden, da die Ähnlichkeiten dieser Dokumente untereinander als deutlich
relevanter angesehen werden können. Grundlage für die Bewertungen waren N-Gramme
der Länge 4. Vertauschungen von Wörtern sowie Einfügungen von maximal einem Wort
wurden dabei toleriert.
Das Ergebnis, sortiert nach Bewertungen, kann in Anhang A.1 eingesehen werden. Die
gebildeten Gruppen erscheinen durchaus plausibel. So werden beispielsweise bei einer
Suche nach Unternehmen einzelne Branchen wie Telekommunikation, Software, Medien,
Banken, Verlage oder Versicherungen erkennbar. Die Namen einzelner Bürger finden sich
dagegen, der vorherige Abschnitt hatte es angedeutet, vermehrt am Ende der Tabelle.
Mehrfacheinsendungen einzelner Interessenvertreter wurden in den meisten Fällen korrekt
zugeordnet, teilweise bildeten sie sogar eigene Cluster. Auffällig dagegen war beispielsweise
eine Gruppierung der Telekom Austria mit drei Einsendungen von Bürgern. Deren
inhaltliche Übereinstimmung beschränkte sich lediglich auf Zitate der ursprünglichen
Fragestellungen der EU-Kommission, wodurch es jedoch zu einer Überschneidung vieler
gemeinsamer Wörter und damit hohen Ähnlichkeitswerten kam.
5.4.2. Clustering nach Fundstellen
Wie in Abschnitt 3.4.2 erläutert, wurde nicht nur ein Clustering anhand des Vokabulars,
sprich einzelnen Wörtern, implementiert, sondern auch eine Variante basierend auf den ge-
meinsamen Übereinstimmungen mit dem Zieldokument. Die Vergleichsparameter blieben
dabei zum vorangegangenen Abschnitt unverändert. Um irrelevante Gemeinsamkeiten
herauszufiltern, wie etwa die in Abschnitt 5.2.2 ermittelten häufigen Zitate der Konsul-
tationstitel, der Fragestellungen oder von Passagen aus gemeinsamen Quellen, wurden
ausschließlich Fundstellen berücksichtigt, die in höchstens zehn Dokumenten auftraten.
Die Clustering-Hierarchie wurde erneut in pre-order traversiert und sämtliche Teilcluster
der Größe ≥ 2 erfasst, in denen alle Dokumente über gemeinsame Fundstellen verfügten.
Aufgrund der Beschränkung auf relevante Fundstellen wurde hier im Unterschied zum
35
Clustering nach Vokabular keine Obergrenze festgelegt. Ignoriert wurden Teilcluster, bei
denen sich die Anzahl der Fundstellen gegenüber ihren Eltern nicht erhöhte. Für jeden
ermittelten Cluster wurden schließlich die Bewertungen der gemeinsamen Fundstellen
summiert.
Das Resultat waren 154 Cluster aus 269 Dokumenten. Für 95 weitere Konsultationstexte,
die Gemeinsamkeiten mit dem Gesetzentwurf aufwiesen, fanden sich basierend auf den
obigen Kriterien keine Überschneidungen mit anderen Dokumenten. Im Median hatten
die Dokumente eines Clusters drei gemeinsame Fundstellen. Ohne die Beschränkung auf
seltene Fundstellen lag dieser Wert bei 23. In Anhang A.2 werden die ermittelten Cluster
sortiert nach ihren Bewertungen auszugsweise in Tabellenform aufgelistet. Einträge
mit weniger als drei gemeinsamen Fundstellen wurden dazu herausgefiltert. Der größte
ermittelte Cluster bestand aus acht Dokumenten (Score: 2,108). Durch die gewählte
Vorgehensweise können sowohl Cluster als auch deren Teilcluster in der Tabelle auftauchen
und damit Dokumente in mehreren Einträgen enthalten sein. Die Hierarchie wird dadurch
teilweise nachvollziehbar. So zitierten beispielsweise im Cluster act, act, dp at csls study
group, ebu, european publishers council, bbc (Score: 3,260) fünf Organisationen aus
dem für sie relevanten Artikel 9 der Vorgängerrichtlinie über die Vereinbarkeit von
Meinungsfreiheit mit der Verarbeitung personenbezogener Daten und konnten somit
gemeinsame Fundstellen für sieben 4-Gramme aufweisen. Die Association of Commercial
Television in Europe (ACT) trat hier doppelt auf, da sie in den Jahren 2009 und 2011
Stellungnahmen eingereicht hatte. Ohne die Einsendung der BBC waren es bereits zehn
gemeinsame Fundstellen, bei EBU und European Publishers Council allein betrachtet
sogar elf. Mit ACT, BBC und EBU fanden sich drei Interessenvertreter bereits beim
Clustering nach Vokabular in einer gemeinsamen Gruppe wieder.
36
6. Zusammenfassung und Ausblick
Bei der extrinsischen Suche nach Plagiaten sind N-Gramme eine bewährte Methode
zur Erkennung übernommener Textabschnitte. Doch während dort meist ganze Absätze
oder gar Dokumente als Plagiat eingeordnet werden, bestätigte die Auswertung in die
in Abschnitt 2.2.2 gemachte Annahme, dass beim Vergleich der Konsultationstexte
mit dem Entwurf zur Datenschutz-Grundverordnung einzelne Begriffe im Vordergrund
stehen. Ob es sich dabei tatsächlich um Übernahmen von damit verbundenen inhaltlichen
Forderungen aus der jeweiligen Einsendung oder Zufallsfunde handelt, wird letztlich nur
eine Auswertung durch fachkundige Juristen klären können.
Für Trigramme konnten, wie in Abschnitt 5.2.2 dargestellt, 1 158 Textpassagen identi-
fiziert werden, die sich auf genau ein Quelldokument zurückführen ließen. Für 4-Gramme
waren es 508 Textpassagen. Davon waren 88 bzw. 79 Prozent nicht länger als die gesuchten
drei bzw. vier Wörter. Aus maximal zwei überlappenden N-Grammen setzten sich bereits
94 bzw. 88 Prozent der Textpassagen zusammen. Anstatt der Software jeweils ein festes
N vorzugeben und die Fundstellen zusammenzufassen, wäre denkbar gewesen, nach den
maximalen gemeinsamen N-Grammen zu suchen.
Längere übereinstimmende Textpassagen haben sich, soweit geprüft, fast ausnahmslos
als Zitate aus gemeinsamen Quellen herausgestellt. Diese stammten zumeist aus den
Fragestellungen der Kommission sowie der gegenwärtig geltenden Datenschutz-Richtlinie
95/46/EG. Dies war insofern unproblematisch, als dass in sehr vielen Dokumenten zitierte
Passagen auf Basis der in Abschnitt 3.2.1 definierten TF-IDF-Metrik vergleichsweise
geringe Bewertungen erhielten und somit in der graphischen Darstellung der Dokumente
nur schwach hervorgehoben wurden. Seltene Zitate erhielten sehr hohe Bewertungen. Die
ihnen damit zugesprochene inhaltliche Relevanz kann aber durchaus als gerechtfertigt
angesehen werden, sofern sie mit entsprechenden Forderungen verbunden wurden.
Für eine mögliche Weiterentwicklung der Software bedeutet dies zunächst die Erkennt-
nis, Zitate aus gemeinsamen Quellen gesondert zu berücksichtigen. Hierzu ließen sich ein
oder mehrere Referenzdokumente angeben, mit deren N-Grammen und damit inhaltlichen
Fingerabdrücken die verarbeiteten Texte abgeglichen werden könnten. Vonnöten wären
dabei vermutlich höhere Werte von N ≥ 5, um längere identische Abschnitte von isolier-
37
ten Phrasen oder Begriffen unterscheiden zu können. Die betroffenen Passagen könnten
schwächer bewertet und in der Darstellung der Dokumente gesondert hervorgehoben
werden. Ferner ließe sich untersuchen, inwieweit sich relevante Begriffe in Einsendungen
und Gesetzentwurf in der Nähe solcher Zitate befanden und somit Hinweise auf mit
ihnen verbundenen inhaltlichen Forderungen liefern könnten. Möglicherweise könnten
sich so Passagen identifizieren lassen, die auf Änderungen an konkreten Paragraphen
der Vorgängerrichtlinie eingewirkt hatten. Entscheidend für die Wiederverwendbarkeit
der Software auf Dokumente anderer Gesetzgebungsverfahren dürfte der Vergleich mit
früheren Fassungen von Gesetzestexten sein.
Verbesserungen wären zudem bei der Bedienbarkeit der Software denkbar. Dies betrifft
zum einen die Bestimmung gemeinsamer Fundstellen innerhalb der ermittelten Clus-
ter. Zwar lassen sich einzelne Fundstellen per Mausklick anhand der beim Indexieren
vergebenen Identifikationsnummern, siehe Abschnitt 4.4, in mehrere Dokumente zurück-
verfolgen. Die für einen Cluster relevanten gemeinsamen Fundstellen können aus der
Oberfläche heraus jedoch nur durch Probieren bestimmt werden. Darüber hinaus könnte
die Darstellung der Dokumente besser gelöst werden, die aufgrund der Vorgehensweise
beim Einlesen, siehe Abschnitt 4.1, als unformatierter Text erfolgte. Stattdessen könnten
die Hervorhebungen direkt innerhalb der PDF-Dokumente gespeichert werden, um die
Navigation anhand von Seiten zu erleichtern und Überschriften oder Fußnoten leichter
als solche zu erkennen.
38
Literatur
[Bao+04] Jun-Peng Bao, Jun-Yi Shen, Xiao-Dong Liu, Hai-Yan Liu und Xiao-Di Zhang.
„Semantic sequence kin: A method of document copy detection“. In: Advances
in Knowledge Discovery and Data Mining. Springer, 2004, S. 529–538.
[BC+10] Alberto Barrón-Cedeño, Chiara Basile, Mirko Degli Esposti und Paolo Ros-
so. „Word length n-Grams for text re-use detection“. In: Computational
Linguistics and Intelligent Text Processing. Springer, 2010, S. 687–699.
[BCR09] Alberto Barrón-Cedeño und Paolo Rosso. „On automatic plagiarism detec-
tion based on n-grams comparison“. In: Advances in Information Retrieval.
Springer, 2009, S. 696–700.
[Dav12] Mark Davis. Unicode Text Segmentation. Unicode Standard Annex #29. Sep.
2012. url: http://unicode.org/reports/tr29/ (besucht am 01. 08. 2013).
[EC09a] EC (European Commission). Consultation on the legal framework for the
fundamental right to protection of personal data. Dez. 2009. url: http://
ec.europa.eu/justice/newsroom/data-protection/opinion/090709_en.htm
(besucht am 01. 05. 2013).
[EC09b] EC (European Commission). Review of the data protection legal framework.
Mai 2009. url: http://ec.europa.eu/justice/newsroom/data-protection/
opinion/090501_en.htm (besucht am 01. 05. 2013).
[EC10a] EC (European Commission). Consultation on the future European Union
(EU) - United States of America (US) international agreement on personal
data protection and information sharing for law enforcement purposes. März
2010. url: http://ec.europa.eu/justice/newsroom/data-protection/opinion/
100128_en.htm (besucht am 01. 05. 2013).
[EC10b] EC (European Commission). Stakeholder consultation: meeting on the review
of the EU’s data protection regulatory framework. Juli 2010. url: http://
ec.europa.eu/justice/newsroom/data-protection/events/100701_en.htm
(besucht am 01. 05. 2013).
[EC11] EC (European Commission). Consultation on the Commission’s comprehensi-
ve approach to personal data protection in the European Union. Jan. 2011.
url: http://ec.europa.eu/justice/newsroom/data- protection/opinion/
101104_en.htm (besucht am 01. 05. 2013).
39
[EC12] EC (European Commission). Proposal for a Regulation of the European
Parliament and of the Council on the protection of individuals with regard to
the processing of personal data and on the free movement of such data (General
Data Protection Regulation). COM(2012) 11 final. Jan. 2012. url: http://eur-
lex.europa.eu/LexUriServ/LexUriServ.do?uri=CELEX:52012PC0011:en:
NOT (besucht am 01. 05. 2013).
[EC13] EC (European Commission). PDF (Portable File Format). Aug. 2013. url:
http://ec.europa.eu/ipg/standards/document/pdf/index_en.htm (besucht
am 12. 08. 2013).
[EU13] EU (Europäische Union). Verhaltenskodex - Register der Interessenvertreter.
Aug. 2013. url: http://ec.europa.eu/transparencyregister/info/about-
register/codeOfConduct.do?locale=de (besucht am 06. 09. 2013).
[GB10] Bela Gipp und Jöran Beel. „Citation based plagiarism detection: a new
approach to identify plagiarized work language independently“. In: Proceedings
of the 21st ACM conference on Hypertext and hypermedia. ACM. 2010, S. 273–
274.
[Hua08] Anna Huang. „Similarity measures for text document clustering“. In: Procee-
dings of the Sixth New Zealand Computer Science Research Student Conference
(NZCSRSC2008), Christchurch, New Zealand. 2008, S. 49–56.
[HZW02] Steffen Heinz, Justin Zobel und Hugh E Williams. „Burst tries: a fast, efficient
data structure for string keys“. In: ACM Transactions on Information Systems
(TOIS) 20.2 (2002), S. 192–223.
[Lei+01] Charles E Leiserson, Ronald L Rivest, Clifford Stein und Thomas H Cormen.
Introduction to algorithms. The MIT press, 2001, S. 311–318.
[LMD01] Caroline Lyon, James Malcolm und Bob Dickerson. „Detecting short passages
of similar text in large document collections“. In: Proceedings of the 2001
Conference on Empirical Methods in Natural Language Processing. 2001,
S. 118–125.
[Lob13a] LobbyPlag. Comparison of Amendments ans Lobby Proposals. 2013. url:
http://lobbyplag.eu/influence (besucht am 12. 05. 2013).
[Lob13b] LobbyPlag. Documents. 2013. url: http://lobbyplag.eu/docs (besucht am
12. 05. 2013).
[Lob13c] LobbyPlag. LobbyPlag. 2013. url: http : / / lobbyplag . eu/ (besucht am
12. 05. 2013).
[Luc13a] Apache Software Foundation. BlockTreeTermsReader (Lucene 4.3.0 API).
Mai 2013. url: http://lucene.apache.org/core/4_3_0/core/org/apache/
lucene/codecs/BlockTreeTermsReader.html (besucht am 28. 07. 2013).
[Luc13b] Apache Software Foundation. TFIDFSimilarity (Lucene 4.3.0 API). Mai 2013.
url: http://lucene.apache.org/core/4_3_0/core/org/apache/lucene/search/
similarities/TFIDFSimilarity.html (besucht am 30. 07. 2013).
40
[MRS08] Christopher D Manning, Prabhakar Raghavan und Hinrich Schütze. Introduc-
tion to information retrieval. Bd. 1. Cambridge University Press Cambridge,
2008, S. 117–119.
[Ora11a] Oracle and/or its affiliates. Color (Java Platform SE 7). 2011. url: http:
//docs.oracle.com/javase/7/docs/api/java/awt/Color.html (besucht am
17. 08. 2013).
[Ora11b] Oracle and/or its affiliates. JTextArea (Java Platform SE 7). 2011. url:
http://docs.oracle.com/javase/7/docs/api/javax/swing/JTextArea.html
(besucht am 17. 08. 2013).
[Pot+10] Martin Potthast, Alberto Barrón-Cedeño, Andreas Eiselt, Benno Stein und
Paolo Rosso. „Overview of the 2nd international competition on plagiarism
detection“. In: Notebook Papers of CLEF 10 (2010).
[Sch13] Max Schrems. „Forum Shopping“ für die IT-Industrie? Feb. 2013. url:
http://www.europe-v-facebook.org/IMCO_pub_de_ON.pdf (besucht am
01. 05. 2013).
[SM58] R. R. Sokal und C. D. Michener. „A statistical method for evaluating syste-
matic relationships“. In: University of Kansas Scientific Bulletin 28 (1958),
S. 1409–1438.
[Sta11] Efstathios Stamatatos. „Plagiarism detection using stopword n-grams“. In:
Journal of the American Society for Information Science and Technology
62.12 (2011), S. 2512–2527.
[ZES06] Sven Meyer Zu Eissen und Benno Stein. „Intrinsic plagiarism detection“. In:
Advances in Information Retrieval. Springer, 2006, S. 565–569.
41
A. Anhang
A.1. Clustering nach Vokabular
Die Erläuterung zu dieser Tabelle findet sich in Abschnitt 5.4.1. Für die Dokumente
sind die originalen Dateinamen angegeben. Zur besseren Lesbarkeit wurden Unterstriche
durch Leerzeichen ersetzt und die Endung _en.pdf weggelassen.
Score Dokumente
10,280 dpoq, task force copyright, wada, matthios fabien
9,210 ernst young, kuner christopher, gonzalez fuster gloria
8,364 amberhawk, dp at csls study group, art29 wp and wppj, beuc, beuc, european
privacy association, edri
7,103 allen and overy, bba and afme, bskyb, eadp
7,037 bundesregierung, open society, pocs matthias
5,550 bird bird, skype, edpr, linklaters llp, intrum justitia, ecta, eiaa, von
5,546 amcham, microsoft, telecom italia, telefonica, ecta, euroispa, ispa, bsa,
business software alliance, microsoft corporation
5,483 a and n media, act, bbc, ebu, fiad fiapf ivf mpa, mpa ivf fiad fiapf, icmp,
nbc universal, icmp, ifpi
5,289 american chamber commerce to eu, international chamber of commerce icc,
cisco, cisco, epof, european privacy officers forum, epof, garrigues
5,169 associazione bancaria italiana, european banking federation, ebf, zentralen
kreditausschuss, fbf, french banking federation
5,130 advertising association, epc and annex1, european publishers council, data
industry platform, enpa and faep, bisnode
5,030 abi, bba, bt, bird and bird, field fisher waterhouse llp
5,024 alain bensoussan selas, ngfg, lee and white, ngfg, deutsche vereinigung, etuc,
uni
5,006 aldhouse francis, austrian bar, general electric
4,961 epa, gpa, johnson and johnson, hewlett packard, nokia
4,926 asedie, ced, wfa, euro ispa, fedma, fedma, ueapme, ueapme, fenca, minjust
lv
4,834 deutsche telekom , etno, etno, telefonica, gse, gdd, gdd
4,662 acxiom, intrum, data protection forum, rackspace us inc, verizon
4,640 carfax europe, janet uk, guzman rodriguez hector
42
Score Dokumente
4,509 bitkom, cea, gdv, munich re, german insurance association
4,469 article29 and working party on police and justice publicauthority, association
for fair data processing unregistered, ben tasker citizen, talkademy org
unregistered, bcs the chartered institute for it unregistered, dr heinrich kuhn
citizen, ectaa registered, british bankers association registered, european
banking federation registered, esgb registered
4,464 Bdma, data industry platform annex, emota, the direct marketing association
UK, the direct mktg, eadp, joint replypa faep, ppa, ppa uk
4,365 acro, acro, international pharmaceutical privacy consortium, ippc, efam-
ro and esomar, joint reply esomar efamro, roy-toole christopher, encore,
kanellopoulou nadja
4,339 bcs, nhs, cocir, big brother, institute innovative progress
4,303 anker wolfram, data inspection board, kukk urmas, krenker andrej
4,300 accis, accis, eurofinas, eurofinas, kpf poland, sifma
4,244 cdt, iab europe, gsma, gsma europe, vodafone, vodafone
4,157 iata, world check, ico infocommoffice, ico uk, symantec, symantec, tech
america europe
4,108 digital europe, digitaleurope, intel, intel corporation, liberty global, liberty
global europe
4,077 yahoo, yahoo europa
4,043 anacom, telecom italia, ceep, orange
4,013 aea, ectaa, febis
3,927 aktion freiheit, ccbe, ccbe, privacy international, eurojust, theissen sascha
3,915 association for fair data processing, natarchives uk, bma, british medical
association, national information governance board, cpme
3,848 act joint response, iab europe, tech america europe, hide rise consortia,
alcatel lucent, mcafee, bcs, guernsey data protection commissioner
3,690 aure, aure, general medical council, gmc, nursing and midwifery Council,
council for healthcare regulatory excellence, psni, encepp, euphex, national
aids trust nat
3,674 bitkom, sabi
3,507 consumer focus, pi, cyberspace, eabc, icc, icaew
3,341 ebay registered, mark dziecielewski citizen
3,322 the number, the number
3,197 breyer patrick 0, efrn, the global privacy alliance, mersault stephan
3,187 benton dustin, corbet rob, kilian wolfgang, masdevall jordi
3,005 ebay, eBay, europeansocialnetworks, privowny, facebook, isfe, isfe
2,845 adrian kerton citizen, bell raymond, mendez raul, elra, ziemba krzysztof
2,816 aug atheist, p breyer citizen, pounder chris
2,690 anec, anec, danish consumer council, vzbv, phorm inc, center for democary
technology, ftc federaltradecommission, jones eric, coueignoux philippe and
leprat marc, enacso
43
Score Dokumente
2,586 abi, fla, minjust uk, uk government, cipl, hunton and williams1, hunton and
williams2, datatilsynet
2,535 european privacy association registered, greenberg traurig llp unregistered
2,525 fluck nick, telekom austria, segaud olivier, strangar gerhard
2,522 joint reply by vno ncw mkb nederland, vno ncw
2,464 julian schutte citizen, maria grazia porcedda citizen, moureen schobert
citizen
2,457 bdi, kapsch trafficCom, law society uk, dietrich daniel, ipc info and priva-
cy comm ca, kortbaek frederik, rannenberg kai, hatscher jordan, karhula
paivikki
2,453 cbi, cbi
2,420 freriks gerard, vlad ioan luca
2,312 dsci, jbce, lachaud eric, schneider robert, naid, tuvit, ernst young, h7b1
2,312 bag, ehfcn, betfair, bt, ericsson in registering process, bdiu, yamada yasuhide,
microsoft corporation 2nd document, provvidera marco
1,942 cancer research uk, in house charity lawyers group, european fundraising
association
1,713 activision, egdf, dif
1,089 afcdp table2, henno jacques, edri, fep, ripe ncc, emota, info center finland,
laubacher gerard, laxen jon
0,664 anonymous vi citizen, arne wichmann citizen, jan schejbal citizen
0,620 cascianelli paolo, christoforidis k, idnetters, oliver paul
0,568 bundesministerium des innern 1, bundesministerium des innern 2
0,474 epc annex2a, epc annex2b, epc annex3, xuereb patrick
0,422 monaghan mark, narusberg ilona
0,329 anonymous iv citizen, french banking association registered, michael greig
citizen
0,245 dpof, young pirates
0,126 anonymous iii citizen, denis dettmer citizen, hoppermann p, simon molina
francisco, d hegeler citizen
0,072 anonymous vii citizen, pedro griell barnes citizen, powell robert, ralf siegert
citizen
0,061 croft sylvia, norbert toth citizen, zurich financial services unregistered,
gernot ziegler citizen, young david, cyrille giquello citizen, everix patrick,
van den broek jasper, ojedarique
0,000 ian blythe citizen, john pepin citizen
0,000 colin hodgson citizen, wood john, foebud
Fehlend: michael citizen, common sense privacy ltd unregistered, miron roth citizen,
finnish industries, act, klaus hammermuller citizen, dr eric bodden citizen, fenca, eacb
registered, gs1, sigacus gestion, air berlin, ioan luca vlad citizen, malcolm boura citizen,
swift registered, orange, step, visa, strasser maritta, jason bell citizen, jay libove citizen.
44
A.2. Clustering nach Fundstellen
Die Erläuterung zu dieser Tabelle findet sich in Abschnitt 5.4.2. Für die Dokumente
gelten die gleichen Anmerkungen wie in Abschnitt A.1.
Score Fundstellen Dokumente
48,084 77 dpoq, task force copyright
25,636 50 epof, european privacy officers forum
19,631 35 gdv, munich re
13,786 24 amberhawk, pi
12,579 27 epof, european privacy officers forum, epof
11,077 24 bcs, telecom italia
10,656 23 bba and afme, bcs, telecom italia
8,629 18 euroispa, ispa
8,505 15 american chamber commerce to eu, association for fair data
processing
8,410 17 general medical council, gmc
8,116 16 art29 wp and wppj, gonzalez fuster gloria, johnson and johnson
7,952 14 ccbe, ccbe
7,229 14 gdv, munich re, german insurance association
6,990 13 dpoq, task force copyright, efamro and esomar
6,677 11 center for democary technology, gsma europe
6,650 12 ecta, eiaa
6,642 12 institute innovative progress, pocs matthias
6,189 14 bba and afme, bcs, telecom italia, the direct mktg
5,984 10 business software alliance, european privacy association
5,777 12 art29 wp and wppj, gonzalez fuster gloria, johnson and johnson,
cdt
5,597 11 ebu, european publishers council
5,240 10 advertising association, lee and white
5,075 11 euroispa, ispa, gsma
4,863 8 ico infocommoffice, ico uk
4,835 10 act, act, dp at csls study group, ebu, european publishers council
4,833 9 advertising association, lee and white, open society
4,724 11 bag, symantec
4,612 9 austrian bar, ccbe, ccbe
4,455 8 amberhawk, pi, amcham
4,333 9 aure, aure, general medical council, gmc
4,317 10 bag, symantec, carfax europe
4,162 8 etno, etno
4,063 8 intel corporation, intel
3,983 9 breyer patrick 0, edri, guzman rodriguez hector
45
Score Fundstellen Dokumente
3,926 7 kukk urmas, telefonica
3,924 7 etuc, uni
3,924 6 air berlin, microsoft
3,917 7 fiad fiapf ivf mpa, icmp, mpa ivf fiad fiapf
3,908 6 bisnode, bskyb
3,864 7 symantec, tech america europe
3,807 5 aldhouse francis, ueapme
3,694 7 cisco, cisco
3,603 8 bird and bird, epof, european privacy officers forum, epof
3,567 8 bba and afme, bcs, telecom italia, the direct mktg, eadp
3,561 6 eurofinas, eurofinas
3,441 6 general electric, sifma
3,430 7 ecta, eiaa, von
3,347 6 ben tasker citizen, talkademy org unregistered
3,326 6 act joint response, iab europe
3,296 7 british bankers association registered, european banking fede-
ration registered
3,290 6 digitaleurope, iab europe
3,260 7 act, act, dp at csls study group, ebu, european publishers
council, bbc
3,152 5 abi, europeansocialnetworks
3,146 5 data industry platform, enpa and faep
3,066 6 associazione bancaria italiana, european banking federation
3,020 5 ebf, zentralen kreditausschuss
2,871 6 association for fair data processing unregistered, bundesregie-
rung
2,776 6 euroispa, ispa, gsma, liberty global
2,771 6 british bankers association registered, european banking fede-
ration registered, institute innovative progress, pocs matthias,
minjust lv, efrn
2,671 6 accis, bba and afme, bcs, telecom italia, the direct mktg, eadp
2,651 5 french banking federation, intrum justitia
2,589 4 fla, pounder chris
2,578 4 business software alliance, european privacy association, joint
reply esomar efamro
2,548 6 bag, symantec, carfax europe, janet uk
2,339 4 digitaleurope, iab europe, rannenberg kai
2,297 5 aktion freiheit, association for fair data processing unregistered,
bundesregierung
2,284 3 ftc federaltradecommission, ppa uk
2,199 5 bird and bird, epof, european privacy officers forum, epof, nbc
universal, field fisher waterhouse llp
46
Score Fundstellen Dokumente
2,108 5 bag, symantec, carfax europe, janet uk, deutsche vereinigung,
center for democary technology, gsma europe, beuc
2,051 3 aea, iata
2,048 3 bba, guernsey data protection commissioner
2,042 4 acro, acro
2,029 4 advertising association, lee and white, open society, p breyer
citizen
1,965 4 cyberspace, lachaud eric
1,890 4 aure, aure, general medical council, gmc, nursing and midwifery
Council
1,888 4 bma, cbi
1,814 3 act joint response, iab europe, fedma
1,811 3 ced, ippc
1,672 3 ceep, orange
1,671 4 naid, world check
1,609 3 bird bird, skype
1,609 3 hunton and williams2, international pharmaceutical privacy
consortium
1,560 3 emota, fedma
1,497 3 ebf, zentralen kreditausschuss, gdd
1,490 3 cancer research uk, in house charity lawyers group
1,476 3 cipl, cisco, cisco
1,449 3 deutsche telekom , etno, etno
1,440 3 cyberspace, lachaud eric, hunton and williams1
1,319 3 nhs, nokia
1,250 3 ebay, the number
1,234 3 breyer patrick 0, edri, guzman rodriguez hector, telecom italia
1,234 3 kuner christopher, symantec, tech america europe
47
A.3. Kurzanleitung zu LawPlag
LawPlag benötigt Java SE ab Version 7 und kann wie jede andere Java-Anwendung per
Kommandozeile gestartet werden:
java -jar lawplag.jar
Nach Programmaufruf wird zunächst zur Auswahl eines Verzeichnisses mit Quelldo-
kumenten aufgefordert, das daraufhin mitsamt aller Unterverzeichnisse eingelesen wird.
Anschließend kann ein Zieldokument ausgewählt werden, das sich in einem anderen
Verzeichnis befinden sollte. Alternativ können diese beiden Angaben durch Parameter
vorgegeben werden:
java -jar lawplag.jar <Quellverzeichnis> <Zieldokument>
Dokumente können als PDF- oder Textdateien vorliegen. PDF-Dateien werden zum
schnelleren späteren Zugriff im Textformat (UTF-16) mit der Endung .pdf.txt abgespei-
chert. Sind keine PDFs vorhanden, dann werden stattdessen alle Textdateien geladen.
Umgang mit Fundstellen
Nach dem Einlesen und Vergleichen werden im Zieldokument sämtliche über alle Quellen
verteilte Fundstellen markiert. Durch Auswahl eines Quelldokuments auf der linken Seite
wird ein Dokument dem Zieldokument gegenübergestellt. Mit Strg+Klick auf den Eintrag
kann diese Auswahl wieder rückgängig gemacht werden. Durch Klick auf eine konkrete
Fundstelle werden sämtliche Übereinstimmungen sowohl in den beiden Texten als auch
in der Auflistung der Dokumente angezeigt. Zur leichteren Unterscheidung wechselt
dabei die Farbe. Die Auswahl kann im Quell- oder Zieldokument erfolgen und bleibt
beim Wechsel auf andere entsprechend markierte Dokumente erhalten, wodurch sich eine
Formulierung in mehreren Quellen verfolgen lässt. Ein Klick außerhalb der Fundstelle
setzt die Auswahl wieder zurück.
Ranking und Clustering
Über die Spalte Score können Dokumente nach ihrer Relevanz sortiert werden. Die
Anzeige des Clusterings setzt eine Sortierung der Dokumentliste nach der dazugehörigen
Spalte voraus.
48
Selbstständigkeitserklärung
Hiermit erkläre ich, dass ich die vorliegende Arbeit selbstständig und nur unter Zuhilfe-
nahme der angegebenen Quellen und Hilfsmittel verfasst habe.
12. Dezember 2013
Frank Bicking
