Adding Twitter-Specific Features to Stylistic Features
for Classifying Tweets by User Type and Number
of Retweets
Yui Arakawa
Graduate School of Library, Information and Media Studies, University of Tsukuba 1-2 Kasuga, Tsukuba-city,
Ibaraki-ken 305-8550, Japan. E-mail: s1221577@u.tsukuba.ac.jp
Akihiro Kameda
Research Organization of Information and Systems, 2-1-2 Hitotsubashi, Chiyoda-ku, Tokyo 101-8430, Japan.
E-mail: kameda@nii.ac.jp
Akiko Aizawa
National Institute of Informatics, 2-1-2 Hitotsubashi, Chiyoda-ku, Tokyo 101-8430, Japan / Graduate School of
Information Science and Technology, University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo 113-8656, Japan.
E-mail: aizawa@nii.ac.jp
Takafumi Suzuki
Faculty of Sociology, Toyo University, 5-28-20, Hakusan, Bunkyo-ku, Tokyo 112-8606, Japan. E-mail:
takafumi_s@toyo.jp
Recently, Twitter has received much attention, both from
the general public and researchers, as a new method of
transmitting information. Among others, the number of
retweets (RTs) and user types are the two important
items of analysis for understanding the transmission of
information on Twitter. To analyze this point, we applied
text classification and feature extraction experiments
using random forests machine learning with conven-
tional stylistic and Twitter-specific features. We first col-
lected tweets from 40 accounts with a high number of
followers and created tweet texts from 28,756 tweets. We
then conducted 15 types of classification experiments
using a variety of combinations of features such as
function words, speech terms, Twitter’s descriptive
grammar, and information roles. We deliberately
observed the effects of features for classification perfor-
mance. The results indicated that class classification
per user indicated the best performance. Furthermore,
we observed that certain features had a greater impact
on classification. In the case of the experiments that
assessed the level of RT quantity, information roles had
an impact. In the case of user experiments, important
features, such as the honorific postpositional particle
and auxiliary verbs, such as “desu” and “masu,” had an
impact. This research clarifies the features that are
useful for categorizing tweets according to the number
of RTs and user types.
Introduction
Twitter (www.twitter.com) is an application that allows
users to create microblogs by posting messages within a
limit of 140 characters. Twitter’s service began in the United
States in 2006, and Twitter continues to be used for a variety
of communication and information dissemination purposes.
Its functionality is simple, and it has descriptive grammar,
such as replies (@), retweets (RT and QT) that quote the
main text of the tweet, and hash tags (#) that users include
in their messages to show they are referring to the same
issue. Twitter is characterized by its speed, simplicity, and
communicability. In particular, the previously mentioned
Received August 1, 2012; revised September 5, 2013; accepted September
5, 2013
© 2014 ASIS&T • Published online in Wiley Online Library
(wileyonlinelibrary.com). DOI: 10.1002/asi.23126
JOURNAL OF THE ASSOCIATION FOR INFORMATION SCIENCE AND TECHNOLOGY, ••(••):••–••, 2014
descriptive grammar element, RT, has high communicability
and allows the tweets of users who are not followed to be
visible.
In recent years, a lot of attention has been given to com-
munications using social media among members of demo-
cratic movements in Islamic regimes (Jasmine revolution).
After the Japan earthquake that occurred on May 11, 2011,
Twitter was used as a tool to collect and transmit informa-
tion in Japan. It was used to exchange information between
search-and-rescue personnel and to provide information that
could not be received from the mass media, such as infor-
mation to help relieve the emotional stress related to the fear
of earthquakes. Although its usefulness has gained much
attention, Twitter’s negative role in spreading wild and false
rumors has also been pointed out (Ogiue, 2011; Tachiiri,
2011). Twitter can be used as a tool to collect and distribute
useful information and also to transmit and receive misin-
formation. It is vital to be able to extract important informa-
tion from a huge volume of tweets not only in the case of
emergencies but also during everyday life.
With Twitter, a huge volume of information is created
from all users’ tweets. Using this information, it is possible
to see the flow of information and links between people.
Users can obtain a large amount of information. However,
because the volume of information is so large, it is difficult
to examine it all closely and judge what is important and
what is not. This research considers one such item of impor-
tant information and concentrates on easily communicable
information.
If we broadly categorize the elements of easily commu-
nicable tweets on Twitter into two groups, we can see a
relationship between the type of user who transmitted the
information and the number of RTs. The question of who
transmitted the information is important to the users who
receive that information. RT is an original feature in Twitter
in which other tweets are quoted. It is possible to under-
stand the number of RTs in terms of the volume of com-
munication. Furthermore, to analyze whether the volume of
RTs is high or low from tweet information alone, it is nec-
essary to compare the users who transmit the information
with the same intensity. For this reason, tweets for our
research were chosen from users with a large number of
followers and who were thought to have strong communi-
cability. We believe that clarifying the differences between
more retweeted and less retweeted tweets is important
because the former have greater influence, and investigat-
ing which characteristics of tweets affect the likeliness of
being retweeted is an important research question for text
analysis studies and the social sciences. Several researchers
have focused on information propagation or information
spreading (Boyd, Golder, & Lotan, 2010; Hong, Dan,
& Davison, 2011), but previous studies have targeted
tweets in English. According to a survey by Semiocast,1
Japanese is the second most frequently used language after
English. Thus, in this research we focus on Japanese
tweets.
In this research, we conducted tweet classification experi-
ments using random forests machine learning that focuses
on the number of RTs and user types. In consideration of the
differences in communication depending on the account,
tweets were collected after establishing four user types. User
types were employed as information transmitter type classes
and classification experiment classes. In addition, using the
number of RTs as a standard, the data were divided in
advance into levels of RT usage, which were used as
RT-number classes. Furthermore, we extracted features
based on the importance of the experimental results. For the
features, we used (a) the relative frequency of the function
words, (b) the rate of occurrence of parts of speech, (c) the
relative frequency of Twitter’s descriptive grammar and uni-
versal resource locators (URLs), and (d) the rate of tweet
information roles. Textual characteristics, such as (a) rela-
tive frequency of function words and (b) rate of occurrence
of parts of speech, were used in existing stylistic text clas-
sification studies (Stamatatos, 2007; Suzuki, Kawamura,
Yoshikane, Kageura, & Aizawa, 2012). This research pro-
poses to add new Twitter-specific features, such as (c) the
relative frequency of Twitter’s descriptive grammar and
URLs and (d) the rate of tweet information roles, to the more
conventional stylistic features.
The objective of this study is to clarify the features that
are important for distinguishing tweets by user types and
number of RTs. In this way, the study provides basic empiri-
cal knowledge to aid our understanding of information
propagation in Japanese tweets, and this information is
useful for further developing automated tweet-filtering
methods.
Related Work
Along with advances in computational linguistics,
computational stylistics has expanded in scope. Useful sty-
listic features such as the relative frequencies of function
words and the rate of each part of speech have been the
subject of discovery attempts by researchers. Stamatatos
(2007) systematically surveyed the methods and features
used in authorship attribution, an important subfield
of computational stylistics. In this article, we use
Twitter’s descriptive grammar (RT, etc.) and tweet infor-
mation roles as features in addition to conventional
stylistic features.
With the growth in the number of Twitter users, a great
deal of attention has focused on filtering information to find
specific tweets and users to use the information on Twitter.
Some researchers have analyzed specific topics (Naaman,
Becker, & Gravano, 2011; Thelwall, Buckley, & Paltoglou,
2011) to detect the new trend-setter transmitters on Twitter
(Shirakihara, Oishi, Hasegawa, Fujita, & Koshimura, 2010),
to study the use of positional information systems for tweet
1semiocast.com/downloads/Semiocast_Half_of_messages_on_Twitter
_are_not_in_English_20100224_ja.pdf
2 JOURNAL OF THE ASSOCIATION FOR INFORMATION SCIENCE AND TECHNOLOGY—•• 2014
DOI: 10.1002/asi
information (Arakawa, Tagashira, & Fukuda, 2010), and to
provide automatic summaries of tweets (Takamura, Yokono,
& Okumura, 2010). With regard to RTs, researchers have
made basic observations of tweets, and, by dialoging with
the authors’ own followers, have clarified the reasons why
people use RTs (Boyd et al., 2010). Other research focused
on predicting the number of RTs and the features used for
prediction (Hong et al., 2011). Hong et al. (2011) performed
classification experiments concerning the existence of RTs
and the prediction of RT numbers using large volumes of
tweets with the aim of searching for features included in
tweets that can easily be forwarded using RT. Since user
characteristics were not included in the features, this
research summarizes user types as those with similar user
characteristics, targeting users with a comparatively high
number of followers. In Hong et al. (2011), many content-
based features are shown to perform well in RT number
classification, but our research focuses on styles of the tweet
texts, and we used stylistic features for classification instead.
In addition to conventional stylistic features, we added
Twitter-specific grammar and manually assigned informa-
tion role tags, which we believe are important features in the
analysis of Twitter.
Experimental Setup
Machine Learning Methods
We conducted experiments that made classifications
based on the number of RTs and user types. The random
forests machine learning method (Breiman, 2001) was
adopted as the classifier in the experiments. The random
forests machine learning method is a type of machine learn-
ing that uses a decision tree. This method has the benefit of
being able to operate validly even if the data have missing
values. In addition, the method is known to be robust to
overfitting and suits our experiments; the data set used for
training models is small compared to the much larger size of
the features, and the model seemed likely to overfit the data
if other methods had been used. The random forests machine
learning method can estimate the importance of variables for
classification and filter the features that have an effect on
classification. Strong performance in classifying Japanese
texts has been demonstrated by previous research (Jin &
Murakami, 2007).
The algorithm is shown below. First, we created the
feature quantity from the i column and the j row and repro-
duced that column (text) allowing duplication from that line.
We then sampled the variables, creating 1,000 bootstrap
samples. Using the sampled variables, the decision tree was
developed by voting and it was used for classification. A
classifier was created from two thirds of the created samples
as learning data, and the remaining third was used as evalu-
ation data. This is called an out-of-bag (OOB) test, and a third
of the data used for evaluation are referred to as OOB data.
Further, the importance of the variables used for classi-
fication was calculated as follows (Breiman, 2001):
VI
mean C C
s e
acu
oob per=
−( )
. .
Coob refers to the correct answers in the OOB data, Cper is the
correct answers when randomly replacing the OOB data
variable m, and s.e. is the standard error. VIacu shows how the
sense of class is lost when variable m is replaced by other
variables. We can say that the higher these figures are, the
more impact the variable has on classification (Jin &
Murakami, 2007; Suzuki, 2009).
Features
The four features used in the classification experiments
were (1) the relative frequency of function words (non-
independent nouns, conjunctions, pre-noun adjectives,
postpositional particles, and auxiliary verbs); (2) the rate of
part-of-speech (nouns, verbs, adverbs, adjectives, prefixes,
interjections, conjunctions, determiner, particles, and auxil-
iary verbs), signs, and others; (3) the relative frequency of
tweets that included Twitter’s descriptive grammar (RT, @,
and #) and URLs; and (4) the ratio of tweet information roles
(monologues, advertisements, informational, and talk).
For Features (1) and (2), after deleting the Twitter origi-
nal declarations, such as RTs, hash tags, and URLs from the
main text of the tweet, we conducted a morphological analy-
sis with MeCab.2 Features (1) and (2) were filtered using the
part-of-speech tags. When posting on Twitter, there is a
restriction of 140 characters per tweet. For this reason, there
are several types of abbreviations in Twitter’s descriptive
grammar. In this research, for Feature (3), we measured the
relative frequency for the use of RT (including QTs), #, and
@. In addition, we measured the quantity of links, consid-
ering their existence to be important from the point of view
of the communicability of information. Feature (4) involved
manually assigned information roles. We established the
following four information categories: (a) tweets that were
conversations between users were classified as “talk”; (b)
tweets that included information considered to be beneficial
for sender (or the sender’s company) were classified as
“advertisement”; (c) tweets sent for the purpose of notifying
a wide range of people, regardless of the benefit, were cat-
egorized as “informational”; and (d) other unclassifiable
tweets were labeled “monologues.” These information role
tags were assigned manually by the first author to half the
tweets,3 and the relative frequency of the measured tags in
the tweet texts was used as a feature.
Evaluation
For the evaluation of the classification experiments, pre-
cision (Pi), recall rates (RRi), and F1 values are used. The F1
2http://mecab.sourceforge.net
3In order to facilitate manual classification.
JOURNAL OF THE ASSOCIATION FOR INFORMATION SCIENCE AND TECHNOLOGY—•• 2014 3
DOI: 10.1002/asi
value is the harmonic mean between precision and recall
rates. The formulae are defined as follows (Takamura, 2010;
Tokunaga, 1999):
P
a
a b
i
i
i i
=
+
RR
a
a c
i
i
i i
=
+
F
P R
P R
β
β
β
=
+( ) × ×
× +
2
2
1
where the values for ai, bi, and ci are calculated according to
the contingency table in Table 1.
Experimental Design
For the classification classes used in these experiments,
classes based on the number of RTs (two classes), user types
classes (four classes), and classes based on the number of RTs
and user types classes (eight classes) were used (Table 2):
Exp1: Experiments using all features for classes based on the
number of RTs.
Exp2: Experiments using all features for user type classes.
Exp3: Experiments using all features for classes based on the
number of RTs and user type classes.
Exp4: Experiments using function words as features for classes
based on the number of RTs.
Exp5: Experiments using function words as features for user
type classes.
Exp6: Experiments using function words as features for classes
based on the number of RTs and user type classes.
Exp7: Experiments using information roles as features for
classes based on the number of RTs.
Exp8: Experiments using information roles as features for user
type classes.
Exp9: Experiments using information roles as features for
classes based on the number of RTs and user type classes.
Exp10: Experiments using Twitter signs and information roles
as features for classes based on the number of RTs.
Exp11: Experiments using Twitter signs and information roles
as features for user type classes.
Exp12: Experiments using Twitter signs and information roles
as features for classes based on the number of RTs and user type
classes.
Exp13: Experiments using Twitter signs as features for classes
based on the number of RTs.
Exp14: Experiments using Twitter signs as features for user
type classes.
Exp15: Experiments using Twitter signs as features for classes
based on the number of RTs and user type classes.
In Exps. 1 through 3, we made a comprehensive assess-
ment of which features influenced classification. Exps. 4
through 6 involved classification experiments using conven-
tional stylistic features, whereas Exps. 7 through 15 used
classification roles and Twitter-specific signs. After compar-
ing the results of the experiments using different feature
sets, we observed how classification results could change
according to differences in the features and assessed the
features powerful for classification.
Data
To create the data, we used the Twitter application pro-
gramming interface (API) to capture 28,756 tweets from
40 accounts as of September 7, 2011. The target accounts
(averaging 718.9 tweets per account) were filtered according
to the user types in Twinavi4 and ranked by the number
of followers. There were four categories, namely, “enter-
tainers” (comedians, “idols,” actors, and sportsmen),
“names” (politicians, authors, cultural icons, intelligentsia,
entrepreneurs, and comic book writers), “characters,” and
“organizations” (enterprises, local government, and other
governments). We chose a total of 40 accounts with a
high number of followers: 10 in each category. We obtained
the number of RTs using Twitter API. We calculated the
median number of RTs, and regarded tweets with more than
the median number of RTs as high RT tweets, and those with
less than the median number of RTs as low RT tweets.
Therefore, we made two classes for classification experi-
ments for each account. In sum, classification experiments
were conducted using these 80 tweet texts.
Results and Discussion
Basic Observations
Results on basic data (Table 3) show the respective
summary statistics in terms of the number of followers and
the number of tweets for each user type. The indexes are the
median value, the standard deviation (SD), and the coeffi-
cient of variation (CV). The CV is the SD divided by the
average. This index is the one standard for checking
variability in the data. The variability was highest in the
character category for the number of followers, and in the
entertainer category for the number of tweets.
Results on rate of part-of-speech (Table 4) lists the rate of
the parts of speech in the user types and RT number groups.
As an overall trend, nouns have the highest rate, followed by
particles and signs. When looking at the CV, the “etc.” value
is highest at 1.22, followed by interjections at 0.56. From this
4Japanese Twitter Navigation Site: http://twinavi.jp/
TABLE 1. Contingency table for evaluation.
Results
True False
actual class True ai ci
False bi di
4 JOURNAL OF THE ASSOCIATION FOR INFORMATION SCIENCE AND TECHNOLOGY—•• 2014
DOI: 10.1002/asi
we can see that rates including “etc.” have a high value. For
this reason, we deduced that it was composed of a different
part of speech than were the other categories. Other rates were
low, most of the values were 0, and it is thought that this had
an effect on the CV. The lowest CV was significant at 0.10.
Among the user types, the organization category dis-
played the most notable results. The organization category
had the highest rate of nouns among the user types, exceed-
ing 50%. Verbs and adverbs, on the other hand, had a low
rate when compared with the other categories. Accounts
included in the organization category had a high number of
tweets where the objective was to transmit information.
When information is transmitted using Twitter, an important
consideration is how accurately information can be trans-
mitted using only 140 characters. It is surmised that this
may be the reason that tweets in the information category
exhibit a different structure of speech parts than other
categories.
Measuring Twitter’s descriptive grammar and links
(Table 5) shows the relative frequency of descriptive
grammar and URLs in tweets as a percentage. In general
terms, a large difference was seen for the @ sign in catego-
ries with more or less numbers of RTs. The reason for this is
thought to be that, due to the design of Twitter, conversa-
tional tweets are not registered on the timelines.
When looking at the characteristics of the user types, we
can see that there are many hash tags and URLs in the
organizations category. In addition, in the two categories in
which people are tweeting entertainers and names, a major
disparity was seen in terms of whether there were URLs.
There were more links in the tweets in the entertainer cat-
egory than in the prominent figures category. There was a
particularly notable difference in the groups with more RT
numbers, with 26.92% in the entertainers category more RTs
group, and 0.33% in the prominent figures category more
RTs group. For the entertainer category, it is considered that
this result has been notably influenced by the fact that the
destinations of the URLs included in the tweets of certain
“idols” are links to upload their own pictures.
Results on informational role (Table 6) show the relative
frequency of information roles in tweets. The averages for
each information role are 40.64% for monologue, 16.75%
for advertisement, 3.56% for informational, and 39.05% for
talk. Regardless of the user type, for talk, the rate of the
group with less numbers of RTs is higher. The cause of this
is thought to be that, in the case of the person tweeting @, or
the addressee of the @, or accounts following both talking
parties, these tweets are not displayed on the timeline. This
is not the case for conversations using RT. As a result, a
certain amount of talk can be observed in the case of the
group with more RTs.
Variability is most prominent in the case of informa-
tional, which has a CV of 1.13. Conversely, advertisement
has the smallest value at 0.30. Informational is a distinctive
information role for the organization category. Compared
with other user types, the rate for informational is notably
high, and it is predicted that this may affect the CV value.
Results of the Classification Experiments
Experimental performance (Table 7) shows the results of
the classification experiments based on random forests.
Among the classification classes, the classifications in user
types showed the highest values. When comparing by fea-
tures in the user type classes, Exp2, which used all the types
of features, gave the best performance. Looking at the
results by classification class, for the experiments using RT
number classification classes (G1), Exp4, which used func-
tion words as features, and Exp7, which used information
roles as features, both showed higher values than Exp1,
which used all features. In particular, Exp7 used four infor-
mation roles as features, and it is estimated that the infor-
mation roles strongly influenced the classifications based on
the number of RTs. The results in group G1 seem to conflict
with the common sense of machine learning results, in that
Exp1, using all the features, does not have the best perfor-
mance. The reason for this is that in G1 classification that
aims to classify high and low RT classes, features except
information roles can be noises for classification. The reason
Exp4 and 10 perform worse than Exp7 is the same. As
opposed to that, in user type classification experiments (G2),
Exp2 using all the features displayed the best performance,
and Exp5 using function words as features displayed the
second best performance. Classification experiments that
TABLE 2. Experimental outline.
All
Function
words Information roles
Twitter-specific grammar +
information roles
Twitter-specific
grammar
RT (G1) Exp1 Exp4 Exp7 Exp10 Exp13
user types (G2) Exp2 Exp5 Exp8 Exp11 Exp14
RT + user types (G3) Exp3 Exp6 Exp9 Exp12 Exp15
TABLE 3. Basic data (amounts about followers and tweets).
Followers Tweets
Median SD CV Median SD CV
entertainer 495,167 101,993.79 1.38 788 132.45 1.69
name 419,840 299,239.79 1.37 711 229.34 1.18
organization 464,123 134,564.87 1.25 790 50.70 1.20
character 170,015 256,785.34 1.69 799 13.08 1.36
JOURNAL OF THE ASSOCIATION FOR INFORMATION SCIENCE AND TECHNOLOGY—•• 2014 5
DOI: 10.1002/asi
considered both the number of RTs and the user types (G3)
could not achieve very high performance for classification.
From this we can see that a variety of features in the user
type classification classes and the function words and infor-
mation roles in the RT-number classification classes have a
major impact on the classification results.
Variable importance (Table 8) shows the 20 most impor-
tant features for each experiment obtained from Exp1
through Exp3 in which classification was performed using
all the features. “No.” refers to the number of the features
described in Chapter 3. Of the top 20 features in Exp1, based
on RT-number classes, 18 were function words. At the top,
we can see interjections and talk. For the rate of part of
speech in interjections, the group with less RTs tended to be
high and the group with more RTs was low, which was
thought to influence classification. The second most impor-
tant was conversation. Because conversations using @ are
basically displayed on the timeline between talkers through
a Twitter function, this feature is thought to strongly influ-
ence the class with less RTs. When looking at the function
words individually, these included words often used to
describe the reasons for speech and summarization, such as
“beki,” “tsumari,” and “ni atatte.” In Exp2, which uses user
type classes, we can see a wide variety of features compared
to Exp1 (function words = 12, speech parts = 3, signs = 2,
and information roles = 2). Monologue, which is the most
important class, had the highest rate in the three categories
other than the organization category and might have influ-
enced classification. From the basic observation conducted
TABLE 4. Relative frequency of appearance for different speech parts (%).
Particle Auxiliary verb Noun Verb Adverb Adjective
entertainer / more 19.39 8.54 39.18 11.01 1.77 1.82
entertainer / less 17.24 9.16 37.47 10.58 1.77 1.92
name / more 22.43 8.80 37.20 10.62 1.58 1.17
name / less 19.50 10.42 35.59 10.08 1.89 1.36
organization / more 17.30 4.10 53.26 5.80 0.59 0.75
organization / less 16.84 5.04 51.52 5.87 0.82 0.83
character / more 22.20 7.62 33.06 11.69 1.69 1.71
character / less 21.47 7.24 33.80 11.48 1.64 1.50
mean 19.54 7.61 40.13 9.64 1.47 1.38
SD 2.29 2.13 7.83 2.40 0.49 0.44
CV 0.12 0.28 0.20 0.25 0.33 0.32
Prefix Interjection Conjunction etc. Determiner Sign
entertainer / more 0.80 0.81 0.34 0.02 0.33 15.99
entertainer / less 1.06 1.43 0.42 0.01 0.31 18.62
name / more 0.81 0.51 0.32 0.00 0.48 16.09
name / less 1.03 1.09 0.24 0.00 0.45 18.37
organization / more 1.00 0.14 0.12 0.00 0.25 16.69
organization / less 1.16 0.37 0.13 0.00 0.20 17.21
character / more 0.40 0.70 0.42 0.00 0.59 19.92
character / less 0.46 0.82 0.35 0.01 0.55 20.69
mean 0.84 0.73 0.29 0.01 0.40 17.95
SD 0.28 0.41 0.12 0.01 0.14 1.75
CV 0.33 0.56 0.40 1.22 0.36 0.10
TABLE 5. Relative frequency of specific descriptive grammar in Twitter
and URL (%).
RT # http @
entertainer / more 24.54 5.07 26.92 52.55
entertainer / less 30.81 7.61 19.72 88.56
name / more 30.43 7.80 0.33 46.05
name / less 43.21 5.65 19.20 95.61
organization / more 2.30 51.89 87.61 8.63
organization / less 0.86 57.82 78.25 18.14
character / more 0.17 9.45 28.41 2.59
character / less 0.37 10.49 31.46 18.54
mean 16.59 19.47 36.49 41.33
SD 17.52 21.97 30.30 35.76
CV 1.06 1.13 0.83 0.87
TABLE 6. Relative frequency of informational role (%).
Monologue Advertisement Informational Talk
entertainer / more 56.36 16.78 1.85 25.01
entertainer / less 30.83 11.83 0.88 56.46
name / more 46.37 23.76 9.54 20.33
name / less 28.99 14.64 1.97 54.40
organization / more 1.93 20.84 72.13 5.10
organization / less 2.33 20.95 62.15 14.57
character / more 87.94 3.56 6.15 2.34
character / less 69.56 4.33 8.09 18.02
mean 40.64 16.75 3.56 39.05
SD 13.06 5.09 4.01 19.03
CV 0.32 0.30 1.13 0.49
6 JOURNAL OF THE ASSOCIATION FOR INFORMATION SCIENCE AND TECHNOLOGY—•• 2014
DOI: 10.1002/asi
in the previous section, there was a difference between the
organization category and other categories in terms of fea-
tures such as URLs (which start with “http”), informational,
and verbs. In the organization category, informational and
advertisements were often tweeted intentionally, and this is
a category where the issue is how well information can be
communicated with the small number of 140 characters. As
a result, in the case of news tweets, there are many assertions
and it is estimated that the fact that the rate of verb speech
parts is low compared to that of other categories, those have
an effect on classification. When focusing on the individual
features, it was observed that polite terms such as “desu” and
“masu” are used and many function words are included.
The polite terms “desu” and “masu” were observed to be
included very regularly as function words in all of the
accounts. As the selected accounts on this occasion have a
high number of followers, it is surmised that tweets are an
expression of the intention to tweet to a large number of
people. For Exp3, the first to the fourth were the same
features as selected for Exp2. It is considered that they
were heavily influenced by the characteristics of the user
types.
Conclusion
In this research, we conducted 15 types of classification
experiments using a variety of combinations of features;
function words, speech terms, Twitter’s descriptive
grammar, and information roles. We systematically
observed the effects of features for classification perfor-
mance. The results showed that class classification by user
type indicated the best performance. We discovered that
information roles and function words are important features
in the RT-number classes and a number of features are
important in user types. We also observed that the most
important were “talk” as an information role in the RT class
classification and function words used to summarize text
and state opinions, such as the function words “tsumari” and
“beki.” In the user type class classification, the “informa-
tional” information role and function words used in polite
language, such as “desu” or “masu,” were features that have
a major influence on classification. Future issues include
finding methods to increase performance in classification
and generalization of the research. The best results were
achieved by classification experiments related to user types,
and for experiments related to the number of RTs, only
the classes classified by the RT number gave the best results.
TABLE 7. Experimental results.
Precision Recall rates F1
Exp1 43.79 43.84 43.75
Exp2 83.46 83.40 83.32
Exp3 18.05 18.96 –
Exp4 44.92 44.95 44.88
Exp5 81.05 80.81 80.69
Exp6 15.40 15.43 –
Exp7 49.75 49.75 49.74
Exp8 60.15 59.94 59.98
Exp9 30.35 30.40 –
Exp10 40.38 40.40 40.38
Exp11 63.39 64.48 62.85
Exp12 18.24 19.80 –
Exp13 38.93 38.95 38.93
Exp14 59.52 59.11 59.11
Exp15 16.61 18.05 –
TABLE 8. Variable importance in experiments (top20).
Exp1 Exp2 Exp3
No VIacu No VIacu No VIacu
1 interjection (2) 0.001749 monologue (4) 0.016969 monologue (4) 0.006414
2 talk (4) 0.001742 desu (be, polite) (1) 0.015249 desu (be, polite) (1) 0.004651
3 zu (not) (1) 0.001643 http (3) 0.011861 http (3) 0.003484
4 shika (only) (1) 0.001568 informational (4) 0.009642 informational (4) 0.003406
5 toiu (purport) (1) 0.001393 toki (when) (1) 0.009423 talk (4) 0.002982
6 sae (even) (1) 0.000895 adjunct (2) 0.009378 toki (when) (1) 0.002769
7 ga (–, subjective) (1) 0.000794 verb (2) 0.008418 adverb (2) 0.002639
8 beki (should) (1) 0.000582 deshi (be, polite) (1) 0.008213 wo (–, objective) (1) 0.002518
9 tsumari(namely) (1) 0.000568 da (be) (1) 0.007948 @ (3) 0.002364
10 desho (don’t you) (1) 0.000565 kedo (but) (1) 0.007483 deshi (be, polite) (1) 0.002208
11 ni atatte (in) (1) 0.000535 masu (–, polite) (1) 0.007245 da (be) (1) 0.002136
12 ki (–) (1) 0.000458 yo (–) (1) 0.007211 yo (–) (1) 0.002081
13 aitsu (that guy) (1) 0.000457 nai (not) (1) 0.007016 tai (want) (1) 0.00205
14 nee (–, chatty) (1) 0.000383 cha (–) (1) 0.006552 masu (–, polite) (1) 0.002047
15 tame (to) (1) 0.000327 @ (3) 0.006418 toiu (purport) (1) 0.002021
16 are (that) (1) 0.000314 mashi (–, polite) (1) 0.006383 verb (2) 0.001935
17 nioite (according to) (1) 0.000308 talk (4) 0.006108 kedo (but) (1) 0.001933
18 ookina (big) (1) 0.000307 tai (want) (1) 0.005848 advertisement (4) 0.00192
19 fuu (likely) (1) 0.0003 tte (–, chatty) (1) 0.005637 no (of) (1) 0.001888
20 sosite (and) (1) 0.000284 noun (2) 0.005572 nai (not) (1) 0.001757
JOURNAL OF THE ASSOCIATION FOR INFORMATION SCIENCE AND TECHNOLOGY—•• 2014 7
DOI: 10.1002/asi
However, because there are differences in posted tweets
depending on the user type, filtering information merely by
the number of RTs might not be sufficient. Based on the
results of these experiments, we will search for features to
use and ways of using them in experiments and strive to
improve classification performance with the aim of propos-
ing an effective method of information filtering for Twitter
users. As this is a preliminary study of the information roles
of tweets, we manually assigned four labels to each tweet.
Our results indicated that information roles are very impor-
tant in relation to the types and number of RTs. Furthermore,
we would like to develop automated methods to assign
labels for information roles to tweets by using, for example,
semisupervised machine learning methods in the future.
With regard to the generalization of the research, we will in
the future include properties of the accounts used in the data
and the reactions of the receiving party.
Acknowledgments
This study was supported by Grant-in-Aid for Scientific
Research 23700288 for Young Scientists (B), from the Min-
istry of Education, Culture, Sports, Science and Technology,
Japan, and Grant for joint research from National Institute of
Informatics. This research includes revised and expanded
content based on the graduation thesis presented by
Arakawa Yui to the Faculty of Sociology, Toyo University.
Earlier versions of this study were presented at the 74th
National Convention of the Information Processing Society
of Japan and JADH2012, and the 2nd conference of the
Japanese Association for Digital Humanities. We thank the
participants for useful comments.
References
Arakawa, Y., Tagashira, S., & Fukuda, A. (2010). Relational analysis
between user context and input word on Twitter. IPSJ SIG Technical
Reports, 2010-MBL-53(50), 1–7.
Boyd, D., Golder, S., & Lotan, G. (2010). Tweet, tweet, retweet: Conver-
sational aspects of retweeting on Twitter. In Proceedings of the 43rd
Hawaii International Conference on Social Systems (HICSS), 1–10. CA:
IEEE Computer Society.
Breiman, L. (2001). Random forests. Machine Learning, 45(1), 5–23.
Hong, L., Dan, O., & Davison, B.D. (2011). Predicting popular messages in
Twitter. In 20th International World Wide Web Conference
(WWW2011), Hyderabad, India.
Jin, M., & Murakami, M. (2007). Authorship identification using random
forests. Proceedings of Institute of Statistical Mathematics, 55(2), 255–
268.
Naaman, M., Becker, H., & Gravano, L. (2011). Hip and trendy: Charac-
terizing emerging trends on twitter. Journal of the American Society for
Information Science and Technology, 62(5), 902–918.
Ogiue, C. (2011). Kensho Higashi Nihon Daisinnsai no Ryugen / Dema
[Research: False and groundless rumors after Japan Earthquake]. Tokyo:
Kobunsha.
Shirakihara, W., Oishi, T., Hasegawa, R., Fujita, H., & Koshimura, M.
(2010). Trendspotter detection system for Twitter. IPSJ SIG Notes, 2010-
DBS-150(2), 1–8.
Stamatatos, E. (2007). A survey of modern authorship attribution methods.
Journal of the American Society of Information Science and Technology,
60(3), 538–556.
Suzuki, T. (2009). Extracting speaker-specific functional expressions from
political speeches using random forests in order to investigate speakers’
political styles. Journal of the American Society for Information Science
and Technology, 60(8), 1596–1606.
Suzuki, T., Kawamura, S., Yoshikane, F., Kageura, K., & Aizawa, A.
(2012). Co-occurrence-based indicators for authorship analysis. Literary
& Linguistic Computing, 27(2), 197–214.
Takamura, H. (2010). Gengo Shori no tame no Kikai Gakushu Nyumon
[Introduction to machine learning for language processing]. Tokyo:
Corona-sha.
Takamura, H., Yokono, H., & Okumura, M. (2010). Summarizing microb-
log stream, Paper Presented at 22nd Semantic Web and Ontology
Research Group, Tokyo. Retrieved from http://sigswo.org/papers/SIG-
SWO-A1001/SIG-SWO-A1001-03.pdf
Tachiiri, K. (2011). Kensho Higashinihon Daisinsai: Sono Toki Social
Media wa Nani wo Tutae ta ka? [Examining the Great East Japan Earth-
quake: What did social media transmit at that time?]. Tokyo: Discover21.
Thelwall, M., Buckley, K., & Paltoglou, G. (2011). Sentiment in Twitter
events. Journal of the American Society for Information Science and
Technology, 62(2), 406–418.
Tokunaga, T. (1999). Jouhou Kensaku to Gengo Shori [Information
retrieval and language processing]. Tokyo: University of Tokyo Press.
8 JOURNAL OF THE ASSOCIATION FOR INFORMATION SCIENCE AND TECHNOLOGY—•• 2014
DOI: 10.1002/asi
