Digital Signal Processing 22 (2012) 726–733Contents lists available at SciVerse ScienceDirect
Digital Signal Processing
www.elsevier.com/locate/dsp
Efficient illumination compensation techniques for text images
Kuo-Nan Chen a, Chin-Hao Chen b, Chin-Chen Chang a,b,c,∗
a Department of Computer Science and Information Engineering, National Chung Cheng University, Chiayi 62102, Taiwan, ROC
b Department of Information Engineering and Computer Science, Feng Chia University, Taichung 40724, Taiwan, ROC
c Department of Computer Science & Information Engineering, Asia University, Taichung 41354, Taiwan, ROC
a r t i c l e i n f o a b s t r a c t
Article history:
Available online 17 April 2012
Keywords:
Text recognition
Uneven illumination
Camera
Illumination compensation
With the great advantages of digitization, more and more documents are being transformed into digital
representations. Most content digitization of documents is performed by scanners or digital cameras.
However, the transformation might degrade the image quality caused by lighting variations, i.e. uneven
illumination distribution. In this paper we describe a new approach for text images to compensate
uneven illumination distribution with a high degree of text recognition. Our proposed scheme is
implemented by enhancing the contrast of the scanned documents, and then generating an edge map
from the contrast-enhanced image for locating text area. With the information of the text location,
a light distribution image (background) is created to assist the producing of the final light balanced
image. Simulation results demonstrate that our approach is superior to the previous works of Hsia et al.
(2005, 2006).
© 2012 Elsevier Inc. All rights reserved.1. Introduction
Digitization of documents is the process that transforms mate-
rial into its digital form using digital cameras or scanners. Devel-
oped countries digitize important documents in order to preserve
cultures, artistry, and histories; these processes are known as dig-
ital archives. In this way, digitized documents can be preserved
forever and also exhibited conveniently via the Internet. With
more valuable documents being digitized for preservation, light-
balance techniques in imaging processing have become a serious
concern. The uneven illumination distribution of digitized docu-
ments results from an incomplete contact plane between material
and scanner or from uneven lighting conditions during the photo-
copying process. The shadow caused by uneven illumination distri-
bution degrades the visual quality of the text image and makes it
difficult to recognize the content, as shown in Fig. 1. Document un-
derstanding methods, such as optical character recognition, might
be applied to solve this problem, but its requirement of semantic
content preservation narrows down its applications.
Some studies have been proposed to deal with the uneven il-
lumination distribution problem [2,3,5,9–11,13–16]. In image bi-
narization, researchers found that adaptive thresholding methods
outperform global thresholding ones due to lighting variation. In
* Corresponding author at: Department of Information Engineering and Computer
Science, Feng Chia University, No. 100, Wenhwa Rd., Seatwen, Taichung 40724, Tai-
wan, ROC. Fax: +886 4 27066495.
E-mail addresses: kuonan.chen@gmail.com (K.-N. Chen),
unknown_0521@hotmail.com (C.-H. Chen), alan3c@gmail.com, ccc@cs.ccu.edu.tw
(C.-C. Chang).1051-2004/$ – see front matter © 2012 Elsevier Inc. All rights reserved.
http://dx.doi.org/10.1016/j.dsp.2012.04.010Fig. 1. A scanned text image with uneven illumination distribution.
2000, Sauvola and Pietikäinen proposed a thresholding method
[13] in which a hybrid switching was used to classify a scanned
image into textual and non-textual regions at first and apply his-
togram based and soft decision based methods to these textual and
non-textual components, respectively. For text binarization, the au-
thors applied an adaptive thresholding method which is a modified
version of Niblack’s algorithm [12]. In 2001, Seeger and Dance
[14] presented a background surface thresholding (BST) method.
BST first generates two intermediate images, i.e. block average and
block variance images, and then produces a block average image
with high variance areas removed to complete text labeling. Then,
a continuous background image is created by estimating text areas
using interpolating. Afterwards, a binarization image is generated
according to the background image by thresholding. The advantage
of BST is that it uses adaptive window sizes during text labeling.
However, the determination of window size is related to the font
K.-N. Chen et al. / Digital Signal Processing 22 (2012) 726–733 727size and character stroke width. The authors have not mentioned
how to deal with a text image with different font sizes and char-
acter stroke widths. In 2005, Hsia and Tsai proposed an efficient
light balancing technique (ELBT) [3] for text images. The main
idea of ELBT is to separate the text part from the background
area using block-based processing. Whether a block belongs to a
content block or to a background block is determined by com-
puting the block mean variance (BMV). The BMV of a content
block is higher than that of a background block. After the text
part has been located, new values are substituted for the text pix-
els by applying linear interpolation to obtain a background-like
image. Referring to the background-like image, an adaptive gain
control technique is employed to achieve a light balanced text im-
age.
After that, in 2006, Hsia et al. proposed a line-based light-
balancing technique (LLBT) [2]. Unlike the block-based ELBT, LLBT
generates the background-like image using lines. First, each hor-
izontal line is split into sections. Then, LLBT finds the section
level by computing the average value of maximum M pixels in
each section. Next, the background-like image can be obtained by
adapting interpolation in terms of these section levels. Finally, the
light balanced text image is achieved according to the background-
like image by employing the adaptive gain control technique in
LLBT.
However, most of previous works completed mission by the
raw data, i.e. the original scanned files. The threshold determina-
tion or object and non-object classification might not work well
while the textural pixels were very close to the background pix-
els. In this paper, we propose an efficient edge-based light bal-
ancing scheme (ELBS) for text images. ELBS contains five phases:
(1) contrast enhancement phase; (2) edge detection phase; (3) text
locating phase; (4) light distribution phase; and (5) light balanc-
ing phase. The processes of ELBS are illustrated as follows. The
contrast of the original text image is enhanced first. The Sobel
technique [4,6] is adapted to generate the edge image from the
original text image in order to indicate the text part roughly. The
text part can be located more precisely by merging the contrast
enhanced and the edge-detected results. The located text pixels
are replaced with new values by interpolation according to the
background part; this generates the light distribution image. Fi-
nally, the light balanced image is constructed in terms of the
contrast enhanced and light distribution images. The simulation re-
sults show that ELBS outperforms ELBT and LLBT for text images.
Our approach not only balances the illumination distribution well
but also maintains high visual quality. The details of the proposed
scheme are illustrated in Section 2, followed by simulation results
in Section 3. Finally, conclusions and further works are stated in
Section 4.
2. The proposed scheme
The goals of our proposed scheme are to balance uneven light
distribution and to produce content with a high degree of recog-
nition. To achieve these goals, five phases are included in the
proposed scheme: contrast enhancement, edge detection, text lo-
cation, light distribution, and light balancing.
Contrast enhancement [1,7,8] is used to emphasize image char-
acteristics. The contrast of the text image is enhanced to obtain
the contrast enhanced image CEI in the first phase. In Phase 2, the
Sobel edge detection technique [6] is adapted to obtain an edge
image from the original text image. The edge image is then trans-
lated into binary edge image EIbin using a predefined threshold.
In Phase 3, CEI is translated into binary contrast-enhanced image
CEIbin , and the text location image TLI is generated according to
CEIbin and EIbin . In Phase 4, the light distribution image LDI is ob-
tained according to CEI and TLI. Finally, the light balanced imageFig. 2. The flowchart of the proposed scheme.
LBI can be constructed according to CEI, TLI, and LDI. The flowchart
of the proposed scheme is shown in Fig. 2.
2.1. Contrast enhancement phase
In the first phase, the contrast is enhanced to increase the lu-
minance difference between the text and background of the orig-
inal text image. Assume that the original gray-level text image
is denoted as I with h × w pixels. The contrast enhancement
procedure is described as follows, and the result is shown in
Fig. 3(b).
Step 1. Compute hpi of I , where hpi is the accumulation of pixels in
a histogram from gray-level i×10 to (i+1)×10 for i = 0,1, . . . ,25.
Step 2. Find the first i that hpi > 
√
h × w for i = 0,1, . . . ,25, and
then set hr = i × 10, where hr is the histogram reducing value of I .
Step 3. Enhance contrast of I to obtain the contrast enhanced im-
age CEI by the following formula:
CEI(pv j) =
(
I(pv j) − (hr + 50 × c)
) × 2, (1)
where pv j is the jth pixel in I for j = 1,2, . . . ,h × w , and c is
in the interval [0,1] used to further reduce image brightness, and
finally multiple a gain factor “2” to enhance image contrast. In un-
derflow and overflow cases, if CEI(pv j) < 0, then set CEI(pv j) = 0;
if CEI(pv j) > 255, then set CEI(pv j) = 255.
2.2. Edge detection phase
In the second phase, the Sobel edge detection technique is used
to produce an edge image that indicates the text part of the orig-
inal image. Four edge images are generated according to four dif-
ferent masks in order to detect different directions. The four masks
that used in Sobel edge detection are shown as follows:
728 K.-N. Chen et al. / Digital Signal Processing 22 (2012) 726–733−1 0 1
−2 0 2
−1 0 1
Mask (1). 0◦
−2 −1 0
−1 0 1
0 1 2
Mask (2). 45◦
−1 −2 −1
0 0 0
1 2 1
Mask (3). 90◦
0 1 2
−1 0 1
−2 −1 0
Mask (4). 135◦
After the four edge images are generated, the detection result is
constructed by computing the average result. The detection result
is translated into a binary image according to a predefined thresh-
old. The procedures are listed as follows, and the detection result
is shown in Fig. 3(c).
Step 1. Produce four edge images EI1, EI2, EI3, and EI4 according to
I by four Sobel edge masks with four different directions: 0◦ , 45◦ ,
90◦ , and 135◦ .
Step 2. Generate the average edge image EIavg by the following
formula:
EIavg = 1
4
4∑
n=1
h×w∑
i=1
(
EIn(pv j)
)
. (2)
Step 3. Produce the binary edge image EIbin of EIavg by the follow-
ing formula:
EIbin(pv j) =
{
0, if EIavg(pv j) < the,
255, if EIavg(pv j) the,
(3)
where the is a predefined threshold, i.e. the average value of
the two peak points in the histogram result of EIavg , and j =
1,2, . . . ,h × w .
2.3. Text location phase
To create the background-like image of the original text image,
the text must be located first. Once the text pixels are found, their
pixel values can be replaced with new ones using interpolation.
To locate the text pixels in I , images CEI and EIbin are used as
requirements. First, CEI is translated into its binary representation,
CEIbin , according to the predefined threshold thc . Next, CEIbin and
EIbin are merged to construct the text location image, TLI, according
to Eq. (5). Finally, we adopt the morphology erosion operation to
TLI according to the erosion mask, which is defined as follows:
1 1 1
1 1 1
1 1 1
Erosion Mask
The text location result is shown in Fig. 3(e), and the procedure
of text location phase is illustrated as follows.
Step 1. Produce CEIbin , the binary representation of CEI, by the fol-
lowing formula:
CEIbin(pv j) =
{
255, if CEI(pv j) < thc,
0, if CEI(pv j)  thc,
(4)
where thc is a predefined threshold generated by calculating the
average value of the two peak points in the histogram result of
CEI, and j = 0,1, . . . ,h × w . Fig. 3(d) shows the binary contrast-
enhanced image CEIbin .
Step 2. Merge EIbin with CEIbin to obtain the text location image TLI
by the following equation:Fig. 3. The gradual outcome.
TLI(pv j) =
{
0, if EIbin(pv j) = 255 or CEIbin(pv j) = 255,
255, otherwise,
(5)
where j = 0,1, . . . ,h × w .
Step 3. Adopt morphology erosion operation to TLI according to the
erosion mask.
2.4. Light distribution phase
There are three steps to obtain the background-like image, the
light distribution image of CEI, in the light distribution phase. The
first step is to determine the text pixels in CEI according to TLI.
K.-N. Chen et al. / Digital Signal Processing 22 (2012) 726–733 729A pixel in CEI is regarded as a text pixel if the corresponding pixel
value in TLI is 0; otherwise, it is treated as a background pixel.
Next, the values of the text pixels are replaced using interpolation.
The interpolated image II is generated as shown in Fig. 3(f). The
mean filter is then used to smooth the interpolated image in order
to produce the light distribution image LDI, as shown in Fig. 3(g).
The steps of this phase are outlined as follows:
Step 1. Search all pixels in TLI; if pixel value 0 is found in TLI,
then the corresponding pixel in CEI is regarded as a text pixel;
otherwise, it is treated as a background one.
Step 2. Find text sections in each pixel-column from left to right
in CEI. If a text section is found, then record the first and last pixel
locations as head and end, respectively. Note that a text section
means a vertical line with connected text pixels.
Step 3. Replace text pixel values in each text section to build the
interpolated image II by the following equation:
II(pvhead+m) = CEI(pvhead−1) +
mpvend − mpvhead
n
× (m + 1), (6)
where head and end are the location of the first and last pixel in
a text section, respectively, m means the mth pixel in the current
processing section for m = 0,1, . . . ,n−1, and n means the number
of pixels in the processing text section. In addition, mpvhead and
mpvend are defined as follows:
mpvhead = MAX
(
CEI(pvhead−k)
)
, for k = 0 to 4, (7)
mpvend = MAX
(
CEI(pvend+k)
)
, for k = 0 to 4. (8)
Step 4. Repeat Steps 1 and 2 until all text sections have been pro-
cessed.
Step 5. Adapt mean filter with 11 × 11 matrix to II for generating
light distribution image LDI.
2.5. Light balancing phase
The final result of the proposed scheme is generated in the light
balancing phase. The light balanced image LBI is constructed ac-
cording to images CEI, TLI, and LDI using the following equation:
LBI(pv j) =
⎧⎨
⎩
bl
LDI(pv j)
× CEI(pv j), if TLI(pv j) = 0,
bl×1.5
LDI(pv j)
× CEI(pv j), otherwise,
(9)
where bl is a luminance-level adjusting parameter, and j = 1,2,
. . . ,h × w . The result is shown in Fig. 3(h).
3. Simulation results
To demonstrate the performance of our proposed scheme,
scanned images are treated as test images for simulations in Sec-
tion 3.1. In Section 3.2, we create artificial scanned-liked images as
test images to show that the proposed scheme is suitable for var-
ious situations. Note that all sampling images are gray-level with
512 × 512 pixels and that the values of parameters the , thc , and
bl are set to be 30, 60, and 260, respectively. In Section 3.3, we
discuss how the parameters affect the simulation results. To show
the superiority of our scheme, it is compared with previous works
[2,3].Fig. 4. The simulation result with physical scanned image S1.
3.1. Simulations with scanned images
We utilized a digital scanner to sample all images from hard
copies. It is well known that an incomplete contact plane between
material and scanner leads to uneven light distribution of the
scanned image and reduces the visual quality. Fig. 4 gives an exam-
ple to show the performance of previous works and the proposed
scheme. Fig. 4(a) depicts scanned image S1, whose image quality is
damaged seriously. Figs. 4(b), (c), and (d) are the simulation results
of ELBT, LLBT, and the proposed scheme, respectively. It is obvious
that the proposed scheme has outstanding performance in both
light balancing and text recognition, especially by comparing the
marked parts where the image quality is damaged most seriously.
Furthermore, Fig. 5 presents three scanned images with dif-
ferent font sizes and light distribution directions. The simulation
results for ELBT are shown in Figs. 5(d) to (f); Figs. 5(g) through (i)
are the results of LLBT; Figs. 5(j) to (l) show the results of the pro-
posed scheme with c = 0.5. It is clear that our proposed scheme
outperforms both ELBT and LLBT in text recognition, especially in
the marked parts.
3.2. Simulations with artificial images
To show that the proposed scheme is suitable for various sit-
uations, we create artificial images with various uneven light dis-
tribution directions. Here, we utilize the peak signal-to-noise ra-
tio (PSNR) to measure the image quality. The equation of PSNR is
shown as follows:
PSNR = 10 × log10
2552
MSE
, (10)
where MSE (mean square error) is defined as
MSE =
(
1
h × w
) h×w∑
i=1
(
Xi − X ′i
)2
, (11)
and h and w are the height and width of the image, respectively;
Xi and X ′i are the original pixel value and processed pixel value,
respectively.
730 K.-N. Chen et al. / Digital Signal Processing 22 (2012) 726–733Fig. 5. The simulation results with physical scanned images S1 through S3.
Fig. 6 lists the artificial images (A1 through A6) used for the
simulations. Note that each was created by adding shadows to the
image translated from a word file, which has perfect light distribu-
tion. For example, Fig. 7(a) is the original text image of Fig. 6(a).
Fig. 7 shows that the proposed scheme outperforms ELBT and
LLBT in terms of image quality and text recognition. The original
text image of A1 is shown in Fig. 7(a). Its corresponding artifi-
cial image is shown in Fig. 7(b), whose PSNR value is less than
9 dB. Figs. 7(c) and (d) are the simulation results of ELBT and
LLBT, respectively. The simulation result of our proposed scheme is
shown in Fig. 7(e). First, the PSNR values are greater than 33.3 dB
using the proposed scheme and less than 24.1 dB with the pre-
vious works. Moreover, the proposed scheme is better than pre-
vious works in terms of text recognition, especially comparing
the marked parts where the image quality is damaged most se-
riously.
All of the artificial images with various shadow directions and
their simulation results are listed in Fig. 8. Images R1 through R6
are the simulation results of artificial images A1 through A6, re-
spectively. It can be observed that the proposed scheme is superior
for balancing uneven light distribution and improving the degree
of text recognition.
Table 1 compares the PSNR values of the proposed scheme with
those of previous works. It can be observed from Table 1 that the
proposed scheme outperforms previous works in all simulations.
Furthermore, all PSNR values of the simulation results are more
than 30.8 dB using the proposed scheme. On average, the proposedFig. 6. Artificial test images.
Fig. 7. Simulation results of artificial image A1.
scheme can improve the image quality by 38.37% compared with
ELBT and 40.42% compared with LLBT.
We created two artificial images whose quality is so damaged
that the text is difficult to be recognized. The original image is
K.-N. Chen et al. / Digital Signal Processing 22 (2012) 726–733 731Table 1
Comparisons for sampling images.
Schemes Sampling images (dB)
A1 A2 A3 A4 A5 A6 Average
Artificial image 8.31 7.76 9.23 8.86 9.16 8.59 8.65
ELBT [3] 22.80 22.53 21.12 24.09 24.79 24.18 23.25
LLBT [2] 22.07 22.24 20.69 24.09 24.60 23.78 22.91
Proposed scheme 33.96 31.82 31.70 33.31 30.81 31.47 32.17Fig. 8. The simulation results of all artificial images using our proposed scheme.
shown in Fig. 9. Fig. 10(a) is the first special artificial image (SA1),
whose PSNR value is 6.11 dB, and Figs. 10(b) to (f) show the grad-
ual outcome of our proposed scheme. The simulation results of
ELBT and LLBT are shown in Figs. 10(h) and (i), respectively. It can
be observed that the result of LLBT is slightly better than that of
ELBT, but it is still unsatisfactory. Fig. 10(g) shows the result of
the proposed scheme. The text recognition degree is much greater
than that with previous works.
Fig. 11 gives another example to show the performance of the
proposed scheme. The artificial image used here is SA2 (PSNR =
5.289 dB), which is shown in Fig. 11(a). As we can observe from
Fig. 11(b), the result is close to a blank image, and it show that
ELBT almost cannot work with SA2. The result is also unacceptable
for LLBT, as shown in Fig. 11(c). On the contrary, Fig. 11(d) depicts
the satisfactory result made by the proposed scheme.
Furthermore, we use 30 historical text images downloaded from
the Library of Congress website to test the performance of our pro-Fig. 9. The original test image of the two special artificial images.
Fig. 10. The simulation results of the first special artificial image SA1.
posed scheme. Table 2 shows an example of a historical text image
processed with our proposed and previous schemes, and the av-
erage recognition results of 30 historical text images using Google
Docs OCR. The experiment results presented in Table 2 show that
our proposed scheme has a better performance in text recognition
rate compared with previous schemes.
Table 3 lists the comparisons of simulation time within the en-
vironment: Intel Core 2 Quad Q9300 2.5 GHz CPU, 4.0 GB main
memory, and Java Development Kit 1.6.0_26. The fastest scheme
is LLBT [2], the second one is ELBT [3] followed by our proposed
scheme. The longer processing time of our proposed scheme is
caused by the extra preprocess of raw data (ex: contrast enhance-
ment) which is helpful for generating a good light-balanced re-
sult.
732 K.-N. Chen et al. / Digital Signal Processing 22 (2012) 726–733Table 2
The comparisons of historical text images.Fig. 11. The simulation results of the second artificial image SA2.
Table 3
The comparisons of simulation time among our proposed and previous schemes.
Schemes Proposed scheme ELBT [3] LLBT [2]
Simulation time (s) 1.197 0.203 0.061
3.3. Discussions
In this section, we discuss how two important parameters,
c and bl, affect the image quality of simulation results. For pa-
rameter c, we use three artificial images for simulations, and the
results are shown in Fig. 12. Note that x- and y-coordinates de-
note the value of c in the interval [0,1] and the visual quality of
the processed images, respectively, where the = 30, thc = 60, and
bl = 260. As shown in Fig. 12, the suggested values of c are from
0.1 to 0.4.
Next, we focus on parameter bl. Fig. 13 shows how the different
values of bl affect the visual quality of images, where the = 30,
thc = 60, and c = 0.1. The suggested values of bl are from 200 to
300.
4. Conclusions and further works
In this paper, a novel light balancing scheme for text images
based on edge detection technique is proposed. Our approach con-
sists of five phases: contrast enhancement, edge detection, text
location, light distribution, and light balancing. Simulation results
illustrate that the proposed scheme can achieve superior perfor-Fig. 12. The simulations of c and the visual quality of processed image.
Fig. 13. The simulations of bl and the processed image visual quality.
mance in terms of both balancing uneven light distribution and
achieving a high degree of text recognition. In the future, we will
focus on developing an efficient scheme to compensate for the un-
even illumination problem for all kinds of scanned images, such as
text images, text-photo images, and photo images.
References
[1] S.D. Chen, A.R. Ramli, Contrast enhancement using recursive mean-separate
histogram equalization for scalable brightness preservation, IEEE Trans. Con-
sum. Electron. 49 (4) (2003) 1301–1309.
[2] S.C. Hsia, M.H. Chen, Y.M. Chen, A cost-effective line-based light-balancing
technique using adaptive processing, IEEE Trans. Image Process. 15 (9) (2006)
2719–2729.
[3] S.C. Hsia, P.S. Tsai, Efficient light balancing techniques for text images in video
presentation systems, IEEE Trans. Circuit Syst. Video Technol. 15 (8) (2005)
1026–1031.
K.-N. Chen et al. / Digital Signal Processing 22 (2012) 726–733 733[4] N. Kanopoulos, N. Yasanthavada, R. Baker, Design of an image edge detection
filter using the Sobel operator, IEEE J. Solid State Circuits 23 (2) (1988) 358–
367.
[5] E. Kavallieratou, E. Stamatatos, Improving the quality of degraded document
images, in: Proceedings of the Second International Conference on Document
Image Analysis for Libraries, Lyon, France, Aug. 2006, pp. 340–349.
[6] N. Kazakova, M. Margala, N.G. Durdle, Sobel edge detection processor for a
real-time volume rendering system, in: Proceedings of the 2004 International
Symposium on Circuits and Systems, vol. 2, Vancouver, Canada, May 2004,
pp. II-913–II-916.
[7] Y.T. Kim, Contrast enhancement using brightness preserving bi-histogram
equalization, IEEE Trans. Consum. Electron. 43 (1) (1997) 1–8.
[8] J.Y. Kim, L.S. Kim, S.H. Hwang, An advanced contrast enhancement using par-
tially overlapped sub-block histogram equalization, IEEE Trans. Circuits Syst.
Video Technol. 11 (4) (2004) 475–484.
[9] Y.C. Liu, W.H. Chan, Y.Q. Chen, Automatic white balance for digital still camera,
IEEE Trans. Consum. Electron. 41 (3) (1995) 460–466.
[10] S. Lu, B. Su, C.L. Tan, Document image binarization using background estima-
tion and stroke edges, Int. J. Doc. Anal. Recogn. 13 (4) (2010) 303–314.
[11] S. Lu, C.L. Tan, Binarization of badly illuminated document images through
shading estimation and compensation, in: Proceedings of the Ninth Interna-
tional Conference on Document Analysis and Recognition (ICDAR 2007), Sept.
2007, pp. 312–316.
[12] W. Niblack, An Introduction to Image Processing, Prentice–Hall, Englewood
Cliffs, NJ, 1986, pp. 115–116.
[13] J. Sauvola, M. Pietikäinen, Adaptive document image binarization, Pattern
Recogn. 33 (2) (2000) 225–236.
[14] M. Seeger, C. Dance, Binarising camera images for OCR, in: Proceedings of the
Sixth International Conference on Document Analysis and Recognition (ICDAR
2001), Sept. 2001, pp. 54–58.
[15] Z. Shi, V. Govindaraju, Historical document image enhancement using back-
ground light intensity normalization, in: Proceedings of the 17th International
Conference on Pattern Recognition (ICPR 2004), vol. 1, Aug. 2004, pp. 473–476.
[16] S.D. Yanowitz, A.M. Bruckstein, A new method for image segmentation, Com-
put. Vis. Graph. Image Process. 46 (1) (1989) 82–95.
Kuo-Nan Chen received his Ph.D. in Computer Sci-
ence and Information Engineering in 2011 from the
National Chung Cheng University, Chiayi County, Tai-
wan. His current research interests include data hid-
ing, image processing, and watermarking of digital
images.Chin-Hao Chen received the M.S. degree in Infor-
mation Engineering and Computer Science from Feng
Chia University in 2009. His research interests include
image processing.
Chin-Chen Chang received his Ph.D. in Computer
Engineering in 1982 from the National Chiao Tung
University, Hsinchu, Taiwan. During the academic
years of 1980–1983, he was on the faculty of the
Department of Computer Engineering at the National
Chiao Tung University. From 1983 to 1989, he was on
the faculty of the Institute of Applied Mathematics,
National Chung Hsing University, Taichung, Taiwan.
From August 1989 to July 1992, he was the head
of, and a professor in, the Institute of Computer Science and Informa-
tion Engineering at the National Chung Cheng University, Chiayi, Taiwan.
From August 1992 to July 1995, he was the dean of the college of En-
gineering at the same university. From August 1995 to October 1997, he
was the provost at the National Chung Cheng University. From September
1996 to October 1997, Dr. Chang was the Acting President at the National
Chung Cheng University. From July 1998 to June 2000, he was the di-
rector of Advisory Office of the Ministry of Education of the ROC. From
2002 to 2005, he was a Chair Professor of the National Chung Cheng Uni-
versity. Since February 2005, he has been a Chair Professor of Feng Chia
University. In addition, he has served as a consultant to several research
institutes and government departments. His current research interests in-
clude database design, computer cryptography, image compression and
data structures.
