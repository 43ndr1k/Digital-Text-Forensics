Authorship Attribution of Short Historical Arabic Texts Based on Lexical Features 
   
 
 
S. Ouamour 
USTHB University 
Siham.ouamour@gmail.com 
 
 
H. Sayoud 
USTHB University 
Halim.sayoud@uni.de 
 
 
 
Abstract‚Äî In this paper the authors investigate the authorship 
of several short historical texts that are written by ten ancient 
Arabic travelers: this Arabic dataset, which was collected by the 
authors in 2011, is called AAAT dataset.  
Several experiments of authorship attribution are conducted on 
these Arabic texts, by using different lexical features such as 
words, word-bigrams, word-trigrams, word-tetragrams and rare 
words. Furthermore, seven different classifiers are employed, 
namely: Manhattan distance, Cosine distance, Stamatatos dis-
tance, Camberra distance, Multi Layer Perceptron (MLP), Se-
quential Minimal Optimization based Support Vector Machine 
(SMO-SVM) and Linear Regression. 
For the evaluation task, several experiments of authorship attri-
bution are conducted on the AAAT dataset by using the different 
quoted features and classifiers. 
Results show good attribution performances with an optimal 
score of 80% of good authorship attribution. Moreover, this 
investigation has revealed interesting results concerning the 
Arabic language and more particularly for the short texts.     
 
Keywords- Artificial Intelligence; Computational Linguistics; 
Text-mining; Authorship Attribution; Arabic language; Word 
N-Grams; Rare words; Lexical Features.   
I. INTRODUCTION 
Stylometry has attracted a lot of interest during the last 
years, especially (but not exclusively) for security purposes. 
Authorship Attribution (AA) is a research field of stylometry, 
which consists in determining who (out of a given list of 
candidates) wrote a given  piece of text by using some tech-
niques of text mining. The longer is the text; the better is the 
attribution accuracy. 
Stylometry or Authorship recognition can be divided into 
several related fields that are: 
- Authorship attribution (AA) or identification: consists in 
identifying the author(s) of a set of different texts; 
- Authorship verification: consists in checking whether a 
piece of text is written or not by an author who claimed to 
be the writer; 
- Authorship discrimination: consists in checking if two 
different texts are written by a same author or not [1]; 
- Plagiarism detection: in this research field we look for 
the sentences or paragraphs that are taken from another 
author [2]; 
 
 
- Text indexing and segmentation: when several texts, 
which are issued from different authors, are concatenated in 
a form of a global book or forum text, one particular interest 
in stylometry is to segment the global text into homogene-
ous segments (each segment or paragraph contains the 
contribution of only one author) by giving the name of the 
appropriate author in each text segment (paragraph) [3]; 
In general, individuals have distinctive ways of speaking 
and writing, and there exists a long history of linguistic and 
stylistic investigation into authorship attribution.  
Although several works are reported for the English, 
Greek and Hebrew languages [2] [3] [4] [5], the authors 
have not found any serious research work made with Arabic 
texts. That is why, they propose in the present paper an 
overall research work of AA (Authorship Attribution) that 
handles 30 different texts written by 10 ancient Arabic trav-
elers who wrote several books describing their travels. 
A special Arabic corpus has been built by the authors in 
order to assess several features and classifiers that are usual-
ly employed in stylometry. 
The experiments of AA are described in the following 
sections. 
In section two, we describe the text corpus which was 
built to undergo the experiments. Section three defines the 
different classifiers used for the task of authorship attribu-
tion. The different results are presented in the forth section. 
Finally, we conclude with a conclusion, future work and 
some references. 
II. DESCRIPTION OF THE TEXT DATASET 
The text dataset, called AAAT corpus (i.e. Authorship 
attribution of Ancient Arabic Texts) [6], is built by the au-
thors of this paper for a purpose of authorship attribution. It 
contains 10 groups of old Arabic texts that are extracted 
from 10 different Arabic books and which belong respec-
tively to 10 different ancient authors (table1). Each group 
contains 3 different texts that are written by the same au-
thor, which means that each group corresponds to only one 
ancient author. This set of texts has been collected in 2011 
from ‚ÄúAlwaraq library‚Äù and can be accessed throw the fol-
lowing web site: http://sayoud.net/AAAT.pdf.  
 
The different ancient books are summarized in table 1.  
2013 International Conference on Cyber-Enabled Distributed Computing and Knowledge Discovery
978-0-7695-5106-7/13 $26.00 ¬© 2013 IEEE
DOI 10.1109/CyberC.2013.31
144
 
Each author is presented by 3 different texts. The texts 
are very short: the average text length is about 550 words; 
furthermore some texts have less than 300 words. This sit-
uation involves bad experimental conditions, since it has 
been shown in previous research works conducted by Eder 
[7] and Signoriello [8] that the minimum number of words 
per text should be 2500 words in order to obtain a good 
attribution results.  
TABLE 1. DESCRIPTION OF THE DIFFERENT BOOKS. 
Author name Date AD Book title 
Ibn Batuta  1325-1352 Travels of Ibn Batuta  
Ibn Jubayr  1182-1185 Travels of Ibn Jubayr  
Nasser Khasru 1045  Book of the Travels  
Ibn Fathlan 921  Travels of Ibn Fathlan  
Ibn Al Mu-
jawer  
1233  History of the Mustabsir 
Al Yussee  1684  Conferences in language and 
literat.  
Lessan Addin  1684  Khatrat Al Tife during the tra 
  vel of the winter and summer  
Al Alussi  1852  Strangeness of travels  
Al Hamawi  
 
1542-1608 Hady Alathaan Annajdia to the 
Egypt houses  
Al Balwi 
 
Before 
1364 
Taj Almafraq Fi Tahlyet orien-
tal scientist  
 
 
We have chosen to use short text documents in order to 
evaluate the different classifiers using the Word N-Grams. 
In fact, when short texts are used, the AA performances 
decrease and it becomes easy to evaluate the different clas-
sifiers (i.e. avoiding high scores). 
III. DESCRIPTION OF THE CLASSIFIERS 
The different experiments of authorship attribution are 
made by using the seven following classifiers:  
Manhattan distance, Cosine Distance, Stamatatos dis-
tance, Camberra distance, Multi Layer Perceptron (MLP), 
Support Vector Machines (SVM), and Linear regression. 
Moreover, the lexical characteristics represented by word N-
Grams and rare words have been chosen as features. 
Some brief definitions of the different classifiers are giv-
en below: 
A. Manhattan distance 
The Manhattan distance [1] between two vectors f and g 
is given by the following formula:    	
                                                                    (1) 
where n is the length of the vector. 
B. Cosine distance 
Cosine similarity is a measure of similarity between two 
vectors that measures the cosine of the angle between them. 
The technique is also used to compare documents in text 
mining. 
The cosine of two vectors can be derived by using the 
Euclidean dot product formula:                                                               (2) 
Given two vectors of attributes, f and g, the cosine simi-
larity, cos(), is represented using a dot product and magni-
tude as: 
      
  	  		
  	!"	
    	!"	
  
(3) 
     where  denotes the magnitude of vector f and n is its 
length [9]. 
C. Stamatatos distance 
The Stamatatos distance [10] between two vectors f and g 
is given by the following formula: 
                                   
          # $%   !&  ' !("	
                                 (4) 
 
where n is the length of the vector. 
D. Camberra distance  
The Canberra distance is a numerical measure of the dis-
tance between pairs of points in a vector space. It is similar 
to the Manhattan distance. It is mostly used for data scat-
tered around the origin. 
The Camberra distance between two vectors f and g is 
given by the following formula: 
) * +,-.,!+,/., *
0


    
                          (5)  
where n is the length of the vector. 
E. Multi-Layer Perceptron (MLP) 
The MLP is a neural network classifier that uses the er-
rors of the output to train the neural network [11]. The MLP 
can use different back-propagation schemes to ensure the 
training of the classifier. The MLP is trained by the two first 
texts for every author, whereas the remaining text (the third 
one) is used for the testing task. 
F. The Sequential Minimal Optimization based Support 
Vector Machine (SMO-SVM)  
In machine learning, support vector machines (SVMs) 
are supervised learning models with associated learning 
algorithms that analyze data and recognize patterns, used for 
classification and regression analysis. The basic SVM takes 
a set of input data and predicts, for each given input, which 
of two possible classes forms the output, making it a non-
probabilistic binary linear classifier. Given a set of training 
examples, each marked as belonging to one of two catego-
ries, a SVM training algorithm builds a model that assigns 
new examples into one category or the other. A SVM model 
is a representation of the examples as points in space, 
145
mapped so that the examples of the separate categories are 
divided by a clear gap that is as wide as possible. New ex-
amples are then mapped into that same space and predicted 
to belong to a category based on which side of the gap they 
fall on. 
In addition to performing linear classification, SVMs can 
efficiently perform non-linear classification using what is 
called the kernel trick, implicitly mapping their inputs into 
high-dimensional feature spaces.   
The SVM is a very accurate classifier that uses bad exam-
ples to form the boundaries of the different classes [12]. The 
SMO algorithm is used to speed up the training of the SVM 
[13]. The SVM is trained by the two first texts for every 
author, whereas the third one is used for the testing task. 
G. Linear Regression 
Linear regression is the oldest and most widely used pre-
dictive model. The method of minimizing the sum of the 
squared errors to fit a straight line to a set of data points was 
published by Legendre in 1805 and by Gauss in 1809. Li-
near regression models are often fitted using the least 
squares approach, but they may also be fitted in other ways, 
such as by minimizing the ‚Äúlack of fit‚Äù in some other norms 
(as with least absolute deviations regression), or by mini-
mizing a penalized version of the least squares loss function 
as in ridge regression [14] [11] [15]. 
IV. EXPERIMENTS OF AUTHORSHIP ATTRIBUTION 
In this section, we present the different experiments of 
authorship attribution on the old Arabic dataset (AAAT), 
which consists of several short texts that were written by ten 
Arabic travelers.   
Several lexical features are tested: words, word-bigram, 
word-trigrams, word-tetragrams and rare words.  
Furthermore for the machine-learning classifiers (MLP, 
SVM and Linear Regression), the two first texts of each 
author are used for the training step and the third one is used 
for the testing one. 
Table 2 displays the scores of good authorship attribution 
in % that are obtained by the seven classifiers using the 
different lexical features. As we can observe, we obtain an 
optimal score of 80% by the SMO-SVM classifier using 
rare words. This score is the best score with regards to all 
the classifiers and features that have been employed in these 
experiments. 
Concerning the classifiers, we remark that the best scores 
for the distances (Manhattan, Cosine, Stamatatos and Cam-
berra distances) are obtained with the features words and 
rare words (20 ~ 60%). For the learning machines classifiers 
(MLP and SVM), the best scores are got with rare words 
(70% and 80% respectively). For the linear regression, the 
two features: words and rare words provide the best score 
(60%).  
 
 
TABLE 2: SCORE OF GOOD ATTRIBUTION IN % 
* means 600 most frequent features only and ‚Äì means a failure. 
                       
Feature 
 
 
Classifier R
ar
e 
W
or
ds
 
W
or
d 
W
or
d 
 B
ig
ra
m
 
W
or
d 
Tr
ig
ra
m
 
W
or
d 
Te
tra
-
gr
am
 
B
es
t S
co
re
  p
er
 
cl
as
si
fie
r 
Camberra dist. 20 20 10 10 10 20 
Cosine dist. 60 60 20 10 20 60 
Manhattan dist. 60 60 30    ‚Äì 10 60 
Stamatatos dist. 20 20 10 10 10 20 
MLP 70* 60* 40* 20* 20* 70 
SMO-SVM 80* 70* 20* 10* 10* 80 
Linear Regres-
sion 
60* 60* 50* 20* 10* 60 
Best score  80 70 50 20 20  
We remark also that the comparison between the differ-
ent classifiers shows that the best performances are obtained 
with the SMO-SVM classifier with 80% of good attribution, 
followed by the MLP with 70% of good attribution, then 
after the Linear Regression, Manhattan and Cosine distances 
with 60% of good attribution, and finally, the Camberra and 
the Stamatatos distances with only 20%, which represents 
the worst performances (table 2). Concerning the features, 
the best type, in our experiment, is the rare words followed 
by the words, word-bigrams and finally word-trigrams and 
tetragrams (table 2). For these two last ones, the different 
classifiers present very bad classification, since the scores 
do not exceed 20%. 
Note that the Authorship Attribution Precision (AAP) is 
defined as the ration of ‚Äúthe number of texts that are well 
attributed‚Äù to ‚Äúthe total number of texts‚Äù. 
   It is important to mention that an authorship attribution 
precision of 80% with short texts is relatively high, since 
several previous works showed that the minimum amount of 
text that is required for a good authorship attribution is at 
least 2500 words per text [7][8]. In this investigation, very 
short texts are used, ranging from only 209 words to a max-
imum of 800 words per text. 
V. CONCLUSION 
This research work focused on the authorship attribution 
of some old Arabic texts that were written by ten ancient 
Arabic travelers. We recall that several lexical features have 
been tested for the Arabic language and particularly with 
very short texts. These two particularities (Arabic language 
and small text size) represent the main originality of this 
research work. Hence, seven different classifiers were used 
for the attribution task with the different features (Manhat-
tan, Cosine, Stamatatosand Camberra distances, MLP, SVM 
and Linear Regression) as described in section 3. The dif-
ferent MLPs, SVMs and Linear Regressions are trained by 
146
 
using 20 texts and tested on 10 different texts (not present in 
the training dataset). 
Experiments of authorship attribution, for each classifier 
and each feature, have shown the following interesting 
points: 
 The best performances are obtained with the SMO-
SVM classifier with a score of 80%, followed by the 
MLP (70%), the Linear Regression (60%), Manhattan 
and Cosine distances (60%), and finally, Camberra and 
Stamatatos distances (20%).  
 Rare words and words seem to be suitable for the dif-
ferent distances and Linear Regression, while for the 
MLP and SVM classifiers, rare words are the most 
suitable features. 
 The best used features in our experiments are rare 
words followed by words, word-bigrams and finally 
word-trigrams and tetragrams. 
 For the two features: word trigram and word tetra 
gram, we notice a failure for all the classifiers: the 
scores of good attribution do not exceed 20%, whereas 
several recent research works have shown the good 
performances of those features in Arabic [1]. The most 
probable reason is that the size of the investigated doc-
uments is relatively too small and then there is no 
enough data to build a strong word tri(or tetra)gram 
text characterization. 
 Although the text size was too small (between 209 and 
800 tokens per text), the AAP score seems interesting 
(80% of good attribution). 
This new work of authorship attribution, which 
represents a rare research work on Arabic language, shows a 
real motivation and interest for this type of language. It also 
shows that the rules are almost the same for both English 
and Arabic (for the lexical level). Consequently, it should be 
possible to exploit most of the knowledge that has been 
acquired with the Latin or Greek language (regarding the 
lexical level), in order to employ it in Arabic text-mining 
applications.  
Finally, it could be interesting to mention that the authors 
of this investigation have also tested other types of features 
such as character n-grams (not reported in this paper) and 
have noticed that this last type of features provides better 
results than the lexical ones. 
ACKNOWLEDGMENT 
The authors wish to warmly thank: Dr G. Tambouratzis, 
and Dr M. Vassiliou (from the ILSP of Athens), Dr E. Sta-
matatos (from Aegen University of Samos), Prof M. Oakes 
(from Sunderland University) and Dr P. Juola (from Du-
quesne University). 
REFERENCES  
[1] H. Sayoud, ‚ÄúAuthor Discrimination between the Holy Quran and 
Prophet‚Äôs Statements‚Äù, Literary and Linguistic Computing, Volume 
27 Issue 4, pp.427-444, 2012. 
[2] R. K√ºppers, and S. Conrad, ‚ÄúA Set-Based Approach to Plagiarism 
Detection‚Äù, PAN 2012 Lab Uncovering Plagiarism, Authorship, and 
Social Software Misuse held in conjunction with the CLEF 2012, 
17-20 September, Rome, Italy, 2012.   
[3] D. Forest, ‚ÄúApplication de Techniques de Forage de Textes de 
Nature Pr√©dictive et Exploratoire √† des Fins de Gestion et d‚ÄôAnalyse 
Th√©matique de Documents Textuelles Non Structur√©s. Th√®se de 
Doctorat, Universit√© du Qu√©bec √† Montr√©al, Juin 2006. 
[4] P. Juola, ‚ÄúAuthorship Attribution, a survey and technical monograph 
on authorship attribution, the process of inferring the author or au-
thor's characteristics from the text of a document,‚Äù published 
through NOW Publishers, 2006. 
[5] G. Tambouratzis, S. Markantonatou, N. Hairetakis, M. Vassiliou, D. 
Tambouratzis & G. Carayannis, ‚ÄúDiscriminating the Registers and 
Styles in the Modern Greek Language,‚Äù Proceedings of the Work-
shop on Comparing Corpora (held in conjunction with the 38th ACL 
Meeting), Hong Kong, China, 7 October. pp. 35-42, 2000. 
[6] S. Ouamour, H. Sayoud, Authorship Attribution of Ancient Texts 
Written by Ten Arabic Travelers Using a SMO-SVM Classifier. The 
2nd International Conference on Communications and Information 
Technology (ICCIT): Digital Information Management, Hammamet, 
Tunisia 2012. pp 37-40. 
[7] M. Eder, ‚ÄúDoes size matter? : autorship attribution, short samples, 
big problem,‚Äù In Digital humanities 2010 conference, pp. 132-135, 
London, 2010.   
[8] D. J. Signoriello, S. Jain, M. J. Berryman, D. Abbott, ‚ÄúAdvanced 
text authorship detection methods and their application to biblical 
texts,‚Äù Proceedings of SPIE (2005),  Volume: 6039, Publisher: Spie, 
pp. 163‚Äì175, 2005.  
[9] Wikipedia, Cosine similarity, From Wikipedia, the free encyclope-
dia. The web page was last modified on 27 March 2013.   
http://en.wikipedia.org/wiki/Cosine_similarity. 
[10] E. Stamatatos, Author identification using imbalanced and limited 
training texts. In Proceedings of the 4th International Workshop on 
Text-based Information Retrieval, 2007, pp. 237-241. 
[11] H. Sayoud, ‚ÄúAutomatic speaker recognition ‚Äì Connexionnist ap-
proach‚Äù, PhD thesis, USTHB University, Algiers, 2003. 
[12] Ian H. Witten, Eibe Frank, Len Trigg, Mark Hall, Geoffrey Holmes, 
and Sally Jo Cunningham, ‚ÄúWeka: Practical machine learning tools 
and techniques with Java implementations,‚Äù In Nikola Kasabov and 
Kitty Ko, editors, Proceedings of the ICONIP/ANZIIS/ANNES'99 
Workshop on Emerging Knowledge Engineering and Connectionist-
Based Information Systems, pp. 192-196, Dunedin, New Zealand, 
1999. 
[13] S.S. Keerthi, S.K. Shevade, C. Bhattacharyya & K.R.K, ‚ÄúMurthy, 
Improvements to Platt‚Äôs SMO Algorithm for SVM Classifier De-
sign‚Äù, Neural Computation 13, pp. 637‚Äì649, 2001. 
[14] Wikipedia, Linear regression, From Wikipedia, the free encyclope-
dia. The web page was last modified on 28 March 2013.  
http://en.wikipedia.org/wiki/Linear_regression. 
[15] X. Huang and W. Pan,‚Äù Linear regression and two-class classifica-
tion with gene expression data‚Äù, Bioinformatics (2003,) Vol 19 (16), 
pp. 2072-2078, 2003. 
147
