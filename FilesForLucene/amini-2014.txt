Accepted Manuscript
Capturing Scholar’s Knowledge from Heterogeneous Resources for Profiling in
Recommender Systems
Bahram Amini, Roliana Ibrahim, Mohd Shahizan Othman, Ali Selamat
PII: S0957-4174(14)00380-7
DOI: http://dx.doi.org/10.1016/j.eswa.2014.06.039
Reference: ESWA 9411
To appear in: Expert Systems with Applications
Please cite this article as: Amini, B., Ibrahim, R., Othman, M.S., Selamat, A., Capturing Scholar’s Knowledge from
Heterogeneous Resources for Profiling in Recommender Systems, Expert Systems with Applications (2014), doi:
http://dx.doi.org/10.1016/j.eswa.2014.06.039
This is a PDF file of an unedited manuscript that has been accepted for publication. As a service to our customers
we are providing this early version of the manuscript. The manuscript will undergo copyediting, typesetting, and
review of the resulting proof before it is published in its final form. Please note that during the production process
errors may be discovered which could affect the content, and all legal disclaimers that apply to the journal pertain.
  
Capturing Scholar’s Knowledge from Heterogeneous Resources for 
Profiling in Recommender Systems 
Bahram Amini, Roliana Ibrahim, Mohd Shahizan Othman, Ali Selamat 
Faculty of Computing, Universiti Teknologi Malaysia (UTM), Malaysia 81310 
avbahram2@live.utm.my, {roliana, shahizan, aselamat }@utm.my 
Abstract. In scholars’ recommender systems, acquisition knowledge for construction profiles is 
crucial because profiles provide fundamental information for accurate recommendation. Despite 
the availability of various knowledge resources, identification and collecting extensive 
knowledge in an unobtrusive manner is not straightforward. In order to capture scholars’ 
knowledge, some questions must be answered: what knowledge resource is appropriate for 
profiling, how knowledge items can be unobtrusively captured, and how heterogeneity among 
different knowledge resources should be resolved. To address these issues, we first model the 
scholars’ academic behavior and extract different knowledge items, diffused over the Web 
including mediated profiles in digital libraries, and then integrate those heterogeneous 
knowledge items by Wikipedia. Additionally, we analyze the correlation between knowledge 
items and partition the scholars’ research areas for multi-disciplinary profiling. Compared to the 
state-of-the-art, the result of empirical evaluation shows the efficiency of our approach in terms 
of completeness and accuracy. 
Keywords: Knowledge Acquisition, Scholar Profiling, Recommender System, Mediated Profile 
1.  Introduction 
Scholar’s recommender systems recommend scientific articles based on the information in 
profiles. Profiles encompass characteristics of scholars including research interests and 
background knowledge (Amini, Ibrahim, Othman, & Rastegari, 2011). The effectiveness of 
recommender systems depends highly on the completeness and accuracy of profiles (Gauch, 
Speretta, Chandramouli, & Micarelli, 2007). Recently, many attempts have been conducted to 
improve profiles by employing knowledge driven approaches (Uchyigit, 2009), which take into 
consideration different scholar’s information including publication history (Sugiyama & Kan, 
2010), homepage information (Yao, Tang, & Li, 2007), and/or collaborative information of 
scholars (Vellino & Zeber, 2007).  
These approaches employ statistical approaches such as Vector Space Model (VSM) (Salton, 
Wong, & Yang, 1975), association rules, Bayesian networks (Schiaffino & Amandi, 2000), and 
ontologies (Eyharabide & Amandi, 2011) to extract scholars’ interests in terms of key words. 
These approaches work well on the assumption that the recommended articles should be 
“similar” to the past scholars’ practices. Thus, the similarity between candidate articles and 
profile’s key words is measure to filter out dissimilar articles. 
However, individual scholar has their own tendency and attitude in selecting an article because 
of differences in their proficiency level and background knowledge (Bitonto, Laterza, & Roselli, 
  
n.d.). A scientific article from a scholar's viewpoint is interesting if it has been grounded on his 
background knowledge (Devedžić, 2006), and “complement” to what has been already learned. 
In theory, scholars acquire knowledge upon a “cumulative learning” process (Gagne, 2000), 
where current knowledge helps to capture more advanced knowledge. Fig. 1 depicts the structure 
of cumulative learning at overall. It advocates that scholars learn basic knowledge first and 
continue learning upon existing knowledge towards more advanced knowledge. Thus, articles in 
which are similar to the past experience of scholars is not interesting. Our approach works upon 
this theory and aim to extract knowledge items, suitable for profiling scholars’ background 
knowledge in a hierarchical order. 
More importantly, the focus of full researchers changes 
over time from one topic to another, because they do 
search in several topics simultaneously. For example, a 
professor may do research in “Database Systems” as 
well as “Semantic Web” fields at the same time. 
Current scholarly recommender systems such as  
(Liang, Yang, Chen, & Ku, 2008) and (Sugiyama & 
Ken, 2011) suggest articles which are similar to both 
fields, leading to divergence and low precision 
recommendation. Therefore, it is crucial to profile the 
multi-disciplinary scholars’ knowledge, which enables 
topic-aware recommendation.  
To address these issues, the following steps are 
proposed:  
1- Identification the resource of scholars’ knowledge and extending the scope of scholars’ 
context.  
2- Extracting knowledge items in which model the scholars’ knowledge. 
3- Integrating different knowledge items with a knowledge base which resolves 
inconsistency and clean up ambiguous items. 
4- Clustering of knowledge items into groups of semantically relevant to support multi-
disciplinary research areas. 
Moreover, capturing scholars’ knowledge similar to other acquisition systems, suffers from the 
knowledge acquisition bottleneck (Cimiano, 2005), i.e., asking scholars explicitly on what they 
know is intrusive and prone to errors. Thus, knowledge acquisition must be unobtrusive and must 
not interfere with scholar’s tasks (Middleton, Roure, & Shadbolt, 2009). Additionally, extracting 
knowledge items from different resources brings inconsistency and heterogeneity, which requires 
knowledge unification and transformation.   
The paper is organized as follows: Section 2 discusses related works and significant contribution. 
Section 3 explains our methodology in knowledge acquisition and transformation. Section 4 
describes the experiments and findings. Section 5 justifies the findings and compares with 
 
Fig. 1: Hierarchy of learning scholars’ 
knowledge 
  
similar works. Finally, Sections 6 through 8 discuss the results, proposes extensions, and draws 
conclusion. 
2.  Related Work 
Term extraction is the core approach of many document processing systems, particularly 
profiling approaches. We first discuss the term extraction methods in general, and then review 
the profiling approaches. 
2.1 Term Extraction Methods 
These methods are classified into three general categories including statistical, linguistic, and 
hybrid approaches. 
Statistical approaches exploit statistical techniques to extract terms from document. They are 
generally useful for finding importance terms in a corpus. The most cited approach is Vector 
Space Model (VSM) with standard TF/IDF weighting method (Salton et al., 1975). It extracts the 
most important terms of a corpus and assigns weight value to each term, which indicates the 
importance degree. This value is higher for terms that appear frequently in one document, but it 
is lower for terms that appear frequently in multiple documents in the corpus. These approaches 
lack in handling grammatical function of terms in a sentence such as part of speech (POS). 
TF/IDF-based methods works well for general or non-technical text documents but not for 
scientific context such as Computer Science (Kozakov, Park, Fin, & Drissi, 2004). 
Linguistic approaches employ Natural Language Processing (NLP) techniques (D.Manning & 
Schütze, 1999), and extracts the terms based on the linguistic function of words in sentences. 
However, the linguistic methods lack in calculating the importance degree of words. A common 
method in NLP is part-of-speech (POS) tagging, where it assigns a tag to words indicating part 
of speech such as nouns, verbs, and adjectives. Nouns clause or adjectives are often selected as 
terms when POS tagging is applied. 
Hybrid methods combine statistical and linguistic methods to overcome both shortcomings. 
Sclano et al. (Sclano & Velardi, 2007) first employ the linguistic methods to extract terms, and 
the importance of terms are then determined by applying five statistical filters. These filters are 
primarily based on term frequencies (TF) in a domain corpus. Each filter defines the importance 
degree in different way. The terms with highest scores remain in the final list of term. Another 
method is χ2 (Matsuo & Ishizuka, 2003), where named entities are extracted using a linguistic 
processor, and occurrences of such entities are placed in a contingency table. It contains 
frequency of terms in a corpus. Once χ2 values are calculated, the terms with highest values are 
selected using a threshold value. 
2.2 Profiling Methods 
Many attempts have been conducted to improve the scholars’ profiles by employing knowledge 
driven approaches which mostly extract the scholars’ interests from the textual content. In the 
following, related approaches in capturing scholars’ knowledge are discussed. The most 
  
promising ones (Middleton, Roure, & Shadbolt, 2001) attempt to integrate various domain 
knowledge by implicitly extracting information from user context. It represents the scholars’ 
interests as a high-dimensional vector of words without considering the semantic relations 
among words, and ignoring the multi-topic property of research task. Classification of such 
vectors with thousands entries diminishes the accuracy of scholars’ profiles and burden 
processing time. 
The framework in (Lopes, Martins Souto, Krug Wives, & Moreira de Oliveira, 2007) allows 
scholars to supply their interests explicitly through CV (Curriculum Vitae) files. The system also 
implicitly gathers keywords from a user’s query interface. A harvester then collects metadata 
about the scientific articles retrieved by the digital library in response of queries. The query 
vector is constructed with terms collected from “title” and “keywords” of the “bibliography” and 
“university degree” sections of the scholar’s CVs. However, this approach has several 
drawbacks: it depends on the explicit feedback of scholars including CV files and long-period 
query interactions. Besides, multidisciplinary property of research task is not supported, as it 
assumes incorrectly all query’s keywords are belonging to the same research topic. 
In (S. Liao, Kao, Liao, & Chen, 2009), a traditional cataloging scheme (Classification for 
Chinese Libraries, CCL) as a reference ontology for document classification is employed. The 
reference ontology, which is a basic user profile, is extracted from the borrowing records of 
individual users as well as the notes keyed by librarians. It is assumed that the collection of 
keywords and title of loaned books in a library represents the user interests. On logging into the 
system, the favorite topics of users from these resources are extracted and assembled to build up 
the user profile. The system is linked to online check in/out information system and collects such 
information from the user interactions. This approach, however, collects very general topics 
about the user interests including book’s titles and searching keywords. It omits the keywords 
appeared within the book’s chapters. Besides, some chapters of a loaned book are often out of 
interest of a scholar. Also, there is no way to assign weights to searching keywords of users. 
In (Vellino & Zeber, 2007), user model is a blend of different information resources including 
explicit user’s judgment on recommendations, implicit features or metadata of articles which is 
derived from text corpora, search queries, click streams, citation information, and collaborative 
information which is collected from the rating information by “similar users”. Although this 
approach engages a wide variety of information resources to construct scholars’ profiles, but it 
suffers from three shortcomings: it does not support multi-disciplinary property of research topic, 
employs collaborative information of so-called similar scholars which takes into account the 
indecisive information of articles’ rating by other scholars, and provides the “cold-start” problem 
for the recommender system when new user interacts with the system. 
The work of (Kodakateri, Gauch, Luong, & Eno, 2009) leverages the ACM Computing 
Classification System (CCS) as a classification tool for CiteSeerX digital library. The ACM’s 
CCS tags on user’s visiting articles are used to create the user profiles. For those documents with 
no ACM tag, a training model is created based on documents in the collection that contain ACM 
  
tags. On recommendation process, it considers ten top-most tags on each document in the 
collection. It, however, considers the ACM tag to classifies the new articles and ignores the key 
terms appeared in the body of articles, which have been visited/rated by scholars. Besides, the 
multi-disciplinary feature of research topic does not supported, because a scholar who 
searches/tags articles in different disciplines, the profile leads to inaccurate recommendation. 
Yao et al. (Yao et al., 2007) automatically identifies and annotates general information from 
scholars’ homepage using the probabilistic Conditional Random Fields (CRF) (Lafferty, 
McCallum, & Pereira, 1999). It extends the FOAF ontology (Brickley & Miller, 2010) and tags 
different personal properties of researcher’s information such as affiliations, institutions, and 
educational history. However, it does not take into consideration the publication information, but 
integrates the publication data from DBLP bibliography (dblp.uni-trier.de). This type of scholars’ 
profiles are exploited in “expert finding” application and do not contribute to the recommender 
systems. Particularly, it does not collect key terms of reading articles and formal education as a 
background knowledge item. 
The work in (Sugiyama & Kan, 2010) derives scholars’ interests from their recent publication 
list, associated neighboring papers (i.e., citation papers of publications), and the papers 
referenced by the target papers (i.e., reference papers). It deals with two types of researchers: 
junior and senior whom have one or many publications, respectively. It also adopts tf*idf (Salton 
et al., 1975) weighting scheme for feature extraction from these articles. The approach processes 
tens to several hundred papers, indexed in DBLP data set as well as ACL Anthology Reference 
Corpus. This approach, however, does not concern about the scholars’ knowledge residing in 
academic home pages, reading articles (rated articles), and formal educations. Moreover, the 
weighting scheme does not take into account the semantic relations among key words. 
In summary, there are little works in the literature concerning about the scholar’s knowledge, and 
most approaches focus on extraction statistical information from the users’ content. As reviewed, 
these approaches are typically inefficient in scholar domain for several reasons: they engage very 
limited information resources and are typically intrusive with the user practices; they also do not 
represent the multi-area property of research and neglect the semantic relations among the 
keywords within the feature vectors. Our approach mainly concentrates on engaging various 
knowledge resources in which constitutes the scholars’ background knowledge, and examines 
how knowledge items are acquired from the mediated profiles and how to aggregate the key 
words by semantic approaches which  preserves the cross-relation semantics.  
3.   Methodology 
Fig. 2 represents the overall structure as well as the processing sequence of our method. All 
processes are connected in a way that data flows from left to right, and each component receives 
its input from the upstream components, and in turn, feeds its own result to the downstream 
component. The first process analyzes the context of scholar's domain and explores resource of 
pertinent academic information. The second one deals with the term extraction from knowledge 
resources. In third process, key terms are disambiguated and merged to build up a unified 
  
domain concept. The process four groups key concepts into clusters of focused-topics. Finally, 
the process five measures and evaluates our approach in terms of precision, recall, and F-score. 
Here, the notation “term” refers to a multi-word phrase that have been treated as more important 
terms in a context, and “concept” is a term that bears a specific meaning in understanding of a 
domain. In the following sub-sections, the task of each step is described.  
 
Fig. 2: The methodology of capturing scholar’s knowledge from 
heterogeneous resources  
3.1 Context and Resource Analysis  
To understand the scholars’ contextual knowledge, the use case approach (British Colombia, 
2005), which represents the scholar’s roles and interactions in an academic setting, is proposed. 
Fig. 3 in consideration of research tasks depicts a general view of scholars’ interactions with the 
knowledge resources. As shown, scholars incorporate in several academic activities and capture 
new knowledge in a variety of approaches including formal education, studying articles, 
authoring, conducting projects, etc. Besides, scholars express their knowledge, often represented 
in a textual form, by means of different medium such as academic homepages, blogs, and online 
communities. 
 
Formal Education 
Incorporates 
Papers/Articles 
Publishes/ Studies 
Research Projects 
Incorporate
Homepages/Blogs 
Mediated Profiles 
Creates/Updates 
Creates/Updates 
Curriculums, Learning concepts 
Includes
Concepts, Graphs, Formula, etc 
Project description (Key terms) 
Publications, Research Interests, CV 
Research Interests, Demographic data, 
etc 
Includes 
Includes 
Includes 
Includes 
Initial Terms 
1. Context and Source 
Analysis 
2. Key Term Extraction 3. Term Unification 
4. Term Clustering 
Knowledge Resources
5. Review & Evaluation 
Clustered Terms 
Clean Concepts 
  
Fig. 3: A use case model of scholar roles and activities in the academic setting 
We put forward the knowledge items from the use case scenario and represent the scholar’s 
knowledge in a conceptual model. We identified the resources of scholars’ knowledge- the sites 
that encompass textual information about the scholars in Computer Science domain, by 
analyzing the information in WebKB data set (Das, Giles, & Mitra, 2011). This data set contains 
more than eight thousands of pages collected from the Computer Science departments of world-
class universities. It is a symbolic knowledge base that mirrors the content of academic 
homepages (Craven, Dipasquo, & Freitag, 1998) categorized into student, faculty, staff, 
department, and course. An analysis of 160 samples of web pages in WebKB has identified the 
scholar’s home page content contain publications, educations, research interests, teaching and 
lectures, and partly uninformative data such as contacts, news, awards, etc.  
Having employed this behavioral use case, we model the resources of scholars’ knowledge by a 
UML-like composition diagram (see Fig. 4). It represents a conceptual model of scholars’ 
knowledge components and their relationship. As shown, scholars knowledge is a composition of 
formal education, home page information, digital library profiles (DL-Profiles), and publications. 
Moreover, the result of “research projects” updates the publications and “home page” 
information. Thus, no component for this resource is shown in the diagram. Likewise, each 
coarse–grained component is aggregated by its underlying fine-grained components. This model 
helps to understand the scholars’ knowledge components and inclusion or exclusion of resources 
given in the use-case diagram in Fig. 3. 
From this analysis, it has been concluded that the majority of text-based scholars’ knowledge on 
the web can be collected in implicit and non-intrusive manner from the following resources. An 
extensive integration of these knowledge resources provides a rich knowledgebase for modeling 
scholars’ background knowledge: 
• Academic homepage involves scholar’s research interests and research projects, 
• Publication includes published articles such as papers, chapter book and similar items, 
• Formal education includes lecture notes and curriculum-based education.  
In addition, we employ distributed scholar profiles or so-called mediated profiles (Bilchev & 
Marston, 2003) (Fig. 4), which are reproduced by major bibliographic databases in Computer 
and Information Science including CiteSeerX1, ACM2, Google Scholar3, IEEEXplore4, and 
                                                           
1 http://citeseerx.ist.psu.edu 
2 http://dl.acm.org/ 
3 http://scholar.google.com/ 
4 http://ieeexplore.ieee.org/ 
  
Microsoft Academic Search5 (MAS). By leveraging such freely access databases, we are not 
concerned about the privacy and protection issues, which facilitates the non-intrusive 
information acquisition.  
 
Fig. 4: The conceptual model of scholar’s background knowledge resources 
3.2 Term Extraction 
The goal of term extraction is to build a machine-readable abstraction from textual content of 
scholars’ knowledge including articles (publications or reading papers), formal education, and 
homepage content. Thus, Information Retrieval and Text Mining techniques (Weiss, Indurkhya, 
Zhang, & Damerau, 2010) is employed to statistically analyze the text content and extract the 
important key terms. By “key terms”, we refer to terms which describe the theme or topics of 
articles (Medelyan, Witten, & Milne, 2008). 
3.2.1 Term Extraction from Articles 
To extract terms from text corpora, the C-Value/NC-Value method (Frantzi, Ananiadou, & 
Mima, 2000), which is a statistical and linguistic-based method is proposed. It outperforms the 
similar weighting schemes (Piao, Forth, Gacitua, Whittle, & Wiggins, 2010), and it is a domain-
independent method, because exploits the contextual information in recognition of technical 
terms.  
The C-Value/NC-Value algorithm has two related parts (Frantzi et al., 2000): the linguistic and 
the statistical processing parts. 
• The linguistic part: {Identifies the candidate terms in a corpus} 
- Tokenize the text by Penn Treebank Tokenization method (Marcus et al., 1994). 
                                                           
5 http://academic.research.microsoft.com/ 
  
- Tagging with Brill's rule-based part-of-speech tagger (Eric, 1992). The POS tagger 
assigns grammatical tag (e.g. noun, adjective, verb, preposition, determiner, etc.) to each 
candidate term in the corpus, and limits specific patterns to extract. 
- Apply linguistic filters, i.e., the linguistic patterns on useful words to be extracted such as 
terms containing the pattern (Adj | Noun)+ | (Adj | Noun), etc. Three types of application-
dependent filters is considered (Frantzi et al., 2000):  
I. Noun+Noun, 
II. (Adj|Noun)+Noun, 
III. ((Adj|Noun)+|((Adj|Noun)*(NounPrep)?)(Adj|Noun)*)Noun 
- Remove popular stop-words, non-domain terms, and high frequencies words, i.e., the 
words not to be expected to occur as real terms such as great, numerous, several, year, 
just, good, etc.  
• The statistical part: {Assigns a termhood measure, C-Value, to a candidate term “a”} 
- If “a” is not nested term, then the frequency of it and its length is computed. The longer 
term, the more important it is. The termhood is a function of length “a”. 
- Otherwise (“a” is a nested term), subtracts the weight of involving “shorter terms.” 
The formula is given in (Eq. 1), where “a” is a candidate term, f(a) is the frequency of a in 
the corpus, Ta is the set of candidate terms containing a, P(Ta) is the number of such 
candidate terms. 
 
(1) 
- The NC-value (Eq. 2) incorporates context information to C-value. A context word 
appears in the vicinity of a term in the corpus. Typically, context words are adjectives, 
nouns, and verbs that either precede or follow a shorter term. 
 
(2) 
where a is the candidate term, Ca is the set of context words of a, fa(b) denotes the 
frequency of b in the corpus, weight(b) is weight of b, a context word adjacent to a.  
However, this method may produce outliers terms- the terms that cannot characterize a document 
as an index term, or more precisely, the terms that not referring to the domain topics or theme of 
corpus information. For example, the terms “Fuzzy Systems” and “Machine Vision” refer to 
some knowledge items in the Computer Science domain, but “Defect Size” and “Test Image” do 
not. Thus, to select suitable terms, the following steps are applied:  
  
• Step 1: Non positive terms, the terms with negative or zero weights, are removed from lists. 
According to (Eq. 1), if  then the weight of compound term is zero or 
negative. This means that the sub parts of a compound term appear more frequent than the 
longer compound term. For example, the frequency of “ad hoc” is more than frequency of “ad 
hoc network”. Thus “ad hoc” has negative weight, and it is a good candidate to prune. This 
implies that the longer terms bear more knowledge than the smaller ones. 
• Step 2: The bottom 25% of terms from each list are filtered, as they appear more frequently in 
the text files and contained “non-technical” or “non-specific-research” terms for describing 
methods such as “Wide Variety”, “Future Work”, and “Generalized Approach”. 
• Step 3: The terms that are general, i.e. non-discriminant, neutralized, uninformative, and out 
of the domain, which give no sense of conception in the domain are removed. It includes 
terms that can be changed without affecting the topics. We employ domain-specific 
vocabulary of Computer Science6 to exclude the un-matching words (Kozakov et al., 2004).  
• Step 4: Variant terms in each list are aggregated based on their syntactic similarity. The 
variant terms which appear in different forms are inflectional variants (singular and plural 
variants), compounding variants (data set versus dataset), orthographic variants (terms with 
special characters such as hyphens or dashes such as object-oriented design), case-sensitive, 
misspellings (behavior versus behavior), overlapping, and abbreviations (Kozakov et al., 
2004). As an example, the term “artificial neural network” and “neural networks” are 
overlapping, and thus are aggregated to the longer term. The respected score is equal to the 
maximum value of their scores.  
 
3.2.2 Term Extraction from Formal Educations  
Our objective is to integrate the formal education subjects (topics) to other topics of scholars’ 
knowledge. It requires exploiting standard learning subjects, which are independent to the 
curriculums of academic centers. Higher education institutes typically offer very inconsistent 
curriculums in terms of course topics. For example, they offer the same course with different 
terminologies, leading to syntactic heterogeneity in topics names. Thus, we employ a full 
featured curriculum in which supplies the domain consensus terminologies of scholar’s 
knowledge. Such curriculum provides a universal, homogenous, accurate, and cleaned source of 
scholars’ formal education subjects.  
                                                           
6 http://www.springerreference.com/docs/index.html#Computer+Science-lib4 
  
We employ the ACM/IEEE Computing Curricula 2013 (Shams, Danyluk, Fincher, & Fisher, 
2013) as a reference topic collection, which provides a standard, full course based, and 
community consensus terminologies for describing the body of scholars’ knowledge (I. Liao, 
Hsu, Chen, & Chen, 2010). This curriculum is a hierarchical arrangement of courses and 
corresponding content that we refer as a representative content of scholars’ formal education. 
This curriculum consists of 18 knowledge areas, 290 cores, and 1428 respected topics and sub-
topics. Fig. 5 represents a partial view of the curriculum, representing the knowledge area 
“Intelligent Systems,” and one of its cores “Basic Search Strategies,” and the underlying 
concepts. It shows that if a researcher has studied the basic search strategies, s/he may know 
about the search algorithms (in core category), and knows the concepts such as “Problem space”, 
“Initial states”, “Goal state”, and “Heuristic search algorithm” as well. 
In order to assign weights (importance degrees) to core topics, we consider the minimum value 
of same key terms extracted from other scholar’s knowledge resources including publications 
and reading articles. For example, if a scholar has learned about “Advanced Search”, so its 
weight is equal to the minimum value of this key term appeared in his publications and/or 
reading materials. If such key term not existed, the minimum weights of all other key terms are 
assigned. 
Fig. 5: A view of formal education terminologies taken from ACM/IEEE Computing Curricula 2013 
3.2.3 Mediated Profiles 
Capturing the body of publications of full researchers in an unobtrusive manner from digital 
libraries has many limitations including authorization problem and perhaps unavailability of full 
text. Besides, extracting terms by tf*idf method will provide sparse terms and diverse research 
topics. To address these issues, we engage “mediated profiles” supplied by modern digital 
libraries. Several online digital libraries in Computer Science including CiteSeerX, ACM, 
Google Scholar, IEEEXplore, and Microsoft Academic Search (MAS) support authors’ profile or 
so-called mediated profile, which are created and updated semi-automatically. To capture rich 
scholars’ profile and tackle the access hurdle, we put all in our framework and integrate 
individual scholar’s profiles. In the following, the details of these mediated profiles are 
described:  
Cores 
Problem spaces; problem solving by search 
Brute-force search (breadth-first, depth-first, 
iterative deepening) 
Best-first search (best-first, Dijkstra’s 
algorithm A* admissibility)
Knowledge Areas 
IS/BasicSearchStrategies 
IS/KnowledgeBasedReasoning  
IS/AdvancedSearch  
Concepts 
Problem space 
States, operator, initial states, goal state 
Brute force search algorithm
  
• CiteSeerX is a free online repository, which manages the scholars’ profiles. The profile 
components are derived implicitly from researcher’s online behavior. The user profile is 
created while users search and browse the repository for locating papers of interest 
(Bollacker, Lawrence, & Giles, 1999). It minimizes the efforts of keeping up to date user 
profiles by maintaining the track of citation patterns and crawls the web to find the 
relevant papers based on the user’s keywords. The author profile encompasses homepage 
link, author’s publication, list of relevant papers (co-citations), and abstract of each 
publication. It contains about two million articles and two millions unique authors. 
• ACM maintains the Institutional Profile Page service- the basic information about the 
authors who have registered and published in ACM. The author profiles include the 
following information: 1) the list of publications where at least one author was affiliated 
with ACM at the time of publishing, 2) the subject areas, which give an overall view of 
areas that the authors have published most often, 3) the publication keywords, and 4) the 
title and abstract of author’s publications, dated between 1950 to present.  
• Google Scholar allows authors to record their own partial background knowledge 
including research interest areas and personal information. Scholars may include 
interested links to blogs, academic, and professional information. As an example, a 
portion of author’s profile may contain affiliation, research interest, and abstract of 
publications. An important feature is the automatic profile updating; metadata about the 
new papers is augmented to the profile pages, which makes the profiles precise and up to 
date. 
• Microsoft Academic Search (MAS) is a free academic library, which covers a vast 
collection of author information including more than 12 million publications and over 10 
million authors in Computer Science domain. The author’s profile encompasses the 
author’s publication list, research interests, publications’ keywords, and home page link. 
It collects the keywords automatically from publications and ranks based on the 
frequencies. 
• IEEEXplore provides authorized access to technical literature in Computer Science. It 
supports full access to abstract of articles for more than 3.2 million articles. It allows 
researchers to create professional profiles containing authors’ general information, 
homepage link, education information (employment, college, certification, etc.), and 
research areas. Registered authors can also personalize search queries by defining 
keywords of their preferences.  
Table 1 summarizes the main features of aforementioned digital libraries in terms of providing 
efficient scholars’ information. As shown, digital libraries maintain a wide spectrum of scholars’ 
information, ranging from article’s titles to full research preferences.  
Table 1: Main feature of digital libraries in terms of scholar’s information items suited for profiling 
Digital  CiteSeerX ACM Google IEEE Xplore Microsoft 
  
Library Scholar Academic Search 
Information 
Items 
Homepage  
Publication 
(Full body) 
Affiliation 
Publications (Abstracts,  
Keywords) 
Affiliation history 
Research areas 
Research keywords 
Publication 
(full text) 
Homepage  
Publications 
(Abstracts,  
Keywords) 
Research interest 
Homepage address 
Publication (full 
body) 
Detailed research 
interests 
 
However, one potential problem with such independent profile resources is the name 
ambiguities, where seeking the publication of an author’s name retrieves articles of the same 
author with different variations, or different authors with the same name (J. Huang, Ertekin, & 
Giles, 2006). To disambiguate author’s name, we consider different author’s attributes and 
calculate the similarities of authors with class of articles. Hence, two distinct similarity strategies 
are employed sequentially:  
1) The Levenshtein distance (Manning, Raghavan, & Schütze, 2009) (Eq. 3), which measures 
the lexical difference between two strings: 
 
(3) 
where i and j stand for length of strings a and b, respectively. For example, if edit distance of 
two emails is greater than a threshold value, both emails are considered “approximately” 
similar. The greater distance, the more different two strings are.  
2) The popular Jaccard measure (Borges & Lorena, 2010) (Eq. 4) for non-binary data such as 
authors’ affiliation and address attributes: 
 
(4) 
where Sa and Su are the set of textual attributes of two ambiguous authors. For instance, if 
Sa={bb,ca,ba} and Su={ab,ca,bb,ba} then Sa∩Su={ca,ba,bb}, and Sa∪Su={ab,ca,bb,ba}. 
Hence, Jaccard(a,u)=3/4=0.75. Using 0.90 or higher as a threshold would identify the similar 
authors effectively. 
 
  
To acquire the mediated profiles, we engage ArnetMiner7 web service (Tang & Zhang, 2008) as 
an extraction tool. It automatically identifies and extracts the author profiles from Web by using 
Social Network Analysis (SNA) and information extraction techniques (Tang, Zhang, & Yao, 
2007). 
3.3 Concept Unification 
Different terms which are extracted from knowledge resources are not only ambiguous but also 
in dispersed-granularity due to inconsistencies in resources, partly inherent Information Retrieval 
(IR) shortcomings, and context-dependent authors’ supplied keywords. For example, key terms 
such as “Stability”, “Optimization”, “Indexing”, and “Modeling” have no specific sense if their 
context is unspecified, which might refer to, for example, either “Document Indexing” or 
“Probabilistic Indexing”. Moreover, the authors’ supplied keywords compared to the articles’ 
keywords are in different granularity. For instance, “Approximation Algorithm” is more specific 
than “Algorithm,” in Computer Science. Thus, we apply the unification process on the retrieved 
terms to eliminate such anomalies and produce homogeneous and unambiguous terms.   
Formally, to unify the candidate terms to “clean terms” in which bearing the same granularity 
and unambiguous meaning, we define the function f over the term collection , in which maps 
each term C∈  to its semantically equivalence target term belonging to a Unified Concept Set 
(UCS): 
 
In practice, we employ Wikipedia (Nakayama, Hara, & Nishio, 2008) to treat as UCS because it 
offers domain-consensus and consistent terms for Computer Science domain, and provides 
reliable and qualified term categorization (Medelyan, Milne, Legg, & Witten, 2009). It provides 
disambiguation wiki pages, which contain the category names as well as semantically equivalent 
meaning of a target term. The function f maps each candidate term to a category name of Wiki 
page through the following steps (Mihalcea, 2007):  
1.  If there is a unique Wiki page in which entitled with the candidate term C, then the 
associated category name is chosen as Cu. For instance, term “Fitness Function” is the 
title of a Wiki page categorized by “Genetic Algorithms.” For further processing in the 
next steps, key terms within this page is retrieved as “contextual information”, which is 
used for disambiguation process. 
2.  If multiple Wiki pages have been found for a candidate term, it is treated as Word Sense 
Disambiguation (WSD) problem (Mihalcea & Csomai, 2007) and the semantic 
relatedness of such pages to the candidate term (and its neighboring terms) is calculated 
by Jaccard similarity relation (Eq. 4), and then re-ranked based on the similarity scores. 
Each Wiki page is first abstracted to its featured terms. Therefore, the title of higher 
                                                           
7 http://www.arnetminer.org 
  
ranked Wiki page is the sense of the candidate term, and therefore, the associated 
category name is selected as equivalent term Cu. For instance, the term “Training Set” is 
the title of a Wiki page, categorized by three names including “Machine Learning,” “Data 
Analysis,” “Artificial Intelligence Stubs.”  In (Eq. 4), a and u are two Wiki pages, where 
Sa and Su are the collection of corresponding Wiki pages’ terms, linking to a and u 
respectively (Li, Sun, & Datta, 2011). 
3.  If no Wiki page has been found for the candidate term, we measure the semantic distance 
of the candidate term with those neighboring terms in which had been assigned a 
category name in step 1 or 2. Thus, we employ the Jensen-Shannon divergence (JSD) 
distance (A. Huang, 2008) between those terms (represented by their context terms in 
vectors). It relies on the fact that co-occurring terms in a text are generally more similar. 
JSD is defined in (Eq. 4), where DKL is the averaged Kullback-Leibler divergence 
between p and q, and a vector of n neighboring pi words in the corpus represents each 
term p.  
 
 
(4) 
3.4 Term Clustering 
Even though we provide a unified list of key terms which represents the items of scholars’ 
background knowledge, the research focus is diverse. It happens due to two reasons: 1) change 
of research areas over time from one subject to another or, 2) a researcher may do research in 
multiple topics at the same time. As a result, relying on a list of terms for profiling leads to 
biased recommendation, i.e. the recommender system recommends articles in dispersed topics. 
Thus, it is crucial to discriminate the scholars’ knowledge into coherent topics, which might be 
partially disjoint research areas. To address this issue, we group the key terms into categories of 
semantically related terms using the induced bisecting K-mean clustering algorithm (Wartena & 
Brussee, 2008). This method is a partitional approach in which outperforms the standard K-
means as well as hierarchical approaches in terms of time complexity and quality of clusters 
(Steinbach, 2000). The clustering method is summarized as follows:  
1- Select two terms that have the largest semantic distance- the seeds of two initial clusters. 
2- The remaining terms are assigned to the nearest cluster by calculating semantic distance 
between each candidate term and the cluster’s centers. 
3- The center of both clusters is recomputed by calculating the sum of weighted terms. 
4- Repeat step 2 to 3 using the new centers until the centers are converged to a predefined 
threshold. 
  
5- If the diameter of a cluster is bigger than the threshold, the whole procedure is repeated 
recursively to each large cluster. 
To measure the distance between two terms, semantic similarity (Zhiqiang & Port, 2009) using 
the simplified Jensen-Shannon method (A. Huang, 2008) over Wikipedia is applied. 
Accordingly, if two terms appear frequently in the same Wiki page, then they are semantically 
similar (Zhiqiang & Port, 2009). For example, the terms “Cold-Start Problem” and 
“Collaborative Filtering” appear very frequently in the same Wiki page entitled “Collaborative 
Filtering”, representing semantic similarity as well as sub/super relationship. We also preserve 
this hierarchical relationship in order to facilitate the hierarchical modeling of scholars’ 
knowledge. For illustration, Fig. 6 shows each semantically similar term that have been joint to 
superiors, constructing coherent clusters. It should be noted that, however, due to multi-
disciplinary property of research topics, some terms might contribute to multiple clusters. 
Fig. 6: A clustering example of semantically related concepts. The semantically similar terms are grouped in the 
same cluster. 
4.  Experiments and Analysis 
We distinguish three types of scholars: 
- Master students who have several publications and their primitive knowledge is grounded 
on their undergraduate studies, e.g., formal education or curriculum-based learning 
- Ph.D. students who have a number of focused-topic publications 
- Full researchers who have many publications, thereby in different diverse disciplines 
Before extracting knowledge from the knowledge resources, we determined the share (degree of 
importance) of each knowledge resource for different type of scholars. Thus, we collected 
statistical data from ArnetMiner8 for 100 randomly selected researchers in three separate groups, 
and analyzed the relationship between academic degrees, publications, and education of scholar 
groups. In other words, we calculated how many papers a master student has published, what 
                                                           
8
 www.arnetminer.org 
Cold start problem 
Collaborative filtering 
Recommender Systems 
Context Aware 
recommender system
Context Aware systems
Contextual 
recommendation 
Cost-aware 
recommendation
Personalization 
Hierarchical Bayesian 
models
Bayesian network 
Data mining queries
Data mining
Association rulesMobile recommender 
system 
Clustering
  
percent of full researchers carry on research relevant to their academic degrees, and the similar 
data. Table 2 represents the statistics about scholars’ knowledge resources. As shown, reading 
articles is the main source of knowledge for all class of scholars by default, formal education is 
an additional source of knowledge for master students, and publication is a significant source of 
knowledge for full researcher. Besides, both formal educations as well as publications are the 
secondary sources of knowledge for PhD students. This analysis helps to extract effective 
knowledge pertaining to each scholar class. As an example, we extract the publication 
information but discard the formal education of full researchers. 
Table 2: The distribution of scholars’ knowledge resources on textual content 
Researchers 
Source of Knowledge 
Formal 
Education 
Number of 
Publications 
Reading 
Articles 
Reading 
Articles 
Academic 
Home Page 
Master Student >90% 0-5 100% 100% 10% 
Ph.D. student and 
Graduate Ph.D.  
65% 3-10 100% 100% 83% 
Full Researcher <5% >10 N/A 100% 100% 
4.1 Source of Data  
We applied our approach to two different groups of scholars in Computer Science: 1) a group of 
25 volunteer researchers from the Faculty of Computing at UTM9, 2) a group of 35 international 
full researchers from different academic or research centers. The members of former group are 
master and PhD students who studying in any branch of Computer Science and supplied us a 
collection of 20-25 reading articles relevant to their research topics. The second group is a subset 
of randomly selected main authors from the ArnetMiner collection who published at least ten 
papers in the past six years (2007-2012). These collections simulate the scholars’ behavior when 
they read and save interesting articles. The details of construction of these data sets can be found 
at (Amini, Ibrahim, & Othman, 2013). We finally performed a 70/30 sampling on each data set, 
where 70% of articles in each corpus which were published during 2006 to 2010 were used as 
training data (profiles) and the remaining 30% for testing. 
4.2 Term Extraction  
In the following subsections, each knowledge resource is examined, and the knowledge items or 
important terms are extracted, unified, and then clustered to produce scholars’ background 
knowledge. 
                                                           
9 http://comp.utm.my 
  
4.2.1. Articles  
At this stage, key terms from articles including “reading articles” as well as “publications” are 
extracted. We collected 20-25 articles of each participant scholar, resulting about 600 PDF 
articles, and did preprocessing on the articles to build a corpus of plain text documents for each 
scholar. We also removed uninformative parts of the articles including header and footer, figures, 
formulas, tables, acknowledgments, references, and authors’ affiliation. 
To extract the key terms, we applied the C-Value/NC-Value algorithm on the corpora using the 
JATE toolkit version 1.11  (Zhang, Brewster, & Ciravegna, 2008). It is an open source tool, 
which implements the C-Value feature extraction algorithm in Java. We run this tool under Java 
1.6, Linux Centos, and Oracle’s Virtual Machine version 4.2.6. We extracted 3750 terms on 
average from each corpus. Table 3 represents a sample of such candidate terms, which are not 
clean and contain outliers. Thus, we applied the filtering steps (1 and 2) of our methodology to 
prune outliers. Both steps reduced the terms to about 1500 on average. By applying the Step 3, 
general terms have been removed. Table 4 represents a sample of such general terms. Finally, 
Step 4 has been applied in which aggregated the similar terms based on their syntactic similarity. 
This refinement improved the quality of terms and decreased the number of input terms by 10-15 
percent. 
Table 3: A sample view of terms from a scholar’s set of article 
Terms Score Terms Score 
industrial vision 
measurement process 
dimensional metrology 
ceramic tile 
machine vision 
defect size 
percolation process 
defect detection 
56.6 
51.8 
49.7 
44.0 
37.3 
34.5 
33.1 
31.0 
neural networks 
ceramic tile surface 
test image 
fuzzy systems 
….  …   …..  
defects detection 
artificial neural network 
tile manufacturing 
17.3 
17.3 
16.6 
16.6 
… 
6.8 
6.9 
6.4 
4.2.2.  Formal Education  
As depicted in Table 2, formal education is an important source of scholars’ knowledge. Thus, 
we requested the volunteers to identify the general notion of their formal education. Then, we 
extracted the corresponding concepts (knowledge) of their formal education from the learning 
objectives of standard ACM/IEEE Computing Curricula. For instance, a researcher who has 
identified his education in three subfields such as Parallel Computation, Software Design, and 
Software Verification, we extracted the corresponding concepts of respected core subjects. 
  
However, there are many irrelevant (unimportant) concepts in the scholars’ knowledge of Master 
and PhD levels. Thus, we applied two intuitive filtering rules to eliminate them:  
1- Exclude very general knowledge of the domain based on the associated tags including 
Definitions, Applications, Programming Skills, Introductions, and Hardware. 
2- Remove each subject topic under the tag “undergraduate program”. 
Table 5 represents a sample of extracted key terms from this curricula corresponding to the 
participant’s formal education. Each column also shows the concepts of scholar’s knowledge in 
its subfield of formal education. 
Table 4: A sample of general and non discriminant terms in the Computer Science 
domain 
image size 
number of particles 
output layer 
number of hidden 
total responses 
experimental results 
results show 
real world 
efficiency of 
input data 
examples of 
experimental results 
interference and 
total number 
key index 
large number of 
sample size 
nodes 
feed forward 
shown in fig 
many research 
Moreover, in order to assign appropriate weight (importance degree) to individual key terms, we 
look up the key terms of reading articles of respected scholars. If similar key term has been 
matched, corresponding score is assigned to the target key term. Otherwise, the minimum score 
of key terms in reading articles is assigned to the target key terms. It should be noted that, 
however, these scores are an estimation of scholar’s education knowledge, and the dynamic 
nature of profiling process will adjust the scores over time. 
Table 5: A sample of terminologies extracted from the core topics of a scholar’s formal education 
Parallel Computation Software Design  Software Verification  
Caching and coherence 
Data parallelism 
Event parallelism 
Properties of computation 
Message passing 
Parallel software architectures 
Design patterns 
Software architecture 
Structured design 
Object-oriented analysis 
Component-level design 
Design qualities 
Verification and validation 
Validation planning 
Test plan, test case generation  
Defect seeding 
Systems testing 
Object-oriented testing  
  
Event driven techniques 
Threading 
Parallel architectures 
Multi-core process 
Memory systems 
Clusters 
Internal including low coupling  
High cohesion 
Information hiding 
Object-oriented design 
Fault logging 
Regression testing 
Inspections, reviews, audits 
Black-box testing 
White-box testing 
Fault tracking 
4.2.3. Mediated Profiles 
To acquire the mediated profiles of second group of scholars, we engaged ArnetMiner. We 
exploited the authors’ information in ArnetMiner as an identifier to digital libraries mentioned in 
Section 3.2.3 for retrieving the abstract of publications and the researcher’s information. To 
tackle name ambiguity, the disambiguation (reconciliation) algorithm in (Eq. 3) is applied. We 
focused on research interests’ parts and key words of recent publications dated between 2007 and 
2012. However, since such key terms have different significance to scholars’ knowledge and 
lack of weight values, we assigned an intuitive weight by following steps to individual terms in 
which approximate the C-Value:  
1. Value 10 is assigned to key terms of publication year 2012, value 9 to key terms of year 
2011, and former values to other publications down to year 2007 decreasingly. 
2. The key terms which are repeating or similar (either semantically or syntactically) are 
reduced to common terms and the summation of corresponding weights is assigned. 
3. The values are then normalized to base value 100 by dividing each value to the total 
summation of weights. 
Finally, the clustering method (described in Section 3.4) is applied. Table 6 represents three 
research areas of a full researcher, retrieved from the aforementioned knowledge resources. The 
parenthesized number beneath the names of researcher indicates the total key terms in time 
horizon and the number of associated clusters, respectively. As shown, the scholar has different 
concurrent research areas since plays two roles as either author or co-author in different research. 
Hence, the scholar profiles contain multiple topics, which represent the background knowledge 
in several research areas. The result of this data analysis contains 3090 key terms in total and 88 
key terms on average for each researcher.  
Table 6: Sample key terms of three research areas, retrieved from scholar’s knowledge resources 
Scholar Research Area 1 Research Area 2 Research Area 3 
R. Studer 
(91,7) 
complex event processing 
energy efficiency 
intelligent complex event processing 
argumentation technology  
deductive databases 
domain modeling 
domain adaptation 
knowledge management 
multilingual 
  
office occupancy control  
semantic technology  
smart office 
energy consumption in commercial buildings 
efficient energy consumption 
icep framework 
 
dynamic logic 
human centered computing 
knowledge acquisition 
knowledge engineering 
knowledge frame 
knowledge meta process 
knowledge process 
knowledge representation 
logic programming 
Prototyping, Semantic Web 
natural language for dke 
natural language interfaces 
natural language processing 
ontologies   
ontology evolution 
ontology mapping 
ontology registry 
ontology learning  
ontology reuse 
lightweight semantic models  
wikipedia 
5.  Evaluation 
The goal of evaluation is to measure the quality of key terms thru two dimensions: by scholar 
assessment and a quality-based metrics called “relative entropy” (A. Huang, 2008), which 
measures the correspondence of key terms to a base baseline model. 
For the first measure, individual scholars assessed their own extracted terms and qualitatively 
measured each term in a 3-point scale as “Correct,” “Incorrect,” or “Missing”. Fig. 7 represents 
the participant’s feedback in terms of F1-Score, where F1=2*Pr*Rc/(Pr+Rc) in which Pr and Rc 
stand for precision and recall, respectively. As shown, average score is 82%, and the minimum 
and maximum values are 72% and 90%, respectively.  
For the second group of scholars, we did evaluation based on the “relative entropy” which 
measures the pair wise similarity or “relevance level” between two distributions. We calculated 
this metric over two sets of key terms: 1) the topics of scholars’ background knowledge or {Ti, 
i=1..k}, 2) the body of simplified publication of individual scholars (including abstracts, title, and 
keywords), which were available free and demonstrated the fundamental parts of scholars’ 
publications. We first transformed the simplified publications into the equivalent topics, {Ti*, 
i=1..k}, using C-value/NC-value method, and then calculated the distance between the two sets. 
The set of former topics treats as a benchmark or baseline model for evaluation purpose.  
  
 
Fig. 7: The distribution of  F1-score based on the rating of 25 volunteer scholars (Si) on key terms 
To measure the distance between two distribution, the Averaged Kullback-Leibler Divergence 
(AKLD) (A. Huang, 2008) has been used, which measures the distance (differences) between 
two probability distributions, i.e., the inverse relevance level of two term sets. The relevance 
level of clusters determines to which extent the terms of {Ti*} are the members of {Ti}. The 
AKLD relation is given in (Eq. 5), where P and Q are two term distributions. DAvgKL is greater 
or equal to zero, which zero indicates the minimum distance, or inversely, the highest relevance 
level. For the sake of simplicity, we inversed the distance to similarity measure of scale 10. 
 
 
 
(5) 
Fig. 8 represents the relative entropy between sets {Ti} and {Ti*}. As shown, on average 
(86.5%) key terms of the simplified publications are similar to the scholars’ key terms. The 
dissimilarity influenced by different factors including: 1) the engagement of abstract part of 
publications instead of full text, due to unavailability of full text articles, 2) unavailability of 
authors’ keywords of some indexed publications, 3) nonoccurrence of authors’ keywords in the 
abstract publication, and 4) the inherit differences in weighing schemes of the two term sets. 
6.  Discussion 
We started this study with two main questions: First, what are the basic elements of scholar’s 
background knowledge, and second, how can we extract the knowledge items from the 
knowledge resources unobtrusively. We further refined the research questions with respect to the 
application of profiling for recommender system as follows:  
• What knowledge resource best describes the scholars’ knowledge? 
  
• How scholars’ information can be effectively captured and transformed to knowledge 
items? 
• How different heterogeneous knowledge items can be integrated?  
Fig. 8: The relative entropy between two distributions of key terms, {Ti} and {Ti*} 
Regarding these questions, we analyze our approach in different dimensions: First, in order to 
capture the scholars’ background knowledge, we investigated the scholars’ domain and identified 
rich available knowledge resources. Second, we employed different approaches to extract 
knowledge items from each resource. Third, knowledge acquisition had been effectively 
addressed the challenges of term extraction through the following features: 
1- Non-intrusive extraction: the task of knowledge acquisition from knowledge resources 
including studied articles, scholars’ publications, and homepages is a non-intrusive 
approach since it does not interfere with the normal task of researchers. Besides, we re-
used the mediated scholars’ profiles supplied by digital libraries. 
2- Addressing knowledge heterogeneity: since the key terms have been extracted from 
independent and autonomous knowledge resource, heterogeneity to some extent exists. 
Wikipedia as well as ACM/IEEE curricula have been engaged to tackle the syntactic and 
semantic heterogeneity among the key terms. Wikipedia helped to substitute the 
ambiguous terms with unified and decisive terms. 
3- Multiple focus of the scholar’s research: since full researchers contribute to different 
research at the same time, often in different topics, we employed clustering method to 
discriminate the independent and overlapping research areas. In our approach, shared 
terms are assigned with different weights to distinguish the importance of terms in 
different research topics.  
4- Multidisciplinary of research areas: our approach is independent of the researchers’ 
fields as it captures the key terms using statistical and linguistic methods, regardless of 
the knowledge resources in the domain. The analysis of the extracted terms shows that a 
great number of key terms are relevant to separate fields of research. 
  
Additionally, the comparison of our approach with the related works demonstrates some 
improvement. As shown in Table 7, the most significant improvements produced by our 
approach are the engagement of professional scholars’ knowledge, implicit and non-intrusive 
knowledge extraction from the Web, i.e., academic social network (ArnetMiner) as well as the 
mediated scholar profiles. Moreover, we unified and consolidated a large number of key terms, 
extracted from the knowledge resources by means of Wikipedia. 
7.  Extensions and Future Work  
Our proposed framework is flexible enough to incorporate more knowledge resources. Yet other 
potential knowledge resources for scholars’ profiling are search queries, click streams, and 
metadata in digital libraries such as subject catalogues, and borrowing articles’ history (Vellino 
& Zeber, 2007). These resources seem crude and need intelligent applications (Batyrshin & 
Gonzalez-Mendoza, 2014) and Natural Language Processing techniques (Sidorov, Velasquez, 
Stamatatos, Gelbukh, & Chanona-Hernández, 2014) to discover pattern of data, interlink 
individual items to produce knowledge items, and dealing with new heterogeneities. 
Table 7: Comparison of referenced works with our approach 
Work Features Similarities Improvements 
(Lopes et 
al., 2007) 
Explicit knowledge 
extraction, limited type of 
knowledge (user’s CV), 
intrusive interaction 
Implicit meta-data extraction 
from the articles retrieved by 
digital library 
Use of full publication content as well 
as formal education, nonintrusive and 
pure knowledge extraction 
(S. Liao et 
al., 2009) 
Type of data (library 
cataloging system versus 
ACM/IEEE classification) 
Using pre-built ontological 
concepts, online data 
Use of live/dynamic thesaurus 
information (Wikipedia),  substitution 
of semantically similar terms, full 
content document analysis,  
nonintrusive knowledge extraction 
(Vellino & 
Zeber, 
2007) 
Explicit extraction of user 
knowledge 
Implicit extraction of user 
knowledge, using 
collaborative information 
Implicit knowledge extraction from the 
prebuilt Mediated profiles 
(Kodakateri 
et al., 2009) 
Concerns on general users of 
CiteSeerX and uses the ACM  
classification information 
Extraction of concepts from 
the visited (studied) 
documents 
Engage of  several digital libraries as a 
source of knowledge including ACM, 
IEEEXplore, MAS, Google Scholar, 
uses extended DL’s information 
(mediated profiles) 
(Yao et al., 
2007) 
Use of networked 
information,  extending 
FOAF ontology 
Extracting the general 
information of  scholars from 
their homepage by analyzing 
social data 
Re-use of rich social network 
information (ArnetMiner), applies 
statistical and language content analysis 
versus  probabilistic analysis, key 
phrase extraction from the publication 
  
Other sources of scholars’ knowledge in academic discipline are blogs and online notes (Zhou, 
Xu, Li, & Josang, 2012), which encompass the recent scholars’ concerns, professional interests, 
and clues of researcher knowledge. Context reasoning techniques (Strobbe, Van Laere, Dhoedt, 
De Turck, & Demeester, 2011) as well as pervasive computing approaches (Haghighi, 
Krishnaswamy, & Zaslavsky, 2008) may help to analyze the content of scholars and extract the 
knowledge items in dynamic and pervasive environments.  
Furthermore, social networks information, Linked Open Data (LOD) (Curé, 2014), and 
alternative digital libraries including Pronetos, Academici, ArXiv, Inspec, or TDG Scholar, 
which provide mediated profiles can be incorporated in our framework. 
However, one potential challenge that should be addressed is that some researchers from 
disciplines such as Mathematics or Electrical Engineering do research in the fields of Computer 
Sciences, and therefore, the knowledge of formal education is not effective for profiling. One 
potential solution is to span exhaustively the boundary of formal education beyond the Computer 
Science to contain every relevant domain and incorporate pertaining subjects to reference model. 
8.  Conclusion  
In this paper, we presented an unobtrusive approach to capture scholars’ background knowledge 
effectively by employing statistical information extraction approaches, mediated profiles, and 
knowledge unification approaches. Our approach collected and integrated an extensive collection 
of knowledge items from different independent resources. Since the integration of disparate 
items is always a challenging task, Wikipedia was employed which effectively disambiguated 
and substituted the poor key terms. As the area of scholar’s research is varied and changing over 
time, a clustering solution was applied to discriminate the scholars’ active knowledge areas. We 
also exploited mediated profiles, which are supplied by some digital libraries. Compared to the 
state-of-the-art, our approach exposes a significant improvement in terms of F-Score in feature 
extraction, reuse of mediated profiles, and semantic integration of heterogeneous knowledge. 
Acknowledgement 
The authors would thank Dr. Stuart Middleton from IT Innovation Centre, University of 
Southampton for his collaboration and assistance. 
References 
content 
(Sugiyama 
& Kan, 
2010) 
Extracts information from 
scholars’ recent publications, 
citations, and reference 
papers,  tf*idf  weighting 
scheme 
Construction of feature vector 
from the scholars’ 
publications, non-intrusive 
manner 
Use of C-Value/NC-Value for feature 
vectors representation, utilization of 
pre-built scholars profiles and the 
semantic relatedness between key terms 
(versus keywords), clustering of 
scholars’ knowledge into relevant 
research topics 
  
Amini, B., Ibrahim, R., & Othman, M. S. (2013). Data Sets for Offline Evaluation of Scholar ’ s 
Recommender System. In Lecture Notes in Computer Science, pp. 158–167. 
Amini, B., Ibrahim, R., Othman, M. S., & Rastegari, H. (2011). Incorporating Scholar’s Background 
Knowledge into Recommender System for Digital Libraries. In 5th Malaysian Conference in 
Software Engineering (MySEC’11), pp. 516–523. 
Batyrshin, I., & Gonzalez-Mendoza, M. (2014). Methods and applications of artificial and computational 
intelligence. Expert Systems with Applications, 41(3), 779–780. doi:10.1016/j.eswa.2013.08.007 
Bilchev, G., & Marston, D. (2003). Personalised advertising -exploiting the distributed user profile. BT 
Technology Journal, 21(1), 84–90. 
Bitonto, P. Di, Laterza, M., & Roselli, T. (n.d.). Peer Reviewed Papers A recommendation method for e-
learning environments: the rule-based technique, 6(September 2010), 31–40. 
Bollacker, K. D., Lawrence, S., & Giles, C. L. (1999). A System For Automatic Personalized Tracking of 
Scientific Literature on the Web. Spring, 105–113. 
Borges, H. L., & Lorena, A. C. (2010). A Survey on Recommender Systems for News Data. Knowledge 
Creation Diffusion Utilization, 129–151. 
Brickley, D., & Miller, L. (2010). FOAF Vocabulary Specification, Namespace Document. Retrieved 
from http://xmlns.com/foaf/spec/ 
British Colombia. (2005). Essential Use Case Modling Standards and Guidlines. IM / IT Standards & 
Guidelines (pp. 1–14). 
Cimiano, P. (2005). Learning Concept Hierarchies from Text Corpora using Formal Concept Analysis. 
Data Engineering, 24, 305–339. 
Craven, M., Dipasquo, D., & Freitag, D. (1998). Learning to Extract Symbolic Knowledge from the 
World Wide Web. In National Conference on Artificial Intelligence - AAAI, pp. 509–516. 
Curé, O. (2014). On the design of a self-medication web application built on linked open data. Web 
Semantics: Science, Services and Agents on the World Wide Web, 24, 27–32. 
doi:10.1016/j.websem.2013.12.001 
D.Manning, C., & Schütze, H. (1999). Foundations of Statistical Natural Language Processing.pdf (pp. 
117–148). 
Das, S., Giles, C. L., & Mitra, P. (2011). On Identifying Academic Homepages for Digital Libraries. In 
Proceedings of the ACM/IEEE Joint Conference on Digital Libraries, pp. 123–132. Ontario, 
Canada: ACM. 
  
Devedžić, V. (2006). PERSONALIZATION ISSUES. In Semantic Web and Education (pp. 175–219). 
Springer Berlin / Heidelberg. doi:10.1007/978-0-387-35417-0_6 
Eric, B. (1992). A Simple Rule-Based Part of Speech Tagger. In Applied Natural Language Processing, 
pp. 152–155. 
Eyharabide, V., & Amandi, A. (2011). Ontology-based user profile learning. Applied Intelligence, 36(4), 
2012. doi:10.1007/s10489-011-0301-4 
Frantzi, K., Ananiadou, S., & Mima, H. (2000). Automatic Recognition of Multi-Word Terms: the C-
value/NC-value Method. International Journal on Digital Libraries, Springer, 3(2), 115–130. 
Gagne, R. M. (2000). Learning Hierarchies. In Learning Hierarchies (Vol. 2, pp. 63–84). 
Gauch, S., Speretta, M., Chandramouli, A., & Micarelli, A. (2007). User Profiles for Personalized 
Information Access. In The Adaptive Web, LNCS 4321 (pp. 54–89). 
Haghighi, P. D., Krishnaswamy, S., & Zaslavsky, A. (2008). Reasoning about Context in Uncertain 
Pervasive. In EuroSSC 2008, LNCS 5279, pp. 112–125. Springer Berlin / Heidelberg. 
Huang, A. (2008). Similarity Measures for Text Document Clustering. In NZCSRSC 2008, pp. 49–56. 
Huang, J., Ertekin, S., & Giles, C. L. (2006). Efficient Name Disambiguation for Large-Scale Databases. 
In PKDD 2006, LNAI 4213, pp. 536–544. Springer-Verlag Berlin Heidelberg. 
Kodakateri, A., Gauch, S., Luong, H., & Eno, J. (2009). Conceptual Recommender System for CiteSeerX. 
In RecSys’09, pp. 241–244. NY, USA: ACM. 
Kozakov, L., Park, Y., Fin, T., & Drissi, Y. (2004). Glossary extraction and utilization in the information 
search and delivery system for IBM Technical Support. IBM SYSTEMS JOURNAL, 43(3), 546–563. 
Lafferty, J., McCallum, A., & Pereira, F. (1999). Conditional Random Fields: Probabilistic Models for 
Segmenting and Labeling Sequence Data. In 18th International Conf. on Machine Learning, pp. 
282–289. Morgan Kaufmann. 
Li, C., Sun, A., & Datta, A. (2011). A Generalized Method for Word Sense Disambiguation based on 
Wikipedia. In Advances in Information Retrieval Proceedings ECIR2011 (Vol. 6611, pp. 653–664). 
Liang, T., Yang, Y., Chen, D., & Ku, Y. (2008). A semantic-expansion approach to personalized 
knowledge recommendation. Elevier, Decision Support Systems, 45(3), 401–412. 
doi:10.1016/j.dss.2007.05.004 
Liao, I., Hsu, W., Chen, M.-S., & Chen, L. (2010). A library recommender system based on a personal 
ontology model and collaborative filtering technique for English collections. Emeral Group 
Publishing, 28(3), 386–400. doi:10.1108/02640471011051972 
  
Liao, S., Kao, K., Liao, I., & Chen, H. (2009). PORE: a personal ontology recommender system for 
digital libraries. Emerald, 27(3), 496–508. doi:10.1108/02640470910966925 
Lopes, G. R., Martins Souto, M. A., Krug Wives, L., & Moreira de Oliveira, J. P. (2007). A Personalized 
Recommender System for Digital Libraries. In WebMedia’08 Proceedings of the 14th Brazilian 
Symposium on Multimedia and the Web, pp. 59–66. 
Manning, C., Raghavan, P., & Schütze, H. (2009). An Introduction to Information Retrieval. Online. 
Cambridge University Press. 
Marcus, M., Kim, G., Marcinkiewicz, M. A., Macintyre, R., Bies, A., Ferguson, M., … Schasberger, B. 
(1994). The Penn TREEBANK: Annotating predicate argument structure. In ARPA Human 
Language Technology Workshop (HLT’94), pp. 114–119. 
Matsuo, Y., & Ishizuka, M. (2003). Keyword Extraction from a Single Document using Word Co-
occurrence Statistical Information. Journal, International Tools, Artificial Intelligence Scientific, 
13(01), 157–169. 
Medelyan, O., Milne, D., Legg, C., & Witten, I. H. (2009). Mining meaning from Wikipedia. Journal of 
Human Computer Studies, 67(9), 716–754. doi:10.1016/j.ijhcs.2009.05.004 
Medelyan, O., Witten, I. H., & Milne, D. (2008). Topic Indexing with Wikipedia. In Proceedings of AAAI 
Workshop on Wikipedia and Artificial Intelligence: an Evolving Synergy, pp. 19–24. 
Middleton, S. E., Roure, D. C. De, & Shadbolt, N. R. (2001). Capturing knowledge of user preferences: 
ontologies in recommender systems. In International Conference on Knowledge Capture - K-CAP, 
pp. 100–107. 
Middleton, S. E., Roure, D. De, & Shadbolt, N. R. (2009). Ontology-Based Recommender Systems. In 
Handbook on Ontologies, International Handbooks on Information Systems (pp. 779–796). 
doi:10.1007/978-3-540-92673-3 
Mihalcea, R. (2007). Using Wikipedia for Automatic Word Sense Disambiguation. In Proceedings of the 
Conference of NAACL’07, pp. 196–203. 
Mihalcea, R., & Csomai, A. (2007). Wikify! Linking Documents to Encyclopedic Knowledge. In 
CIKM’07, pp. 1–9. Lisboa, Portugal: ACM. 
Nakayama, K., Hara, T., & Nishio, S. (2008). A Search Engine for Browsing the Wikipedia Thesaurus. In 
Database Systems for Advanced Applications (LNCS 4947) (pp. 690–693). India: Springer. 
Piao, S., Forth, J., Gacitua, R., Whittle, J., & Wiggins, G. (2010). Evaluating Tools for Automatic 
Concept Extraction: a Case Study from the Musicology Domain. In Proceedings of The Digital 
Economy All Hands Meeting - Digital Futures 2010 Conference, pp. 1–3. Nottingham, UK. 
  
Salton, G., Wong, A., & Yang, C. S. (1975). A Vector Space Model for Automatic Indexing. 
Communications of the ACM, 18(11), 613–620. 
Schiaffino, S. N., & Amandi, A. (2000). User profiling with Case-Based Reasoning and Bayesian 
Networks. In Open Discussion Track Proceedings-IBERAMIA-SBIA 2000, pp. 12–21. ACM. 
Sclano, F., & Velardi, P. (2007). TermExtractor: a Web Application to Learn the Common Terminology 
of Interest Groups and Research Communities. In C. E. R. Dieng-Kuntz (Ed.), Conférence TIA-
2007, pp. 8–9. Presses Universitaires de Grenoble. 
Shams, M., Danyluk, A., Fincher, S., & Fisher, K. (2013). Computer Science Curricula 2013, Ironman 
Draft (Version 1.0). Computer (pp. 50–199). 
Sidorov, G., Velasquez, F., Stamatatos, E., Gelbukh, A., & Chanona-Hernández, L. (2014). Syntactic N-
grams as machine learning features for natural language processing. Expert Systems with 
Applications, 41(3), 853–860. doi:10.1016/j.eswa.2013.08.015 
Steinbach, M. (2000). A Comparison of Document Clustering Techniques. In KDD workshop on text 
mining (2000), pp. 1–20. 
Strobbe, M., Van Laere, O., Dhoedt, B., De Turck, F., & Demeester, P. (2011). Hybrid reasoning 
technique for improving context-aware applications. Knowledge and Information Systems 
(Springer), 31(3), 581–616. doi:10.1007/s10115-011-0411-7 
Sugiyama, K., & Kan, M. (2010). Scholarly Paper Recommendation via User’ s Recent Research 
Interests. In JCDL’10, pp. 29–38. 
Sugiyama, K., & Ken, M.-Y. (2011). Serendipitous Recommendation for Scholarly Papers. In JCDL’11, 
pp. 307–310. Ontario, Canada: ACM. 
Tang, J., Zhang, D., & Yao, L. (2007). Social Network Extraction of Academic Researchers. In 7th IEEE 
International Conference on Data Mining (ICDM 2007), pp. 292–301. 
Tang, J., & Zhang, J. (2008). ArnetMiner: Extraction and Mining of Academic Social Networks. 
KDD’08, 990–998. 
Uchyigit, G. (2009). Semantically Enhanced Web Personalization. Group, 25–43. 
Vellino, A., & Zeber, D. (2007). A Hybrid, Multi-Dimensional Recommender for Journal Articles in a 
Scientific Digital Library. In Proceedings of the 2007 IEEE/WIC/ACM, pp. 111–114. 
Wartena, C., & Brussee, R. (2008). Topic Detection by Clustering Keywords. In Database and Expert 
Systems Applications - DEXA’08, pp. 54–58. 
  
Weiss, S. M., Indurkhya, N., Zhang, T., & Damerau, F. J. (2010). Information Retrieval and Text Mining. 
In Fundamentals of Predictive Text Mining, Texts in Computer Science (pp. 75–90). 
doi:10.1007/978-1-84996-226-1 
Yao, L., Tang, J., & Li, J. (2007). A Unified Approach to Researcher Profiling. In IEEE Computer 
Society, pp. 359–365. doi:10.1109/WI.2007.60 
Zhang, Z., Brewster, C., & Ciravegna, F. (2008). A Comparative Evaluation of Term Recognition 
Algorithms. In The sixth international conference on Language Resources and Evaluation, (LREC 
2008). Marrakech, Morocco. 
Zhiqiang, L., & Port, R. (2009). Measuring Semantic Similarity between Words Using Wikipedia. In 
International Conference on Web Information Systems and Mining, pp. 251–255. 
doi:10.1109/WISM.2009.59 
Zhou, X., Xu, Y., Li, Y., & Josang, A. (2012). The State-of-the-Art in Personalized Recommender 
Systems for Social Networking. In Artificial Intelligence Review (pp. 119–132). Springer. 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
Highlights 
 
• We examine appropriate knowledge resources for profiling scholars’ background knowledge. 
• We discuss how knowledge items can be unobtrusively captured from knowledge resources. 
• We represent how heterogeneity among different knowledge resources is resolved. 
• We model scholars’ academic knowledge by collecting knowledge items from mediated profiles 
in digital libraries. 
• We unify the scholars’ knowledge items by Wikipedia.  
 
 
 
