Übungsarbeit
Information Search and Retrieval
Technische Universität Graz
WS 2006
Automatische Erkennung von
Plagiaten in Textdokumenten
Einführung, Methoden und Anwendungen
Ulrich Wirleitner
Technische Universität Graz, Österreich
ulrich.wirleitner@tugraz.at
Magdalena Lauber
Technische Universität Graz, Österreich
magdalena.lauber@student.tugraz.at
Lorenz Strouhal
Technische Universität Graz, Österreich
ls1.gmx.at
Betreuer
Dipl.-Ing. Dr.techn. Christian GÜTL
Institute for Information Systems and Computer Media (IICM), Austria
cguetl@iicm.edu and cguetl@acm.org
Copyright (C) 2006 [Lauber, Strouhal, Wirleitner].
Dieses Werk kann durch jedermann gemäß den Bestimmungen der Lizenz für
Freie Inhalte genutzt werden.
Die Lizenzbedingungen können unter http://www.uvm.nrw.de/opencontent
abgerufen oder bei der Geschäftsstelle des Kompetenznetzwerkes
Universitätsverbund MultiMedia NRW, Universitätsstraße 11, D-58097 Hagen,
schriftlich angefordert werden.
Automatische Erkennung von Plagiaten in
Textdokumenten
Ulrich Wirleitner
(Technische Universität Graz, Österreich
ulrich.wirleitner@tugraz.at)
Magdalena Lauber
(Technische Universität Graz, Österreich
magdalena.lauber@student.tugraz.at)
Lorenz Strouhal
(Technische Universität Graz, Österreich
ls1.gmx.at)
Kurzfassung: Durch die neuen Rahmenbedingungen des Computerzeitalters ist es
sehr einfach geworden Plagiate, im Besonderen Textplagiate zu erstellen. Dieser Um-
stand hat die Notwendigkeit für neue, automatisierte und unterstützende Software-
methoden zur Detektion von Plagiaten notwendig gemacht. Diese Arbeit soll eine
Einführung in die Problematik bieten und einige Ansätze liefern, die eine Unterschei-
dung zwischen Originaltext und unrechtmäßiger Verwendung bzw. Kopie ermöglichen
sollen.
Abstract: Because of the new conditions derived from the computer age it is very
easy to produce plagiarism, especially plagiarism of texts. Due to this reason there
exists an increasing necessity for new automated and supporting software methods for
plagiarism detection. This term paper provides an overview of the area, as well as an
introduction to some methods used for detecting wheter or not a specific paper was
authored committing a breach of regulations or making illegal use of sources.
Schlüsselworte: Plagiat, Plagiatserkennung, Ähnlichkeitserkennung, Stilometrie
Kategorie: I.5.4 [Pattern Recognition]: Applications – Text processing; J.5 [Arts and
Humanities]: Linguistics; K.4.1 [Computers and Society]: Public Policy Issues – In-
tellectual property rights, ethics; K.3.1 [Computers and Education]: Computer Uses
in Education; K.3.2 [Computers and Education]: Computer and Information Science
Education;
2
Inhaltsverzeichnis
1 Einleitung . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4
2 Übersicht und Definition . . . . . . . . . . . . . . . . . . . . . . . . . . . 4
2.1 Was ist ein Plagiat? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5
2.2 Plagiatstypen . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6
3 Methoden zum Erkennen von Plagiaten . . . . . . . . . . . . . . . . . . 8
3.1 Triviale Methoden . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8
3.2 Komplexe Methoden . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9
3.3 Fingerprinting . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9
3.4 Alternative Methoden . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13
4 Plagiarismus im Bereich der Software–Entwicklung . . . . . . . . . . 13
4.1 Was gilt als Plagiat im Gebiet des Software–Engineering? . . . . . . . . 13
4.2 Beispiel für eine Grenzsituation . . . . . . . . . . . . . . . . . . . . . . . 14
4.3 Code Similarity Analyzers . . . . . . . . . . . . . . . . . . . . . . . . . . 14
4.4 Eigenschaften von Copy-Detection Algorithmen . . . . . . . . . . . . . . 15
4.5 Ansätze für Plagiat–Detektion von Sourcecode . . . . . . . . . . . . . . 15
5 Schwierigkeiten bei der Plagiatserkennung und Messung der De-
tektionsperformance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17
5.1 Falsch–Positiv Detektion . . . . . . . . . . . . . . . . . . . . . . . . . . 18
5.2 Falsch–Negativ Detektion . . . . . . . . . . . . . . . . . . . . . . . . . . 18
5.3 Messung der Detektions–Performance . . . . . . . . . . . . . . . . . . . 18
6 Werkzeuge zum Erkennen von Plagiaten . . . . . . . . . . . . . . . . . 18
6.1 Kommerzielle Lösungen . . . . . . . . . . . . . . . . . . . . . . . . . . . 19
6.2 Frei verfügbare Tools . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24
6.3 Gegenüberstellung . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25
7 Zusammenfassung und Ausblick . . . . . . . . . . . . . . . . . . . . . . . 26
Literatur . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28
Abbildungsverzeichnis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30
Tabellenverzeichnis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30
3
1 Einleitung
Einhergehend mit dem Zugang der Computertechnik für die Allgemeinheit wurde
auch die einfache Kopierbarkeit von Daten ermöglicht. Für jedermann verfügba-
re Netzwerke –wie das Internet– haben den leichten Zugriff auf Inhalte ver-
schiedenster Art ermöglicht. Dies hat neben vielen Vorteilen auch Schattensei-
ten mit sich gebracht. Denn es wurde damit unter anderem auch gleichzeitig
ermöglicht, sehr einfach, schnell und unkompliziert Plagiate zu erstellen. Ob
Plagiate nun von der Gesellschaft geächtet oder akzeptiert werden mag ein eige-
nes Thema sein. Tatsache ist, dass Plagiate durch die neuen Möglichkeiten stark
zugenommen haben. Im akademischen Bereich, wo Plagiate wohl unbestritten
unerwünscht sind, sind die Zahlen alarmierend [CIA Research 2005]. Zudem hat
das illegitime Verwenden anderer Quellen eine neue Stufe hinsichtlich der Qua-
lität erreicht – Original und Kopie können unter Umständen vollständig ununter-
scheidbar sein. Zusammen mit dem quantitativ hohen Vorkommen von Plagiaten
ist es zu einem Problem mit bisher unbekanntem Ausmaß geworden. Ein Aus-
maß, das dem menschlichen Begutachter nur mehr mit sehr viel Aufwand ein
kopiertes Werk von einem original verfasstem Werk unterscheiden lässt.
Es sind daher automatisierte, unterstützende Werkzeuge gefragt, welche den Be-
gutachter bei der Erkennung von Plagiaten unterstützen. In dieser Arbeit soll im
Speziellen die automatisierte Detektion von Textplagiaten behandelt werden. Als
Text soll in dieser Arbeit folgendes definiert sein: Erstens Text, verfasst in einer
natürlichen Sprache wie beispielsweise in wissenschaftlichen Arbeiten, Internet-
Inhalte und Bücher. Und zweitens Computer-Quelltext, Computer-Sprachen und
Algorithmen.
2 Übersicht und Definition
Bevor noch geeignete Methoden zur Plagiatserkennung entworfen werden können,
ist eine ausführliche Analyse notwendig welche Merkmale ein Plagiat als solches
kennzeichnen. Neben einer möglichst genauen Definition des Begriffes ”Plagiat“,
müssen die unterschiedlichen Arten und Typen von Plagiaten festgestellt wer-
den. Es muss die Grenze zwischen einem Plagiat und der legalen Verwendung
dritter Quellen definiert werden. Umso mehr Hintergrundwissen über Plagiate
existiert, umso besser können diese auch erkannt werden –wobei natürlich eine
zweifelsfreie, eindeutige Erkennnung angestrebt wird.
Die Bandbreite von Text–Plagiaten reicht angefangen von einer 1:1–Kopie –
bei der sich der Text mit dem Original vollkommen gleicht– bis hin zum par-
tiellen Übernehmen von Konzepten und Ideen mit eigenen Worten und Sätzen.
Nahezu analog dazu verhaltet sich die Komplexität der Methoden, welche Pla-
giate erkennen sollen. So ist es nicht sonderlich schwierig eine 1:1–Kopie, auch
4
wenn diese nur einen Teil einer Arbeit ausmacht, zu entlarven. Es kann aber
unter Umständen sehr schwierig bis nahezu unmöglich sein, Plagiate zweifelsfrei
zu erkennen. Dies ist beispielsweise dann der Fall, wenn Ideen, Konzepte und
Inhalte in nur geringfügigem Ausmaß und ggf. leicht abgeändert übernommen
wurden. Auch sind in manchen Fällen die Grenzen zwischen Plagiat und legi-
timer Verwendung von Quellen anderer Herkunft nicht immer völlig eindeutig
definiert bzw. nicht leicht unterscheidbar –beispielsweise koexistieren verschie-
dene mehr oder weniger strenge Regulierungen (sog. ”Policies“) zur Definition
von Plagiaten. Beispielsweise geben im akademischen Bereich und bei wissen-
schaftlichen Arbeiten die jeweilige Universität oder die Zeitschriften, welche die
Arbeiten veröffentlichen, üblicherweise eigene Richtlinien dazu an wie in Kapitel
2.1.1 angegeben. Trotzdem können die Erkennungsmethoden auch als Hinweis–
Werkzeug für eine weitere –manuelle– Begutachtung dienen. Natürlich macht
es einen Unterschied, ob die Art des Plagiates Gesetze, Richtlinen verletzt oder
unter Umständen ”nur“ aus ethischer Sichtweise bedenklich ist. Diese Diskussi-
on ist aber nicht Gegenstand dieser Arbeit – hier sollen mögliche Methoden zur
Erkennung vorgestellt werden.
2.1 Was ist ein Plagiat?
Es gibt mehrere Definitionen des Plagiatsbegriffes. Einig sind sich die viele Quel-
len über folgende Definition des Begriffes ”Plagiat“:
– Ein Plagiat liegt vor wenn die Ideen und/oder Worte von Dritten als die
eigenen ausgeben werden.
– Ein Plagiat liegt vor wenn die Ideen und/oder Worte von Dritten benutzt
werden, ohne darauf hinzuweisen.
Natürlich ist es auch eine Sichtweise der Gesellschaft, was genau ein Plagiat ist.
In dieser Arbeit sollen technische Möglichkeiten zur Erkennung von Plagiaten
beschrieben werden –unabhängig davon, ob Plagiate akzeptiert, als unerwünscht
oder als illegal betrachtet werden.1 Verschiedenen Definitionen zum Begriff Pla-
giat wurden den folgenden Quellen zusammengefasst übernommen und sind
dort auch noch näher erläutert: [Plagiarism.org 2006]2, [Maurer et al. 2006] und
[Daly, Horgan 2005].
1 Je nach philosophischer Betrachtung einer Gesellschaft über das Gedankengut, kann
der Begriff
”
Plagiat“ unter Umständen auch gar nicht existieren. Dies kann dann
nämlich der Fall sein, wenn die Gesellschaft geistige Äußerungen als Allgemeingut
ansieht (
”
Allmende“).
2 http://www.turnitin.com/research_site/e_what_is_plagiarism.html
5
2.1.1 Grenze zwischen Plagiat und wissenschaftlichem Referenzieren
In der Wissenschaft ist die Verwendung von bestehenden wissenschaftlichen Er-
kenntnissen eine Notwendigkeit. Es besteht aber ein wesentlicher Unterschied
zwischen dem Referenzieren und Zitieren von wissenschaftlichen Texten und dem
illegitimen Verwenden oder Kopieren von Arbeiten anderer. Um eine automati-
sierte Detektion von Plagiaten bei wissenschaftlichen Arbeiten zu ermöglichen,
muss die Trennlinie zwischen normalem Referenzieren und illegitimen Kopie-
ren möglichst genau gezogen werden. Hierzu dienen in erster Line Richtlinien
von Universitäten oder akademischen Organisationen zum richtigen Verwenden
und Zitieren von Arbeiten Dritter. Sehr bekannt sind beispielsweise die Zitierre-
geln der APA (American Psychological Organisation)3 oder der MLA (Modern
Language Organisation)4. In der Informatik wird hauptsächlich der IEEE Emp-
fehlung nach das CMS (The Chicago Manual of Style) benutzt.5 Für Arbeiten
in deutscher Sprache wird oft nach DIN 1505 (BibTeX-Citation Rules) zitiert.
2.2 Plagiatstypen
Grundsätzlich können verschiedenste Arten und Typen von textbasierenden Pla-
giaten eingeteilt werden. Vielfach treffen auf die Plagiate mehrere der Einteilun-
gen zu und die Abgrenzung zwischen zwei oder mehreren Typen ist nicht immer
scharf zu trennen. Trotzdem sollen in diesem Kapitel einige wichtige Unterschei-
dungsmerkmale genannt sein, wobei die folgende Einteilung eine Zusammen-
fassung unter Verwendung von [Maurer et al. 2006], [Plagiarism.org 2006] und
[Wikipedia 2007] ist:
– wortgetreue Kopie: Exakte Kopie eines kompletten Textes oder erhebli-
chen Textteiles (z.B. mittels ”Copy and Paste“) unter Angabe des eigenen
Namens anstatt des richtigen Urhebers. Dies ist zwar einfach und schnell zu
erstellen, allerdings auch sehr einfach durch Softwaremethoden zu erkennen.
– modifizierte Kopie (”Paraphrasing“): Dies ist eine absichtliche Ver-
schleierte unzulässige Verwendung von fremden Quellen. Die Bandbreite da-
bei reicht von einfacher Veränderung der Satzreihenfolge über den Austausch
von Worten mit selber semantischer Bedeutung bis hin zur kompletten Um-
formulierung von Sätzen oder der ganzen Arbeit.
– rein inhaltliche Kopie: Unzulässige Kopie der Idee bzw. des Inhalts bzw.
des Konzeptes, allerdings unter Verwendung eigener Worte. Das Verwenden
von Allgemeinwissen ist natürlich zulässig.
3 http://www.apastyle.org/elecref.html
4 http://www.mla.org/style
5 http://www.computer.org/author/style/index.htm
6
– Fehlende Quellenangabe: Dies ist eine der am häufigsten vorkommen-
den Plagiatsart, die Quelle wird dabei –absichtlich oder unabsichtlich– nicht
angegeben.
– Eigen-Plagiat: Unzulässige Wiederverwendung von Text(teilen), welche
bereits für andere Zwecke bzw. Veröffentlichungen verwendet wurden. Die
genaue Abgrenzung ist je nach Anwendungsfall dabei oft genauer geregelt.
Eine Diskussion zu diesen Thema ist unter [Collberg, Kobourov 2005] zu
finden.
– Anzahl der Plagiatsquellen: Plagiate können von nur einer Quelle oder
von mehreren Quellen abgeschrieben sein. Natürlich ist es erheblich aufwändi-
ger Plagiate zu erkennen, welche von mehreren Quellen stammen.
– Ungenaue Quellenangabe: Ebenfalls sehr häufig ist die ungenaue Anga-
be der Quelle, wie beispielsweise nur des Autors ohne weitere Hinweise auf
das Werk (Titel, Zeitschrift, Zeit oder ähnliche Angaben), so daß die Über-
prüfung der Quellenangaben gar nicht, schwer oder nur uneindeutig erfolgen
kann. Der Grund hierfür ist häufig eine ”schlampige“ Zitierweise, es kann
aber auch ein Hinweis auf eine absichtliche Verschleierung der eigentlichen
Quellen sein. [Plagiarism.org 2006]
– Falsche Quellenangabe: Die eigentliche Quelle wird nicht korrekt angege-
ben, was die Überprüfung dieser unmöglich macht.
– Verschleierte Quellenangaben: Teile der Arbeit werden korrekt zitiert
um zu verschleiern, dass andere Teile absichtlich nicht richtig zitiert bzw.
illegitim kopiert wurden.
– Zitat ohne Hinweis: Das wortgenaue Zitieren eines Textteiles, jedoch ohne
Hinweis (Verwendung von Anführungszeichen) darauf, dass der Text Wort–
für–Wort übernommen wurde. Auch wenn ein Hinweis auf den richtigen Au-
tor vorhanden ist, ist das wortgetreue Zitat nicht klar erkennbar.
– Überwiegende Verwendung anderer Inhalte: Die Arbeit besteht –im
Verhältnis zum eigenen Inhalt– überwiegend aus fremden Inhalten, auch
wenn die fremden Inhalte möglicherweise alle richtig zitiert wurden.
– Übersetzungs–Plagiat: Natürlich liegt auch dann ein Plagiat vor, wenn
die Quelle zuerst von einer anderen Sprache übersetzt und dann unrechtmäßig
verwendet wurde. Dies gilt sowohl für natürliche Sprachen, als auch für
Computer–Sprachen.
Eine weitere Unterscheidung gibt an, aus welchen Gründen ein Plagiat entstehen
kann:
– Zufällig: Es kann nicht vollständig ausgeschlossen werden, dass zwei oder
sogar mehrere Werke mit annähernd gleichem Inhalt nahezu unabhängig
voneinander erstellt wurden. Dies kann vor allem dann der Fall sein, wenn
ähnliche oder sogar gleiche Quellen verwendet wurden.
– Unbeabsichtigt: Durch Unwissenheit über das richtige Verwenden von
7
Quellen und vor allem wie richtig zitiert wird, kann unbeabsichtigt ein Pla-
giat entstehen.
– Beabsichtigt: Das absichtliche, unrechtmäßige Verwenden von Worten und
Inhalten von Dritten. Es besteht besonderes Interesse diese Form erkennen
und unterscheiden zu können.
3 Methoden zum Erkennen von Plagiaten
Basierend auf dem Wissen wie Plagiate entstehen, welche Arten davon existieren
und aus welcher Intuition sie entstehen, können Software–Methoden zur Detek-
tion aufbauen. Dabei hängt die Komplexität und der Aufwand der Software–
Methoden im Wesentlichen direkt proportional vom Plagiatstyp ab.
In [Maurer et al. 2006] werden die Methoden in folgende drei Hauptkategorien
unterteilt:
– Methoden, die das verdächtige Dokument mit einem Dokumentensatz
vergleichen (im einfachsten Fall auf Wort-Basis)
– Methoden, die in einem ersten Schritt aus dem verdächtigen Dokument
einen charakteristischen Paragraphen auswählen und in einem zwei-
ten Schritt diesen suchen lassen mittels einem geeigneten Suchsystem bzw.
Suchmaschine.
– Methoden, die den Schreibstil entweder innerhalb eines Dokumentes un-
tersuchen oder mit anderen Dokumenten vergleicht – dies wird als ”Stylo-
metrie“ bezeichnet.
Viele Softwaremethoden sind eine Kombination aus verschiedenen Detektions-
ansätzen. Dies ist notwendig, um den vielfältigen Möglichkeiten der Plagiatoren
gerecht zu werden. In dieser Arbeit wird versucht eine andere Einteilung zu fin-
den. Es wird unterteilt in triviale Methoden, komplexe Methoden und alternative
Methoden.
3.1 Triviale Methoden
Als triviale Methoden seien hier solche genannt, welche Wort–für–Wort kopierte
Texte oder Textteile als Plagiate erkennen können.
3.1.1 Einfache textbasierende Vergleichsmethoden
Hierbei wird ganz einfach der gesamte Text, oder Teile davon mit einem Do-
kumentensatz verglichen. Beispielsweise kann der Text der verdächtigten Arbeit
8
(oder nur Auszüge davon) in Internet-Suchmaschine(n) eingegeben werden um
danach zu suchen. Diese Strategie funktioniert nicht zuletzt deswegen, weil auch
der Hersteller des Plagiats sehr wahrscheinlich in ähnlicher Weise das Plagiat
erzeugt hat: Es wurde zuerst im Internet nach den passenden Themen gesucht
und diese dann in die eigene Arbeit kopiert. Das Prinzip funktioniert prinzipiell
auch dann, wenn aus verschiedenen Quellen unrechtmäßig Material verwendet
wurde. Es ist dazu allerdings eine geeignete Aufteilung der zu vergleichenden
Textabschnitte notwendig. Zur Effizienzsteigerung des Verfahrens kann folgen-
de Strategie verwendet werden: Es wird dabei nach geeigneten Schlüsselwor-
ten oder Phrasen in der verdächtigen Arbeit gesucht. Die zugehörenden Sätze
oder Absätze werden anschließend im Dokumentensatz gesucht. Die Auswahl
der Schlüsselworte oder der Phrasen kann entweder automatisch (selten vorkom-
mende Wörter, eindeutige Bezeichnungen etc.) oder auch manuell vom Benutzer
(beispielsweise bei konkretem Verdacht) durchgeführt werden.
3.2 Komplexe Methoden
Komplexere Methoden zur Detektion von Plagiaten sind notwendig, wenn der
Vergleich von Inhalten, Ideen oder Konzepten notwendig ist. Oder wenn es sich
bei dem Plagiat um eine modifizierte Kopie handelt, bei der die eigentlichen
Quelle(n) absichtlich verschleiert wurde(n). Offensichtlich komplexer werden die
Software–Methoden auch dann, wenn eine Differenzierung wie beispielsweise
über den Typ des Plagiats ermittelt werden soll.
3.3 Fingerprinting
Exakte Kopien zu vergleichen ist relativ einfach, die Detektion von partiellen
Kopien hingegen kann nur durch viel subtilere Methoden erfolgen. Beim Ansatz
des Fingerprinting wird das Dokument in n–Gramme unterteilt. Jedes dieser
n–Gramme wird gehasht, und dann ein Subset dieser Hashes als Fingerprints
verwendet. Wenn die Hashfunktion so gewählt wird, dass die Wahrscheinlichkeit
für eine Kollision sehr gering ist, dann kann daraus geschlossen werden, dass im-
mer wenn zwei Dokumente einen oder mehrere Fingerprints teilen, sie auch sehr
wahrscheinlich n–Gramme teilen. Die Auswahl der Hashes, die als Fingerprints
dienen sollen, ist bei dieser Methode von großer Bedeutung. Ein verbreiteter
Ansatz ist es, alle Hashes zu wählen, die 0 mod p sind (für ein fixes p). Die Wahl
eines Subsets anstatt der kompletten Anzahl von Hashes führt auf der einen Seite
zu einer Effizienzsteigerung, auf der anderen Seite können aber nur n-Gramm-
Matches entdeckt werden, deren Hash 0 mod p sind. N–Gramme – nicht aber
diejenigen, die in den Raum dazwischen fallen. Umso wichtiger ist es also, dass
die Auswahl der Fingerprints so erfolgt, dass garantiert zumindest immer Tei-
le einer ausreichend langen Übereinstimmung gefunden wird. Eine Möglichkeit
9
dafür, die [Aiken et al. 2003] vorstellen, ist die Definition eines Fensters mit der
Größe w. Ein Fenster sind also w aufeinanderfolgende Hashes von n–Grammen.
Indem aus jedem Fenster mindestens ein Hash gewählt wird, limitiert der Al-
gorithmus den maximalen Abstand zwischen den Fingerprints. Der Algorithmus
detektiert daher zumindest ein n–Gramm in jedem geteilten Substring der Länge
w + k – 1. Algorithmen, die aus jedem Fenster w einen Hash wählen und deren
Wahl nur auf den Inhalt des Fensters ankommt, werden als sogenannte Local
Algorithms bezeichnet. Eines der Plagiat–Erkennungswerkzeuge, die auf Finger-
printing basieren, ist MOSS (siehe Kapitel 6.2.5).
3.3.1 Stilometrische Analyse
Die Stilometrische Analyse von Texten gehört zu der Klasse jener Ansätze, die
zwar sehr aufwändig, dafür aber auch sehr erfolgsversprechend sind. Man ver-
steht darunter die Analyse bzw. das Untersuchen der Merkmale des individuellen
Schreibstils – unabhängig vom Inhalt des Geschriebenen. Die stilometrische Ana-
lyse ist im Übrigen eines der Hauptwerkzeuge der forensischen Linguistik, welche
sich mit der Autorzuordnung von Texten beschäftigt. Stilometrische Merkmale
zur Erkennung von Plagiaten sollen möglichst schwer manipulierbar sein. Außer-
dem sollen sie möglichst invariant bezüglich Textlänge und Genre des jeweiligen
Textes sein. Im folgenden sollen einige einfachere stilometrische Merkmale –ohne
Anspruch auf Vollständigkeit– beschrieben werden:
3.3.2 Satzlänge
Ein sehr einfaches Beispiel eines stilometrischen Merkmals ist die Satzlänge.
Trotz der Einfachheit dieses Merkmals, wird die Satzlänge auch in modernen Stu-
dien verwendet – allerdings nur als ein Merkmal unter vielen [Steinmann 2004].
Die Satzlänge soll nicht alleine verwendet werden, kann aber die Ergebnisse an-
derer Methoden in der Regel bestätige. Steinmann schreibt über die Nachteile:
”Die größten Nachteile der Satzlänge bestehen in der Kontrollier- und Imitier-
barkeit durch den Autor und in der Abhängigkeit von der Interpunktion, was sie
als Merkmal gerade für ältere Texte ungeeignet macht, da man ansonsten Gefahr
läuft, bis zu einem gewissen Grad statt der Satzlängenvorlieben des Autors dieje-
nigen eines Herausgebers zu untersuchen“ [Steinmann 2004] über [Holmes 1994].
3.3.3 Wortschatz
Eine zentrale Rolle bei den Merkmalen der stilometrischen Methoden nimmt
die Analyse des Wortschatzes ein. Laut [Stamatatos et al. 2001] gibt es dazu die
folgenden zwei grundlegende Ansätze: Erstens die Analyse der Frequenz einzel-
ner Wörter und zweitens die Analyse des Umfanges und der Differenziertheit
10
des Wortschatzes. [Steinmann 2004]. Wörter die nur einmal in einem Text vor-
kommen werden hapax legomena genannt, Wörter die zweifach bzw. dreifach
auftreten werden als hapax dislegomena bzw. als hapax trislegomena bezeichnet.
Wörter die nur einmal im Text vorkommen wird ein besonders hohes Gewicht
beigemessen und daher auch gerne als Merkmal herangezogen. Seltenen hapax
dislegomena bzw. Fachbegriffen und altmodischen Wörtern wird von manchen
Methoden eine höhere Wertigkeit beigemessen.
Weitere wichtige Wortschatzmerkmale sind das Type–Token–Verhältnis, wel-
ches die Verteilung der Worthäufigkeit misst. Dabei entspricht ein ”Type“ übli-
cherweise dem sog. Lexem 6. Eine Regel zur Bildung von Lexemen ist sprach–
und grammatikabhängig. Als ”Token“ gilt ein Satzbaustein. Das Type–Token–
Verhältnis ist nicht invariant gegenüber der Textlänge. Analoges gilt für die
durschschnittliche Worthäufigkeit welche sich reziprok zum Type–Token–
Verhältnis verhält [Steinmann 2004].
Eine weiteres wortschatzbasierendes Merkmal ist die Simpson´s Methode 7.
Dabei wird die Wahrscheinlichkeit gemessen, dass zufällig ausgewählte Wörter
vom selben Wortstamm bzw. Typ (Lexem) sind [Steinmann 2004].
Ähnlich dazu funktioniert die Yules K-Charakteristik – K ist dabei ein Mass
für die Anzahl der Wortwiederholungen. Bei unabhängiger Verteilung der Wörter
im Text (entspricht einem Poisson–Prozess) ist das Maß invariant hinsichtlich
der Textlänge [Holmes 1994].
Mit dem Merkmal Entropie kann der Informationsgehalt eines Textes gemes-
sen werden. Im Sinne der Stilometrie versteht man unter Entropie die Struktu-
riertheit des Textes. Je inhomogener, zufälliger die Wortverteilung umso höher
die Entropie. Die Entropie lässt sich normalisieren, um invariant gegenüber der
Textlänge zu sein.
Einen weiteren möglichen Ansatz für Detektionsmerkmale bildet ”Zipf´s Law“,
welches einen engen Zusammenhang herstellt zwischen der Wortfrequenz eines
Wortes in einem Text und dem zugehörigen Rang des Wortes in einer nach der
Wortfrequenz sortierten Wortliste. Anders ausgedrückt gilt: Wortfrequenz ∗
Listenrang = konstant. Außerdem ist gemäß Zipf die die Wortfrequenz im Mit-
tel annähernd umgekehrt proportional zur Wortlänge. Diese Merkmale können
zum Vergleich von Texten verwendet werden.
Ein Vorteil von Wortschatzbasierenden Merkmalen zur Detektion von Plagiaten
ist die eingeschränkte Manipulierbarkeit durch den Autor – es ist in hohem
6
”
Als Lexem wird in der Linguistik die Einheit des Wortschatzes einer Sprache be-
zeichnet, die über verschiedene grammatische Wörter abstrahiert. So sind Traum,
Traums, Träume und Träumen grammatische Wörter zum selben Lexem TRAUM.“
[Wikipedia 2007,
”
lexem“]
7 Nein, es geht nicht um die bekannte Fernsehserie
11
Maße unwahrscheinlich, dass ein Autor seinen Wortschatz plötzlich stark variiert
[Hoover 2003]. Als erheblicher Nachteil ist der erheblichen Einfluss der Textlänge
auf den Wortschatz zu benennen – dies muss bei der Ermittlung der Merkmale
berücksichtigt werden. Außerdem ist die Performance der Merkmale derzeit noch
nicht ausreichend um vollständig unbeaufsichtigte bzw. automatische Software
zu ermöglichen. Es ist eher das Gegenteil der Fall, der Benutzer kann solche
Softwaremethoden nur als Hilfestellung bzw. für eine Vorsortierung benutzen.
3.3.4 Syntax
Methoden die den Syntax bzw. den Satzbau eines Textes zur Bewertung heran-
ziehen, sind relativ aufwändig. Dies begründet sich vor allem darin, weil diese
eine entsprechende Zerlegung voraussetzen. Wegen der Aufwändigkeit werden
daher im Allgemeinen oft nur Methoden implementiert, welche einen vereinfachte
Syntaxzerlegung verwenden. Ein Beispiel hiefür ist die Zerlegung in sogenannte
Funktionswörter wovon meist nur die häufigsten verwendet werden. Alternativ
kann eine Zerlegung auch durch das so genannte ”Chunking“ durchgeführt wer-
den. (”Chunking ist ein in den 50er Jahren in die Gedächtnisforschung ein-
geführter Terminus zur Bezeichnung der (individuell unterschiedlichen) Seg-
mentierung und Bündelung von Informationseinheiten.“ [Wiki Lingua 2007] 8
). Einen Vergleich der beiden Zerlegungsmethoden ist zu finden beispielsweise
in [Stamatatos et al. 2001, Seiten 197–201], wobei die Chunking–Merkmale die
besseren Resultate lieferte. Eine minimale Anzahl von ca. 1000 Wörtern war aber
für eine erfolgreiche Anwendung notwendig [Steinmann 2004]. Syntaxmethoden
sind normalerweise nicht invariant gegenüber der verwendeten Sprache.
3.3.5 Zusammenfassung Stilometrische Analyse
Wichtig für verwertbare Ergebnisse in der stilometrischen Analyse ist unter an-
derem ein geeigneter sowie ausreichend großer Vergleichs–Dokumentensatz. So
wurde beispielsweise in [Baayen et al. 1996] der stilometrische Einfluss von Au-
tor und Genre untersucht. Verglichen wurde dabei der Unterschied zwischen
verschiedenen Autoren innerhalb des gleichen Genres, als auch jener zwischen
den Texten eines Autors anhand von Beispieltexten. Das Ergebnis war, dass
sich die Texte des selben Genres höher korrelierten als jene des selben Autors.
Im Unterschied dazu war es aber innerhalb eines Genres möglich die Auto-
ren voneinander zu unterscheiden [Baayen et al. 1996], [Steinmann 2004]. Laut
[Eissen, Stein 2006] fallen die erfolgreichsten bisherigen stilometrischen Merk-
male in eine der folgenden fünf Kategoerien: 1.) Zeichen– bzw. Buchstabenba-
sierende Text–Statistik. 2.) Syntaktische Merkmale, welche den Schreibstil auf
8 http://wiki-lingua.uni-trier.de
12
Satzebene messen. 3.) Merkmale, welche die Benutzung von bestimmten Wort–
Kategorien quantifizieren. 4.) Geschlossene Kategorie von Wortmengen, um spe-
zielle Worte zu zählen. 5.) strukturale Merkmale, welche die Organisation des
Textes reflektieren. Zusätzlich dazu stellen [Eissen, Stein 2006] in ihrer Arbeit
eine weitere Kategorie. die sog. ”Averaged Word Frequency Class“ vor.
3.4 Alternative Methoden
Neben den reinen Softwareansätzen existieren auch eine Reihe von alternativen
–mehr oder weniger automatisierten– Methoden um Plagiate zu detektieren.
Ein typisches Beispiel hierfür ist Glatt´s ”Plagiarism Self–Detection Program“
[Glatt 2007]. Hierbei wird aus dem verdächtigen Dokument bzw. Absatz jedes
fünfte Wort ausgelöscht und durch Leerzeichen ersetzt. Anschließend muss der
Autor des Textes die Leerstellen wieder einsetzen. Dabei wird die Zeit und die
Anzahl der Fehler gemessen, um herauszufinden ob kopiert wurde oder der Au-
tor den Text selbst verfasst hat. Diese Methoden können zwar automatisations-
gestützt, aber offensichtlich nicht vollautomatisch erfolgen, da Interaktion des
”Erstellers“ notwendig ist.
4 Plagiarismus im Bereich der Software–Entwicklung
Die Möglichkeiten für Entwickler sowohl im universitären als auch im außeruni-
versitären Bereich, Plagiate von Sourcecode zu erstellen, sind vor allem durch
das Internet, die steigende Anzahl von sogenannten ”Essay–Banks“ und für je-
den frei verfügbaren elektronischen Quellen enorm gestiegen. Doch wo sind in
diesem Bereich die Grenzen von Plagiarismus — ab wann gilt ein Programm
bzw. Programmteil als Plagiat?
4.1 Was gilt als Plagiat im Gebiet des Software–Engineering?
Diese Frage ist vor allem unter dem Gesichtspunkt der allseits ermutigten Wie-
derverwendung von Code und Codemustern in der objektorientierten Program-
mierung gar nicht so trivial wie es auf den ersten Blick scheint.
Unzählige, in den letzten Jahren durchgeführte Erhebungen (hauptsächlich im
universitären Bereich) zu diesem Thema zeigen, dass die Meinungen stark diffe-
rieren und es kaum möglich ist, ein einheitliches Bewertungssystem zu schaffen
und so die Grenzen zu objektivieren.
So hat etwa eine Untersuchung von [Sutherland–Smith 2005], in der elf Professo-
ren von Universitäten in Australien ihre Beurteilung von verschiedenen Situatio-
nen abgeben, gezeigt, dass zwischen Akademikern, die das selbe Fach unterrich-
ten, zum Teil sehr divergierende oder sogar konträre Ansichten von Plagiarismus
13
haben. Der Versuch, eine eindeutige Definition von Plagiaten zu schaffen, gestal-
tet sich dementsprechend schwierig.
In einer Studie von [Cosma, Joy 2006] werden verschiedene Aspekte beleuch-
tet, die nur im Zusammenhang mit Code–Plagiaten auftauchen. Diese Fragen
betreffen in der Hauptsache Grenzsituationen in den Themen ”Wiederverwen-
dung von Sourcecode“ und den sogenannten ”Self–Plagiarism“, die im Bereich
von natürlichsprachlichen Texten eindeutig klassifizierbar und somit nicht von
Relevanz sind.
4.2 Beispiel für eine Grenzsituation
Das folgende Beispiel ist entnommen aus [Cosma, Joy 2006]:
”Ein Student konvertiert den Code eines anderen teilweise oder gesamt in eine
andere Programmiersprache und gibt das Programm ohne Referenzen als sein
eigenes aus.“ [Cosma, Joy 2006]
Die Meinungen der befragten Professoren gehen auseinander: Während manche
damit argumentieren, dass es als Plagiat zu betrachten ist, wenn der Code au-
tomatisch oder mit wenig Mühe vom Studenten übersetzt wurde, wohingegen
andere der Meinung sind, dass es legitim ist, wenn sich der Student die Ideen
anderer zunutze macht, vorausgesetzt er schreibt seinen Code von Grund auf
selbst. Ein Kommentar eines Professors zu dieser Fragestellung:
”The key question is whether the student is being misleading about how much
work is theirs or not. I can imagine examples where the translation was definitely
plagiarism, and I can imagine examples where the student has taken legitimate
inspiration from someone else‘s example code, and has rewritten it in a different
language.“ [Cosma, Joy 2006]
Andere Beispiele für Grenzsituationen wären etwa die Verwendung von Source-
code, der mit Hilfe von Generatoren (etwa JSPMaker) erstellt wurde, die Er-
stellung nach dem Vorbild eines bereits vorhandenen Codes (wie viel Inspiration
darf sich ein Entwickler holen — wie viel muss seine eigene Idee sein?) oder auch
die Wiederverwendung von eigenem Code ohne explizite Angabe.
4.3 Code Similarity Analyzers
Nach [Mishne, de Rijke 2004] können Werkzeuge zur Detektion von Sourcecode
Plagiaten in folgende Kategorien gruppiert werden:
– Pattern–based Analyzers: Diese Tools verwenden Pattern-Matching und
Tiling–Algorithmen, um Ähnlichkeiten zwischen Codezeilen zu überprüfen.
Sehr effektiv ist dieser Ansatz nur bei einfach duplizierten und sehr ähnlichen
14
Codefragmenten (copy & paste); sobald strukturelle Änderungen des Codes
ins Spiel kommen, ist diese Methode jedoch komplett nutzlos.
– Code Signature Analyzers: Diese Tools assoziieren eine sogenannte ”Code–
Signature“ mit jedem Codestück, die aus bestimmten Features des Codes
heraus berechnet wird. Codefiles mit ähnlichen Signaturen werden als ähn-
lich eingestuft (siehe auch ”Fingerprinting“ , Kapitel 3.3).
– Structural Analyzers: Diese Tools vergleichen die Struktureigenschaften
eines Programms, indem die Codefiles als Strings repräsentiert werden und
eine Distanz zwischen ihnen errechnet wird.
4.4 Eigenschaften von Copy-Detection Algorithmen
[Aiken et al. 2003] definieren drei Eigenschaften, die jeder Copy-Detection Algo-
rithmus erfüllen sollte:
– Whitespace Insensitivity: Übereinstimmungen sollten unbeeinflusst von
Tabulatoren, Leerzeichen, Groß–Kleinschreibung, Satzzeichen, etc. sein. Im
Bereich der Softwareentwicklung sollte auf eine Unempfindlichkeit z.B. ge-
genüber Variablennamen gegeben sein. Die meisten Ansätze eliminieren ein-
fach in einem ersten Durchgang alle diese Details.
– Noise Suppression: Die gefundenen Übereinstimmungen müssen lang ge-
nug sein, um den Verdacht zu rechtfertigen. Übereinstimmungen wie etwa
ein oft verwendetes Wort oder Idiom einer Sprache sind uninteressant (z.B.
das Wort und). Ansätze, die auf Fingerprinting beruhen, erfüllen diese For-
derung durch die Wahl eines ausreichend großen n für die n–Gramme.
– Position Independence: Eine grobe Umsortierung der Inhalte eines Doku-
ments, sowie auch Hinzufügen oder Löschen von Teilen sollte die Entdeckung
von Übereinstimmungen nicht beeinflussen.
4.5 Ansätze für Plagiat–Detektion von Sourcecode
[Moussiades, Vakali 2005] teilen die bisher existierenden Systeme in zwei Klas-
sen ein — Attributbasierte und Strukturbasierte Systeme. Im folgenden werden
diese beiden Gruppen kurz charakterisiert und dann ein dritter, Clusterbasierter
Ansatz (entwickelt von [Moussiades, Vakali 2005]) vorgestellt.
4.5.1 Attributbasierte Systeme (Attribute–counting systems)
Diese Systemen waren die ersten in dem Bereich. Ein Beispiel für ein solches
System wäre eines, das auf [Halstead 1977] Software Science Metrik basiert. Ein
15
Programm kann dabei als eine Sequenz von Tokens gesehen werden, die jeweils
entweder als Operatoren oder als Operanden klassifiziert werden können. Jedes
Programm bekommt ein Quadrupel zugewiesen, bestehend aus N1 (Anzahl der
vorkommenden Operatoren), N2 (Anzahl der vorkommenden Operanden), n1
(Anzahl an unterschiedlichen Operatoren) und n2 (Anzahl an unterschiedlichen
Operanden). Dateien mit dem selben Quadrupel werden als verdächtig markiert.
Im Laufe der Zeit kamen noch andere Metriken hinzu, um das Ergebnis zu
verbessern (etwa Anzahl der Variablen, Aufrufe von Subprogrammen, etc.). Der
Erfolg dieser Systeme basiert auf der Annahme von einfachen Copy & Paste´s
-– ihre Performance ist dementsprechend gering.
4.5.2 Strukturbasierte Systeme (Structure metric systems)
Im Gegensatz zu den Attributbasierten Systemen setzen diese auf den Vergleich
von Strukturen. Beispiele für ein solches System wären etwa MOSS (siehe auch
Kapitel 6.2.5), YAP3 oder JPlag. MOSS unterstützt etwa eine Unempfindlichkeit
gegenüber Whitespaces, Rauschunterdrückung und eine Unabhängigkeit von der
Position der Fragmente. Dazu verwendet MOSS die Fingerprinting-Methode, die
Programme in n–Gramme unterteilt, einen Hashcode von diesen erstellt und ein
Subset dieser Hashes als Fingerprint definiert. Über den Vergleich der Finger-
prints einzelner Programme können so verdächtige Übereinstimmungen identifi-
ziert werden (siehe auch Kapitel 3.3).
YAP3 und JPlag hingegen verwenden den Greedy-String–Tiling Algorithmus,
um vermischte Codefragmente zu detektieren. Dazu werden Programme in Token–
Strings unterteilt. Der Algorithmus vergleicht zwei Strings (genannt Pattern
und Text, indem im Text nach Substrings des Patterns gesucht wird.
4.5.3 PDetect: Ein Ansatz mit Clustering
[Moussiades, Vakali 2005] stellen mit der Software PDetect einen Ansatz zur De-
tektion von Sourcecode Plagiaten, der auf Clustering setzt. Clustering bezeich-
net einen Prozess des Gruppierens von gleichen oder sehr ähnlichen Objekten in
Klassen. Ein Cluster ist demzufolge also eine Gruppe bzw. Sammlung von ähn-
lichen Objekten, die sich von Objekten anderer Cluster unterscheiden. Cluster
werden dabei durch den Grad der Ähnlichkeit zwischen Mustern, aufgrund der
Korrelation von deren Inputvektoren, gebildet.
PDetect läuft in zwei Phasen:
– Phase 1: In dieser Phase werden die Programme für das Clustering auf-
bereitet. Dazu wird für jedes Input-Programm eine Repräsentation durch
ein Keyword-Set erstellt. Daraufhin wird eine Evaluierung der Ähnlichkeit
zwischen jedem Paar von Programmen durchgeführt, aus denen paarweise
Ähnlichkeiten resultieren.
16
Abbildung 1: PDetect – Workflow, entnommen aus [Moussiades, Vakali 2005].
(a) Phase 1, (b) Phase 2
– Phase 2: In dieser Phase erfolgt durch die Anwendung des Clustering–
Algorithmus eine Einteilung der Paare aus Phase 1 in Cluster von plagiierten
Programmen. In Abbildung 1 ist der Ablauf grafisch dargestellt.
5 Schwierigkeiten bei der Plagiatserkennung und Messung
der Detektionsperformance
Das Erkennen von Plagiaten ist mit dem derzeitigen Stand der Wissenschaft
technologisch keinesfalls auf einem Status, der eine unbeaufsichtigte, automa-
tische Detektion ermöglichen kann. Vielmehr ist im Allgemeinen nur eine Vor-
selektion möglich, um eine spätere manuelle Begutachtung zu unterstützen. In
diesem Kapitel sollen Hindernisse und die größeren Schwierigkeiten bei der De-
tektion von Plagiaten betrachtet werden. Dabei wird unterteilt in Falsch–Positiv
und Falsch–Negativ Detektion.
Im Allgemeinen hängt die Erkennungsperformance von drei wichtigen Faktoren
ab: Erstens von der jeweiligen verwendeten Methode bzw. von dem Extrakti-
onsmerkmal zweitens von den notwendigen Invarianzen der Methode gegenüber
verschiedensten störenden Einflüssen und drittens von der Ähnlichkeit der Do-
kumente innerhalb des Vergleichsdokumentensatzes. Bezüglich der Detektions–
Merkmale soll –wie bei anderen Klassifikationsproblemen auch– die Intragrup-
penvarianz, also die Varianz innerhalb eines Merkmales klein sein um eine scharfe
Trennung zu ermöglichen. Hingegen soll die Intergruppenenvarianz der Merk-
male groß sein, damit sich die Verteilungen nicht durchmischen. Lassen sich die
17
Merkmale der Vergleichsdokumente zu schlecht unterscheiden, so ist eine Klassi-
fikation entweder nicht möglich oder erfolgt mehr oder weniger zufällig. In gewis-
sen Fällen mag es ausreichen einen Schwellwert der Methode –ab dem die Wahr-
scheinlichkeit für ein Plagiat spricht– zu verändern. Sehr wichtig ist es aber aus
oben genannten Gründen einen geeigneten Vergleichsdatensatz sowie die hierfür
geeigneten Merkmale zu wählen, damit diese eine Unterscheidung ermöglichen.
Leider sind viele Software–Methoden nicht invariant gegenüber unterschiedli-
cher Textlänge, der verwendeten Sprache, der Anzahl der Autoren und anderen
wichtigen Faktoren (siehe dazu auch Kapitel 3.3.1). Diese Einschränkung ist ein
weiterer Grund für Falschmeldungen der Software–Detektoren.
5.1 Falsch–Positiv Detektion
Eine falsch–positiv Detektion liegt dann vor, wenn die Software Methode einen
authentischen, nicht kopierten Text fälschlicherweise als Plagiat erkennt. Wenn
die Zahl der falsch–positiv Detektionen hoch ist, ist es für den Begutachter be-
sonders aufwändig die wahren Plagiate darunter herauszufinden und daher die
Softwaremethode wenig nützlich. Die Rate der falsch–positiv detektierten Texte
kann unter anderem als Performancemerkmal verwendet werden.
5.2 Falsch–Negativ Detektion
Die falsch–negativ Detektion ist höchstens für den Plagiator von zweifelhaftem
”Vorteil“, so doch dessen Arbeit nicht als Plagiat sondern als von ihm selbst
erstellt erkannt wird. Dies kann beispielsweise dann auftreten, wenn die verwen-
dete Software–Methode nicht hinreichend geeignet ist zur Klassifikation einer
bestimmten Textgruppe (falsche Sprache, falsches Genre etc.).
5.3 Messung der Detektions–Performance
Analog zur Evaluierung von Daten aus dem Bereich ”Information–Search and
Retrieval“ können zur Performancemessung der Plagiatdetektons–Methoden Re-
call und Precision Graphen eingesetzt werden. Die Berechnung erfolgt mit Hilfe
der falsch–positiv Rate und der falsch–negativ Rate, sowie mit dem Wissen wel-
che Textdokumente tatsächlich Plagiate sind.
6 Werkzeuge zum Erkennen von Plagiaten
Gerade im akademischen Bereich ist es von grossem Interesse mit Hilfe von
automatisierten Methoden auf einfache Weise eine grosse Anzahl an Arbeiten von
Schülern und Studenten überprüfen zu können. Im folgenden Abschnitt werden
einige praktische Anwendungen zum Erkennen von Plagiaten näher erläutert.
18
Neben den kommerziellen Anwendungen sind auch einige frei verfügbare Tools
erhätlich. Abschließend wird noch ein Programm zur Erkennung von Plagiaten
bei Programmiersprachen angeführt.
6.1 Kommerzielle Lösungen
Leider stellen die meisten der kommerziellen Produkte keine Testversionen zur
Verfügung. Daher wurden die folgenden Informationen und Screenshots hauptsächlich
von den jeweiligen Produktbeschreibungen übernommen.
6.1.1 Turnitin - Plagiarism prevention
iParadigms9 bietet mit Turnitin eine umfassende Umgebung für Lehrer und Pro-
fessoren um Studenten beurteilen zu können. Ein Teil dieser Umgebung befasst
sich mit der Plagiatserkennung. Neben Turnitin bietet iParadigms ein weite-
res Produkt namens iThenticate10 an welches ebenfalls die Originalität einer
Arbeit überprüfen kann. Im Gegensatz zu TurnitIn speichert iThenticate die
überprüften Dokumente nicht in einer Datenbank ab, wodurch die Suche nach
Plagiaten nicht auf die bereits übermittelten Dokuemente ausgeweitet wird. Da
iThenticate aber sonst nahezu auf der gleichen Engine wie Turnitin basiert, wird
auf dieses zweite Produkt im folgenden Abschnitt nur kurz näher eingegangen.
Turnitin benötigt keine clientseitige Installation, da die gesamte Funktionalität
online per Browser-Interface zur Verfügung gestellt wird. Nachdem sich der Be-
nutzer am System angemeldet hat kann er abhängig von der erworbenen Lizenz
beliebig viele Dokumente in das Online-System übertragen. Bereits nach kurzer
Zeit steht dem Benutzer eine erste Bewertung der übertragenen Dokumente zur
Verfügung. Ein grosser Vorteil von Turnitin gegenüber anderen Anwendungen
besteht darin, dass Turnitin auf eine sehr grosse Datenbank an Dokumenten
zurückgreifen kann. Um Plagiate erkennen zu können wird das Dokument ge-
genüber drei verschiedenen Datenbanken verglichen [Turnitin 2007]:
– Die interne Internet Datenbank umfasst 4,5 Milliarden Seiten wobei pro Tag
40 Millionen Seiten aktualisiert werden. In diesem Archiv befinden sich auch
mehrere Millionen Seiten, welche nicht mehr online verfügbar sind und somit
auch durch Suchmaschinen nicht mehr gefunden werden können. Dokumente
werden bis zu einer Grösse von 2MB archiviert.
– Eine grosse Datenbank an Büchern und Journalen.
– Mehrere Millionen an zuvor von Benutzern übertragenen Arbeiten werden
gespeichert, welche nicht durch diverse Suchmaschinen auffindbar sind. Tru-
nitin ist im amerikanischen Raum sehr weit verbreitet, wodurch die Anzahl
9 http://www.iparadigms.com
10 http://www.ithenticate.com
19
an Papers, welche händisch an das System übertragen werden, sehr rasch
ansteigt. Zu Stosszeiten werden täglich über 20000 neue Papers überprüft
und dem Archiv hinzugefügt.
Abbildung 2: Turnitin Originality Report
In Abbildung 2 ist der Originality Report ersichtlich den der Benutzer zu jedem
übertragenen Dokument zur Verfügung gestellt bekommt. Im oberen Bereich
wird prozentuell die gesamte Ähnlichkeit des Textes zu anderen Quellen ange-
geben. Im linken Teil der Seite wird der übermittelte Text angezeigt, während
auf der rechten Seite die ermittelten Quellen dargestellt werden. Zu jeder Quelle
wird in Prozent die ermittelte Ähnlichkeit angegeben. Um einen direkten Ver-
gleich der Textstellen zu ermöglichen kann der Benutzer im linken Bereich auf
eine Textstelle klicken um dann im rechten Bereich direkt die dazugehörige Stelle
der Quelle sehen zu können. Dies ermöglicht einen einfachen Vergleich der Texte.
[Turnitin 2007]
20
iThenticate bietet zusätzlich noch die Möglichkeit festzulegen in welchen zeitli-
chen Intervallen das übermittelte Paper erneut auf Plagiate untersucht werden
soll.
6.1.2 EVE Plagiarism Detection System
Das von Canexus11 entwickelte System EVE2 Plagiarism Detection System be-
ruht im Gegensatz zu Turnitin auf einem am Client installierten Programm.
EVE – Essay Verification Engine – vergleicht die Texte nicht mit einer eige-
nen grossen Datenbank, sondern verwendet direkt eine komplexe Internetsuche.
Abhängig von den gewählten Einstellungen erhält der Benutzer nach durch-
schnittlich ca. 20 Minuten einen Report welcher die gefundenen Ähnlichkeiten
auflistet. [Eve2 2007] [Bull et al. 2006]
6.1.3 Copycatch
David Woolls entwickelte eine auf der forensischen Textanalyse basierte Anwen-
dung, welche es erlaubt ein Dokument mit verschiedenen anderen Dokumenten
zu vergleichen. Die Standardvariante des Tools erlaubt nur den Vergleich inner-
halb lokaler Dokumente. Eine erweiterte Variante (Copycatch Web) ermöglicht
aber zusätzlich mit Hilfe der Google API die Suche im Internet. [Copycatch 2003]
Abbildung 3: Copycatch Screenshot
11 http://www.canexus.com
21
Abbildung 3 zeigt einen Screenshot der Demoversion des Programmes. Nach-
dem man zwei Texte, welche verglichen werden sollen, ausgewählt hat, werden
im rechten Bereich oben die ähnlichen Textabschnitte angeführt. Klickt der Be-
nutzer nun auf eine dieser Phrasen werden die Textstellen detaillierter im unteren
Bereich dargestellt. Der Benutzer hat auch die Möglichkeit den gesamten Text
beider Dokumente anzuzeigen, wobei dabei die ähnlichen Textstellen farblich
hervorgehoben werden.
6.1.4 SafeAssignment
Mit der MyDropBox Suite bietet Sciworth Inc. 12 eine von der Grundfunktio-
nalität zu Turnitin sehr Ähnliche Umgebung. Innerhalb dieser Suite bietet Sa-
feAssignment die Möglichkeit nach Plagiaten zu suchen. Die Möglichkeit diese
Anwendung in eine grosse Lernplattform wie beispielsweise Blackboard 13 ein-
binden zu können stellt einen grossen Vorteil gegenüber anderen Standalone
Lösungen dar. Ähnlich wie Turnitin nutzt auch SafeAssignment eine sehr gros-
se Datenbank, wobei sich diese bei SafeAssignment wie folgt zusammensetzt:
[SafeAssignment 2006]
– Ein Internet-Archiv mit beinahe 8 Milliarden Seiten.
– Viele öffentlich zugänglichen Datenbanken (z.B. PubMed14 und Project Gut-
tenberg15)
– FindArticles Datenbank 16, welche bereits mehr als 10 Millionen Articel
beinhaltet.
– ProQuest ABI/Inform Datenbank 17 mit mehr als 2,7 Millionen Artikeln
– MyDropBox Datenbank mit über 300.000 Dokumenten
– Aus Datenschutzrechtlichen Gründen bietet SafeAssignment nicht die Möglich-
keit innerhalb aller Dokumente aller Kunden zu suchen, sondern nur inner-
halb der Dokumente eines Institutes.
Sobald ein Student ein Paper in das System übertragen hat, wird automatisiert
mit Hilfe eines Textvergleich-Algorithmus bereits nach ungefähr 2 Minuten ein
ausführlicher Bericht erstellt. Es besteht die Möglichkeit diesen Bericht auch
dem Student selbst zur Verfügung zu stellen damit dieser in Zukunft daraus
lernen kann. Abbildung 4 zeigt einen solchen Bericht. Im oberen Bereich wird
eine gesamte Ähnlichkeit angezeigt, wobei im mittleren Bereich detaillierter die
einzelnen gefundenen Quellen dargestellt werden. Im unteren Bereich wird die
Möglichkeit geboten die Textstellen direkt zu vergleichen. [SafeAssignment 2006]
12 http://www.mydropbox.com/company/index.php
13 http://www.blackboard.com
14 http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?DB=pubmed
15 http://www.gutenberg.org/wiki/Main_Page
16 http://www.findarticles.com/
17 http://www.proquest.com/products_pq/descriptions/abi_inform.shtml
22
Abbildung 4: SafeAssignment - Report
6.1.5 Docoloc
Dieses Online Service bietet auf einfache Weise die Möglichkeit Dokumente zu
übertragen und nach einer Bearbeitungszeit einen Report per email zu erhal-
ten, oder online betrachten zu können. Docoloc verwendet die Google Suche
und hat somit laut eigenen Informationen auf über 8 Mrd. Dokumente Zugriff.
[Docoloc 2006]
6.1.6 Plagiarism-Finder
Der Plariarism-Finder wurde in Deutschland entwickelt und bietet als Standalo-
ne Lösung eine einfache Möglichkeit um mit Hilfe einer Suchmaschine ähnliche
Quellen zu finden. Dafür werden zusammenhängende Wörter als Suchanfrage
herangezogen. Der Benutzer hat die Möglichkeit diese Suche nur stichprobenar-
tig, normal oder ausführlich durchführen zu lassen, wobei die Bearbeitungszeit
dabei zwischen 2 und 40 Minuten schwankt. [Plagiarism–Finder 2006]
6.1.7 Damocles
Damocles wurde an der Monash 18 University in Australien entwickelt. Dieses
System zählt eigentlich nicht zu den kommerziellen Anwendungen, da es nur
18 http://www.monash.edu.au/
23
innerhalb der Universität zum Einsatz kommt. Im ersten Schritt werden die
unterschiedlichen Dokumentformate in Plaintext umgewandelt. Um eine interen
Datenbank aufbauen zu können werden dann alle Internetverweise innerhalb der
von Studenten übermittelten Dokumente herausgesucht. Diese Verweise werden
dann indiziert und die Inhalte in einer Datenbank gespeichert. Weiters werden
ebenfalls die übermittelten Dokumente selbst gespeichert. Zuerst wird dann in-
nerhalb dieser Datenbank nach ähnlichen Absätzen gesucht. Ist dies erfolglos, so
wird eine Internetsuche gestartet. [Damocles 2006]
6.2 Frei verfügbare Tools
Neben den kommerziellen Tools existieren auch einige frei verfügbare Anwen-
dungen.
6.2.1 Pl@giarism - a free plagiarism detection tool
Pl@giarism bietet die Möglichkeit innerhalb einer Sammlung an lokalen Doku-
menten Ähnlichkeiten herauszufiltern. In Form einer Tabelle erhält der Benutzer
einen prozentuellen Vergleich von jeweils zwei Dokumenten. Nachdem ein Doku-
mentenpaar ausgewählt wurde, werden die dazugehörigen Texte angezeigt, wobei
die Übereinstimmungen farblich dargestellt werden. [Pl@giarism 2006]
6.2.2 AntiPlagiarist / AntiCutAndPaste
Sowohl AntiPlagiarist als auch AntiCutAndPaste sind sehr einfach zu bedienen-
de Standalone Anwendungen welche Dokumente innerhalb einer lokalen Doku-
mentsammlung vergleichen können. Während AntiPlagiarist nur den Vergleich
von Textdokumenten unterstützt können mit AntiCutAndPaste zusätzlich Sour-
ce Codes von verschiedenen Programmiersprachen geprüft werden. Weiters kann
AntiCutAndPaste in die Programmierumgebung Microsoft Visual Studio inte-
griert werden.[AntiPlagiarist 2006]
6.2.3 OrCheck
Dieses als Java Applet realisierte online Service verwendet die Google API um
ähnliche Dokumente finden zu können. Damit dieses Tool verwendet werden
kann müssen die Java Sicherheitseinstellungen des eigenen Computers sehr stark
gelockert werden, da ein Lesen und Schreiben auf die lokale Festplatte notwendig
ist. [OrCheck 2006]
24
6.2.4 Visualisation and Analysis of Similarity Tool (VAST)
VAST bietet wie OrCheck mit Hilfe eines Java Applets die Möglichkeit Ähn-
lichkeiten zwischen Dokumenten zu finden. Dieses Tool arbeitet aber nicht mit
der Google API, sondern zwei Texte müssen direkt in das Tool kopiert wer-
den. Abbildung 5 zeig ein von VAST erzeugtes Bild welches Übereinstimmungen
darstellt.
Abbildung 5: VAST - generiertes Bild
Dunkle Stellen im erzeugten Bild deuten auf Ähnlichkeiten zwischen den beiden
Dokumenten hin. Anhand der Grafik kann der Benutzer nun die dazugehörigen
Textstellen anzeigen und vergleichen. [VAST 2006]
6.2.5 MOSS - Measure of Software Similarity
Das bereits im Jahre 1994 entwickelte System dient hauptsächlich der Auffin-
dung ähnlicher Stellen von Programmiercode. Dieses online Service kann nur mit
Hilfe von verschiedenen Scripts erreicht werden. Ein Script sendet ausgewählte
Dokumente an das Service, wobei der Benutzer als Antwort einen Report im
HTML Format erhält. [Moss 2006]
6.3 Gegenüberstellung
Tabelle 1 zeigt eine Gegenüberstellung von einigen zuvor angeführten Anwen-
dungen. Die Daten wurden einer Studie über Plagiatserkennungs-Software ent-
nommen und zeigen die Bewertung im Schulnotensystem. Die letzte Spalte gibt
an, wie gut das Tool für eine grosse Anzahl an Dokumenten verwendbar ist.
[Bull et al. 2006]
In Tabelle 2 werden alle zuvor erwähnten Produkte nochmals kurz aufgelistet.
25
Produkt Performance Report Zuverlässigkeit Geschwindigkeit Massendokumente
Turnitin 2 1 4 4 1
Eve2 2 3 3 3 4
Copycatch 1 1 1 1 3
Tabelle 1: Bewertung einiger Anwendungen [Bull et al. 2006]
Produkt Typ frei Suche in
Turnitin online Service nein Internetarchiv
gespeicherte Dokumente
Bücher und Journal -
Datenbank
EVE2 Applikation nein Internet
Copycatch Gold Applikation nein lokale Dokumente
SafeAssignment online Service nein Internetarchiv
öffentliche DBs
kommerzielle DBs
Docoloc online Service nein Internet
Plagiarism-Finder Applikation nein Internet
Damocles online Service - lokale DB
Internet
Pl@giarism Applikation ja lokale Dokumente
AntiPlagiarist Applikation ja lokale Dokumente
OrCheck online Service ja Internet
VAST online Service ja lokale Dokumente
Moss online Service ja lokale Dokumente
Tabelle 2: Grobe Gegenüberstellung einiger Anwendungen
7 Zusammenfassung und Ausblick
Einführend wurde in dieser Arbeit der Begriff Plagiat näher beschrieben um
Methoden zur automatischen Erkennung bzw. Unterscheidungsmerkmale ver-
stehen und erstellen zu können. Ansätze, wie solche Methoden funktionieren
wurden in Kapitel 3 vorgestellt. Um kompliziertere Plagiate erkennen zu können,
sind auch komplexere Methoden notwendig. Vielversprechend, wenn auch rela-
26
tiv aufwändig sind stilometrische Ansätze. Der Mehrzahl der Methoden fehlt es
aber noch an Invarianz gegenüber Einflüssen wie beispielsweise der verwendeten
Sprache, verschiedener Textlänge oder der Anzahl der Autoren einer Arbeit.
Da die Zahl der Plagiate deutlich im Ansteigen ist, ist zukünftig auch mit einem
entsprechenden Bedarf an einer Weiterentwicklung der Erkennungsmethoden zu
rechnen. Plagiate zu Erkennen ist eine Herausforderung an die moderne Wis-
sensgesellschaft.
27
Literatur
[Aiken et al. 2003] Aiken, A., Schleimer, S., Wilkerson, D., S.:
”
Winnowing: Local Al-
gorithms for Document Fingerprinting “; Proceedings of ACM SIGMOD Inter-
national Conference on Management of Data, USA (2003) S. 76–85.
[AntiPlagiarist 2006] ACNP Software Website:
”
AntiPlagiarist / AntiCutAndPast“;
http://www.anticutandpaste.com/, visited: 9 Jänner 2007
[Baayen et al. 1996] Baayen, H.; Halteren, H.; Tweedie, F.:
”
Outside the cave of Sha-
dows: Using Syntactic Annotation to Enhance Authorship Attribution“; Literary
and Linguistic Computing, Vol. 11, Nr. 3 (1996) S. 121–130
[Broder 1998] Broder, A., Z.:
”
On the Resamblance and Containment of Documents
“; In SEQS: Sequences ’91, 1998.
[Bull et al. 2006] University of Luton:
”
Technical Review of Plagiarism Detection Soft-
ware Report“; http://www.jisc.ac.uk/uploaded_documents/luton.pdf, visi-
ted: 8 Jänner 2007
[CIA Research 2005] The Center for Academic Integrity: http://www.
academicintegrity.org/cai_research.asp, visited: 3 Jänner 2007
[Collberg, Kobourov 2005] Collberg, C. and Kobourov, S.:
”
Self–Plagiarism in Com-
puter Science“; Communications of the ACM, Vol. 48, Nr. 4 (April 2005), S. 88–94
[Copycatch 2003] CFL Software Development:
”
Copycatch Gold“; http://www.
copycatchgold.com/ visited: 8 Jänner 2007
[Cosma, Joy 2006] Cosma, G., Joy, M.:
”
Source–Code Plagiarism: A UK Academic
Perspective “; University of Warwick, Technical Report No. 422 (2006).
[Daly, Horgan 2005] Daly, C. and Horgan, J.:
”
Patterns of plagiarism “; ACM SIGCSE
Bulletin, Vol. 37, Nr. 1 (2005), S. 383–387
[Damocles 2006] Damocles Website: http://viper.csse.monash.edu.au/damocles/
about/, visited: 10 Jänner 2007
[Docoloc 2006] Docoloc Website: http://www.docoloc.com/, visited: 9 Jänner 2007
[Eissen, Stein 2006] Eissen, S. and Stein, B.:
”
Intrinsic Plagiarism Detection“; Procee-
dings of the 28th European Conference on IR Research, ECIR 2006, Springer
(2006), S. 565–569.
[Eve2 2007] Canexus Website:
”
EVE Plagiarism Detection System website“; http:
//www.canexus.com/, visited: 8 Jänner 2007
[Glatt 2007] Glatt Plagiarism Services website: http://www.plagiarism.com/, visited:
16 Jänner 2007
[Halstead 1977] Halstead, M.:
”
Elements of Software Science “; Elsevier, New York.
[Helfman 1994] Helfman, J. I.:
”
Similarity Patterns in Language “;, 1994 IEEE Sym-
posium on Visual Languages (1994), S. 173–175
[Holmes 1994] Holmes, D.:
”
Authorship Attribution“; Computers and the Humanities,
Vol. 28, Nr. 2 (April 1994), S. 87–106
[Hoover 2003] Hoover, D. L.:
”
Another Perspective on Vocabulary Richness“; Compu-
ters and the Humanities, Vol. 37, Nr. 2 (May 2003), S. 151–178
28
[Kienreich et al. 2006] Kienreich, W., Granitzer M., Sabol V., Werner Klieber, W.:
”
Plagiarism Detection in Large Sets of Press Agency News Articles “; Proceedings
of the 17th International Conference on Database and Expert Systems Applica-
tions (DEXA’06) (Sept. 2006), S. 181–188
[Malkin, Venkatesan 2005] Malkin, M. and Venkatesan, R.:
”
Comparison of Texts Stre-
ams in the Presence of Mild Adversaries “; ACM, Conferences in Research and
Practice in Information Technology Series; Vol. 108 (2005), S. 179–186
[Maraisn et al. 2006] Marais, E., Minnaar U., Argles, D.:
”
Plagiarism in e–learning
systems: Identifying and solving the problem for practical assignments “; Procee-
dings of the Sixth International Conference on Advanced Learning Technologies
(ICALT’06); Vol. 108 (July 2006), S. 822–824
[Maurer et al. 2006] Maurer, H., Kappe, F., Zaka, B.:
”
Plagiarism – A Survey“; J.UCS
(Journal for Universal Computer Science), Vol. 12, Nr. 8 (2006), S. 1050–1084.
[Mishne, de Rijke 2004] Mishne, G., De Rijke, M.:
”
Source Code Retrieval using Con-
ception Similarity “; Proceedings of RIAO (2004).
[Moussiades, Vakali 2005] Moussiades, L., Vakali, A.:
”
PDetect: A Clustering Ap-
proach for Detecting Plagiarism in Source Code Datasets “; The Computer Jour-
nal Vol. 48, Nr. 6 (2005), S. 651–661.
[Moss 2006] Moss Website:
”
A System for Detecting Software Plagiarism“; http://
theory.stanford.edu/~aiken/moss/, visited: 10 Jänner 2007
[OrCheck 2006] Centre for Interactive Systems Engineering:
”
OrCheck “; http://
cise.sbu.ac.uk/orcheck/, visited: 9 Jänner 2007
[Plagiarism.org 2006] Research resources at plagiarism.org, http://www.plagiarism.
org/research_site/e_what_is_plagiarism.html, visited: 15 November 2006
[Plagiarism–Finder 2006] Plagiarism–Finder Website: http://www.m4-software.de/
index.htm, visited: 10 Jänner 2007
[Pl@giarism 2006] Universiteit Maastricht:
”
Pl@giarism Website:“; http://www.
personeel.unimaas.nl/georges.span/Plagiarism/, visited: 10 Jänner 2007
[SafeAssignment 2006] MyDropBox Website:
”
SafeAssignment“; http://www.
mydropbox.com/services/safeassignment.php, visited: 9 Jänner 2007
[Stamatatos et al. 2000] Stamatatos, E.; Kokkinakis, G.; Fakotakis, N.:
”
Automatic
text categorization in terms of genre and author“; Computational Linguistics,
Volume 26, Issue 4 (December 2000), S: 471–495
[Stamatatos et al. 2001] Stamatatos, E.; Kokkinakis, G.; Fakotakis, N.:
”
Authorship
Attribution Without Lexical Measures“; Computers and the Humanities, Vol. 35,
Nr 2 (May 2001), S. 193–214
[Steinmann 2004] Steinmann, C.:
”
Forensische Linguistik und Stilometrie “; http://
cornelia.siteware.ch/linguistik/stilo.html, visited: 1 Jan. 2007
[Sutherland–Smith 2005] Sutherland–Smith W.:
”
Pandora’s box: academic percepti-
ons of student plagiarism in writing “; Journal of English for Academic Purposes,
Vol 4 (2005), S. 83–95.
[Turnitin 2007] Turnitin website: http://www.turnitin.com/, visited: 8 Jänner 2007
[Uzuner et al. 2005] Uzuner, Ö., Katz B., Nahnsen T.:
”
Using Syntactic Information
to Identify Plagiarism“; Proceedings of the 2nd Workshop on Building Educa-
tional Applications Using NLP, S. 37–44, Ann Arbor, June 2005. Association for
Computational Linguistics.
29
[VAST 2006] Centre for Interactive Systems Engineering:
”
Visualisation and Analy-
sis of Similarity Tool“; http://cise.lsbu.ac.uk/orcheck/vast.html, visited: 9
Jänner 2007
[Wiki Lingua 2007] Wiki Lingua – Computerlinguistik Universität Trier, http://
www.uni-trier.de/uni/fb2/ldv/ldv_wiki/index.php/Chunking_I, visited: 16
Jänner 2007
[Wikipedia 2007] Wikipedia website about:
”
Lexem“; http://de.wikipedia.org/
wiki/Lexem, visited: 16 Jänner 2007
[White, Joy 2004] White, D. R. and Joy, M. S.:
”
Sentence–Based Natural Language
Plagiarism Detection“; ACM Journal on Educational Resources in Computing
(JERIC), Vol. 4, Nr. 4 (Dezember 2004), Article No. 2
Abbildungsverzeichnis
1 PDetect – Workflow; [Moussiades, Vakali 2005] . . . . . . . . . . . . . . 17
2 Turnitin Report; [Turnitin 2007]; http://www.turnitin.com . . . . . . . 20
3 Copycatch GOLD; [Copycatch 2003]; http://www.copycatchgold.com . . 21
4 SafeAssignment; [SafeAssignment 2006]; http://www.mydropbox.com . . 23
5 VAST; [VAST 2006]; http://cise.lsbu.ac.uk/orcheck/vast.html . . . . . . 25
Tabellenverzeichnis
1 Bewertung einiger Anwendungen [Bull et al. 2006] . . . . . . . . . . . . 26
2 Grobe Gegenüberstellung einiger Anwendungen . . . . . . . . . . . . . . 26
30
