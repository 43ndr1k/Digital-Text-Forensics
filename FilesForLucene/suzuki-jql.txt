1 
 
Stylistic analysis of text submissions to Japanese Q&A 
Communities* 
 
Takafumi Suzuki1, Shuntaro Kawamura2 and Akiko Aizawa23 
1Toyo University, 2University of Tokyo, 3National Institute of Informatics 
 
Running head: Stylistic analysis of Japanese Q&A text submissions 
 
 
ABSTRACT 
 
This study is a mixed method, i.e., qualitative as well as quantitative, analysis of the stylistic 
characteristics of texts submitted to Japanese Q&A communities. Along with the development 
of social media, Q&A communities are attracting much scholarly attention as important 
resources for analyzing online communication. In Q&A communities, people freely submit 
questions and answers; questions are classified into subject categories; and the best answers are 
selected. In this study, we analyze the stylistic characteristics of three types of submission, i.e., 
questions, best answers, and normal answers, in two different subject categories, i.e., ‘personal 
computers and related devices’ and ‘love and human relations advice’. The results show that the 
textual styles clearly distinguished these six classes of texts and clarified their respective 
characters. Our findings provide useful knowledge about how people differ in their 
communication styles regarding subject categories and on how people select communication 
styles. This study will contribute to research into discovering current online communication 
styles. 
 
Key words: computational stylistics, Q&A communities, stylistic text classification 
 
 
1. INTRODUCTION 
 
Through the development of the Web, various new text media have appeared (Aitchison 
& Lewis, 2003). In particular, texts in social media such as Wiki, blogs, and SNS are 
produced by the users themselves, reflect their users’ interests, and reveal new styles of 
online communication. The textual characteristics of such media should be useful for 
tracking changes in language usage and current communication styles on the Web, 
especially in the context of Japanese. 
Among the many social media, Q&A communities, where people freely submit 
questions and answers online, are attracting much scholarly attention. In Q&A 
communities, questions are classified into subject categories, and the best answers are 
selected by some criteria.1 Thus, the text submissions provide us with fruitful examples 
of how people differ in their communication styles regarding subject categories and of 
how people select communication styles to fit their circumstances. 
To analyze the text submissions, we focus on their styles. Style, i.e., textual 
characteristics orthogonal to the content of the text, is ‘how it is mentioned in the text’ 
                                                   
1 Regarding the data we used in this study, all the best answers were selected by questionnaire. 
*Address Correspondence to: Takafumi Suzuki, Faculty of Sociology, Toyo University. 5-28-20, 
Hakusan, Bunkyo-ku, Tokyo, 112-8606, Japan. Email: takafumi_s@toyo.jp. 
2 
 
(Argamon et al., 2007), and knowledge of style has various new applications, such as 
authorship profiling, sentiment analysis, and computational sociolinguistics, as well as 
conventional applications, such as authorship attribution and genre discrimination 
(Argamon et al., 2007; Koppel et al., 2009; Stamatatos, 2009; Suzuki, 2009). Styles are 
useful for determining, for example, the author’s personality, feelings, sentiments; thus, 
we thought they would be good for analyzing communication styles of Q&A 
communities. 
This study constitutes a mixed method, i.e., qualitative as well as quantitative, 
analysis (Creswell & Clark, 2007) of the stylistic characteristics of texts submitted to 
Japanese Q&A communities. We first use quantitative methods such as multivariate 
analysis and machine learning to understand whether any factor affects the styles of text 
submissions, and then analyze the specific expressions related to the factors affecting 
the styles using random forests feature selection techniques (Breiman, 2001; Suzuki, 
2009). 
We especially focus on the two factors, namely question types and submission types. 
Two question types we analyze here are factual questions 2  and personal advice 
questions3 (Harper et al., 2008; Miura & Kawaura, 2008), which are typical, yet 
completely different types of questions. By analyzing the stylistic characteristics of 
three submission types, namely questions, best answers, and normal answers, of these 
two question types (subject categories), we can see how people vary their 
communication styles across subject categories and how people select communication 
styles. Our purpose here is to clarify the effects of the two factors on the stylistic 
characteristics of this new type of texts. By so doing, we can derive knowledge on how 
people communicate with each other online, which is becoming more and more 
important since people are spending more time in virtual spaces. Our study also 
provides fundamental knowledge for many information retrieval and natural language 
processing tasks, e.g., good answer estimation, automatic paraphrasing, and automatic 
conversation generation. The rest of this paper is organized as follows. We review 
related work in Section 2. We explain our data in Section 3 and methods in Section 4. 
We discuss the results of the basic observation, principal component analysis, and 
feature analysis in Section 5 and conclude in Section 6. 
 
 
2. RELATED WORK 
 
There have been a lot of studies in the field of computational stylistics (Kenny, 1982), 
and currently multivariate analyses and machine learning have become popular in this 
field (Grieve, 2007; Jin & Murakami, 2007; Koppel et al., 2009;Stamatatos, 2009). 
These methods were first used for classifying texts and clarifying factors affecting the 
classification (Burrows, 2003a, b). Recently however, some studies have tried to use 
these methods for characterizing texts; that is, they focus more on analyzing the features 
contributing to the classification and use the classification results for interpreting and 
understanding the texts (Argamon et al., 2007; Suzuki, 2009). This study, sharing these 
                                                   
2 They are, in other words, questions that have certain answers. 
3 They are, in other words, questions that have no certain answers. 
3 
 
current tendencies, uses multivariate analysis and machine learning to characterize texts 
submitted to Q&A communities. 
Q&A communities have recently attracted much scholarly attention. Gazan (2011) 
presents a review and analysis of the research literature related to this topic. Adamic et 
al. (2008) tried to clarify the characteristics of Q&A communities by examining basic 
characteristics according to subject categories and network structure between 
questioners and repliers. Liu et al. (2008) investigated information seeker satisfaction 
and presented a general prediction model based on content, structure, and 
community-focused features. Pomerantz (2005) surveyed the literature in automatic 
question answering and identified five question taxonomies at four levels of linguistic 
analysis, and Kim & Oh (2009) tried to clarify questioners’ relevance criteria by doing 
content analyses of the submissions. Harper et al.(2008) investigated predictors of 
answer quality through a comparative, controlled field study of responses, and Harper et 
al. (2009) tried to distinguish informational and conversational questions using machine 
learning. Shah & Pomerantz (2010) tried to evaluate and predict answer quality using 
qualitative and quantitative features with logistic regression. 
Regarding Japanese Q&A communities, Kuriyama & Kando (2009), and Sato et al. 
(2009) tried to classify the submissions by their respective criteria, and Miura et al. 
(2007) evaluated the frequencies of frequent nouns in submitted texts. Nishihara et al. 
(2008) tried to understand patterns between questions and answers according to the end 
of the sentences expressions. Nishimura et al. (2009) tried to detect the authors of the 
submissions. As such, there is an increasingly large body of literature studying 
submissions to Q&A communities in the field of information retrieval and natural 
language processing, but the stylistic characteristics of the submissions have not been 
explored yet. 
 
 
3. DATA 
 
We used Yahoo! Chiebukuro (Japanese version of Yahoo! answers) data provided to 
National Institute of Informatics by Yahoo Japan Corporation. This data includes 
3,116,009 questions, 3,116,008 best answers, 10,361,777 normal answers that were 
submitted during the period from April 2004 to October 2005. All the submissions 
are classified into subject categories. 
We selected two categories for our analyses, ‘personal computers and peripheral 
devices’ (PC), and ‘love and human relationships advice’ (LH). The former category is 
a typical one that includes factual questions, whereas the latter category is a typical one 
that includes personal advice questions. We collected texts of questions (Q), best 
answers (BA), normal answers (NA), per month4 and applied morphological analysis 
using MeCab,5 a Japanese morphological analysis system. We assigned parts-of-speech 
tags by using MeCab and calculated the number of tokens per submission and 
frequencies of function words per a text. 
                                                   
4 Text is usually analyzed on a per submission basis for many tasks, but our purpose here is to clarify the 
basic stylistic characteristics of six categories; thus, it is better to use the texts per month. 
5 mecab.sourceforge.net 
4 
 
As features, we used the bag-of-words of the relative frequencies of function words, 
i.e., functional nouns (noun-dependent and noun-pronominal), adnominals, conjunctions, 
particles and auxiliary verbs. As function words orthogonal to the content represent the 
affect, genre, register and personality of the texts (Argamonet al., 2007), and are 
effective for sociolinguistic analysis as well as stylistic text classification (Garcia & 
Martin, 2007; Grieve, 2007; Suzuki, 2009), they are appropriate features for our 
purpose. In Japanese, particles and auxiliary verbs are strongly related to the modality 
of the text (Otsuka et al., 2007) and adnominals, conjunctions, and some particles 
represent the logicality and readability of the text (c.f., Otsuka et al., 2007; Tuldava, 
1993), while some functional nouns can represent explanation patterns. The detailed 
interpretation of these features will be given when we set out our results in Section 5. 
It is better for our purpose to use deeper-order part-of-speech tags of particles6 and 
the stemming version of auxiliary verbs as they facilitate more meaningful 
interpretations.7 
 
 
4. METHODS 
 
After we observe the basic characteristics, we make a text-feature matrix, whose rows 
represent the texts per month and columns represent features (relative frequencies of 
each function word to the sum of all the function words). Then we apply principal 
component analysis and random forests. 
First we apply principal component analysis with the covariance matrix of the 
features. Principal component analysis enables us to view the distances or similarities of 
stylistic characteristics between the six class texts as a scatter plot and to clarify the 
factors classifying the texts as the principal component.8 
We next used the random forests classifier proposed by Breiman (2001) as our 
classification method. Random forests is an improved way of bagging (Breiman, 1996), 
an ensemble learning method. The basic idea of ensemble learning is to improve the 
classification performance of previous statistical methods, i.e., decision trees in these 
cases, by repeatedly performing the experiments and calculating the mean or majority 
votes on the results. However, the results will always be the same when using exactly 
the same data to perform these experiments, thus ensemble learning methods including 
bagging usually use bootstrap samplings from the original data to repeat the 
experiments. The main improvement in random forests from bagging is the extraction of 
a random subset from each bootstrapping sample, that enlarges the variances in 
bootstrapping samples (Breiman, 2001; Jin, 2007). 
We first sampled from i cases at random from the original text-feature matrix Mi, j 
with replacements to make a bootstrap sample, and we extracted random subsets of √j 
                                                   
6 ‘Case particles’ or ‘conjunctive particles’ etc. 
7 A particle can have different meanings when it is used in different second-order parts-of speech, while 
the different forms of an auxiliary verb have the same meaning in Japanese. 
8 There are other methods of exploratory data analyses, e.g., factor analysis, correspondence analysis, or 
multidimensional scaling. Even though there are no special rules for deciding which method is the best 
for respective data, we selected PCA because its results tend to be unambiguous, and thus it should be 
applied first (Jin, 2007). 
5 
 
variables from a bootstrap sample to make a sample for constructing an unpruned  
decision tree. For split the nodes, we used the Gini index formalized as follows: 
 
 
 
where pτk represents the proportion of data points in region Rτ assigned to class k (k = 
1,…, K), and this vanishes for pτk = 0 and pτk = 1 and has a maximum at pτk = 0.5 
(Bishop, 2006). These sampling, extraction, and tree-constructing processes are 
repeated 1000 times, and we construct a new classifier by a majority vote of the set of 
trees. When the training set for the current tree was drawn by sampling with 
replacement, one-third of the cases were left out of the sample. This is called the 
out-of-bag (OOB) data, and used to get a running unbiased estimate of the classification 
error as trees are added to the forest. It is also used to get estimates of variable 
importance (Breiman & Cutler, -). 
An important characteristic of random forests is it returns variable importance (VIacu) 
for classification experiments. For calculating variable importance, we first put down 
the out-of-bag cases and count the number of votes cast for the correct class, and second 
we randomly permute the values of the variable m in the out-of-bag cases, and put these 
cases down the tree. We subtract the number of votes for the correct class in the 
variable-m-permuted out-of-bag data from the number of votes for the correct class in 
the original, untouched out-of-bag data. We calculate the average of this number over 
all trees in the forest, and that number is the raw importance score for variable m. 
Finally, we divide the raw score by the standard error of the valuable in the calculation 
over all the trees, and that number is VIacu for variable average m (Breiman, 2001; 
Breiman & Cutler, -). The VIacu represents the degree to which a class loses its specific 
character when one type of morpheme changes into another type of morpheme. This 
method has advantages for our task, as our purpose is to compare the contributions of 
the indicators, rather than achieving the best performance. This method calculates 
important variables directly contributing to the classification in the experiment; thus, it 
best suits our purposes. 
We used the macro average of F1 values for evaluating the results. Random forests 
uses random numbers in the experiments; thus, we performed the experiments100 times 
and calculated the mean F1 values for these 100 experiments (Jin& Murakami, 2007). 
 
 
5. RESULTS AND DISCUSSION 
 
5.1. Basic observation 
 
Table 1 lists the results of the basic observation, number of submissions, and number of 
tokens for a submission (mean, standard deviations, coefficient of variation), for six 
categories. The results show that on average LH has a larger number of submissions and 
is longer in length than PC; BA is as long as Q; NA is shorter than others, and NA has 
larger variances than others. 
6 
 
 
 
Insert Table 1 here. 
 
 
Table 2 lists the respective numbers of tokens (N) and types (V(N)) for each 
part-of-speech and all the function words in six categories. These results show that BA 
has a larger N than Q in terms of conjunctions and particles and a smaller N in 
functional nouns and auxiliary verbs. The tendency of N is different between PC and 
LH adnominals. NA has larger N and V(N) compared with Q and BA, because it 
includes multiple answers. These basic characteristics show the differences between 
PC/LH and Q/BA/NA, which we will discuss in Section 5.3 in detail. 
 
 
Insert Table 2 here. 
 
 
5.2. Principal component analysis 
 
We carried out a principal component analysis using the covariance matrix of the 
features.9 Fig. 1 represents the scatter plot showing the first two principal components.10 
The proportion of variance accounted for by the first principal component was 56.17%, 
and the cumulative proportion of variances accounted for by the first two principal 
components was 93.37%. The first principal component mainly represents the axis of 
subject categories, because the texts in LH fell to the left side of the scatter plot and 
those in PC to the right side. The second principal component mainly represents the axis 
of questions/answers, because questions fell on the upper side, and answers on the lower 
side. Best answers and normal answers were clearly distinguished regarding PC, but not 
regarding LH. These results show that the difference between questions and answers is 
rather large, and there is still a difference between best and normal answers regarding 
writing styles. Three texts in a rather isolated position in the scatter plot were 
submissions in April 2004, in which the total number of tokens (N) and number of 
submissions were small. 
 
 
Insert Fig. 1 here. 
 
 
5.3. Feature selection by machine learning 
 
We next carried out six-class classification experiments (Q_LH, Q_PC, B_LH, B_PC, 
N_LH, N_PC) by using random forests using the text-feature matrix of function words 
(each part-of-speech tags and all the function words). Table 3 describes the precision, 
                                                   
9 We also carried out the method using the correlation coefficient matrix, and found no significant 
differences between results. 
10 Texts are indicated by combinations of subject categories (PC/LH) and types (Q/BA/NA). 
7 
 
recall rates, and F1 values in each classification experiment, using functional nouns, 
conjunctions, adnominals, particles (first and second order part-of-speech tags), 
auxiliary verbs (with and without stemming), particles, and all function words 
(second-order part-of-speech tags and with stemming). F1 values were more than 93 % 
in each part-of-speech experiment. It should be remarkable that (a) particles and 
auxiliary verbs returned better performance than other part-of-speech, and (b) deeper 
order part-of-speech tags (particles) and stemming (auxiliary verbs) improved 
performance. While (b) corresponds the results by a previous study that analyzed 
political speeches with a similar method (Suzuki, 2009), (a) do not necessarily 
correspond to their results. It can be inferred that (b) is a general finding common to 
many types of texts, while (a) is a finding specific to this type of texts. 
 
 
Insert Table 3 here. 
 
 
Table 4 show the top 20 variables in the classification experiments using all the 
function words with their parts-of-speech, variable importance (VIacu), and the notation 
that these variables were frequently used (H) or infrequently used (L) in the category in 
comparison with mean of other categories. These variables significantly contributed to 
the classification, and, thus, they represent class-specific function words. We shall 
discuss the results by conducting qualitative analyses. In this way, we will find many 
interesting issues in an exploratory way. 
 
 
Insert Table 4 here. 
 
 
Comparison of subject categories regarding questions 
 
Both categories include the particle ‘ka’ as a frequent expression. This is a typical 
expression for making questions and a salient character of the question type. LH 
includes many pronouns like ‘watashi’ (I; rank1), ‘kare’ (he; 2), ‘boku’ (I; 11), and 
‘kanojo’ (she; 16), and adnominal ‘konna’ (such; 6) and noun-affix ‘mitai’ (like; 5) as 
frequent expressions; these rarely appeared in the PC category. These results represent 
the characteristic of the LH category wherein people tend to ask questions after they 
explain episode about themselves. The frequent expressions in the PC category includes 
the particle-conjunctive ‘ga’ (-(subjective); 7) and noun-affix ‘no’ (of; 4). These results 
represent the characteristic that people simply ask about people what they would like to 
know. 
 
Comparison of best and normal answers 
 
Both answers in the LH category include particle-conjunctive ‘tari’ (- (parallel), 6) as a 
frequent expression, while it does not appear in the PC answers. ‘tari’ is a parallelling 
expression used as ‘… sitari, … sitari’. This result represents the characteristic of the 
LH category whereby people tend to reply with several propositions, instead of the one 
8 
 
specific solution, as is usually expected in the PC category. BA in the LH category 
includes ‘anata’ (you; 18) as a frequent expression, whereas NA in the LH category 
includes ‘anta’ (you; 14); the latter is a impolite version of the former in Japanese. This 
result implies that answers with polite expressions are likely to be selected as a best 
answer. BA in PC includes the particle-adnominalizer ‘no’ (of; 2), particle-case ‘wo’ 
(-(objective); 3), and particle-case ‘ni’ (on; 4) as frequent expressions, while NA in PC 
includes the particle-adverbial ‘ja’ (-(conversational); 3), particle-adverbial ‘nante’ 
(-(conversational); 2), particle-final ‘ne’ (-(conversational); 7) and particle-final ‘yo’ 
(-(conversational); 14). The former results imply that BA in PC is a writing style like 
that found in instructional manuals containing specific explanations with clear and 
pertinence expressions (‘… wo … ni …’), while the latter results mean that NA in PC is 
a conversational style because all of the latter expressions are chatty ones. The results 
show that regarding the PC category, polite and ‘manuallike’ submissions are likely to 
be selected as the best answers than conversational submissions. 
 
 
6. Conclusion 
 
This study was a mixed method analysis of the stylistic characteristics of text submitted 
to Japanese Q&A communities. After observing the basic characteristics of the 
submissions, we applied principal component analysis and random forests to the 
text-feature matrix using the relative frequencies of function words. The results clearly 
show the stylistic characteristics of questions, best answers, and normal answers 
regarding the two categories of ‘personal computers and peripheral devices’ and ‘love 
and human relations advice’. This study provided basic, but very important findings on 
how people differ in their communication styles regarding subject categories and on  
how people select communication styles online. 
Our findings will be the foundation of various research. First, we will develop 
methods to distinguish the best answers from normal answers, by extending the findings 
of this study. Second, we will make a predictive transform or automatic paraphrase 
system focusing on the styles that we identified. Third, we will investigate the changing 
language usage of Japanese by comparing texts of the submissions against balanced 
corpora. 
 
Acknowledgement 
We used Yahoo! Chiebukuro data, that Yahoo Japan Corporation provided National 
Institute of Informatics. We would like to express our gratitude for them. This study 
was supported by Grant-in-Aid for Scientific Research 21800087 for Young Scientists 
(Start-up) and 23700288 for Young Scientists (B), from the Ministry of Education, 
Culture, Sports, Sciences and Technology, Japan, and Grant for joint research from 
National Institute of Informatics. Earlier versions of this study was presented at the 53rd 
Annual Meeting of the Mathematical Linguistic Society of Japan at the Tokyo 
Woman’s Christian University, and 10th International Conference on Statistical 
Analysis of Textual Data at the Sapienza University of Rome. We would like to express 
9 
 
our gratitude for the participants in the meeting for their useful comments. We would 
also like to thank Professor Kyo Kageura at the University of Tokyo and Professor 
Noriko Kando at the University of Tokyo for their useful comments. 
 
 
 
Appendix 
 
These are sample texts extracted from the submissions at October 2005 to Yahoo! 
Chiebukuro. 
 
LH_Q 
 
Toku ni baiku-zuki no dansei ni kiki-tai desu. Ima chotto kini natte-iru danseiwa 
baiku-zuki de, baiku wo totemo daiji ni shite-iru mitai desu. Sorede, futari desyokuji ni 
itta toki, kare kara ikinari ‘Kondo au toki wa baiku ni nosete ageru’ toiware mashita. 
Kyotu no yujin ni kono koto wo hanashitara, ‘Ushiro ni-wa daremo nosenai-tte mae ni 
itteta koto aruyo’ to iware mashita. Korewa, sukoshi wawatashi ni ki wo yurushite iru 
no de syou-ka? 
(I would especially wonder about men who love to ride motorcycles. It seems that 
the men who love to ride motorcycles make much of it. When I went to dinner together 
with one motorcyclist, he said to me ‘Next time we meet, you should ride on the back of 
my motorcycle’. I talked about this with a mutual friend, ands he said ‘He told me he 
never allows anyone to ride on back of his motorcycle’. Was he off guard with me?) 
 
LH_Q 
Kare ga shigoto de tsukare te bakari ite, saikin, genki ga nai-no-ga uzaku 
nattekima-shita. Watashi ni yowane hakitaku naru no wa wakarun desu ga, mou 
sukosisyaki-tto shite hoshii-desu. Konna watashi wa tsumetai onna de syouka? 
   (He is always too tired at work, and recently, he’s been down so much that he’s 
become bother to me. I understand that he would like to tell me all his negative thoughts, 
but I would like him to be more mature. Are women like me cold?) 
 
PC_Q 
Mac OS (nihongo ban) wo tachiageru to, itsumo moji nyuryoku modo ga katteni, ‘kana 
nyuryouku’ ni natte-iru no desu ga, kidouji ni hankaku eisu modo de tachiagerukoto wa 
kano desuka? Mata, dekiru to shitara doko no settei wo ijirebayoi no de syouka? Mac 
OSX, Mac OS9 izen, kurashikku kankyo sorezore ni tsuiteoshiete itadakeru to  
arigatai desu. 
(When I start up Mac OS (Japanese version), the character input device always says 
‘Japanese kana’. Is it possible to start up in English one byte character mode? And, if 
possible, which settings should I change? Could you tell me how to do so in Mac OSX, 
as well as in the preceding versions of Mac OS9 and Classic?) 
 
LH_BA 
10 
 
Tomodachi to ason-dari, nomikai ittari, DVD karite-kite mitari. Nakanaka yuigini 
sugoshite masu. Ironna tomodachi to asobuto, wa ga hirogatte dondon tomodachiga 
fuete tanoshi desu (^ ⊆ ^). Jibun migaki wa . . . n ˜. Sutorecchi kuraikana? ... 
(Playing with friends, going drinking, watching DVD. I spent a meaningful life. It is 
fun to play with various friends as networks between friends become larger and larger 
(^ ⊆ ^). Regarding self-improvement . . . n ˜. Stretching? ... ) 
 
LH_BA 
Naze anata ga futtanoka, riyuu wa aite no kata ni wakareru toki ni tsutaeta no desu ka. 
Daisuki datta kara koso, waruguchi wo iwarete taerare nakatta koto, wakarete kara mo 
suki-na kimochi ni kawari wa naku ima mo daisuki da, to sono niten wo kyocyo-shite 
meru de tsutaete mite wa do de syo. Saigo ni, onaji toshigoro nomusume ga iru node 
hahaoya to shite no iken desu. Benkyo mo chanto shite ne. Koi mo juken benkyo mo, 
ima-shika dekinai koto wa zenryoku de ganbatte hoshiidesu. 
(Did you tell him why you dumped him? How about telling him by mail 
emphasizing two points; you are impatient and you lash out, and you still love him. 
Finally, as a mother who has a daughter of your age, I think you ought to study hard. I 
would like you should study and love with all of your heart, because these are 
opportunities that will one day pass.) 
 
LH_NA 
Kanojo wa anta toiu hito yori komuin toiu ‘antei’ ga iino da yo. ‘amattare te naide 
motto genjitsu-teki ni naro u yo’ tte ‘genjitsu teki’ to iu kotoba, tsumari, ‘kane’ da yo. 
Hayaku kiduki nayo. 
(She prefers ‘stability’ of a public officer to your lifestyle. The ‘realistic’ in ‘You 
should be realistic’ means you should have ‘money’. You ought to be aware of this.) 
 
PC_BA 
C doraibu wa kihon-teki ni shisutemu doraibu to syoshi masu. C doraibu wa PC wo 
unyo-suru tame no OS wo kioku sasete iru kankei de sagyo ni shiyo suru deta wo 
icvhijiteki ni sakusei site yuku ryoiki wo katte ni tsukuri masu. Sono kankeijo C doraibu 
wa jubunna yoryo wo kakuho-suru hitsuyo ga ari, yokei-na sofuto wabetsu patisyon ni 
insutoru suru to iu no ga, chotto mae made no tsusetsu deshita.Sakkon no PC no seino 
appu de hado, OS tomo ni seinou ga agari saikin dewa sahodo ki ni shinakutemo yoi to 
omoware masu. Doshitemo wakeru hitsuyou gaaru no de areba, C doraibu wa 
apurikesyon, hokano doraibu ni deta wo hozonsureba yoi de syo. 
(C drive is called the system drive. C drive makes regions for temporarily storing 
data as it loads the PC’s OS. Related to this fact, C drive has to have enough capacity, 
and it is a common knowledge additional software can be installed in another partitions. 
But with recent improvements to PCs, other hardware, and OSs, we do not need to be as 
careful as we once had to be. If you must distinguish them, you should install 
applications on C drive and save data toon other drives.) 
 
PC_NA 
Real Player wo ire-reba mireru-n-ja nai desu ka ne? Real Network no saito ni itte 
kudasai. 
(You can watch it with Real Player? Please go to the Real Network site.) 
11 
 
 
PC_NA 
Shikyu rikabari shita ho ga iidesu yo. Dengen nagaoshi deno syattodaun wa yoku ari 
mase-n. Mashiteya konsento nuku yarikata nante motteno hoka-desu. PC 
koware-masu-yo. Ato dengen nagaoshi de syattodaun-suru baai wa HDD gaugoite inai 
koto wo kakunin shite kuda-sai. Ugoite iru toki ni syattodaun suru to HDD ga 
koware-masu node. 
(You should recover as soon as possible. It is bad to shut down by pushing the 
power button. Even more so by pulling the cord out of the wall. The PC will break 
down. Furthermore, the hard disk drive might not work if you shut it down by pushing 
the power button. The PC will break down by shutting it down like this while in 
operation.) 
 
References 
 
Adamic, L. A., Zhang, J., Bakshy, E., & Ackerman, M. S. (2008). Knowledge sharing  
and Yahoo answers: everyone knows something. In WWW’08: Proceedings of 
the 17th International Conference on World Wide Web, 665–674. 
Aitchison, J., & Lewis, D. M. (eds.) (2003). New Media Language. Routledge, 
London. 
Argamon, S., Whitelaw, C., Chase, P., Raj Hota, S., Navendu. G, & Levitan, S. (2007).  
Stylistic text classification using functional lexical features. Journal of the 
American Society for Information Science and Technology, 58(6), 802–822. 
Bishop, C. M. (2006). Pattern Recognition and Machine Learning. Springer Science+ 
Business Media, LLC, New York. 
Breiman, L. (1996). Bagging predictors. Machine Learning, 24(2), 123–140. 
Breiman, L. (2001). Random forests. Machine Learning, 45(1), 5–23. 
Breiman, L., & Cutler, A. (-). Random forests. www.stat.berkeley.edu/ ˜breiman/ 
RandomForests (accessed Jan. 6, 2011) 
Burrows, J. (2003a). ‘Delta’: a measure of stylistic difference and a guide to likely 
authorship. Literary and Linguistic Computing, 17(3), 267–287. 
Burrows, J. (2003b). Questions of authorship: attribution and beyond. Computers and 
the Humanities, 37(1), 5–32. 
Creswell, J.W., & Clark, V. L. P. (2007). Designing and Conducting Mixed Methods 
Research. Sage Publications, Inc., Thousand Oaks, CA. 
Garcia, A. M., & Martin, J. C. (2007). Function words in authorship attribution studies. 
Literary and Linguistic Computing, 22(1), 49–66. 
12 
 
Gazan, R. (2011). Social Q&A. Journal of the American Society for Information 
 Science and Technology, 62(12), 2301-2312. 
Grieve, J. (2007). Quantitative authorship attribution: an evaluation of  
techniques. Literary and Linguistic Computing, 22(3), 251–270. 
Harper, M. F., Moy, D., & Konstan, J. A. (2009). Facts or friends? Distinguishing 
informational andconversational questions in social Q&A sites. In CHI ’09: 
Proceedings of the 27th Annual International Conference on Human Factors in 
Computing Systems. 759-768, New York, NY, USA. ACM. 
Harper, M. F., Raban, D., Rafaeli, S., & Konstan, J. A. (2008). Predictors of answer 
quality in online Q&A sites. In CHI ’08: Proceedings of the Twenty-sixth 
Annual SIGCHI Conference on Human Factors in Computing Systems,  
865–874. 
Jin, M. (2007). R ni yoru Deta Saiensu. Morikita Syuppan, Tokyo. 
Jin, M., & Murakami, M. (2007). Authorship identification using random forests.  
Proceedings of the Institute of Statistical Mathematics, 55(2), 255–268. 
Kenny, A. (1982). The Computation of Style: an Introduction to Statistics for 
Students of Literature and Humanities. Pergamon Press, Oxford. 
Kim, S., & Oh, S. (2009). Users’ relevance criteria for evaluating answers in a 
social Q&A site. Journal of the American Society for Information Science and 
Technology, 60(4), 716–727. 
Koppel, M., Schler, J., & Argamon, S. (2009). Computational methods in 
authorship attribution. Journal of the American Society for Information Science 
and Technology, 60(1), 9–26. 
Kuriyama, K. & Kando, N. (2009). Q&A saito ni okeru sitsumon to kaito no bunseki. 
In IPSJ SIG technical report (FI). 95. 
Liu, Y., Bian, J., & Agichtein, E. (2008). Predicting information seeker satisfaction 
in community question answering. In SIGIR’08: Proceedings of the 31st 
Annual International ACM SIGIR Conference on Research and Development in 
Information Retrieval, 483-490. 
Miura, A., & Kawaura, Y. (2008). Why do people join Web-based knowledge sharing 
communities?: analysis on questioning and answering behavior. Japanese 
Journal of Social Psychology 23(3), 233–245. 
Miura, A., Kawaura, Y., Jifuku, S., Otaki, N., & Okamoto, M. (2007). People who 
create knowledge-sharing community (4): What is included in ‘Chie-Bukuro’?. 
In JSAI2007: Proceedings of the 21st Annual Conference of Japanese Society 
for Artificial Intelligence. 2F4-8. 
13 
 
Nishihara, Y., Matsumura, N., & Yachida, M. (2008). Understanding of writing style 
patterns between Q&A in knowledge sharing community. In JSAI2008: the 
22nd Annual Conference of the Japanese Society for Artificial Intelligence. 
1H2-7. 
Nishimura, R., Watanabe,Y., Murata, M., & Okada, Y. (2009). Yahoo! Chiebukuro ni 
toko sareta tekisuto ni taisuru chosya hanbetsu. In NLP2008: the 15th Annual 
Meeting of Japanese Natural Language Processing,558-561. 
Otsuka, H., Inui, T., & Okumura, M. (2007). Iken Bunseki Enjin: Keiryo Gengo-gaku to 
Syakai-gaku no Setten. Colona Publishing, Tokyo. 
Pomerantz, J. (2005). A linguistic analysis of question taxonomies. Journal of the 
American Society for Information Science and Technology 56(7), 715–728. 
Sato, F., Uda, N. & Matsumura, A. (2009). What is a good answer?: Factor analysis of 
good answer in Q&A community. In IEICE SIG Notes (WI2). 
Shah, C. & J. Pomerantz (2010). Evaluating and predicting answer quality in 
community QA. In SIGIR ’10: Proceedings of the 33rd International ACM 
SIGIR Conference on Research and Development in Information Retrieval, 
411-418. 
Stamatatos, E. (2009). A survey of modern authorship attribution methods. 
Journal of the American Society for Information Science and Technology, 
60(3), 538–556. 
Suzuki, T. (2009). Extracting speaker-specific functional expressions from political 
speeches using random forests in order to investigate speakers’ political styles. 
Journal of the American Society for Information Science and Technology, 
60(8), 1596–1606. 
Tuldava, J. (1993). The statistical structure of a text and its readability. In Quantitative 
Text Analysis, pp. 215–227. Wissenschaftlicher Verlag Trier, Trier. 
 
 
 
 
 
 
 
 
 
 
 
 
 
14 
 
Table 1. Basic data of our corpora 1. 
 
* Length of postings equals number of tokens of morphemes. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
15 
 
 
Table 2. Basic data of our corpora 2. 
 
N represents number of tokens of morphemes. 
V(N) represents number of types of morphemes. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
16 
 
Table 3. Precision, recall rate, and F1-values in each experiment. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
17 
 
 
Fig. 1. The scatter plot showing first two principal components. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
18 
 
Table 4. Top twenty variables with high variable importance (VIacu) for respective 
classes. 
 
 
