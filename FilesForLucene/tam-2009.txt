Age Detection in Chat 
 
Jenny Tam and Craig H. Martell 
Department of Computer Science 
Naval Postgraduate School 
1411 Cunningham Road, Monterey, California 
{jktam, cmartell}@nps.edu 
 
 
Abstract— This paper presents the results of using statistical 
analysis and automatic text categorization to identify an 
author’s age group based on the author's online chat posts.  A 
Naive Bayesian Classifier and Support Vector Machine (SVM) 
model were used.  The SVM model experiments generated an 
f-score measurement of 0.996 on test data distinguishing teens 
from adults.  We also introduce an alternative method for 
generating “stop words” that chooses n-grams based on their 
relative distribution across the classes. 
Keywords-online chat; age classification; Support Vector 
Machine; Naïve Bayesian Classifier; stop words 
I.  INTRODUCTION 
The second Youth Internet Safety Survey conducted in 
2005 by the Crimes Against Children Research Center found 
that the percentage of youths receiving unwanted sexual 
solicitations has declined.  The percentage of aggressive 
solicitations seeking offline contact, however, has not.  
Education and law enforcement may have deterred casual 
solicitors, but not the more determined or compulsive 
solicitors [8].   
To catch online predators, law enforcement officers or 
volunteers pose as youths in online chat rooms.  Given the 
limited number of law enforcement officers and volunteers, 
being able to detect adults soliciting youths using an 
automated system will help law enforcement officials.  
Internet providers could also add such a system as a feature 
for parental control [10]. 
Though it is a crime for adults to sexually exploit a child, 
depending on state law, it is not always a crime for teens to 
solicit other teens.  When analyzing suspicious chat 
behavior, it is important that law enforcement officials be 
able to detect adults soliciting teens versus teens soliciting 
other teens.  This paper presents machine learning techniques 
that have proven successful in the laboratory.  Using an 
expanded version of the NPS Chat Corpus, our goal is to 
contribute toward building an automatic recognition system 
of adults conversing with teens. 
II. SOURCE OF DATA 
Studies have shown that there are differences in 
communication in different ages, social groups, educational 
levels, and language backgrounds [1, 11, 12].  Therefore, it 
may be possible to model these differences in order to detect 
the age of an author based on the author's chat behavior. 
The chat data used was gathered by Lin from a publicly 
available chat host and is described in [6].  Though the chat 
room server hosted scheduled chat rooms and chat rooms for 
different topics, Lin gathered data from chat rooms 
organized by age to keep the topics as general and unbiased 
as possible.  A portion of this data is available as the NPS 
Chat Corpus.1 
In the Lin corpus, each chat log (document) contains all 
the chat posts of a unique author and a label with the author's 
age (self-reported in the author’s profile information).  We 
considered each line in the chat log to be a chat post.  There 
are 3,290 unique authors in the corpus.  For this study, we 
removed all documents written by authors of unknown age 
or documents that contained less than three tokens.  This left 
2,161 documents with 292,831 posts, comprised of 732,964 
tokens and 85,479 types.  The test set contained 432 
randomly selected documents (20% of total number of 
documents).  This test set was not used for feature selection 
or training.  See Table 1 for distribution of files. 
TABLE I.  NUMBER OF DOCUMENTS IN THE TEST AND TRAINING SET. 
Category Training Set Test Set
teens (13-19) 465 116
20s (20-29) 689 172
30s (30-39) 259 65
40s (40-49) 235 59
50s (50-59) 80 20
Adult (20-59) 1263 316  
III. RELATED WORK 
Lin tried to determine the age group of an author using a 
Naive Bayes Classifier (NBC).  She used the following 
features: 
 
• Emoticon (e.g. ":)" or ":P") token counts 
• Emoticon types per sentence 
• Punctuation token counts 
• Punctuation types per sentence 
• Average sentence length 
• Average word type per document 
 
                                                          
1 http://faculty.nps.edu/cmartell/NPSChat.htm 
2009 IEEE International Conference on Semantic Computing
978-0-7695-3800-6 2009
U.S. Government Work Not Protected by U.S. Copyright
DOI 10.1109/ICSC.2009.37
33
Authorized licensed use limited to: Aegean University. Downloaded on July 27,2010 at 15:21:36 UTC from IEEE Xplore.  Restrictions apply. 
Her experiments to classify teens versus 20 year olds 
failed to generate notable results.  As she compared teens 
against older and older age groups, however, her results 
monotonically increased until generating an f-score measure 
of 0.932 for teens against 50 year olds [6]. 
Pender used a Support Vector Machine (SVM) model to 
detect online sexual predators. His corpus consisted of chat 
conversations between sexual predators and volunteers 
posing as underage victims.  In his experiments, his SVM 
model had an f-score measure of 0.908 [10].  His features 
included unigrams, bigrams, and trigrams with stop words 
removed.  He generated his stop words list by finding the 79 
most frequent word types in his corpus. 
Pender was able to successfully distinguish between two 
different authors using contextual information and Lin's 
work demonstrated that a NBC could potentially classify 
different age groups.  Building on their success, we wanted 
to try a NBC model, SVM model, and n-grams to classify 
different age groups. 
IV. THE CLASSIFIERS 
We trained a series of SVMs and a NBC using a variety 
of different features. 
A. Naïve Bayes Classifier 
This classifier is discussed in [4, 6, 7].  It uses Bayes’ 
theorem and makes strong independence assumptions. The 
NBC assumes n random variables for features (F1, …, Fn) 
and a random variable, C, for classes, the probability of 
which is conditional on the set of features.  Combined with 
Bayes’ theorem, we get: 
 
1
1
1
( ) ( ,..., | )( | ,... )
( ,... )
n
n
n
P C P F F CP C F F
P F F
=  
 
For this classification task, the denominator does not 
depend on C, therefore, we can ignore it completely.  The 
NBC assumes independence among the features, thus 
simplifying our model to: 
 
1
1
( | ,..., ) ( ) ( | )n i
n
i
P C F F P C P F C
=
∝ ∏  
 
The most probable class, given the set of features in 
question, is found by taking the argmax over all C’s. 
Because the vocabulary size can be very large, the 
probability of an n-gram appearing in the vocabulary can be 
quite small.  Thus, rather than using the probability of a 
feature, given an n-gram, the log of the probability is used to 
prevent numeric underflow. 
B. Support Vector Machine 
This model is discussed in [2, 3, 4, 5, 7].  We used a 
SVM with a linear kernel, which takes two classes of data 
(e.g. teen and adults) represented by n-dimensional vectors.  
Each dimension represents a feature and the model generates 
a hyperplane, which separates the two classes.  This 
hyperplane separates the feature vectors with the maximum 
margin. 
Conversations between different groups can be very 
similar (e.g. between teens and 20s), thus classes are likely to 
overlap or have a very small margin.  Since SVMs are 
maximum-margin classifiers, we used "slack variables" [5] 
to compensate for this effect. 
V. FEATURE EXTRACTION 
The following word-based features were used: unigrams, 
bigrams, trigrams, character trigrams, and word meta-data 
features.  We also used character 4-grams, and 5-grams in 
the NBC experiments. 
We used character n-grams, a series of n characters, 
because they can capture indications of style including 
lexical information, contextual information, and use of 
punctuation.  Additionally, such n-grams are noise tolerant.  
When texts contain grammatical errors or non-standard use 
of punctuation (e.g. emoticons), the character n-gram is not 
as affected [13].  For example, the words misspelled and 
mispelled would generate many common trigrams, but in a 
lexically-based representation they would be different.  The 
character n-gram also captures errors that could be 
considered an identifying feature for a class (e.g. ssp and 
spe). 
Typically, stop words, which have syntactic functions in 
English but do not contribute to content, are removed from 
the vocabulary.  We generated our own stop word list 
because online chat communication has its own vocabulary 
and does not follow conventional spelling rules.   
We used two different methods of generating the stop 
word (actually stop n-gram) list.  The first method found the 
75 most frequent mutual n-grams between two classes (e.g. 
the 75 most frequent mutual words in the teen and adult 
dictionary). 
The second method used entropy as a measure of 
information gain, that is, how much a given feature 
contributes to separating the training examples into their 
target classifications [9].  We used the following formula to 
measure the conditional entropy of p(C|ni)  – the probability 
of a class given n-gram i: 
 
( ( | )) ( | ) lg ( | )i j i j i
j
H P C n p c n p c n= −  
 
The higher the conditional entropy the more equally 
distributed the n-gram is across the classes; therefore, the 
less discriminative the n-gram is.  We ranked the n-grams by 
their entropy values and removed the 5, 15, 25, 50, and 75 n-
grams with the highest entropy for each classification task. 
We used this second method, because we felt that high 
frequency based stop n-grams might contain contextual 
information.  Also, different age groups may use mutual n-
grams, but one age group may use them more often than 
another.  We wanted to see if there was a difference in 
performance using a list based on an n-gram's discriminative 
power versus its high frequency count. 
34
Authorized licensed use limited to: Aegean University. Downloaded on July 27,2010 at 15:21:36 UTC from IEEE Xplore.  Restrictions apply. 
Also, it is not unusual for people to add letters to words 
to accentuate them, such as spelling the word cool as coool, 
cooool,…etc.  Internet slang may misspell words.  Instead of 
cool, some people spell that word as kewl.  We felt that 
correcting spelling and stemming words would remove 
features that would distinguish between different age groups.  
We also kept punctuation to maintain emoticons.  Lin found 
that the younger the author, the more the author's posts 
contained emoticon types [6].  We converted all posts to 
lower case letters to reduce the size of the dictionary.  To 
account for the use of capital letters, we added that feature to 
a meta-data feature set. 
We measured the following meta-data for each 
document:   
 
• Average number of capitals per post 
• Average number of tokens per post 
• Average number of emoticon types per post 
• Average post length 
• Average word types per document.   
 
We calculated the average number of capitals per post by 
adding the total number of capitals in a document and 
divided by the total number of posts.  We found the average 
number of tokens per post by taking the total number to 
tokens and dividing by the total number of posts.  To find the 
average number of emoticon types per post, we added up the 
total number of emoticon types per post in the document and 
divided by the total number of posts.  To calculate the 
average post length, we added the total number of word 
tokens (tokens were stripped of punctuation and emoticons) 
and divided by the total number of posts.  We calculated the 
average number of word types per document by adding all 
the word types per document and divided by the total 
number of posts. 
There were five classification tasks: 
 
• Teens versus 20 year olds 
• Teens versus 30 year olds 
• Teens versus 40 year olds 
• Teens versus 50 year olds 
• Teens versus adults (20-59 year olds) 
 
For each classification task, we made three passes over 
the data sets to generate the n-gram dictionary using a 
window of one, two, and three tokens.  Each n-gram 
dictionary only contained n-grams of n size (e.g. trigram 
dictionary only contained trigrams).  Also during each pass, 
the meta-data features were calculated.  For the SVM 
training data, hapax legomena, n-grams that only appeared 
once, were removed in each classification task to reduce 
dimensionality.  Table 2 shows the resultant number of 
unigrams, bigrams, trigrams and character trigrams. 
For the NBC, we generated n-gram dictionaries of both 
words and character grams for each age group.  We, 
however, removed no n-grams from any dictionary.  Table 3 
shows the resultant number of unigrams, bigrams, and 
trigrams. 
TABLE II.  NUMBER OF N-GRAMS GENERATED FOR EACH SVM 
CLASSIFICATION TASK (NO STOP WORDS OR ENTROPY BASED WORDS 
REMOVED, HAPAX LEGOMENA REMOVED). 
Category unigrams bigrams trigrams 3-ch grams
teens/adults 575453 516741 212587 3160572
teens/20s 323135 287568 115610 1768926
teens/30s 213909 179526 68153 1187163
teens/40s 171020 144729 53202 956736
teens/50s 102152 84576 30724 577130  
TABLE III.  NUMBER OF N-GRAMS GENERATED FOR EACH SVM 
CLASSIFICATION TASK (NO STOP WORDS OR ENTROPY BASED WORDS 
REMOVED, HAPAX LEGOMENA REMOVED). 
Category unigrams bigrams trigrams
teens 100444 100909 101870
20s 247423 248112 251355
30s 132638 132897 134022
40s 87483 87718 89622
50s 13722 13813 14016
Adult 512376 513639 520418
3-ch grams 4-ch grams 5-ch grams
teens 527556 527091 526626
20s 1328342 1327653 1326964
30s 714793 714534 714275
40s 479332 479097 478862
50s 82063 81983 81903
Adult 2775440 2774177 2772914  
VI. EXPERIMENTS 
For the two different classifiers, we ran experiments with 
the following feature sets: 
A. Support Vector Machine 
• Unigrams/bigrams/trigrams with no n-grams 
removed  
• Unigrams/bigrams/trigrams with entropy based stop 
n-grams removed 
• Unigrams/bigrams/trigrams with high frequency stop 
n-grams removed 
• Unigrams/bigrams/trigrams with the set of meta-data 
features 
• 3 character grams 
B. Naïve Bayes Classifier 
• Unigrams/bigrams/trigrams with no n-grams 
removed 
• 3/4/5 character grams 
 
We used the LIBLINEAR [3] library to generate a series 
of SVM models for each classification task.  The models 
used a linear kernel and for each experiment, we used a slack 
35
Authorized licensed use limited to: Aegean University. Downloaded on July 27,2010 at 15:21:36 UTC from IEEE Xplore.  Restrictions apply. 
variable ranging from 2-17 to 214 and increased it by powers 
of 2. 
For smoothing, we implemented the Witten-Bell 
Discounting method for the NBC. 
C. Evalution 
We used precision, recall, and f-score measurement for 
the evaluation of the results in the experiment.  The formulas 
for each are as follows: 
TPPrecision
TP FP
=
+
 
 
TPRecall
TP FN
=
+
 
 
2( )Precision RecallF score
Precision Recall
×− =
+
 
 
TP  =  number of true positives 
FP  =  number of false positives 
FN =  number of false negatives 
D. Results 
Both models demonstrated that they have the capability 
to distinguish an author's age group.  See Tables 4 and 5 for 
results.  Experiments with additional features (i.e. stop word 
removal type or meta-data) are labeled as the n-gram type 
with the additional feature in parenthesis. 
TABLE IV.  RESULTS FROM SUPPORT VECTOR MACHINE MODEL 
(RANKED BY F-SCORE). 
Feature Precision Recall F-Score
bigram 0.659 1.000 0.795
bigram (entropy) 0.659 1.000 0.795
trigram 0.627 1.000 0.771
trigram (entropy) 0.627 1.000 0.771
unigram 0.592 1.000 0.744
unigram (entropy) 0.592 1.000 0.744
3 character  gram 0.588 0.983 0.735
bigram (mutual) 0.563 1.000 0.720
bigram (meta-data) 0.509 1.000 0.674
unigram (mutual) 0.483 1.000 0.652
unigram (meta-data) 0.470 1.000 0.639
trigram (mutual) 0.446 1.000 0.617
trigram (meta-data) 0.425 1.000 0.596
(a)
Teens versus 20s
 
 
 
 
 
Feature Precision Recall F-Score
unigram (mutual) 1.000 1.000 1.000
trigram 0.991 1.000 0.996
trigram (entropy) 0.991 1.000 0.996
bigram (mutual) 0.991 0.991 0.991
3 character  gram 1.000 0.983 0.991
unigram 1.000 0.983 0.991
unigram (entropy) 1.000 0.983 0.991
unigram (meta-data) 1.000 0.957 0.978
trigram (mutual) 0.943 1.000 0.971
bigram 1.000 0.940 0.969
bigram (entropy) 1.000 0.940 0.969
trigram (meta-data) 0.900 0.931 0.915
bigram (meta-data) 0.876 0.914 0.895
(b)
Teens versus 30s
 
 
Feature Precision Recall F-Score
trigram 1.000 1.000 1.000
trigram (entropy) 1.000 1.000 1.000
unigram (mutual) 1.000 1.000 1.000
bigram (mutual) 0.991 1.000 0.996
trigram (mutual) 0.991 1.000 0.996
3 character  gram 0.991 0.991 0.991
unigram 0.991 0.991 0.991
unigram (entropy) 0.991 0.991 0.991
bigram 0.991 0.983 0.987
bigram (entropy) 0.991 0.983 0.987
trigram (meta-data) 0.906 1.000 0.951
unigram (meta-data) 0.981 0.905 0.942
bigram (meta-data) 0.917 0.957 0.937
(c) 
Teens versus 40s
 
 
36
Authorized licensed use limited to: Aegean University. Downloaded on July 27,2010 at 15:21:36 UTC from IEEE Xplore.  Restrictions apply. 
Feature Precision Recall F-Score Feature Precision Recall F_Score
bigram 0.983 0.983 0.983 trigram 0.991 1.000 0.996
bigram (entropy) 0.983 0.983 0.983 trigram (entropy) 0.991 1.000 0.996
unigram 0.974 0.983 0.979 bigram 0.899 1.000 0.947
unigram (entropy) 0.974 0.983 0.979 bigram (entropy) 0.899 1.000 0.947
unigram (meta-data) 0.950 0.991 0.970 bigram (mutual) 0.571 1.000 0.727
bigram (meta-data) 0.958 0.974 0.966 unigram 0.540 0.991 0.699
bigram (mutual) 0.912 0.983 0.946 unigram (entropy) 0.540 0.991 0.699
trigram 0.892 1.000 0.943 3 character  gram 0.441 0.991 0.610
trigram (entropy) 0.892 1.000 0.943 unigram (mutual) 0.428 1.000 0.599
trigram (mutual) 0.892 1.000 0.943 bigram (meta-data) 0.368 1.000 0.538
3 character  gram 0.891 0.983 0.934 trigram (mutual) 0.334 1.000 0.501
trigram (meta-data) 0.878 0.991 0.931 unigram (meta-data) 0.330 1.000 0.497
unigram (mutual) 0.859 1.000 0.924 trigram (meta-data) 0.294 1.000 0.455
Teens versus AdultsTeens versus 50s
(d) (e)
 
 
TABLE V.  RESULTS FROM NAÏVE BAYESIAN CLASSIFIER MODEL (RANKED BY F-SCORE). 
Feature Precision Recall F-Score Feature Precision Recall F-Score Feature Precision Recall F-Score
3 character gram 0.645 0.940 0.765 5 character gram 0.817 1.000 0.932 5 character gram 0.899 1.000 0.971
trigram 0.487 0.319 0.754 4 character gram 0.823 1.000 0.903 4 character gram 0.935 1.000 0.967
unigram 0.431 0.241 0.502 3 character gram 0.872 1.000 0.899 bigram 0.943 1.000 0.954
4 character gram 0.504 0.500 0.385 unigram 0.804 0.991 0.888 3 character gram 0.906 0.991 0.947
bigram 0.468 0.319 0.379 bigram 0.792 0.983 0.877 unigram 0.927 0.983 0.947
5 character gram 0.608 0.991 0.309 trigram 0.776 0.983 0.867 trigram 0.912 0.983 0.946
Feature Precision Recall F-Score Feature Precision Recall F-Score
trigram 0.885 1.000 0.966 trigram 0.416 0.319 0.658
bigram 0.879 1.000 0.947 3 character gram 0.311 0.121 0.361
unigram 0.872 1.000 0.943 unigram 0.344 0.095 0.199
3 character gram 0.898 0.991 0.939 4 character gram 0.277 0.155 0.174
4 character gram 0.906 0.991 0.935 5 character gram 0.200 0.103 0.149
5 character gram 0.950 0.983 0.932 bigram 0.523 0.888 0.136
(d)
Teens versus 50s
(e)
Teens versus adults
(c) 
Teens versus 40s
(b)
Teens versus 20s Teens versus 30s
(a)
 
 
 
The SVM model performed slightly better than the NBC 
in all age group categories and did significantly better when 
classifying teens versus adults.  The NBC performed 
comparably when classifying teens versus specific age 
groups. 
Generally, the trigram feature did the best in 
distinguishing age groups.  Given the lack of success of 
character grams when classifying teens against adults, 
context appears to be a necessary feature. 
When classifying teens against adults, it is possible that 
the NBC did not do as well because the unbalanced data set.  
This unbalance may give undue influence to the prior 
probability (e.g. for trigrams, the prior for the adult class is 
84%). 
37
Authorized licensed use limited to: Aegean University. Downloaded on July 27,2010 at 15:21:36 UTC from IEEE Xplore.  Restrictions apply. 
The experiments with the removal of entropy generated 
n-grams did not generate better results than the counterpart 
feature that had no n-grams removed.  They, however, still 
performed just as well.  The results of the experiments with 
the removal of less than 75 n-grams are not shown because 
they had exactly the same results as removing 75 n-grams.  
The entropy values for the n-grams were all 1, thus none of 
the n-grams had any discriminating value.  It is, therefore, 
not surprising that removing fewer n-grams had no effect.  
This demonstrates that this technique could be used to reduce 
the number of dimensions in a model without degrading 
performance. 
The removal of mutual high frequency n-grams did not 
perform as well as the entropy based n-grams.  In all but one 
instance, the removal of the high frequency n-grams 
degraded performance, especially when classifying teens 
against 20s and adults.  Though each age group used the n-
grams mutually, one group sometimes used them more than 
another group.  By removing the n-gram, that distinguishing 
feature is lost.  This occurred in the teens versus adults stop 
word list.  As an example in that classification task, the fifth 
highest frequency bigram removed was <beginning of post 
tag> hi.  Teens wrote that bigram 326 times.  20s usage was 
1,300; 30s was 952; 40s was 2,244; and 50s was 335.  Teens 
only used that n-gram 10% of the time compared to adults; 
thus, that n-gram could have been a good distinguishing 
feature. 
It appeared that the more even the usage, the better the 
performance; and the more disparate the usage, the greater 
the performance degradation.  Table 6 shows the average 
percentage of usage of the removed n-grams. 
TABLE VI.  AVERAGE PERCENTAGE OF USE OF THE STOP N-GRAMS 
BASED ON HIGH FREQUENCY 
teens adult teens adult
unigrams 0.71 0.29 0.59 0.41
bigrams 0.31 0.69 0.45 0.55
trigrams 0.66 0.34 0.48 0.52
teens adult teens adult
unigrams 0.49 0.51 0.14 0.86
bigrams 0.51 0.49 0.75 0.25
trigrams 0.39 0.61 0.10 0.90
teens adult
unigrams 0.84 0.16
bigrams 0.29 0.71
trigrams 0.78 0.22
20s 30s
40s 50s
adults
 
 
Where there is a disparate usage of common n-grams, it 
appears that it is better to use the entropy generated n-grams 
than high frequency n-grams.  If the n-gram usage is almost 
even, it appears to be beneficial to remove those common n-
grams (e.g. teens versus 40s). 
Character n-grams performed comparably with word 
grams, except in the case of teens versus adults in both 
models.  In some cases, different sized grams did better than 
other sized grams.  They also gave the best performance for 
the NBC, except when classifying teens versus adults.  The 
success in the NBC could be because the character grams 
capture and tolerate the non-standard uses of punctuations 
and errors in chat and give more probability mass to the 
rarely occurring, but common features. 
The character grams, however, did not do well when 
distinguishing between teens and adults.  In this case, it 
could be that context is more important.  The success of 
trigrams when distinguishing adults from teens demonstrates 
the need for context. 
The addition of the meta-data features in all cases 
degraded performance.  The reason for this might be due to 
the small file sizes of some of the documents.  In our corpus, 
there were 1,717 documents that were 1 kilobyte or less in 
size.  Because of the small sizes, there may not be enough 
data to capture meaningful counts.  We performed an 
experiment removing all files less than 1kb in size.  In this 
experiment, the removal of such files caused severe 
degradation to performance likely caused by using a smaller 
training set. 
VII. CONCLUSIONS AND FUTURE WORK 
Both models demonstrated that they have the capability 
of distinguishing age groups.  The SVM model, however, 
outperformed the NBC.  In this case, the SVM model was 
better able to handle the unbalanced data in the teens/adult 
data set.  It is possible that with a more balanced data set, the 
NBC's performance could improve. 
High entropy valued n-grams generated a better stop 
word list for chat than lists based on high frequency counts.  
There is less of a risk of removing n-grams, which may 
contain information.  For these experiments, we removed 
only words with an entropy value of 1.  An exploration of the 
effects of removing words at different thresholds is needed.  
If more words were removed, it could improve the NBC 
because words that have more distinctiveness would be 
given more weight.  It may also improve the SVM model by 
reducing the amount of sparse data.  At the very least, it 
would help reduce computation time. 
None of the work in this study used combinations of the 
feature types.  Given the success of removing n-grams based 
on their entropy, that technique could be applied to the 
Bayesian Classifier.  Fine tuning of both model types may be 
possible by removing both high frequency stop n-grams and 
entropy based n-grams or removing fewer high frequency n-
grams. 
In this experiment, all the meta-data features were used 
as a set in an experiment.  Instead, each individual feature 
could be analyzed to determine its contribution to 
performance.  The success of the character grams in the NBC 
38
Authorized licensed use limited to: Aegean University. Downloaded on July 27,2010 at 15:21:36 UTC from IEEE Xplore.  Restrictions apply. 
suggest there is some sort of noise or feature, not captured by 
word grams, which could help performance (e.g. counting 
misspelled words). 
We tried to perform multi-class classification using the 
linear kernel, but the results were not at all noteworthy.  
There is similarity between age groups, so they may occupy 
the same vector space areas, therefore not allowing for a 
clean linear division.  The small size of the slack variable 
demonstrates the similarity of classes (e.g. in one model, the 
slack variable was 2-17).  A SVM model using a non-linear 
kernel may generate better performance. 
The corpus used in our experiments relied on self-
reported ages, which we assumed were true.  When creating 
an online profile, people can easily misrepresent their age.  
The models we generated have the potential to distinguish 
different age groups, but our experiments did not try to 
distinguish ages when a person pretends to be of a different 
age.  Our models have success with truthful ages, but 
experiments with misrepresentative ages are needed to 
determine if SVMs and NBCs have the ability to distinguish 
the actual age. 
Based on the results generated, SVMs and NBC models 
have the potential to contribute towards building an 
automated system to recognize teens conversing with adults.  
Future work may refine these models and develop a multi-
class classification system. 
ACKNOWLEDGMENT 
We would like to thank Ms. Jane Lin for her contribution 
to this work by generating the chat corpus and her early work 
in the area.  Also, we would like to thank Mr. David Dreier 
for developing  software to run some of the experiments.  
Finally, we would like to thank the National Reconnaissance 
Office for funding that partially supported this research. 
 
REFERENCES 
[1] R.H. Baayen, H. Van Halteren, and F.J. Tweedie,  “Outside the Cave 
of Shadows: Using Syntactic Annotation to Enhance Authorship 
Attribution”, Literary and Linguistic Computing, 11(3), pp. 121-131, 
1996. 
[2] C.J.C. Bruges, "A tutorial on support vector machines for pattern 
recognition", Data Mining and Knowledge Discovery, 2(2), 1998, pp. 
121-167. 
[3] R.E. Fan, K.W. Chang, C.J. Hsieh, X.R. Wang, and C.J. Lin, 
“LIBLINEAR:  A library for large classification”, Journal of 
Machine Learning Research, 9, 2008, pp. 1871-1874. 
[4] D. Jurafsky and J. Martin,  Speech and Language Processing, Pearson 
Eduction, Inc., Upper Saddle River, NJ, USA, 2009. 
[5] J.P. Lewis, "A Short SVM (Support Vector Machine) Tutorial", 
December 2004.  Available: 
http://scribblethink.org/Work/Notes/svmtutorial.pdf, [Accessed: July 
7, 2009]. 
[6] J. Lin, Automatic author profiling of online chat logs.  Master’s 
thesis, Naval Postgraduate School, Monterey, California, March 
2007. 
[7] C. Manning and H. Schutze,  Foundations of Statistical Natural 
Language Processing,  The MIT Press, Cambridge, MA, USA, 1999. 
[8] K.J. Mitchell, J. Wolak, and D. Finkelhor, “Trends in Youth Reports 
of Sexual Solicitations, Harassment and Unwanted Exposure to 
Pornography on the Internet”, Journal of Adolescent Health, 40(2), 
Elsevier Inc., February 2007, pp. 116-126. 
[9] T. Mitchell,  Machine Learning.  The McGraw-Hill companies, Inc., 
Boston, MA, USA, 1997. 
[10] N. Pendar,  "Toward Spotting the Pedophile Telling victim from 
predator in text chats",  International Conference on Semantic 
Computing, 2007, pp. 235-241. 
[11] P. Rayson, G. Leech, and M. Hodges,  “Social differentiation in the 
use of English Vocabulary:  Some Analysis of the Conversational 
Component of the British National Corpus”,  International Journal of 
Corpus Linguistics, 2(1), 1997, pp. 133-152. 
[12] V. Savicki, D. Lingenfelter, and M. Kellye,  “Gender Language Style 
and Group composition in Internet Discussion Groups”, Journal of 
Computer Mediated Communications, 2(3), 1996. 
[13] E. Stamatatos,  ”A Survey of Modern Authorship Attribution 
Methods”, Journal of American Society for Information Science and 
Technology, 60(3), 2009, pp. 538-556. 
[14] Wikipedia,  "List of Emoticons,"  Available: 
http://www.en.wikipedia.org/wiki/List_of_emoticons, March 2009.  
[Accessed July 7, 2009]. 
39
Authorized licensed use limited to: Aegean University. Downloaded on July 27,2010 at 15:21:36 UTC from IEEE Xplore.  Restrictions apply. 
