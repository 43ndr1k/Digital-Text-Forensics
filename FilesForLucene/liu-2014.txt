1	 Â 
	 Â 
Automated Degradation Diagnosis in Character Recognition System subject to 
Camera Vibration 
Chunmei	 Â Liu1	 Â 
1	 Â Department	 Â of	 Â Computer	 Â Science	 Â and	 Â Technology,	 Â Tongji	 Â University,	 Â Shanghai,	 Â China	 Â 
E-mail: { chunmei.liu@tongji.edu.cn } 
Abstract 
Degradation diagnosis plays an important role for degraded 
character processing, which can tell the recognition difficulty 
of a given degraded character. In this paper, we present a 
framework for automated degraded character recognition 
system by statistical syntactic approach using 3D primitive 
symbol, which is integrated by degradation diagnosis to 
provide accurate and reliable recognition results. Our 
contribution is to design the framework to build the character 
recognition sub-models corresponding to degradation subject 
to camera vibration or out of focus. In each character 
recognition sub-model, statistical syntactic approach using 3D 
primitive symbol is proposed to improve degraded character 
recognition performance. In the experiments, we show 
attractive experimental results, highlighting the system 
efficiency and recognition performance by statistical syntactic 
approach using 3D primitive symbol on the degraded 
character dataset.  
Keywords: Degradation Diagnosis; Automated Character 
Recognition 
1. Introduction 
Degraded character recognition is an important research 
topic in OCR with the rapid progress of digital imaging 
technology and the variety of image acquisition conditions. 
The accuracy of degraded character recognition results largely 
affects the accuracy of the overall document processing 
system. In the real world, some difficulties are involved in 
character recognition due to camera Vibration, lack of focus, 
noise, low contrast to background. These kinds of degraded 
characters canâ€™t be recognized smoothly by traditional OCR 
methods because it is very hard to get clear character images. 
Degradation diagnosis plays an important role for 
degraded character recognition system, which can tell 
recognition difficulty of a given degraded character. In this 
article, we aim to achieve an adaptive degraded character 
recognition system by syntactic approach using 3D primitive 
symbol according to degradation diagnosis. It inludes: 
degradation diagnosis, 3D primitive symbol extraction, and 
syntactic classification. We briefly survey the related works in 
the following subsection. 
1.1 Related Work 
Some approaches have focused on degraded character 
recognition. These works can be divided into two groups:	 Â 
statistical approach and syntactic approach. The statistical 
approaches have been used widely in practical systems since it 
is simple and objective algorithm. For degraded character 
recognition, it can be further divided into two categories: 
binarization based character recognition and gray feature 
based character recognition. 
The binarization based character recognition is to extract 
character feature from the binary character image by 
degradation recovery and advanced binarization [1,2]. It 
focuses on how to remove degradation and get ideal binary 
patterns. These processes will inevitably result in information 
loss and will generate a lot of broken strokes or connected 
strokes and noise into a binarized image. Taylor,M.J. and 
Dance,C.R perform the recovery of text from digital camera 
images by deblurring by deconvolution, and resolution 
enhancement by linear interpolation, and applies thresholding 
to obtain texts [1]. E.Kavallieratou and E. Stamatatos [3] 
combine global and local thresholding to improve the quality 
of old documents. J.Banerjee et al. [4] use a probabilistic 
Contextual model to restore degraded document images. 
The gray feature based character recognition is directly 
to extract features from a gray scale image which can 
effectively avoid the information loss. It can be further 
divided into two types: structural features and frequency 
features. Structural features try to extract character structure 
from a gray scale image, such as direction feature, skeleton 
feature, topological feature and so on [6,7]. Although the 
structural features can precisely describe the character 
structure, it is difficult to extract invariable structural features 
2	 Â 
	 Â 
 
Figure 1. Flow chart of the proposed approach. 
 
because it suffers various degradation. In contrast to structural 
features, frequency features are very effective for the 
recognition of low resolution gray scale character, such as 
Fourier transform and wavelet transform. In these features, 
Gabor filter feature is demonstrated that has good behavior in 
degraded character recognition [9,10,11,12,13]. Xuewen 
Wang et al. [9] use Gabor filters to extract features directly 
from gray-scale character images, which has excellent 
performance on both low-quality machine-printed character 
recognition and cursive handwritten character recognition. 
Peifeng Hu et al. [10] propose dominant orientation matrix 
based on Gabor filter for low resolution gray scale character 
classification. Hamamoto et al. [11] use a Gabor filter on a 
multi-channel filtering theory for handwritten numeral 
character recognition. V. Tavsanoglu et al. [12] use a CNN 
Gabor filter and an orientation map to successfully recognize 
the hand-written characters. Yoshimura et al. [13] extract 
Gabor jet features for the character recognition with various 
font types. 
The other syntactic approaches use the primitive symbol 
to describe the character structure, and the grammar to 
analyze the category of character. According to primitive 
symbol types, the syntactic approach can be divided into two 
categories: 1D primitive symbol based syntactic recognition 
and 2D primitive symbol based syntactic recognition. The 1D 
primitive symbol based syntactic method extract primitive 
symbol in one dimension to describe the character structure. It 
adapts to character recognition of western languages and 
online character recognition. 
The 2D primitive symbol based method extract primitive 
symbol in two dimensions, generally chain-coded to map each 
2D image to a single string. Lee et al. [14] use 2D phonetic 
symbols and an attribute-dependent programmed grammar to 
recognize the Korean character. Marc Parizeau et al. [15] 
present an original approach for modeling cursive script 
allographs and use exclusively morphological and pragmatic 
knowledge to recognize them. It separates two distinct 
problems: the recognition of a set of graphics symbols and the 
reading of a message coded with those symbols. Lucas et al. 
[16] obtain the chain code string from character image and 
build a statistical model for strings of each class based on a 
probabilistic version of an n-tuple classifier. Abdur Rahman et 
al. [17] propose curve-fitting algorithm to extract the primitive 
and the syntactic method to recognize the handwritten Bengali 
characters. 
1.2. Framework 
The work in this paper presents an adaptive degraded 
Chinese character recognition system by statistical syntactic 
approach using 3D primitive symbol, which spans a broad 
range from low level degradation diagnosis to high level 
syntactic character recognition. The general framework of the 
adaptive degraded character recognition system is composed 
of seven character recognition sub-models corresponding to 
seven degradation levels as shown in Figure 1. Each character 
recognition sub-model includes 3D primitive symbol 
extraction and syntactic classifier which is trained by the 
specific dataset corresponding to each degradation level. For a 
given degraded character, according to degradation diagnosis 
result, each character recognition sub-model adaptively acts. 
Thus the degraded character recognition system can better 
obtain the instruction from the degradation information of the 
given character to reduce the character recognition error and 
improve the system performance. 
In this paper, the first contribution is the proposal of the 
adaptive degraded character recognition system which is 
composed by degradation diagnosis and character recognition. 
3	 Â 
	 Â 
It well integrates degradation cues into every character 
recognition sub-model to improve the system performance. 
The second contribution is to propose 3D primitive symbol 
which is directly extracted from the gray scale image and 
apply the statistical syntactic classifier to recognize the 
degraded character which degradation includes disk-blurring 
by lack of focus and motion-blurring by camera vibration. In 
contrast with 2D primitive symbol used in the traditional 
syntactic approach, this kind of 3D primitive symbol can 
better describe the character structure and adapt to various 
degradation to reduce the recognition error. Experiment 
results demonstrate the proposed approach highly improved 
the performance of multi-degradation character recognition 
system. 
The reminder of this paper is organized as follows. 
Degradation diagnosis is discussed in Section 2. Section 3 
introduces the process of 3D primitive symbol extraction. 
Section 4 presents the syntactic analysis to recognize the 
degraded character. In Section 5, the experimental studies are 
presented. Finally, Section 6 summarizes the main 
contributions of the paper together with discussions on some 
opening issues and future research directions. 
2. Degradation Diagnosis 
For degraded character recognition, it is a good way to 
use degradation diagnosis to help degraded character 
recognition. In this paper, two degradation types are 
considered, disk blurring by out of focus and motion blurring 
by camera vibration. According to degradation type and 
degradation degree, we build seven degradation levels, which 
are clear level L!, light blur level L!, heavy blur level L!, 
motion blur level L!in 0Â° direction, motion blur level L!in 
45Â°  direction, motion blur level L! in 90Â°  direction and 
motion blur level L! in âˆ’45Â° direction. According to these 
degradation levels the character dataset is classified into seven 
subsets. For each degradation level, the corresponding 
character recognition sub-model is designed by statistical 
syntactic approach using 3D primitive symbol, which is built 
by the corresponding character subset (seen from Figure 1). 
For a given degraded image, the character recognition 
sub-model adaptively acts according to degradation diagnosis 
result of the given character image. 
For a given degraded character, we use the 
dual-diagnosis method to diagnose its degradation level, 
which is finished by two parts: disk-blurring diagnosis and 
motion-blurring diagnosis. The algorithm applies the gray 
distribution feature to evaluate disk-blurring degradation [5]. 
It is performed by three steps: preprocessing, gray distribution 
feature extraction and classification. After disk-blurring 
diagnosis, clear level ğ¿! Â and heavy blur level ğ¿! Â can be 
diagnosed, and the other levels are diagnosed into one big 
level. This one big level need to be further diagnosed by 
motion-blurring diagnosis.  
The gray value distribution of the motion-blurring image 
in different direction is different [8]. According to this gray 
distribution characteristic, we use four edge structure elements 
to statisticise the difference in four motion-blurring directions. 
The edge density ratio feature is extracted to diagnose the 
motion-blurring levels in four motion-blur directions. In this 
paper, the four edge structure elements are applied to obtain 
the edge images in four directions, âˆ’45Â°, 0Â°, 45Â° and 90Â° 
[18].	 Â When the motion-blurring diagnosis is accomplished, the 
rest five degradation levels ğ¿!, ğ¿!~ğ¿! can be diagnosed. The 
detailed algorithm is performed by the steps in Table 1. 
Table 1. Motion-blurring Diagnosis Procedure 
Algorithm1: Motion-blurring Diagnosis 
Input: a input character image I! 
Output: motion-blurring level L! 
STEP.1 A given character image I! is preprocessed to 
a uniform image ğ¼!! (64Ã—64pixels). Four edge 
structure elements are used on I to acquire the 
edge images ğ¸!!!"Â°, Â ğ¸!!Â°, Â ğ¸!!"Â°, Â ğ¸!!"Â°. 
STEP.2 The edge density ratio feature ğ‘Ÿ!! and ğ‘Ÿ!! can 
be computed by Equation (1) and (2): 
ğ‘Ÿ!! =
!!
!Â°
!!
!"Â°                            (1) 
ğ‘Ÿ!! =
!!
!!"Â°
!!
!"Â°                            (2) 
Here, â„!!!"Â° , â„!!Â° , â„!!"Â° and â„!!"Â°  are the 
respective gray distribution features of 
ğ¸!!!"Â° ,  Â ğ¸!!Â° ,  Â ğ¸!!"Â° ,  Â ğ¸!!"Â° , namely if the bin of 
ğ¸!!!"Â° Â  gray histogram is more than defined 
thresholding ğ‘¡!"#, it would be recorded 1.  
STEP.3 The one big level after disk-blurring diagnosis 
can be further diagnosed as followed: 
if Â  Â ğ‘Ÿ!! < ğ‘¡!, Li = ğ¿! 
elseif Â  Â ğ‘Ÿ!! < ğ‘¡!, Li = ğ¿! 
elseif Â  Â ğ‘Ÿ!! > ğ‘¡!, Li = ğ¿! 
elseif Â  Â ğ‘Ÿ!! < ğ‘¡!, Li = ğ¿! 
ğ‘’ğ‘™ğ‘ ğ‘’ Â Li = ğ¿! 
Here ğ‘¡!ï¼Œğ‘¡!ï¼Œğ‘¡! and ğ‘¡! are the thresholdings for 
motion-blurring diagnosis in four directions. 
 
4	 Â 
	 Â 
 
Figure 2. 3D primitive symbol extraction for seven degradation levels. 
3. 3D Primitive Symbol 
We propose a novel primitive symbol to describe 
character structure. It is directly extracted from the gray-scale 
space without any binarization. So it can avoid the 
information loss as binarization and obtain the more 
information to describe character structure. As shown in 
Figure 3, 3D primitive symbol extraction can be implemented 
by five steps: (1) Normalize a input image into the standard 
size 64Ã—64; (2) Design and apply four-directional Gabor 
filters to extract structure information from the normalized 
character image; (3) Divide the gray-scale space into three 
subspaces that the outputs of Gabor filters locate in; (4) In 
each subspace, obtain the primitive string code base on block 
sampling; (5) Connect all primitive string code into one 
primitive string code. 
3.1 Gabor Filter 
Gabor filter is a kind of frequency filter which can 
extract directional structure directly from gray-scale images to 
tolerate some kinds of degradation. We apply a kind of Gabor 
filter â„ ğ‘¥, ğ‘¦  to a given image ğ¼ ğ‘¥, ğ‘¦ . The response output 
ğº ğ‘¥, ğ‘¦  Â can be defined through the convolution sum: 
â„ ğ‘¥, ğ‘¦ = !
!!"
ğ‘’
!(!!!!!)
!!! ğ‘’!"(! !"#!!!! !"#!!)             (3) 
ğº ğ‘¥, ğ‘¦, ğœƒ! = ğ¼ ğ‘¥!, ğ‘¦! âˆ™ ğ‘’
!((!!!!)!!(!!!!)!)
!!! âˆ—
!!!!
!!!!!
!
!
!!!!
!!!!!
!
!
 Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â ğ‘’!"((!!!!) !"#!!!(!!!!) !"#!!)              (4) 
Where ğœ†  is the wavelength of Gabor filter and ğœ  is the 
standard deviation of Gaussian. Â ğ‘€,ğ‘ are the dimension of 
Gabor filter. ğœƒ! is the orientation angle of Gabor filter. As 
the strokes of Chinese character mainly have four 
directions: Â 0Â°, 45Â°, 90Â°,âˆ’45Â°, we use a set of Gabor filter to 
localize direction spatial frequency at ğœƒ!. 
{ğœƒ!|ğœƒ! =
!"
!
, ğ‘˜ = 0,â€¦ ,3}                           (5) 
So after convolution by Gabor filter, the directional output ğº! 
can be obtained, as shown in Figure 3. 
3.2 Primitive symbol 
Every gray-scale space of the directional output ğº! is 
divided into three subspaces ğ‘†! , ğ‘– = 1,2,3  by thresholding 
ğ‘‡! , ğ‘– = 1,2,3. In every gray-scale subspace ğ‘†!, the directional 
output ğº! is divided into nÃ—n blocks. The primitive string 
ğ¶! is coded on each block. It can be computed as the Equation 
(6). 
ğ¶! x!!, y!! = 
argmax! G x!" , y!" , ğœƒ! âˆ™ G x!" , y!" , ğœƒ! > ğ‘‡!   (6) 
(x!" , y!") is the point coordinate in the block  Â ğ‘!, namely 
(x!" , y!") âˆˆ block Â ğ‘!  and ğ¶! x!!, y!!  is the 
corresponding code of the block ğ‘! which is searched in all 
points of block ğ‘! . Finally all codes ğ‘!ğ‘!ğ‘!  are 
concatenated into one string code as primitive symbol, as 
shown in Figure 3. 
 
Figure 3. The flowchart of 3Dprimitive symbol extraction 
 
Figure 2 shows 3D primitive symbol extraction for seven 
degradation levels. The more subspaces include the more 
information. For the different degradation level, we take the 
different subspace ğ‘†!. For the clear level ğ¿!, it is enough to 
take the top subspace ğ‘†! to generate the sting code ğ‘!. For 
the light blur level ğ¿! , two top subspaces  Â ğ‘†!  and ğ‘†!  are 
considered to form string code ğ‘!ğ‘! . For the other five 
degradation level ğ¿!~ğ¿!, the primitive numeric string codes 
ğ‘!ğ‘!ğ‘!  are generated by three subspaces ğ‘†!~ğ‘†!  as they 
include more information, which can help to improve the 
5	 Â 
	 Â 
recognition performance. 
4. Syntactic Classification  
In the section, we provide details on how to use the 
proposed adaptive statistical syntactic method based on 3D 
primitive symbol to recognize the degraded Chinese character. 
As shown in Figure 1, according to 7 degradation levels, we 
design 7 character recognition sub-models by training 
character sets with 7 degradation levels. In each sub-model, 
the special 3D primitive symbol and the special syntactic 
classifier are designed to recognize the character subject to the 
corresponding degradation. 
In each sub-model, as described in section 3, the 3D 
primitive string codes are extracted for each type of 
degradation. Namely for the degradation level ğ¿!  the 
primitive string code is ğ¶!(ğ‘!). For the degradation level 
ğ¿!  the primitive string code is ğ¶!(ğ‘!ğ‘!) . And for the 
degradation level ğ¿!~ğ¿!  the primitive string code is 
ğ¶! ğ‘!ğ‘!ğ‘! ~ğ¶! ğ‘!ğ‘!ğ‘! . Matching algorithm is applied to 
recognize the characters. For a given degraded character, it is 
matched with the reference strings. We also set the reference 
strings respectively for each degradation level ğ¿!~ğ¿! . 
Namely for the degradation level ğ¿! the reference string is 
ğ‘…!(ğ‘Ÿ!) which is taken from top subspace of Gabor filter 
response. And for the degradation level ğ¿! the reference 
string is ğ‘…!(ğ‘Ÿ!ğ‘Ÿ!). For the other degradation levels ğ¿!~ğ¿! 
the reference strings are taken as ğ‘…!(ğ‘Ÿ!ğ‘Ÿ!ğ‘Ÿ!).  
For a given degraded character, according to the 
degradation diagnosis result, each character recognition  
Table 2. Degraded Character Recognition Procedure 
Algorithm2: Degraded Character Recognition 
Input: the input character image I! 
Output: character category Ï‰! 
STEP.1 For the input character image I!, extract the 
gray distribution feature to diagnose I!  and 
obtain disk-blurring level L!
!; 
STEP.2 If L!
! = 2, extract the edge gray distribution 
feature to diagnose I!  and obtain 
motion-blurring diagnosis result L!! . Set 
L! = L!!. Otherwise, update L! = L!
!.  
STEP.3 For the input character image I!, extract the 
string code C!.  
STEP.3 According to the blurring level L!  of I! , 
acquire character category Ï‰!  by adaptive 
classification weights W to adaptively adjust 
every sub-modelâ€™s action. 
 
sub-model adaptively acts. Here, we define the adaptive 
classification weights ğ‘Š(ğ‘¤!,â€¦ ,ğ‘¤!)  to adaptively assign 
each sub-model action. For example, if the degradation level of 
the given character is ğ¿!, the weight ğ‘¤! Â is set large, and the 
other weights ğ‘¤!~ğ‘¤! are set small. 
For the given degraded character, the 3D primitive string 
C!  is extracted and syntactic matching is implemented as 
Equation 5. 
Ï‰! = argmin! w!Ã—d(C!",R!")!!!! , Â                   (7) 
where Â Ï‰! is the recognition category of the given character, 
and j is the character category of recognition. The detailed 
character recognition procedure is implemented as Table 2.  
5. Experiments 
In order to illustrate the performance of the proposed 
method we have performed a number of experiments on 
printed Chinese character data sets, including 3755 character 
categories. We use a point-spread function (PSF) to generate 
two degradation types of the degraded character sets. One type 
is disk-blurring degradation by lack of focus. We used 20 
blurring run r! to generate 20 disk-blurring character subsets. 
The other type is motion-blurring degradation by camera 
vibration. We use 11 blurring runs r! Â  and 8 blurring 
directions to generate 88 motion blurring character subsets.  
In all experiments with the proposed character recognition 
algorithm, the thresholdings for motion-blurring diagnosis are 
empirically set as t!"# = 10, t! = 0.75ï¼Œt! = 0.85ï¼Œt! = 1.1 
and t! = 1.1. For the edge density ratio feature, the gray 
histogram is computed with n! = 256  bins. The adaptive 
classification weight is set to w! = 1 if L = L! , otherwise 
w! = 0. Our experiments are all implemented by matlab. 
5.1 Degradation Diagnosis 
In disk-blurring diagnosis part, we randomly select 200 
character images respectively from character subsets by three 
blurring run r  as training data. The other 106 character 
subsets are used as testing data to demonstrate the 
effectiveness of degradation diagnosis. Figure 4 and Figure 5 
show the degradation diagnosis results by the proposed 
method.  
We use seven degradation levels (L!~L!) to diagnose 21 
character subsets by 21 disk- blurring runs (r!). As these 21 
data subsets are degraded by disk-blurring degradation, they  
6	 Â 
	 Â 
 
Figure 4. Degradation diagnosis results on disk-blurring character subsets 
theoretically should be diagnosed into ğ¿!~ğ¿!  according to 
our degradation levels. Figure4 shows the diagnosis results of 
seven degradation levels (ğ¿!~ğ¿!) on these 21 subsets. The 
horizontal axis is blurring run r! by PSF. The vertical axis is 
the diagnosis ratio to 7 levels. It can be shown that the 
distribution of 21 degraded character subsets are subject to the 
normal distribution of 3 disk-blurring levels. The character 
images with light blurring degree mostly locate in clear level 
scope. And most of the character images with heavy blurring 
degree distribute in heavy blurring level scope. Experiment 
result demonstrates the proposed algorithm can effectively 
diagnose the degraded character images by disk-blurring 
degradation. 
We also do the same experiment on the other 88 degraded 
character subsets by 11 motion-blurring run ğ’“ğ’ in 8 
motion-blurring directions ğ›‚. The final result is shown in 
Figure 5. The horizontal plane represents the blurring run ğ’“ğ’ 
in blurring direction ğ›‚  by PSF. The vertical axis is the 
diagnosis ratio to 7 degradation levels. In order to demonstrate 
the final diagnosis results clearly, only the rest 4 degradation 
levels (ğ¿!~ğ¿!) are shown. In Figure 5, it can be seen that the 
degraded character images by small motion-blurring run ğ’“ğ’ 
are diagnosed to ğ¿!  because it has the similar gray value 
distribution with character images with light disk-blurring level. 
In this condition, the influence of motion-blurring direction can 
be neglected. With the motion-blurring run ğ’“ğ’  increasing, 
motion-blurring diagnosis plays an increasingly important part 
in degradation diagnosis. We can see the proposed edge 
density ratio features can effectively diagnose the character 
subsets by 11 motion-blurring run and 8 motion-blurring 
direction subject to 4 degradation levels in 4 motion-blurring 
directions (ğ¿!~ğ¿!).  
From Figure 4 and Figure 5, experiment results 
demonstrate the proposed dual-diagnosis algorithm can  
 
Figure 5. Degradation diagnosis results on motion-blurring character subsets 
effectively be applied on the degradation diagnosis of the 
degraded characters. 
5.2 Degraded character recognition 
We present both quantitative and qualitative results for 
degraded character recognition as well as comparative results 
with a 1D primitive string method (SDCR) trained by all 
character subsets. More specifically, we have tested the 
algorithm in 109 degraded character subsets with different 
degradation. In the proposed adaptive algorithm (ADCR), 21 
character subsets are trained to obtain the reference strings 
which respectively correspond to 7 degradation levels. Each 
character subset includes 3755 degraded Chinese characters. 
Figure 6 shows comparative results of the SDCR algorithm 
and the ADCR algorithm. The horizontal axis is the 109 
character subsets. The vertical axis is the degraded character 
recognition rate. The blue line is the character recognition 
result of SDCR, and the red line is the result of ADCR. From 
Figure 6, notice that ADCR algorithm generates better 
degraded character recognition result than the SDCR algorithm. 
Experiment demonstrates the proposed method highly 
improved the performance of the degraded character 
recognition system. 
	 Â 
Figure 6. Results of degraded character recognition. 
0 40 80 120
0
0.2
0.4
0.6
0.8
1
 
 
SDCR
ADCR
7	 Â 
	 Â 
6. Conclusion 
In this paper, we have proposed a framework for the 
adaptive degraded character recognition system by statistical 
syntactic approach using 3D primitive symbol, which is 
integrated by the degradation information to provide accurate 
and reliable recognition results. Experiments have validated 
that the proposed method can highly improve the performance 
of the degraded character recognition system. We believe that 
improvements are due to the integration of degradation 
diagnosis and the information provided by 3D primitive 
symbol. We have noticed the proposed is only the degraded 
character recognition for print Chinese character. In the future, 
we will try some other 3D effective structure features from the 
gray-scale image to recognize the handwriting character. 
Furthermore, a well degradation diagnosis algorithm can help 
in tackling degraded character recognition. We will further 
examine more features to diagnose more degradation sources 
in character degradation diagnosis in future work.  
Acknowledgement 
This work is supported by National Natural Science 
Foundation of China (No. 61003102, No. 61103072, No. 
61272271) and the scientific and technological projects of 
Science and Technology Commission of Shanghai 
Municipality (No. 11dz1210404). 
 
References 
[1] Taylor,M.J., Dance,C.R., â€œEnhancement of document images from 
camerasâ€, Proc. Of SPIE, 1998, 23305: 230â€“241. 
[2] T. Kanungo, RM Haralick, H. Baird, W. Stuezle and D. Madigan, â€œA 
statistical, nonparametric methodology for document degradation model 
validationâ€, IEEE. Trans. PAMI, 2002, 22 (11): 1209â€“1223. 
[3] E. Kavallieratou and E. Stamatatos, â€œImproving the Quality of 
Degraded Document Images,â€ Proc. of DIAL, 2006, pp. 340 â€“ 349. 
[4] J.Banerjee, A.M.Namboodiri, and C.V.Jawahar, â€œContextual 
restoration of severely degraded document images,â€ Proc. of CVPR 2009, 
Miami, US, 2009, pp. 517 â€“ 524. 
[5] C.M. Liu, C.H. Wang, R.W. Dai., â€œLow Resolution Character 
Recognition by Image Quality Evaluationâ€, Proc. of ICPR 2006, Aug.2006, 
1:864 â€“ 867,.  
[6] L. Wang, T. Pavlidis, â€œDirect gray-scale extraction of features for 
character recognitionâ€, IEEE Trans. PAMI, 1993, 15 (10): 1053â€“1066. 
[7] S.-W. Lee and Y.-J. Kim, â€œDirect Extraction of Topographic Features 
for Gray Scale Character Recognitionâ€, IEEE Trans. PAMI, 1995, 17 (7): 
724-729. 
[8] C.M. Liu and D.Q. Miao, â€œDegraded Character Recognition by 
Image Quality Evaluationâ€, Proc. of ICPR 2010, Istanbul, Turkey, 2010, pp. 
1908 â€“ 1911. 
[9] Xuewen Wang, Xiaoqing Ding, Changsong Liu, â€œGabor filters-based 
feature extraction for character recognitionâ€, Pattern Recognition, 2005, 29 
(7): 369â€“379. 
[10] Peifeng Hu, Yannan Zhao, Zehong Yang, Jiaqin Wang, 
â€œRecognition of gray character using gabor filtersâ€, Proceedings of 
FUSIONâ€™2002, Annapolis, USA, 2002. 
[11] Hamamoto, Y., S. Uchimura, M. Watanabe, T. Yasuda, Y. Mitani, 
and S. Tomita, â€œA Gabor filter-based method for recognizing handwritten 
numeralsâ€, Pattern Recognition, 1998, 31 (4): 395-400. 
[12] V. Tavsanoglu, E. Saatci, â€œFeature Extraction for Character 
Recognition Using Gabor-Type Filters Implemented by Cellular Neural 
Networksâ€, CNNAâ€™00, Catania, Italy, 2000. 
[13] Hiroshi Yoshimura, Minoru Etoh, Kenji Kondo, Naokazu Yokoya, 
â€œGray-Scale Character Recognition by Gabor Jets Projectionâ€, Proceedings of 
ICPRâ€™00, Barcelona, Spain, 2000. 
[14] Kyoon Ha Lee ; Eom, K.-B. ; Kashyap, R., â€œCharacter Recognition 
Based on Attribute-dependent Programmed Grammarâ€, IEEE Transactions on 
PAMI, 1992, Vol.14, issue.11, pp.1122 â€“ 1128 
[15] Marc Parizeau and Rejean Plarnondon, â€œA Fuzzy-syntactic 
Approach to Allograph Modeling for Cursive Script Recognitionâ€, IEEE 
Transactions on PAMI, JULY 1995, Vol.17. No. 7, pp.702-712. 
[16] Lucas, S., Amiri, A., â€œStatistical syntactic methods for 
high-performance OCRâ€, IEEE Proceedings of Vision, Image and Signal 
Processing, 1996, Vol.143, pp.23 â€“ 30. 
[17] Md. Abdur Rahman, and Abdulmotaleb El Saddik, â€œModified 
Syntactic Method to Recognize Bengali Handwritten Charactersâ€, IEEE Trans. 
Instrumentation and Measurement, Dec.2007, Vol. 56, No. 6, pp.2623-2631. 
[18] Q.R. Chen,  Q.S. Lu, and L.Z. Cheng, â€œIdentification of the 
Motion Blurred Direction of Motion Blurred Images,â€ Journal of National 
University of Defense Technology, Chinese, vol. 26, no. 1, pp. 41 â€“ 45, 2004. 
 
 
