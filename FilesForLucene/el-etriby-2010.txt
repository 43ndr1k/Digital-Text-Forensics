International Conference on Computer and Communication Engineering (ICCCE 2010), 11-13 May 2010, Kuala Lumpur, Malaysia 
978-1-4244-6235-3/10/$26.00 ©2010 IEEE 
Detection and Correction of Deformed Historical 
Arabic Manuscripts 
 
 
Sherif Said El-etriby 
Faculty of Computers and Information 
Menoufia University 
Shebin El kom, 32511, Egypt  
Sherif.ali@ci.menofia.edu.eg 
Khalid Mohammad Amin 
Faculty of Computers and Information 
Menoufia University 
Shebin El kom, 32511, Egypt 
khaled.abdelmoneam@ ci.menofia.edu.eg
 
 
Abstract— Historical manuscripts are considered one of the most 
imperative human riches and a source of intellectual production. 
Unfortunately, due to aging effects, multiple noises and 
deviations are found in the document image. Moreover, 
challenges for several images of ancient documents show defects 
of inclinations and curvatures of text lines. These defects arise 
due to bad storage conditions, or during the digitization process. 
In order to improve the readability and the automatic recognition 
of historical Arabic manuscripts, preprocessing steps are 
imperative. This paper presents a novel method that consists of 
two major phases. The first refer to binarization and 
enhancement of the scanned document image. In the second 
phase, correction of skew angle in the text line passes by the 
detection of curvature/inclination of the baseline. Then, 
calculating the skewed angle of this line, and finally, correcting 
the line with a rotation relative to its centre. The proposed 
method was implemented on different scanned Arabic 
documents. The proposed methodology overcomes the defects of 
global binarization method, also, save the high computation 
effort of adaptive binarization techniques. Moreover, it works 
well with both Arabic handwritten words and printed text.  
Keywords- preprocessing; Arabic Baseline; Ancient documents; 
correction of inclination; correction of curvature 
I.  INTRODUCTION 
Historical Arabic document collections are a valuable 
resource for human history. It is a common that documents 
belonging to historical manuscripts are poorly preserved and 
are prone to various degradation processes Fig. 1. There are 
lots of problems facing digital image processing specialists 
when trying to use available OCR software. They cannot get 
accurate results when trying to extract the useful text areas 
from the manuscript under study. Examples of such problems 
are; show through effects, interfering strokes, background 
spots, humidity absorbed by paper in different areas, curvature 
of text lines and other defects. Fig. 2 shows samples of these 
defects. However, there are some complex old manuscripts 
which contain extra problems as will be discussed in the 
following subsection. 
In this paper, we are interesting in easing usage of OCR 
programs for extracting text regions from image of a complex 
manuscript like that shown in Fig.1. Such image and others are 
available on the site of Arabic manuscripts network [1]. In 
addition to the above problems, the manuscript, e.g. which 
shown in Fig. 1(a), contains four text blocks in the same page 
with brown background. The brown color of background is not 
uniformly distributed. Also, some words were written with red 
pen, while all of the other words were written with black pen. 
Each text block has a different skew angle (center block: 0, 
upper: -45, left: 45, and lower: 135 approximately). Our 
goal is to decompose the image into four separate images (each 
text block in a separate part). Each image part must have a 
clear and uniform background as much as we can. Moreover, 
the skew angle of each block must be detected and hence, 
rotate text lines to be horizontally directed. The above 
preprocessing step guarantees minimum errors during the OCR 
steps, and provides the user with an easy and fast reading. 
In the following section, we present the previous wok on 
both binarization and skew angle detection and correction. 
Then in section III, our methodology and the obtained results 
are discussed. Finally, section IV concludes the paper.   
II. RELATED WORK 
The Arabic OCR preprocessing stage should contain 
smoothing, noise removal, binarization, image decomposition, 
skew detection and correction [2-3]. One of the most important 
steps in the OCR is the image binarization which is the process 
of converting gray image into binary image. A threshold 
intensity level is used to segment an image by setting all pixels 
whose intensity values are above the threshold to a foreground 
value and all the remaining pixels to a background value. The 
available algorithms can be classified into global or adaptive 
(local) thresholding methods. In the global approach, threshold 
selection leads to a single threshold value for the entire image. 
If T is the global threshold of image f(x,y) and the g(x,y) is the 
thresholding image, Then,  
   Ty)f(x,if1, otherwise0,y,xg   (1)
Among the global techniques, the most efficient is Otsu’s 
technique [4]. Otsu’s method applies clustering analysis to the 
grayscale data of input image and models two clusters of 
Gaussian distribution of pixels of the image. 
 
 
 
(a) Complex manuscript (b) ancient manuscript with many background deffects 
 
(c) ancient manuscript with background noise 
and low contrast (d) ancient manuscript non-uniform illuminated background 
Figure 1. Samples of historical arabic manuscripts 
 
  
(a) Show through effect, and some 
words were written with red pen (b) Background spots (c) Inclination and curvature 
Figure 2. Defects of ancient manscript document images 
 
 
 
 
 
 
 
 
Figure 3. Steps sequence of document processing using the proposed method. 
 
    
(a)  gray image (b)  filtered binary image using Weiner filter then classical Otsu’s method 
(c) final binary image using the 
proposed method. 
Figure 4. Results of denoising process 
 
The optimal threshold minimizes the class variance of the 
two classes of pixels. Global threshold [4-7], [8], has a good 
performance in the case that there is a good separation between 
the foreground and background of the image. However, very 
often, ancient document images are exposed to degradation that 
weakens that separation. On the other hand, adaptive threshold 
changes the threshold value dynamically over the image pixels 
(or regions). Local area information guides the threshold value 
for each pixel (or region) [9-13], [14]. Such method can deal 
with different kinds of noise existing in an image. However, 
adaptive technique is significantly more time consuming and 
computationally expensive [15]. Taking into account the above 
methods, we introduce in this paper a hybrid thresholding 
method. The method depends on both global and adaptive 
techniques. Details of the proposed technique will be discussed 
later.  
As is observed from the previous Arabic manuscript 
images, in Arabic language, the word likely consists of two or 
more characters which are connected through an imaginary line 
called baseline. Detecting Arabic baseline is still one of the 
Arabic OCR challenges, these challenges include the 
following: 
 Arabic is written cursively, and it has 28 characters and 
each character written between two to four ships 
according to its location in the word, see Tab. 1 
 The diacritics, such as top-bottom dots of the character 
and zigzag (e.g.  ,  ,  ,   ), have significant effects 
on the Arabic baseline detection 
 The text gradient is also considered trouble in base line 
detection 
 Arabic words may be contracted from two or more sub 
words, and the distribution of these sub words in the 
same word makes detecting baseline difficult. 
TABLE I. SAMPLES OF SHAPES ARABIC CHARACTERS 
Final Medial Initial Character Isolated 
 
 
	 .  .   . 

 :  . 
 
 :  .  
 
 
 
  
  .  .   .  
  :  .  
  :  .  
  
 
 
  
  .  .   .  
  :  .  
  
 :  . 
  
  
  
  
  .  .   .  
  :  .  
  
  :  .  
 
 
 
The correction of curvature and inclinations has a direct 
effect on the reliability and efficiency in OCR. Revealing the 
importance of this stage, many researches have been presented 
with various methods for skew detection and correction of the 
scanned image. These methods can be classified according to 
the technique used for detection of the baseline [16]. The 
baseline can be detected based on; horizontal projection, word 
 
Original 
RGB image 
 
RGB to 
Gray image 
 
Weiner 
filter 
Binarization 
using proposed 
hybrid method 
 
skeleton, contour tracing, or principle component analysis 
method. Such methods will be briefly discussed as follows: 
Horizontal projection method: This method works by 
reducing the 2D of data to 1D based on the pixels of the text 
image. The text baseline location is determined according to 
longest peak [17], [18]. 
The horizontal projection profile is defined as: 
	


N
j
jiimageiP
1
),()(
 
(2)  
Where P(i) is the horizontal projection of the image for row 
i; and the image(i, j) is the pixel value at (i, j). 
Word skeleton method: This method based on the skeleton 
lines of the polygonal word skeleton. Subsequently, set of 
feature are extracted, these features represent the baseline 
relevant features. Afterward the best extracted baseline relevant 
feature will be chosen. The baseline detected by using linear 
regression depending on the selected relevant features [17]. 
This method works well with the Arabic handwritten words, 
also it can be applied in printed text, and on the other hand it 
needs more time because it works with set of complex 
calculations. 
Contour tracing method: This method based on local 
minima point of the word contour [19]. The minima points 
depend on the contour direction; it is located where the contour 
changes direction from the down word to the up word. Then, 
apply (least squared sum) linear regression to detect the 
approximate baseline. Reset a new minima point close to the 
old point. Finally, Use the second linear regression to detect the 
word baseline. This method works well with the Arabic 
handwriting words. Also it can be applied in the printed text, 
but, character size affects the performance of the method.  
Principle component analysis method: Principal 
components analysis (PCA) can be used to compress and 
recognize the two and the three domination images as well as it 
used for Latin skew detection [20] and Arabic baseline 
detection. This method based on angle detected by principle 
Components Analysis. It is used to determine the Arabic word 
baseline direction according to the foreground or background 
pixels distribution. 
The previous methods work well with printed text, but there 
is a need for more efficient handwritten baseline detection 
method. In this paper, we proposed a modified Centroid of 
Ellipse method [21] to detect and correct the baseline in 
skewed Arabic document images.  
III. METHODOLOGY & REULTS 
A. Denoising & Binarization  processes 
As a starting point, the Arabic manuscript colored image 
shown in Fig. 1(a) is considered. Fig. 3 illustrates our proposed 
methodology. The RGB image is transformed to a gray image 
using the classical method (i.e. converting the RGB values to 
NTSC coordinates, setting the hue and saturation components 
to zero, and then converts back to RGB color space), Fig. 4 (a). 
As shown, the gray image is full of noise and defects. Then, 
low pass wiener filter is used because it introduces smoothing 
of background texture as well as contrast enhancement between 
background and text areas [8]. The window size of Wiener 
filter is chose to be 3×3, since it gives us good output. Otsu’s 
threshold method [4] based on a very simple idea: Find the 
threshold that minimizes the weighted within-class variance. 
The threshold level calculated by Otsu's method gives us 
degraded image especially for the characters written with red 
pen (   ). This defect is shown in Fig. 4 (b). In order to 
overcome such defect, we propose a hybrid thresholding 
method which depends on both global and adaptive techniques. 
The gray image is divided into large rectangular blocks with 
dimensions (d × d). The parameter "d" depends on the total 
number of vertical pixels occupied by the text and white space 
just below it. Otsu's method is used to calculate the threshold 
level of each sub image. Then, each block is binarised 
according to its pre-calculated self threshold level. Finally, 
binarised blocks are assembled to construct the resultant binary 
image. Fig. 4 (c) shows the binary image after applying the 
proposed method. As noticed, the area that contains characters 
with red font conserves the included characters after 
binarization. For the document under study, the quality of 
results is degraded for d  30 pixels. The best results are 
obtained using d = 60.    
B. Skew detection & correction 
In this stage, we present a simple approach for skew 
detection and correction illustrated in Fig. 5. The slanted 
Arabic document image (e.g. as that shown in Fig. 6 (a)), is 
written with skew angle can be rotated to the correct position 
according to the following steps. The first is the baseline 
identification by searching of the center of each connected 
component as shown in Fig. 6 (b), in the document. The 
contour of the connected component is formed by nearest 
ellipse with an equivalent area. The baseline detected as the 
principal axe of the ellipse, see Fig. 6 (c). The second step is 
the skew angle correction. The orientation of connected 
component is defined as a skew between its principal axe and 
the reference axe. After that, rotate the image according to the 
estimated direction. The method works well with the Arabic 
manuscript and it can be applied in the printed text.  
Our method has been implemented using MATLAB 7.0. 
We have considered different skewed documents (either 
printed or handwritten documents). Fig. 7 shows the corrected 
test image after applying the proposed method of image 
reported in Fig. 6 (a). Samples of handwritten (historical 
Arabic Manuscripts) with skew angle 43 shown in Fig. 8 (a); 
wherever after the binarization and enhancement of the input 
images, the baseline is identified as the principal axe of the 
ellipse which is the contour of the connected component. Then 
the image is rotated into the estimated direction. Fig. 8 (b, d) 
shows the corrected text image after applying the proposed 
method. 
 
 
 
 
 
 
 
Figure 5. Steps sequence of the skewed document image correction 
 
  
(a) Skewed test image (b) Connected component  (c) Skwed angle detection 
Figure 6. Centroid of the connected component, and Calculates the skew angle (angle between the principal axe and the reference axe) 
 
 
 
Figure 7. Corrected test image after applying the proposed method 
 
(a) Input image, skewed 
 
(b) Output correct image 
 
(c) Input image, skewed 
 
(d) Output correct image 
Figure 8. Result of the propsed skew angle detection and coreection method 
IV. CONCLUSION 
In this study, an image of complex colored Arabic manuscript, 
has four text blocks with different skew angles, is considered. 
We focus on two main tasks. The first is to get the best binary 
image with clean background. The second task is to detect the 
skew angle and then correct the orientation of skewed text 
lines.  We propose a hybrid thresholding method which 
depends on both global and adaptive techniques. Such system 
is implemented to process the manuscript under study and 
gives promised results. Moreover, a simple method is presented 
to estimate skew angle. The proposed method modifies the 
centroid of ellipse method and then implemented. Good results 
are obtained when using such system to detect the skew angle 
and then rotating the skewed text lines. 
More processing steps are still required as a future work. The 
most important one is to automatically decompose the 
manuscript image into four separate images where each image 
has horizontal text lines.  
 
REFERENCES 
 
[1] http://www.manuscripts.idsc.gov.eg/Manuscript/ 
[2] A. M. Al-shatnawi, K. Omar “ skew detection and correction technique 
for arabic document images based on center of gravity,” Jor. Of 
computer sc., vol. 5, no. 5, 2009, pp 363-368 
[3] W. Boussellaa, A. Zahour, B. Taconet, A. Alimi, A. Benabdelhafid,  
“PRAAD: Preprocessing and Analysis Tool for Arabic Ancient 
Documents,” Document Analysis and Recognition, 2007. ICDAR 2007. 
Ninth International Conferenceon, Vol. 2, Sept. 2007 pp 1058 – 1062 
[4] N. Otsu "A threshold selection method from gray-level histograms,". 
IEEE Trans. Sys., Man., Cyber. Vol 9, 1979, pp. 62–66. 
[5] J. Kittler, J. Illingworth, “On threshold selection using clustering 
criteria,” IEEE Trans. Systems Man Cybernet.  Vol. 15, 1985, pp. 652–
655. 
x
y
x
y 
Center 
 
Baseline 
detection 
 
Skew angle 
Detection & correction 
Centroied 
of 
connected 
component 
 
[6] A. D. Brink, “Thresholding of digital images using two-dimensional 
entropies,” Pattern Recognition vol. 25  no. 8, 1992, pp. 803–808.  
[7] H. Yan, “Unied formulation of a class of image thresholding 
techniques,” Pattern Recognition vol. 29, no. 12, 1996,  pp. 2025–2032. 
[8] N. Nikolaos, V. Dimitrios, “A Binarization Algorithm For Historical 
Manuscripts,” 12th WSEAS International Conference on 
COMMUNICATIONS, Heraklion, pp 41-51, 2008. 
[9] I. K. Kim, D. W. Jung, R. H. Park, “Document image binarization based 
on topographic analysis using a water ow model,” Pattern Recognition 
vol. 35, 2002 pp. 265–277.  
[10] W. Niblack, “An Introduction to Digital Image Processing,” Prentice-
Hall, Englewood Cliffs, NJ, 1986 pp. 115–116. 
[11] J. Yang, Y. Chen, W. Hsu, “Adaptive thresholding algorithm and its 
hardware implementation,” Pattern Recognition Lett. Vol. 15 no. 2 
,1994, pp. 141–150.  
[12] J. Sauvola, M. Pietikainen, Adaptive document image binarization, 
Pattern Recognition 33 (2000) 225–236.  
[13] M. Chang, S. Kang, W. Rho, H. Kim, D. Kim, Improved binarization 
algorithm for document image by histogram and edge detection, 
ICDAR’95, 1993, pp. 636–643. 
[14] Y. S. Halabi, Z.  SA, F. Hamdan, K. Haj Yousef, “Modeling Adaptive 
Degraded Document Image Binarization and Optical Character System,”  
European Journal of Scientific Research, Vol.28, No.1, 2009, pp.14-32 
[15] E. Kavallieratou and E. Stamatatos, "Improving the Quality of Degraded 
Document Images", Proc. of the Second International Conf. on 
Document Image Analysis for Libraries, 2006. 
 
[16] A. M. Al-shatnawi, K. Omar “Methods of Arabic Language Baseline 
Detection – The State of Art,” arab research institute in sciences and 
engeneering, vol. 4, no. 4, 2008, pp 185-193 
[17] M . Pechwitz, V. Maergner, “Baseline estimation for arabic handwritten 
words,”  In Frontiers in Handwriting Recognition, pp. 479–484, (2002) 
[18] A. M. Zeki, “The segmentation problem on Arabic character recognition  
the state of the art,” in Proc. 1st Int. Conf. on Information and 
Communication Technology (ICICT), pp. 11-26, Pakistan, 2005 
[19] F. Farooq, V. Govindaraju, M. Perrone “Pre-processing Methods for 
Handwritten Arabic Documents,” in Proc. of the 2005 Eight Int. Conf. 
on Document Analysis and Recognition, IEEE, 2005, pp. 267-271. 
[20] T. Steinherz, N. Intrator, E. Rivlin, “Skew detection via principal 
components analysis,” In Proc. 5th ICDAR, IEEE, pp. 153–156 , 1999 
[21] M. Charfi, W. Boussellaa, A. M. Alimi, “Detection and Correction of 
Inclination   and Curvature of the Scripts in the Images of Ancient 
Arabic Documents,” the 4th International Conference on Computer 
Science practice in Arabic (CSPA 08), pp. 1-12 
 
 
 
 
 
