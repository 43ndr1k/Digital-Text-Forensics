                                        Knowledge-Based Systems 
                                  Manuscript Draft 
 
Manuscript Number: KNOSYS-D-15-01485 
 
Title: Novel Undersampling Approaches based on Global distance criteria 
to handle Class Imbalance in Supervised Learning 
 
Article Type: Full Length Article 
 
Keywords: Imbalance, Stratied Sampling, UnderSampling, Clustering, 
Classication 
 
 
 
 
 
 
Highlights of  “Novel Undersampling Approaches based on Global distance criteria to handle 
Class Imbalance in Supervised Learning” 
 
1. Simplicity 
2. Taken care in choosing samples so that they are taken from throughout without confining to    
     particular region. 
 
3. Effective for high dimensional and large datasets also. 
4.  Do not use any clustering or classification algorithms as many of the existing undersampling  
     methods do. 
 
5.  Completely novel method which is based on distance from reference points(Centroid,  
      Quartiles).   
 
Highlights (for review)
Novel Undersampling Approaches based on Global
distance criteria to handle Class Imbalance in
Supervised Learning
C.V. Krishna Venia, T. Sobha Ranib
acvkrishnaveni19@gmail.com, University of Hyderabad, India
bt.sobharani.cs@gmail.com, University of Hyderabad, India
Abstract
Class Imbalance problem has received considerable attention in the research
field of machine learning. Among the methods which handle class imbalance
problem, undersampling is a data level approach which preprocesses the data
set to reduce the size of the majority class instances. Most of the existing
undersampling methods apply either prototype selection or clustering tech-
niques to balance the data set. They are effective and popular undersampling
methods, but both processes are complex. Drawbacks of the cluster based
undersampling methods are : The quality of the chosen majority class sam-
ples varies depending on clustering algorithm, number of clusters and also
the convergence is difficult. Drawback of prototype selection methods is that
they have to compare each majority instance with it’s k nearest neighbors to
decide which majority class instance should be selected/discarded which is
not only time consuming and is also difficult to implement for large datasets.
Two undersampling methods Centroid based UnderSampling(CUS),
Quartile based UnderSampling(QUS) proposed in this work overcome
the above said problems. These methods are simple, parameter independent
and are based on distribution specific grouping. They also handle the issues
of information loss and proper representation of the majority class instances
in the training sets. Extensive experimentation is done on data sets of var-
ious sizes and various dimensions with imbalance ratio ranging over a large
range of values. Empirical results prove that the proposed methods outper-
form or are similar to the existing methods and the accuracy of minority
class prediction has improved as compared to the training set without pre-
processing. To the best of our knowledge this kind of grouping has not been
used in undersampling to improve the classification accuracy of imbalanced
Preprint submitted to Knowledge Based Systems October 23, 2015
*Manuscript
Click here to view linked References
data sets.
Keywords:
Imbalance, Stratified Sampling, UnderSampling, Clustering, Classification
1. Introduction
In many real world applications like oil spilts in satellite images, credit
card fradulant transactions, cardinality of cases that are rare(minority) are
much smaller than cases that are common(majority). A data set of this kind
is called an Imbalanced data set. Traditional classifiers do not perform well
on imbalanced data sets. Main reasons for this are the inherent assumptions
made for traditional classifiers such as (i) equal class distribution in the
training set (ii) equal mis-classification cost for both the classes and (iii) the
performance is based upon accuracy. Overall classification rate of test set is
computed irrespective of their class distribution which results in giving higher
accuracy even if mis-classification of all positives happens. For example, a
classifier is built to predict a rare-disease. Positive cases of that rare-disease
are only 2% and the rest are 98%. Classifying all unseen cases as negatives
would give an accuracy of 98%, even while classifying all positive cases as
negatives.
Several solutions are proposed at data level and algorithmic level to han-
dle the problem of imbalance in the data sets and to reduce the impact of
imbalance on the minority instances classification. Cost-sensitive learning,
ensemble methods are also widely implemented to address this problem. At
data level, the data set is manipulated to balance the class distribution.
Data level sampling methods for handling imbalanced data sets are catego-
rized into (i)Oversampling methods and (ii) Undersampling methods. At
algorithmic level, thresholds and parameters in the algorithm are adjusted in
classification methods to handle the imbalance. In the case of cost-Sensitive
learning, cost matrix with unequal costs, more penalty for false negatives
and low penalty for false positive is used. Ensemble learning methods make
use of subsets of the samples of the data set and several classifiers to improve
the classification of imbalanced data sets.
Section 2 covers related literature on imbalanced data sets. Section 3
provides framework of the proposed methods, Section 4 describes experiments
and results, Section 5 provides discussion through comparison and Friedman
ranking tests. Section 6 gives the conclusions.
2
2. Related Work
In the literature, several papers [3, 4, 5, 6, 7, 9, 10, 11, 12, 46, 14, 15,
16, 17, 18, 19, 20, 8] provide a very good survey on the classification of
imbalanced data sets and on various methods which can handle the imbalance
problem. Data level sampling methods to handle imbalanced data sets can
be categorized into oversampling and undersampling methods.
2.1. Data level Handling Techniques
Oversampling methods are those in which minority class instances are
increased to balance the data set and undersampling methods reduce the
number of majority class instances to balance the data set. Oversampling
methods are further divided into Random oversampling and Informative
Oversampling methods. Random oversampling replicates the minority class
instances randomly. Informative oversampling methods increase the number
of minority samples by following certain criteria. In Informative oversam-
pling methods, Synthetic Minority Oversampling TEchnique(SMOTE) [26]
is popular which creates artificial samples between two samples in the minor-
ity class. Several modifications of SMOTE such as borderline-SMOTE [27],
safe-level SMOTE [28], ADASYN [29] are proposed.
Undersampling methods are also divided into Random Undersampling
and Informative Undersampling. Random undersampling, removes majority
instances randomly to balance the training set. Because of this there is loss of
useful information. Informative undersampling, chooses or discards certain
majority instances based on certain conditions. Many solutions are proposed
based on informative undersampling. It can be surmised that most of the
methods in undersampling deal with either kNN based approaches, clustering
based approaches or a combination of these two approaches.
2.2. Popular Undersampling Techniques
Condensed Nearest Neighbor(CNN) Rule [21], the Condensed Nearest
Neighbor Rule with Tomek Link (CNNTL) [7], Neighborhood Cleaning Rule
(NCL) [25], One Sided Selection(OSS) [22], Tomek Link [23] etc are widely
used undersampling techniques. They select majority class samples based on
their distance from minority class samples using kNN classifier.
Condensed Nearest Neighbor (CNN) [21] as an undersampling ap-
proach initially places all minority class samples and one randomly chosen
majority class sample in ’S’ from ’D’, the given dataset. Then 1-NN is used
3
to classify the samples from D with respect to contents of ’S’ and every mis-
classified sample is moved from ’D’ to ’S’. The idea behind CNN method is
to eliminate the majority class samples that are distant from the decision
border as they are considered to be less relevant for learning.
Tomek links [23] can be used as data cleaning method which eliminates
noisy and borderline samples. But as an undersampling approach Tomek
links are used to eliminate noisy and borderline majority class samples only
and not minority class samples. Consider two samples xi and xj which belong
to different classes and d(i,j) be the distance between xi and xj. An (xi, xj)
pair is said to be a Tomek Link, if there is no sample xl such that d(i,l) <
d(i,j) or d(j,l) < d(i,j).
One Sided Selection(OSS) [22], is an undersampling method which
applies Tomek Links followed by CNN. This method retains all the ’safe’
(which do not participate in Tomek Link that is other than borderline) ma-
jority class samples and all minority class samples in the data set. CNNTL
[7] is another undersampling method which is similar to OSS but applies TL
after CNN as TL is computationally expensive, first condensed set is formed
using CNN and then TL is applied on the reduced set.
Neighborhood Cleaning rule (NCL) [25] uses Wilson’s Edited Near-
est Neighbor rule [30] to remove majority class samples. ENN eliminates a
sample whose class label differs from the class of atleast two of its three near-
est neighbors. For a two class problem NCL as an undersampling approach
uses ENN in the following way: For each sample xi in the given training set,
its three nearest neighbors are found. If xi belongs to majority class and is
misclassifed by three of its nearest neighbors then xi is removed. If xi belongs
to minority class and is misclassified by its three nearest neighbors then the
three nearest neighbors which belong to majority class are removed.
Class Purity Maximization(CPM) [31] finds a pair of minority and
majority samples as centers. Using these centers, it partitions all the in-
stances into two clusters C1 and C2 according to their nearest centers and
this process is repeated till atleast one subset has class impurity less than
its parent’s impurity. A training set is constructed by adding all minority
instances to each non-pure cluster.
Yen and Lee in [24] proposed a cluster based undersampling tech-
niques (SBC). In their approach, they cluster the entire data set and the
number of majority samples to be chosen is determined by the number of mi-
nority samples in that cluster. Along with SBC, they proposed five methods
namely: sampling based on clustering with NearMiss-1(SBCNM-1), sampling
4
based on clustering with NearMiss-2 (SBCNM-2), sampling based on clus-
tering with NearMiss-3(SBCNM-3), sampling based on clustering with Most
Distance(SBCMD) and sampling based on clustering with most far(SBCMF).
Rushi et al. [32] clustered majority class samples XMaj into k clusters
and select Ri×size(MinClass) number of samples from each cluster so that
the total number of selected majority samples equals the size of the minority
set XMin to balance the training set, where Ri = XMaji/XMaj, 1 ≤ i ≤ k
represents the number of majority class samples to be chosen is based on the
ratio of the number of majority samples in each cluster to the total number
of majority samples. The number of majority class samples chosen from ith
cluster is calculated using Si = XMin×Ri, 1 ≤ i ≤ k. Our method resembles
this method in the way majority samples are chosen, but the way we form
grouping is completely different from this method.
In [33], a cluster based undersampling with ensemble learning is proposed.
The authors have clustered the majority instances into k clusters where k
value lies between 1 and size of the minority class and size(MinClass)/k
number of samples are selected from each cluster to be equal to the number of
minority samples. m training sets are formed and trained using m classifiers
and the final result is obtained by weighted majority voting, where weight of
each classifier is taken as the inverse of its error on the whole training set.
In [34], majority class instances are divided into k clusters andk training
sets are formed with majority class instances of each cluster combined with
all the minority class samples and the training sets with highest accuracy is
used as the final training set for classification.
2.3. Other types of Imbalance Handling
Latest papers on imbalanced data sets include [36, 37, 38, 39, 42, 40] etc.
Wang et al in [36] use an ensemble method along with weights and informa-
tion about sample misclassification to effectively classify imbalanced data.
Zhang et al. [37] present empirical analysis by conducting various exper-
iments on imbalanced data sets of varying imbalance, size and complexity
applying three popular classifiers Naive Bayes, c4.5 and SVM. Results have
shown that SVM outperforms the other two classifers. Barella et al. in [40]
proposed a cluster based one sided selection method for undersampling. In
[38], a similarity based hierarchical decomposition method is proposed to
classify imbalanced data sets. Wing et al. in [39] proposed a diversified
sensitivity-based undersampling method for imbalance classification. An-
other latest works, [42] uses ensembles of First Order logical Decision Trees
5
to handle the problem of imbalanced classification, [44] uses feature weight-
ing to deal with overlap in imbalanced datasets, [45] proposed a Random-
Balance method for imbalanced data which uses ensembles of variable priors
classifiers. In [46], Sun et al proposed a novel ensemble method to classify
imbalanced data sets.
3. Proposed Work
3.1. Motivation for the Proposed Work
Existing under sampling methods to balance the imbalanced data set ei-
ther apply
(i) Prototype Selection Methods or
(ii) Clustering algorithms
3.1.1. Drawbacks of applying prototype selection methods in under sampling
• The Complexity involved in choosing the majority class samples is high
because selection is done based on the distance from k nearest neigh-
bors that is, every majority sample is to be compared with k nearest
neighbors which is arduous.
• Also, it is some what time consuming as it has to compare k Nearest
Neighbors fro each of the majority class sample. The method com-
plexity and time consumption increases with the increase in number of
instances or number of attributes of the dataset.
3.1.2. Drawbacks of cluster based under sampling methods
Once clusters are formed, this method is simple to implement but to form
clusters several issues are to be addressed viz.:
• Which clustering algorithm is to be used This decision depends
mostly on :
(a) The size of the dataset. (b) The dimensionality of the dataset. (c)
The type of data present in the dataset.
• After deciding on a particular clustering algorithm, next issue to be
handled is : How many clusters are to be formed
This can be decided by using cluster validity indices. Again in those, if
6
external cluster validity indices are chosen, parameters are to be sup-
plied by the user i.e., again quality of the cluster may vary depending
upon the parameters. Even, if internal cluster validity indices are used,
which is appropriate and why are to be known.
Keeping the above factors in mind, we have designed a new method which
is simple, consumes less time, works for any size and dimensional dataset.
These methods ensure minimum loss of information. Proposed two under-
sampling methods are
(i ) Centroid based UnderSampling(CUS) and
(ii) Quartile based UnderSampling(QUS)
These methods are:
• simple and consume less time.
• do not depend of external parameters(They do not use any specific
clustering algorithm or classification algorithm in choosing majority
class samples.)
• work well on small, medium, large datasets
• work well on low, medium , high dimensional data sets.
These methods choose samples which are representative, reduce the majority
class samples with minimal loss and samples are chosen so that they cover
the entire distribution of the data set.
3.2. Theoritical Background of Proposed methods
Centroid based UnderSampling(CUS) and Quartile based UnderSampling
(QUS) methods are proposed. Both methods balance the given training set
by choosing negatives from the entire distribution so that there is minimal
loss in information and that the selected negatives act as representatives
of all the negatives in the training set. These methods are proposed to
address two major drawbacks of the undersampling (i) information loss and
(ii) representation of the majority class. Information loss is handled by the
way groups are formed which allows the samples to be chosen throughout
the majority class without confining to any particular region. The issue
of representation of the majority class is addressed by employing stratified
sampling strategy, which chooses the number the samples from each group
7
depending on its size, so that the samples chosen represent the majority class
as a whole.
Novelty of the methods lies in forming groups without depending on
any external parameters given by the user. The main difference between
[33, 24, 32] and the proposed methods is that they form groups using clus-
tering whereas the proposed methods do not use any clustering algorithm,
instead they divide the majority class samples based on their distance from
the reference point(s). Their methods are dependent on chosen clustering
method and k, the number of clusters. Optimal number of clusters, cluster
quality are the issues in all clustering mechanisms, whereas the proposed
methods are not dependent on any of these external parameters.
Difference between the proposed methods and CNN, CNNTL, NCL , OSS
lies in the way of choosing the majority class instances. They choose/discard
the majority class samples based on their distance from minority class sampes
whereas CUS and QUS choose majority class samples based on their distance
from the reference point(Centroid(Neg Cent)) in CUS and reference points
Neg Min, Neg Q1, Neg Median, Neg Q3 and Neg Max in case of QUS.
They use kNN classifier to choose majority class samples, but the proposed
methods do not use any classifier thereby reducing computation involved in
finding nearest neighbors as the size of the data set increases.
3.3. Framework for the proposed methods
A given data set is divided into 5 training sets and 5 test sets for 5 fold
cross validation. Pre-processing is done using CUS and QUS only on the
negative sets of the training sets in each fold to balance the positive and
negative sets. The new balanced training sets are used to train the classifiers
for each fold respectively. The average of the results obtained on 5 test sets
is shown as the output of the classifier. Two classifiers, C4.5 and kNN are
chosen to check the performance of the proposed undersampling methods.
In these two methods, negative samples in the training set are grouped
based on their distance from the reference point(s). And then stratified
sampling is employed to choose negatives from each group, that is the number
of samples to be chosen from each group depends on the size of the group
and the total number of negatives to be chosen from all the groups which is
equal to the number of positives in the training set.
Let Np be the number of Minority class instances, Nn be the number of
Majority class instances of the training set.
8
After formation of groups, Np Majority instances are selected based on strat-
ified sampling to balance the minority and majority instances. ri instances
are chosen in each group so that resultant number of chosen Majority class
samples will be equal to Minority class samples.
ri =
size(groupi)
Nn
Np 1 ≤ i ≤ k (1)
Negative samples chosen = Σiri (2)
Contribution to the classification by different instances varies depend-
ing on their distance from the decision border. That is, the internal(closer)
instances influence more than the borderline instances(farther). However,
farther instances help in learning the concept better. Hence, the samples
are chosen with varying levels of influence on the classification which com-
pensates for the left-over instances from the original training set that is, the
chosen negative samples should act as representatives of the entire negatives
in the training set.
Each of the proposed two pre-processing methods are implemented in four
ways:
1. Changing distance measures to find the similarity of negative in-
stances to the reference points. Euclidean and Soergel distance
measures are used in the experiments.
2. Standardizing attribute values Training sets with and without
standardization are used for experimentation. As the range of attribute
values can be very large for few attributes, standardization gives equal
weightage to all attributes.
3.4. Centroid based Under Sampling technique
The idea behind Centroid based UnderSampling(CUS) method is to cap-
ture the majority class samples based on their similarity with respect to the
average behaviour of all the majority class instances. This method chooses
the majority class samples based on their distance from their centroid(Ccent),
that is samples throughout the distribution from nearer to farther reflecting
the distribution of the majority class instances so that the chosen samples
act as representatives of the majority class samples in the training set. Dia-
grammatic representation of CUS is given in figure 1. Steps followed in the
pre-processing are shown in the algorithm 1. Number of groups are not based
on any criteria but are chosen arbitrarily.
9
Algorithm 1 Centroid Based Undersampling Technique
Input: An Imbalanced Data Set
Output: A Balanced Data Set
1. Find the centroid of the majority class instances of the training set,
Negcent.
2. Find the euclidean distance of each negative training instance, i from
Negcent. Let it be dist(i).
3. Normalize the values of dist(i) to the range 0 to 1.
4. The negative training instances which are at a distance from 0 to 0.1
are placed in group1, 0.1 to 0.2 in group2 and so on 0.9 to 1.0 in group10.
5. r (Eq.1) samples are chosen from each group to select a total of Np
(Number of Positives) negatives.
6. The set with all positives and chosen negatives from the given training
set form a balanced set New − Training.
3.5. Quartiles based Under Sampling technique
Quartiles are used to represent the distribution of the data set in statistics.
In machine learning, these points are used to identify outliers. Here these are
used as reference points and divide the instances in the training set based
on the distance from the quartiles. The idea behind this is that all the
instances which are close to min are formed into group1, all the instances
those are close to Q1 are grouped into group2 and so on, the instances which
are close to max are formed into group5. And then, based on the size of the
groups, instances equal to the size of the minority class are chosen. Intuition
behind the idea is to choose the majority class samples throughtout the
distribution which exhibit characteristics closer to reference points. In this
method, majority class samples are chosen based on the quartile distances.
Diagrammatic representation of QUS is given in figure 2. As compared to the
CUS, here only five reference points from which the distances are computed.
The steps are shown in algorithm 2.
4. Experiments and Results
In order to verify the efficacy of the pre-processing techniques proposed
here, a varied set of data sets are chosen to take into account the effect of data
complexities and attribute complexities. Broadly they can be categorized as
10
Figure 1: Centroid Based Undersampling: diagrammatic representation
Figure 2: Quartile Based Undersampling: diagrammatic representation
sets with instances (low and high) and attributes (low and high), like small
number of features with large number of instances, large number of features
and large number of instances etc. Table 1 lists these data sets.
11
Algorithm 2 Quartiles Based Undersampling Technique
Input: An Imbalanced Data Set
Output: A Balanced Data Set
1. Find the reference points i.e., Negmin, NegQ1, Negmedian, NegQ3 and
Negmax of all the negative training instances.
2. Find the euclidean distance of each negative training instance, i from
each of the reference point.
3. The negative training instances which are nearer to Negmin are grouped
as group1, NegQ1 as group2 and so on Negmax as group5.
4. r (Eq.1) samples are chosen from each group to select a total of Np
(Number of Positives) negatives.
6. The set with all positives and chosen negatives from the given training
from a balanced set New − Training.
Table 1: Details of the data sets with imbalance ratios in the brackets. (Data sets with
number instances ≥ 2000 and attributes ≥ 90 are considered as qualifying under high
category).
Instances
low high
Ecoli4(14.3) Pageblocks0(8.79)
Haberman(2.78) Skin(3.82)
low Iris(2) Shuttlecc4vsal(5.51)
NewThyroid1(5.14) Segment0(6.02)
Attributes Pima(1.89)
Vowel0(9.98)
Yeast1289(30.57)
LibrasMove(14) Scene(12.6)
high Isolet5(24.98) Spectrometer(10.8)
Musk2(5.49)
4.1. Details of the data sets used in the experiment
Binary class data sets are used in the experiments. Multi-class data sets
are converted into binary class by taking required class as positive and all
other classes as negative. The data sets are chosen based on their number of
attributes, number of instances and imbalance ratio to check the performance
of the proposed methods on small, medium and large number of attributes,
instances and imbalance ratio. Table 2 shows the details of the data sets.
All the values in these data sets are numeric except the class attribute. The
12
data sets are taken from the UCI [48], KEEL[49] data repositories and used
KEEL[49], weka[50] tools to conduct the experiments.
Table 2: Details of the data sets.
Name of the # Features Total # Imbalance
Data Set Instances Ratio
Ecoli4 7 459 14.3
Haberman 3 306 2.78
Iris0 4 150 2
Isolet5 617 1599 24.98
LibrasMove 90 360 14
Musk2 166 6599 5.49
NewThyroid1 5 215 5.14
Pageblocks0 10 5472 8.79
Pima 8 768 1.89
Scene 294 2407 12.6
Segment0 19 2308 6.02
Shuttlec4vsall 9 58000 5.51
Skin-Segmentation 3 245057 3.82
Spectrometer 93 7797 10.8
Vowel0 13 988 9.98
Yeast1289Vs7 8 947 30.57
4.2. Evaluation Criteria
Performance of a classifier is calculated based on the confusion matrix. Various
measures used for describing the performance of the classifiers are based on the
confusion matrix and are listed below.
Table 3: Confusion Matrix
Predicted Positives Predicted Negatives
Actual Positives True Positives(TP) False Negatives(FN)
Actual Negatives False Positives(FP) True Negatives (TN)
Sensitivity : Recall and True Positive Rate(TPRate), TPR are other names
of Sensitivity.
Sensitivity = TP Rate = Recall = TPTP+FN
Specificity: True Negative Rate(TNRate), TNR are other names of Speci-
ficity.
Specificiy = TN Rate = TNTN+FP
FalsePositiveRate: False Positive Rate is the percentage of negatives wrongly
classified.
FP Rate = FPTP+FN
FalseNegativeRate: False Negative Rate is the percentage of positives wrongly
classified.
FN Rate = FNTN+FP
13
Accuracy: The percentage of correctly classified instances.
Accuracy = (TP+TN)(TP+FN+TN+FP )
Error Rate: The Percentage of incorrectly classified instances.
Error Rate = (FP+FN)(TP+FN+TN+FP )
Precision: Precision is the percentage of correctly classified positives.
Precisiion = TPTP+FP
GMean: It is the geometric mean of Sensitivity and Specificity.
Gmean =
√
Sensitivity × Specificity
F-Measure: It is the harmonic mean of Precision and Recall.
F-Measure = 2×Precision×RecallPrecision+Recall
AUC: Receiver Operating Characteristic(ROC) and the Area Under ROC
are the most commonly used evaluation measures for imbalanced data sets. A
visual indication of the classifier superiority over another classifier over a wide
range of operating points is given by the ROC curve and the area under the ROC
curve(AUC) (Figure 3) summarizes the performance of a classifier into a single
metric.
Figure 3: AUC Curve.
Area Under ROC Curve(AUC) = (1+TPR−FPR)2
AUC and Gmean are the popularly used evaluation metrics for imbalanced
data sets classification. In this paper, we used AUC measure to compare the
classification results achieved by different classifiers using different pre-processing
techniques.
4.3. Details of Implementation
Proposed two undersampling methods differ in the first step that is in the way
they form groups. CUS divides all the negatives into m bins based on the distance
from their Centroid(Negcent). QUS divides all the negatives into 5 bins based on
their closeness to the 5 reference points that is, Negmin, NegQ1, Negmedian, NegQ3
and Negmax.
14
As a second step, (Np) number of negatives are chosen from groups using strat-
ified sampling, that means number of instances to be chosen from each depends
on its size. The methods are implemented and tested using classifiers C4.5 and
kNN and compared with other existing undersampling, oversampling, ensemble
and cost based techniques with the same classifiers.
Two distance metrics are considered here to compute the distances between
the reference point(s) and an instance in the data set: Soergel distance belongs
to L1 family and Euclidean belongs to L2 family of distances. Euclidean distance
measure is a standard that is used most often. Soergel distance [35] has been cho-
sen in some of the works to compute the similarity. Soergel computes similarity
better than euclidean by consideration from another family of distances. Exper-
imentation is done after standardizing the attributes values to bring the varying
attribute range to achieve uniformity. i.e., while giving input we use normal data
without standardization experimentation, and data with standardization. Soergel
distance is also experimented with and without standardization as an other dis-
tance measure to capture the similarities of the reference instance with each in-
stance. Implementation of above algorithms differ in step 2 i.e., using euclidean
or soergel distance formula. Euclidean distance is found using dEucl (Eq.3) and
Soergel distance is found by using dsg (Eq.4)
deucl =
√√√√ d∑
i=1
|Pi −Qi|2 (3)
dsg =
∑d
i=1 |Pi −Qi|∑d
i=1max(Pi, Qi)
(4)
Tables 4, 5, 6, 7, 8, 9 10, 11 show the classification results obtained for various
data sets using the pre-processing methods C4.5 and kNN with different distances
measures to compute the distances between reference point and the instances in
the data set with 10, 20 and 5 bins respectively. Tables show the average values
for the 5-fold cross validation conducted on the data sets. Here, number of bins
are varied from 5 to 20 to observe the effect of bins on the classification. These are
tested with Euclidean, Soergel distance measures with and without standardizing
the attribute values. It is observed that there is not much impact of number of
groups on the results. As distance value in normalized form is taken in order to
maintain a particular range for all the data sets to lie between 0 and 1, 10 bins
are chosen with the simple intuition that all instances with distance value between
0 to 0.1 lies in group1 etc. Since in QUS, 5 bins are being used, in CUS also 5
bins are used. In order to find the effect of increasing the number of bins, bins
are increased to 20. In all the three cases, proposed methods achieve improvement
15
in the True Positive Rate(TPR) and also good AUC results are obtained. To
know which variant of CUS is performing better and to choose one among those,
friedman test is conducted.
16
Table 4: AUC Results with C4.5 Classifier with variants of CUS. CUS using euclidean
(CUS-Eucl), CUS with standardization using Euclidean(CUS-Stand-Eucl), CUS using
Soergel distance (CUS-Soergel), CUS with standardization using Soergel (CUS-Stand-
Soergel). Number of bins = 10.
Data Set Measure No
Sam-
pling
CUS-
Eucl10
CUS-
Stand-
Eucl10
CUS-
Soergel10
CUS-
stand-
Soergel10
Ecoli4 Sensitivity 0.65 0.85 0.83 0.80 0.92
Specificity 0.97 0.77 0.86 0.82 0.72
AUC 0.81 0.81 0.85 0.81 0.82
Haberman Sensitivity 0.28 0.64 0.54 0.54 0.48
Specificity 0.84 0.68 0.72 0.69 0.74
AUC 0.56 0.66 0.63 0.62 0.61
Iris0 Sensitivity 0.98 0.98 0.98 0.98 0.98
Specificity 1.00 1.00 1.00 1.00 1.00
AUC 0.99 0.99 0.99 0.99 0.99
NewThyroid1 Sensitivity 0.91 0.92 0.95 0.93 0.95
Specificity 0.98 0.92 0.93 0.93 0.92
AUC 0.95 0.92 0.94 0.93 0.93
Pima Sensitivity 0.59 0.72 0.74 0.71 0.74
Specificity 0.81 0.72 0.68 0.74 0.68
AUC 0.70 0.72 0.71 0.72 0.71
Vowel0 Sensitivity 0.94 0.93 0.96 0.97 0.95
Specificity 0.99 0.93 0.94 0.94 0.96
AUC 0.97 0.93 0.95 0.95 0.95
Yeast1289vs7 Sensitivity 0.23 0.67 0.63 0.62 0.6
Specificity 0.99 0.68 0.60 0.6 0.7
AUC 0.61 0.67 0.62 0.61 0.64
PageBlocks0 Sensivitiy 0.85 0.94 0.94 0.94 0.95
Specificity 0.98 0.94 0.95 0.94 0.93
AUC 0.92 0.94 0.95 0.94 0.94
Skin-Segmentation Sensitivity 0.99 0.99 0.99 0.99 0.99
Specificity 0.99 0.99 0.99 0.99 0.99
AUC 0.99 0.99 0.99 0.99 0.99
Shuttlec4vsall Sensitivity 0.99 0.99 0.99 0.99 0.99
Specificity 0.99 0.99 0.99 0.99 0.99
AUC 0.99 0.99 0.99 0.99 0.99
Segment0 Sensitivity 0.97 0.98 0.98 0.98 1.00
Specificity 0.99 0.98 0.98 0.98 0.98
AUC 0.98 0.99 0.98 0.98 0.98
Isolet5 Sensitivity 0.65 0.83 0.90 0.85 0.85
Specificity 0.98 0.83 0.89 0.88 0.87
AUC 0.82 0.83 0.90 0.87 0.85
LibrasMove Sensitivity 0.62 0.75 0.78 0.76 0.89
Specificity 0.97 0.78 0.77 0.77 0.76
AUC 0.80 0.77 0.78 0.77 0.82
Musk2 Sensitivity 0.86 0.92 0.92 0.93 0.92
Specificity 0.98 0.90 0.90 0.90 0.90
AUC 0.92 0.91 0.91 0.91 0.91
Scene Sensitivity 0.22 0.63 0.58 0.6 0.66
Specificity 0.94 0.63 0.63 0.63 0.65
AUC 0.58 0.63 0.62 0.62 0.66
Spectrometer Sensitivity 0.73 0.84 0.78 0.79 0.79
Specificity 0.98 0.91 0.86 0.89 0.94
AUC 0.86 0.89 0.82 0.84 0.86
17
Table 5: AUC results with kNN classifier with variants of CUS. CUS using euclidean
(CUS-Eucl), CUS with standardization using Euclidean(CUS-Stand-Eucl), CUS using
Soergel distance (CUS-Soergel), CUS with standardization using Soergel (CUS-Stand-
Soergel). Number of bins = 10.
Data Set Measure No
Sam-
pling
CUS-
Eucl10
CUS-
Stand-
Eucl10
CUS-
Soergel10
CUS-
stand-
Soergel10
Ecoli4 Sensitivity 0.75 0.94 0.91 0.93 0.97
Specificity 0.99 0.92 0.91 0.92 0.87
AUC 0.87 0.93 0.91 0.82 0.92
Haberman Sensitivity 0.34 0.53 0.51 0.56 0.55
Specificity 0.80 0.64 0.58 0.61 0.62
AUC 0.57 0.58 0.55 0.58 0.58
Iris0 Sensitivity 1.00 1.00 1.00 1.00 1.00
Specificity 1.00 1.00 1.00 1.00 1.00
AUC 1.00 1.00 1.00 1.00 1.00
NewThyroid1 Sensitivity 0.97 0.98 0.99 0.98 0.97
Specificity 0.98 0.95 0.95 0.97 0.98
AUC 0.97 0.96 0.97 0.98 0.97
Pima Sensitivity 0.52 0.59 0.65 0.65 0.65
Specificity 0.81 0.71 0.69 0.69 0.69
AUC 0.66 0.65 0.68 0.68 0.68
Vowel0 Sensitivity 1.00 1.00 1.00 1.00 1.00
Specificity 1.00 0.96 0.97 0.96 0.95
AUC 1.00 0.97 0.97 0.98 0.97
Yeast1289vs7 Sensitivity 0.13 0.7 0.7 0.7 0.74
Specificity 0.97 0.51 0.58 0.56 0.57
AUC 0.55 0.60 0.64 0.69 0.65
PageBlocks0 Sensivitiy 0.76 0.90 0.90 0.91 0.9
Specificity 0.98 0.92 0.92 0.92 0.92
AUC 0.87 0.91 0.91 0.92 0.91
Skin-Segmentation Sensitivity 0.99 0.99 0.99 0.99 0.99
Specificity 0.99 0.99 0.99 0.99 0.99
AUC 0.99 0.99 0.99 0.99 0.99
Shuttlec4vsall Sensitivity 0.99 0.99 0.99 1.0 1.0
Specificity 0.99 0.99 0.99 0.98 0.98
AUC 0.99 0.99 0.99 0.99 0.99
Segment0 Sensitivity 0.99 0.99 0.99 1.0 1.0
Specificity 0.99 0.99 0.99 0.98 0.98
AUC 0.99 0.99 0.99 0.99 0.99
LibrasMove Sensitivity 0.70 0.91 0.86 0.92 0.95
Specificity 0.99 0.93 0.95 0.91 0.92
AUC 0.85 0.92 0.91 0.92 0.94
Isolet5 Sensitivity 0.88 1.00 1.00 1.00 0.99
Specificity 0.99 0.81 0.81 0.79 0.79
AUC 0.94 0.91 0.91 0.89 0.89
Musk2 Sensitivity 0.87 0.96 0.96 0.96 0.96
Specificity 0.96 0.82 0.82 0.82 0.82
AUC 0.92 0.89 0.89 0.89 0.89
Scene Sensitivity 0.14 0.59 0.62 0.56 0.62
Specificity 0.95 0.72 0.69 0.69 0.69
AUC 0.55 0.65 0.66 0.63 0.66
Spectrometer Sensitivity 0.73 0.85 0.88 0.85 0.86
Specificity 0.99 0.95 0.96 0.94 0.96
AUC 0.86 0.9 0.92 0.89 0.91
18
Table 6: AUC results with C4.5 classifier with variants of CUS. CUS using euclidean
(CUS-Eucl), CUS with standardization using Euclidean(CUS-Stand-Eucl), CUS using
Soergel distance (CUS-Soergel), CUS with standardization using Soergel (CUS-Stand-
Soergel). Number of bins = 20.
Data Set Measure No
Sam-
pling
CUS-
Eucl20
CUS-
Stand-
Eucl20
CUS-
Soergel20
CUS-
stand-
Soergel20
Ecoli4 Sensitivity 0.65 0.82 0.75 0.86 0.87
Specificity 0.97 0.79 0.88 0.81 0.83
AUC 0.81 0.81 0.82 0.83 0.85
Haberman Sensitivity 0.28 0.55 0.59 0.53 0.51
Specificity 0.84 0.72 0.59 0.69 0.73
AUC 0.56 0.63 0.59 0.61 0.62
Iris0 Sensitivity 1.00 0.97 0.97 0.97 0.97
Specificity 1.00 1.00 1.00 1.00 1.00
AUC 1.00 0.98 0.98 0.98 0.98
NewThyroid1 Sensitivity 0.91 0.95 0.96 0.95 0.95
Specificity 0.98 0.92 0.92 0.92 0.92
AUC 0.95 0.94 0.94 0.94 0.94
Pima Sensitivity 0.59 0.75 0.72 0.72 0.74
Specificity 0.81 0.66 0.71 0.69 0.69
AUC 0.70 0.70 0.71 0.71 0.71
Vowel0 Sensitivity 0.94 0.95 0.96 0.96 0.96
Specificity 0.99 0.94 0.94 0.94 0.93
AUC 0.97 0.94 0.95 0.95 0.95
Yeast1289vs7 Sensitivity 0.23 0.78 0.75 0.61 0.68
Specificity 0.99 0.41 0.53 0.55 0.50
AUC 0.61 0.59 0.64 0.58 0.59
PageBlocks0 Sensivitiy 0.85 0.95 0.94 0.94 0.95
Specificity 0.98 0.93 0.94 0.94 0.94
AUC 0.92 0.94 0.94 0.94 0.94
Skin-Segmentation Sensitivity 0.99 0.99 0.99 0.99 0.99
Specificity 0.99 0.99 0.99 0.99 0.99
AUC 0.99 0.99 0.99 0.99 0.99
Shuttlec4vsall Sensitivity 0.99 0.99 0.99 0.99 0.99
Specificity 0.99 0.99 0.99 0.99 0.99
AUC 0.99 0.99 0.99 0.99 0.99
Segment0 Sensitivity 0.97 0.98 0.98 0.98 0.98
Specificity 0.99 0.98 0.98 0.98 0.97
AUC 0.98 0.98 0.98 0.98 0.98
Isolet5 Sensitivity 0.65 0.87 0.87 0.84 0.85
Specificity 0.98 0.87 0.88 0.89 0.89
AUC 0.82 0.87 0.87 0.87 0.87
LibrasMove Sensitivity 0.62 0.8 0.82 0.8 0.79
Specificity 0.97 0.76 0.81 0.78 0.76
AUC 0.80 0.78 0.82 0.79 0.77
Musk2 Sensitivity 0.86 0.92 0.93 0.91 0.93
Specificity 0.98 0.89 0.89 0.90 0.90
AUC 0.92 0.91 0.91 0.91 0.92
Scene Sensitivity 0.22 0.64 0.62 0.60 0.62
Specificity 0.94 0.61 0.62 0.64 0.62
AUC 0.58 0.62 0.62 0.62 0.62
Spectrometer Sensitivity 0.73 0.72 0.78 0.78 0.82
Specificity 0.98 0.84 0.85 0.85 0.86
AUC 0.86 0.78 0.81 0.82 0.84
19
Table 7: AUC results with kNN classifier with variants of CUS. CUS using euclidean
(CUS-Eucl), CUS with standardization using Euclidean(CUS-Stand-Eucl), CUS using
Soergel distance (CUS-Soergel), CUS with standardization using Soergel (CUS-Stand-
Soergel). Number of bins = 20.
Data Set Measure No
Sam-
pling
CUS-
Eucl20
CUS-
Stand-
Eucl20
CUS-
Soergel20
CUS-
stand-
Soergel20
Ecoli4 Sensitivity 0.75 0.94 0.88 0.98 1.00
Specificity 0.99 0.89 0.87 0.87 0.92
AUC 0.87 0.92 0.88 0.93 0.95
Haberman Sensitivity 0.34 0.55 0.59 0.53 0.51
Specificity 0.80 0.72 0.59 0.69 0.73
AUC 0.57 0.63 0.59 0.61 0.62
Iris0 Sensitivity 0.98 1.00 1.00 1.00 1.00
Specificity 1.00 1.00 1.00 1.00 1.00
AUC 0.99 1.00 1.00 1.00 1.00
NewThyroid1 Sensitivity 0.97 0.98 0.97 0.98 0.98
Specificity 0.98 0.97 0.96 0.96 0.96
AUC 0.97 0.98 0.96 0.97 0.97
Pima Sensitivity 0.52 0.64 0.65 0.66 0.66
Specificity 0.81 0.69 0.69 0.69 0.69
AUC 0.66 0.67 0.67 0.67 0.67
Vowel0 Sensitivity 1.00 1.00 1.00 1.00 1.00
Specificity 1.00 0.96 0.96 0.96 0.95
AUC 1.00 0.98 0.98 0.98 0.97
Yeast1289vs7 Sensitivity 0.13 0.76 0.74 0.7 0.68
Specificity 0.97 0.49 0.52 0.54 0.56
AUC 0.55 0.63 0.63 0.62 0.62
PageBlocks0 Sensitivity 0.76 0.89 0.90 0.89 0.90
Specificity 0.98 0.91 0.92 0.92 0.92
AUC 0.87 0.91 0.91 0.91 0.91
Skin-Segmentation Sensitivity 0.99 0.99 0.99 0.99 0.99
Specificity 0.99 0.99 0.99 0.99 0.99
AUC 0.99 0.99 0.99 0.99 0.99
Shuttlec4vsall Sensitivity 0.99 0.99 0.99 1.00 0.99
Specificit 0.99 0.99 0.99 0.99 0.99
AUC 0.99 0.99 0.99 0.99 0.99
Segment0 Sensitivity 0.99 0.99 0.99 0.99 0.99
Specificity 0.99 0.98 0.98 0.97 0.97
AUC 0.99 0.99 0.99 0.98 0.98
Isolet5 Sensitivity 0.88 1.00 0.98 0.99 0.99
Specificity 0.99 0.82 0.78 0.81 0.80
AUC 0.94 0.91 0.88 0.90 0.89
LibrasMove Sensitivity 0.70 0.96 0.92 0.95 0.93
Specificity 0.99 0.92 0.92 0.91 0.90
AUC 0.85 0.94 0.92 0.93 0.92
Musk2 Sensitivity 0.87 0.95 0.96 0.95 0.95
Specificity 0.96 0.82 0.82 0.82 0.82
AUC 0.92 0.89 0.89 0.88 0.89
Scene Sensitivity 0.14 0.59 0.63 0.63 0.61
Specificity 0.95 0.65 0.69 0.68 0.68
AUC 0.55 0.62 0.66 0.65 0.65
Spectrometer Sensitivity 0.73 0.85 0.85 0.85 0.86
Specificity 0.99 0.94 0.94 0.94 0.95
AUC 0.86 0.89 0.89 0.89 0.91
20
Table 8: AUC results with C4.5 classifier with variants of CUS. CUS using euclidean
(CUS-Eucl), CUS with standardization using Euclidean(CUS-Stand-Eucl), CUS using
Soergel distance (CUS-Soergel), CUS with standardization using Soergel (CUS-Stand-
Soergel). Number of bins = 5.
Data Set Measure No
Sam-
pling
CUS-
Eucl5
CUS-
Stand-
Eucl5
CUS-
Soergel5
CUS-
stand-
Soergel5
Ecoli4 Sensitivity 0.65 0.91 0.9 0.87 0.87
Specificity 0.97 0.83 0.86 0.83 0.88
AUC 0.81 0.87 0.88 0.85 0.88
Haberman Sensitivity 0.28 0.55 0.54 0.56 0.57
Specificity 0.84 0.66 0.73 0.71 0.71
AUC 0.56 0.61 0.63 0.63 0.64
Iris0 Sensitivity 0.98 0.97 0.97 0.97 0.97
Specificity 1.00 1.00 1.00 1.00 1.00
AUC 0.99 0.98 0.98 0.98 0.98
NewThyroid1 Sensitivity 0.86 0.93 0.94 0.93 0.92
Specificity 0.98 0.93 0.92 0.94 0.95
AUC 0.92 0.93 0.93 0.94 0.94
Pima Sensitivity 0.59 0.71 0.70 0.71 0.70
Specificity 0.81 0.71 0.70 0.71 0.71
AUC 0.70 0.71 0.70 0.71 0.71
Vowel0 Sensitivity 0.94 0.95 0.93 0.95 0.94
Specificity 0.99 0.94 0.93 0.94 0.94
AUC 0.97 0.94 0.93 0.95 0.94
Yeast1289vs7 Sensitivity 0.23 0.57 0.61 0.57 0.58
Specificity 0.99 0.69 0.53 0.55 0.73
AUC 0.61 0.63 0.57 0.56 0.66
PageBlocks0 Sensivitiy 0.85 0.95 0.95 0.95 0.95
Specificity 0.98 0.93 0.93 0.94 0.94
AUC 0.92 0.94 0.94 0.94 0.94
Skin-Segmentation Sensitivity 0.99 0.99 0.99 0.99 0.99
Specificity 0.99 0.99 0.99 0.99 0.99
AUC 0.99 0.99 0.99 0.99 0.99
Shuttlec4vsall Sensitivity 0.99 0.99 0.99 0.99 0.99
Specificity 0.99 0.99 0.99 0.99 0.99
AUC 0.99 0.99 0.99 0.99 0.99
Segment0 Sensitivity 0.97 0.98 0.98 0.98 0.98
Specificity 0.99 0.97 0.98 0.98 0.97
AUC 0.98 0.98 0.98 0.98 0.98
Isolet5 Sensitivity 0.65 0.89 0.85 0.87 0.87
Specificity 0.98 0.86 0.86 0.87 0.87
AUC 0.82 0.87 0.85 0.87 0.87
LibrasMove Sensitivity 0.62 0.73 0.83 0.76 0.81
Specificity 0.97 0.79 0.75 0.77 0.71
AUC 0.80 0.76 0.79 0.77 0.76
Musk2 Sensitivity 0.91 0.91 0.91 0.93 0.91
Specificity 0.98 0.89 0.90 0.89 0.89
AUC 0.95 0.90 0.91 0.91 0.91
Scene Sensitivity 0.22 0.64 0.61 0.59 0.58
Specificity 0.94 0.63 0.63 0.63 0.61
AUC 0.58 0.63 0.62 0.61 0.59
Spectrometer Sensitivity 0.73 0.78 0.82 0.81 0.81
Specificity 0.98 0.86 0.84 0.84 0.86
AUC 0.86 0.82 0.83 0.82 0.83
21
Table 9: AUC results with kNN classifier with variants of CUS. CUS using euclidean
(CUS-Eucl), CUS with standardization using Euclidean(CUS-Stand-Eucl), CUS using
Soergel distance (CUS-Soergel), CUS with standardization using Soergel (CUS-Stand-
Soergel). Number of bins = 5.
Data Set Measure No
Sam-
pling
CUS-
Eucl5
CUS-
Stand-
Eucl5
CUS-
Soergel5
CUS-
stand-
Soergel5
Ecoli4 Sensitivity 0.75 0.95 0.92 0.91 0.87
Specificity 0.99 0.90 0.91 0.91 0.88
AUC 0.87 0.93 0.91 0.91 0.88
Haberman Sensitivity 0.34 0.53 0.51 0.54 0.52
Specificity 0.80 0.59 0.60 0.60 0.58
AUC 0.57 0.56 0.56 0.57 0.55
Iris0 Sensitivity 1.00 1.00 1.00 1.00 1.00
Specificity 1.00 1.00 1.00 1.00 1.00
AUC 1.00 1.00 1.00 1.00 1.00
NewThyroid1 Sensitivity 0.97 0.97 0.98 0.98 0.98
Specificity 0.98 0.97 0.96 0.97 0.96
AUC 0.97 0.97 0.97 0.97 0.97
Pima Sensitivity 0.52 0.65 0.66 0.67 0.67
Specificity 0.81 0.70 0.68 0.71 0.69
AUC 0.66 0.68 0.67 0.69 0.68
Vowel0 Sensitivity 1.00 1.00 1.00 0.99 1.00
Specificity 1.00 0.95 0.96 0.96 0.95
AUC 1.00 0.97 0.98 0.98 0.98
Yeast1289vs7 Sensitivity 0.13 0.67 0.68 0.71 0.68
Specificity 0.97 0.58 0.57 0.59 0.59
AUC 0.55 0.62 0.63 0.65 0.64
PageBlocks0 Sensitivity 0.76 0.89 0.90 0.90 0.90
Specificity 0.98 0.92 0.92 0.92 0.92
AUC 0.87 0.90 0.91 0.91 0.91
Skin-Segmentation Sensitivity 0.99 0.99 0.99 0.99 0.99
Specificity 0.99 0.99 0.99 0.99 0.99
AUC 0.99 0.99 0.99 0.99 0.99
Shuttlec4vsall Sensitivity 0.99 0.99 0.99 0.99 0.99
Specificity 0.99 0.99 0.99 0.99 0.99
AUC 0.99 0.99 0.99 0.99 0.99
Segment0 Sensitivity 0.99 0.99 0.99 0.99 0.98
Specificity 0.99 0.97 0.98 0.97 0.97
AUC 0.99 0.98 0.98 0.98 0.98
Isolet5 Sensitivity 0.88 0.99 0.99 0.99 0.98
Specificity 0.99 0.83 0.80 0.81 0.81
AUC 0.94 0.91 0.90 0.90 0.89
LibrasMove Sensitivity 0.70 0.91 0.94 0.92 0.95
Specificity 0.99 0.91 0.93 0.90 0.92
AUC 0.85 0.91 0.93 0.91 0.94
Musk2 Sensitivity 0.87 0.95 0.95 0.96 0.95
Specificity 0.96 0.82 0.82 0.82 0.82
AUC 0.92 0.88 0.89 0.89 0.88
Scene Sensitivity 0.14 0.61 0.62 0.64 0.62
Specificity 0.95 0.66 0.68 0.67 0.66
AUC 0.55 0.63 0.62 0.65 0.64
Spectrometer Sensitivity 0.73 0.88 0.86 0.85 0.89
Specificity 0.99 0.95 0.94 0.93 0.95
AUC 0.86 0.91 0.90 0.89 0.92
22
Table 10: AUC results with C4.5 classifier with variants of QUS. QUS using euclidean
(QUS-Eucl), QUS with standardization using Euclidean(QUS-Stand-Eucl), QUS using
Soergel distance (QUS-Soergel), QUS with standardization using Soergel (QUS-Stand-
Soergel). Number of bins = (fixed because reference points are min,Q1,median,Q3,max).
Data Set Measure No
Sam-
pling
QUS-
Eucl
QUS-
Stand-
Eucl
QUS-
Soergel
QUS-
stand-
Soergel
Ecoli4 Sensitivity 0.65 0.89 0.9 0.85 0.87
Specificity 0.97 0.83 0.81 0.81 0.88
AUC 0.81 0.86 0.85 0.83 0.88
Haberman Sensitivity 0.28 0.51 0.54 0.57 0.51
Specificity 0.84 0.75 0.73 0.65 0.76
AUC 0.56 0.63 0.64 0.61 0.64
Iris0 Sensitivity 0.98 0.98 0.98 0.98 1.00
Specificity 1.00 1.00 1.00 1.00 1.00
AUC 0.99 0.99 0.99 0.99 1.00
NewThyroid1 Sensitivity 0.91 0.95 0.95 0.92 0.93
Specificity 0.98 0.93 0.92 0.91 0.93
AUC 0.95 0.94 0.93 0.91 0.93
Pima Sensitivity 0.59 0.72 0.75 0.72 0.7
Specificity 0.81 0.72 0.68 0.71 0.71
AUC 0.70 0.72 0.71 0.72 0.7
Vowel0 Sensitivity 0.94 0.96 0.95 0.95 0.94
Specificity 0.99 0.95 0.93 0.93 0.95
AUC 0.97 0.95 0.94 0.94 0.95
Yeast1289vs7 Sensitivity 0.23 0.56 0.60 0.50 0.52
Specificity 0.99 0.66 0.74 0.69 0.74
AUC 0.61 0.61 0.67 0.59 0.63
Isolet5 Sensitivity 0.65 0.85 0.89 0.89 0.84
Specificity 0.98 0.89 0.88 0.83 0.88
AUC 0.82 0.87 0.89 0.86 0.86
LibrasMove Sensitivity 0.62 0.81 0.75 0.8 0.75
Specificity 0.97 0.78 0.82 0.72 0.68
AUC 0.80 0.79 0.79 0.75 0.72
PageBlocks0 Sensitivity 0.85 0.95 0.95 0.95 0.95
Specificity 0.98 0.95 0.94 0.94 0.93
AUC 0.92 0.95 0.94 0.95 0.94
Skin-Segmentation Sensitivity 0.99 0.99 0.99 0.99 0.99
Specificity 0.99 0.98 0.98 0.99 0.99
AUC 0.99 0.99 0.99 0.99 0.99
Shuttlec4vsall Sensitivity 0.99 0.99 0.99 0.99 0.99
Specificity 0.99 0.98 0.98 0.99 0.99
AUC 0.99 0.99 0.99 0.99 0.99
Segment0 Sensitivity 0.97 0.98 0.98 0.98 0.98
Specificity 0.99 0.98 0.98 0.99 0.99
AUC 0.98 0.98 0.97 0.99 0.99
Musk2 Sensitivity 0.86 0.93 0.96 0.92 0.96
Specificity 0.98 0.89 0.83 0.90 0.82
AUC 0.92 0.92 0.90 0.91 0.89
Scene Sensitivity 0.22 0.64 0.66 0.61 0.63
Specificity 0.94 0.63 0.65 0.64 0.64
AUC 0.58 0.63 0.65 0.63 0.63
Spectrometer Sensitivity 0.73 0.79 0.82 0.61 0.63
Specificity 0.98 0.86 0.82 0.64 0.64
AUC 0.86 0.82 0.82 0.63 0.64
23
Table 11: AUC results with kNN classifier with variants of QUS. QUS using euclidean
(QUS-Eucl), QUS with standardization using Euclidean(QUS-Stand-Eucl), QUS using
Soergel distance (QUS-Soergel), QUS with standardization using Soergel (QUS-Stand-
Soergel). Number of bins = 5 (fixed because reference points are min,Q1,median,Q3,max).
Data Set Measure No
Sam-
pling
QUS-
Eucl
QUS-
Stand-
Eucl
QUS-
Soergel
QUS-
stand-
Soergel
Ecoli4 Sensitivity 0.75 0.96 0.9 0.93 0.97
Specificity 0.99 0.90 0.89 0.91 0.92
AUC 0.87 0.93 0.9 0.92 0.95
Haberman Sensitivity 0.34 0.48 0.54 0.52 0.53
Specificity 0.80 0.58 0.6 0.59 0.59
AUC 0.57 0.53 0.57 0.56 0.56
Iris0 Sensitivity 1.00 1.00 1.00 1.00 1.00
Specificity 1.00 1.00 1.00 1.00 1.00
AUC 1.00 1.00 1.00 1.00 1.00
NewThyroid1 Sensitivity 0.97 0.95 0.99 0.99 0.98
Specificity 0.98 0.93 0.97 0.98 0.97
AUC 0.97 0.94 0.98 0.98 0.98
Pima Sensitivity 0.52 0.67 0.66 0.66 0.65
Specificity 0.81 0.70 0.7 0.69 0.69
AUC 0.66 0.69 0.68 0.68 0.67
Vowel0 Sensitivity 1.00 1.00 1.00 1.0 1.0
Specificity 1.00 0.95 0.96 0.96 0.96
AUC 1.00 0.97 0.98 0.98 0.98
Yeast1289vs7 Sensitivity 0.13 0.72 0.72 0.69 0.66
Specificity 0.97 0.62 0.6 0.6 0.62
AUC 0.55 0.67 0.66 0.64 0.63
PageBlocks0 Sensivitiy 0.76 0.9 0.9 0.9 0.9
Specificity 0.98 0.92 0.92 0.92 0.92
AUC 0.87 0.91 0.91 0.91 0.92
Skin-Segmentation Sensitivity 0.99 0.99 0.99 0.99 0.99
Specificity 0.99 0.99 0.99 0.99 0.99
AUC 0.99 0.99 0.99 0.99 0.99
Shuttlec4vsall Sensitivity 0.99 0.99 0.99 0.99 0.99
Specificity 0.99 0.99 0.99 0.99 0.99
AUC 0.99 0.99 0.99 0.99 0.99
Segment0 Sensitivity 0.99 0.99 0.99 0.99 0.99
Specificity 0.99 0.98 0.98 0.97 0.97
AUC 0.99 0.99 0.99 0.98 0.98
Isolet5 Sensitivity 0.88 0.98 0.99 1.00 0.98
Specificity 0.99 0.81 0.80 0.81 0.85
AUC 0.94 0.89 0.90 0.90 0.9
LibrasMove Sensitivity 0.70 0.89 0.92 0.96 0.95
Specificity 0.99 0.93 0.91 0.9 0.89
AUC 0.85 0.91 0.91 0.93 0.92
Musk2 Sensitivity 0.87 0.93 0.93 0.92 0.92
Specificity 0.96 0.91 0.91 0.90 0.90
AUC 0.92 0.92 0.92 0.91 0.91
Scene Sensitivity 0.14 0.62 0.6 0.6 0.63
Specificity 0.95 0.69 0.67 0.7 0.69
AUC 0.55 0.66 0.63 0.65 0.66
Spectrometer Sensitivity 0.73 0.91 0.87 0.63 0.63
Specificity 0.99 0.94 0.95 0.68 0.69
AUC 0.86 0.93 0.91 0.65 0.66
24
Figure 4: Distribution of negatives(Blue-Original,Red-Selected) Ecoli4 in best of our meth-
ods with c4.5
Main aim of the pre-processing methods proposed here is to improve the ac-
curacy of prediction of the minority class. From the tables, 8, 9, 4, 5, 6, 7, 10, 11,
it is evident that all the variants of the proposed methods CUS and QUS improve
significantly the accuracy of the Minority class, that is, sensitivity. There is an
increase of sensitivity in all most all data sets except in a few where there is a
negligible difference.
Table 12: Comparison of AUC results with c4.5 classifier with variants of CUS. Number
of bins = 5,10,20
Data Set CUS-
Eucl5
CUS-
Eucl10
CUS-
Eucl20
CUS-
Stand-
Eucl5
CUS-
Stand-
Eucl10
CUS-
Stand-
Eucl20
CUS-
Soergel5
CUS-
Soergel10
CUS-
Soergel20
CUS-
Stand-
Soergel5
CUS-
Stand-
Soergel10
CUS-
Stand-
Soergel-
20
Ecoli4 0.87 0.81 0.81 0.88 0.85 0.82 0.85 0.81 0.83 0.88 0.82 0.85
Haberman 0.61 0.66 0.63 0.63 0.63 0.59 0.63 0.62 0.61 0.64 0.61 0.62
Iris0 0.98 0.99 0.98 0.98 0.99 0.98 0.98 0.99 0.98 0.98 0.99 0.98
NewThyroid1 0.93 0.92 0.94 0.93 0.94 0.94 0.94 0.93 0.94 0.94 0.93 0.94
Pima 0.71 0.72 0.70 0.70 0.71 0.71 0.71 0.72 0.71 0.71 0.71 0.71
Vowel0 0.94 0.93 0.94 0.93 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95
Yeast1289vs7 0.63 0.67 0.59 0.57 0.62 0.64 0.56 0.61 0.58 0.66 0.64 0.59
PageBlocks0 0.94 0.94 0.94 0.94 0.95 0.94 0.94 0.94 0.94 0.94 0.94 0.94
Skin Seg-
mentation
0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.83 0.99 0.99
ShuttleC4vsall 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99
Segment0 0.98 0.99 0.98 0.98 0.98 0.98 0.98 0.98 0.98 0.98 0.98 0.98
Isolet5 0.87 0.83 0.87 0.85 0.90 0.87 0.87 0.87 0.87 0.87 0.85 0.87
LibrasMove 0.76 0.77 0.78 0.79 0.78 0.82 0.77 0.77 0.79 0.76 0.82 0.77
Musk2 0.90 0.91 0.91 0.91 0.91 0.91 0.91 0.91 0.91 0.91 0.91 0.92
Scene 0.63 0.63 0.62 0.62 0.62 0.62 0.61 0.62 0.62 0.59 0.66 0.62
Spectrometer 0.82 0.89 0.78 0.83 0.82 0.81 0.82 0.84 0.82 0.94 0.86 0.84
25
Figure 5: Distribution of negatives (Blue-Original,Red-Selected) Yeast1289vs7 in best of
our methods with c4.5
Figure 6: Distribution of negatives(Blue-Original,Red-Selected) Haberman in best of our
methods with c4.5
26
Figure 7: Distribution of negatives (Blue-Original,Red-Selected) Ecoli4 in best of our
methods with kNN
Table 13: Comparison of AUC results with kNN classifier with variants of CUS. Number
of bins = 5,10,20
Data Set CUS-
Eucl5
CUS-
Eucl10
CUS-
Eucl20
CUS-
Stand-
Eucl5
CUS-
Stand-
Eucl10
CUS-
Stand-
Eucl20
CUS-
Soergel5
CUS-
Soergel10
CUS-
Soergel20
CUS-
Stand-
Soergel5
CUS-
Stand-
Soergel10
CUS-
Stand-
Soergel-
20
Ecoli4 0.93 0.93 0.92 0.91 0.91 0.88 0.91 0.92 0.93 0.88 0.95 0.95
Haberman 0.56 0.58 0.63 0.56 0.55 0.59 0.57 0.56 0.61 0.55 0.56 0.62
Iris0 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00
NewThyroid1 0.97 0.96 0.98 0.97 0.97 0.96 0.97 0.98 0.97 0.97 0.98 0.97
Pima 0.68 0.65 0.67 0.67 0.68 0.67 0.69 0.68 0.67 0.68 0.67 0.67
Vowel0 0.97 0.97 0.98 0.98 0.97 0.98 0.98 0.98 0.98 0.98 0.98 0.98
Yeast1289vs7 0.62 0.60 0.63 0.63 0.64 0.63 0.65 0.64 0.62 0.64 0.63 0.62
PageBlocks0 0.90 0.91 0.91 0.91 0.91 0.91 0.91 0.91 0.91 0.91 0.92 0.91
Skin -
Segmentation
0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99
ShuttleC4vsall 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99
Segment0 0.98 0.99 0.99 0.98 0.99 0.99 0.98 0.98 0.98 0.98 0.98 0.98
Isolet5 0.94 0.91 0.91 0.90 0.91 0.88 0.90 0.90 0.90 0.89 0.90 0.89
LibrasMove 0.91 0.92 0.94 0.93 0.91 0.92 0.91 0.92 0.93 0.94 0.92 0.92
Musk2 0.88 0.89 0.89 0.89 0.89 0.89 0.89 0.91 0.88 0.88 0.91 0.89
Scene 0.63 0.65 0.62 0.62 0.66 0.66 0.65 0.65 0.65 0.64 0.66 0.65
Spectrometer 0.91 0.9 0.89 0.90 0.92 0.89 0.89 0.84 0.89 0.92 0.86 0.91
Figures 5, 6, 4, 8, 9, 7 represent the distribution of samples over groups formed
by best of CUS with varying number of bins and QUS using c4.5 an kNN classifiers.
It is evident from the figures that the distribution of samples divided does not
change by changing the number of groups in the case of CUS. Only the number of
times samples are selected varies which does not have much effect on classification
results. The idea is to choose the samples by changing the distribution led to the
proposal of QUS which forms groups in different way and its difference from CUS
is clear from the plots. And also it is to be noted that in the plots, there is a lot of
difference in actual umber of negatives present in each group and chosen number of
negatives for training. Eventhough very few samples are chosen, except in dataset
27
Figure 8: Distribution of negatives (Blue-Original,Red-Selected) Yeast1289vs7 in best of
our methods with kNN
Figure 9: Distribution of negatives (Blue-Original,Red-Selected) Haberman in best of our
methods with kNN
28
Yeast1289vs7 where number of positives are only 30 and negatives are 917, there
is not much degradation in correctly classifying the negatives.
Extensive experimentation is conducted on CUS by changing the number of
bins, standardization of attributes, changing distance measures. Tables 12, 13
show the results of variants of CUS with c4.5 and kNN classifiers respectively.
It is evident from the results of tables 12, 13 that as long as there are sufficient
number(no fixed upper limit) of instances are used in training, even though the
imbalance ratio is high and number of attributes are more the classifiers perform
better. If the imbalance is high and the dataset is complex, the classifiers do not
perform well(Yeast1289vs7). Even though the dataset is small with lower number
of attributes and instances and if it is not complex, the classifier gives good results
irrespective of the methods that are applied(Iris0).
5. Discussion
In this section, comparison of the results obtained by the proposed methods
to other undersampling, oversampling and ensemble methods are presented.
5.1. Scalability
In order to know the scalability of the methods, experiments are conducted on
large data sets shuttlec4vsall with 58000 instances, 9 attributes and 5.51 IR, skin
segmentation with 2,45,057 instances, 3 attributes and IR 3.82. For both of them,
AUC is 0.99 using CUS and QUS methods. It is known that, the imbalance does
not affect the classification accuracy if there are sufficient number of instances for
training. This is proven with the above two large data sets. The other under-
sampling methods are taking a huge amount of time as compared to the proposed
pre-processing methods. For small and medium data sets, proposed methods and
the specified undersampling methods took almost the same time where as for large
data sets, proposed methods took few minutes and other undersampling methods
took hours together.
5.2. Friedman test for CUS and QUS methods using c4.5
Friedman test [43] is a non-parametric test which performs multiple compar-
isons and checks whether all the classification methods are equivalent or not. This
method gives ranks to all methods for each dataset separately. Rank 1 is given to
the best peforming method, rank 2 to the second best and so on. If there is a tie
in rank, average ranks are assigned. Average ranks of each method are computed
by summing up all the ranks given to a particular method for different data sets
and take an average over them. It then compares the average ranks of all these
methods. Null-hypothesis is that all the methods are equal. Rejection of this
29
Table 14: Average Rankings of the algorithms c4.5 CUS AUC comparison(Friedman).
Friedman statistic (distributed according to chi-square with 11 degrees of freedom):
7.459135. P-value computed by Friedman Test: 0.760777.
Algorithm Ranking
CUS-Eucl5 7.4062
CUS-Eucl10 5.7812
CUS-Eucl20 7.5312
CUS-Soergel5 6.9688
CUS-Soergel10 6.375
CUS-Soergel20 6.75
CUS-Stand-Eucl5 7.375
CUS-Stand-Eucl10 5.125
CUS-Stand-Eucl20 6.5938
CUS-Stand-Soergel5 6.125
CUS-Stand-Soergel10 5.875
CUS-Stand-Soergel20 6.0938
hypothesis signifies that there are considerable differences among the algorithms
under study. Tables 14, 15 provides the ranks obtained by the Friedman test for
the CUS variants usinf c4.5 classifier.
Table 15: Average Rankings of the algorithms QUS-c4.5(Friedman). Friedman statis-
tic (distributed according to chi-square with 3 degrees of freedom): 4.435714. P-value
computed by Friedman Test: 0.218097.
Algorithm Ranking
QUS-Eucl 2.0357
QUS-Stand-Eucl 2.3571
QUS-Soergel 3.0357
QUS-Stand-Soergel 2.5714
5.3. Friedman test for CUS and QUS methods using kNN
Friedman test conducted for CUS and QUS variants using kNN classifier are
given in tables 16, 17. Null hypothesis holds here, indicatiing that there is not
much dependence on the number of bins.
5.4. Comparison with Other Undersampling Methods
Proposed methods are compared with other undersampling methods like CNN,
CNNTL, CPM, SBC, OSS, RUS, TL which are popular among the under-
30
Table 16: Average Rankings of the CUS-kNN algorithms (Friedman). Friedman statis-
tic (distributed according to chi-square with 11 degrees of freedom): 5.120192. P-value
computed by Friedman Test: 0.925206.
Algorithm Ranking
CUS-Eucl5 7.5
CUS-Eucl10 6.9375
CUS-Eucl20 5.5
CUS-Soergel5 6.3438
CUS-Soergel10 6
CUS-Soergel20 6.7188
CUS-Stand-Eucl5 7
CUS-Stand-Eucl10 6.0312
CUS-Stand-Eucl20 6.9062
CUS-Stand-Soergel5 6.8125
CUS-Stand-Soergel10 5.5625
CUS-Stand-Soergel20 6.6875
Table 17: Average Rankings of the QUS-kNN algorithms (Friedman). Friedman statis-
tic (distributed according to chi-square with 3 degrees of freedom): 0.385714. P-value
computed by Friedman Test: 0.943178.
Algorithm Ranking
QUS-Eucl 2.4643
QUS-Stand-Eucl 2.3929
QUS-Soergel 2.6786
QUS-Stand-Soergel 2.4643
sampling methods in the literature. Many of these methods choose kNN classifier
to select the samples, whereas the proposed methods do not use any classifier to
choose the samples. The results from tables 18, 21 prove that the proposed meth-
ods outperform these methods in few data sets and obtain comparable results
with these methods in other remaining sets. In no case, the proposed methods
are proven to be inferior to all these existing popular undersampling methods.
Friedman tests provide lowest rank to QUS-Eucl and QUS-stand-Eucl among the
methods used with C4.5 and kNN. Even among these two, except for the three data
sets Haberman, Pageblocks0 and Pima, kNN is performing a better classification
than C4.5.
Even though the Friedman statistic is not able to accept the hypothesis that
there are any significant differences between the methods using different bins, it is
31
giving a strong indicator for the same statistic when used in the comparison of the
the best ranked centroid and quartile based methods and the other undersampling
methods. Tables 18 and 21 present the results obtained for the data sets using the
other undersampling techniques for both c4.5 and KNN classifiers respectively. In
order to determine, which method is the best among the undersampling methods
including the currently proposed methods using post-hoc method, it turns out that
the proposed methods are the best in both cases.
5.4.1. Comparison with Other Undersampling Methods using c4.5
Main result of the comparison with other undersampling methods is that the
other undersampling methods experience considerable delay in classifying as in the
the case of skin-segmentation. Whereas the bin based sampling has no issue in
performing the undersampling and classifying there upon.
Table 18: Comparison of AUC results of proposed methods with other undersampling
techniques using C4.5.(- indicate results not obtained even after 300 seconds)
Data set CNN
(1968)
CNNTL
(2004)
CPM
(2005)
SBC
(2006)
NCL
(2001)
OSS
(1997)
RUS
(2004)
TL
(1976)
CUS-
Stand-
Eucl10
QUS-
Eucl
Ecoli4 0.83 0.84 0.81 0.81 0.81 0.84 0.86 0.81 0.85 0.86
Haberman 0.63 0.59 0.61 0.57 0.63 0.64 0.61 0.63 0.63 0.63
Iris0 0.97 0.97 0.50 0.99 0.99 0.97 0.99 0.99 0.99 0.99
Newthryroid1 0.93 0.92 0.82 0.94 0.94 0.94 0.91 0.92 0.94 0.94
Pima 0.67 0.64 0.64 0.71 0.72 0.66 0.72 0.74 0.71 0.72
Vowel0 0.92 0.92 0.89 0.95 0.92 0.92 0.94 0.97 0.95 0.95
Yeast1289vs7 0.59 0.61 0.63 0.5 0.53 0.61 0.60 0.54 0.62 0.61
PageBlocks0 0.94 0.94 0.91 0.93 0.93 0.93 0.94 0.93 0.95 0.95
Skin-
segmentation
- - - - - - - - 0.99 0.99
Shuttlec4vsall 0.97 0.97 - - 0.99 - - - 0.99 0.99
Segment0 0.97 0.97 0.94 0.98 0.98 0.98 0.97 0.98 0.98 0.98
Isolet5 0.84 0.86 0.57 0.57 0.86 0.86 0.87 0.81 0.90 0.87
LibrasMove 0.84 0.77 0.70 0.50 0.78 0.79 0.73 0.83 0.78 0.79
Musk2 0.92 0.88 0.78 0.50 0.92 0.91 0.89 0.92 0.91 0.92
Scene 0.60 0.58 0.58 0.50 0.60 0.57 0.63 0.58 0.62 0.63
Spectrometer 0.81 0.79 0.83 0.62 0.85 0.81 0.85 0.87 0.82 0.82
In order to determine the best method among the undersampling methods
including the best of the proposed CUS and QUS methods, Friedman test followed
by Holm post-hoc tests are conducted. From Table 19 it is evident that the null
hypothesis can be rejected and there is differnce between the algorithms. Friedman
test ranks the QUS-Eucl as the best method among the undersampling methods.
Post-hoc test results in 20, indicates that the the null hypothesis can be rejected
for CPM and SBC and can not surmise about the other methods.
32
Table 19: Average Rankings of the algorithms (Friedman).Friedman statistic (distributed
according to chi-square with 9 degrees of freedom): 38.216883. P-value computed by
Friedman Test: 0.000016.
Algorithm Ranking
CNN 5.7143
CNNTL 7
CPM 8.2143
SBC 7.4286
NCL 5
OSS 5.6071
RUS 4.9286
TL 4.6429
CUS-Stand-Eucl10 3.3571
QUS-Eucl 3.1071
5.4.2. Comparison with Other Undersampling Methods using kNN
Various undersampling techniques are tested on the data sets and compared
with the best ranked CUS and QUS methods as shown in Table 21. Friedman test
results shown in Table 22 indicatesthat CUS-Eucl20 is the best among all. But,
post-hoc test results indicates that the proposed CUS-Eucl20 is better than CPM,
SBC and CNN and can not conclude about the other methods.
Tables 14 and 15 give the ranking of the methods considered separately for
centriod based and quartile based preprocessing using C4.5 and in Tables 16 and
17 using kNN. Friedman statistic is not rejecting the null hypothesis, hence it
cannot be said that the methods using diffrent bins may not be very significant.
Same arguement holds for centroid based and quartile based preprocessing using
KNN classifier also. But, the method given the best rank is chosen to compare
with the other methods.
As the proposed methods are undersampling methods, friedman test along
with Holm posthoc test are conducted and the results are seen in Tables 19, 20,
22, 23. From the tables it is understood that our proposed methods outperforms
the existing undersampling methods.
5.5. Comparison with Oversampling Methods
Best of the proposed methods are compared with a few popular oversampling
methods available in KEEL using c4.5 and kNN classifiers in tables 24, 25. Here
more cases are not providing results within 300 seconds. The reason could be
that oversampling needs to oversample the instances. Hence, there are more cases
where results are obtained within the 300 seconds time limit.
33
Table 20: Post Hoc comparison Table for α = 0.05 (FRIEDMAN) using QUS-Eucl as
the control method. Holm’s procedure rejects those hypotheses that have an unadjusted
p-value ≤ 0.008333.
i algorithm z = (R0 −Ri)/SE p Holm
9 CPM 4.462943 0.000008 0.005556
8 SBC 3.776336 0.000159 0.00625
7 CNNTL 3.401823 0.000669 0.007143
6 CNN 2.278285 0.02271 0.008333
5 OSS 2.184657 0.028914 0.01
4 NCL 1.654098 0.098108 0.0125
3 RUS 1.591679 0.111457 0.016667
2 TL 1.342004 0.179595 0.025
1 CUS-Stand-Eucl10 0.218466 0.827066 0.05
5.6. Comparison with Ensemble Methods
To know the performance of the proposed methods with respect to other meth-
ods of class imbalance viz., ensemble based, algorithm based and costsensitive
based, they are compared with each of them available in KEEL. Results shown
in the tables 26 prove that the proposed methods are not inferior to any of the
exisitng methods and are giving comparable results.
6. Conclusions
In this paper, two undersampling methods CUS, QUS are proposed to balance
the training set by choosing the samples from the majority class equal to the num-
ber of minority class samples. Most of the existing undersampling methods apply
either (a) prototype selection or (b) clustering techniques to balance the data set
which are parameter dependent and convergence is difficult. The proposed meth-
ods are simple and parameter independent. These are based on distribution
specific grouping, additionally, issues considered are: (i) Information loss and (ii)
Proper representation of the majority class. Information loss is handled by the way
groups are formed which allows the samples to be chosen throughout the majority
class without confining to any particular region. Representative samples problem
is addressed by employing stratified sampling strategy, which chooses the number
the samples from each cluster depending on its size, so that the samples chosen
represent the majority class as a whole. Most of the undersampling methods use
kNN classifier to choose majority class samples, but we do not use any classifier
thereby reducing computation involved in finding nearest neighbors as the size of
the data set increases. Do not depend on external parameters. Do not use any
specific clustering algorithm or classification algorithm in choosing majority class
34
Table 21: Comparison of AUC results of proposed methods with other undersampling
techniques using kNN. (- indicate results not obtained even after 300 seconds)
data set CNN
(1968)
CNNTL(2004)CPM
(2005)
SBC
(2006)
NCL
(2001)
OSS
(1997)
RUS
(2004)
TL(1976)CUS-
Eucl20
QUS-
Stand-
Eucl
Ecoli4 0.91 0.89 0.69 0.50 0.86 0.88 0.95 0.87 0.92 0.9
Haberman 0.54 0.56 0.53 0.59 0.57 0.53 0.62 0.58 0.63 0.57
Iris0 1.00 1.00 1.00 0.50 1.00 1.00 1.00 1.00 1.00 1.00
Newthryroid1 0.97 0.97 0.94 0.50 0.99 0.96 0.96 0.97 0.98 0.98
Pima 0.64 0.65 0.62 0.67 0.70 0.67 0.66 0.70 0.67 0.68
Vowel0 0.99 0.99 0.96 0.75 1.00 0.99 0.97 1.00 0.98 0.98
Yeast1289vs7 0.56 0.65 0.59 0.50 0.59 0.63 0.62 0.55 0.63 0.66
PageBlocks0 0.86 0.88 0.86 0.89 0.91 0.89 0.91 0.89 0.91 0.91
Skin-
segmentation
- - - - - - - - 0.99 0.99
Shuttlec4vsall - - - - - - - - 0.99 0.99
Segment0 0.99 0.99 0.97 0.50 0.99 0.99 0.98 0.99 0.99 0.99
Isolet5 0.97 0.96 0.87 0.56 0.94 0.96 0.89 0.94 0.91 0.90
LibrasMove 0.85 0.93 0.86 0.50 0.92 0.86 0.93 0.85 0.94 0.91
Musk2 0.88 0.83 0.88 0.50 0.83 0.87 0.88 0.83 0.89 0.92
Scene 0.58 0.59 0.56 0.50 0.61 0.60 0.65 0.58 0.62 0.63
Spectrometer 0.91 0.90 0.90 0.67 0.90 0.88 0.93 0.88 0.89 0.91
samples. Moreover, the methods are simple to implement and effective even for
high dimensional and large data sets.
A good insight is obtained by these methods. Unlike in kNN or clustering meth-
ods, CUS and QUS partitions the data set from a global perspective. Distribution
Specific Grouping of the data is a kind of annular spherical neighbourhood in the
case of Euclidean distance based methods. Hence, the probability of selecting the
samples from the annular neighbourhood is better compared to the clustering,
where, a local neighbourhood defines the clusters and there is a probability of
missing some disjuncts altogether. All the kNN based undersampling methods are
looking at a very small neighbourhood(K=1,3 or 5). This may introduce lot of
bias.
Empirical results also support the theory. Among all the variants of CUS and
QUS, CUS-Stand-Eucl, QUS-Eucl performed well with C4.5 classifier and CUS-
Stand-Soergel, QUS-Stand-Eucl gave better results with kNN Classifier. The ma-
jor advantage of our methods is that it is simple to implement hence consumes
less time as compared to other undersampling methods and that it is not depen-
dent on any of the input parameters and works well with data sets having large
instances, large features, small instances and small features as well. To the best
of our knowledge the kind of grouping that was used in the proposed methods has
not been used so far in undersampling to improve the classification of imbalanced
data sets.
35
Table 22: Average Rankings of the algorithms (Friedman). Friedman statistic (distributed
according to chi-square with 9 degrees of freedom): 27.201818.
P-value computed by Friedman Test: 0.001295.
Algorithm Ranking
CNN 5.55
CNNTL 5.25
CPM 8.45
SBC 8.4
NCL 4.3
OSS 5.3
RUS 5.15
TL 5.05
CUS-Eucl20 3.75
QUS-Stand-Eucl10 3.8
7. Bibliography
[1] T. Mitchell, Machine Learning, McGraw Hill, 1997.
[2] J. Han and M. Kamber ,Data Mining Concepts and Techniques, Morgan Kauf-
mann, Elsevier Edition, 2000.
[3] Nathalie Japkowicz, Learning from Imbalanced Data Sets: A Comparison of
Various Strategies, AAAI Technical Report WS-00-05, 2000,pp10-15.
[4] N. Japkowicz, S. Stephen, The class imbalance problem: a systematic study,
Intelligent Data Analysis Journal 6 (5) (2002) 429450.
[5] Maria Carolina Monard and Gustavo E.A.P.A. Batista, Learning with Skewed
Class Distributions, In Advances in Logic, Artificial Intelligence and Robotics,
2002, pp173180.
[6] R. Barandela, S. Sanchez, V. Garcia, E. Rangel, Strategies for learning in class
imbalance problems, Pattern Recognition, 36, 2003, pp849-851.
[7] Gustavo E.A.P.A. Batista, Ronaldo C. Prati, Maria Carolina Monard, A Study
of the Behavior of Several Methods for Balancing Machine Learning Training
Data, Sigkdd Explorations, Volume 6, Issue 1, 2004, 20-29.
[8] T. Jo, N. Japkowicz, Class imbalances versus small disjuncts, ACM SIGKDD
Explorations Newsletter 6 (1) (2004) 4049.
36
Table 23: Post Hoc comparison Table for α = 0.05 (FRIEDMAN) using CUS-Eucl20 as
the control method. Holm’s procedure rejects those hypotheses that have an unadjusted
p-value ≤ 0.007143.
i algorithm z = (R0 −Ri)/SE p Holm
9 CPM 3.47118 0.000518 0.005556
8 SBC 3.434253 0.000594 0.00625
7 CNN 1.329388 0.18372 0.007143
6 OSS 1.144751 0.252312 0.008333
5 CNNTL 1.107823 0.267938 0.01
4 RUS 1.033969 0.301151 0.0125
3 TL 0.960114 0.336998 0.016667
2 NCL 0.406202 0.684594 0.025
1 QUS-Stand-Eucl10 0.036927 0.970543 0.05
[9] Nitesh V. Chawla, Data Mining for Imbalanced Datasets: an Overview, Chap-
ter 40, Data Mining and Knowledge Discovery Handbook, 2004, pp853-867.
[10] Sofia Visa, Anca Ralescu, Issues in Mining Imbalanced Data Sets - A Review
Paper, Proceedings of the Sixteen Midwest Artificial Intelligence and Cognitive
Science Conference, MAICS-2005, Dayton, 2005, 67-73.
[11] V. Garcia, J.S. Sanchez, R.A. Mollineda, R. Alejo, J.M.Sotoca, The class
imbalance problem in pattern classification and learning, ISBN: 978-84-9732-
602-5, 2007, pp283-291.
[12] Xinjian Guo, Yilong Yin, Cailing Dong, Gongping Yang, Guangtong Zhou,
On the Class Imbalance Problem, Fourth International Conference on Natural
Computation, IEEE Computer Society, 2008, 192-200.
[13] Yanmin Sun, Andrew K.C. Wong, Mohamed S. Kamel, Classification of Im-
balanced Data:A Review, International Journal of Pattern Recognition and
Artificial Intelligence, Volume 23, Issue 04,June 2009, 687-719.
[14] Giang Hoang Nguyen, Abdesselam Bouzerdoum and Son Lam Phung, Learn-
ing Pattern Classification Tasks with Imbalanced Data Sets, Pattern Recogni-
tion, 2009, 193-208.
[15] Haibo He, Garcia E.A, Learning from Imbalanced Data, IEEE Transactions
on Knowledge and Data Engineering, Volume:21 , Issue: 9 , 2009, 1263 - 1284.
[16] D. Ramyachitra, P. Manikandan, Imbalanced Dataset Classification and So-
lutions: A Review, International Journal of Computing and Business Research
(IJCBR), Volume 5 Issue 4 July 2014.
37
Table 24: Comparison of AUC results of proposed methods with other OverSampling
techniques using C4.5. (- indicate results not obtained even after 300 seconds)
Data set ADASYN
(2008)
ADOMS
(2008)
Borderline-
SMOTE
(2005)
ROS
(2004)
SafeLevel-
SMOTE
(2009)
SMOTE-
TL
(2004)
SMOTE
(2002)
CUS-
Stand-
Eucl10
QUS-
Eucl
Ecoli4 0.87 0.90 0.84 0.84 0.89 0.87 0.95 0.85 0.86
Haberman 0.63 0.59 0.61 0.55 0.63 0.59 0.63 0.63 0.63
Iris0 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99
Newthryroid1 0.95 0.95 0.96 0.96 0.95 0.95 0.93 0.94 0.94
Pima 0.69 0.73 0.72 0.69 0.73 0.72 0.74 0.71 0.72
Vowel0 0.96 0.98 0.97 0.95 0.95 0.98 0.97 0.95 0.95
Yeast1289vs7 0.68 0.66 0.54 0.66 0.64 0.58 0.67 0.62 0.61
PageBlocks0 0.93 0.94 0.93 0.93 0.90 0.94 0.93 0.95 0.95
Skin-
segmentation
- - - - - - - 0.99 0.99
Shuttlec4vsall - - - - - - 0.99 0.99
Segment0 0.98 0.99 0.98 0.99 0.98 0.98 0.98 0.98 0.98
Isolet5 0.82 - 0.88 0.84 - 0.89 0.86 0.90 0.87
LibrasMove 0.76 0.87 0.89 0.82 0.83 0.83 0.85 0.78 0.77
Musk2 - - - - - 0.92 - 0.91 0.92
Scene - - - - - - - 0.62 0.63
Spectrometer 0.90 0.87 0.83 0.85 0.86 0.86 - 0.82 0.82
[17] Mohamed Bekkar, Taklit Akrouf Alitouche, Imbalanced Data Learning Ap-
proaches Review, International Journal of Data Mining & Knowledge Manage-
ment Process (IJDKP), Vol.3, No.4, July 2013 , 15-33.
[18] Sotiris Kotisiantis Dimitris Kanellopoulos, Panayiotis Pintetas, Handling Im-
balanced Datasets: A Review, GESTS International Transactions on Computer
Science and Engineering, Volume 30, 2006.
[19] S.Jayasree and A.Alice Gavya, Addressing imbalance problem in the class
A survey, International Journal of Application or Innovation in Engineering
& Management(IJAIEM), ISSN 2319-4847, Volume 03, Issue 09, September
2014, 239-243.
[20] C.V. Krishna Veni, T. Sobha Rani, On the Classification of Imbalanced
Datasets, International Journal of Computer Science and Technology(IJCST),
volume 2, Spl, December 2011, 145-148.
[21] P.E.Hart, The Condensed Nearest Neighbor Rule, IEEE Transactions on In-
formation Theory, IT-4, 1968, 515-516,
[22] M.Kubat and S. Matwin, Addressing the curse of imbalanced training sets:
One Sided Selection, In Proceedings of the Fourteenth International Conference
on Machine Learning, Nashville, Tennesse, Morgan Kaufmann, 179-186, 1997.
38
Table 25: Comparison of AUC results of proposed methods with other OverSampling
techniques using kNN. (- indicate results not obtained even after 300 seconds)
Data set ADASYN
(2008)
ADOMS
(2008)
Borderline-
SMOTE
(2005)
ROS
(2004)
SafeLevel-
SMOTE
(2009)
SMOTE-
TL
(2004)
SMOTE
(2002)
CUS-
Eucl-20
QUS-
Stand-
Eucl
Ecoli4 0.90 0.91 0.89 0.87 0.87 0.92 0.93 0.92 0.9
Haberman 0.54 0.57 0.58 0.54 0.54 0.59 0.58 0.63 0.57
Iris0 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00
Newthryroid1 0.97 0.97 0.97 0.97 0.97 0.97 0.95 0.98 0.98
Pima 0.67 0.67 0.67 0.66 0.66 0.72 0.66 0.67 0.68
Vowel0 0.99 1.00 1.00 1.00 1.00 0.99 0.99 0.98 0.98
Yeast1289vs7 0.60 0.58 0.59 0.55 0.55 0.63 0.60 0.63 0.66
PageBlocks0 0.89 0.92 0.91 0.87 0.86 0.91 0.91 0.91 0.91
Skin-
segmentation
- - - - - - - 0.99 0.99
Shuttlec4vsall - - - - - - - 0.99 0.99
Segment0 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99
Isolet5 0.96 - 0.98 0.94 0.79 0.98 0.97 0.91 0.90
LibrasMove - - - - - - 0.91 0.94 0.91
Musk2 0.92 - - 0.92 0.91 - 0.91 0.89 0.92
Scene - - - - - - - 0.62 0.63
Spectrometer - - - - - - - 0.89 0.91
[23] I.Tomek, Two Modifications of CNN, IEEE Transactions on Systems Man
and Communications SMC-6, 769-772, 1976.
[24] Show Jane Yen and Yue Shi Lee , Cluster-based under-sampling approaches
to imbalanced data distributions, Expert Systems with Applications, 36, 5718-
5727, 2009.
[25] J. Laurikkala, Improving Identification of Difficult Small Classes by Balancing
Class Distribution, Technical Report, A-2001-2, University of Tampere, 2001.
[26] N.V. Chawla, A. Lazarevic, L.O.Hall, W.P. Kegelmeyer, SMOTE: synthetic
minority over-sampling technique, Applied Intelligence 36(3) 664-684, 2012.
[27] H. Han, W.Y. Wang, B.H. Mao, Borderline-SMOTE: a new over-sampling
method in imbalanced data sets learning, International Conference on Intelli-
gent Computing(ICIC), Lecture Notes in Computer Science, vol 3644, 878-887,
2005.
[28] C. Bunkhumpornpat, K. Sinapiromsaran C. Lursinsap, Safe-level-SMOTE:
Safe-level-synthetic minority over-sampling TEchnique for handling the class
imbalanced problem, Procedings of the 13th Pacific Asia Conference on Ad-
vances in Knowledge Discovery and Data Mining PAKDD’09, 475-482, 2009.
39
Table 26: Comparison of AUC results of proposed methods with some Ensemble Meth-
ods, Cost Sensitive and Algorithm based Methods. (- indicate results not obtained
even after 300 seconds)
Data set Balance
Cas-
cade
(2009)
Easy
En-
semble
(2009)
AdaC2
(2007)
CSVMCS
(2009)
C45CS
(2002)
NNCS
(2006)
CUS-
Stand-
Eucl10-
c4.5
QUS-
Eucl-
c4.5
CUS-
Eucl20-
kNN
QUS-
Stand-
Eucl-
kNN
Ecoli4 0.84 0.85 0.92 0.95 0.86 0.87 0.85 0.86 0.92 0.90
Haberman 0.61 0.65 0.56 0.61 0.57 0.62 0.63 0.63 0.63 0.57
Iris0 0.99 0.99 0.99 1.00 0.99 1.00 0.99 0.99 1.00 1.00
Newthryroid1 0.93 0.93 0.94 0.98 0.97 0.82 0.94 0.94 0.98 0.98
Pima 0.69 0.73 0.70 0.74 0.71 0.69 0.71 0.72 0.67 0.68
Vowel0 0.94 0.94 - 0.97 0.94 0.68 0.95 0.95 0.98 0.98
Yeast1289vs7 0.65 0.65 0.63 - 0.67 0.51 0.62 0.61 0.63 0.66
PageBlocks0 0.95 0.95 0.88 - 0.94 0.76 0.95 0.95 0.91 0.91
Skin-
segmentation
- - - - - 0.85 0.99 0.99 0.99 0.99
Shuttlec4vsall - - - - - - 0.99 0.99 0.99 0.99
Segment0 0.98 0.98 0.98 0.99 0.99 0.50 0.98 0.98 0.99 0.99
Isolet5 - - - - - 0.50 0.90 0.87 0.91 0.90
LibrasMove - - - - - 0.50 0.81 0.77 0.94 0.89
Musk2 - - - - - 0.57 0.91 0.92 0.89 0.92
Scene - - - - - - 0.62 0.63 0.62 0.63
Spectrometer - - - - - - 0.82 0.82 0.89 0.91
[29] H.He, Y. Bai, E.A. Garcia, S. Li, ADASYN: adaptive synthetic sampling
approach for imbalanced learning: Proceedings of the IEEE International Joint
Conference on Neural Networks(IJCNN’08), 1322-1328, 2008.
[30] D.R. Wilson, T.R. Martinez, Reduction Techniques for Instance-Based Learn-
ing Algorithms, Machine Learning, 38, 2000, 257-286.
[31] Kihoon Yoon, Stephen Kwek, An Unsupervised Learning Approach to Resolv-
ing the Data Imbalance Issue in Supervised Learning Problems in Functional
Genomics, Hybrid Fifth International Conference onIntelligent Systems,HIS
’05,2005.
[32] Rushi Longadge, Snehlata S. Dongre, Latesh Malik, Multi-Cluster Based Ap-
proach for skewed Data in Data Mining, IOSR-JCE,Volume 12, Issue 6, 66-73,
2013.
[33] Parinaz Sobhani, Herna Viktor, Stan Matwin, Learning from imbalanced data
using ensemble methods and cluster-based undersampling, Workshop on New
Frontiers in Mining Patterns, European Conference on Machine Learning and
Principles and Practice of Knowledge Discovery in Databases (ECML PKDD
2014).
40
[34] M. Mostafizur Rahman and D.N. Davis, Cluster Based Under-Sampling for
Unbalanced Cardiovascular Data, Proceedings of the World Congress on En-
gineering 2013 Vol III.
[35] Sung-Hyuk Cha, Comprehensive Survey on Distance/Similarity Measures be-
tween Probability Density Functions, International Journal of Mathematical
Models and Methods in Applied Sciences, 1, Issue 4, 300-307, 2007.
[36] C.Y.Wang, L.L.Hu, M.Z. Guo, X.Y.Liu and Q.Zou, imDC:an ensemble learn-
ing method for imbalanced classification with miRNA data, Genetics and
Molecular Research(GMR), Online Journal 14(1), 123-133, 2015.
[37] Shu Zhang, Samira Sadaoui and Malek Mauhoub, An Empirical Analy-
sis of Imbalanced Data Classification, Computer and Information Science,
Vol.8,No.1,2015.
[38] Cigdem Beyan, Robert Fisher, Classifying imbalanced data sets using simi-
larity based hierarchical decomposition, Pattern Recognition, Volume 48, Issue
5, 1653-1672, May 2015.
[39] Wing W.Y. Ng, Junjie Hu, Daniel S. Yeung, Shaohua Yin, Fabio Roli, Di-
versified sensitivity-based undersampling for imbalance classification problems,
IEEE Transaction on Cybernetics, 2014.
[40] Victor H Barella, Eduardo P Costa and Andre C P L F Carvalho, ClusterOSS:
a new undersampling method for imbalanced learning, 2014.
[41] M. Mostafizur Rahman and D.N. Davis, Addressing the Class Imbalance
Problem in Medical Datasets, International Journal of Machine Learning and
Computing, Vol.3 No.2, April 2013.
[42] M. Manjula, T. Seeniselvi, Ensembles of First Order logical Decision Trees
for Imbalanced Classification Problems, International Journal of Innovative
Research in Computer and Communication Engineering, Volume 3, Issue 1,
January 2015.
[43] Salvador Garcia, Alberto Fernandez, Alicia D. Benitez, Francisco Herrera,
Statistical Comparisons by Means of Non-Parametric Tests: A Case Study on
Genetic Based Machine Learning, II Congreso Espanol de Informatica, pp95-
104,2007.
[44] Saleh Alshomrani, Abdullah Bawakid, Seong.O.Shim, Alberto Fernandez,
Francisco Herrera, A Proposal for evolutionary fuzzy systems using feature
41
weighting: Dealing with Overlapping in imbalanced datasets. Knowledge-
Based Systems Vol.73:pp1-17,2015.
[45] Jose-Francisco, Diez-Pastor, Juan J. Rodriguez, Cesar Garcia-Osorio, Lud-
mila, I. Kuncheva, Random Balance : Ensembles of variable priors classifiers
for imbalanced data,Knowledge Based Systems, Vol.85, pp96-111, 2015.
[46] Zhongbin Sun, Qinbao Song, Xiayon Zhu, Heli Sun, Baowen Xu, Yuming
Zhou, A Novel Ensemble method for classifying imbalanced data, Pattern
Recognition, Vol.48, No.5, pp1623-1637,2015.
[47] Jerzy Blaszczynski, Jerzy Stefonowski, Neighbourhood sampling in bagging
for imbalanced data, NeuroComputing, Vol.150, pp529-542,2015.
[48] UCI Machine learning repository.
[49] KEEL data set. http://sci2s.ugr.es/keel
[50] http://www.cs.waikato.ac.nz/ml/weka/.
42



























