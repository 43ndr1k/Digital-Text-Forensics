Expert Systems with Applications 36 (2009) 4321–4330Contents lists available at ScienceDirect
Expert Systems with Applications
journal homepage: www.elsevier .com/locate /eswaBehavior-based spam detection using a hybrid method of rule-based techniques
and neural networks
Chih-Hung Wu *
Department of Electrical Engineering, National University of Kaohsiung, Kaohsiung, Taiwana r t i c l e i n f o
Keywords:
Spam filtering
Classification
Back-propagation neural networks
Rule-based reasoning
Machine-learning0957-4174/$ - see front matter  2008 Elsevier Ltd. A
doi:10.1016/j.eswa.2008.03.002
* Tel.: +886 7 5919446; fax: +886 7 5919374.
E-mail address: johnw@nuk.edu.tw
URL: http://www.johnw.idv.tw.a b s t r a c t
Earlier methods on spam filtering usually compare the contents of emails against specific keywords,
which are not robust as the spammers frequently change the terms used in emails. This paper presents
a hybrid method of rule-based processing and back-propagation neural networks for spam filtering.
Instead of using keywords, this study utilize the spamming behaviors as features for describing emails.
A rule-based process is first employed to identify and digitize the spamming behaviors observed from
the headers and syslogs of emails. An enhanced BPNN with a weighted learning strategy is designed as
the classification mechanism. Since spamming behaviors are infrequently changed, compared with that
of keywords used in spams, the proposed method is more robust with respect to the change of time. The
experimental results show that the proposed method is useful in identifying spam emails.
 2008 Elsevier Ltd. All rights reserved.1. Introduction
With the popularity of the Internet, the inundation of unsolic-
ited commercial emails, or spam, is an emerging problem. Anti-
spam by determining whether or not an incoming email is spam
has become an important problem. Various techniques for auto-
matically detecting or filtering spam emails have been proposed.
Many practical applications rely on building comprehensive dat-
abases for blocking emails whose addresses have been reported
as black-lists or whose message bodies contain specific words or
phrases defined as threatening terms. Among the others, ma-
chine-learning based techniques for context investigation receive
a lot of attentions. Such machine-learning based methods con-
struct rules or models with weighted scoring about the positions,
frequencies and context associations of terms or phrases used in
spam and estimate the likelihood that an incoming email is spam
or ham accordingly. Methods based on such context filtering, or
keyword-based filtering, are effective, if keywords are explicitly gi-
ven. However, spammers usually attempt to make their messages
as indistinguishable from legitimate email as possible and change
the patterns of spam to foil the filters. Some spams are tailored
by sophisticated programs to make them like normal messages
which may not contain any specific keywords. From the point of
view of machine-learning, the key to success of applying ma-
chine-learning based methods is the correctness of features whichll rights reserved.can precisely describe the training samples. However, with the
limited spam corpus and the changes of email keywords, conven-
tional approaches may not be able to precisely capture the charac-
teristics of spam. Clearly, keyword-based filtering is a workable but
limited approach for detecting spam. By observing the behaviors of
spammers, we found that spam emails are generated and delivered
according to some specific ‘‘spamming behaviors”. For example,
spam emails are sent with anonymous or forged user names, for-
warded by illegal permission or accounts, delivered with a bunch
of the same message repeatedly and unauthorizedly to many dif-
ferent recipients, and so on. Using specific keywords is only a class
of these behaviors. Although, spam emails are changing their forms
(Hall, 2000), human beings can easily recognize them no matter
how they are generated (for example, image spam) and distrib-
uted. Spam filtering according to the concept of spamming behav-
iors is first presented in Tseng and Wu (2003) which claims that
such behaviors can be used for identifying spams since they have
better resistance with respect to the change of time. In this paper,
a back-propagation neural network is designed and implemented
for spam classification. Emails to be investigated by the neural net-
work are described in terms of their spamming behaviors, not key-
words them contains. The spamming behaviors of emails are first
identified by a rule-based pre-processor. Next, the identified fea-
tures are encoded as three-valued vectors and processed by the
proposed neural network. Since spamming behaviors change inac-
tively, in comparison with the changing frequency of keywords, so
that classification of spams using behavior-based features may be
more robust than keyword-based methods. Experimental results
show that spam classification using behavior-based features is
more robust.
4322 C.-H. Wu / Expert Systems with Applications 36 (2009) 4321–4330The rest of the paper is organized as follows. Section 2 pre-
sents several typical methods of anti-spamming. Section 3 gives
a brief description on the features for spam classification and the
concept of spamming behaviors of emails. Section 4 presents a
rule-based method for instantiating behavior-based features into
discrete values. In Section 5 we present the design and imple-
mentation of back-propagation neural networks for spam classi-
fication using behavior-based features. The experimental results
are presented in Section 6. Finally, we conclude this study in
Section 7.2. Related work
In most machine-learning based methods, filtering models
using keyword-base features is intuitive since they are easier to
implement. Commonly used learning techniques include decision
trees (Crawford, Kay, & McCreath, 2001), case-based reasoning
(Delany, Cunningham, Doyle, & Zamolotskikh, 2005; Mendez,
Fdez-Riverola, Iglesias, Diaz, & Corchado, 2006), support vector
machine (SVM) (Camastra, 2005; Wang, Yu, & Liu, 2005), artificial
immune systems (Bezerra1et al., Wang, You, & Man, 2006; Wang
et al., 2006), and boosting method Schapire and Singer (2000).
Here are some examples. Bayesian-based spam filtering computes
the probability that an email is spam based upon previous fea-
ture frequencies in spam and ham (Androutsopoulos, Koutsias,
Chandrinos, & Spyropoulos, 2000; Graham, 2003; Wang, Hori, &
Sakurai, 2006). Katirai (1999) employs genetic programming
(GP) and Naı̈ve Bayesian (NB) to filter out spam e-mails. The re-
sults demonstrate that NB slightly outperforms GP. Sakkis, And-
routsopoulos, Paliouras, and Stamatopoulos (2003) develop a
memory-based approach and claim that it outperforms NB meth-
ods. Brutlag and Meek (2000) compared SVM, TF-IDF, and uni-
gram model in general e-mail classification. Diao, Lu, and Wu
(2000) compare NB with decision trees in classification-based
personal e-mail filtering. Applying neural networks for filtering
spam e-mails is also studied in Clark, Koprinska, and Poon
(2003), which produces a very good training accuracy. In Wang,
Jones, and Pan (2006), two linear classifiers, Perceptron and Win-
now, are integrated for spam filtering. A Hybrid method which
combines neural networks and genetic algorithms for feature
selection is presented in Gavrilis, Tsoulos, and Dermatas (2006)
for robust detection of spam. Unfortunately, they do not give
impressive results on practical tests. Also using keyword-based
exploration, the concept drill problem is studied for filtering
spam emails in Fdez-Riverola, Iglesias, Díaz, Méndez, and Corch-
ado (2007), wherein lazy learning algorithms are applied to select
relevant terms and the representative emails associated with the
terms. The filtering method presented in Jiang (2006) applies the
techniques of Latent semantic indexing and singular value
decomposition to transform emails into statistically semantic
vectors and classify them accordingly. A content-based mining
method for author identification of e-mails is proposed in de
Vel, Anderson, Corney, and Mohay (2001), where structural char-
acteristics and linguistic patterns are analyzed. Yue, Abraham,
Chi, Hao, and Mo (2007) employ ‘‘behavior-based” features in
an artificial immune system for spam filtering. The features they
used focus on the sender’s IP addresses recorded in the MX re-
cord. Zhang, Liu, Zhang, and Wang (2006) present in a method
for recognizing spam behaviors using decision trees learned from
data maintained during transfer sessions. However, the so-called
behaviors they defined are not the same as what we defined in
this paper. More comparative studies on spam filtering tech-
niques are available at Blanzieri and Bryl (2006), Hoanca
(2006), Lai and Tsai (2004), Webb et al. (2005).3. Behavior-based features
3.1. Spamming behaviors
A spam is generally recognized as an electronic message in
which the recipient’s personal identity and context are irrelevant
because the message is equally applicable to many other potential
recipients; and the recipient has not verifiably granted deliberate,
explicit, and still-revocable permission for it to be sent; and the
transmission and reception of the message appears to the recipient
to give a disproportionate benefit to the sender (MAPS, 2003). The
objective of sending spams is to sell products or services to the cus-
tomers available on the Internet. For this purpose, spams are mas-
sively and repeatedly dispatched in order to broadly contact
potential customers. However, in order not to be detected, spams
are elaborately pretended as hams. The so-called spamming behav-
ior is a pretending trick that spammers use for composing or deliv-
ering a spam for specific purposes. For example, in order to bypass
spam filters, spambots fill the subject line with randomly gener-
ated characters and make the subject irrelevant to the message
body. To hide the origin of spams, routing addresses or returning
address are forged or invalid. Spams are massively sent to desig-
nated addresses which are collected manually by the spammer
or automatically by spambots. Moreover, spams are usually deliv-
ered at non-office hours, such as 02:00 AM–06:00 AM, because of
larger bandwidth available and lower risk to be coped. Unlike find-
ing keyword-based features that can be extracted directly from the
contents of emails, formatting behavior-based features for emails
has more difficulty in direct extraction. Fortunately, they can be
partially obtained from the transmission information associated
with emails. Let us recall the process of delivering emails. Internet
users usually compose or read emails using mail user agents
(MUAs) which connect to mail servers. A mail transfer agent
(MTA) is installed on the mail server for delivering emails and com-
municating with MUAs. Emails received by MTA are retained in a
temporary file called mailbox until being downloaded by the recip-
ients. Regarding to the structure of an email, the header is a piece of
structured messages stating the organization and destination of
the mail. Some of the information in the header can be given by
the sender manually; some by MUA automatically. MTA delivers
an email according to its header information. When an email is
delivered by MTA, a record describing this delivery is added to
an auditing file, referred to as syslog. Unlike the header parts, sys-
logs are generated by MTA and are not modifiable by users or MTA.
Each record in an email’s header or syslog consists of several
‘‘fields” each of which describes a piece of information related to
the email. Emails transmitted with different communication proto-
cols may have different formats in constructing headers and sys-
logs. Throughout this paper, we explore emails delivered by
Simple Mail Transfer Protocol (SMTP) and sendmail in BSD 4.4 for-
mat. The readers may refer to Costales and Allman (2002) for more
details. Fig. 1a and b present sample headers and syslogs of emails,
where ‘‘From:”, ‘‘Reply-To:”, etc., are fields in the header and
‘‘daemon”, ‘‘nrcpts”, etc., are fields in the syslog. Spamming
behaviors like forging messages, late or massively delivering, and
the ones that cause inconsistency in the email messages are obser-
vable from headers and syslogs. The concept of spamming behav-
iors is first presented in Tseng and Wu (2003) which claims that
such behaviors can be used for identifying spams since they have
better resistance with respect to the change of time. In most cases,
normal emails (or hams) are composed and delivered with valid
and real transmission information. Conversely, the information
associated with spams may contain inconsistent or abnormal
information from which may reveal the existence of spamming
behaviors.
Received: from mail.stu.edu.tw (MAIL [210.71.4.131])
by ms.student.stu.edu.tw with SMTP (Microsoft Exchange Internet Mail
Service Version 5.5.2656.59)
id L2Q1M00D; Sat, 21 May 2005 14:30:18 +0800
Received: by mail.stu.edu.tw with Internet Mail Service (5.5.2656.59)
id <K9XGQT1P>; Sat, 21 May 2005 14:33:53 +0800
Received: from t503carolhsu2 (t503-carolhsu2.stu.edu.tw [210.71.7.184])
by mail.stu.edu.tw with SMTP (Microsoft Exchange Internet Mail Service
Version 5.5.2656.59)
id K9XGQT13; Sat, 21 May 2005 14:33:44 +0800
From: jacky@mail.stu.edu.tw
To: allmis@mail.student.stu.edu.tw
Message-ID: <009401c31f62$ed4c6a10$b80747d2@stu.edu.tw>
Subject: An exam at the end of term
Date: Sat, 21 May 2005 14:33:43 +0800
MIME-Version: 1.0
Content-Type: multipart/alternative;
boundary="----=_NextPart_000_0091_01C31FA5.FAF87E40"
X-Priority: 1
X-MSMail-Priority: High
X-Mailer: Microsoft Outlook Express 6.00.2800.1158
X-MimeOLE: Produced By Microsoft MimeOLE V6.00.2800.1165
An exam about MIS at the end of term ...
Wed 21 14:30:18 mail sendmail[9812]: [ID 484541 mail.info] L2Q1M00D1111:
from=<jacky@mail.stu.edu.tw>, size=3124, class=0, nrcpts=60,
msgid=<009401c31f62$ed4c6a10$b80747d2@stu.edu.tw>,
proto=ESMTP, daemon=MTA, relay=mail.stu.edu.tw [163.27.126.7]
Wed 21 14:30:18 mail sendmail[9813]: [ID 484541 mail.info] L2Q1M00D1111:
to=<allmis@mail.student.stu.edu.tw>, delay=00:00:48, xdelay=00:00:00,
mailer=local, pri=2758984, relay=local, dsn=4.2.0, stat=Sent
Mail Header
System Log
Return-path: <fijekji.eoiw58kij@msa.hinet.net>
Delivered-to: jack@ksts.seed.net.tw
Delivery-date: Mon, 15 Aug 2005 03:49:59 +0800
Received: from [163.27.126.7] (helo=wwwst.pksh.ylc.edu.tw)
by ksts.seed.net.tw with esmtp (Seednet MTA build 20010831)
id 17f49R-0006UO-00
for jack@ksts.seed.net.tw; Thu, 15 Aug 2002 03:49:53 +0800
Received: from html (h176-203-67-207.seed.net.tw [203.67.207.176]
(may be forged))
by wwwst.pksh.ylc.edu.tw (8.8.8/8.8.8) with SMTP id EAA10583;
Mon, 15 Aug 2005 04:28:55 +0800 (CST)
(envelope-from fijekji.eoiw58kij@msa.hinet.net)
Message-Id: <200208142028.EAA10583@wwwst.pksh.ylc.edu.tw>
From: ad883002x106464@ms28.hinet.net
To: allmis@mail.student.stu.edu.tw
Subject: NEW VCD  ............. fhjdsluewl hjfdsf Time:AM 03:47:06
Date: Mon, 15 Aug 2005 03:47:06
Mime-Version: 1.0
Content-Type: text/html; charset="CHINESEBIG5_CHARSET"
X-Priority: 3
X-MSMail-Priority: Normal
X-Mailer: Microsoft Outlook Express 5.00.2919.6700
X-MimeOLE: Produced By Microsoft MimeOLE V5.00.2919.6700
Status: O
IJDNJF e6311e23REIU2@FJVKE.ROIE  I'm sorry!
New AV VCD, $NT40
DJKFDSJIDHUFER 2002
Wed 26 18:25:11 mail sendmail[1019]: [ID 812395 mail.info] g9MBXo111211:
from=<faithsprague_15@pppool.de>, size=5942, class=0, nrcpts=1, 
msgid=<DAMDNPIACKMHKCEAAKENEDNIEOAA.faithsprague_15@pppool.de>,
proto=ESMTP, daemon=MTA, relay=mail.stu.edu.tw [210.71.4.131]
Wed 26 18:25:11 mail sendmail[1020]: [ID 812395 mail.info] g9MBXo111211:
to=<jack@mail.stu.edu.tw>, delay=00:00:57, xdelay=00:00:00,
mailer=local, pri=4833315, relay=local, dsn=4.2.0, stat=Sent
Mail Header
System Log
Fig. 1. Samples of the formats of headers and syslogs.
Table 1
Statistics on the appearing frequencies of header fields
Ham Spam Average
Delivery-To: 100.00 100.00 100.00
Return-path: 100.00 100.00 100.00
Date: 100.00 99.90 99.95
Received: 99.90 100.00 99.95
Message-Id: 99.90 99.90 99.90
From: 100.00 98.30 99.15
Subject: 100.00 97.20 98.60
To: 99.60 84.50 92.05
Content-type: 97.80 60.50 79.15
Mime-Version: 97.60 55.10 76.35
Sender: 99.90 7.20 53.55
Precedence: 99.90 7.00 53.45
C.-H. Wu / Expert Systems with Applications 36 (2009) 4321–4330 43233.2. Feature selection and formulation
In order to utilize headers and syslogs to describe spamming
behaviors of emails, we can formulate an email e according to its
header hh1;h2; . . . ;hmi and syslog hs1; s2; . . . ; sni in a vector form as
e ¼ hhh1;h2; . . . ;hmi; hs1; s2; . . . ; snii; ð1Þ
where hi;1 6 i 6 m and sj;1 6 j 6 n, are fields in e’s header and sy-
slog, respectively. However, there are more than 190 header fields
and 23 syslog fields which can be used by MUA/MTA Costales and
Allman (2002). Clearly, it results in very high-dimension vector
spaces, if all these fields are used for describing emails. Besides,
the contents of each feature are represented as plain texts which
are hard to be processed directly. To reduce the processing com-
plexity, there are two issues for formatting behavior-based features
for emails, the selection of sufficient amount of features from head-
ers and syslogs and making them discretized. Observing the activi-
ties of MUA/MTA and the information recorded in headers and
syslogs, we found that not all fields are used; some of them are
not even used in MUA/MTA. In order to get statistical evidences,
we analyze on the headers of 10,022 spams and 22,809 hams which
are publicly available at Massey, Thomure, Budrevich, and Long
(2005) and list in Table 1 the most frequently used ones. Among
these fields, we select the top-6 which frequently and meaningfully
appear in both hams and spams as the representative header fields.
They are Received:, Return-Path:, From:, Delivered-To:, To:, and Date:.
As for the syslog-part, since there are no public corpora collecting
syslogs, we analyze on the mail servers available to the authors.
We select from, to, nrcpts, date because they have higher appearing
frequencies and are meaningful to humans. The other fields in head-
ers or syslogs are seldom used or are serial numbers which aregenerated by MTA and may be meaningless for spam analysis. We
term these fields describing the primitive information of an email
as the basic features or B-features of an email. Interestingly, by
pair-wisely comparing the values of B-features, we also found that
some fields are related. For instance, From: in the header and from in
the syslog of the same email should direct to the same address. A
reasonable hypothesis can be made that information in related
fields of headers or syslogs is consistent in hams and inconsistent
in spams. Therefore, B-features from headers and syslogs should
be cross-referred if they are related. The referred results indicate
the status of consistency after cross-checking these fields and can
be used as features of emails and provide more stronger evidences
for spam filtering.
According to the format of B-features, we extract 16 meaningful
combinations of B-features as follows:
4324 C.-H. Wu / Expert Systems with Applications 36 (2009) 4321–4330– To:&From:
– To:&Return-Path:
– To:&Delivered-To:
– From:&Return-Path:
– From:&Delivered-To:
– Return-Path:&Delivered-To:
– to&from
– To:&to
– To:&from
– From:&to
– From:&from
– Delivered-To:&from
– Delivered-To:&to
– Return-Path:&from
– Return-Path:&to
– Date:&date
The symbol ‘‘&” connecting two B-features indicates that the
two B-features need to be cross-referred. Note that we do not
cross-check, for example, ‘‘From:” and ‘‘date” since they are in dif-
ferent formats (address vs. date). We term these as cross-referred
features or X-features. By using the above features, an email e can
be described as a 5-tuple hH; L;XH;XL;XXi, where
– H = hTo:, From:, Return-Path:, Date:, Delivered-To, Received:i,
– L = hto, from, date, nrcptsi,
– XH = hTo:&From:, To:&Return-Path:, To:&Delivered-To,
From:&Return-Path:, From:&Delivered-To, Return-Path:&Deliv-
ered-Toi,
– XL = hto&fromi,
– XX = hTo:&to, To:&from, From:&to,
From:&from, Delivered-To&from, Delivered-To&to:, Return-
Path:&from, Return-Path:&to, Date:&datei
The elements in XH and XL are fields that are cross-referred
fields in the same format in the header and syslog, individually.
The elements in XX are cross-referred fields one of which is from
the header and one is from syslog. Note that the relationship in
X-features is reflexive, e.g., Delivered-To:&from = from&Deliv-
ered-To:.4. Rule-based processing
Using the representation of hH; L;XH;XL;XXi, spamming behav-
iors can serve as features of emails. However, these features are
represented in plain-texts. They have to be instantiated and ex-
pressed in discrete or numeric values to be processed by the
learning algorithm. Such transformation needs to interpret the
plain-texts according to some background knowledge. In this
study, we try to interpret them based on spamming behaviors.
First, B-features are discussed. Though there are thousands of
possible interpretations for a given B-feature, we roughly inter-
pret them by their formats. The B-features are generally repre-
sented in the form of addresses, date-and-time, or numbers, so
we categorize B-features according to the legitimacy of ad-
dress/date-time formats, scalar of numbers, and the ones that
commonly appear in spams. Suppose that Fb is a B-feature. The
following heuristic rules Rules_01–Rule_10 are applied for con-
verting Fb.
– Rule_01: IF Fb is in address form AND the user account part is
empty THEN the symbolic value of Fb is C.
– Rule_02: IF Fb is in address form AND the domain part is
empty THEN the symbolic value of Fb is D.– Rule_03: IF Fb is in address form AND (the user account is
faked OR the user account does not exist) THEN the symbolic
value of Fb is E.
– Rule_04: IF Fb is in address form AND (the domain part is
faked OR the domain part does not exist) THEN the symbolic
value of Fb is F.
– Rule_05: IF Fb is in address form AND the address is randomly
generated THEN the symbolic value of Fb is G.
– Rule_06: IF Fb is in date-and-time form AND the value of Date/
Time is illegal THEN the symbolic value of Fb is H.
– Rule_07: IF Fb is in date-and-time form AND the value of Date/
Time is legal AND the delivery time is ‘‘late” THEN the symbolic
value of Fb is I.
– Rule_08: IF Fb is in numeric form AND its value is larger than
or equal to a specific integer (threshold) THEN the symbolic
value of Fb is J.
– Rule_09: IF Fb is empty THEN the symbolic value of Fb is N.
– Rule_10: IF none of the above rules applicable THEN the sym-
bolic value of Fb is A.
When the above rules are invoked, several procedures are called
when needed. For example, the examination on legal formats of ad-
dresses or date-and-time are performed through regular expres-
sions. To test if a domain address is valid, the format of the
address is scanned and verified against the valid domains. Valid
user accounts or domain names are archived for fast investigation.
In Rule_05, tests on text string’s randomness are performed. Since
accurate detection of random strings is a hard problem, we apply
dictionary- and entropy-based detection (Chaitin, 1974) for scan-
ning the relationships between the characters of Fb. In Rule_07,
the so-called ‘‘late” delivery time is temporarily set as the period
between 23:30 and 06:30, which is generally not working hours
of normal email users. Rule_08 examines numeric values. For
example, the number of relays recorded in Received: are counts
and checked if the number of relays is larger than a threshold.
Rule_08 is also applicable to nrcpts. If Rules_01–Rule_10 are not
applicable, Fb is considered as normal and instantiated by the value
A.
Similarly, suppose that an X-feature Fx consisting of two B-fea-
tures b1 and b2; FX is instantiated by the following 4 rules.
– Rule_11: IF the value of b1 is empty OR the value of b2 is
empty THEN the value of Fx is N.
– Rule_12: IF b1 and b2 are in the same format AND b1 and b2
have the same values THEN the value of Fx is T.
– Rule_13: IF b1 and b2 are in the same format AND b1 and b2
have different values THEN the value of Fx is Q.
– Rule_14: IF b1 and b2 are in the different format THEN the
value of Fx is X.
When testing on X-features, the procedures in B-features may
also be invoked. For instance, the two fields (To: test@abc.com)
and (From: test@abc.com) are of the value (test@abc.com) in the
same format (address format); while (To: 05, February, 2005, CST
01:33:54) and (From: test@abc.com) are in different formats (time
format vs. address format).
5. Using back-propagation neural networks
The back-propagation neural network (BPNN) is a commonly
used neural network architecture. The standard architecture of a
BPNN consists of an input layer, an output layer, and one or more
than one hidden layer. Each layer consists of several nodes of neu-
rons, and there are no connections between neurons in the same
layer or to a previous layer. Like many other supervised ma-
C.-H. Wu / Expert Systems with Applications 36 (2009) 4321–4330 4325chine-learning approaches, the use of BPNNs consists of the train-
ing phase and the testing phase. In the training phase, input vec-
tors of classified training patterns are submitted to BPNN and the
activations for each layer of neurons are cascaded forward. At the
output layer, the desired output is compared with the produced
output. If the expected output is not satisfactory, the learning algo-
rithm updates the weights of each neuron starting at the output
layer. The change in weights is calculated for the previous layer
and continues to cascaded through the hidden layers toward the
input layer. BPNN can model high-dimension problems. Since, in
the present problem, the feature space organized by behavior-fea-
tures discussed in Section 3 is of high dimensionality and there is
ambiguity in determining which features are critically used in
spam instances, we adopt BPNN as the learning mechanism.
5.1. Feature encoding
First of all, to be used as input vectors, B-features and X-features
are further encoded. This paper uses numeric encoding. Since there
are 11 cases for instantiation of B-features and 4 cases for X-fea-
tures, they can be encoded as 4-bit and 2-bit vectors, respectively.
However, from time to time, some fields may be empty or contain
null string and will be instantiated as ‘‘N”. Such features are instan-
tiated as other values when they are not empty. In order not to am-
plify the effects of empty-valued features, we use 3-valued
encoding for B- and X-features. For each B-feature, 4-digit encod-
ing is used; while for each X-feature, 2-digit encoding is used.
The values other than ‘‘N” are encoded in either 1 or 0 and an
empty-valued is encoded as 12 ð0:5Þ, as shown in Table 2. Therefore,
an input email e can be described as a 72 1 vector
IIðeÞ ¼ ½I1; I2; . . . ; I72T ð2ÞTable 2
Encoding for the behavior-based features
Case Encoding Case Encoding
(a) 4-digit B-features
B 0 0 0 1 H 1 0 0 1
C 0 0 1 0 I 0 1 1 0
D 0 1 0 0 J 0 1 1 1
E 1 0 0 0 G 1 0 1 0
F 0 1 0 1 A 1 1 1 1
N 12
1
2
1
2
1
2
(b) 2-digit X-features
N 12
1
2 Q 1 0
T 0 1 X 1 1
Fig. 2. Encoded input vectors correswhere I1  I40 represent the values of H and L and I41  I72 the val-
ues of XH;XL, and XX , respectively. For example, considering the
header and syslog of the emails presented in Fig. 1, the correspond-
ing 5-tuple hH; L;XH;XL;XXi and encoded vectors are presented in
Fig. 2.
5.2. Architecture design
According to the proposed behavior-based features, we design a
BPNN, as described as follows. In the input layer of the proposed
BPNN, there are 72 input nodes which are partitioned into two
groups, nodeIðBiÞ and nodeIðXjÞ;1 6 i 6 40 and 41 6 j 6 72. For a
feature vector hH; L;XH;XL;XXi;nodeIðBiÞ accepts the first 40 values
describing H and L; while nodeIðXjÞ takes care of the rest 32 values
holding information about XH;XL, and XX . Generally, a neural net-
work with no more than two hidden layers can generate arbitrarily
complex regions in the state space. In our design, two hidden lay-
ers are used. The first hidden layer collects the information from B-
features and X-features individually and the second hidden layer is
for the combined information of all features. In the first hidden
layer, 10 nodes are used, where nodeH1ðBpÞ; p ¼ 1 . . . 5, accept the
outputs from nodeIðBiÞ and nodeH1ðBqÞ; q ¼ 1 . . . 5, accept the out-
puts from nodeIðXjÞ. The second hidden layer has 6 nodes,
nodeH2ðNrÞ; r ¼ 1 . . . 6, which connect all outputs from nodeH1ðÞ to
the output layer. There is only one output node nodeO in the pro-
posed architecture, which indicates the classification result. All
nodes between two layers are fully connected. The architecture
of the BNPP is depicted in Fig. 3.
5.3. Putting weights to features
In BPNNs, the weight or connection strength assigns different
importance to the signal transferred between nodes layers.
Although the selected features appear frequently in emails, it is
possible that some features of emails in a training dataset are
instantiated by specific values. Such training samples may mislead
the classification mechanism. Such a problem is usually solved by
the technique of feature reduction.
For spam filtering, emails in various formats are collected from
Internet as the training samples. However, the feature values
change over time. When some input features are no longer work-
able, it is necessary to change the architecture of BNPP accordingly.
In order not to change the architecture of BNPP frequently, we
associate weights with each feature and use all features for train-
ing. The weights of features are based on information entropy.
Let D be a data set of n cases, Bi a B-feature in hH; L;XH;XL;XXi,ponding to the emails of Fig. 1.
…
Input vector I72×1
B1
B2
B3
B4
B37
B38
Bi
…
X1
X2
X3
X4…
X31
X32
Xj
…
Input Layer
(node  )I
B39
B40
Digit 1-40:
B-features 
H, L
Digit 41-72:
X-features
XH, XL, XX
Hidden Layer1
(node    )H1
HB1
HB2
HB3
HB4
HB5
HX1
HX2
HX3
HX4
HX5
Hidden Layer2
(node    )H2
HH1
HH2
HH3
HH4
HH5
HH6
Output Layer
(node  )O
Desired
Output
Forward-pass
Backward-pass
δ
θH1(⋅)
0/1
feature bias 
θI(Bi)
Output error
θH2(⋅)
θO(⋅)
feature bias 
θI(Xj)
O
4-digit/field
2-digit/field
To:
…
nrcpts
To:&From:
…
Date:&date
0/1
0/1
<
< <
<
Fig. 3. The proposed BPNN architecture for spam classification.
4326 C.-H. Wu / Expert Systems with Applications 36 (2009) 4321–4330and bij the jth value of Bi appearing in D. The effectiveness of Bi in D
is computed as follows:
EðBi;DÞ ¼ 
X
j
jbijj
n
log2
jbijj
n
 
; ð3Þ
where j bij j is the number of bij appearing in D. Similarly, for a X-
feature Xi, the effectiveness of Xi in D is computed by
EðXi;DÞ ¼
X
j
jxijj
n
log2
jxijj
n
 
: ð4Þ
The input from Ii to the input node nodeIðBiÞ;1 6 i 6 40 corre-
sponding to the B-feature Bi is weighted by hIðBiÞ, where
hIðBiÞ ¼ EðBi;DÞ: ð5Þ
Similarly, the inputs from I41; . . . ; I72 for X-features are also
weighted. Suppose that nodeIðXjÞ;1 6 j 6 32 is such a node which
cross-refers two B-features Bj1 and Bj2, the input to nodeIðXjÞ is
weighted as follows:
hIðXjÞ ¼
1
2
ð1wxÞðEðBj1;DÞ þ EðBj2;DÞÞ þwxEðXj;DÞ; ð6Þ
where 0 6 wx 6 1 is a balance factor set by the user. The net input
to the hidden nodes follows the general rules. That is, for the pth
example presented to the network, the net input to a node nodei is
vpi ¼
Xn
j¼1
Opjhij; ð7Þ
where n is the number of nodes having connections to the nodei, Opj
is the output of nodej and hij is the weight of the connection from
the nodej to nodei. In this way, we need not have to reconfigurethe architecture of the neural network for different training data
sets.
5.4. The learning strategies
First, we have to define the activation function associated with
each net input. We use the standard sigmoidal function, i.e.
f ðxÞ ¼ 1
1þ eax ; ð8Þ
in all nodes with different a values. Currently, we set a ¼ 1 for
nodeIðBiÞ and nodeH1 ðBiÞ and a ¼ 0:8 for the other nodes. One of
the reasons of doing this is to put different importance to B-features
and X-features. Second, the learning algorithm is to try to minimize
the training error which is defined as the mean-square difference
between the desired output dp and the actual output yp
E ¼
XP
p¼1
Ep ¼
1
2
XP
j¼1
ðdp  ypÞ
2
; ð9Þ
where P is the number of training patterns. Ep represents a local
approximation to the global error surface E. The learning algorithm
employed in this study is the standard gradient descent method.
Since the significance of B-features and X-features differs in training
set, the weight changes for a layer utilizes the gradient descent
method with a momentum term that allows a low learning coeffi-
cient to be used and creates faster learning. The general form for
the change of weights that are proportional to the gradient of Ep
with respect to the weights for that layer is
Dphkj ¼ g
oEp
ohkj
¼ gdpkypj; ð10Þ
Rule-based Pre-processingRulebase
Emails received
fromthe Internet
Behavior Identification
72-bit Encoding
ANN Classifier
Training
Dataset 
Background
Knowledge on
Email
Pass-1:
identifying 
spamming behaviors 
Pass-2: ANN 
classification
Deciding Spam/Ham??
Fig. 4. Two-staged processing flow of our method.
Table 3
The hams and spams collected from the MTA
Group Dates HAM SPAM Total
01 2004/08–2005/02 23142 31721 54863
02 2005/03 7891 10322 18213
03 2005/04 6975 9813 16788
04 2005/05 7212 9877 17089
05 2005/06 5431 7823 13254
Total 50651 69556 120207
C.-H. Wu / Expert Systems with Applications 36 (2009) 4321–4330 4327where ypj ¼ fjðvpkÞ; g is the learning rate parameter. For the output
layer node
dp ¼ f 0ðvpÞðdp  ypÞ; ð11Þ
while for the for hidden layer nodes
dpk ¼ f 0kðvpkÞ
X
i
dpjhik: ð12Þ
Therefore, the change of weight in each learning iteration is
hkjðt þ 1Þ ¼ hkjðtÞ þ gdpkypj þ bDphkjðtÞ; ð13Þ
where 0 < b < 1 is the momentum factor and MphkjðtÞ ¼ hkj
ðtÞ  hkjðt þ 1Þ. The learning rate g and momentum factor b are set
in hidden layers H1ðBiÞ and H1ðXjÞ to reflect the significance of B-
or X-features.
5.5. The processing flow
Our method can be viewed as a two-pass classification process.
Given a set of emails which have been determined as hams or
spams by golden rules, we try to determine the type of spamming
behaviors according to the information from headers and syslogs of
emails. The feature biases in the training dataset are calculated for
weighting the corresponding input nodes. Then, the emails are
transformed in the discrete format. The proposed BPNN is used
to produce classification model using the training samples in the
vector form. The BPNN is trained with supervision; thus, the de-
sired output (ham = 1 and spam = 0) corresponding to the input
vector is supplied to the BNPP in the training phase. By the pro-
duced classification model, new emails are classified accordingly.
The processing flow is depicted in Fig. 4.
6. Experiments
6.1. Data collection
As stated earlier, the success of machine-learning methods for
problem-solving depends on the use of unique features which canfully describe the underlying problem and sufficient corpora of
training data. Public corpora such as those in Hopkins, Reeber, For-
man, and Suermondt (2006), Mark and Perrault (2005), Spam-
Links.net (2005), SpamArchive.org (2006) collect a huge number
of emails. However, all emails in these corpora are submitted by
Internet users who receive spams. Unfortunately, these emails only
contain headers and message bodies. Information of syslogs of
emails in these corpora is not available since Internet users are able
to submit their syslogs. If we want to analyze the behaviors from
syslogs and headers and cross-refer their differences, we need to
collect emails in some other ways. To overcome this obstacle, we
have installed a MTA for collecting emails. Several email accounts
are created on the MTA and are used as contact information for bul-
letin board systems, news groups, and web sites publicly available
on the Internet. Also, we put these accounts on web pages and pub-
lish them on web sites. The purpose of doing these is to try to let
these accounts be catched by spambots or web crawlers which col-
lect mailing lists. These strategies were deployed since August 2004
and had being successfully collected more than 120,000 emails
(hams and spams). Since we can access to the MTA, important infor-
mation like headers, message bodies, and syslogs associated with all
emails are available to us. These emails are manually determined as
hams or spams so that they can serve as training samples. We par-
tition these emails into 5 groups, as shown in Table 3.
6.2. Measurements
In order to estimate the effectiveness of our approach, several
performance indicators are used. In each experiment, let a be the
number of hams which are correctly predicted as hams; b the num-
ber of spams which are predicted as hams; c the number of hams
which are predicted as spams; and d the number of spams which
are predicted as spams. The primary measures of interest are de-
fined as follows:
– Mean squared error (MSE): The mean-square difference
defined in Eq. (9).
– Ham misclassification fraction hm ¼ caþc
 
: The ratio of the
number of misclassified hams to the total number of hams.
– Spam misclassification fraction sm ¼ bbþd
 
: The ratio of the
number of misclassified spams to the total number of spams.
– Overall misclassification fraction m ¼ bþcaþbþcþd
 
: The overall
ratio of the number of misclassified emails (hams and spams)
to the total number of emails.
– Accuracy ACC ¼ aþdaþbþcþd
 
: The ratio of the number of correctly
classified emails to the total number of emails, which is also
1m.
– Total cost ratio (TCR): The ratio of the number of correctly
identified emails to the number of incorrectly identified emails.
Two TCRs are defined in the experiments, i.e. TCRs ¼ dkcþb is for
spams and conversely, TCRh ¼ akbþc is for hams, where k is a var-
iable defined in the experiments.
Table 4
Experimental I: the effectiveness of behavior-based features on the proposed BPNN
Features MSE ð%Þ ACC ð%Þ hm sm m
(a) Accuracy, misclassification ratio, and MSE
Training hH;/;XH ;/;/i 28.49 87.33 0.1747 0.0789 0.1267
h/; L;/;XL;/i 47.82 61.57 0.1427 0.6249 0.3843
hH; L;XH ;XL;XXi 5.23 99.73 0.0055 0.0000 0.0027
Testing hH;/;XH ;/;/i 28.50 86.81 0.1806 0.0818 0.1319
h/; L;/;XL;/i 47.77 61.18 0.1552 0.6281 0.3882
hH; L;XH ;XL;XXi 6.34 99.60 0.0063 0.0017 0.0040
TCRs TCRh
Features k ¼ 1 9 99 999 k ¼ 1 9 99 999
(b) Total cost ratio
Training hH;/;XH ;/;/i 3.6425 0.5601 0.0532 0.0053 3.2508 0.9296 0.1029 0.0104
h/; L;/;XL;/i 0.4890 0.1970 0.0255 0.0026 1.1134 0.1481 0.0138 0.0014
hH; L;XH ;XL;XXi 183.8148 20.4239 1.8567 0.1840 182.3704 182.3704 182.3704 182.3704
Testing hH;/;XH ;/;/i 3.4293 0.5231 0.0497 0.0049 3.1511 0.9150 0.1019 0.0103
h/; L;/;XL;/i 0.4721 0.1801 0.0226 0.0023 1.1038 0.1496 0.0139 0.0014
hH; L;XH ;XL;XXi 122.0526 16.6835 1.5574 0.1547 125.0526 46.5882 5.7810 0.5924
4328 C.-H. Wu / Expert Systems with Applications 36 (2009) 4321–4330For convenience, an empty-set symbol / in the tuple
hH; L;XH;XL;XXi denotes that the feature at that position is not used
and the corresponding feature bias is set as 0. For example,
hH;/;XH;/;/i means that only H in the B-features and XH in the
X-features are used and the feature biases at the input connections
for nodeIðLÞ;nodeIðXLÞ, and nodeIðXXÞ are 0.
6.3. Experiment I
First of all, we test if behavior-based features is suitable for the
classification of emails. First, training patterns are extracted ran-
domly from the corpora mentioned in Section 6.1 and transformed
to behavior-based vector form and submitted to the BPNN. Dupli-
cated samples are ignored. From each group of emails of Table 3,
we randomly select 80% of emails for training. Among these train-
ing data, 80% of emails are used for building classification model0.5
0.6
0.7
0.8
0.9
1.0
t1 t2 t3 t4 t5 t6 t7 t8 t9 t10
Behavior-based Acc
Keyword-based Acc
0.00
0.04
0.08
0.12
0.16
0.20
t1 t2 t3 t4 t5 t6 t7 t8 t9 t10
Behavior-based hm Behavior-based sm
Behavior-based m Keyword-based hm
Keyword-based sm Keyword-based m
Fig. 5. Experimental result II: comparison on the effectivenesand the rest of 20% are for validation. Also we randomly select
20% of the dataset for testing. We repeat this experiment for 10
times with the same settings and average the experimental results.
Table 4 presents the experimental results. This experimental result
shows that the performance of classification using hH;/;XH;/;/i is
better than that using h/; L;/;XL;/i. Besides, hH; L;XH;XL;XXi out-
performs the others. This phenomenon can be explained by that
features from hH;/;XH;/;/i can be real or faked information given
by MUA or spam-bot so that it is possible to identify spam using
hH;/;XH;/;/i directly. However, a spam can be sophisticatedly
faked, making the values of hH;/;XH;/;/i looked just like normal
messages, and confusing the classifier. Conversely, features from
h/; L;/;XL;/i contain real information since they are recorded by
the receiver’s MTA. Classification using only h/; L;/;XL;/i is not
satisfactory due to the low identification rate. When using
hH; L;XH;XL;XXi which combines hH;/;XH;/;/i and h/; L;/;XL;/i,0.00
0.10
0.20
0.30
0.40
0.50
0.60
0.70
t1 t2 t3 t4 t5 t6 t7 t8 t9 t10
Behavior-based MSE
Keyword-based MSE
-5
0
5
10
15
20
25
30
t1 t2 t3 t4 t5 t6 t7 t8 t9 t10
λ=1 (Behavior-based)
λ=99 (Behavior-based)
λ=1 (Keyword-based)
λ=99 (Keyword-based) λ=999 (Keyword-based)
λ=9 (Keyword-based)
λ=999 (Behavior-based)
λ=9 (Behavior-based)
s of the proposed method with keyword-based filtering.
C.-H. Wu / Expert Systems with Applications 36 (2009) 4321–4330 4329the accuracy is significantly improved due to the effect of cross-ref-
erence on hH;/;XH;/;/i and h/; L;/;XL;/i.
6.4. Experiment II
In this experiment, we test the time-robustness of the proposed
method with keyword-based filtering using BPNN. Emails in group
01 are used for building the classification model. Then the ones in
group 02–05 are partitioned into 10 subsets according to their
receiving dates. Spam/ham are randomly selected from each parti-
tion so that the numbers of spams and hams in the same dataset
are even. These partitioned datasets are applied to the BPNN model
in the order of the receiving dates to simulate the change of time.
In order to compare with keyword-based methods, keywords are
extracted using TF * IDF (Salton & Buckley, 1988) after stemming
and the removal of stop-words from the message bodies of the
same emails. A number of 3000 frequently appeared keywords
are extracted and transformed into the vector-form and applied
to a BPNN using the same learning algorithms presented in Section
5.4 except that the learning strategies are unbiased. The features
hH; L;XH;XL;XXi are used in the proposed BPNN. Also, this experi-
ment is repeated for 10 times and the results are averaged and pre-
sented in Fig. 5. From the results, we find that features of emails
based on spamming behaviors or keywords do changed over time.
The resistance to the change of time of the behavior-based method
is higher to the keyword-based method. Keyword-based filtering
becomes unstable and unsatisfactory as the time changes. Interest-
ingly, machine-learning based methods for keyword-based spam
filtering are reported to have satisfactory performance. However,
keyword-based methods usually need thousands of keywords to
serve as features to gain satisfactory results (Jiang, 2006; Kanaris,
Kanaris, & Stamatatos, 2006; Pampapathi, Mirkin, & Levene,
2006). On the contrary, in the proposed approach, only 72 input
features are used. It may be conclude that behavior-based features
can better distinguish spams and hams than keywords.
6.5. Experiment III
Finally, we compare the effectiveness of the proposed BPNN
architecture and the weighted learning strategy with some ma-
chine-learning approaches which are available from Weka (version
3.4) Garner (1995). The features hH; L;XH;XL;XXi are used in the
proposed BPNN with the same settings in Experiment I. The results
are given in Table 5. From the results, the proposed BPNN with
weighted learning strategy outperforms the others. This may due
to the architecture of BPNN is specially tailored according to theTable 5
Experimental result III: comparison with other learning algorithms
Methods MSE ACC hm sm m
AODE 26.40 90.50 8.16 10.89 9.50
BayesNet 30.55 87.57 12.55 12.31 12.43
HNB 37.01 84.37 14.76 16.53 15.63
NBSimple 30.55 87.57 12.55 12.31 12.43
NBUpdateable 30.55 87.57 12.55 12.31 12.43
WAODE 25.33 90.56 7.99 10.93 9.44
Logistic 28.00 88.61 11.04 11.75 11.39
RBFNetwork 36.26 82.16 19.32 16.32 17.84
VotedPerceptron 34.77 87.91 10.96 13.26 12.09
Winnow 51.78 73.19 49.10 3.87 26.81
VFI 47.56 86.08 14.35 13.47 13.92
ConjunctiveRule 38.09 82.39 16.48 18.77 17.61
OneR 41.96 82.39 16.48 18.77 17.61
ADTree 26.72 91.60 6.27 10.59 8.40
DecisionStump 38.09 82.39 16.48 18.77 17.61
NBTree 12.11 98.54 1.84 1.08 1.46
OUR BPNN 6.34 99.60 0.63 0.17 0.40
All data are expressed in %.characteristics of behavior-based features of emails and the
weighted learning strategy involved in the BPNN. It is also possible
that the performance of other machine-learning algorithms can be
further improved, provided that their learning architectures and
parameters are elaborately designed.7. Concluding remarks
We have presented in this paper a hybrid method of rule-based
processing and back-propagation neural networks for spam filter-
ing. Instead of using keywords, this study utilize the spamming
behaviors as features for describing emails. A rule-based process
is first employed to identify and digitize the spamming behaviors
observed from the headers and syslogs of emails. An enhanced
BPNN together with a weighted learning strategy is designed as
the classification mechanism. Since spamming behaviors are infre-
quently changed, compared with that of keywords used in spams,
the proposed method is more robust with respect to the change of
time. Although it seems that our method gives a promising solu-
tion to the problem of spam filtering, there are several improve-
ments to be done in the future.
– Currently, there are only 26 features selected from the head-
ers and syslogs of emails. Potential features other than the pres-
ent ones may exist. Current behavior-based features are
selected from headers and syslogs of emails since they are used
by MUA/MTA more frequently. Selecting features may consider
features’ importance not only according to the appearing fre-
quency but also mutual information or information entropy,
which may further improve the performance of spam filtering.
– The weight of features is currently computed statically from
the given training dataset. Though behavior-based features are
resistant to the change of time, they change slowly. Some fea-
tures may be out of date after a period of time; and hence, the
weight of importance of features should be changed dynamically.
– One of the drawbacks of using BPNN is its unstable time to
converge. The number of features and effective training samples
dominate the performance of the BPNN. Additionally, there may
exist some BPNN architectures which can perform better than
the present one. More comparative studies will be conducted
in the future.
– It may not be possible to detect, totally and always exactly, all
spams using a single technique. Hybridizing several workable
techniques for anti-spamming is essential.
Acknowledgement
Supported by National Science Council (NSC), Taiwan, under
Grant No. NSC 95-2221-E-390-023.
References
Androutsopoulos, I., Koutsias, J., Chandrinos, K. V., & Spyropoulos, C. D. (2000). An
experimental comparison of Naive Bayesian and keyword-based anti-spam
filtering with personal e-mail messages. In Proceedings of the 23rd annual
international ACM SIGIR conference on research and development in information
retrieval (pp. 160–167). Athens, Greece: ACM Press.
Bezerra1, G. B., Barra1, T. V., Ferreira, H. M., Knidel, H., de Castro, L. N., & Zuben1, F. J.
V. (2006). An immunological filter for spam. In International conference on
artificial immune systems (pp. 446–458).
Blanzieri, E., Bryl, A. (2006). A survey of anti-spam techniques, Tech. Rep. DIT-06-
056, Informatica e Telecomunicazioni, University of Trento.
Brutlag, J. D., & Meek, C. (2000). Challenges of the email domain for text
classification. In Proceedings of the 17th international conference on machine
learning (pp. 103–110), Stanford University, Stanford, CA, US.
Camastra, F. (2005). Kernel methods for clustering. In International workshop on
natural and artificial immune systems (pp. 1–9).
Chaitin, G. J. (1974). Information theoretic limitations on formal systems. Journal of
the Association for Computing Machinery, 21(3), 403–424.
4330 C.-H. Wu / Expert Systems with Applications 36 (2009) 4321–4330Clark, J., Koprinska, I., Poon, J. (2003). A neural network based approach to
automated e-mail classification, in: Proceedings of the 2003 IEEE/WIC
International Conference on Web Intelligence, IEEE Computer Society, Halifax,
Canada, pp. 702–705.
Costales, B., & Allman, E. (2002). Sendmail (3rd ed.). O’Reilly & Associates, Inc.:
Sebastopol, CA 95472.
Crawford, E., Kay, J., & McCreath, E. (2001). Automatic induction of rules for e-mail
classification. In Proceedings of the sixth Australasian document computing
symposium (pp. 13–20). Coffs Harbour, Australia.
Delany, S. J., Cunningham, P., Doyle, D., & Zamolotskikh, A. (2005). Generating
estimates of classification confidence for a case-based spam filter. In H. Munoz-
Avila, F. Ricci (Eds.), International conference on case-based reasoning (pp. 177–
190).
de Vel, O., Anderson, A., Corney, M., & Mohay, G. (2001). Mining e-mail content for
author identification forensics. SIGMOD Record, 30(4), 55–64.
Diao, Y., Lu, H., & Wu, D. (2000). A comparative study of classification-based
personal e-mail filtering. In Proceedings of the 4th Pacific–Asia conference on
knowledge discovery and data mining (pp. 408–419). Kyoto, Japan.
Fdez-Riverola, F., Iglesias, E. L., Díaz, F., Méndez, J. R., & Corchado, J. M. (2007).
Applying lazy learning algorithms to tackle concept drift in spam filtering.
Expert Systems with Applications, 33(1), 36–48.
Garner, S. (1995). WEKA: The waikato environment for knowledge analysis. In
Proceedings of the New Zealand computer science research students conference (pp.
57–64).
Gavrilis, D., Tsoulos, I. G., & Dermatas, E. (2006). Neural recognition and genetic
features selection for robust detection of e-mail spam. In G. Antoniou, G.
Potamias, C. Spyropoulos, & D. Plexousakis (Eds.), SETN, Vol. 3955 of lecture notes
in computer science (pp. 498–501). Springer.
Graham, P. (2003). Better bayesian filtering. In Proceedings of the 2003 spam
conference January 2003. URL http://www.paulgraham.com/better.html.
Hall, R. J. (2000). Feature interactions in electronic mail. In Proceedings of the sixth
international workshop on feature interactions in telecommunications and software
systems (pp. 67–82). Amsterdam, Netherlands.
Hoanca, B. (2006). How good are our weapons in the spam wars? IEEE Technology
and Society Magazine, 25, 22–30.
Hopkins, M., Reeber, E., Forman, G., & Suermondt, J. (2006). Spam e-mail database
from UCI machine learning repository. http://www.ics.uci.edu/~mlearn/
MLSummary.html.
Jiang, E. (2006). Learning to semantically classify email messages. In
Proceedings of the international conference on intelligent computing 2006
(pp. 700–711).
Kanaris, I., Kanaris, K., & Stamatatos, E. (2006). Spam detection using character n-
grams. In G. Antoniou et al. (Eds.), Hellenic conference on artificial intelligence (pp.
95–104).
Katirai, H. (1999). Filtering junk e-mail: A performance comparison between
genetic programming & Naïve Bayes, Tech. Rep., University of Waterloo
(September 10 1999).Lai, C.-C., Tsai, M.-C. (2004). An empirical performance comparison of machine
learning methods for spam e-mail categorization. In Proceedings of the fourth
international conference on hybrid intelligent systems.
M.A.P.S.L. ðMAPSSMÞ (2003). http://www.mail-abuse.com/spam_def.html.
Mark, B., & Perrault, R. C. (2005). Enron email dataset. http://www-2.cs.cmu.edu/
~enron.
Massey, B., Thomure, M., Budrevich, R., & Long, S. (2005). The psam project. http://
www.nexp.cs.pdx.edu/~psam.
Mendez, J., Fdez-Riverola, F., Iglesias, E., Diaz, F., & Corchado, J. (2006). Tracking
concept drift at feature selection stage in spam hunting: An anti-spam instance-
based reasoning system. In T. Roth-Berghofer et al. (Eds.), European conference
on case-based reasoning (pp. 504–518).
Pampapathi, R., Mirkin, B., & Levene, M. (2006). A suffix tree approach to anti-spam
email filtering. Machine Learning, 65, 309–338.
Sakkis, G., Androutsopoulos, I., Paliouras, G., & Stamatopoulos, P. (2003). A memory-
based approach to anti-spam filtering for mailing lists. Information Retrieval,
6(1), 49–73.
Salton, G., & Buckley, C. (1988). Term-weighting approaches in automatic text
retrieval. Information Processing and Management, 24(5), 513–523.
Schapire, R. E., & Singer, Y. (2000). Boostexter: A boosting-based system for text
categorization. Machine Learning, 39(2/3), 135–168.
SpamArchive.org (2006). Spamarchive project. http://www.spamarchive.org.
SpamLinks.net, (2005). Spam links – spam archives. http://www.spamlinks.net/filter-
archives.htm.
Tseng, L.-S., & Wu, C.-H. (2003). Detection of spam e-mails by analyzing the
distributing behaviors of e-mail servers. In Proceedings of the third international
conference on hybrid intelligent systems (pp. 1024–1033).
Wang, H.-B., Yu, Y., & Liu, Z. (2005). SVM classifier incorporating feature selection
using GA for spam detection. In The 2005 international conference on embedded
and ubiquitous computing (pp. 1147–1154).
Wang, Z., Hori, Y., & Sakurai, K. (2006). Application and evaluation of bayesian filter
for Chinese spam. In Proceedings of conference on information security and
cryptology (pp. 253–263).
Wang, F., You, Z., & Man, L. (2006). Immune-based peer-to-peer model for anti-
spam. In Proceeding of the international conference on intelligent computing (pp.
660–671).
Wang, B., Jones, G. J. F., & Pan, W. (2006). Using online linear classifiers to filter spam
emails. Pattern Analysis and Applications, 9, 339–351.
Webb, S., Chitti. S., Pu, C. (2005). An experimental evaluation of spam filter
performance and robustness against attack. In Proceedings of the 1st
international conference on collaborative computing: networking, applications
and worksharing (pp. 19–21).
Yue, X., Abraham, A., Chi, Z.-X., Hao, Y.-Y., & Mo, H. (2007). Artificial immune system
inspired behavior-based anti-spam filter. Soft Computing, 11, 729–740.
Zhang, X., Liu, J., Zhang, Y., & Wang, C. (2006). Spam behavior recognition based on
session layer data mining. In L. Wang et al. (Eds.), Proceedings of third international
conference on fuzzy systems and knowledge discovery (pp. 1289–1298).
