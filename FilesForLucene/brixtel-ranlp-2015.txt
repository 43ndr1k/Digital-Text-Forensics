See	discussions,	stats,	and	author	profiles	for	this	publication	at:	http://www.researchgate.net/publication/281742612
Maximal	Repeats	Enhance	Substring-based
Authorship	Attribution
CONFERENCE	PAPER	·	SEPTEMBER	2015
READS
6
1	AUTHOR:
Romain	Brixtel
University	of	Lausanne
25	PUBLICATIONS			17	CITATIONS			
SEE	PROFILE
All	in-text	references	underlined	in	blue	are	linked	to	publications	on	ResearchGate,
letting	you	access	and	read	them	immediately.
Available	from:	Romain	Brixtel
Retrieved	on:	06	November	2015
Proceedings of Recent Advances in Natural Language Processing, pages 63–71,
Hissar, Bulgaria, Sep 7–9 2015.
Maximal Repeats Enhance Substring-based Authorship Attribution
Romain Brixtel
Department of Organizational Behavior, Faculty of Business and Economics
University of Lausanne, Quartier Dorigny, 1015 Lausanne, Switzerland
romain.brixtel@unil.ch
Abstract
This article tackles the Authorship Attri-
bution task according to the language in-
dependence issue. We propose an alterna-
tive of variable length character n-grams
features in supervised methods: maximal
repeats in strings. When character n-
grams are by essence redundant, maximal
repeats are a condensed way to represent
any substring of a corpus. Our experi-
ments show that the redundant aspect of
n-grams contributes to the efficiency of
character-based techniques. Therefore, we
introduce a new way to weight features
in vector based classifier by introducing
n-th order maximal repeats (maximal re-
peats detected in a set of maximal repeats).
The experimental results show higher per-
formance with maximal repeats, with less
data than n-grams based approach (ap-
proximately divided by a factor of 10).
1 Introduction
Internet makes it easy to let anyone share his opin-
ion, to communicate news or to disseminate his lit-
erary production. A main feature of textual traces
on the web is that they are mostly anonymous.
Textual data mining is used to characterise au-
thors, by categories (e.g. gender, age, political
opinion) or as individuals. The latter case is called
the Authorship Attribution (AA) issue. It consists
of predicting the author of a text given a prede-
fined set of candidates, thus falling in the super-
vised machine learning subdomain. This problem
is often expressed as the ultimate objective, find-
ing the author. Technically the task is to predict a
new pair, considering given pairs linking text and
author. It is also known as writeprint, in reference
of fingerprint in written productions. For a sur-
vey, see (Koppel et al., 2009; Stamatatos, 2009;
El Bouanani and Kassou, 2014).
For AA, stylometry is most often used. The as-
sumption is that a writer leaves unintended clues
that lead to his identification. Bouanani et al.
(2014) define a set of numerical features that re-
mains relatively constant for a given author and
sufficiently contrasts his writing style against any
author’s style. In the previous studies, numerical
data such as word-length, and literal data such as
words or character strings were used to capture
personal style features (Koppel et al., 2011). Un-
like words or lemmas that belong to a priori re-
sources, character strings are in compliance with a
language independent objective. Supervised ma-
chine learning techniques are used to learn au-
thor’s profile, from a training set where text and
author pairs are known. Eventually, results are
used to attribute new texts to the right author. This
is a multi-variate classification problem. Support
Vector Machine (SVM) is one of the favorite ap-
proaches to handle such complex tasks (Sun et al.,
2012). This is the chosen solution here.
AA therefore consists of predicting the author
of a textual message given a predefined set of can-
didates. The difficulty of the task depends on its
scope and the choice of the training set. It in-
creases when the objects of study come from the
web, with different textual genres, styles or lan-
guages. Research on AA can focus on several
issues. Item scalability addresses matching text
with a huge number of authors. Language inde-
pendence requires techniques that are efficient ir-
respective of language resources such as lexica.
In this study, the language independence issue
is addressed, with character-based methods. How-
ever, computation of all the character subtrings in
a text is costly. The major contribution of this pa-
per is a new way to handle character substrings,
to reduce the training data and therefore the train-
ing time and cost, without loosing accuracy in AA.
The well-known variable length character n-grams
approach is compared to a variable length max-
63
imal repeats approach. As a controversial state-
ment, experiments conducted in this article high-
light that the redundancy of features based on n-
grams is beneficial in a classification task as AA.
This introduces a new way to weight features that
takes into account this redundancy with n-th or-
der maximal repeats (maximal repeats in a set of
maximal repeats). Experiments are conducted on
three corpora: one in English, one in French and
the concatenation of those two corpora.
The remainder of this article is organized as fol-
lows. Section 2 describes related work and com-
monly used features. Section 3 introduces the ex-
perimental settings, the characteristics of the cor-
pora and the experimental pipeline. Section 4 de-
scribes features, detailing the maximal repeats al-
gorithm. Section 5 details experimental results.
Section 6 concludes.
2 Related Work
AA is a single-label multi-class categorisation
task. Three characteristics have to be defined (Sun
et al., 2012): single feature, set of features repre-
senting a text and the way to handle those sets to
match a text with an author.
2.1 Features Definition
AA features exploited in the literature can be sep-
arated in different groups as advocated by Abbasi
et al. (2008): numerical values associated with
words (total number of words, number of char-
acter per word, number of character bi/tri-grams),
hence called lexical; mixed values associated with
syntax at sentence level (frequency of function
words, n-grams of Part-Of-Speech tags); numeri-
cal values associated with bigger units (number of
paragraphs, average length of paragraphs), called
structural; values associated with content (bag-of-
words, word bi-grams/tri-grams); and a last group
called idiosyncratic related with individual use
(misspellings, use of Leet speak).
Among those features, some are specific to
some types of language and writing systems. For
instance, tokenizing a text in words is common
in word separating cases, but is a non-trivial task
in Chinese or Japanese. Part-Of-Speech (POS)
tagging requires specific tools that might lack in
some languages. Approaches based on character
n-grams appear to be the simplest and the most
accurate methods when the aim is to handle any
language (Grieve, 2007; Stamatatos, 2006).
But, as advocated by Bender et al. (2009), a
language independent method should not be a lan-
guage naive method. If the extraction of n-grams
is done whatever the language, the n parameter
has to be chosen according to the properties of the
processed language. The same results cannot be
expected for the same parameter on different lan-
guages according to their morphological typology
(e.g. inflected or agglutinative languages).
Sun et al. (2012) argue that using a fixed value
of n can only capture lexical informations (for
small values of n), contextual or thematic informa-
tions (for larger values), but do not explain why or
whether this is valid for Chinese or all languages.
The authors argue that this issue is avoided by
exploiting variable length n-grams (substrings of
length in [1, n]). Variable length substrings are ex-
ploited in this study to see how this parameter im-
pacts the results in French and English.
2.2 Feature-based Text/Author
Representation
A single feature can be allocated to several text
and author pairs. Each text and author does not
systematically share the same set of features. Dif-
ferent sets of features can be defined to repre-
sent texts (and by extension, to represent authors).
From existing methods, two main categories of set
of features can be defined for AA:
• off-line set of features: features a priori con-
sidered relevant with prior knowledge, as those
deeply described by Chaski et al. (2001). They
are defined without the knowledge of the corpus
to be processed.
• on-line set of features: features defined accord-
ing to the current analysis (according to the
training and test corpora for supervised meth-
ods, as the character language models described
by Peng et al. (2003)). They can only be de-
fined when the corpora to be processed (test and
training) are fully collected.
On-line sets of features naturally match with the
language-independence aim. The characteristics
of the corpora are exploited without any external
resource. The method described hereafter follows
this principle.
2.3 Feature-based Text Categorisation
Different techniques for handling features ex-
tracted from texts have been proposed. SVM and
Neural Network are established ways to conduct
AA in the supervised machine-learning paradigm
(Kacmarcik and Gamon, 2006; Tweedie et al.,
64
1996). When the set of authorship candidates is
large or incomplete, thus not including the correct
author, some approaches compare sets of features
with specific similarity functions (Koppel et al.,
2011). Individual level sets of features are used
with machine-learning techniques to build a clas-
sifier per author. Each classifier acts as an ex-
pert dedicated to process a subarea of the features
space (i.e. each classifier is specialised on detect-
ing some specific authors). The experiments de-
scribed in this article use an SVM classifier, keep-
ing the same parameters for each experiment, to
analyse the impact of the features.
3 Experimental Pipeline and Corpora
A classical AA pipeline is drawn in Figure 1. This
pipeline contains two main elements: a Features
selector (features are extracted from the training
and the test corpus) and a Classifier (using the fea-
tures extracted in the training corpora, each mes-
sage of the test corpus is classified).
Features Classifier
Authorship
Attribution
Training corpora
Test
corpus
vector of features
test corpus
author0 author1 authorn-1
...
te
xt
s
te
xt
s
te
xt
s
te
xt
s vector of feature
s
training corpo
ra
Figure 1: Pipeline processing for supervised AA.
Experiments are conducted to highlight charac-
teristics of substring-based AA methods. SVM is
used as the classifier of the pipeline for all exper-
iments, following Sun et al. (2012) and Brennan
et al. (2012). The features selection step is meant
to extract the right features from corpora irrespec-
tive of language. The experimental pipeline is kept
as simple as possible to avoid interferences in the
analysis of the features selection.
3.1 Definitions
D is a dataset for stylometric analysis contain-
ing I texts and K authors. ti is the i-th text
and ak the k-th author. F is the set of all the
features in the dataset D, Fi the set of features
of ti. Each text ti is represented as a vector of
features. Considering o(i,j) the occurrence fre-
quency of the jth feature fj of the ith text ti
containing n features, the text is represented as
ti = {o(i,0), . . . , o(i,n−1)}. A weight function w
can be applied on each feature of a text, w(ti) =
{w(f0).o(i,0), . . . , w(fn−1).o(i,n−1)}. A classifier
C is therefore trained on a subsample of texts writ-
ten by preselected authors (training corpora). The
set of features used is the intersection of each set of
features from the test and training corpora. During
experiments, similar results have been obtained
with features occurring only in the training corpus,
but with a much larger search space to explore.
3.2 Corpora
Two corpora are exploited for experiments: a
French one, the LIB corpus and an English one,
the EBG corpus. Those two languages are chosen
because they have many characters and linguistic
characteristics in common. A third corpus, MIXT,
is constituted from the merge of EBG and LIB.
A subcorpus of 40 authors, EBG, is extracted
from the EXTENDED BRENNAN GREENSTADT
adversarial corpus (Brennan et al., 2012). The
EBG corpus is constituted of texts exclusively in
English (Table 1).
#characters #texts #authors
corpus 1.9× 106 631 40
authors
(mean±stdv)
4.6× 104 ± 8075 15.8± 2.6
texts (mean ±
stdv)
2945.1± 178.5
Table 1: Overall characteristics of EBG.
The second corpus is extracted from the web-
site of the French newspaper LIBÉRATION. The
LIB corpus contains texts from 40 different au-
thors who have written in more than one journal-
istic categorie, such as sports or health. This is in-
tended to minor subgenre impact, i.e. characteris-
tics that might blur the personal style. The corpus
main characteristics are drawn in Table 2.
#characters #texts #authors
corpus 5.1× 106 1247 40
authors 1.3× 105 31.2± 4.2
(mean±stdv) ± 2.6× 104
texts (mean ±
stdv)
4070.6± 1524.2
Table 2: Overall characteristics of LIB.
LIB contains the same number of authors as
EBG, but the number of texts bounded to each au-
thor is higher (31.2 ± 4.2 texts per author in LIB,
15.8 ± 2.6 in EBG). All texts in LIB and EBG
are longer than the 250 words limit (≈ 1500 char-
acters), the minimum length considered effective
for authorship analysis seen as a text classification
task (Forsyth and Holmes, 1996).
The MIXT corpus, 80 authors with texts in both
English and French, is obtained from the merge of
EBG and LIB. It is built to erase language distinc-
tions. During experiments, tests are also driven on
65
different subcorpora of EBG, LIB and MIXT. We
denote EBG-10 (respectively LIB-10 and MIXT-
10) a sample of 10 authors from the EBG cor-
pus (respectively LIB and MIXT). Note that the
MIXT-20, . . . , 80 are the merge of LIB-10 + EBG-
10, . . . , LIB-40 + EBG-40. Experiments using
these corpora are described hereafter to highlight
the characteristics of the features and their differ-
ences, used in the experimental pipeline.
4 Features
Maximal repeats, motifs in (Ukkonen, 2009),
are based on the work of Ukkonen (2009) and
Kärkkäinen (2006). The algorithm is described in
Section 4.1 to explain the improvements discussed
in Section 4.2. Motifs are a way to represent each
substring of a corpus in a condensed manner. For
the detection of hapax legomena inside a set of
strings from their motifs, see the work of Ilie and
Smyth (2011).
4.1 Maximal Repeats in Strings
Maximal repeats are substring patterns of text with
the following characteristics: they are repeated
(motifs occur twice or more) and maximal (motifs
cannot be expanded to the left –left maximality–
nor to the right –right maximality– without lower-
ing the frequency).
For instance, the motifs found in the string S =
HATTIVATTIAA are T, A and ATTI. TT is not
a motif because it always occurs inside an occur-
rence of ATTI. In other words, its right-context is
always I and its left-context A. All the motifs in
a list of strings can be enumerated using an Aug-
mented Suffix Array (Kärkkäinen et al., 2006).
Given two strings S0 = HATTIV and S1 =
ATTIAA, Table 3 shows the Augmented Suffix
Array of S = S0.$1.S1.$0, where $0 and $1 are
lexicographically lower than any character in the
alphabet Σ and $0 < $1. The Augmented Suffix
Array consists in the Suffix Array (SA), suffixes
of S sorted lexicographically, with the Longest
Common Prefix (LCP ) between each two suffixes
that are contiguous in SA. With, n the size of S,
S[i] the ith character of S, S[n, m] a sample of S
from the nth character to the mth, SAi the start-
ing offset of the suffix of S at the ith position in
the lexicographical order and lcp(str1, str2) the
longest common prefix between two strings str1
and str2 :
LCPi = lcp(S[SAi, n− 1],S[SAi+1, n− 1])
LCPn−1 = 0
The LCP allows the detection of all the repeats
inside a set of text. The maximal criterion is still
not valid because the LCP only inquires on the
left maximality between repeated prefixes in SA.
i LCPi SAi S[SAi]...S[n]
0 0 13 $0
1 0 6 $1ATTIAA$0
2 1 12 A$0
3 1 11 AA$0
4 4 7 ATTIAA$0
5 0 1 ATTIV$1ATTIAA$0
6 0 0 HATTIV$1ATTIAA$0
7 1 10 IAA$0
8 0 4 IV$1ATTIAA$0
9 2 9 TIAA$0
10 1 3 TIV$1ATTIAA$0
11 3 8 TTIAA$0
12 0 2 TTIV$1ATTIAA$0
13 0 5 V$1ATTIAA$0
Table 3: Augmented Suffix Array (SA and LCP )
of S = HATTIV$1ATTIAA$0.
The substring ATTI occurs for example in S at
the offsets (1, 7), according to LCP4 in Table 3.
The process enumerates all the motifs by read-
ing through LCP . The detection of those motifs
is triggered according to the difference between a
LCP and the next one in the way SA is ordered.
For example, TTI is equivalent to ATTI be-
cause the last characters of these two motifs occur
at the offsets (4, 10). They are said to be in a rela-
tion of occurrence-equivalence (Ukkonen, 2009).
In that case, ATTI is kept as a motif because it is
the longest of its equivalents. The others motifs A
and T are maximal because their contexts differ in
different occurrences. All motifs across different
strings are detected at the end of the enumeration
by mapping the offsets in S with those in S0 and
S1. This way, any motif detected in S can be lo-
cated in any of the strings Si. SA and LCP are
constructed in time-complexity O(n) (Kärkkäinen
et al., 2006), while the enumeration process is
done in O(k), with k defined as the number of
motifs and k < n (Ukkonen, 2009). This corrob-
orate the statement done by Umemura and Church
(2009): there are too many substrings to work with
in corpus O(n2), but they can be grouped into a
manageable number of interesting classes O(n).
4.2 n-th Order Motifs
LetR be the set of motifs detected in the n strings
S = {S0, . . . ,Sn−1}, with |S| =
∑n
i=1 size(Si).
The set of motifsR is computed on the concatena-
tion of all strings Si: c(S) = S0$n−1 . . .Sn−1$0.
Second order motifs R2 in S are computed from
the concatenation of the set of m strings of R
(c(R) = R0$m−1 . . .Rm−1$0 with m < |S|,
66
and each Ri a motif in S). The set of n-th or-
der motifs is noted Rn. For instance, let c(S)
be HATTIV$1ATTIAA$0. The set of motifs R
from c(S) is a compound of the following motifs:
R = {ATTI,A,T}. The set of repeatsR2 consists
of the motifs T (twice in ATTI and once in T) and
A (once in ATTI and once in A).
FACT — The set of motifsRn is a subset ofRn−1.
REDUCTIO AD ABSURDUM — Let assume that Rn 6⊂
Rn−1. In other words, ∃m a motif with m ∈ Rn
and m 6∈ Rn−1. m is maximal, so it occurs
with different left-contexts (denoted a and b) and
different right-contexts (c and d) with a 6= b,
c 6= d and a, b, c and d being any character of
c(Rn−1) – including the special character £ if m
starts c(Rn−1). Rn is computed from c(Rn−1) =
...amc...bmd... with Rn−1 = {amc, bmd, ...}
and m 6∈ Rn−1. So, amc and bmd are two motifs
detected inRn−2. Because m is repeated and have
two differents contexts, it is a motif and should
have been detected inRn−2 thus inRn−1 as well,
so m ∈ Rn−1 — a contradiction
Figure 2 draws the number of different motifs
according to their order. Because Rn ⊂ Rn−1,
the number of different motifs decreases steadily
whatever the corpus. The number of motifs in
Rn drops to 0 for n = 26 (LIB-40, EBG-40 and
MIXT-80) and n = 25 (MIXT-40).
1 6 11 16 21 26
nu
m
b
e
r o
f d
iff
e
re
nt
  m
o
tif
s 
(lo
g
. s
c
a
le
)
i-th order of maximal repeats
Figure 2: Evolution of the number of motifs (log.
scale) according to the i-th order (LIB-40, EBG-
40, MIXT-40 and MIXT-80)
The computation of 2nd order motifs is based
on the same algorithm than the one used to extract
motifs. The enumeration of all the 2nd order mo-
tifs is done in O(n) as well. Those motifs are used
to detect the repetitions encapsulated in a set of
maximal repeats.
4.3 Exploiting the Differences between
Character n-grams and Motifs
Experiments have emphasize that redundancy in
n-grams have a positive impact in AA (Subsec-
tion 5.1). To explain the effect of this redundancy,
this section deals with the main differences be-
tween character n-grams and motifs, and how to
exploit them when dealing with vector-based rep-
resentation of texts. As defined before, motifs
are a condensed way to represent all substrings
of a corpus. In other words, for a fixed value of
n, the set of motifs of size n is a subset of all
the character n-grams of a corpus (as well with
variable length substrings: motifs with length in
[min, max] or character [min, max]-grams). The
substrings that are not motifs are those that are
only left-maximal, right-maximal (i.e. repeated
but not maximal) or hapax legomena. In a super-
vised classification process, hapax have no impact
because they only appear once in the training cor-
pus or once in the test corpus.
If n-grams can catch different types of features
according to n (lexical, contextual or thematic
(Sun et al., 2012)), they also catch features that
can be represented by substrings of size superior
to n. For instance, let abcdef be a motif, occur-
ring k times and none of its characters occurring
elsewhere in the corpus. Because abcdef is maxi-
mal, each substring of abcdef has the same occur-
rence frequency k. Figure 3 shows how the use
of 3-grams in a string containing the abcdef motif
affects the vector representation of this substring.
Indeed, n-grams “represent” motifs of size supe-
rior to n by adding features in the vector represen-
tation of the texts according to the frequency of
those motifs.
a b c d e f
ab
c bcd cde def
......
k k k k ...... ,,,
number of 3-grams: 4
vector representation
motif in string
features
]
]
]
]
Figure 3: Substrings of a motif in a string.
Exploiting only motifs of size 3 will not allow
to catch any substring of this motif with the same
occurrence frequency than abcdef (according to
the definition of a motif). Considering only some
specific lengths affect the representation based
on occurrence frequency, and vise versa accord-
ing to the interdependency between frequency and
length (Zipf, 1949).
67
2nd order motifs are used to exploit this charac-
teristic with this assumption: a substring is more
relevant than an other of same size if it encapsu-
lates less repeated substrings. The weight func-
tion w2nd(feat) is defined as the difference be-
tween the number of substrings of a feature and
the number of motifs occurring in this feature
w2nd(feat) = pot(feat)− sub(feat). pot(feat)
is the potential number of substrings occurring in-
side a feature. sub(feat) is the number of mo-
tifs occurring inside a feature and elsewhere in the
corpus. w2nd(feat) is linked to the length of the
feature and two features with the same length can
be weight differently. If there is only one differ-
ent character between two motifs (e.g. thing and
things), the weight function minimises this add:
the products of the weight function and the fre-
quency are close together. Conversely, a feature
that is more than a small variation of any other mo-
tif has more importance.
With S = {S0, . . . ,Sn−1}, R the set of motifs
from S andR2 the set of motifs fromR, each mo-
tif in R can be weighted according to the set of
repeats R2. Ri is a motif used as a feature and
S is the set each text of all authors. The num-
ber of different substrings in any string of size n,
pot(feat), is calculated with the formula n(n+1)2
(eq. to the triangular number, the whole string is
considered as a potential substring). The number
of occurrences of each sub-repeat inR2 occurring
in a feature R, sub(feat), is done by enumerat-
ing all the occurrences of all the motifs in a set of
strings as described in Section 4.1. If each poten-
tial substring in a feature is a motif as well, then
w2nd(feat) = 1. During our experiments, this
weight function is compared with wlength(feat)
= n(n+1)2 (with n the length of the feature). Note
that wlength cannot be easily applied to n-grams
because the overlaps between contiguous n-grams
make each potential substring of each n-gram ap-
pears elsewhere in the corpus.
5 Experiments
The experiments in this section examine the pre-
diction accuracy of the proposed approach. Two
sets of features with variable length are exam-
ined: n-grams and motifs. Three different ways
to consider motifs are analysed: motifs with no
weight, weighted by their length (using wlength)
and weighted by 2nd order repeats (using w2nd).
A stratified 10-fold cross validation is used to
validate the performances. Corpora are randomly
partitioned into 10 equal size folds containing the
same proportion of authors. To measure the per-
formance of the systems, the prediction score is
computed as follows: the number of correctly clas-
sified texts divided by the number of texts clas-
sified overall. SVM is used with linear kernels
(adapted when the set of features is larger than the
set of elements to be classified) and with the regu-
larisation parameter C = 1. The aim of those ex-
periments is to highlight the differences between
motifs and n-grams. The same settings are there-
fore set whatever the feature, assuming that their
impacts are similar on both n-grams and motifs.
5.1 Impact of the Length of Variable
Substrings and Maximal Repeats
The prediction score of AA is computed in three
corpora: EBG-40 (Figure 4), LIB-40 (Figure 5)
and MIXT-80 (Figure 6). Each figure is consti-
tuted of 4 matrices using different sets of fea-
tures: maximal repeats (motif ), n-grams, maxi-
mal repeats weighted by length (motiflength) and
maximal repeats weighted by 2nd order repeats
(motif2nd). The prediction written in the coordi-
nates (i, j) of each matrix is sourced from the use
of features with length in the range [i, j].
motifs (maximal repeats) n-grams
motifs (2nd order weight)motifs (length weight)
<
<
Figure 4: Prediction accuracy in EBG-40.
Whatever the corpus, the features can be or-
dered following their ability to correctly predict
the author of a text: motif ≤ motiflength <
n-grams < motif2nd . The fact that motifs <
n-grams shows the positive effect of feature redun-
dancy. The diagonals of the matrix using motif
and motiflength have the same values because a
single factor affects every feature on the vector
68
motifs (maximal repeats) n-grams
motifs (2nd order weight)motifs (length weight)
<
<
Figure 5: Prediction accuracy in LIB-40.
motifs (maximal repeats) n-grams
motifs (2nd order weight)motifs (length weight)
<
<
Figure 6: Prediction accuracy in MIXT-80.
representation of the texts. The overall high pre-
diction score on the EBG corpus is explained by
the bind between author and the thematic content
of his written productions (for a given author, al-
most each of his texts is related to a single topic as
sport or arts). For comparison, the systems tested
by Brennan et al. (2012) obtain a prediction ac-
curacy of approximately 80% in a sample of texts
written by 40 authors in EBG as well (≈ −15%).
The task is more difficult on LIB because, contrary
to EBG, each selected author has written texts
in different thematic areas. Similar observations
have been given by Stamatatos (2012) as well. The
prediction on the three corpora has also been com-
puted using motif2nd whatever their length, ob-
taining the following scores: 66.40% on EBG-40,
48.20% on LIB-40 and 54.21% MIXT-80. This
emphasizes the necessity of selecting a subspace
of motifs in AA. From these experiments, the best
parameters for the length of the features are se-
lected by computing the average of each predic-
tion score on each matrix for each couple of pa-
rameters [min, max] length (Table 4).
best length parameter average prediction
[min, max]
n-grams [4, 6] 84.61%
motifs [4, 6] 83.69%
motifs (length) [4, 6] 83.88%
motifs (2nd order) [4, 5] 85.39%
Table 4: Best parameters on LIB-40, EBG-40
and MIXT-80.
motif2nd features obtain the smallest range of
values among the set of parameters computed.
Note that the best length parameter extracted for
all the corpora is not necessarily the best parame-
ters for each corpus (i.e. motif2nd have better re-
sults with parameters [6, 6] in LIB than with [4, 5]).
Aside from offering a condensed representation
of substrings, motifs need less elements to per-
form better than other methods. The experiments
show better results with variable length features
than with fixed length ones. Using a large range
of size in substring selection is not systematically
the best option according to the results. For in-
stance, a 4.01% discrepancy is observable between
the range [1, 6] and the optimal range [4, 5] on the
results on LIB using motif2nd features (Figure 5).
5.2 Influence of the Number of Authors on
the Prediction and the Number of
Features
Given the best parameters for each type of features
(Table 4), the following experiments draw the evo-
lution of the prediction based upon the number of
authors (Figure 7).
Whatever the corpus and the type of features,
the prediction score decreases steadily as the num-
ber of author increases. The corpus with the
worst results is still LIB where the prediction
score decreases from 92.04% to 77.38% (89.60%
to 76.82% with n-grams). The prediction using
motif2nd is higher than with the others meth-
ods. Moreover, weighting features by a factor
of their length (motiflength) does not enhance
significantly motif -based representations of text.
The numbers of features used for the prediction
is given on Figure 8. This number of features is
the average of the length of the vector represent-
ing texts in each fold of the cross-validation.
Considering the motifs of length [4, 5] reduce
69
CorpusdLIB
CorpusdEBG
CorpusdMIXT
n-grams
motifsd(maximaldrepeats)
motifsd(weight.dlength)
motifsd(weight.d2nddorder)
Figure 7: Evolution of the prediction accuracy ac-
cording to the number of authors.
1062
1
1.5
0.5
106
2
1
1.5
0.5
1062
1
1.5
0.5
nu
m
be
rCo
fCd
iff
er
en
tCf
ea
tu
re
s
nu
m
be
rCo
fCd
iff
er
en
tCf
ea
tu
re
s
nu
m
be
rCo
fCd
iff
er
en
tCf
ea
tu
re
s
n-gramsC[4,6]
motifsCTmaximalCrepeats)
motifsC[4,5]
motifsC[4,6]
CorpusCLIB
CorpusCEBG
CorpusCMIXT
Figure 8: Evolution of the number of features ac-
cording to the number of authors.
considerably the number of features with regards
to the number of substrings with size [4, 6] or the
number of motifs of any size. The number of mo-
tifs grows linearly with the number of authors (i.e.
with the size of the corpus). The number of sub-
strings with length [4, 6] is higher than the number
of motifs at the beginning of the curve, but is lower
after a certain amount of data due to its sublinear
distribution. The number of motifs of size [4, 5]
seems to scale with the increase of data processed.
5.3 Monolingual Evaluation from
Multilingual Corpora
The corpus MIXT is composed of the LIB cor-
pus in French and the EBG corpus in English,
both languages share pattern substrings because of
their common origin. The use of two similar lan-
guages is well adapted to analyse the effects of the
features in multilingual corpora. Table 5 shows
the prediction accuracy on the two monolingual
corpora, LIB and EBG, after applying the above
methods on the multilingual corpus MIXT. The
aim is to analyse how the features behave when
different languages are processed at the same time.
Substrings with length in the range [4, 6]
nb. of authors EBG EBG LIB LIB
from MIXT from MIXT
10 98.75% 98.75% 89.60% 91.13%
20 97.20% 96.89% 83.15% 82.69%
30 95.79% 94.85% 79.34% 78.65%
40 95.40% 94.10% 76.82% 75.03%
Motifs weighted by 2nd order motifs with length in [4, 5]
nb. of authors EBG EBG LIB LIB
from MIXT from MIXT
10 98.75% 98.75% 92.01% 92.35%
20 97.83% 97.52% 83.77% 83.46%
30 95.59% 96.84% 80.93% 80.08%
40 95.40% 95.09% 77.38% 77.47%
Table 5: Predictions on LIB and EBG from the
MIXT corpus using substrings with length in [4, 6]
and motifs weighted by 2nd order motifs with
length in [4, 5].
The results with the two settings, the multilin-
gual corpus and each corpus processed indepen-
dently, are close to each other. However, some im-
provements can be seen with the use of motif2nd ,
where in more cases the results are better when
EBG and LIB are handled together. Using n-
grams, the difference of results grows when the
number of authors increases. On the contrary, us-
ing motifs seem to be adapted to this issue.
6 Conclusion
We proposed an efficient alternative to variable
length n-grams approaches for AA with the use of
maximal repeats in strings. They improve classi-
cal substring approaches in two major ways. First,
maximal repeats are, in essence, non-redundant
features compared with n-grams. Their maximal-
ity characteristic avoids the use of redundant oc-
currence equivalent substrings in corpora. This
considerably reduces the feature space size and we
advocate that they are a best breeding ground for
variable subset selection (as Genetic Algorithm,
Simulated Annealing, or Information Gain). Sec-
ond, with the second order maximal repeats, the
feature search space is condensed efficiently and
propose a new way to enhance the prediction ac-
curacy in AA. We have emphasize the positive ef-
fect of redundancy in features, and by doing so we
validated the assumption that a long repeated sub-
string is more important if it does not contain too
many sub-repeats, thus guaranteeing consistency.
We hope this research will herald more improve-
ments in substring-based Authorship Attribution.
70
References
Ahmed Abbasi and Hsinchun Chen. 2008.
Writeprints: A stylometric approach to identity-
level identification and similarity detection in
cyberspace. ACM Transactions on Information
Systems (TOIS), 26(2):7.
Emily M. Bender. 2009. Linguistically naı̈ve != lan-
guage independent: Why NLP needs linguistic ty-
pology. In Proceedings of the EACL 2009 Workshop
on the Interaction Between Linguistics and Compu-
tational Linguistics: Virtuous, Vicious or Vacuous?,
ILCL ’09, pages 26–32. ACL.
Michael Brennan, Sadia Afroz, and Rachel Green-
stadt. 2012. Adversarial stylometry: Circumvent-
ing authorship recognition to preserve privacy and
anonymity. ACM Transactions on Information and
System Security (TISSEC), 15(3):12.
Carole E Chaski. 2001. Empirical evaluations
of language-based author identification techniques.
Forensic Linguistics, 8:1–65.
Sara El Manar El Bouanani and Ismail Kassou. 2014.
Authorship analysis studies: A survey. Interna-
tional Journal of Computer Applications, 86:22–29.
Richard S Forsyth and David I Holmes. 1996. Feature-
finding for text classification. Literary and Linguis-
tic Computing, 11(4):163–174.
Jack Grieve. 2007. Quantitative authorship attribution:
An evaluation of techniques. Literary and linguistic
computing, 22(3):251–270.
Lucian Ilie and William F Smyth. 2011. Minimum
unique substrings and maximum repeats. Funda-
menta Informaticae, 110(1):183–195.
Gary Kacmarcik and Michael Gamon. 2006. Ob-
fuscating document stylometry to preserve author
anonymity. In Proceedings of the COLING/ACL
on Main conference poster sessions, pages 444–451.
Association for Computational Linguistics.
Juha Kärkkäinen, Peter Sanders, and Stefan Burkhardt.
2006. Linear work suffix array construction. Jour-
nal of the ACM, 53(6):918–936.
Moshe Koppel, Jonathan Schler, and Shlomo Arga-
mon. 2009. Computational methods in authorship
attribution. Journal of the American Society for in-
formation Science and Technology, 60(1):9–26.
Moshe Koppel, Jonathan Schler, and Shlomo Arga-
mon. 2011. Authorship attribution in the wild. Lan-
guage Resources and Evaluation, 45(1):83–94.
Fuchun Peng, Dale Schuurmans, Shaojun Wang, and
Vlado Keselj. 2003. Language independent author-
ship attribution using character level language mod-
els. In Proceedings of the tenth conference on Euro-
pean chapter of the Association for Computational
Linguistics-Volume 1, pages 267–274. Association
for Computational Linguistics.
Efstathios Stamatatos. 2006. Ensemble-based au-
thor identification using character n-grams. In Pro-
ceedings of the 3rd International Workshop on Text-
based Information Retrieval, pages 41–46.
Efstathios Stamatatos. 2009. A survey of modern au-
thorship attribution methods. Journal of the Ameri-
can Society for Information Science and Technology,
60(3):538–556.
Efstathios Stamatatos. 2012. On the robustness of au-
thorship attribution based on character n-gram fea-
tures. JL & Pol’y, 21:421.
Jianwen Sun, Zongkai Yang, Sanya Liu, and Pei Wang.
2012. Applying stylometric analysis techniques to
counter anonymity in cyberspace. Journal of Net-
works, 7(2).
Fiona J Tweedie, Sameer Singh, and David I Holmes.
1996. Neural network applications in stylometry:
The Federalist papers. Computers and the Humani-
ties, 30(1):1–10.
Esko Ukkonen. 2009. Maximal and minimal represen-
tations of gapped and non-gapped motifs of a string.
Theoretical Computer Science, 410(43):4341–4349.
Kyoji Umemura and Kenneth Church. 2009. Substring
statistics. In Computational Linguistics and Intelli-
gent Text Processing, pages 53–71. Springer.
George Kingsley Zipf. 1949. Human Behaviour and
the Principle of Least-Effort : an Introduction to Hu-
man Ecology. Addison-Wesley.
71
