 
N. Lavrač, L. Todorovski, and K.P. Jantke (Eds.): DS 2006, LNAI 4265, pp. 102 – 113, 2006. 
© Springer-Verlag Berlin Heidelberg 2006 
Identifying Historical Period and Ethnic Origin 
of Documents Using Stylistic Feature Sets 
Yaakov HaCohen-Kerner1, Hananya Beck1, Elchai Yehudai1, and Dror Mughaz1,2 
1 Department of Computer Science, Jerusalem College of Technology (Machon Lev) 
21 Havaad Haleumi St., P.O.B. 16031, 91160 Jerusalem, Israel 
{kerner, hananya, yehuday}@jct.ac.il, myghaz@cs.biu.ac.il 
2 Department of Computer Science, Bar-Ilan University, 52900 Ramat-Gan, Israel 
Abstract. Text classification is an important and challenging research domain. 
In this paper, identifying historical period and ethnic origin of documents using 
stylistic feature sets is investigated. The application domain is Jewish Law arti-
cles written in Hebrew-Aramaic. Such documents present various interesting 
problems for stylistic classification. Firstly, these documents include words 
from both languages. Secondly, Hebrew and Aramaic are richer than English in 
their morphology forms. The classification is done using six different sets of 
stylistic features: quantitative features, orthographic features, topographic fea-
tures, lexical features and vocabulary richness. Each set of features includes 
various baseline features, some of them formalized by us. SVM has been cho-
sen as the applied machine learning method since it has been very successful in 
text classification. The quantitative set was found as very successful and supe-
rior to all other sets. Its features are domain-independent and language-
independent. It will be interesting to apply these feature sets in general and the 
quantitative set in particular into other domains as well as into other. 
1   Introduction 
Text classification (TC) is the supervised learning task of assigning natural language 
text documents to one or more predefined classes (also called categories) [19]. The 
meaning of supervised in this definition is that all the documents in a training set are 
pre-assigned a class before the training process starts. 
TC is applied in many tasks, such as: clustering, document indexing, document fil-
tering, information retrieval (IR), information extraction (IE), word sense disambigua-
tion (WSD), text filtering, and text mining [13, 22]. Current-day TC presents 
challenges due to the large number of features present in the text set, their dependen-
cies and the large number of training documents. The main difficulty with having a 
large number of features is finding out if some of them are redundant so that they can 
be ignored. 
The most frequent TC task is to classify documents to one or more predefined 
categories according to their content. Another type of classification is stylistic classi-
fication, i.e.: classifying documents according to their author’s style. 
Classification according to categories is usually based on content words and collo-
cations. For instance, texts about economics are different from texts about army by 
 Identifying Historical Period and Ethnic Origin of Documents 103 
 
their content words and collocations. In contrast, stylistic classification is usually 
based on linguistic features, e.g.: Argamon et al [1] on news stories and Koppel et al 
[14] on gender. 
Hebrew-Aramaic documents present various interesting problems for stylistic clas-
sification. Firstly, these documents include words from both languages. Secondly, 
Hebrew and Aramaic are richer than English in their morphology forms. Thirdly, 
these documents include a relatively high rate of abbreviations [9]. 
The corpus that was analyzed in this paper includes responsa (answers written in 
response to Jewish legal questions) authored by rabbinic scholars. These documents 
are taken from a widespread variety of Jewish domains, e.g.: laws, holidays, customs, 
kosher food, economics and army. Each answer is based on both ancient Jewish writ-
ings and answers given by previous rabbinical authorities over the years. More so, 
arguments contradicting the author’s answer should also be referred to. The author 
should give an acceptable explanation to solve such arguments. 
In this research, the following classification tasks are investigated: Jewish ethnic 
origin of the authors (Sephardim or Ashkenazim) and / or historical period when the 
responsa were written. To the best of our knowledge, identifying the ethnic origin of 
documents’ authors using stylistic feature sets is the first proposed. 
The proposed model chooses the best combination of sets of stylistic features. The 
results are rather successful for all investigated classification tasks. The quantitative 
feature set was found as very successful and superior to all other sets. Its features are 
language-independent and domain-independent. In addition, this research can yield 
results of great use to scholars in the humanities, e.g.: identifying the differences in 
writing-style, culture and customs between writers who belong to different ethnic 
origin and / or historical period. 
This paper is organized as follows: Section 2 gives background concerning the He-
brew and Aramaic languages. Section 3 describes previous classification of Hebrew-
Aramaic texts. Section 4 presents feature sets for classification. Section 5 describes 
the proposed model. Section 6 presents the results of the experiments and analyzes 
them. Section 7 concludes and proposes future directions. 
2   The Hebrew and the Aramaic Languages 
2.1   The Hebrew Language 
Hebrew is a Semitic language. It uses the Hebrew alphabet and it is written from right 
to left. Hebrew words in general and Hebrew verbs in particular are based on three 
(sometimes four) basic letters, which create the word's stem. The stem of a Hebrew 
verb is called pl1,2 ( פעל,  “verb”). The first letter of the stem p (פ) is called pe hapoal; 
the second letter of the stem  (ע) is called ayin hapoal and the third letter of the stem l 
                                                          
1 The Hebrew Transliteration Table that has been used in this paper, is taken from the web site 
of the Princeton university library. 
2 In this Section, each Hebrew word is presented in three forms: (1) transliteration of the He-
brew letters written in italics, (2) the Hebrew letters, and (3) its translation into English in 
quotes. 
104 Y. HaCohen-Kerner et al. 
 
 is called lamed hapoal. The names of the letters are especially important for the (ל)
verbs' declensions according to the suitable verb types. 
Except for the word’s stem, there are other components which create the word’s 
declensions, e.g.: conjugations, verb types, subject, prepositions, belonging, object 
and terminal letters. In Hebrew, it is impossible to find the declensions of a certain 
stem without an exact morphological analysis based on these features, as follows: 
Conjugations: The Hebrew language contains seven conjugations that include the 
verb’s stem. The conjugations add different meanings to the stem such as: active, pas-
sive, cause, etc. For example the stem hrs ( הרס,  “destroy”) in one conjugation hrs 
means destroy but in another conjugation nhrs ( נהרס,  “being destroyed”). 
Verb types: The Hebrew language contains several verb types. Each verb type is a 
group of stems that their verbs are acting the same form in different tenses and differ-
ent conjugations. There is a difference in the declensions of the stem in different verb 
types. In English, in order to change the tense, there is a need to add only one or two 
letters as suffixes. However, In Hebrew, for each verb type there is a different way 
that the word changes following the tense. 
To demonstrate, we choose two verbs in past tense of different verb types: (1) ktv 
( כתב,  “wrote”) of the shlemim verb type (strong verbs - all three letters of the stem are 
apparent), and (2) the word nfl ( נפל,  “fell”) of the hasrey_pay_noon verb type (where 
the first letter of the stem is the letter n and in several declensions of the stem this 
letter is omitted). When we use the future tense, the word ktv ( כתב,  “wrote”) will 
change to ykhtv ( יכתב,  “will write”) while the second word nfl will change to ypl ( יפל,  
“will fall”) which does not include the letter n. Therefore, in order to find the right 
declensions for a certain stem, it is necessary to know from which verb type the stem 
comes from. 
Subject: Usually, in English we add the subject as a separate word before the verb. 
For example: I ate, you ate; where the verb change is minimal if at all. However, in 
Hebrew the subject does not have to be a separated word and it can appear as a suffix.  
Prepositions: Unlike English, which has unique words dedicated to expressing rela-
tions between objects (e.g.: at, in, from), Hebrew has 8 prepositions that can be writ-
ten as a concatenated letter at the beginning of the word. Each letter expresses another 
relation. For example: (1) the meaning of the letter v (ו) at the beginning of word is 
identical to the meaning of the word “and” in English and (2) the meaning of the letter 
l (ל) at the beginning of word is similar to the English word “to”. 
Belonging: In English, there are some unique words that indicate belonging (e.g.: my, 
his, her). This phenomenon exists also in Hebrew. In addition, there are several suf-
fixes that can be concatenated at the end of the word for that purpose. The meaning of 
the letter y (י) at the end of word is identical to the meaning of the word “my” in Eng-
lish. For example, the Hebrew word ty (עטי) has the same meaning as the English 
words “my pen”. 
Object: In English, there are some unique words that indicate the object in the sen-
tence, such as: him, her, and them. This is also the case in Hebrew. In addition, there 
are several letters that can be concatenated at the end of the word for that purpose. 
The letter v (ו) at the end of a word has the same meaning as the word him in English. 
For example, the Hebrew word r’ytyv (ראיתיו) has the same meaning as the English 
words “I saw him”. 
 Identifying Historical Period and Ethnic Origin of Documents 105 
 
Terminal letters: In Hebrew, there are five letters: m (מ), n (נ),  ts (צ), p (פ),  kh (כ) 
which are written differently when they appear at the end of word: m (ם), n (ן),  ts (ץ), 
p (ף),  kh (ך)  respectively. For example, the verb ysn (ישן, “he slept”) and the verb 
ysnty (ישנתי, “I slept”). The two verbs have the same stem ysn, but the last letter of 
the stem is written differently in each one of the verbs. 
The English language is richer in its vocabulary than Hebrew. The English lan-
guage has about 40,000 stems while Hebrew has only about 3,500 and the number of 
lexical entries in the English dictionary is 150,000 compared with only 35,000 in the 
Hebrew dictionary [3]. 
However, the Hebrew language is richer in its morphology forms. The Hebrew 
language has 70,000,000 valid (inflected) forms while English has only 1,000,000 [3]. 
For instance, the single Hebrew word וכשיכוהו is translated into the following se-
quence of six English words: “and when they will hit him”. 
In Hebrew, there are up to seven thousand declensions for only one stem, while in 
English there is only a few declensions. For example, the English word eat has only 
four declensions (eats, eating, eaten and ate). The relevant Hebrew stem אכל (eat) has 
thousands of declensions. 
Hebrew in general is very rich in its vocabulary of abbreviations. The number of 
Hebrew abbreviations is about 17,000 not including unique professional abbrevia-
tions, relatively high comparing to 40,000 lexical entries in the Hebrew language. 
About 35% of them are ambiguous. That is, about 6000 abbreviations have more than 
one possible extension for each abbreviation in particular contain a high frequency of 
abbreviations. Moreover, Jewish Law articles written in Hebrew-Aramaic include a 
high rate of abbreviations. About 20% of all the words in the documents, while more 
then one third of them (about 8%) are ambiguous. 
2.2   The Aramaic Language 
Aramaic is another Semitic language. It is particularly closely related to Hebrew, and 
was written in a variety of alphabetic scripts. Aramaic was the language of Semitic 
peoples throughout the ancient Near East. It is spoken for at least three thousand 
years. Aramaic is still spoken today in its many dialects, especially among the Chal-
deans and Assyrians. (more details can be found in [27]). 
Although Aramaic and Hebrew have much in common, there are several major dif-
ferences between them. The main difference in grammar is that while Hebrew uses 
aspects and word order to create tenses, Aramaic uses tense forms. Another important 
difference is that there are several types of changes in one particular letter in many 
words. In some cases a Hebrew prefix is replaced in Aramaic by a suffix. More details 
can be found in Melamed [18]. 
3   Previous Classification of Hebrew-Aramaic Texts 
Automatic classification of Hebrew-Aramaic texts is almost an uninvestigated research 
domain. CHAT, a system for stylistic classification of Hebrew-Aramaic texts is presented 
in [15, 16, 20]. It presents applications of several TC tasks to Hebrew-Aramaic texts: 
106 Y. HaCohen-Kerner et al. 
 
1. Which of a set of known authors is the most likely author of a given docu-
ment of unknown provenance?  
2. Were two given corpora written/edited by the same author or not? 
3. Which of a set of documents preceded which and did some influence others? 
4. From which version (manuscript) of a document is a given fragment taken? 
CHAT uses as features only single words, prefixes and suffixes. It uses simple ML 
methods such as Winnow and Perceptron. Its datasets contain only a few hundreds of 
documents. CHAT does not investigate the various tasks proposed at the end of Section 1. 
Classification of Biblical documents has been done by Radai [24, 25, 26]. How-
ever, he did not implement any ML method. 
4   Classification Features 
Various kinds of stylistic features have been proposed during the years. For example: 
Quantitative features such as word and sentence length and punctuation–signs pro-
posed by Yule [34]. Function words (e.g.: are, at, is, of, on, then and will) proposed 
by Mosteller and Wallace [21]. 
Many kinds of stylistic features have been applied for automatic classification of 
documents. Karlgren and Cutting [12] developed 20 features that belong to the three 
following sets: POS counts (e.g.: noun and adverb), lexical counts (e.g.: “that” and 
“we”), and textual counts (e.g.: characters per word and words per sentence). A set of 
orthographic features (abbreviations, acronyms, various spellings of the same words) 
has been proposed by Friedman [7]. Stamatatos et al [30] applied syntactic features 
(e.g.: frequencies and distribution of parts of speech tags, such as: noun, verb, adjec-
tive, adverb; basic syntactic sequences, such as noun-adjective and subject-verb rela-
tions and active and passive sentences). 
Lim et al [17] used five different sets of features for automatic genre classification 
of web documents. Two of them were web-oriented: URL tags (e.g.: depth of URL, 
document type and domain area), and HTML tags (frequencies of various types of 
links). The other three sets were token information (e.g.: average number of charac-
ters per word and average number of words per sentence), lexical information (e.g.: 
frequency of content words, frequency of function words and frequency of punctua-
tion marks) and structural information (e.g.: number of declarative sentences and 
number of question sentences).  
5   The Proposed Model 
As mentioned at Section 1, Hebrew-Aramaic documents present interesting problems 
for stylistic classification. Therefore, methods already used in text classification re-
quire adaptation to handle these problems. Firstly, the definition of suitable feature 
sets is required. Secondly, the proper combination of feature sets is needed to be in-
vestigated for a variety of classification experiments. 
 Identifying Historical Period and Ethnic Origin of Documents 107 
 
5.1   Feature Sets for Classification of Hebrew-Aramaic Texts 
Several sets of linguistic features mentioned previously found to be applicable for this 
research. Unfortunately, no parts-of-speech tagger for Hebrew was available to us. 
Therefore, neither morphological features (e.g.:  adjectives and verbs) nor syntactic 
features (frequencies and distribution of parts of speech tags, such as: noun, verb, ad-
jective, adverb) are used. 
Forty two baseline stylistic features appropriate for Hebrew-Aramaic texts have been 
defined and programmed. All features are normalized by the number of words in docu-
ment. Features regarding sentences have two versions (relating or not relating to a 
comma as an end of a sentence). These features are detailed in the six following sets: 
1. Lexical features: normalized frequencies of 958 religious help words (e.g.: bible, 
responsa, rabbi), 533 general help words (e.g.: of, at, on, no), both religious and 
general help words and 307 summarization words (e.g.: conclusion, to conclude, 
summary, to sum up). 
2. Orthographic features: normalized frequencies of acronyms and abbreviations. 
3. Topographic features: first n (10, 20) words, last n words, first n/2 words and last 
n/2 words, words in first n (2, 4) sentences, words in last n sentences, words in 
first n/2 sentences and words in last n/2 sentences, words in first n (1, 2) para-
graphs, words in last n paragraphs, words in first n/2 paragraphs and words in last 
n/2 paragraphs. 
4. Quantitative features: average number of characters in a word / sentence / para-
graph / file, average number of words in a sentence / paragraph / file, average 
number of sentences in a paragraph / file, average number of paragraphs in a file, 
and average number of punctuation-signs (e.g.: !. ?, :, ;) in a file. 
5. Function features: normalized frequencies of sentences appeared in brackets and 
normalized frequency of 11 pronouns (e.g.: I, we, you, he, she). 
6. Vocabulary’s richness: size of author’s vocabulary in words. 
The lexical, orthographic and pronoun features are domain-dependent and language-
dependent. They have been especially fitted to the Hebrew and Aramaic languages. Dic-
tionaries containing religious help words, general help words, summarization words, 
abbreviations and acronyms have been built. Moreover, they have been combined with 
various kinds of prepositions, belonging, terminal letters, etc.  The quantitative, function 
and vocabulary’s richness features are domain-independent and language-independent. 
In order to find the best combination of sets for any particular classification task, 
one should try all possible combinations of sets. One of the known properties of the 
binomial coefficients is that the total number of distinct k-subsets on a set of n ele-
ments (i.e., the number of possible subsets) is ∑ ⎟⎟
⎠
⎞
⎜⎜
⎝
⎛
=
n
k k
n
0
 = n2  where a k-subset is a 
subset of a set on n elements containing exactly k elements. 
In this research, there are six feature sets. That is, there are only 26 = 64 combinations 
(including the empty set). The combination with the highest classification rate is selected. 
Investigating whether the accuracy can be improved if the feature selection process will 
be applied to every single feature not to entire feature set is left for future research. 
108 Y. HaCohen-Kerner et al. 
 
5.2   Support Vector Machines 
Various machine learning methods have been applied for TC [29], e.g.: Naïve Bayes 
[28], C4.5 [8] and Winnow [15, 16, 20]. 
However, the Support Vector Machines (SVM) method [4, 31] has been chosen to be 
applied in this model since it seems to be the most successful for TC [5, 6, 10, 11, 33]. 
There are various variants of SVMs. One simple and fast method is Sequential Minimal 
Optimization (SMO) developed by Platt [23]. In this setting multi-class problems are 
solved using pairwise classification. 
6   Experimental Results 
To test the accuracy of the model, the 5-fold cross-validation is used. The SVM ap-
plied version was the SMO implementation of Weka [32] using a linear kernel, de-
fault values and no feature normalization. Model tuning is left for future research. 
Three experiments have been applied on each one of two different data sets. These 
data sets include responsa that were downloaded from The Global Jewish Database 
(The Responsa Project3) at Bar-Ilan University. As mentioned above, these documents 
are taken from a widespread variety of domains relevant to Jewish life, e.g.: laws, 
holidays, customs, kosher food, economics and army. 
The history of Jewish responsa covers a period of 1,700 years. The responsa in-
vestigated in this research were authored by Sephardic rabbis (Mediterranean) and 
Ashkenazic rabbis (eastern or central Europe) in the last 500 years (16th - 20th cen-
turies). This era is called the Acharonim era. Acharonim (אחרונים) literally "the 
later ones", is a term used in Jewish law and history, to signify the leading rabbis 
living from roughly the 16th century to the present. The experts in the responsa 
domain think that the 20th century’s responsa are much different from the previous 
ones for various reasons. In the 20th century there were major changes in the world 
in general and in the Jewish world in particular. Jewish rabbis from different ethnic 
origin (Sephardim and Ashkenazim) met each other. Some of them even immi-
grated to live within the communities of the other ethnic origin. Since the means of 
communication have developed so much Jewish rabbis read much more responsa 
written by other rabbis including from the other ethnic origin, and were influenced 
to one degree or another. 
The accuracy that was measured in all experiments is the fraction of the number of 
documents correctly classified to the total number of possible documents to be classified. 
6.1   Experiment # 1 
The data set is a collection of 10,504 responsa authored by 60 Jewish rabbinic schol-
ars, with about 175 documents for each scholar. These scholars belong to the two ma-
jor Jewish ethnic groups (Sephardim and Ashkenazim). The responsa were written in 
the 16th - 20th centuries either. The total number of words in all files is about 18.5M 
words, while a document contains on average about 1763 words. 
                                                          
3 http://www.biu.ac.il/ICJI/Responsa 
 Identifying Historical Period and Ethnic Origin of Documents 109 
 
This dataset can be classified into three different classifications: (1) ethnic Jewish 
groups (Sephardim or Ashkenazim) of their authors, (2) historical period when they 
were written (in the 16th - 19th centuries or in the 20th century) and (3) combination of 
classification (according to ethnic and time). For each classification task the dataset 
was divided into equal-sized suitable categories. That is the number of documents in 
the positive and in the negative sets is the same in each sub-experiment. The main 
results of all these three sub-experiments are presented in Table 1. 
Table 1. Classification results of Dataset # 1 
 
The first / second / third results’ rows in Table 1 present the results of the classifi-
cation to ethnic / time / both ethnic and time, respectively. The first results’ row de-
scribes the classification according to the Jewish ethnic groups (Sephardim or 
Ashkenazim).  The second results’ row describes the classification according to the 
two historical periods when the responsa were written (Old or New). The last results’ 
row describes the classification to the four possible categories (Old  Sephardim, Old 
Ashkenazim, New Sephardim and New Ashkenazim). 
In all sub-experiments, the best result by a unique set was always achieved by the 
quantitative set. The best result achieved by a combination of feature sets was 
achieved by a combination of all / almost all sets.  
Several general conclusions can be drawn from Table 1: 
1. All three classification tasks were highly successful. 
2. The quantitative set (set # 4) was superior to all other sets and in the first two 
experiments it was enough for an excellent classification. 
3. Only in the last sub-experiment, the most complex one (both ethnic and time), 
there is a meaningful contribution of other sets to the quantitative set. 
4. The more complex is the classification task, the lowest classification results we 
achieve. 
5. The lexical (# 1) and function (# 5) sets achieve reasonable results and are al-
ways part of the best combination of sets. 
6. The orthographic, topographic and the vocabulary richness sets were rather 
poor, especially the last one. 
7. The more relevant features we use the higher results we achieve. 
8. The low values of the standard deviations indicate that the classification results 
are stable.  
110 Y. HaCohen-Kerner et al. 
 
6.2   Experiment # 2 
The second experiment is similar to the previous one, but now applied on a larger 
dataset containing responsa written only in the 19th and 20th centuries. This dataset 
includes 12,020 responsa authored by 48 Jewish rabbinic scholars, with about 250 
documents for each scholar. These scholars belong to the two major Jewish ethnic 
groups (Sephardim or Ashkenazim). The responsa were written in the 19th and 20th 
centuries). The total number of words in all files is about 19M words, while a docu-
ment contains on average about 1579 words. 
This dataset can be also classified into three classifications: (1) ethnic Jewish 
groups (Sephardim or Ashkenazim), (2) historical period when they were written (in 
the 19th century or in the 20th century) and (3) ethnic / time. For each classification 
task the dataset was divided into equal-sized suitable categories. That is, the number 
of documents in the positive and in the negative sets is the same in each sub-
experiment. Table 2 presents the main results of all three sub-experiments. 
Table 2. Classification results of Dataset # 2 
 
In general, the explanations to Table 2 and the results presented in it are very simi-
lar to the explanations and results described for Table 1. The same general conclu-
sions that were drawn there can be also drawn from Table2. 
In both experiments, in the first two classifications (ethnic only and time only) it 
seems that the classification performance when the quantitative feature set is applied 
is highly successful and almost the same as the classification performance when all 
(or almost all) feature sets are used. This is not really surprising - the SVMs are 
known to be robust with respect to irrelevant features. Only in the last sub-
experiment, the most complex one (both ethnic and time), there is a meaningful con-
tribution of other sets to the quantitative set. 
Due to limitations of space, we cannot detail the differences in writing-style be-
tween writers who belong to different ethnic groups and / or different historical  
periods. However, it is interesting to mention that among the most successful features 
we can find the following quantitative features:  
(1) Average number of punctuation-signs in a file - 
      Sephardim use much more punctuation-marks than Ashkenazim and  
      New authors use much more punctuation-marks than Old authors 
 
 Identifying Historical Period and Ethnic Origin of Documents 111 
 
(2) Average number of characters/words in a sentence - 
      Ashkenazim use much more characters/words in a sentence than Sephardim 
      Old authors use much more characters/words in a sentence than New authors 
Such findings can yield results of great use to scholars in the humanities who want 
to identify the differences in writing-style between writers who belong to different 
ethnic groups and / or different historical periods. 
7   Conclusions and Future Work 
In this paper, identifying historical period and ethnic origin of documents using stylis-
tic feature sets is investigated. To the best of our knowledge, identifying the ethnic 
origin of documents’ authors using stylistic feature sets is the first proposed. 
The application domain is Jewish Law articles written in Hebrew-Aramaic. Such 
documents present various interesting problems for stylistic classification. Firstly, 
these documents include words from both languages. Secondly, Hebrew and Aramaic 
are richer than English in their morphology forms.  
All three classification tasks were highly successful. The quantitative feature set 
was superior to all other sets and in the first two experiments it was enough for an 
excellent classification. Only in the last sub-experiment, the most complex one (both 
ethnic and time), there is a meaningful contribution of other sets to the quantitative 
set. The more complex is the classification task, the lowest classification results we 
achieve. The more relevant features we use the higher results we achieve. The ortho-
graphic, topographic and the vocabulary richness sets were rather poor, especially the 
last one.  
Many features proposed in this research in general and the quantitative features in 
particular are language-independent and domain-independent. 
It will be interesting to compare these results to the results of the same classifica-
tion tasks based on language-dependent and domain-dependent feature sets. 
It will be also interesting to apply these stylistic feature sets in general and the 
quantitative set in particular into other domains as well as into other languages. 
Another relevant future research would be to apply a co-training-like algorithm [2] 
based "views" created from various types of features. This may both increase accu-
racy and reduce the amount of documents needed for training. 
Other general research proposals are: (1) Investigating whether the accuracy can be 
improved if the feature selection process will be applied to every single feature (2) 
Investigating other features and other machine learning techniques that might improve 
classification.  
Concerning feature sets there are various potential research directions. For exam-
ple: (1) Which feature sets are good for which classification tasks? (2) What are the 
specific reasons for sets to perform better or worse on different classification tasks? 
(3) What are the guidelines to choose the correct sets for a certain classification task? 
Acknowledgements. The authors thank two anonymous reviewers for their fruitful 
comments. 
112 Y. HaCohen-Kerner et al. 
 
References 
1. Argamon-Engelson, S., Koppel, M., Avneri, G.: Style-based text categorization: What 
newspaper am I reading? Proceedings of the AAAI Workshop on Learning for Text Cate-
gorization (1998) 1-4 
2. Blum, A., Mitchell, T.: Combining Labeled and Unlabeled Data with Co-Training Pro-
ceedings of the Conference on Computational Learning Theory (COLT), (1998) 92–100 
3. Choueka, Y., Conley, E. S., Dagan, I.:  A comprehensive bilingual word alignment system: 
application to disparate languages - Hebrew, English, in J. Veronis (Ed.), Parallel Text 
Processing, Kluwer Academic Publishers, (2000) 69–96 
4. Cortes, C., Vapnik, V.: Support-Vector Networks. Machine Learning, 20 (1995) 273-297 
5. Díaz, I., Ranilla, J., Montañés, E., Fernández, J., Combarro, E. F.: Improving performance 
of text categorization by combining filtering, supportvector machines. JASIST 55(7) 
(2004) 579-592 
6. Dumais, S., Platt, J., Heckerman, D., Sahami, M.: Inductive Learning Algorithms, Repre-
sentations for Text Categorization. in Proceedings of the 7th ACM International Confer-
ence on Information, Knowledge Management (CIKM), Bethesda, MD (1998) 148-155 
7. Friedman, S.: The Manuscripts of the Babylonian Talmud: A Typology Based Upon 
Orthographic and Linguistic Features. In: Bar-Asher, M. (ed.) Studies in Hebrew and 
Jewish Languages Presented to Shelomo Morag (in Hebrew), Jerusalem (1996) 163-190  
8. Gabrilovich, E., Markovitch, S.: Text categorization with many redundant features: using 
aggressive feature selection to make SVMs competitive with C4.5. Proceedings of the 21 
Int. Conference on Machine Learning ICML (2004) 321-328 
9. HaCohen-Kerner, Y., Kass, A., Peretz, A.: Baseline Methods for Automatic Disambigua-
tion of Abbreviations in Jewish Law Documents, Proceedings of the 4th International Con-
ference on Advances in Natural Language Processing, EsTal 2004, Lecture Notes in 
Artificial Intelligence 3230, Berlin: Springer-Verlag, (2004) 58-69 
10. Joachims, T.: Text Categorization with Support Vector Machines: Learning with Many 
Relevant Features. In Proceedings of the 10th European Conference on Machine Learning 
(ECML), Chemnitz, Germany, (1998) 137-142 
11. Joachims, T.: Learning to Classify Text using Support Vector Machines. Kluwer (2002) 
12. Karlgren, J., Cutting, D.: Recognizing Text Genres with Simple Metrics Using 
Discriminant Analysis''. In Proceedings of the 15th International Conference on 
Computational Linguistics, Kyoto, Japan, 2, (1994) 1071-1075 
13. Knight, K.: Mining online text. Commun. ACM 42, 11 (1999) 58–61 
14. Koppel, M., Argamon, S., Shimony A. R.: Automatically categorizing written texts by 
author gender, Literary, Linguistic Computing 17, 4 (2002) 401-412 
15. Koppel, M., Mughaz D., Schler J.: Text categorization for authorship verification in Proc. 
8th Symposium on Artificial Intelligence, Mathematics, Fort Lauderdale, FL (2004) 
16. Koppel, M., Mughaz D., Akiva N.: New Methods for Attribution of Rabbinic Literature, 
Hebrew Linguistics: A Journal for Hebrew Descriptive, Computational, Applied Linguis-
tics, Bar-Ilan University Press (2006) 57: v-xviii 
17. Lim, C. S., Lee K. J., Kim G-C.: Multiple sets of features for automatic genre 
classification of web documents. Inf. Process. Manage. 41(5) (2005) 1263-1276 
18. Melamed, E. Z.: Aramaic-Hebrew-English Dictionary, Feldheim (2005) 
19. Meretakis, D., Wuthrich, B.: Extending Naive Bayes Classifiers Using Long Itemsets. In 
Proc. 5th ACM-SIGKDD Int. Conf. Knowledge Discovery, Data Mining (KDD'99), San 
Diego, USA, (1999) 165-174 
 Identifying Historical Period and Ethnic Origin of Documents 113 
 
20. Mughaz, D. Classification Of Hebrew Texts according to Style, M.Sc. Thesis (in Hebrew), 
Bar-Ilan University, Ramat-Gan, Israel (2003) 
21. Mosteller, F., Wallace, D. L.: Inference and Disputed Authorship: The Federalist. Reading, 
Mass. : Addison Wesley (1964) 
22. Pazienza, M. T., ed. Information Extraction. Lecture Notes in Computer Science, Vol. 
1299. Springer, Heidelberg, Germany (1997) 
23. Platt, J. C.: Fast training of support vector machines using sequential minimal optimiza-
tion, in Advances in Kernel Methods - Support Vector Learning, (Eds) B. Scholkopf, C. 
Burges,, A. J. Smola, MIT Press, Cambridge, Massachusetts, chapter 12, (1999) 185-208 
24. Radai, Y.: Hamikra haMemuchshav: Hesegim Bikoret uMishalot (in Hebrew), Balshanut 
Ivrit, 13 (1978) 92-99 
25. Radai, Y.: Od al Hamikra haMemuchshav (in Hebrew), Balshanut Ivrit 15 (1979) 58-59 
26. Radai, Y.: Mikra uMachshev: Divrei Idkun (in Hebrew), Balshanut Ivrit 19 (1982) 47-52 
27. Rosenthal, F.: Aramaic Studies During the Past Thirty Years, The Journal of Near Eastern 
Studies, Chicago (1978) 81-82 
28. Schneider, K. M.: Techniques for Improving the Performance of Naive Bayes for Text 
Classification. Proceedings of the 6th International Conference, CICLing 2005, Lecture 
Notes in Computer Science 3406 Springer, ISBN 3-540-24523-5 (2005) 682-693  
29. Sebastiani, F.: Machine learning in automated text categorization, ACM Computing 
Surveys 34 (1) (2002) 1-47 
30. Stamatatos, E., Fakotakis N., Kokkinakis, G.: Computer-based authorship attribution 
without lexical measures, Computers and the Humanities, 35 (2001) 193-214 
31. Vapnik, V. N. The Nature of Statistical Learning Theory. Springer-Verlag, NY, USA, 
ISBN 0-387-94559-8 (1995) 
32. Witten, I. H., Frank, E.: Weka 3: Machine Learning Software in Java: 
http://www.cs.waikato.ac.nz/~ml/weka (1999) 
33. Yang, Y., Liu, X.: A Re-examination of Text Categorization Methods. in Proceedings of 
the 22nd ACM International Conference on Research, Development in Information Re-
trieval (SIGIR), Berkeley, CA (1999) 42-49 
34. Yule, G.U.: On Sentence Length as a Statistical Characteristic of Style in Prose with 
Application to Two Cases of Disputed Authorship, Biometrika, 30 (1938) 363-390 
