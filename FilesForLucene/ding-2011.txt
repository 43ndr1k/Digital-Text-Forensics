B.-L. Lu, L. Zhang, and J. Kwok (Eds.): ICONIP 2011, Part III, LNCS 7064, pp. 113–120, 2011. 
© Springer-Verlag Berlin Heidelberg 2011 
User Identification for Instant Messages 
Yuxin Ding, Xuejun Meng, Guangren Chai, and Yan Tang 
Harbin Institute of Technology Shenzhen Graduate School, Shenzhen 518055, China 
yxding@hitsz.edu.cn, {xjmeng,grchai,ytang}@hotmail.com  
Abstract. In this paper we study on recognizing user’s identity based on instant 
messages. Considering the special characteristics of chatting text, we mainly 
focus on three problems, one is how to extract the features of chatting text, the 
second is how the user’s model is affected by the size of training data, and the 
third is which classification model is fit for this problem. The chatting corpus 
used in this paper is collected from a Chinese IM tool and different feature 
selection methods and classification models are evaluate on it.  
Keywords: Authorship, identification, classification, instant message.  
1   Introduction 
The goal of this paper is to determine whether an instant message is sent by the real 
sender indicated by the sender’s ID. It belongs to the field of authorship verification. 
Authorship verification is used to determine whether an author (for whom we have of 
a corpus of writ-ing samples) is also the author of a given anonymous text. Usually it 
can be viewed as a multi-class, single-label text categorization from the point of the 
machine learning. 
With the wide application of instant messaging tools, instant messaging (IM) has 
become the most popular way of communication through internet. Unfortunately, this 
is also the reason why IM becomes a popular object to be attacked by hackers. Once 
an IM account is stolen by a hacker, the hacker can then send fraudulent messages to 
the victims’ friends in the name of the victim. This brings the users of IM a serious 
security risk. Therefore, it is a meaningful work to verity the identity of an instant 
message sender. Currently as what we know, no similar research has been done in this 
field.  
2   Related Work 
2.1   Verification Problem 
Some researchers look authorship verification as ‘similarity detection’ task, which 
determine whether they are generated by the same entity or not, without knowing the 
actual author. Pavelec[1] used this way to address the writer independent model 
which is possible to create a robust system even when few genuine samples per writer 
114 Y. Ding et al. 
are available. Following the same notion of verification, Van Halteren[2] has 
proposed a relatively different method called linguistic profiling.  
There is another group of researchers who look the authorship verification as two-
class text classification problem. For example, writer dependent or personal model 
adopted by [1] is based on one model per author. However, it is implemented using 
one-against-all strategy which means that positive examples and negative examples 
are all required to create this model. Luyckx and Daelem[3] also applied this kind 
“one vs. all” scheme to analyze the contribution of each kind of features.  
Koppel & Schler[4] considered authorship verification as a one-class classification 
problem, and ‘unmasking’ method is proposed for authorship verification. However, 
this method needs long texts. 
2.2   Features 
Authorship analysis is based on the hypothesis: every author has the writing habit of 
his own, and this habit is defined in terms of different features. Usually two types of 
feature are employed, one is content-based features, and the other is stylometric 
features. 
1. content-based features is relevant to a specific subject, if we want to determine 
the author of an anonymous text in a specific subject, this feature has been proved to 
be efficiently [5]. 2. stylometric features include three types of features: token-based 
feature, syntax feature and structural features. 
Token-based features can be either word-based or character-based features. Word-
based features include word length, sentence length [6], word frequency [7], word n-
gram [8],  and vocabulary richness[9]. Character-based features include alphabetic 
characters count, uppercase and lowercase characters count ,digit characters count,  
letter frequencies, and punctuation marks count [9][10][11]. The most efficient 
feature of this measure is n-gram feature, and the application of this approach to 
authorship identification has been proven quite successful [7][12][13][14]. 
Syntax features, including function words [5][15][16][17], punctuations, and part 
of speech [18][19], can capture the writing style in sentence level, it is considered 
more reliable authorial features in comparison to the token-based features. Among 
them, function words are the best features to discriminate between authors.  
Structural features which are applied to handle the layout and organization of a 
piece of writing have proved particularly important in analyzing online texts [9]. It 
includes the number of paragraphs or sentences, the average length of the paragraph, 
as well as some word structure. Similar features are introduced to the chat mining for 
gender prediction and authorship characterization problem [20][21]. 
Most of works mentioned above experimented with the literatures. However, the 
style of IM messages is very different from them. The real time nature of IM message 
produces unedited text; they are relatively casual compared with formal text. The 
most difficult problem is that IM messages are very short, and it is very hard to collect 
a large amount corpus for analyzing, in addition the real time nature of instant 
messaging requires to decide the identity of a user in a short time and using messages 
as small as possible. Therefore, we study on validating the identities of IM users. 
 User Identification for Instant Messages 115 
3   User Identification for IM Messages 
3.1   Feature Selection and Extraction 
In this paper the chatting corpus we used is Chinese text. We choose the following 
features considering the special characteristic of Chinese chatting text:  
Token-based features: tokens are defined as Chinese characters, punctuations, 
English words, and some other separated alphabets or symbols appeared in an instant 
message. In this paper we choose the following token-based features from a sample: 
the number of Chinese characters, the number of English words, the number of digits, 
frequency of punctuations, and the punctuation richness (how many types of 
punctuation are used in one sample). 
In our experiments we found punctuation is effective in authorship verification for 
chatting text. When using IM to communicate with others, users are used to using 
characters they like to separate sentences. For example, some peoples like to use 
white space, while others may excessively use some special separators. Moreover, 
users always prefer to use what they like without considering whether the usage is 
correct in grammar. Useful punctuations are selected according to the frequency they 
occur in the text. The punctuation richness is calculated by the ratio of the number of 
punctuations to the total number of tokens in a sample. 
Syntax features: Syntax features include frequency of function words and POS tag 
frequency. Firstly, we use Chinese Word Segmentation tool to find Chinese words, 
and then use Chinese POS tagger to assign POS tags to Chinese words. Function 
words are selected according to their POS tags. To select effective features of a user, 
we prepare two datasets for each user, one dataset contains only text messages of the 
user’s own, and the other dataset contains messages randomly selected from chatting 
groups which include 2000 peoples. Information gain method is used to select 
effective function words that can represent the user’s characteristics. We calculate the 
information gain of each function word and sort the function words in the user’s own 
dataset in the decreasing order of their information gain, and select the top N function 
words as feature words. 
POS tag features are selected according to their frequency in the user’s own 
dataset; top N POS tags with high frequencies are selected. 
IM-related features: Instant messages have their own special language styles. For 
example, popular internet words, special abbreviations, emoticons and words with 
similar pronunciation to others often appear in chatting text. Users select and use 
them according to theirs own language habits. We sum up the features of IM 
messages, and list some in Fig. 1. 
 
Fig. 1. Part of IM related Features 
116 Y. Ding et al. 
Structural feature: in this paper we only choose one structural feature, the average 
length of sentences. 
3.2   Model Generation 
Theoretically we can use multiple classification models to solve authorship 
verification problem. However, in this problem the number of IM users is not fixed, 
we cannot determine the number of categories. For a user to be recognized, the data 
we can obtain is the user’s own data (positive data), it is very difficult to collect 
enough negative samples that are representative of the entire negative class. One 
interesting problem for chatting text is that a person can use different chatting styles 
to chat with different peoples. For example, A has two friends B and C, A can chat 
with B using a totally different style as A chats with C. Usually if A decides a 
speaking style to chat with B, A will not change it; at least will keep it a relatively 
long time. That means we can not create a unique model to represent a user. 
Considering above special situations, one-class classification model is the best choice; 
in addition, a user need to build a recognition model for each of her/his chatting 
friends, for example, B and C will build a model of A respectively, and the two 
models may not be identical. 
In this paper we choose two types of one-class classifiers. One is a feed-forward 
neural network with ‘bottle-neck’[22]; the other is one-class SVM. Fig.1. shows the 
structure of the neural network. The neural network is trained using the standard back 
propagation algorithm to learn the identity function on the samples. The overall idea 
of the neural network is that while the bottleneck prevents learning the full identity 
function on m-space; the identity on the small set of samples is in fact learnable. 
Thus, the set of vectors for which the network acts as the identity function is a kind of 
sub-space which is similar to the trained set. Thus, the filter is defined by applying the 
network to a given vector; if the result is the identity, then the vector is “interesting”.  
To apply this idea to classify documents, we need to (i) decide on the number of 
hidden neurons and choose the appropriate learning rates. (ii) encode the documents 
as vectors, (iii) determine the appropriate acceptance thresholds when applying the 
trained networks to classify new documents.  
If the documents are represented as an m-dimensional feature vectors, the structure 
of the network is m input units, m output units. By trying different network 
parameters, we set the parameters of the network as follows. the feed forward network 
has 3 layers, 37 input units, 37 output units and 18 hidden units. All units are standard 
sigmoid units. The learning rate is 0.75 and momentum coefficient is 0.08. The 
iteration for training is stopped until the mean-square error falls below a 
predetermined level. We set the threshold for classification according to the 
classification error of threshold selection set; the threshold should satisfy that the 
classification accuracy is about 90%. This means that we expect false negative  
is 10%.  
In our work we use the LIBSVM available from http://www.csie.ntu.edu.tw/? 
cjlin/libsvm. This is an integrated tool for support vector classification. We use the 
standard parameters of the algorithm. 
 User Identification for Instant Messages 117 
 
Fig. 2. A neural network with bottleneck 
4   Experiment Result 
The chat dataset used in this paper is collected from QQ, a widely used IM tool in 
China. The corpus contains three month’s chatting text of different peoples. It 
includes 10 personal chatting logs and 14 group chatting logs of 2226 users in total. 
The images and the emoticon symbols are automatically transformed into text when 
we extract the chat logs from the QQ. Therefore, all these data are pure text. 
Information not relevant to the user, such as the system message, joke or notification 
copied from the web, is deleted. 
Performance measure: we use the true positive rate (TP) and true negative rate (TN) 
rate to evaluate the performance of a classifier. TP is the ratio of the number of one 
user data correctly classified as this user to the total number of testing data of this 
user. TN is the ratio of the number of non-self data correctly classified as non-self to 
the total number of the non-self testing data.  
Experiment setting: In the following experiments, we used 37 features in total: 16 
function words, 12 token-based features, 9 IM related features. The data set for each 
user is partitioned into three sets for threefold cross-validation. In additional, we also 
build three shared sets; each includes 800 samples selected randomly from 14 group 
chatting logs, one for threshold selection, one for feature selection, and another for 
evaluating TN. We randomly select four users for training and testing. For the 
convenience of comparison, in the experiments we set the TN is about 90%, and then 
we compare the TP of each model. In practice we want a high TN; it means more 
pretenders are found. 
Experiment 1: We use two methods to choose function words. Method 1(M1) only 
uses the training dataset of each user to select function words according their 
frequency. In method 2(M2), besides the user’s training data set, one shared data set is 
used, the top 16 function words with high information gain in the training data set are 
chosen. The results are shown in table 1. (The number of training samples for each 
user is about 180, and the length of each sample is about 210). 
 
 
118 Y. Ding et al. 
Table 1. Performance of M1 and M2 
User M1(%) M2(%) 
TP TN TP TN 
U1 83 90 86 90 
U2 87 90 91 90 
U2 62 91 65 91 
U3 62 89 60 89 
 
Experiment 2: it is required for IM tools to recognize a user’s identity in a short 
time. In reality it is also difficult to collect a large amount of corpus for a user. Thus, 
the length of data samples is a key factor for recognition. We chose different length of 
samples on the same training data set; the sample length is set as 120, 150, 180, 210, 
240 and 300 Chinese characters, respectively. The corresponding numbers of training 
samples for each length are about 350, 250, 210, 180, 150, and 120, respectively. The 
results are shown in table2. 
Table 2. Performance on the different sample size 
 
Experiment 3: We test the TP and TN using three type features separately, and then 
test the TP and TN using the combination of three types of features, the average 
results for the four users are shown in table 3. In table 3 F1 represents function words, 
F2 represents token based features, F3 represents IM-related features. 
Table 3. Performance for Different Features 
 
5   Conclusion 
From the above experiments we can draw the following conclusions. 
Conclusion from experiment 1: In general the performance of M2 is better than 
that of M1. For one-class classification problem, it is very likely that positive data and 
 User Identification for Instant Messages 119 
negative data have many common features, in our experiment although the shared 
data set cannot represent the features of all negative samples; it is helpful to filter part 
of common features. This is the reason why we use two data sets (positive and 
negative) to select features. 
Conclusion from experiment 2: Compared with a short sample, a long sample can 
more accurately represent the characteristics of instant messages. Therefore, with the 
increase of the sample’s length, the performance of the one-class classifier is 
improved. However, for a fixed training data set, if the samples’ length is too long, 
the number of training samples will be decreased greatly, this will affect the 
classifier’s performance. The experiments show that when we set the sample size at 
200 more or less, we get the best overall performance. 
Conclusion from experiment 3:  The features we expect are the features that have 
big TP and TN. From the experiment result, function words have the best 
discrimination power, the IM related features also have the capability to recognize 
user identity, but their discriminative power is relatively weak, that is because most of 
the IM related features are popular among peoples, it is very difficult to select some 
as features of a specified person. By combining three types of features, we get better 
experimental results. 
Here we only give the results of neural network. We also test the performance of 
one-class SVM; its TP is about 10 percent lower than neural network, so we do not 
show the experimental results of SVM. 
Acknowledgments. This work was partially supported by Scientific Research 
Foundation in Shenzhen (Grant No. JC201005260159A), Scientific Research 
Innovation Foundation in Harbin Institute of Technology (Project No. 
HIT.NSRIF2010123), and Key Laboratory of Network Oriented Intelligent 
Computation (Shenzhen). 
References 
1. Pavelec, D., Oliveira, L.S., Justino, E.J.R.: Using Conjunctions and Adverbs for Author 
Verification. Journal of UCS 14, 2967–2981 (2008) 
2. Van Halteren, H.: Author Verification by Linguistic Profiling: An Exploration of the 
Parameter Space. ACM Transactions on Speech and Language Processing 4, 1–17 (2007) 
3. Luyckx, K., Daelemans, W.: Authorship Attribution and Verification with Many Authors 
and Limited Data. In: 22nd International Conference on Computational Linguistics, pp. 
513–520. ACL Press, Stroudsburg (2008) 
4. Koppel, M., Schler, J.: Authorship Verification as a One-class Classification Problem. In: 
21st International Conference on Machine Learning, pp. 1–7. ACM Press, New York 
(2004) 
5. Abbasi, A., Chen, H.: Applying Authorship Analysis to Extremist-group Web Forum 
Messages. IEEE Intelligent Systems 20, 67–75 (2005) 
6. Yule, G.U.: On Sentence-length as a Statistical Characteristic of Style in Prose: with 
Application to Two Cases of Disputed Authorship. Biometrika 30, 363–390 (1939) 
7. Stamatatos, E.: Ensemble-based Author Identification Using Character N-grams. In: 3rd 
International Workshop on Text-based Information Retrieval, pp. 41–46. Springer, 
Heidelberg (2006) 
120 Y. Ding et al. 
8. Sanderson, C., Guenter, S.: Short Text Authorship Attribution via Sequence Kernels, 
Markov Chains and Author Unmasking: An investigation. In: 2006 International 
Conference on Empirical Methods in Natural Language Engineering, pp. 482–491. ACL 
Press, Stroudsburg (2006) 
9. De Vel, O., Anderson, A., Corney, M.: Mining Email Content for Author Identification 
Forensics. SIGMOD Record 30, 55–64 (2001) 
10. Forsyth, R.S., Holmes, D.I.: Feature Finding for Text Classification. Literary and 
Linguistic Computing 11, 163–174 (1996) 
11. Zheng, R., Li, J., Chen, H., Huang, Z.A.: Framework for Authorship Identification of 
Online Messages: Writing Style Features and Classification Techniques. American Society 
of Information Science and Technology 57, 378–393 (2006) 
12. Grieve, J.: Quantitative Authorship Attribution: An Evaluation of Techniques. Literary and 
Linguistic Computing 22, 251–270 (2007) 
13. Keselj, V., Peng, F., Cercone, N., Thomas, C.: N-gram-Based Author Profiles for 
Authorship Attribution. In: 2003 Pacific Association for Computational Linguistics, pp. 
255–264. Springer Press, Heidelberg (2003) 
14. Kjell, B.: Discrimination of Authorship Using Visualization. Information Processing and 
Management 30, 141–150 (1994) 
15. Argamon, S., Saric, M., Stein, S.: Style Mining of Electronic Messages for Multiple 
Authorship Discrimination: First results. In: 2003 ACM SIGKDD, pp. 475–480. ACM 
Press, New York (2003) 
16. Argamon, S., Whitelaw, C., Chase, P., Hota, S.R., Garg, N., Levitan, S.: Stylistic Text 
Classification Using Functional Lexical Features. Journal of the American Society for 
Information Science and Technology 58, 802–822 (2007) 
17. Zhao, Y., Zobel, J.: Effective and Scalable Authorship Attribution Using Function Words. 
In: Lee, G.G., Yamada, A., Meng, H., Myaeng, S.-H. (eds.) AIRS 2005. LNCS, vol. 3689, 
pp. 174–189. Springer, Heidelberg (2005) 
18. Koppel, M., Schler, J.: Exploiting Stylistic Idiosyncrasies for Authorship Attribution. In: 
IJCAI 2003 Workshop on Computational Approaches to Style Analysis and Synthesis, pp. 
69–72. AAAI Press, Menlo Park (2003) 
19. Zhao, Y., Zobel, J.: Searching with Style: Authorship Attribution in Classic Literature. In: 
Thirtieth Australasian Computer Science Conference, pp. 59–68. Australian Computer 
Society Press, Darlinghurst (2007) 
20. Kucukyilmaz, T., Cambazoglu, B.B., Aykanat, C., Can, J.: Chat Mining for Gender 
Prediction. In: Yakhno, T., Neuhold, E.J. (eds.) ADVIS 2006. LNCS, vol. 4243, pp. 274–
283. Springer, Heidelberg (2006) 
21. Kucukyilmaz, T., Cambazoglu, B.B., Aykanat, C., Can, F.: Chat Mining: Predicting User 
and Message Attributes in Computer-mediated Communication. Information Processing 
&Management 44, 1448–1466 (2008) 
22. Manevitza, L., Yousef, M.: One-class Document Classification via Neural Networks. 
Neurocomputing 70, 1466–1481 (2007) 
