Information Processing and Management 50 (2014) 821–856Contents lists available at ScienceDirect
Information Processing and Management
journal homepage: www.elsevier .com/ locate/ infopromanCharacter n-gram application for automatic new topic
identificationhttp://dx.doi.org/10.1016/j.ipm.2014.06.005
0306-4573/ 2014 Elsevier Ltd. All rights reserved.
⇑ Corresponding author. Tel.: +90 5065149313.
E-mail addresses: burcucaglar@uludag.edu.tr, burcucaglar@gmail.com (B.C. Gencosman).Burcu Caglar Gencosman ⇑, Huseyin C. Ozmutlu, Seda Ozmutlu
Uludag University, Industrial Engineering, Endustri Muh. Bolumu 3. kat Y306, Gorukle Kampusu, 16059 Bursa, Turkey
a r t i c l e i n f o a b s t r a c tArticle history:
Received 1 November 2011
Received in revised form 5 August 2013
Accepted 26 June 2014
Keywords:
Content-ignorant algorithms
The character n-gram method
New topic identification
The Levenshtein edit-distance
Pre-processed spelling correction methodsThe widespread availability of the Internet and the variety of Internet-based applications
have resulted in a significant increase in the amount of web pages. Determining the behav-
iors of search engine users has become a critical step in enhancing search engine perfor-
mance. Search engine user behaviors can be determined by content-based or content-
ignorant algorithms. Although many content-ignorant studies have been performed to
automatically identify new topics, previous results have demonstrated that spelling errors
can cause significant errors in topic shift estimates. In this study, we focused on minimiz-
ing the number of wrong estimates that were based on spelling errors. We developed a
new hybrid algorithm combining character n-gram and neural network methodologies,
and compared the experimental results with results from previous studies. For the FAST
and Excite datasets, the proposed algorithm improved topic shift estimates by 6.987%
and 2.639%, respectively. Moreover, we analyzed the performance of the character n-gram
method in different aspects including the comparison with Levenshtein edit-distance
method. The experimental results demonstrated that the character n-gram method outper-
formed to the Levensthein edit distance method in terms of topic identification.
 2014 Elsevier Ltd. All rights reserved.1. Introduction
In recent years, applied researchers have become increasingly interested in correctly estimating the behaviors of search
engine users to improve the performance of search engines. In order to determine these behaviors, researchers have inves-
tigated search engine query logs and classified them as topic continuation or topic shifts. For example, if a user continues to
search on the same topic or content, the previous query is labeled as a topic continuation. Conversely, if a user changes the
topic, the previous query is labeled as a topic shift. Using this approach, researchers have to improve the accuracy of search
engine results.
Numerous studies based on content-based (semantic) and content-ignorant (non-semantic) methods have been devel-
oped to determine topic shifts and continuations in the transaction logs of search engine users. Content-based approaches,
which use dictionaries and thesauruses, are complicated, because these tools must be created and stored (Leung, Ng, &
Dik, 2008). Although content-based methods identify new topics more successfully than content-ignorant methods, the con-
tent-ignorant methods have the advantages of speed and low memory requirements, which are essential in real-time appli-
cations. Further, these methods yield satisfactory results for new topic identification problems during search engine user
sessions (Leung et al., 2008). Therefore, in this study content-ignorant methods were used to identify new topics.
822 B.C. Gencosman et al. / Information Processing and Management 50 (2014) 821–856Content-ignorant methodologies consider the statistical characteristics of consecutive queries, such as the duration, and
the set of common and different terms. Spink, Ozmutlu, and Ozmutlu (2002) and Goker and He (2000) conducted some of the
first studies linking the statistical characteristics of queries to topic changes. Various content-ignorant methods have been
developed to identify new topics using the same datasets and performance parameters. Some of these methods include the
Dempster-Shafer theory and genetic algorithms (He, Goker, & Harper, 2002; Ozmutlu & Cavdur, 2005a; Ozmutlu, Cavdur, &
Ozmutlu, 2006), conditional probabilities (Ozmutlu, Ozmutlu, & Buyuk, 2007), Monte-Carlo simulations (Ozmutlu, Ozmutlu,
& Buyuk, 2008a), and neural networks (Ozmutlu & Cavdur, 2005b; Ozmutlu, Cavdur, & Ozmutlu, 2008b; Ozmutlu, Cavdur,
Spink, & Ozmutlu, 2004a; Ozmutlu, Ozmutlu, & Cosar, 2011).
These methods are limited in their ability to detect correct topic changes when consecutive queries have synonymous
words or spelling errors. For example, content-ignorant methodologies cannot estimate topic continuation when subsequent
queries such as ‘‘X Hotel’’ and ‘‘Y Inn’’ are included in a user session, so they generate a topic shift estimate as expected. The
content-ignorant methodologies cannot recognize that the synonymous words are related, because they do not use a dictio-
nary or a thesaurus. Further, if consecutive queries contain spelling errors, no new topic identification algorithm, whether it
is a content-based or a content-ignorant algorithm, can recognize these terms are related which causes errors in topic shift
estimates. For example, when content-ignorant methodologies must process two consecutive single-term queries, such as
‘‘cybersc@n’’ and ‘‘cyberscan’’, which are the actual subsequent queries found in the FAST dataset, the two terms are not con-
sidered to be related because they do not exactly match. As a result, the two subsequent queries will be considered to be
unrelated.
Topic continuations cannot be detected without a dictionary when consecutive queries contain synonymous words; how-
ever, if consecutive queries contain spelling errors, topic changes can be detected by using the typing information contained
in the queries, which has been ignored in previous content-ignorant methods.
In consecutive queries, the majority of the characters in the words with spelling errors remain the same. In nearly all
spelling errors, a single character has been mistyped, or two consecutive characters have been switched. Since the majority
of the characters in the mistyped words are correct (the ‘‘cybersc@n’’ example given above), the use of a similarity measure
could improve the performance of new topic identification algorithms by eliminating incorrect topic shift estimates due to
spelling errors. The error model approach has been used to correct spelling with a dictionary, with correction probabilities
and with an edit distance matrix. To eliminate the complexity of spelling error detection methods and to avoid the use of
a dictionary, we chose the character n-gram method. Although this method detects spelling errors using typing information
from consecutive queries, it does not perform well regardless of the statistical characteristics of queries. Therefore, the best
previous method is combined with the character n-gram method to make use of the statistical characteristics and typing
information of consecutive queries.
Based on the previous studies about the new topic identification problem, the artificial neural network algorithm is cho-
sen to be integrated into the character n-gram algorithm because it generates the most accurate estimates when used in the
new topic identification problem (Ozmutlu et al., 2011). In this study, a hybrid algorithm based on the character n-gram and
artificial neural network methods have been developed to eliminate the incorrect estimates caused by spelling mistakes
while enhancing the performance of the existing algorithms. Comparison of the results from the new hybrid methodology
and the artificial neural network algorithm shows that the proposed algorithm offers significant improvements.
In addition, the performance of the suggested method is compared with one of the well-known similarity measurement
method; the Levenshtein edit-distance. Moreover, original datasets are updated by different spelling correction methods
(Bing, Google and ASPELL) to evaluate the effectiveness of the character n-gram method. Comparison of the results demon-
strates that the character 2-grams method outperforms to the Levenshtein edit-distance, and the Google search engine can
be used as a pre-processed spelling correction method.
The remainder of this paper is organized as follows: in Section 2, previous studies on the new topic identification problem
and character n-gram methodologies are reviewed. In Section 3, the data sources, study notation and definition of the char-
acter n-gram are presented with examples. Experimental results from the character n-gram method and the proposed
method are described in Section 4. In Sections 5, a detailed analysis of the character n-gram method is presented, and in
Sections 6 and 7, the study is summarized and the limitations and future applications are discussed.
2. Related studies
Web search engine data logs have been used in many studies by researchers such as Silverstein, Henzinger, Marais, and
Moricz (1999), Cooley, Mobasher, and Srivastava (1999), Spink, Bateman, and Jansen (1999), Spink, Wolfram, Jansen, and
Saracevic (2001), Spink, Jansen, Blakely, and Koshman (2006), Ozmutlu, Ozmutlu, and Spink (2004b), Ozmutlu et al.
(2006) which are based on statistical or linguistic characteristics of web search queries (Pu, Chuang, & Yang, 2002).
As usual, content-based algorithms work with dictionaries and thesaurus; they are more expensive and difficult to be
implemented due to the requirement of creating and storing these dictionaries. Thus, there is only limited number of con-
tent-based studies in literature for the new topic identification in user sessions; mostly they are used for natural language
processing, classification and clustering.
Spink, Wolfram, Jansen, and Saracevic (2001), aimed to determine the behaviors of search engine users by examining
more than one million queries from the Excite search engine. They ignored logic expressions in the queries, and they used
B.C. Gencosman et al. / Information Processing and Management 50 (2014) 821–856 823the Intelligent Concept Extraction which is a method of making connection between terms. In this study, some useful data
were gathered such as, number of total users, queries, repeated queries and unique queries. The usage ratio of similar pages
was determined with content-based methods, the classification of queries and the distributions of these classes were deter-
mined. According to the results, 16.9% of the queries were included in entertainment subject, 16.8% of them were included in
sexual subject contents, and 10% of the queries were related with science and health. Most of the queries had simple content
and less than 3 words, few of them had complex content because most of the users did not go beyond to second result page.
Further, the frequency of terms used during search was low because query language was very rich so the sessions were
mostly formed by unique queries.
One of the studies about personalization of search engines belongs to Leung et al. (2008). To improve the queries for more
efficient researches, popular and advanced search engines propose various search alternatives related with search topics.
Although search engines offer useful alternatives, they cannot detect the interest of users. Thus, the authors developed a
method based on personalized concept-based clustering techniques to generate personalized proposals for the users. The
authors used clickthrough data to generate query suggestions according to user preferences. They defined the relationship
between queries, users and documents by expanding the scope of graph-based clustering algorithm which was developed by
Beeferman and Berger (2000). They developed a Google interface which tracks the user clicks to collect clickthrough data.
This interface recorded the data whenever user clicks on a search result. They tried to identify similar queries with con-
tent-based methods using the database of records. The study results showed that the improved method could generate per-
sonalized query proposals considering users’ conceptual requirements. Further, it was observed that the new clustering
algorithm was able to yield better results compared to the previous clustering algorithms.
Besides their complexity in real time applications, content-based studies are troublesome and costly. Although successful
results can be acquired through these methods, researchers prefer content-ignorant statistical methods in real time appli-
cations because of the disadvantages of content-based methods. Content-ignorant methods are simpler and less expensive
than content-based methods, and they can obtain realistic results by interpreting collected data statistically.
Web researchers use web search engines for various purposes such as classification, clustering or new topic identification.
Jansen, Booth, and Spink (2007) tried to classify search engine user intent; informational, navigational and transactional
intent. They found that more than 80% of web queries were informational and about 20% of web queries were navigational
and transactional queries. Similar to the classification, some researchers performed content analysis of Web search engine
data logs at the term level; they observed that the highest ranking terms were related to topics of entertainment, pornog-
raphy, and education (Spink et al., 2001).
Further, exploring the behavioral changes throughout the day could provide important data about the behaviors of search
engine users. For this purpose Ozmutlu, Ozmutlu, and Spink (2004b) performed statistical and topical analysis of about 1
million queries from the Excite and the FAST search engines. They found that the popularity of topics was diverse throughout
the day. For example, topics such as finance, business and education were more popular during the earlier hours of the day
whereas entertainment and pornography were more prevalent during the evening. Also Beitzel, Jensen, Chowdhury,
Grossman, and Frieder (2004) reached similar results in their study.
In addition to diversity of interested topics, search engine users can be interested in multiple topics at the same user ses-
sion. Spink et al. (2002) called this research behavior multitasking and defined multitasking as ‘‘the process of searches over
time in relation to more than one, possibly evolving, set of information problems including changes or shifts in beliefs, cog-
nitive, affective, and/or situational states’’. Researchers observed that 1.4% of the Excite search engine users and 31.8% of the
FAST search engine users performed multitasking searches.
Numerous studies have been developed based on query clustering models and algorithms to investigate search engine
users behaviors. Beeferman and Berger (2000) and Wen, Nie, and Zhang (2002) applied the query clustering methods to
search engine query logs, including clickthrough data. Leung et al. (2008) explored a methodology to develop personalized
search engines based on Beerferman and Berger’s graph-based clustering algorithm. Muresan and Harper (2004) proposed a
topic modeling system for developing mediated queries. The terms in a set of documents were analyzed statistically and then
represented as a lexicographic model of the query. The context analysis was applied on the mediated queries based on the
similarity of terms to specific topics. Giacomo, Didimo, Grilli, Liotta, and Palladino (2007) affirmed that classical search
engines had a weak point in the presentation of results, and alternatively new generation search engines which are called
web clustering engines have been designed. According to Giacomo et al. (2007) web clustering engines organized search
results into set of clusters, and each cluster contained web pages that were semantically related to each other. They used
various clustering algorithms to achieve this classification.
Alternatively content-ignorant methods can be used for query clustering or new topic identification in a search session. In
such an approach, queries can be categorized in different groups of topics respect to their statistical characteristics, such as
time intervals between subsequent queries. He et al. (2002) proposed a topic identification algorithm based on Dempster-
Shafer theory (Shafer, 1976). The algorithm identified topic changes automatically using statistical data obtained from
Web search logs. The probabilities and the weights (importance) of events and a threshold were used by Dempster-Shafer
theory to detect topic shifts. Probabilities of a topic shift (or continuation) based on a single factor (the time interval or the
search pattern of the subsequent queries) were easily obtained through the analysis of the data log. To set the required
weights and the threshold, the authors applied a genetic algorithm. The researchers concluded that the Dempster-Shafer
theory could be used for the purpose of new topic identification successfully. Moreover, this approach was replicated by
some researchers such as, Ozmutlu and Cavdur (2005a) and Ozmutlu et al. (2006).
824 B.C. Gencosman et al. / Information Processing and Management 50 (2014) 821–856Due to the advantages of content-ignorant methodologies, numerous studies have been performed for the purpose of new
topic identification. For example, Ozmutlu et al. (2004a) and Ozmutlu and Cavdur (2005b) used artificial neural networks to
identify the topic changes automatically by content-ignorant methods. In addition to these studies Ozmutlu et al. (2007) pro-
posed conditional probabilities for automatic new topic identification, and Ozmutlu et al. (2008a) applied Monte-Carlo sim-
ulation for the same reason to the same data. Ozmutlu et al. (2011) developed another neural network approach for the same
data and they reached better results than the other methods. The statistical characteristics of the query log were the inputs
of the neural network, whereas the binary response of topic shift/continuation was the output of the neural network. In this
study, the data were cleaned from regular words found in the transaction logs, such as ‘‘AND’’, ‘‘OR’’, and then regarding to
the statistical characteristics of queries, such as time intervals and search patterns, the neural network method was applied to
the queries with the aim of identifying topic changes in a user session (Ozmutlu et al., 2011).
In previous studies by Ozmutlu et al., 2004a,b, 2006, 2007, 2008a,b; Ozmutlu & Cavdur, 2005a,b, the same datasets and
comparison parameters were used to logically compare different approaches. Based on these comparisons as presented in
Table 1 for the Excite dataset and in Table 2 for the FAST dataset, the neural network application generated better estimate
results than the previous studies (Ozmutlu et al., 2011).
Content-ignorant methodologies do not improve upon the results given in previous studies. Further, two important prob-
lems that cannot be solved by content-ignorant methods have been identified (Ozmutlu et al., 2011). The first problem arises
from spelling differences in subsequent queries, and the second problem arises from content-based mistakes, such as syn-
onymous words. Because content-ignorant methodologies do not consider the meanings of queries, they cannot recognize
topic continuation between sequential queries that include synonymous words. Conversely, in sequential queries that contain
spelling differences, some portions of the queries often remain unchanged. This finding prompted us to identify a method-
ology that can detect similarities within words.
Many researchers have used error model approach for spelling correction. Brill and Moore (2000) developed a new error
model using the position probabilities of words’ partitions, which were calculated based on a dictionary, for noisy channel
spelling correction. They used a training set consists of string pairs, spelling errors and correct spellings of the words. They
calculated distances between letters, and after editing operations, they found the probabilities of each substitution. Using a
dictionary (includes 200,000 entries) and the probabilities, they tested their model with a 10,000-word corpus of common
English spelling errors, paired with their correct spelling. They concluded that the new error model had a significant
improvement in performance compared to the previous studies. Cucerzan and Brill (2004) developed an iterative approach
for spelling correction of search engine queries. They used a modified Damerau-Levenshtein edit distance (Damerau, 1964)
and a prior probability information of correction. They performed two approaches with and without a trusted lexicon. They
developed a successful approach for spelling correction task of search query logs using their collective information. This
study demonstrated that the Levenshtein edit-distance method without lexicon could be used as a content-ignorant method
to detect spelling mistakes in search engine query logs for the purpose of new topic identification. However, detecting only
spelling mistakes would not be sufficient for the new topic identification, hence this situation prompted us to search more
effective tools that can detect similarities within words including spelling mistakes.
The n-gram methodology is widely used in statistical language modeling for the purpose of predicting the next word
given previous words. The n-gram language models make an assumption that the probability of the next word depends upon
the last n  1 words. Shannon (1951) tried to guess next letter in a text with Shannon game. After Shannon’s studies, many
estimate methods have been developed, but the n-gram method is remained the simplest and the most successful method in
language modeling (Huang, Peng, An, Shuurmans, & Cercone, 2003). Damashek (1995) used the n-grams for measuring top-
ical similarity in an unrestricted text. Huang et al. (2003) identified boundaries of sessions using n-grams in a large collection
of Livelink log data. Canvar and Trenkle (1994) researched electronic documents, and they calculated the frequency of
n-grams in terms of textual errors, such as spelling and grammatical errors. Roark, Saraclar, and Collins (2007) used a dis-
criminative n-gram approach for speech recognition. Briefly, the n-gram language modeling can be used for speech or optical
character recognition, spelling correction, handwriting recognition, and statistical machine translation.
Although the n-gram method works with word sequences in a huge amount of text, spelling errors cannot be detected
without considering words in characteristic review. The spelling errors in sequential queries can be detected by character
n-grams. Therefore, using the character n-grams for predicting topic continuations in search engine queries is more logical
than using the word n-grams.
The use of character n-grams in language modeling dates back to Shannon (1951). The researcher made contributions to
the information retrieval theory, and he also described a sequence of the character n-gram and the word n-gram approxi-
mations to English (McNamee & Mayfield, 2004). After this research, implementations of the character n-gram method
increased rapidly. McNamee and Mayfield (2004) used the character n-gram method for multilingual text retrieval. They
aimed to demonstrate that the character n-gram tokenization can provide retrieval accuracy better than the other lan-
guage-specific approaches. Liu and Keselj (2007) studied about automatic classification of web user navigation patterns,
and they implemented the character n-gram method for capturing textual content of web pages. Kamaris and Stamatatos
(2007) studied about webpage genre identification for improving the quality of search engines, and they applied the
character n-gram method to identify of webpage genres. Chau, Lu, Fang, and Yang (2009) researched the character usage
of Chinese search logs from Chinese search engines. Since the character n-gram method is independent from language, they
implemented this method to their study without any difficulty. Vilares, Vilares, and Otero (2011) used the classic stemming-
based methods and the character n-gram method for the purpose of identifying spelling mistakes and make corrections in
Table 1
Comparison of methodologies performed to the Excite dataset.
Origin of results No. of queries
included in
analysis
No. of topic
shifts
No. of topic
contins
Correctly
estimated
number
of shifts
Correctly
estimated
number of
contins
Type A
error
Type B
error
Pshift Rshift Pcontin Rcontin Fß(shift) Fß(contin)
Results from human expert 3394 Ntrue shift = 272 Ntrue contin = 3122 – – – – – – – – – –
Results from Monte Carlo simulation 3394 Nshift = 393 Ncontin = 3001 Nshift&correct = 142 Ncontin&correct = 2871 251 130 0.36 0.53 0.96 0.92 0.45 0.94
Results from neural network (2011) 3394 Nshift = 454 Ncontin = 2940 Nshift&correct = 237 Ncontin&correct = 2905 217 35 0.522 0.871 0.988 0.93 0.698 0.95
B.C.G
encosm
an
et
al./Inform
ation
Processing
and
M
anagem
ent
50
(2014)
821–
856
825
Table 2
Comparison of methodologies performed to the FAST dataset.
Origin of results No. of queries
included in analysis
No. of topic
shifts
No. of topic
contins
Correctly estimated
number of shifts
Correctly estimated
number of contins
Type A
error
Type B
error
Pshift Rshift Pcontin Rcontin Fß(shift) Fß(contin)
Results from human expert 4484 Ntrue shift = 310 Ntrue contin = 4174 – – – – – – – – – –
Results from neural network (2005) 4484 Nshift = 865 Ncontin = 3619 Nshift&correct = 305 Ncontin&correct = 3614 560 5 0.353 0.984 0.999 0.866 0.635 0.903
Results from Monte Carlo simulation 4484 Nshift = 338 Ncontin = 4146 Nshift&correct = 137 Ncontin&correct = 3973 201 173 0.41 0.44 0.96 0.95 0.43 0.95
Results from conditional probabilities 4484 Nshift = 276 Ncontin = 4208 Nshift&correct = 146 Ncontin&correct = 4044 130 164 0.529 0.471 0.961 0.968 0.491 0.966
Results from Dempster Shafer theory 4484 Nshift = 836 Ncontin = 3648 Nshift&correct = 303 Ncontin&correct = 3641 533 7 0.362 0.977 0.998 0.872 0.642 0.907
Results from neural network (2011) 4484 Nshift = 886 Ncontin = 3598 Nshift&correct = 306 Ncontin&correct = 3594 580 4 0.345 0.987 0.998 0.861 0.583 0.907
826
B.C.G
encosm
an
et
al./Inform
ation
Processing
and
M
anagem
ent
50
(2014)
821–
856
B.C. Gencosman et al. / Information Processing and Management 50 (2014) 821–856 827Spanish. They compared these methods and showed performance results in their study. In addition to these studies, the
character n-gram method also has been used in handwriting recognition (El-Nasan A. & M., 2002; Senda & Yamada, 2001).
Researchers have developed various content-ignorant methods for the purpose of new topic identification. These meth-
ods have focused primarily on the statistical characteristics of queries rather than on typing information. As a result, recently
developed methods cannot detect spelling errors or similarities between words in consecutive queries, which are important
in topic identification. The aim of this study is to reduce the number of topic identification failures by using typing informa-
tion from consecutive queries. We develop a character n-gram method that uses similarities between sequential queries and
apply it to datasets that have been used in previous studies. Comparing the results of the character n-gram method with
results from previous methods, we show that using typing information from the queries rather than the statistical charac-
teristics of the queries is not sufficient for new topic identification. Thus, we combine the best previous method with the
character n-gram method to make use of the statistical characteristics and the typing information of the queries. The results
show that combining these methods ensures the accurate identification of new topics. Moreover we also compare our pro-
posed method with well-known spelling detection methods, and we present that our methodology outperforms to these
methods in terms of accurate identification of new topics.
3. Methodology
3.1. Data collection and analysis
Data collection: To avoid any performance bias in the proposed algorithm, datasets that have been used in previous stud-
ies are selected (Ozmutlu & Cavdur, 2005a,b; Ozmutlu et al., 2004a,b, 2006, 2007, 2008a,b, 2011). The first dataset is col-
lected from the FAST search engine (http://www.alltheweb.com) and provide a query log of 1.257.891 queries. The
second dataset is collected from the Excite search engine (http://www.excite.com) and provide a query log of 1.7 million
queries for analysis. The data log structures of the Excite and FAST search engines are similar. From the Excite and FAST
results, samples of 10.007 and 10.256 queries are selected, respectively, using Poisson sampling (Ozmutlu, Spink, &
Ozmutlu, 2002). This approach provides sample datasets from both search engines that are statistically representative of
the entire dataset yet small enough to be analyzed conveniently. The sample size is relatively small because evaluations
of the algorithm’s performance would require a human expert to review all the queries. The datasets are not added to this
paper because of their magnitude, but they are available to interested researchers. Details about the datasets can be found in
Ozmutlu et al. (2004a, 2006, 2007, 2008a,b, 2011), Ozmutlu and Cavdur (2005a,b).
Evaluation by a human expert: The actual topic shifts and continuations in the Excite and FAST datasets are identified and
marked by a human expert rather than by a software program. This step is necessary to determine how accurately topic shifts
and continuations are identified by the proposed approach.
Separating datasets into two sets: The datasets are divided into two approximately equal sections. The first section is used
to train the developed methodologies, and the second section is used to test the performance of the approaches. The methods
are only tested with these datasets to ensure the consistency with results from previous methods and to facilitate logical
comparisons. The last query of each session is not included in the analyses because it has no subsequent queries for iden-
tifying topic continuations or shifts. Thus, the size of the datasets is reduced, as shown in Table 3. Only 3394 queries from
the Excite dataset and 4484 queries from the FAST dataset are used.
Identification of search pattern and time interval of each dataset query: Ozmutlu and Cavdur (2005a) investigated queries
with the same IP addresses and defined search patterns for consecutive queries. The search patterns are summarized in Table 4,
and their definitions can be found in Appendix A.
Each dataset query is categorized in terms of its search pattern and time interval. The classification of the search patterns is
based on the consecutive queries within a user session, which are automatically identified by a computer program described
in Appendix B. The time interval is the difference of the arrival times of two consecutive queries. It is determined with respect
to the length of the difference of the arrival times of two consecutive queries.
The statistical characteristics of queries such as the time interval and the search pattern have been used to determine topic
changes in queries (Ozmutlu & Cavdur, 2005a,b; Ozmutlu et al., 2004a, 2006, 2007, 2008a,b, 2011). In such methods, topic
shifts and continuations are estimated based on the statistical characteristics of the queries. Thus, correctly identifying the
search patterns and time intervals is essential to new topic identification.Table 3
The size of evaluated datasets.
# of queries # of sessions # of evaluated queries
Training set 5128-Excite 1858-Excite 3270-Excite
4997-Fast 437-Fast 4560-Fast
Test set 5128-Excite 1734-Excite 3394-Excite
5010-Fast 526-Fast 4484-Fast
Total 10256-Excite 3592-Excite 6664-Excite
10007-Fast 963-Fast 9044-Fast
Table 4
Time intervals and search patterns of queries.
Class Time intervals (min) Class Search patterns
1 0–5 1 Unique (new)
2 5–10 2 Next page (browsing)
3 10–15 3 Generalization
4 15–20 4 Specialization
5 20–25 5 Reformulation
6 25–30 6 Relevance feedback
7 30+ 7 Others
828 B.C. Gencosman et al. / Information Processing and Management 50 (2014) 821–8563.2. Notation
The notation used in this study is described below.
Query: A set of one or more search terms; it may include advanced search features, such as logical operators and
modifiers.
Session: The entire set of queries issued by a user or an application to achieve a certain searching task over time. A session
can be as short as one query, or it may contain many unique and repeated queries.
Topic shift: A change from one topic to another between queries within a single user session.
Topic continuation: Staying on the same topic from one query to another within a single user session.
Nshift: The number of queries labeled as topic shifts by the proposed method.
Ncontin: The number of queries labeled as topic continuation by the proposed method.
Ntrue shift: The number of queries labeled as topic shifts by the human expert.
Ntrue contin: The number of queries labeled as topic continuation by the human expert.
Nshift&correct: The number of queries labeled as topic shifts by the proposed method and by the human expert.
Ncontin&correct: The number of queries labeled as topic continuation by the proposed method and by the human expert.
Type A error: This type of error occurs in situations in which queries on the same topics are considered as separate topic
groups.
Type B error: This type of error occurs in situations in which queries on different topics are grouped together into a single
topic group.
Some useful formulation related to the above notation is as follows:Ntrueshift ¼ Nshift&correct þ Type B error ð1Þ
Ntruecontin ¼ Ncontin&correct þ Type A error ð2Þ
Nshift ¼ Nshift&correct þ Type A error ð3Þ
Ncontin ¼ Ncontin&correct þ Type B error ð4ÞThe performance measures Precision (P) and Recall (R) are used to compare the performance results with the results of
previous studies. The aim of these measures is to estimate the numbers of topic shifts and continuations correctly. Additional
information about these measures can be found in Ozmutlu and Cavdur (2005b) and Ozmutlu et al. (2006).
When alternative statistical methods improve a specific performance parameter, other parameters tend to deteriorate
contrary to the desired result. In this case, the performance parameters P and R are inversely proportional, and an increment
of one parameter adversely affects the other’s performance. To overcome this interaction, the fifth measure Fß_shift, which
combines Pshift and Rshift, can be used as a single parameter to compare the results from different studies. Similarly, the sixth
fitness function measure Fß_contin (Eq. (10)) can be used similarly to the Fß_shift measure by combining Pcontin and Rcontin into a
single value. To be consistent with previous automatic new topic identification studies, ß is chosen as 1.3 in this study. The
calculations of these measures are as follows:Pshift ¼
Nshift & correct
Nshift
ð5Þ
Pcontin ¼
Ncontin & correct
Ncontin
ð6Þ
Rshift ¼
Nshift & correct
Ntrue shift
ð7Þ
B.C. Gencosman et al. / Information Processing and Management 50 (2014) 821–856 829Rcontin ¼
Ncontin & correct
Ntruecontin
ð8Þ
Fb shift ¼
ð1þ b2ÞPshiftRshift
b2Pshift þ Rshift
ð9Þ
Fb contin ¼
ð1þ b2ÞPcontinRcontin
b2Pcontin þ Rcontin
ð10Þ3.3. Cleaning the datasets
Web search engine users generally use common expressions to extend their queries. Although these terms are necessary
for queries, they cause incorrect estimates in non-semantic based algorithms. The cleaning process eliminates common
terms in sequential queries and helps to reduce incorrect estimates. For example, consecutive queries such as ‘‘www.expose.
com’’ and ‘‘www.expert.com’’ are labeled as topic continuation due to the similarity of the terms. After the cleaning process,
these queries are changed into ‘‘expose’’ and ‘‘expert’’, and the algorithms are able to label them as topic shift. The cleaning
process is the most essential element affecting the performance of the algorithms.
The order of cleaning is also important in this process. First, all letters in the dataset are changed to lower case. Then,
operators and common words such as ‘‘.’’, ‘‘,’’, ‘‘;’’, ‘‘+’’, ‘‘:’’, ‘‘%’’, ‘‘&’’, ‘‘[]’’, ‘‘()’’, ‘‘ ’ ’’, ‘‘!’’, ‘‘$’’, ‘‘/’’, ‘‘n’’, ‘‘<’’, ‘‘>’’, ‘‘www’’, ‘‘http’’,
‘‘com’’, ‘‘uk’’, ‘‘au’’, ‘‘edu’’, ‘‘and’’, ‘‘or’’, ‘‘on’’, ‘‘of’’, ‘‘at’’, ‘‘in’’, ‘‘a’’, ‘‘an’’, ‘‘for’’, and ‘‘to’’ are removed from the dataset by replacing
them with space.
3.4. Character n-gram methodology
Robertson and Willett (1998) define an n-gram as a sub-sequence of n characters from a given word. Namely, in the character
n-gram approach, n consecutive letters of a word are selected, beginning with the first letter. Then, the second n consecutive
letters of the word are selected beginning with the second letter. This process continues until the selected n-gram is the last
n characters of the given word. For example, ‘‘mountain’’ can be represented with the character n-grams shown in Table 5.
The first column indicates the predetermined n values of 2, 3 and 4, which are named as 2-grams, 3-grams and 4-grams respec-
tively. The second column shows the results of the character n-gram method for specific n values, which are represented as the
character 2-grams, the character 3-grams, and the character 4-grams from now. For example, if we generate the character
n-grams using the n value of 2, this means that we use the character 2-grams method for the new topic identification.
The comparison process for queries varies according to the number of words that exist in consecutive queries. If two con-
secutive queries contain a single word, the n-gram pairs are generated using the predetermined n for both words. For
instance, if consecutive queries contain ‘‘cyberscan’’ and ‘‘cybersc@n’’, which are examples from the FAST dataset, the result-
ing n-gram pairs are given in Table 6, with n values of 2, 3 and 4.
To determine the similarity of consecutive queries, we define a threshold value. The character n-gram method makes a
decision by comparing this value with the similarity ratio, which is defined as the ratio of identical n-grams versus the total
number of n-grams. The similarity ratio can be calculated as follows:Similarity ratio ¼ number of identical n-grams
min ðNo: of n-grams for wordAÞ; ðNo: of n-grams for wordBÞgf
ð11Þwhere wordA is the first word, and wordB is the second word used for the character n-gram comparison.
According to the example in Table 5, the similarity ratio of ‘‘cybersc@n’’ and‘‘cyberscan’’ is 68 ¼ 0:75 for the character
2-grams. With a user-defined threshold of 0.7, the similarity ratio exceeds the determined threshold. In this case, the character
n-gram method concludes that these words are similar and labels the first query as topic continuation. If the queries contain
more than one word, the character n-gram method labels the first query as topic continuation when the similarity ratio of at
least one word exceeds the threshold. For example, if we consider the consecutive queries ‘‘buddhism’’ and ‘‘buddhist greet-
ings’’ from the Excite dataset, the similarity ratio will be 67 ¼ 0:857 for the character 2-grams because of the ‘‘buddhism’’ and
‘‘buddhist’’ words. If we assume the threshold is 0.7, the character 2-grams method concludes that these queries are similar,
and labels the first query as topic continuation. This approach is a logical progression for the classification of search patterns.Table 5
Example of character n-grams.
n Character n-gram samples
2-Grams (n = 2) mo-ou-un-nt-ta-ai-in
3-Grams (n = 3) mou-oun-unt-nta-tai-ain
4-Grams (n = 4) moun-ount-unta-ntai-tain
Table 6
Different n-gram pairs of queries.
2-Grams (n = 2) 3-Grams (n = 3) 4-Grams (n = 4)
cybersc@n cyberscan cybersc@n cyberscan cybersc@n cyberscan
cy cy cyb cyb cybe cybe
yb yb ybe ybe yber yber
be be ber ber bers bers
er er ers ers ersc ersc
rs rs rsc rsc rsc@ rsca
sc sc sc@ sca sc@n scan
c@ ca c@n can
@n an
congress
and
social
security
congressional
retirement
Fig. 1. An example comparison for queries with more than one word.
830 B.C. Gencosman et al. / Information Processing and Management 50 (2014) 821–856Topic shifts and topic continuations can be identified automatically by the character n-gram methodology in the following
steps:
A0: i = 1.
A1: Apply the character n-gram approach to the queries that occur in the same search engine session. Label queries as
‘‘current query: qi’’ and ‘‘next query: qi+1’’ sequentially. Separate current query into its words and send every word to an array.
Repeat this step for the next query.
A2: Separate the words of the current and next queries into their characters according to n. Send these separated n-grams
to different arrays. There are now two different arrays for the current and next queries.
A3: Compare the first word’s n-grams for the current and next queries. Calculate the similarity ratio based on the same char-
acter n-grams. If the similarity ratio exceeds the threshold, then estimate topic continuation. Until the similarity ratio exceeds
the threshold, continue to compare all possible word pairs, as shown in Fig. 1. If the calculated similarity ratio never exceeds
the threshold, then estimate topic shift.
A4: After the estimate, increase i. If qi+1 is the last query in a session, go to a new session and define the next two queries as
the current query and the next query. Otherwise, change qi+1 to the current query (i = i + 1) and label the following query as the
next query. Then return A1.
4. Experimental Results
4.1. Character n-gram Method
In this study, we use the character n-gram method for new topic identification without combining it with another
approach, and we research its performance on estimating topic changes. Experiments with the Excite and FAST datasets
are replicated for different threshold and n values. Considering the number of words in queries, the threshold interval is deter-
mined to be 0.5–0.7 and the n value interval is 1–4. We present our findings in Tables 7–10.
As shown in Table 7, the character n-gram method estimates fewer topic shifts for small threshold and n values. Increasing
the threshold and n values, increases the number of topic shift estimates. Compared to the human expert results, the character
n-gram method always estimates more topic shifts, except for the 1-grams and threshold value 0.5. More topic shift estimates
increase the number of Type A errors. Conversely, the character n-gram method estimates fewer topic continuations than the
human expert, except with the 1-grams and threshold value 0.5. Moreover, these estimates are inversely proportional to the n
and threshold values. The number of topic continuation estimates decreases as the n and threshold values increase, eventually
dropping below the number of human expert results.
Table 7
Character n-gram applications with the Excite dataset and different n and threshold values.
N-grams Threshold Nshift Ncontin Human expert Nshift&correct Ncontin&correct Type A error Type B error
Ntrue_shift Ntrue_contin
1-Grams 0.5 200 3194 272 3122 69 2991 131 203
0.6 339 3055 272 3122 116 2899 223 156
0.7 495 2899 272 3122 180 2807 315 92
2-Grams 0.5 682 2713 272 3122 247 2688 434 26
0.6 724 2670 272 3122 261 2659 463 11
0.7 739 2655 272 3122 263 2646 476 9
3-Grams 0.5 752 2642 272 3122 262 2632 490 10
0.6 770 2624 272 3122 263 2615 507 9
0.7 778 2616 272 3122 264 2608 514 8
4-Grams 0.5 855 2539 272 3122 263 2530 592 9
0.6 866 2528 272 3122 264 2520 602 8
0.7 876 2518 272 3122 264 2510 612 8
Table 8
Performance analysis of the character n-gram method for the Excite dataset.
N-grams Threshold Pshift Pcontin Rshift Rcontin Fß(shift) Fß(contin)
1-Grams 0.5 0.345 0.936 0.254 0.958 0.281 0.950
0.6 0.342 0.949 0.426 0.929 0.391 0.936
0.7 0.364 0.968 0.662 0.899 0.507 0.924
2-Grams 0.5 0.362 0.991 0.908 0.861 0.582 0.905
0.6 0.360 0.996 0.960 0.852 0.593 0.900
0.7 0.356 0.997 0.967 0.848 0.590 0.897
3-Grams 0.5 0.348 0.996 0.963 0.843 0.582 0.894
0.6 0.342 0.997 0.967 0.838 0.575 0.890
0.7 0.339 0.997 0.971 0.835 0.574 0.889
4-Grams 0.5 0.308 0.996 0.967 0.810 0.538 0.871
0.6 0.305 0.997 0.971 0.807 0.536 0.869
0.7 0.301 0.997 0.971 0.804 0.532 0.866
Table 9
Character n-gram applications with the FAST dataset and different n and threshold values.
N-grams Threshold Nshift Ncontin Human expert Nshift&correct Ncontin&correct Type A error Type B error
Ntrue_shift Ntrue_contin
1-Grams 0.5 180 4304 310 4174 55 4049 125 255
0.6 302 4182 310 4174 103 3975 199 207
0.7 474 4010 310 4174 171 3871 303 139
2-Grams 0.5 710 3774 310 4174 277 3741 433 33
0.6 751 3733 310 4174 289 3712 462 21
0.7 770 3714 310 4174 295 3699 475 15
3-Grams 0.5 783 3701 310 4174 297 3688 486 13
0.6 800 3684 310 4174 303 3677 497 7
0.7 803 3681 310 4174 303 3674 500 7
4-Grams 0.5 917 3567 310 4174 303 3560 614 7
0.6 921 3563 310 4174 303 3556 618 7
0.7 924 3560 310 4174 303 3553 621 7
B.C. Gencosman et al. / Information Processing and Management 50 (2014) 821–856 831We calculate the performance parameters of the model for the Excite dataset with different n and threshold values, and
present our findings in Table 8. The character n-gram method performs differently with different n and the threshold values.
The Fß(shift) and Fß(contin) results are successful, and after evaluating these findings, we choose the character 2-grams method
and the threshold value of 0.7, to compare the character n-gram method with previous methods.
Similar experiments are performed for the FAST dataset. The findings are detailed in Tables 9 and 10. Although the initial
size of the FAST sample is 10,007 queries, the sample size decreases to 9044 queries because the last queries of the sessions
Table 10
Performance analysis of the character n-gram method with the FAST dataset.
N-grams Threshold Pshift Pcontin Rshift Rcontin Fß(shift) Fß(contin)
1-Grams 0.5 0.306 0.941 0.177 0.970 0.210 0.959
0.6 0.341 0.951 0.332 0.952 0.335 0.952
0.7 0.361 0.965 0.552 0.927 0.461 0.941
2-Grams 0.5 0.390 0.991 0.894 0.896 0.604 0.929
0.6 0.385 0.994 0.932 0.889 0.610 0.926
0.7 0.383 0.996 0.952 0.886 0.613 0.924
3-Grams 0.5 0.379 0.996 0.958 0.884 0.611 0.922
0.6 0.379 0.998 0.977 0.881 0.616 0.921
0.7 0.377 0.998 0.977 0.880 0.614 0.921
4-Grams 0.5 0.330 0.998 0.977 0.853 0.566 0.902
0.6 0.329 0.998 0.977 0.852 0.564 0.901
0.7 0.328 0.998 0.977 0.851 0.563 0.900
832 B.C. Gencosman et al. / Information Processing and Management 50 (2014) 821–856are ignored. To compare the character n-gram method with previous methods, only the test sample of FAST dataset (4484
queries) is used for analysis. According to Table 9, the performance of the character n-gram method in terms of Type A and
Type B errors varies for different n and threshold values. Compared to the human expert findings, the character n-gram
method overestimates topic shifts, increasing the number of Type A errors. Conversely, the character n-gram method esti-
mates fewer topic continuations than the human expert. Further, these estimates are inversely proportional to the n and
threshold values. The estimated number of topic continuation instances decreases as the n and threshold values increase, even-
tually falling below the human expert results. These situations reduce Type B errors.
We calculate the performance parameters of the model for the FAST dataset with different n and threshold values,
and illustrate our findings in Table 10. The performance of the character n-gram method varies based on the n and the
threshold values. We achieve successful Fß(shift) and Fß(contin) results, and after evaluating these findings, we prefer the
character 2-grams method and the threshold value of 0.7 to compare the character n-gram method with previous
methods.
To evaluate the character n-gram method, we compare our approach with previous methods that use the same dataset.
The experimental results for the Excite and FAST datasets are presented in Tables 11 and 12, respectively.
According to Table 11, the character n-gram method incorrectly estimates topic shifts (Type A errors) more than the other
methods. Hence, incorrect estimates adversely affect the performance of the character n-gram method. Although the char-
acter n-gram method estimates topic shifts in the presence of a spelling mistake, its performance is poor in the absence of any
statistical characteristics of queries. Comparison of the Fß(shift) and Fß(contin) results shows that the neural network approach
performs better than the other methods, including the character n-gram method. Similar findings are shown for the FAST
dataset in Table 12.
More studies have been performed with the FAST dataset than the Excite dataset; hence, we use the former methods for
comparisons, as shown in Table 12. Evaluation of the results indicates that the character n-gram method incorrectly esti-
mates topic shifts (Type A errors) less than the neural network method. Conversely, the character n-gram method incorrectly
estimates topic continuations more than the neural network method.
Two faults are identified in the character n-gram method. First, the method identifies topic shifts that cannot be recog-
nized by other methods. However, it overestimates topic shifts, ignoring the statistical characteristics of consecutive queries.
Therefore, it performes worse than previous methods. Second, calculating the frequencies of sequential letters of consecutive
queries adversely affects the character n-gram method, and its performance parameter values. Similar n-grams of dissimilar
words increase the similarity ratio of consecutive queries. After comparing the similarity ratio with the determined threshold,
the character n-gram method estimates topic continuation instead of topic shift. These problems can be alleviated by consid-
ering the statistical characteristics of queries in the decision-making process. Thus, we combine the character n-gram
method with the neural network method in next sub-section, which is chosen as the best previous method in new topic
identification.
4.2. Combined character n-gram and neural network method
Based on previous estimates, the statistical methods, which use the same datasets, generate incorrect topic shift estimates
for similar queries that contain spelling differences and synonyms. As previously mentioned, synonyms, unlike spelling dif-
ferences, cannot be detected without content-based algorithms. The main problem with synonyms is the determination of
the search patterns of queries, which are determined automatically with an algorithm (Appendices A and B). If the algorithm
identifies one of the two consecutive query search patterns as ‘‘new’’, the statistical methodologies will generate a topic shift
label. Thus, the statistical methods will likely generate correct estimates if the query search patterns are determined correctly
despite the presence of spelling differences.
Table 11
Comparison results of different topic identification methods using the Excite dataset.
Origin of results # of queries
included in
analysis
# of topic
shifts
# of topic
contins
Correctly
estimated #
of shifts
Correctly
estimated #
of contins
Type A
error
Type B
error
Pshift Rshift Pcontin Rcontin Fß(shift) Fß(contin)
Human expert 3394 Ntrue shift = 272 Ntrue ontin = 3122 – – – – – – – – – –
Monte Carlo simulation 3394 Nshift = 393 Ncontin = 3001 Nshift&correct = 142 Ncontin&correct = 2871 251 130 0.36 0.53 0.96 0.92 0.45 0.94
Neural networks (2008) 3394 Nshift = 454 Ncontin = 2940 Nshift&correct = 237 Ncontin&correct = 2905 217 35 0.522 0.871 0.988 0.93 0.698 0.95
Character 2-grams thres. = 0.7 3394 Nshift = 739 Ncontin = 2655 Nshift&correct = 263 Ncontin&correct = 2646 476 9 0.356 0.967 0.997 0.848 0.590 0.897
B.C.G
encosm
an
et
al./Inform
ation
Processing
and
M
anagem
ent
50
(2014)
821–
856
833
Table 12
Comparison results of topic identification methods with the FAST dataset.
Origin of results # of queries
included
in analysis
# of topic
shifts
# of topic
contins
Correctly
estimated #
of shifts
Correctly
estimated #
of contins
Type A
error
Type B
error
Pshift Rshift Pcontin Rcontin Fß(shift) Fß(contin)
Human expert 4484 Ntrue shift = 310 Ntruecontin = 4174 – – – – – – – – – –
Monte Carlo Simulation 4484 Nshift = 338 Ncontin = 4146 Nshift&correct = 137 Ncontin&correct = 3973 201 173 0.41 0.44 0.96 0.95 0.43 0.95
Conditional probabilities 4484 Nshift = 276 Ncontin = 4208 Nshift&correct = 146 Ncontin&correct = 4044 130 164 0.529 0.471 0.961 0.968 0.491 0.966
Dempster Shafer theory 4484 Nshift = 836 Ncontin = 3648 Nshift&correct = 303 Ncontin&correct = 3641 533 7 0.362 0.977 0.998 0.872 0.642 0.907
Neural networks (2008) 4484 Nshift = 886 Ncontin = 3598 Nshift&correct = 306 Ncontin&correct = 3594 580 4 0.345 0.987 0.998 0.861 0.583 0.907
Character 2-gram thes. = 0.7 4484 Nshift = 770 Ncontin = 3714 Nshift&correct = 295 Ncontin&correct = 3699 475 15 0.383 0.952 0.996 0.886 0.613 0.924
834
B.C.G
encosm
an
et
al./Inform
ation
Processing
and
M
anagem
ent
50
(2014)
821–
856
B.C. Gencosman et al. / Information Processing and Management 50 (2014) 821–856 835When the incorrect results are analyzed, most of the query search patterns are identified as ‘‘new’’ by the automatic pat-
tern identification algorithm used in Ozmutlu et al. (2011). As a result of the training step of the neural network method, the
algorithm yields a topic shift decision when the search pattern is identified as ‘‘new’’ regardless of the other parameters. Thus,
recognizing incorrect search patterns due to spelling differences before the topic shift estimate may provide a different
method of evaluation for such queries while also altering the topic continuation estimates. To remove these incorrect search
pattern identifications, the character n-gram method can be used. However, using only the character n-gram method to iden-
tify the search patterns can cause problems due to excessive similarity between subsequent queries. Thus, to eliminate the
insufficiencies of these methods, the character n-gram algorithm can be carefully used to supplement the best estimate
results of the previous studies and thereby improve the topic shift estimate accuracy.
Based on the performance comparison of previous methods, the neural network method generates more accurate esti-
mates than the other applications (Ozmutlu et al., 2011). Therefore, the character n-gram method is applied to the neural
network results to improve the topic estimates, and to decrease the number of incorrect new topic identifications. In con-
clusion, in this approach, each word in the consecutive queries of a user session is analyzed based on its characters, and esti-
mates are made despite their relevancy.
As an example, we analyze the ‘‘cybersc@n’’ and ‘‘cyberscan’’ queries. After calculating a similarity ratio of 0.75 for the
consecutive queries shown in Table 6 with the character 2-grams and the threshold value of 0.7, the character n-gram
method concludes that these words are similar and labels the queries as topic continuation unlike the neural network
method. Even if these words are similar except for one letter, the search pattern of the second query is labeled as ‘‘new’’
(without using the proposed algorithm), and a topic shift estimate is generated by the neural network algorithm. If a spelling
difference can be determined, the search pattern is labeled as ‘‘next page (browsing)’’, and the second query requests another
set of results on the first query. As a result, the neural network algorithm does not generate topic shift estimates because the
updated pattern should be classified as ‘‘next page’’.
As mentioned before, the character n-gram method decides topic continuation simply by comparing the n-grams of two
words. Nevertheless, the queries from the FAST and Excite datasets usually contain more than one word; hence, comparisons
of words and their n-grams are more complicated than the previous situation. To overcome this complexity, the topic con-
tinuation is assumed when the character n-gram method decides that at least one of the words in the two queries is similar.
In fact, this assumption is logical considering the search patterns, because consecutive queries which are categorized as ‘‘next
page’’, ‘‘generalization’’, ‘‘specialization’’, or ‘‘reformulation’’ also contain similar words. Moreover, these categories are con-
sidered as topic continuation by the neural network algorithm. Therefore, with this assumption, when the character n-gram
method decides topic continuation, the updated queries are categorized as ‘‘next page’’, ‘‘generalization’’, ‘‘specialization’’, or
‘‘reformulation’’, and the method will improve the results by preventing incorrect estimates.
For example, comparison of consecutive queries (qi = congress and social security, and qi+1 = congressional retirement)
from the FAST dataset is given in Table 13. The neural network method labels the queries as topic shift based on their
‘‘new’’ search pattern. Conversely, the character 3-grams method estimates topic continuation due to the presence of similar
words such as ‘‘congress’’ and ‘‘congressional’’ for the threshold value of 0.6.
In this case, the 3-grams of six words should be compared to make a decision, as shown in Fig. 1. However, given the
aforementioned assumption, a topic continuation decision can be reached when the similarity ratio of at least one word pair
passes the determined threshold. Therefore, these queries will be labeled as topic continuation, and their search patterns will
be labeled as ‘‘generalization’’, ‘‘specialization’’ or ‘‘reformulation’’.
Determining search patterns accurately is crucial for the neural network method which can improve the estimate results.
Conversely, similar improvements can be made by applying the character n-gram method to topic shift estimates from the
neural network method. Therefore, topic shift estimates are updated with the character n-gram method.
To determine the best parameter values for the character n-gram method, many experiments are conducted using differ-
ent n and threshold values. For different n and threshold values, the performance parameters are calculated. Estimations of theTable 13
Comparison of queries with more than one word.
qi = congress Con-ong-ngr-gre-res-ess
qi+1 = congressional Con-ong-ngr-gre-res-ess-ssi-sio-ion-ona-nal
qi+1 = retirement Ret-eti-tir-ire-rem-eme-men-ent
qi = and and
qi+1 = congressional Con-ong-ngr-gre-res-ess-ssi-sio-ion-ona-nal
qi+1 = retirement Ret-eti-tir-ire-rem-eme-men-ent
qi = social Soc-oci-cia-ial
qi+1 = congressional Con-ong-ngr-gre-res-ess-ssi-sio-ion-ona-nal
qi+1 = retirement Ret-eti-tir-ire-rem-eme-men-ent
qi = security Sec-ecu-cur-uri-rit-ity
qi+1 = congressional Con-ong-ngr-gre-res-ess-ssi-sio-ion-ona-nal
qi+1 = retirement Ret-eti-tir-ire-rem-eme-men-ent
Table 14
Results from applying the character n-gram method to the Excite dataset.
N-grams Threshold Nshift Ncontin Ntrue,shift (HumanExpert) Ntrue,contin (HumanExpert) Nshift&correct Ncontin&correct Type A error Type B error
1-Grams 0.5 114 3280 272 3122 62 3070 52 210
0.6 187 3207 272 3122 101 3036 86 171
0.7 280 3114 272 3122 159 3001 121 113
2-Grams 0.5 389 3005 272 3122 220 2953 169 52
0.6 724 2670 272 3122 261 2659 463 11
0.7 739 2655 272 3122 263 2646 476 9
3-Grams 0.5 417 2977 272 3122 233 2938 184 39
0.6 422 2972 272 3122 234 2934 188 38
0.7 423 2971 272 3122 235 2934 188 37
4-Grams 0.5 423 2971 272 3122 234 2933 189 38
0.6 425 2969 272 3122 235 2932 190 37
0.7 427 2967 272 3122 235 2930 192 37
Neural network 454 2940 272 3122 237 2905 217 35
Table 15
Results from applying the character n-gram method to the FAST dataset.
N-grams Threshold Nshift Ncontin Ntrue,shift
(HumanExpert)
Ntrue,contin
(HumanExpert)
Nshift&correct Ncontin&correct Type A error Type B error
1-Grams 0.5 179 4305 310 4174 55 4050 124 255
0.6 301 4183 310 4174 103 3976 198 207
0.7 473 4011 310 4174 171 3872 302 139
2-Grams 0.5 707 3777 310 4174 277 3744 430 33
0.6 748 3736 310 4174 289 3715 459 21
0.7 767 3717 310 4174 295 3702 472 15
3-Grams 0.5 764 3720 310 4174 297 3707 467 13
0.6 781 3703 310 4174 303 3696 478 7
0.7 784 3700 310 4174 303 3693 481 7
4-Grams 0.5 790 3694 310 4174 303 3687 487 7
0.6 794 3690 310 4174 303 3683 491 7
0.7 795 3689 310 4174 303 3682 492 7
Neural network 886 3598 310 4174 306 3593 580 4
Table 16
Correct estimations of 38 Excite queries containing spelling differences.
Threshold Character n-grams
1-Grams 2-Grams 3-Grams 4-Grams
0.5 38 37 33 31
0.6 37 34 30 27
0.7 37 33 30 25
836 B.C. Gencosman et al. / Information Processing and Management 50 (2014) 821–856combined approach are compared with human expert evaluations for the Excite and FAST datasets, as shown in
Tables 14 and 15.
For the query length, n values vary from 1 to 4, and for each n, the results are calculated with threshold values between 0.5
and 0.7. For example, for a threshold value of 0.5, if half of the n-grams are equal, then second query will be labeled as topic
continuation.
From the results in Table 15, the character n-gram estimates include fewer Type A errors than the neural network
estimates for different n and threshold values. Conversely, the character n-gram estimates include more Type B errors than
the neural network estimates, although the numbers are reduced for larger n and threshold values.
According to the detailed query analysis, 38 queries in the Excite dataset (Appendix C) and 71 queries in the FAST dataset
(Appendix D) are estimated as topic shifts by the neural network method because of spelling differences. The character
n-gram method is expected to catch these errors and label them accurately.
Tables 16 and 17 illustrate the experiments for different n and threshold values and represent the correct query estimates
for the Excite and FAST dataset, respectively. These findings demonstrate that most of the query pairs are detected as the
Table 17
Correct estimations of 71 FAST queries containing spelling differences.
Threshold Character n-grams
1-Grams 2-Grams 3-Grams 4-Grams
0.5 71 70 66 59
0.6 71 69 65 56
0.7 70 68 64 57
Table 18
Performance evaluation of the character n-gram results with the Excite dataset.
N-grams Threshold Pshift Pcontin Rshift Rcontin Fß(shift) Fß(contin) %increase Fß(shift) %increase Fß(contin)
1-Grams 0.5 0.544 0.936 0.228 0.983 0.291 0.965 58.335 1.480
0.6 0.540 0.947 0.371 0.972 0.420 0.963 39.789 1.220
0.7 0.568 0.964 0.585 0.961 0.578 0.962 17.130 1.162
2-Grams 0.5 0.566 0.983 0.809 0.946 0.697 0.959 0.063 0.854
0.6 0.360 0.996 0.960 0.852 0.593 0.900 14.994 5.358
0.7 0.356 0.997 0.967 0.848 0.590 0.897 15.414 5.643
3-Grams 0.5 0.559 0.987 0.857 0.941 0.715 0.958 2.461 0.683
0.6 0.555 0.987 0.860 0.940 0.714 0.957 2.318 0.606
0.7 0.556 0.988 0.864 0.940 0.716 0.957 2.639 0.619
4-Grams 0.5 0.553 0.987 0.860 0.939 0.713 0.957 2.202 0.584
0.6 0.553 0.988 0.864 0.939 0.715 0.957 2.406 0.574
0.7 0.550 0.988 0.864 0.939 0.713 0.956 2.175 0.530
Neural network 0.522 0.988 0.871 0.930 0.698 0.951 0.000 0.000
Table 19
Performance evaluation of the character n-gram results with the FAST dataset.
N-grams Threshold Pshift Pcontin Rshift Rcontin Fß(shift) Fß(contin) %increase Fß(shift) %increase Fß(contin)
1-Grams 0.5 0.307 0.941 0.177 0.970 0.210 0.959 -63.947 5.703
0.6 0.342 0.951 0.332 0.953 0.336 0.952 -42.469 4.899
0.7 0.362 0.965 0.552 0.928 0.461 0.941 -20.966 3.743
2-Grams 0.5 0.392 0.991 0.894 0.897 0.605 0.930 3.687 2.481
0.6 0.386 0.994 0.932 0.890 0.611 0.926 4.692 2.073
0.7 0.385 0.996 0.952 0.887 0.615 0.925 5.292 1.895
3-Grams 0.5 0.389 0.997 0.958 0.888 0.620 0.926 6.253 2.005
0.6 0.388 0.998 0.977 0.885 0.625 0.924 6.987 1.863
0.7 0.386 0.998 0.977 0.885 0.623 0.924 6.742 1.808
4-Grams 0.5 0.384 0.998 0.977 0.883 0.620 0.923 6.254 1.700
0.6 0.382 0.998 0.977 0.882 0.618 0.922 5.932 1.627
0.7 0.381 0.998 0.977 0.882 0.618 0.922 5.852 1.609
Neural network 0.345 0.999 0.987 0.861 0.584 0.907 0.000 0.000
B.C. Gencosman et al. / Information Processing and Management 50 (2014) 821–856 837same query by the character n-gram method. Thus, these queries are marked as topic continuation instead of topic shift, and
the number of Type A errors decreases because the incorrect topic shift estimates are eliminated.
As shown in Table 16, the character 1-grams approach detects 38 incorrect query estimates with the threshold value of
0.5. Although the method can detect spelling differences, the linguistics of the experiment with 1-grams and threshold value
of 0.5, are not logical. Therefore, an n value of at least 2 is considered in evaluations. Similar experiments are performed using
the FAST dataset. As shown in Table 17, the character 1-grams approach detects 71 incorrect query estimates with the thresh-
old values of 0.5 and 0.6. However, n values of at least 2 are considered to ensure logical evaluations.
Based on the performance evaluation of the character n-gram method for the Excite and FAST datasets shown in Tables 18
and 19, respectively, the proposed method improves the accuracy of topic shift estimates. Given the Fß(shift) and Fß(contin) values
for the Excite dataset (Table 18), the best results are obtained with the character 3-grams the threshold value of 0.7, which
are presented in bold. With these parameter values, the highest increase, 2.639%, is observed for the Fß(shift) value. In the same
experiment, the improvement in the Fß(contin) parameter of 0.619% is also deemed to be acceptable.
In addition to these evaluations, for the threshold value of 0.7, the character 3-grams method yields 188 Type A errors,
while the neural network method yields 217 (Table 14). The character 3-grams method generates fewer Type A errors than
838 B.C. Gencosman et al. / Information Processing and Management 50 (2014) 821–856the neural network method, and although the number of Type A errors is reduced, the number of Type B errors increases to
37. However, this change is acceptable given the improvements in the other performance parameters.
Using the FAST dataset, the character n-gram estimates of the precision and recall parameters are more consistent than the
estimates from the neural network method (Table 19). Moreover, the character n-gram values of the fitness functions Fß(shift)
and Fß(contin) are greater than the values for the neural network method because the character n-gram method generates
more successful estimates. For the threshold value of 0.6, the character 3-grams yields Fß(shift) and Fß(contin) values of 0.625
and 0.924 which are presented in bold, respectively; the neural network approach yields Fß(shift) and Fß(contin) values of
0.584 and 0.907, respectively. As a result, the Fß(shift) value shows the largest increase at 6.987%. Further, the 1.863% improve-
ment in the Fß(contin) parameter is also deemed acceptable.
In addition to these evaluations, the character 3-grams and neural network methods yield 478 and 580 Type A errors,
respectively, for the threshold value of 0.6 as shown in Table 15. Consequently, the character 3-grams method generates
fewer Type A errors than the neural network method. Although the algorithm reduces the number of Type A errors, the char-
acter 3-grams generates seven Type B errors. However, this number is acceptable given the overall improvements in the per-
formance parameters.
5. Detailed analysis of the character n-gram method
5.1. Comparison between Levenshtein edit-distance and character n-gram
To evaluate the performance of the character n-gram method, we use Levenshtein edit-distance method, which is a fun-
damental tool for the similarity measure of two strings. The edit distance method computes an ‘‘edit distance’’ between two
strings that represents the minimum number of changes required to switch one string to another (Zobel & Dart, 1996). The
edit distance method and its improved versions have been used by many researchers in terms of clustering (Kuo & Chen,
2007) and spelling correction (Varol & Bayrak, 2011). Varol and Bayrak (2011) tried to clean the customer records using
the near miss strategy and edit distance tools effectively. They compared various similarity measurement strategies, such
as Soundex, Phonex, Phonix, DMetaphone, Levenshtein edit-distance, LCS, Jaro-Winkler, 2-grams, 3-grams and PNRS. The
experimental results demonstrated that the character n-gram method outperformed to Levenshtein edit distance method,
also it produced very close estimates with PNRS. Kuo and Chen (2007) proposed a metric of normalized chain edit distance
for event clustering, using a controlled vocabulary from cross-document co-reference chains. They developed different mod-
els, and summarized the experimental results. The experimental results expanded the positive effects of co-reference chains
and the controlled vocabulary in event clustering.
The Levenshtein edit-distance can be used to calculate similarity of two queries. The method computes the required
changes to transform one string to another, in terms of number of insertions, deletions and substitutions. Mathematically,
the Levenshtein edit-distance (Levenshtein, 1966) between two strings a, b is represented by leva,b(IaI, IbI) whereleva;bði; jÞ ¼
maxði; jÞ if minði; jÞ
min
leva;bði 1; jÞ þ 1
leva;bði; j 1Þ þ 1
leva;bði 1; j 1Þ þ ½ai – bj
8><
>:
otherwise:
8>><
>>:
ð12ÞThe minimum part of expression (12) presents the deletion, insertion and substitution from a to b. We demonstrate the
Levenshtein distance from queryi to queryi+1 as D(qi, qi+1), and use expression (12) to compute D(qi,qi+1) for each query pairs.
Then we calculate a difference ratio for the edit distance, which is similar to expression (11). However, we compute similar-
ities between two queries in the character n-gram method, but we calculate differences between two queries in the Levensh-
tein edit-distance. Therefore we consider the maximum length of queries as a denominator instead of minimum n-grams of
queries in expression (13).Difference ratio ¼ Dðqi; qiþ1Þ
maxfjqij; jqiþ1jg
ð13ÞIn order to decide the similarity of two queries, we define a threshold to compare with the difference ratio. If the difference
ratio of the Levenshtein distance is equal to or smaller than the threshold, we decide that two consecutive queries are similar
and we label them as topic continuation. On the other hand, if the difference ratio of two queries is greater than the threshold,
we conclude that these queries are different, and label them as topic shift.
We compare the performance of two methods, the character n-gram and the Levenshtein edit-distance using the same
threshold values of 0.5, 0.6 and 0.7 with previous experiments, and we choose n values of 2 and 3 (We reach best estimate
results with these parameters in Section 4). As mentioned before, we determine 38 queries from Excite, and 71 queries from
FAST dataset, which are labeled wrongly as topic shift by the neural network, and we aim to label them correctly by the char-
acter n-gram method. Therefore, we use the same datasets for the comparison between the Levenshtein edit-distance and
the character n-gram. The experimental results for the Excite dataset are summarized in Table 20. The first column repre-
sents the threshold values, the second part indicates the number of correct estimates by the character 2-grams, the character
3-grams, and the Levenshtein edit-distance (LD) respectively, the third part demonstrates the performance of the approaches
B.C. Gencosman et al. / Information Processing and Management 50 (2014) 821–856 839according to the correct estimates in percentage, and the last part indicates the performance gap between methods, which is
calculated by expression (14). The number of correct estimates of methods is represented by the n-gramcorrect and the
LDcorrect.Table 2
Correct
Thre
0.5
0.6
0.7Gap% ¼ n gramcorrect  LDcorrect
n gramcorrect
ð14ÞThe Levenshtein edit-distance is able to label at most 16 query pairs as topic continuation in 38 query pairs for the thresh-
old value of 0.5. On the other hand, the character 2-grams method outperforms to Levenshtein edit-distance and can detect
37 query pairs, and the character 3-grams method can detect 33 query pairs for the same threshold value. According to the
performance of the methods in percentage, the character 2-grams correctly estimates 97.37% of the query pairs for the
threshold value of 0.5. On the other hand, the Levenshtein edit-distance can only estimate 42.11% of the query pairs correctly
for the same threshold. The last column proves that the character n-gram method with different combinations of n-grams and
threshold outperforms to Levenshtein edit-distance. In worst case, for the threshold value of 0.5, the character 3-grams is
51.52% better than the Levenshtein edit-distance method, in terms of topic identification.
In addition to Table 20, we investigate the performance of two methods in detail. We only consider the correct estimates
of the Levenshtein edit-distance and examine that if the character n-gram is able to label all query pairs as topic continuation.
We detail the experiment results in Appendix C, and present them in Table 21. The first column indicates the filtered number
of query pairs, which are listed in sequence in Appendix C. The second column shows the real location of query pairs in the
whole dataset, the third column presents the query pairs and the other columns group the results of three approaches, the
character 2-grams, the character 3-grams and the Levenshtein distance (LD), in terms of the threshold values of 0.5, 0.6 and
0.7 respectively. If the approach in the sub-column can detect the topic continuation, it labels the first query of the query pair
as 1, and if the approach cannot detect the topic continuation, it labels the first query as 0. The last row illustrates the total
number of correct estimates of methods for different combinations.
Table 21 contains 16 query pairs which are estimated correctly by the Levenshtein edit-distance. According to analysis
results, the character 2-grams method is able to cover all correct estimates for different thresholds. For the threshold value
of 0.5, the character 2-grams detects 16 topic continuations same as the Levenshtein edit-distance, for the threshold value
of 0.6, while the Levenshtein edit-distance labels only 13 query pairs as topic continuation, the character 2-grams identifies
15 topic continuations, and for the threshold value of 0.7, the character 2-grams outperforms to the Levenshtein edit-distance
and detects 15 topic continuations instead of 10 topic continuations. Identifying a topic continuation is difficult for the high
threshold values, but the experimental results demonstrates that the character n-gram method is more powerful than the
Levenshtein edit-distance in terms of topic identification.
We repeat the same experiments with 71 query pairs from FAST dataset that are wrongly labeled as topic shift by the neu-
ral network, and we aim to label them correctly by the character n-gram method. The experimental results for the FAST data-
set are illustrated in Table 22. The first column represents the threshold values, the second part indicates the number of
correct estimates by the character 2-grams, the character 3-grams, and the Levenshtein edit-distance (LD) respectively,
the third part demonstrates the performance of the methods in terms of the correct estimates in percentage, and the last
part indicates the performance gap between methods which is calculated by expression (14).
The Levenshtein edit-distance is able to label at most 26 query pairs of 71 query pairs as topic continuation for the thresh-
old value of 0.5, which means 36.62% of query pairs in percentage. On the other hand, the character 2-grams method is able
to detect 98.59% of total query pairs correctly for the same threshold value. The last column demonstrates that the character
n-gram with different combinations of n and threshold outperforms to Levenshtein edit-distance for the FAST dataset. In the
worst case, for the threshold value of 0.7, the character 3-grams method is 59.38% better than the Levenshtein edit-distance
method in terms of topic identification.
Table 22 proves that the character n-gram method successfully detects similarities between the query pairs better than
the Levenshtein edit-distance. Considering the correct estimates of Levenshtein edit-distance method, we also analyze 71
query pairs, and examine that if the character n-gram is able to label all query pairs as topic continuation. We detail the
experiment results in Appendix D, and summarized them in Table 23. The first column indicates the number of query pairs,
the second column shows the real location of query pairs in the whole dataset, the third column presents the query pairs, and
the other columns group the results of three methods, the character 2-grams, the character 3-grams and the Levenshtein
distance (LD) for the threshold values of 0.5, 0.6 and 0.7 respectively. If the method in the sub-column can detect the topic0
estimates of the 38 Excite queries by 2-grams, 3-grams, and LD.
shold # of Correct estimates Performance% Gap%
2-Grams 3-Grams LD 2-Grams 3-Grams LD 2-Grams vs. LD 3-Grams vs. LD
37 33 16 97.37 86.84 42.11 56.76 51.52
34 30 13 89.47 78.95 34.21 61.76 56.67
33 30 10 86.84 78.95 26.32 69.70 66.67
Table 21
Analysis of the correct estimates of LD in the 38 Excite query pairs.
# of query
pairs
Seq. of queries in
dataset
Queries Threshold
0.5 0.6 0.7
2-
Grams
3-
Grams
LD 2-
Grams
3-
Grams
LD 2-
Grams
3-
Grams
LD
1 5542 scholarships 1 1 1 1 1 1 1 1 1
scholarship news
2 5561 creston iowa 1 1 1 1 1 0 1 1 0
southwestern iowa
3 6307 aerosmıth 1 1 1 1 0 1 1 0 1
aerosmith
4 6565 gorilla 2 1 1 1 1 1 1 1 1 1
gorilla bas
5 6819 physical testing firefighters 1 1 1 1 1 1 1 1 0
phsical requirements for
firefighters
6 7164 cards.ocx 1 1 1 1 1 1 1 1 0
cards.tlb
7 7166 cards vc 1 1 1 1 1 0 1 1 0
cards.dll
8 7329 screensaver 1 1 1 1 1 1 1 1 1
screen saver
9 7364 redbud trees 1 1 1 1 1 1 1 1 1
rdbud tree
10 7469 atlanta, georgia 1 1 1 1 1 0 1 1 0
sandy springs, georgia
11 7634 eniac 1 0 1 0 0 1 0 0 1
enıac
12 8480 wenn soft 1 1 1 1 1 1 1 1 1
wennsoft
13 8580 htp//tcarms 1 1 1 1 1 1 1 1 1
http;//tcarms
14 8989 black planet 1 1 1 1 1 1 1 1 1
blackplanet
15 9530 wal mart 1 1 1 1 1 1 1 1 1
walmart
16 10043 mitel semiconducter 1 1 1 1 1 1 1 1 0
plessey semiconductors
# of correct estimates 16 15 16 15 14 13 15 14 10
Table 22
Correct estimates of the 71 FAST queries by 2-grams, 3-grams, and LD.
Threshold # of Correct estimates Performance% Gap%
2-Grams 3-Grams LD 2-Grams 3-Grams LD 2-Grams vs. LD 3-Grams vs. LD
0.5 70 66 26 98.59 92.96 36.62 62.86 60.61
0.6 69 65 21 97.18 91.55 29.58 69.57 60.00
0.7 68 64 14 95.77 90.14 19.72 79.41 59.38
840 B.C. Gencosman et al. / Information Processing and Management 50 (2014) 821–856continuation, it labels the first query of the query pair as 1, and if the approach cannot detect the topic continuation, it labels
the first query as 0. The last row illustrates the total number of correct estimates of methods for different combinations.
Table 23 contains the 26 query pairs which are correctly estimated by the Levenshtein edit-distance. According to anal-
ysis results, the character 2-grams method is able to cover all correct estimates for all threshold values. For the threshold value
0.5, the character 3-grams cannot estimate first and second query pairs correctly. For the threshold value 0.6, the Levenshtein
edit-distance can only estimate 21 of 26 query pairs correctly, while the character 2-grams can estimate all of them correctly,
and the character 3-grams can estimate 24 of 26 query pairs correctly. In other words, for the threshold value 0.6, the char-
acter n-gram method is able detect all correct estimates of the Levenshtein edit-distance, except for the first two query pairs;
‘‘gu-5a and gu-5b’’ and ‘‘gu-5b and gu-43b’’. On the other hand, the character n-gram method outperforms to the Levensh-
tein edit-distance, and successfully detects similarities between longer queries. The performance gap between the character
2-grams and the Levenshtein edit-distance increases regarding to the threshold value of 0.7. For this threshold, the character
2-grams can detect all topic continuations correctly, but the Levenshtein edit-distance can only detect 14 of 26 query pairs
Table 23
Analysis of the correct estimates of LD in the 71 FAST query pairs.
# of query
pairs
Seq. of queries in
dataset
Queries Threshold
0.5 0.6 0.7
2-Grams 3-Grams LD 2-Grams 3-Grams LD 2-Grams 3-Grams LD
1 5241 gu-5a 1 0 1 1 0 1 1 0 1
gu-5b
2 5247 gu-5b 1 0 1 1 0 1 1 0 0
gu-43b
3 5447 national geographic 1 1 1 1 1 1 1 1 1
nationalgeografic
4 5539 telefonia 1 1 1 1 1 1 1 1 1
telefon a
5 5858 chinese traditional wedding dress 1 1 1 1 1 1 1 1 1
chinese traditional wedding apparels
6 6015 research software 1 1 1 1 1 0 1 1 0
simulation software
7 6339 shane mcmahon babe 1 1 1 1 1 0 1 1 0
shane mcmahon pamela paulshock
8 6346 shane mcmahon pamela paulshock 1 1 1 1 1 0 1 1 0
shane mcmahon news
9 6349 shane mcmahon babe 1 1 1 1 1 1 1 1 1
shane mcmahon love
10 6635 alpha-ionone 1 1 1 1 1 1 1 1 0
beta-ionone
11 7502 solid dispersion-methods 1 1 1 1 1 1 1 1 0
solid dispersion
12 7555 visual basic download 1 1 1 1 1 0 1 1 0
vb6 download
13 7754 horse having sex 1 1 1 1 1 1 1 1 1
horses havingsex
14 8340 cybersc@n 1 1 1 1 1 1 1 1 1
cyberscan
15 8378 diaper girls 1 1 1 1 1 1 1 1 0
diapers pics
16 8535 warmtekijker 1 1 1 1 1 1 1 1 0
warmte nachtkijker
17 8805 sportphoto 1 1 1 1 1 1 1 1 1
sport photo
18 8878 windows tweak 1 1 1 1 1 1 1 1 0
wintweak
19 9019 altrocunsumo 1 1 1 1 1 1 1 1 1
altroconsumo
20 9171 skill-network 1 1 1 1 1 1 1 1 1
skill networks
21 9192 wysiecki 1 1 1 1 1 1 1 1 1
wysiecka
22 9359 dire straits discography 1 1 1 1 1 0 1 1 0
mark knopfler discography
23 9808 vergussm rtel 1 1 1 1 1 1 1 1 1
vergussmörtel
24 9854 monstersound_video 1 1 1 1 1 1 1 1 0
balloon_monstersound_video
25 9927 d hnen 1 1 1 1 1 1 1 1 1
duehnen
26 9935 feuchtefotzen 1 1 1 1 1 1 1 1 1
feuchte fotzen
# of correct estimates 26 24 26 26 24 21 26 24 14
B.C. Gencosman et al. / Information Processing and Management 50 (2014) 821–856 841correctly. Moreover, the character 3-grams also can estimate all topic continuations correctly, except for the first two query
pairs.
Considering the detailed analysis of the character n-gram and the Levenshtein edit-distance estimates, we conclude that
the character 2-grams method can cover all estimates of the Levenshtein edit-distance method, and it can be used instead of
the Levenshtein edit-distance method in terms of topic identification. Although the Levenshtein edit-distance method is able
to detect the similarities between words, usually query pairs include more than one word, and hence the Levenshtein edit-
distance method fails to detect the topic continuation of query pairs. In addition to these results, the experimental results
demonstrate that the character n-gram method fails to detect the similarities between short words which contain spelling
842 B.C. Gencosman et al. / Information Processing and Management 50 (2014) 821–856mistakes. If we use a spelling correction method before the character n-gram method, we would improve the performance of
the character n-gram method. Therefore we investigate the performance change of character n-gram method with pre-pro-
cessed spelling correction methods in next sub-section.
5.2. Combining character n-gram with pre-processed spelling correction methods
To improve the performance of the character n-gram method, we investigate Type A errors in detail. The experimental
results show that the character n-gram method fails to detect similarities between short words which contain spelling
mistakes. If we use a spelling correction method before the character n-gram method, we would improve the perfor-
mance of the character n-gram method. Therefore, we consider one of the well-known spellers ASPELL. Recently, popular
search engines suggest alternative queries to users when the query contains a misspelled word. To evaluate the perfor-
mance of the character n-gram method, we use the corrections of query pairs by the Google and the Bing search engines.
We take into account the first suggestion of search engines, the first website, and ‘‘did you mean this’’ expression, and we
consider ASPELL’s first suggestion for the misspelled word. If the spelling correction method detects a misspelled word, it
suggests an alternative spelling of the word, and the dataset is updated by changing the misspelled word with the sug-
gested one.
We consider 38 Excite and 71 FAST query pairs for the experiments. We use original query pairs for the first two datasets,
and we generate six more datasets which are different from each other and updated by the spelling correction methods. The
corrections of methods are presented in Appendices E and F. Each correction method has different impact on the original
dataset, and some corrections improve the estimates, and some of them damage the query pairs which adversely affects
the estimates. Therefore if the correction method corrupts the query pair in the dataset and causes to estimate a topic shift
instead of a topic continuation, it is recorded as Corrupted estimates. On the other hand, if the correction method improves the
quality of query pair and ensures to estimate a topic continuation instead of a topic shift, it is recorded as Improved estimates.
We detail our findings in next sub-sections.
5.2.1. Character n-gram with ASPELL corrections
Islam and Inkpen (2009) emphasize that the correction precision (the fraction of suggestions that are correct) is important
as much as the correction recall (the fraction of errors corrected). Therefore, we consider the number of wrong corrections
besides the number of true corrections in Table 24. The first column illustrates the threshold values, and the second part indi-
cates the number of correct estimates in original and updated datasets. The second dataset is updated by ASPELL corrections,
and estimates are calculated by the character n-gram after correction process. The third part indicates the number of query
pairs which could not be estimated correctly because of the spelling correction, and the last part shows the number of query
pairs that are estimated correctly thanks to the correction method.
As seen in Table 24, the correction of Excite dataset by ASPELL adversely affects the performance of the character
n-gram, and the number of correct estimates is reduced by the updated dataset. In addition, the number of damaged esti-
mates is greater than the number of improved estimates, which means that ASPELL corrections reduces the performance
of the character n-gram method. We repeat our experiments considering the FAST dataset, which are presented in
Table 25.Table 24
Comparison of the original and the updated Excite dataset by ASPELL corrections.
Threshold # of correct estimates # of corrupted estimates # of improved estimates
Original dataset ASPELL dataset
2-Grams 3-Grams 2-Grams 3-Grams 2-Grams 3-Grams 2-Grams 3-Grams
0.5 37 33 34 31 4 3 1 2
0.6 34 30 32 30 3 4 0 3
0.7 33 30 30 30 4 4 1 4
Table 25
Comparison of the original and the updated FAST datasets by ASPELL corrections.
Threshold # of Correct Estimates # of Corrupted estimates # of Improved estimates
Original dataset ASPELL dataset
2-Grams 3-Grams 2-Grams 3-Grams 2-Grams 3-Grams 2-Grams 3-Grams
0.5 70 66 63 60 7 6 0 0
0.6 69 65 63 59 6 7 0 1
0.7 68 64 61 58 7 7 0 1
B.C. Gencosman et al. / Information Processing and Management 50 (2014) 821–856 843According to Table 25, the number of damaged estimates is greater than the number of improved estimates. Moreover,
the ASPELL correction cannot improve FAST estimates, but one query pair ‘‘hotels in istanbul’’ and ‘‘istanbul’’ (which was
‘‘istambul’’ in the original dataset). However, the character 2-grams method is able to detect similarity between ‘‘hotels
in Istanbul’’ and istambul’’ for threshold values of 0.5, 0.6 and 0.7, and the character 3-grams with the threshold value of
0.5. The ASPELL correction only improves the character 3-grams with threshold values of 0.6 and 0.7. Although, the ASPELL
correction improves only one topic continuation estimate, it damages at least six estimates of topic continuation, and hence
reduces the performance of the character n-gram method.
5.2.2. Character n-gram with Bing and Google corrections
To date, search engines have been collecting huge amount of data about their users for different purposes. They also
have been storing users’ search histories and they recommend alternative queries to users according to these historical
data. Therefore search engines can recognize special names, and specific terms, so they are more successful at detect-
ing a misspelled word than spelling correction methods. For example ASPELL assumes that the query pair ‘‘aerosmıth’’
and ‘‘aerosmith’’ is misspelled and changes this query pair to ‘‘Eros’’ and ‘‘azimuth’’ which is slightly different from the
first one. However, search engines are able to recognize ‘‘aerosmıth’’ and ‘‘aerosmith’’ because of their colossal
databases.
Table 26 demonstrates the comparison between the original and the updated Excite datasets by Bing and Google correc-
tions. The first column presents threshold values, the second part summarizes the number of correct estimates in three dif-
ferent datasets; the original Excite, the updated Excite by Bing, and the updated Excite by Google. The third part indicates the
number of query pairs which could not be estimated correctly because of the spelling correction, and the last part shows the
number of query pairs which is estimated correctly thanks to the updated datasets.
The number of correct estimates demonstrates that Bing and Google update the database in a good way, and these
corrections improve the performance of the character n-gram method. The correct estimates in the updated datasets are
equal to or greater than the original dataset. In addition, the Bing and Google corrections do not damage the original
query pairs and therefore the third part of Table 26 contains zero values for each n and threshold values. Moreover,
the number of improved estimates increases with threshold values. In other words, the character n-gram fails to detect
topic continuations for higher threshold values because of misspelling words, but after the correction, it is able to detect
these topic continuations. For example, the character 3-grams cannot label the ‘‘aerosmıth’’ and ‘‘aerosmith’’ query pair
as topic continuation for threshold values of 0.6 and 0.7. Bing and Google search engines correct ‘‘aerosmıth’’ to
‘‘aerosmith’’, and hence the character n-gram method is able to label the query pair as topic continuation for all threshold
values.
We repeat our experiments for the original and the updated FAST datasets by Bing and Google corrections in Table 27. The
first column presents threshold values, the second part summarizes the number of correct estimates in three different data-
sets; the original FAST, the updated FAST by Bing, and the updated FAST by Google search engine. The third part indicates the
number of query pairs which could not be estimated correctly because of the spelling correction, and the last part shows the
number of query pairs which is estimated correctly thanks to updated datasets.
The character n-gram method performs better with the updated versions of datasets. The update process does not
damage the original query pairs, so the third column contains zero values for each character n-gram combination. The
number of improved estimates is lower, but this does not mean that queries do not include spelling mistakes.
However, the character n-gram is able to detect query pairs with spelling mistakes, and label them as topic
continuation.
Google and Bing search engines correct only one query pair in FAST dataset; ‘‘hotels in istanbul’’ and ‘‘istambul’’, and
change the second query to ‘‘istanbul’’. The character 2-grams method can detect the similarity between ‘‘hotels in Istanbul’’
and istambul’’ query pair with threshold values of 0.5, 0.6 and 0.7. In addition, the character 3-grams also detects the
similarity of two queries with the threshold value of 0.5. The search engine correction only improves the character 3-grams
with threshold values of 0.6 and 0.7, which assures a powerful estimate.Table 26
Comparison of the original and the updated Excite datasets by Bing and Google.
Threshold # of Correct estimates # of Corrupted estimates # of Improved estimates
Original dataset Bing dataset Google dataset Bing dataset Google dataset Bing dataset Google dataset
2-
Grams
3-
Grams
2-
Grams
3-
Grams
2-
Grams
3-
Grams
2-
Grams
3-
Grams
2-
Grams
3-
Grams
2-
Grams
3-
Grams
2-
Grams
3-
Grams
0.5 37 33 37 34 37 34 0 0 0 0 0 1 0 1
0.6 34 30 34 32 34 33 0 0 0 0 0 2 0 3
0.7 33 30 34 32 34 33 0 0 0 0 1 2 1 3
844 B.C. Gencosman et al. / Information Processing and Management 50 (2014) 821–8565.3. The limitations of character n-gram
The experimental results so far show that the character 2-grams method is able to detect similarities between misspelled
words while keeping the correction precision. However, there are several types of spelling variations, and the performance of
the character n-gram method changes depending on these variations. Vilares et al. (2011) analyzed the performance of the
character 4-grams method in terms of different length of queries such as short queries, mid-size queries and long queries.
However, we have been trying to determine the spelling errors concerning words instead of queries, and to our knowledge,
the limitations of the character n-gram method have not been studied in letter/character level. For that reason, we examine
the limitations of the character n-gram method in terms of different types of spelling mistakes such as character substitu-
tion/insertion/deletion, word merging, word splitting and word reordering.
It has to be mentioned that the character n-gram method labels a query pair as topic continuation if they contain at least
one same word, regardless of the position in query. Thus, the character n-gram method is able to detect the similarity
between queries in situation of word reordering. For example, the Excite dataset contains ‘‘traveling to spain pampalona’’
and ‘‘spain the bull run’’ queries in sequence. The queries contain ‘‘spain’’ in a different order, and the character n-gram
method labels the first query as topic continuation.
The character n-gram method is able to detect similarities in situations of word merging and word splitting. For example,
the Excite dataset contains the query pair ‘‘etymol’’ and ‘‘etymology dict’’, and the character n-gram method labels the first
query as topic continuation regardless of n and threshold value, because the second query ‘‘etymology dict’’ contains the firstTable 27
Comparison of the original and the updated FAST datasets by Bing and Google.
Threshold # of correct estimates # of corrupted estimates # of improved estimates
Original dataset Bing dataset Google dataset Bing dataset Google dataset Bing dataset Google dataset
2-
Grams
3-
Grams
2-
Grams
3-
Grams
2-
Grams
3-
Grams
2-
Grams
3-
Grams
2-
Grams
3-
Grams
2-
Grams
3-
Grams
2-
Grams
3-
Grams
0.5 70 66 70 66 70 66 0 0 0 0 0 0 0 0
0.6 69 65 69 66 69 66 0 0 0 0 0 1 0 1
0.7 68 64 68 65 68 65 0 0 0 0 0 1 0 1
Table 28
The estimates of character n-gram method for spelling variations in the Excite and FAST datasets.
Dataset Spelling variation Total #of correct estimates
2-Grams 3-Grams
0.5 0.6 0.7 0.5 0.6 0.7
Excite Substitution 6 6 5 4 4 2 2
Insertion 3 3 3 3 3 3 3
Deletion 5 5 5 5 4 4 4
FAST Substitution 5 5 5 5 4 3 3
Insertion 14 14 14 14 13 13 13
Deletion 8 8 8 8 8 8 8
Table 29
Detailed analysis of character substitutions in the Excite dataset.
# of query pairs Seq. of queries in dataset Queries The character n-gram method
2-Grams 3-Grams
0.5 0.6 0.7 0.5 0.6 0.7
1 5490 toliet order online 1 1 0 0 0 0
Toto Ultramax toilet MS854114S
2 6307 aerosmıth 1 1 1 1 0 0
aerosmith
3 7380 melinoma cancer 1 1 1 1 0 0
melanoma
4 7634 eniac 1 0 0 0 0 0
enıac
5 10043 mitel semiconducter 1 1 1 1 1 1
plessey semiconductors
B.C. Gencosman et al. / Information Processing and Management 50 (2014) 821–856 845query ‘‘etymol’’. The similar situation can be observed for ‘‘wenn soft’’ and ‘‘wennsoft’’ query pair, which is labeled as topic
continuation by the character n-gram method.
To investigate the performance of the character n-gram method in situations of character substitution, insertion and dele-
tion, we consider 38 and 71 query pairs from the Excite and the FAST datasets respectively. We group the spelling variations
as seen in Table 28. We present the analysis results of two datasets together. The second column illustrates the type of spell-
ing variation, the third column shows the total number of spelling variation in the related dataset, and the fourth part dem-
onstrates the number of correct estimates regarding various n and threshold values.
According to analysis results, the character n-gram method can handle the situations of character deletion and character
insertion better than the character substitution. For example, the method correctly labels 3 of 3 character insertions, and 4 of
5 character deletions in the Excite dataset. Similarly, the character n-gram correctly labels 13 of 14 character insertions, and
8 of 8 character deletions in the FAST dataset. However, the method fails to detect the topic continuation of query pairs which
have character substitution situation. Especially for the Excite dataset, the method can could only label 2 of 6 character sub-
stitutions correctly in worst case, which is detailed in Table 29.
Considering the detailed analysis, the performance of the character n-gram depends on the length of misspelled word
and the position of substitution. For example, the character n-gram method is able to detect the topic continuation of
‘‘mitel semiconducter’’ and ‘‘plessey semiconductor’’ query pair for all n and threshold values in the Excite dataset, on
the other hand it cannot detect the topic continuation between ‘‘eniac’’ and ‘‘enıac’’ query pair, but the character 2-grams
and the threshold value of 0.5. Because ‘‘enıac’’ is shorter than ‘‘semiconducter’’, and the length of word determines the
number of n-grams and the similarity ratio. In this example, the similarity ratio of the related query pair would be 0.5,
and the character n-gram method would not be able to detect the topic continuation of ‘‘eniac’’ and ‘‘enıac’’ for higher
threshold values.
The experimental results so far demonstrate that, the character 2-grams method with the threshold value of 0.5 can
handle the words with more than 3 letters, and the misspelled letter at the beginning or at the end. For example, if
we had two consecutive queries as ‘‘and’’ and ‘‘anf’’, we would detect the topic continuation with the character 2-grams
method and the threshold value of 0.5, but we could not detect the topic continuation for higher threshold values. Moreover,
if the misspelled letter is at the middle of the word, we also would not determine the topic continuation with the character
2-grams method and the threshold value of 0.5 either. Although, the character 2-grams method can handle the misspelled
words in general, this analysis could be expanded considering the specific position of the misspelled letter and the length
of word.
6. Discussion
These results suggest that query typing information is significant for identifying new topics with content-ignorant algo-
rithms. However, this information is insufficient for all topic estimates. Content-ignorant methods that combine typing
information and the statistical characteristics of queries perform well in the process of new topic identification. As shown
in the previous section, the proposed method improves topic shift estimates in search engine queries by combining typing
information and statistical characteristics.
These findings show that the proposed content-ignorant hybrid algorithm more accurately estimates topics than previous
methods (Ozmutlu & Cavdur, 2005a; Ozmutlu et al., 2007, 2008a,b). Such improvements may also be obtained with content-
based algorithms, although our aim is to develop an improved content-ignorant algorithm for new topic identification. The
results prove that we have achieved our aim.
7. Conclusions and future research
In this paper, a hybrid content-ignorant algorithm for new topic identification is presented. Previous studies have shown
that typing mistakes and the presence of synonymous words in consecutive queries adversely affect the topic estimate per-
formance of content-ignorant algorithms. Although synonyms cannot be recognized without content information, spelling
differences can be captured based on the typing information of queries. Our results demonstrate that only using the typing
information of consecutive queries in the character n-gram method is insufficient for topic identification. Thus, we gather the
typing information and the statistical characteristics of queries by combining the character n-gram and neural network
methods. Using the character n-gram method as a supplement, we obtain more successful estimates, and we observe that
the character n-gram method significantly improves the results of the neural network method. We also examine the perfor-
mance of the character n-gram method in different aspects.
Unlike other approaches, our proposed method gathers content-ignorant information from search engine queries, such
as typing information, with less effort and then uses this information for automatic topic identification. The results show
that the proposed method improves upon the insufficiencies of previous methods. However, the performance of the pro-
posed methodology depends on n and threshold values, which must be determined according to the length of queries.
Hence, the performance of the method for specific n and threshold values can be different for different datasets. The pro-
posed method performes well with the character 3-grams and the threshold value of 0.7, but these parameters may be
846 B.C. Gencosman et al. / Information Processing and Management 50 (2014) 821–856insufficient for different datasets and situations. For example, the detailed analysis of the character n-gram estimations
presents that the character 2-grams method is more successful than the character 3-grams in terms of detecting the
spelling mistakes in queries. Future research can be focused on determining the average length of queries by using var-
ious search engine query logs and then identifying decision parameters in a general topic identification method that does
not depend on the length of queries. Further, the proposed method can be used to supplement content-based algorithms
to detect spelling errors by using the typing information from consecutive queries in the process of automatically iden-
tifying new topics.Appendix A: The detailed definitions of the classes of search patterns
 Unique (New): The second query has no common term compared to the first query.
 Next Page: The second query is identical to the first query, thus the second query requests another set of results on the
first query.
 Generalization: The second query has fewer terms than the first query, and all terms of the second query are in the first
query.
 Specialization: The second query has more terms that the first query and includes all the terms of the first query.
 Reformulation: Some (not all) of the terms of the second query are also included in the first query but the first query
has some other terms that are not included in the second query. This means that the user has added and deleted
some terms of the first query. Also if the user enters the same terms of the first query in different order, it is also
considered as reformulation. This incident cannot be considered as Next Page, where subsequent queries should be
identical.
 Relevance feedback: The second query has zero terms (empty) and it is generated by the system when the user selects the
choice of ‘‘related pages’’.
 Others: If the second query does not fit any of the above categories, it is labeled as other (Ozmutlu & Cavdur,
2005a,b).
Appendix B: Search pattern identification algorithm
Input: Queries Qi-1, Qi, Qi+1 (set of three subsequent queries)
Local: Qc, current query (as a string)
Qn, next query (as a string)
B = {t | t e Qc and t e Qn}, the set of terms (terms determined using ‘‘space’’ as a divider) that are common in both
Qc and Qn
C = {t | t e Qc and t R Qn}, the set of terms, which appear in Qc only
D = {t | t R Qc and t e Qn}, the set of terms, which appear in Qn only
Output: Search Pattern, SP
begin
if (Qi = = /) then
if (i= = 1) then SP = Other,
else Qc = Qi-1, // if Qi is empty (relevance feedback) then take the preceding query // (Qi-1) to analyze the relationship
Qn = Qi+1,
endif
else Qc = Qi,
Qn = Qi+1,
endif
SP = other //default value
if (Qn = = /) then SP = Relevance Feedback endif // if the next query is empty then //it is relevance feedback
if (Qn = = Qc) then SP = Next Page endif
if (B – / and C – / and D = =/) then SP = Generalization endif
if (B – / and C = = / and D – /) then SP = Specialization endif
if (B – / and C – / and D –/) then SP = Reformulation endif
if (Qn – Qc and B – / and C = = / and D = = /) then SP = Reformulation endif
if (Qc – / and B = = /) then SP = New endif
end
B.C. Gencosman et al. / Information Processing and Management 50 (2014) 821–856 847Appendix C: Estimations of the 38 Excite query pairs by the character 2-grams, the character 3-grams, and the
Levenshtein edit-distance (LD) methods# of
query
pairsSeq. of
queries in
datasetQueries Threshold0.5 0.6 0.72-Gram 3-Gram LD 2-Gram 3-Gram LD 2-Gram 3-Gram LD1 5310 naturism y nudisto 1 1 0 1 1 0 1 1 0
naturistwebjump2 5479 traveling to spain pampalona 1 1 0 1 1 0 1 1 0
spain the bull run3 5490 toliet order online 1 0 0 1 0 0 0 0 0
Toto Ultramax toilet MS854114S4 5542 scholarships 1 1 1 1 1 1 1 1 1
scholarship news5 5561 creston iowa 1 1 1 1 1 0 1 1 0
southwestern iowa6 6161 etymol 1 1 0 1 1 0 1 1 0
etymology dict7 6307 aerosmıth 1 1 1 1 0 1 1 0 1
aerosmith8 6565 gorilla 2 1 1 1 1 1 1 1 1 1
gorilla bas9 6588 childhood illnesses 0 0 0 0 0 0 0 0 0
chldrens ailment10 6637 allstate 1 1 0 0 0 0 0 0 0
statefarm11 6643 mccormack micro-headphone 1 1 0 1 1 0 1 1 0
moth phones 0112 6664 image dinosaurs 1 1 0 1 1 0 1 1 0
dinosaur eggs13 6707 information plasma displays 1 0 0 1 0 0 1 0 0
plsma physics14 6819 physical testing firefighters 1 1 1 1 1 1 1 1 0
phsical requirements for firefighters15 6967 hotmail 1 1 0 1 1 0 1 1 0
bobedsell@hotmail16 6999 dolphims sceern savers 1 1 0 1 1 0 1 1 0
free screen saver17 7003 thong contest 1 1 0 1 1 0 1 1 0
thongs18 7138 msnbc 1 1 0 1 1 0 1 1 0
wsfa msnbc19 7164 cards.ocx 1 1 1 1 1 1 1 1 0
cards.tlb20 7166 cards vc 1 1 1 1 1 0 1 1 0
cards.dll21 7329 screensaver 1 1 1 1 1 1 1 1 1
screen saver22 7364 redbud trees 1 1 1 1 1 1 1 1 1
rdbud tree23 7380 melinoma cancer 1 1 0 1 0 0 1 0 0
melanoma24 7469 atlanta, georgia 1 1 1 1 1 0 1 1 0
sandy springs, georgia25 7634 eniac 1 0 1 0 0 1 0 0 1
enıac26 7904 diseño de planta de una empresa 1 1 0 1 1 0 1 1 0(continued on next page)
Ap
Le
848 B.C. Gencosman et al. / Information Processing and Management 50 (2014) 821–856Appendix c: (continued)# of
query
pairspendi
vensh
# of
query
pairs
1
2
3
4
5
6
7
8
9
Seq. of
queries in
datasetx D: Estim
tein edit-d
Seq. of
queries in
dataset
5241
5247
5447
5539
5687
5756
5783
5855
5858Queriesations of the 71 FAST query pairs by
istance (LD) methods
Queries
gu-5a
gu-5b
gu-5b
gu-43b
national geographic
nationalgeografic
telefonia
telefon a
gunung
gua
monsanto acetic acid process
acetic acid production
midi broadway
midi it had to be you
chinese curved knife
chinese traditional wedding dress
chinese traditional wedding dress
chinese traditional wedding apparelsThreshold0.5the character 2-gra
Threshold
0.5
2-Gram 3-Gram LD
1 0 1
1 0 1
1 1 1
1 1 1
1 0 0
1 1 0
1 1 0
1 1 0
1 1 10.6ms, the character 3-g
0.6
2-Gram 3-Gram LD
1 0 1
1 0 1
1 1 1
1 1 1
0 0 0
1 1 0
1 1 0
1 1 0
1 1 10.72-Gram 3-Gram LD 2-Gram 3-Gram LD 2-Gramrams, an
0.7
2-Gram
1
1
1
1
0
1
1
1
1
3-Gramd the
3-Gram
0
0
1
1
0
1
1
1
1
LDindustrializadora de vinos
vinos27 8291 buddhism 1 1 0 1 1 0 1 1 0
buddhist greetings28 8480 wenn soft 1 1 1 1 1 1 1 1 1
wennsoft29 8525 dragonball legends rom 1 1 0 1 1 0 1 1 0
dreamcast roms30 8533 windows sdk 1 1 0 1 1 0 1 1 0
windows32 programming31 8580 htp//tcarms 1 1 1 1 1 1 1 1 1
http;//tcarms32 8653 holiday inn 1 1 0 1 1 0 1 1 0
redjacketinn33 8693 canadian embassy 1 1 0 1 1 0 1 1 0
canada immigration34 8989 black planet 1 1 1 1 1 1 1 1 1
blackplanet35 9120 en50022 a1 1 0 0 0 0 0 0 0 0
en5014036 9530 wal mart 1 1 1 1 1 1 1 1 1
walmart37 9757 shit/scat 1 1 0 1 1 0 1 1 0
scat/shit/pissing38 10043 mitel semiconducter 1 1 1 1 1 1 1 1 0
plessey semiconductorsLD
1
0
1
1
0
0
0
0
1
Appendix D: (continued)
# of
query
pairs
Seq. of
queries in
dataset
Queries Threshold
0.5 0.6 0.7
2-Gram 3-Gram LD 2-Gram 3-Gram LD 2-Gram 3-Gram LD
10 5954 hot briquette iron plant port hedland 1 1 0 1 1 0 1 1 0
port hedland western australia
11 6015 research software 1 1 1 1 1 0 1 1 0
simulation software
12 6202 schoolgirls spanked 1 1 0 1 1 0 0 0 0
spanking photos
13 6206 cross ibm pen 1 1 0 1 1 0 1 1 0
crosspad
14 6215 free nude gay boys pics 1 1 0 1 1 0 1 1 0
school young men spanked pics
15 6272 vegetable recipes 1 1 0 1 1 0 1 1 0
sauteed vegetables
16 6339 shane mcmahon babe 1 1 1 1 1 0 1 1 0
shane mcmahon pamela paulshock
17 6346 shane mcmahon pamela paulshock 1 1 1 1 1 0 1 1 0
shane mcmahon news
18 6349 shane mcmahon babe 1 1 1 1 1 1 1 1 1
shane mcmahon love
19 6432 free tarot card reading 1 1 0 1 1 0 1 1 0
free valentine backgrounds
20 6631 cheap airfare tickets 1 1 0 1 1 0 1 1 0
line ticket domestic
21 6635 alpha-ionone 1 1 1 1 1 1 1 1 0
beta-ionone
22 6707 www.virginblue.com.au 1 1 0 1 1 0 1 1 0
virgin blue airline
23 6727 poetry criticism 1 1 0 1 1 0 1 1 0
e.e. cummings criticisms
24 6777 congress and social security 1 1 0 1 1 0 1 1 0
congressional retirement
25 7006 colorado state taxes 1 1 0 1 1 0 1 1 0
federal tax returns
26 7040 school nudes 1 1 0 1 1 0 1 1 0
highschoolers fucking each other
27 7124 a2p source 1 1 0 1 1 0 1 1 0
a2ps
28 7317 french american grapevine 1 1 0 1 1 0 1 1 0
ohio grape growers
29 7319 northern grape growers 1 1 0 1 1 0 1 1 0
grapevine rootstock
30 7370 pickering nuclear 1 1 0 1 1 0 1 1 0
canadian national report for the
convention on nuclear safety
31 7404 steamboat realty 1 1 0 1 1 0 1 1 0
maui real estate
32 7418 grado headphones 1 1 0 1 1 0 1 1 0
headphone ratings
33 7422 headphone ratings 1 1 0 1 1 0 1 1 0
grado headphones
34 7502 solid dispersion-methods 1 1 1 1 1 1 1 1 0
solid dispersion
35 7509 beijing capital airport flight 1 1 0 1 1 0 1 1 0
beijing flight information
(continued on next page)
B.C. Gencosman et al. / Information Processing and Management 50 (2014) 821–856 849
Appendix D: (continued)
# of
query
pairs
Seq. of
queries in
dataset
Queries Threshold
0.5 0.6 0.7
2-Gram 3-Gram LD 2-Gram 3-Gram LD 2-Gram 3-Gram LD
36 7555 visual basic download 1 1 1 1 1 0 1 1 0
vb6 download
37 7709 easy rent a car 1 1 0 1 1 0 1 1 0
budget rental cars
38 7710 budget rental cars 1 1 0 1 1 0 1 1 0
uk car hire
39 7739 am602 1 0 0 1 0 0 1 0 0
yamaha am mixer
40 7754 horse having sex 1 1 1 1 1 1 1 1 1
horses havingsex
41 7755 horses havingsex 1 1 0 1 1 0 1 1 0
sex with animals
42 7860 newton apollo program 1 1 0 1 1 0 1 1 0
apollo15
43 8002 messe frankfurt 1 1 0 1 1 0 1 1 0
messe k ln
44 8299 enter the dragon bruce lee pics 1 1 0 1 1 0 1 1 0
bruce lee multimedia
45 8301 lee siu long 1 1 0 1 1 0 1 1 0
rare bruce lee pics
46 8340 cybersc@n 1 1 1 1 1 1 1 1 1
cyberscan
47 8378 diaper girls 1 1 1 1 1 1 1 1 0
diapers pics
48 8391 freeware e-mail software 1 1 0 1 1 0 1 1 0
freeware32
49 8395 freeware32 1 1 0 1 1 0 1 1 0
internet freeware
50 8535 warmtekijker 1 1 1 1 1 1 1 1 0
warmte nachtkijker
51 8624 ordanence survey maps 1 1 0 1 1 0 1 1 0
map nottinghamshire online
52 8805 sportphoto 1 1 1 1 1 1 1 1 1
sport photo
53 8863 paparazzi photos nues 1 1 0 1 1 0 1 1 0
severine ferrer nue
54 8878 windows tweak 1 1 1 1 1 1 1 1 0
wintweak
55 8908 bitumen price 1 1 0 1 1 0 1 1 0
thinners price list
56 8919 hotels in istambul 1 1 0 1 0 0 1 0 0
istanbul
57 9019 altrocunsumo 1 1 1 1 1 1 1 1 1
altroconsumo
58 9171 skill-network 1 1 1 1 1 1 1 1 1
skill networks
59 9192 wysiecki 1 1 1 1 1 1 1 1 1
wysiecka
60 9359 dire straits discography 1 1 1 1 1 0 1 1 0
mark knopfler discography
61 9432 smooth weave copper cable 1 1 0 1 1 0 1 1 0
lightning grounding copper cable
62 9436 jfk international airport 1 1 0 1 1 0 1 1 0
850 B.C. Gencosman et al. / Information Processing and Management 50 (2014) 821–856
Appendix D: (continued)
# of
query
pairs
Seq. of
queries in
dataset
Queries Threshold
0.5 0.6 0.7
2-Gram 3-Gram LD 2-Gram 3-Gram LD 2-Gram 3-Gram LD
airports rename
63 9591 tasa de referencia 1 1 0 1 1 0 1 1 0
tasas bancarias
64 9734 university of cincinnati 1 1 0 1 1 0 1 1 0
cyo sports cincinnati
65 9741 ancient africa 1 1 0 1 1 0 1 1 0
african girls
66 9770 amature movie clips 1 1 0 1 1 0 1 1 0
jerking off movies
67 9808 vergussm rtel 1 1 1 1 1 1 1 1 1
vergussmörtel
68 9854 monstersound_video 1 1 1 1 1 1 1 1 0
balloon_monstersound_video
69 9867 musikmaker 0 0 0 0 0 0 0 0 0
musikprogramme
70 9927 d hnen 1 1 1 1 1 1 1 1 1
duehnen
71 9935 feuchtefotzen 1 1 1 1 1 1 1 1 1
feuchte fotzen
Appendix E: Correction of the 38 Excite query pairs by the spelling correction methods
# of
query
pairs
Seq. of
queries in
dataset
Queries Corrections of spellers
Bing Google ASPELL
1 5310 naturism y nudisto Naturist nudist Naturist nudist
naturistwebjump
2 5479 traveling to spain pampalona Traveling to spain
pamplona
Pamelina
spain the bull run
3 5490 toliet order online Toilet order online Toilet on line
Toto Ultramax toilet MS854114S Ultra max
4 5542 scholarships
scholarship news
5 5561 creston iowa Cresting
southwestern iowa
6 6161 etymol Emil
etymology dict
7 6307 aerosmıth Aerosmith Aerosmith Eros
aerosmith Azimuth
8 6565 gorilla 2
gorilla bas
9 6588 childhood illnesses
chldrens ailment Children’s
10 6637 allstate
statefarm State farm
11 6643 mccormack micro-headphone McCormick
moth phones 01
12 6664 image dinosaurs
dinosaur eggs
13 6707 information plasma displays
plsma physics Plasma
(continued on next page)
B.C. Gencosman et al. / Information Processing and Management 50 (2014) 821–856 851
Appendix E: (continued)
# of
query
pairs
Seq. of
queries in
dataset
Queries Corrections of spellers
Bing Google ASPELL
14 6819 physical testing firefighters
phsical requirements for firefighters Physical
15 6967 hotmail Hot mail
bobedsell@hotmail
16 6999 dolphims sceern savers Dolphins
screensavers
Dolphins CERN
free screen saver
17 7003 thong contest
thongs
18 7138 msnbc Masonic
wsfa msnbc Sofa Masonic
19 7164 cards.ocx .Cox
cards.tlb .TB
20 7166 cards vc .Vic
cards.dll .Dall
21 7329 screensaver screen saver
screen saver
22 7364 redbud trees
rdbud tree Redbud
23 7380 melinoma cancer Melanoma cancer Melanoma
melanoma
24 7469 atlanta, georgia
sandy springs, georgia
25 7634 eniac Anica
enıac
26 7904 diseño de planta de una empresa
industrializadora de vinos
vinos
27 8291 buddhism
buddhist greetings
28 8480 wenn soft wennsoft wennsoft Wen
wennsoft UniSoft
29 8525 dragonball legends rom Dragon ball
dreamcast roms Dream cast
30 8533 windows sdk
windows32 programming
31 8580 htp//tcarms tcarms.com tcarms.com
http;//tcarms
32 8653 holiday inn
redjacketinn Redacting
33 8693 canadian embassy
canada immigration
34 8989 black planet BlackPlanet BlackPlanet
blackplanet Black planet
35 9120 en50022 a1
en50140
36 9530 wal mart Walmart Walmart Wahl
walmart Wilmar
37 9757 shit/scat
scat/shit/pissing
38 10043 mitel semiconducter Mitel
semiconductor
Mitel
semiconductor
Motel
semiconductor
plessey semiconductors Please
852 B.C. Gencosman et al. / Information Processing and Management 50 (2014) 821–856
Appendix F: Correction of the 71 FAST query pairs by the spelling correction methods
# of
query
pairs
Seq. of
queries
in dataset
Queries Corrections of spellers
Bing Google ASPELL
1 5241 gu-5a
gu-5b
2 5247 gu-5b
gu-43b
3 5447 national geographic
nationalgeografic
4 5539 telefonia Telephone
telefon a Telephone
5 5687 gunung Gunning
gua GA
6 5756 monsanto acetic acid process
acetic acid production
7 5783 midi broadway
midi it had to be you
8 5855 chinese curved knife
chinese traditional wedding dress
9 5858 chinese traditional wedding dress
chinese traditional wedding apparels
10 5954 hot briquette iron plant port hedland
port hedland western australia
11 6015 research software
simulation software
12 6202 schoolgirls spanked
spanking photos
13 6206 cross ibm pen
crosspad Cross pad
14 6215 free nude gay boys pics
school young men spanked pics
15 6272 vegetable recipes
sauteed vegetables
16 6339 shane mcmahon babe
shane mcmahon pamela paulshock
17 6346 shane mcmahon pamela paulshock
shane mcmahon news
18 6349 shane mcmahon babe
shane mcmahon love
19 6432 free tarot card reading
free valentine backgrounds
20 6631 cheap airfare tickets
line ticket domestic
21 6635 alpha-ionone Ion one
beta-ionone Ion one
22 6707 www.virginblue.com.au
virgin blue airline
23 6727 poetry criticism
e.e. cummings criticisms
24 6777 congress and social security
congressional retirement
25 7006 colorado state taxes
federal tax returns
26 7040 school nudes
highschoolers fucking each other High schoolers
(continued on next page)
B.C. Gencosman et al. / Information Processing and Management 50 (2014) 821–856 853
Appendix F: (continued)
# of
query
pairs
Seq. of
queries
in dataset
Queries Corrections of spellers
Bing Google ASPELL
27 7124 a2p source
a2ps
28 7317 french american grapevine
ohio grape growers
29 7319 northern grape growers
grapevine rootstock
30 7370 pickering nuclear
canadian national report for the
convention on nuclear safety
31 7404 steamboat realty
maui real estate
32 7418 grado headphones Grad
headphone ratings
33 7422 headphone ratings
grado headphones Grad
34 7502 solid dispersion-methods
solid dispersion
35 7509 beijing capital airport flight
beijing flight information
36 7555 visual basic download
vb6 download
37 7709 easy rent a car
budget rental cars
38 7710 budget rental cars
uk car hire
39 7739 am602
yamaha am mixer
40 7754 horse having sex
horses havingsex Having sex
41 7755 horses havingsex Having sex
sex with animals
42 7860 newton apollo program
apollo15
43 8002 messe frankfurt Mess
messe k ln Mess
44 8299 enter the dragon bruce lee pics
bruce lee multimedia
45 8301 lee siu long
rare bruce lee pics
46 8340 cybersc@n
cyberscan Cyberspace
47 8378 diaper girls
diapers pics
48 8391 freeware e-mail software
freeware32
49 8395 freeware32
internet freeware
50 8535 warmtekijker Mortgagee
warmte nachtkijker Warmed nutcracker
51 8624 ordanence survey maps Ordnance
map nottinghamshire online Nottingham’s on line
52 8805 sportphoto Sport photo
sport photo
854 B.C. Gencosman et al. / Information Processing and Management 50 (2014) 821–856
Appendix F: (continued)
# of
query
pairs
Seq. of
queries
in dataset
Queries Corrections of spellers
Bing Google ASPELL
53 8863 paparazzi photos nues Nus
severine ferrer nue Severing NE
54 8878 windows tweak
wintweak Win tweak
55 8908 bitumen price
thinners price list
56 8919 hotels in istambul Hotels in
istanbul.
Hotels in
istanbul
Istanbul
istanbul
57 9019 altrocunsumo Altroconsumo altruism
altroconsumo altruism
58 9171 skill-network
skill networks
59 9192 wysiecki Sickie
wysiecka Seka
60 9359 dire straits discography
mark knopfler discography Knopf
61 9432 smooth weave copper cable
lightning grounding copper cable
62 9436 jfk international airport
airports rename
63 9591 tasa de referencia Tass de referential
tasas bancarias Tass’s binaries
64 9734 university of cincinnati
cyo sports cincinnati Coy
65 9741 ancient africa
african girls
66 9770 amature movie clips Armature
jerking off movies
67 9808 vergussm rtel Verges rt el
vergussmörtel Vigesimal
68 9854 monstersound_video Monster sound
balloon_monstersound_video
69 9867 musikmaker Music maker Muckraker
musikprogramme Multiprogram
70 9927 d hnen Dehnen D hen
duehnen Deneen
71 9935 feuchtefotzen Festivities
feuchte fotzen Fichte frozen
B.C. Gencosman et al. / Information Processing and Management 50 (2014) 821–856 855References
Beeferman, D., & Berger, A. (2000). Agglomerative clustering of a search engine query log. In Proceedings of ACM SIGKDD International Conference on
Knowledge Discovery and Data Mining.
Beitzel, S. M., Jensen, E. C., Chowdhury, A., Grossman, D., & Frieder, O. (2004). Hourly analysis of a very large topically categorized Web query log. In
Proceedings of the 27th annual International Conference on Research and Development in Information Retrieval, Sheffield, UK, pp. 321–328.
Brill, E., & Moore, R. (2000). An improved error model for noisy channel spelling correction. In Proceedings of the ACL, 2000, 286–293.
Canvar, W.B., & Trenkle, J.M. (1994). N-gram-based text categorization. In Proceedings of the Third Annual Conference on Document Analysis and Information
Retrieval (SDAIR), Las Vegas, pp. 161–175.
Chau, M., Lu, Y., Fang, X., & Yang, C. C. (2009). Characteristics of character usage in Chinese Web searching. Information Processing and Management, 45,
115–130.
Cooley, R., Mobasher, A., & Srivastava, J. (1999). Data preparation for mining worldwide web browsing patterns. Knowledge and Information Systems, 1, 5–32.
Cucerzan, S., & Brill, E. (2004). Spelling correction as an iterative process that exploits the collective knowledge of web users. In Proceedings of EMNLP, 2004,
293–300.
Damashek, M. (1995). Gauging similarity with n-Grams: Language-Independent categorization of text. Science, 267(5199), 843–848.
Damerau, F. J. (1964). A technique for computer detection and correction of spelling errors. Communications of ACM, 7(3), 171–176.
El-Nasan A., & Perrone, M. (2002). On-line handwriting recognition using character bigram match vectors. In Proceedings of the Eighth International Workshop
on Frontiers in Handwriting Recognition IWFHR-8, IEEE Computer Society Press, pp. 67–71.
856 B.C. Gencosman et al. / Information Processing and Management 50 (2014) 821–856Giacomo, E. D., Didimo, W., Grilli, L., Liotta, G., & Palladino, P. (2007). Graph visualization techniques for web clustering engines. IEEE Transactions on
Visualization and Computer Graphics, 13(2), 294–304.
Goker, A., & He, D. (2000). Analyzing Intranet logs to determine session boundaries for user-oriented learning. In Proceedings of AH2000: The international
conference on adaptive hypermedia and adaptive web-based systems, Trento, Italy, pp. 319–322.
He, D., Goker, A., & Harper, D. J. (2002). Combining evidence for automatic Web session identification. Information Processing and Management, 38, 727–742.
Huang, X., Peng, F., An, A., Shuurmans, D., & Cercone, N. (2003). Applying machine learning to text segmentation for information retrieval. Information
Retrieval, 6, 333–362.
Islam, A., & Inkpen, D. (2009). Real-word spelling correction using Google Web 1T n-gram with backoff. In Natural Language Processing and Knowledge
Engineering, 2009. NLP-KE 2009. International Conference on (pp. 1–8). IEEE.
Jansen, B. J., Booth, D. L., & Spink, A. (2007). Determining the informational, navigational, and transactional intent of Web queries. Information Processing and
Management, 44, 1251–1266.
Kamaris, I., & Stamatatos, E. (2007). Webpage genre identification using variable-length character n-grams. In 19th IEEE International Conference on Tools
with Artificial Intelligence, pp. 3–10.
Kuo, J. J., & Chen, H. H. (2007). Cross-document event clustering using knowledge mining from co-reference chains. Information Processing and Management,
43(2), 327–343.
Leung, K. W.-T., Ng, W., & Dik, L. L. (2008). Personalized concept-based clustering of search engine queries. Knowledge and Data Engineering, IEEE
Transactions, 20(11), 1505–1518.
Levenshtein, V. I. (1966, February). Binary codes capable of correcting deletions, insertions and reversals. In Soviet physics doklady (10), 707.
Liu, H., & Keselj, V. (2007). Combined mining of web server logs and web contents for classifying user navigation patterns and predicting users’ future
requests. Data & Knowledge Engineering, 61, 304–330.
McNamee, P., & Mayfield, J. (2004). Character N-gram tokenization for European language text retrieval. Information Retrieval, 7, 73–97.
Muresan, G., & Harper, D. J. (2004). Topic modeling for mediated access to very large document collections. Journal of the American Society for Information
Science and Technology, 55, 892–910.
Ozmutlu, H. C., & Cavdur, F. (2005a). Application of automatic topic identification on excite web search engine data logs. Information Processing and
Management, 41(5), 1243–1262.
Ozmutlu, S., & Cavdur, F. (2005b). Neural network applications for automatic new topic identification. Online Information Review, 29, 34–53.
Ozmutlu, H. C., Cavdur, F., & Ozmutlu, S. (2006). Automatic new topic identification in search engine data logs. Internet Research: Electronic Networking
Applications and Policy, 16, 323–338.
Ozmutlu, H. C., Cavdur, F., & Ozmutlu, S. (2008b). Cross-validation of neural network applications for automatic new topic identification. Journal of the
American Society for Information Science and Technology, 59(3), 339–362.
Ozmutlu, H. C., Cavdur, F., Spink, A., & Ozmutlu, S. (2004a). Neural network applications for automatic new topic identification on excite web search engine
data logs. In Proceedings of ASIST 2004: 67th Annual Meeting of the American Society for Information Science and Technology, Providence, RI, pp. 317–323.
Ozmutlu, S., Ozmutlu, H. C., & Buyuk, B. (2007). Using conditional probabilities for automatic new topic identification. Internet Research: Electronic
Networking Applications and Policy, 37, 491–515.
Ozmutlu, S., Ozmutlu, H. C., & Buyuk, B. (2008a). A Monte-Carlo simulation application for automatic new topic identification of search engine transaction
logs. Simulation Modeling Practice and Theory, 16, 519–538.
Ozmutlu, S., Ozmutlu, H. C., & Cosar, G. C. (2011). Neural network applications for automatic new topic identification of FAST and excite search engine
transaction logs. Expert Systems, The Journal of Knowledge Engineering, Online Library, 28(2), 101–122.
Ozmutlu, S., Ozmutlu, H. C., & Spink, A. (2004b). A day in the life of Web searching: An exploratory study. Information Processing and Management, 40,
319–345.
Ozmutlu, S., Spink, A., & Ozmutlu, H. C. (2002). Analysis of large data logs: An application of Poisson sampling on excite web queries. Information Processing
and Management, 38, 473–490.
Pu, H. T., Chuang, S.-L., & Yang, C. (2002). Subject categorization of query terms for exploring web users’ search interests. Journal of the American Society for
Information Science and Technology, 53(8), 617–630.
Roark, B., Saraclar, M., & Collins, M. (2007). Discriminative n-gram language modeling. Computer Speech & Language, 21, 373–392.
Robertson, A. M., & Willett, P. (1998). Applications of n-grams in textual information systems. Journal of Documentation, 54(1), 48–69.
Senda, S., & Yamada, K., (2001). A maximum likelihood approach to segmentation-based recognition of unconstrained handwriting text. In Proceedings of the
Sixth International Conference on Document Analysis and Recognition, Seattle, WA, pp. 184–188.
Shafer, G. (1976). A mathematical theory of evidence. Princeton, NJ: Princeton University Press.
Shannon, C. E. (1951). Prediction and entropy of printed English. Bell System Technical Journal, 30, 50–64.
Silverstein, C., Henzinger, M., Marais, H., & Moricz, M. (1999). Analysis of a very large Web search engine query log. ACM SIGIR Forum, 33(1), 6–12.
Spink, A., Bateman, J., & Jansen, B. J. (1999). Searching heterogeneous collections on the Web: A survey of excite users. Internet Research: Electronic
Networking Applications and Policy, 9(2), 117–128.
Spink, A., Jansen, B. J., Blakely, C., & Koshman, S. (2006). A study of results overlap and uniqueness among major Web search engines. Information Processing
and Management, 42, 1379–1391.
Spink, A., Ozmutlu, H. C., & Ozmutlu, S. (2002). Multitasking information seeking and searching processes. Journal of the American Society for Information
Science and Technology, 53(8), 639–652.
Spink, A., Wolfram, D., Jansen, B. J., & Saracevic, T. (2001). Searching the Web: The public and their queries. Journal of the American Society for Information
Science and Technology, 53(2), 226–234.
Varol, C., & Bayrak, C. (2011). Estimation of quality of service in spelling correction using Kullback-Leibler divergence. Expert Systems with Applications, 38(5),
6307–6312.
Vilares, J., Vilares, M., & Otero, J. (2011). Managing misspelled queries in IR applications. Information Processing and Management, 47(2), 263–286.
Wen, J., Nie, J.-Y., & Zhang, H. (2002). Clustering user queries of a search engine. ACM Transactions on Information Systems, 20(1), 59–81.
Zobel, J., & Dart, P. (1996). Phonetic string matching: Lessons from information retrieval. In Proceedings of the 19th annual international ACM SIGIR conference
on research and development in information retrieval (SIGIR 96) (pp. 30–38). Zurich, ACM.
