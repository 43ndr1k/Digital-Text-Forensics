A Variant of N-Gram Based Language
Classification
Andrija Tomović1 and Predrag Janičić2
1 Friedrich Miescher Institute for Biomedical Research
Part of the Novartis Research Foundation
Maulbeerstrasse 66, CH-4058 Basel, Switzerland
andrija.tomovic@fmi.ch
2 Faculty of Mathematics, University of Belgrade,
Studentski trg 16,11000 Belgrade, Serbia
janicic@matf.bg.ac.yu
Abstract. Rapid classification of documents is of high-importance in
many multilingual settings (such as international institutions or Internet
search engines). This has been, for years, a well-known problem, ad-
dressed by different techniques, with excellent results. We address this
problem by a simple n-grams based technique, a variation of techniques
of this family. Our n-grams-based classification is very robust and suc-
cessful, even for 20-fold classification, and even for short text strings. We
give a detailed study for different lengths of strings and size of n-grams
and we explore what classification parameters give the best performance.
There is no requirement for vocabularies, but only for a few training
documents. As a main corpus, we used a EU set of documents in 20 lan-
guages. Experimental comparison shows that our approach gives better
results than four other popular approaches.
1 Introduction
The problems of similarities and dissimilarities between different languages and
classification of multi-language documents have many everyday applications.
One of them is automated classification of web pages, required, for instance,
for restricting search only to documents written in a given language. Multi-
lingual institutions, like EU, handle documents in more than twenty languages
and rapid processing of such data is absolutely vital1. Automated classification
of multi-language text has been studied for years and a variety of techniques
give very good results.
In this paper we present a new variant of classification of multi-language doc-
uments based on n-grams. N-grams have been successfully used for a long time
in a wide variety of problems and domains, including text compression, spelling
1 There are 3400 people employed on translation and publications tasks in the Euro-
pean Commission. The annual budget for translations (between 23 languages) tasks
is one billion Euros.
R. Basili and M.T. Pazienza (Eds.): AI*IA 2007, LNAI 4733, pp. 410–421, 2007.
c© Springer-Verlag Berlin Heidelberg 2007
A Variant of N-Gram Based Language Classification 411
error detection and correction, information retrieval, automatic text categoriza-
tion, authorship attribution, finding topical similarity between documents, but
also in domains not related to language processing such as music representa-
tion, computational immunology, analysis of whole-genome protein sequences,
protein classification and phylogenetic tree reconstruction (for more details and
references see [14]).There are n-gram based techniques for distinguishing be-
tween documents written in different languages related to the work presented
in this paper [3, 11]. Experimental comparison shows that our variation of n-
grams-based classification is better than four other successful approaches to the
language classification.
Overview of the paper. In Section 2 we give some basic definition and preliminary
information. In Section 3 we describe our methodology for classification of multi-
language documents, and the data we used for our analyses. In Section 4 we
present and discuss our experimental results. In Section 5 we briefly discuss
related work, and in Section 6 we present experimental comparison between our
system and four other language classification tools. In Section 7 we draw final
conclusions.
2 Preliminaries
In this section we give a brief overview of the notion of n-grams, of classification,
and some algorithms for addressing this problem.
N-grams
Given a sequence of tokens S = (s1, s2, ..., sN+(n−1)) over the token alphabet A,
where N and n are positive integers, an n-gram of the sequence S is any n-
long subsequence of consecutive tokens. The ith n-gram of S is the sequence
(si, si+1, ..., si+n−1) [13]. Note that there are N such n-grams in S. There are
|A|n different n-grams over the alphabet A (where |A| is the size of A).
For example, if A is the English alphabet, and l a string over the alphabet A,
l = life_is_a_miracle, then 1-grams are: l, i, f, e, _, i, s, a, m, r, c; 2-grams
are: li, if, fe, e_, _i, is, s_, _a, . . .; 3-grams are: lif, ife, fe_, e_i, . . . ;
4-grams are: life, ife_, fe_i, . . . and so on.
When used in processing natural-language documents, n-grams show some of
its good features:
– robustness: relatively insensitive to spelling variations/errors;
– completeness: token alphabet known in advance;
– domain independence: language and topic independent;
– efficiency: one pass processing;
– simplicity: no linguistic knowledge is required.
The problem with using n-grams is exponential combinatorial explosion. If A
is the Latin alphabet with the space delimiter, then |A| = 27. If one distinguishes
between upper and lower case letters, and also uses numerical digits, then |A| =
63. It is clear that many of algorithms with n-grams are computationally too
expensive even for n = 5 or n = 6 (for instance, 635 ≈ 109).
412 A. Tomović and P. Janičić
Dissimilarity measures
Dissimilarity measure d is a function on two sets of texts P1 and P2 (defining
specific profiles) and it should reflect the dissimilarity between these two. In the
following text, by (dis)similarity of texts we denote a measure of (dis)similarity
of two n-gram distributions.
In [2], some pioneer methods for the authorship attribution problem2 and dis-
similarity measures were discussed. For a range of language processing problems
there were proposed techniques based on n-grams. For the authorship attribu-
tion problem, the bigram letter statistic was used: two texts are compared for
the same authorship, using the dissimilarity formula:
d(M, N) =
∑
I,J
[M(I, J) − E(I, J)] · [N(I, J) − E(I, J)] (1)
where I and J are indices over the range {1, 2, . . . , 26}, i.e., all letters of the En-
glish alphabet; M and N are two texts written in the English alphabet; M(I, J)
and N(I, J) are normalized character bigram frequencies for these texts and
E(I, J) is the same normalized frequency for “standard English”. The technique
is based on the following idea: the smaller d(M, N), the more likely is that the
author of the text N is the same as the author of the text M . As the bigram
frequencies of “standard English” are obviously language-dependent parameters,
another dissimilarity measure is given:
d(M, N) =
∑
I,J
[M(I, J) − N(I, J)]2 . (2)
Following the ideas from [2, 8], a wide range of new dissimilarity functions
were introduced and tested in [14]. The following functions performed best on
different sets of problems:
d′(P1, P2) =
∑
n∈profile
|f1(n) − f2(n)|√
f1(n) · f2(n) + 1
(3)
d′′(P1, P2) =
√ ∑
n∈profile
(f1(n) − f2(n))2 (4)
where profile is a set of all n-grams appearing in P1 or P2 and fi(n) is a normal-
ized frequency for n-gram n in the set Pi. While the function d′′ is widely used,
as far as we know, the dissimilarity function d′′ was introduced recently in [14].
Classification
Given a set of objects, which is partitioned into a finite set of classes, classifica-
tion is the task of automatically determining the class of an unseen object, based
2 The authorship attribution problem is as follows: given texts written by authors A1,
A2, . . . An, and one additional piece of text, guess who of the given authors wrote
that piece of text.
A Variant of N-Gram Based Language Classification 413
typically on a model trained on a set of objects with known class memberships.
Classification is a supervised process, in a sense that it typically requires labelled
training data to train a classifier.
We use the following simple classification method based on n-grams [14]: for
a given set of families Pi, i = 1, 2, . . . , k and the given object e, compute the
dissimilarity measures d({e}, Pi), i = 1, 2, . . . , k. If the value d({e}, Ps) is the
smallest one, then the guess is that e belongs to the family Ps. Thus, the classifi-
cation algorithm is simple and its quality completely relies on the appropriateness
of the dissimilarity measure used. This is essentially the well-known k Nearest
Neighbours (kNN) classification method, with k = 1 [6].
3 Methodology and Data
For classification, we use the algorithm described in Section 2. For dissimilarity
measure, we use the functions d′ and d′′ (as given by the equations (3) and (4)).
Our corpus is made out of documents in 20 European languages available from
the EU web site3. For each language we took 20 documents for the corpus4. These
are not necessarily translations of the same texts. Table 1 shows the list of these
20 languages and their codes.5
Table 1. Language codes
code language code language
cs Czech lt Lithuanian
da Danish hu Hungarian
de German mt Maltese
et Estonian nl Dutch
el Greek pl Polish
en English pt Portuguese
es Spanish sk Slovakian
fr French sl Slovenian
it Italian fi Finish
lv Latvian sv Swedish
We consider the classification in the following way: for each language we ran-
domly take 15 (out of 20) documents as a training corpus, for building n-gram
language profiles. Then we classify the remaining 20×5 documents6 and count a
percentage of correct guesses. The variant of this classification task is as follows:
3 http://europa.eu/
4 The whole corpus is available from:
http://www.fmi.ch/members/andrija.tomovic/corpus-all.zip.
5 Complete Unicode table of language codes can be found at:
http://unicode.org/onlinedat/languages.html
6 Test documents are available from:
http://www.fmi.ch/members/andrija.tomovic/test.zip.
414 A. Tomović and P. Janičić
from the test documents (20× 5 of them) we produce all subsequences of length
L (L=10, 20, 30, . . .) and apply the classification algorithm to these sequences.
The motivation for this experiment is exploring the lower limits in length of
documents for reliable classification.
The algorithm is implemented using Visual C# (Visual Studio 2003) within
a wider application7. The application offers a range of functionalities concern-
ing classification and clustering algorithms and the user can choose between a
number of dissimilarity functions [14].
4 Experimental Results
The basic classification task (classification of 20 × 5 documents) is performed
in the way described in Section 3. Table 2 shows success rates for dissimilarity
functions d′ and d′′.8 It can be seen that the success rate for both functions
is perfect 100% for small values of n. The quality of the results is very high,
especially taking into account that the classification is 20-fold (i.e., each test
document was supposed to be classified into one of 20 categories). As expected,
the success rate decreases as n increases (after some value). Indeed, long (e.g.,
10 characters long) n-grams do not have high frequencies, so the classification
results cannot be very stable. Despite that, success rate for d′ remain 99% for
n = 8, 9, 10, with only one error (one document in the Slovakian language clas-
sified as being in the Czech language). As observed for different domains in [14],
the function d′ performed better than d′′, proving its quality in classification
problems.
Table 2. Success rates for dissimilarity functions d′ and d′′ in classification of multi-
language documents
n 1 2 3 4 5 6 7 8 9 10
d′ 100% 100% 100% 100% 100% 100% 100% 99% 99% 99%
d′′ 100% 100% 100% 100% 100% 99% 92% 88% 84% 28%
The above results show excellent success rate for classification of whole docu-
ments. The question is whether shorter texts would also be successfully classified.
Of course, very short strings (e.g., up to 20 characters) are very unlikely to be
classified with high success rate (since n-gram frequencies in one short string can
be very different than frequencies in the whole of the language). It is interesting
to explore what string length is sufficient for obtaining high (say, more than
99%) success rate in classification. The following experiment is aimed at answer-
ing this question. As in the previous experiment, for each language we take 15
7 The application is available from:
http://www.fmi.ch/members/andrija.tomovic/NgramsApplication.zip
8 All training data and the detailed experimental results can be obtained upon request
from the first author.
A Variant of N-Gram Based Language Classification 415
0 20 40 60 80 100 120 140 160 180 200 220 240 260 280 300 320 340
10
20
30
40
50
60
70
80
90
100
n = 1
n = 5
n = 10
L
success rate (%)
Fig. 1. Success rate for classification of strings of length L, by using n-grams with
different values of n
(out of 20) documents as a training corpus, for building the n-gram language
profile. Then we construct all L-substrings (L-grams) from the remaining 20× 5
documents and count a percentage of correct guesses for these L-grams, as for
strings to be classified. For classification of these strings, we used n-grams for
different values of n. Figure 1 shows the results for n=1, 5, 10, for L=10, 30, . . .
For all values of n, almost perfect success rate is reached for L as small as 300.
For all values of L the success rate was best for n= 5. For n=5, 93% success rate
is reached for L as small as 50, and 99% success rate is reached for L equal 150.
The value n=5 gives the best results because:
– Short n-grams cannot distinguish different languages easily. Namely, different
languages with similar alphabets can have similar frequencies for some n-
grams, and hence, a short test text, with non-representative distribution
of n-grams (non-representative w.r.t. the language it belongs to), can be
wrongly classified.
– Long n-grams have lower and lower frequencies and become more and more
language- and string-specific. Table 3 and Table 4 show the first 10 most
frequent n-grams in training data set for Italian and English. It can be seen
that with higher n, n-grams become highly dependent on the training set.
Long n-grams make better distinguishing between different languages, but
on the other hand, text from the same language which is not from the same
domain as the training data set is difficult to be recognized (this is well-
known over-fitting problem).
416 A. Tomović and P. Janičić
Table 3. The most frequent n-grams (top 10) in training data for the Italian language
n=1 n=2 n=3 n=4 n=5 n=6 n=7 n=8 n=9 n=10
e de di ione zione azione zione de ommission ommissione
i i di ione azion azione zione d azione d mmissione Commissio
e a ion zion zione ione d ione de ione del Commissi Commission
a d re one ation e dell della missione Commissio a Commissi
o o di del dell mento europe mmission zione del mmissione
t on one azio che one de amento ommissio a Commiss la Commiss
r re ne che e del amento delle Commissi missione zione dell
n ti to dell e di sione one del Commiss ione dell azione del
l c zio con del della ssione deputat azione de terrorismo
s er co la del della issione a Commis terroris terrorism
Table 4. The most frequent n-grams (top 10) in training data for the English language
n=1 n=2 n=3 n=4 n=5 n=6 n=7 n=8 n=9 n=10
e th the the n the of the of the European European
e t the of and of th of the European European Parliament
t th he to tion of the Europe uropean arliament Commission
o a ion and ation that uropean on the Parliamen arliament
a he on and n the f the Europea Europea terroris Commissio
i s to tion of t ation on the rliament ommission e European
n n to ing for Europe ropean arliamen Commissio e Commissi
r d of ion of th Europ on the in the rliament he Commiss
s in of ment f the the E in the Parliame Commissi Parliamen
h on an in that uropea in the terroris e Europea he Europea
The results shown in Figure 1 also suggest a general classification strategy:
if the string that is to be classified is shorter than 350, apply the classification
procedure with n=5, otherwise apply the classification procedure with n=1 (be-
cause the success rates are almost equal for n=5 and n=1, and the classification
for larger n is more time-consuming).
In order to make a system more efficient, the option is to take into account only
a certain number of most frequent n-grams (instead of considering all occurring
n-grams). However, in that case, classification with the functions d′ and d′′ is
not perfect for all values of n. The results of classification performed using the
first 100 most frequent n-grams are given in Table 5. For 1-grams results are the
same (perfect 100%) like in Table 2 because there are no more than 100 1-grams.
For 2-grams, 3-grams, 4-grams results are good, because first 100 most frequent
n-grams (n=2,3,4) represents a significant portion of the set of all 2,3,4-grams. In
these cases, the result of the training phase is a set of only 20×100×n characters,
yielding a knowledge sufficient for perfect identification of 20 languages.
We can conclude that our n-grams based technique gives excellent results,
even for 20-fold classification of documents in different languages, and even for
short strings. For this sort of classification, there is no need for vocabularies,
A Variant of N-Gram Based Language Classification 417
Table 5. Success rates for dissimilarity functions d′ and d′′ in classification of multi-
language documents using only the first 100 most frequent n-grams
n 1 2 3 4 5 6 7 8 9 10
d′ 100% 100% 100% 100% 90% 68% 54% 35% 35% 27%
d′′ 100% 100% 100% 100% 94% 76% 69% 59% 54% 51%
but only for a very small amount of training data. For training data we used
only 15, rather short documents for each of 20 languages. For instance, training
data for English had a total size of only 52Kb and around 2000 different words
(including different forms).
It is interesting to report on the dissimilarities (based on the given functions)
between profiles for different languages. To a somewhat surprise, these dissimi-
larities are not in accordance with the traditional clustering of languages — for
instance, the English language is closer to the Italic languages than to the Ger-
manic languages (this is true for both dissimilarity functions, for all values of n,
and for the variant with 100 most frequent n-grams used). A possible explana-
tion for this could be that written languages and distributions of their n-grams
do not reflect deeper relationships between spoken languages.
5 Related Work
Automated classification has been studied for years and there is a number of
methods for these problem. Also, there are many techniques for classification
of documents in different languages and many of them give excellent results.
However, some of them use some language-specific knowledge, some are applied
to specific corpora, some are applied over specific sets of languages, and so it
is not easy to make a direct, relevant comparison between different approaches.
In [12] there is a good overview of different approaches to this problem, includ-
ing approaches based on the presence of specific characters, on the presence of
specific letter combinations, on the presence of specific words, on distribution of
n-grams, etc.
The technique presented in [3] is based on using an ad hoc rank order statis-
tic to compare the prevalence of n-grams. The test and training texts are first
tokenized in order to avoid sequences which straddle two words. Comparison
between test and training profiles was based on comparing rankings of the most
frequent n-grams. There are results for 8-fold classification (over 8 languages),
and for test strings long 300 characters or more.
A n-gram-based Bayesian classifier is described in [7]. The technique is domain
independent and does not require tokenization. There are results only for 2-fold
classification (over English and Spanish). As expected, classification success rate
is higher with longer training data and longer test data, and generally better
results are obtained for bigrams and trigrams. For 50Kb of training sets and for
20 bytes of input string, the success rate was 92%, while for 500 bytes of input
string, the success rate was even 99.9%.
418 A. Tomović and P. Janičić
Approach based on n-grams, described in [10], uses simple information theo-
retic principles (perplexity and entropy) in combination with Bayesian decision
theory. That technique has been evaluated on four different languages and four
different text categorization problems.
The technique presented in this paper is similar to the one from [12], but
based on different dissimilarity functions. The technique from [12] is applied to
18-fold language classification and it performs well even with short training and
test data, it is simple and easy to implement. The success rate goes from 78.2%
for 1-grams, for 200 lines of training data, and 1 line of test data, up to 100%
for 2-grams, 2000 lines of training data, and 20 lines of test data.
In a recent paper [9], the problem of identifying language in web documents
is addressed, for which the authors claim that it is more difficult variant of the
problem. The authors use n-grams and several dissimilarity measures and reach
around 91% success rates for 12-fold language classification.
There is another recent paper [4], addressing the problem of language identifi-
cation and some of its hard variants: including distinguishing between European
and Brazilian variants of Portuguese and identifying small tourists advertise-
ments. The proposed, n-gram based, approach was also used for the standard
language identification problem: the system was trained by 235 documents writ-
ten in 19 European languages, and tested by 290 new test samples — once of
size at least 6 lines (with 100% success rate) and once of size 4 lines (with 98.9%
success rate). The system was also tested for identifying European and Brazilian
variants of Portuguese (with 200 training documents and 369 test documents),
reaching 98.37% success rate.
6 Experimental Comparison to Other Tools
We performed the experimental comparison between our system and several
well-known tools:
Xerox language identifier is based on [1]. The algorithm performs the clas-
sification by calculating probabilities, based on n-gram probabilities for each
language from a training data set. It has support for 47 languages.
Unknown language identification 9 is based on the algorithm described in
[5]. The method uses a vector with frequencies of all n-grams for training
profiles. The distance function is defined as cosine function of the angle
between the sample text vector and each of text vector from the library. It
has support for 66 languages.
TextCat is an implementation of the text categorization method described in
[3]. This algorithm is similar to the algorithm proposed here. A preprocessing
of the input text is performed, and digits and punctation are discarded. In
order to generate a profile, the method uses all n-grams for n=1,2,3,4,5
on preprocessed text. Then the first 300 most frequent n-grams are used
by different methods for comparing n-gram profiles. It has support for 77
languages.
9 http://complingone.georgetown.edu/~langid/
A Variant of N-Gram Based Language Classification 419
SILC 10 uses Bayesian decision theory and classic Noisy Channel statical ap-
proach. This approach is different from our method and uses only 1-grams
and 3-grams. It has support for 39 languages.
Table 6. Experimental results of four language classification tools
Tool success rate comment
XEROX 99.00% (99/100)
ULI 98.75% (79/80) no support for el,mt,sl,sk
TextCat 97.89% (93/95) no support for mt
SILC 97.33% (73/75) no support for lt,lv,mt,sk,sl
We used the corpus and the test data described in Section 3.11 For testing the
above tools, we used the set of 100 documents that we used as a test set for our
system, so — all systems were ran on the same documents. Some of the above four
tools do not have support for some languages, so the total of available tests was
lower for some tools. Table 6 shows the experimental results. As it can be seen,
all the tools performed in an excellent way, however none of them reached perfect
success, unlike our approach (see the results in Table 2 and Table 5). Despite the
fact that the above tools have support for more languages than our system, the
given results are still relevant and fair. Namely, almost all wrong (5 out of 6) clas-
sifications made by the tested tools pointed to the languages that our system also
has support for(with one exception for SCI). The most frequent error (4 out of 6)
was wrongly classifying czech documents as slovakian and vice versa.
For further evaluation of our method we also used one chapter of the Bible
like in work [10]. In that work authors used translation of one chapter into 6
different languages and achieved 100% accuracy. We used one chapter (Ruth) in
10 different languages. We have used fist two subchapter for the training data
set and the rest for test data. Our approach has achieved 100% accuracy for all
size n-grams.
7 Conclusions
We presented a new variant of a language classification algorithm based on
n-grams (using the dissimilarity function recently introduced in [14]). We
10 http://rali.iro.umontreal.ca/
11 Unfortunately, for most of approaches described in Section 5, data sets and software
which authors used are not publicly, freely available. This makes it difficult to
perform a fair comparison between different existing tools and further evaluation
of the presented method. Trying to promote another practice, we provide all data
and tools which we used publicly availably. A good practice is also using rich sources
of freely available multilingual corpora (and specifying used subsets), such as the
one we use in this paper (http://europa.eu/, http://eur-lex.europa.eu/),
or collections of translations of the Bible (http://bibledatabase.net/,
http://www.biblegateway.com/).
420 A. Tomović and P. Janičić
analyzed its performance on the test documents written in 20 languages. The
results are very good, and they reach perfect 100% success rate for our corpus
of integral documents (for small size of n-grams). There is also high success
rate for very short fragments of test text, reaching 99%, while longer frag-
ments were classified with 100% success rate. These are very good results,
especially taking into account that the classification is 20-fold. This sort of
classification does not require massive vocabularies, but only very few train-
ing documents in different languages. We made an experimental comparison
of our tool with four other language classification tools, and it gave the best
performance. Our classification mechanism is fast, robust, and does not re-
quire any knowledge of the different languages. We believe it can be used in
different contexts, like in multi-lingual institutions, and in Internet search
engines.
References
[1] Beesley, K.R.: Language Identifier: A Computer Program for Automatic Natural-
Language Identification of On-Line Text. In: Languages at Crossroads: Proceeding
of the 29 th Annual Conference of the American Translator Association, pp. 47–54
(1988)
[2] Bennett, W.R.: Scientific and engineering problem-solving with the computer.
Prentice-Hall, Inc., Englewood Cliffs, New Jersey (1976)
[3] Cavnar, W.B., Trenkle, J.M.: N-gram-based text categorization. In: Proceedings
of the 1994 Symposium On Document Analysis and Information Retrieval, Uni-
versity of Nevada, Las Vegas (April 1994)
[4] da Silva, J.F., Lopes, G.P.: Identification of document language is not yet a com-
pletely solved problem. In: CIMCA. International Conference on Computational
Intelligence for Modeling, Control & Automation, IEEE Computer Society Press,
Los Alamitos (2006)
[5] Damashek, M.: Gauging similarity with n-grams: Language independent catego-
rization of text. Science 267, 843–848 (1995)
[6] Dunham, M.H.: Data Mining Introduction and Advanced Topics. Southern
Methodist University, Pearson Education Inc., New Jersey (2003)
[7] Dunning, T.: Statistical Identification of Language. Technical Report Technical
report. CRL MCCS-94-273, Computing Research Lab, New Mexico State Univer-
sity (1994)
[8] Kešelj, V., Peng, F., Cercone, N., Thomas, C.: N-gram-based author profiles for
authorship attribution. In: PACLING’03. Proceedings of the Conference Pacific
Association for Computational Linguistics, August 2003, Dalhousie University,
Halifax, Nova Scotia, Canada (2003)
[9] Martins, B., Silva, M.J.: Language identification in web pages. In: Proceedings of
the 2005 ACM symposium on Applied computing, ACM Press, New York (2006)
[10] Pegn, F., Schuurmans, D., Wang, S.: Language and Task Independent Text Cat-
egorization with Simple Language Models. In: Proceedings of Human Language
Technology Conference, pp. 110–117 (2003)
A Variant of N-Gram Based Language Classification 421
[11] Schmitt, J.: Trigram-based method of language identification. U.S. Patent num-
ber: 5062143 (October 1991)
[12] Sibun, P., Reynar, J.C.: Language identification: Examining the issues. In: Pro-
ceedings of 5th Symposium on Document Analysis and Information Retrieval
(1996)
[13] Tauritz, D.: Application of n-grams. Department of Computer Science, University
of Missouri-Rolla
[14] Tomović, A., Janičić, P., Kešelj, V.: n-Gram-based classification and unsupervised
hierarchical clustering of genome sequences. Computer Methods and Programs in
Biomedicine 81(2), 137–153 (2006)
