This article was downloaded by: [University of Aegean]
On: 25 May 2012, At: 05:15
Publisher: Routledge
Informa Ltd Registered in England and Wales Registered Number: 1072954 Registered
office: Mortimer House, 37-41 Mortimer Street, London W1T 3JH, UK
English Studies
Publication details, including instructions for authors and
subscription information:
http://www.tandfonline.com/loi/nest20
Stylometry and Authorship Attribution:
Introduction to the Special Issue
Javier Calle-Martín a & Antonio Miranda-García a
a Department of English, University of Malaga, Spain
Available online: 22 May 2012
To cite this article: Javier Calle-Martín & Antonio Miranda-García (2012): Stylometry and
Authorship Attribution: Introduction to the Special Issue, English Studies, 93:3, 251-258
To link to this article:  http://dx.doi.org/10.1080/0013838X.2012.668788
PLEASE SCROLL DOWN FOR ARTICLE
Full terms and conditions of use: http://www.tandfonline.com/page/terms-and-
conditions
This article may be used for research, teaching, and private study purposes. Any
substantial or systematic reproduction, redistribution, reselling, loan, sub-licensing,
systematic supply, or distribution in any form to anyone is expressly forbidden.
The publisher does not give any warranty express or implied or make any representation
that the contents will be complete or accurate or up to date. The accuracy of any
instructions, formulae, and drug doses should be independently verified with primary
sources. The publisher shall not be liable for any loss, actions, claims, proceedings,
demand, or costs or damages whatsoever or howsoever caused arising directly or
indirectly in connection with or arising out of the use of this material.
Stylometry and Authorship
Attribution: Introduction to the
Special Issue
Javier Calle-Martı́n and Antonio Miranda-Garcı́a
In everyday life it is often difficult to tell twin brothers apart, especially when no
salient physical features lead to their immediate identification. However, despite their
identical resemblance, human beings are instead characterised by their individuality,
which ultimately depends upon the inner organisation of his/her knowledge. This
organisation has a direct effect on the use of the speaker’s language, written
production in particular. This writing singularity has been traditionally the object of
authorship attribution studies, which propose to ascertain salient stylistic differences
allowing for the association of works and authors with some level of accuracy.1
Authorship attribution is as old as the hills, and can be dated at least as far back as
the mediaeval scholastics, who put their efforts in determining the hand behind many
classical works as a proof of the text’s veracity.2 The twentieth century has also
witnessed a proliferation of this kind of approach analysing the internal/external
dimension of a text within the fields of Stylistics and Literary Criticism. However,
in the last decades, the advent of computers and the increasing availability of
machine-readable texts have largely influenced the development of non-traditional
authorship attribution studies, where a plethora of methods have been applied to
many authorship attribution problems. According to Stamatatos and Koppel,3 the
evolution of methods can be safely traced through three different stages. First,
practitioners put their efforts in the finding of a single numeric function of a text to
discriminate between authors (e.g., Yule’s K, Zipf’s Z or lexical richness, among
others). Later, statistical multivariate discriminant analysis was applied to word
frequencies and related numerical features (e.g., principal component analysis,
Burrows’s Delta). Finally, machine learning methods and high-dimensional textual
features have been recently developed and applied to sets of training documents (e.g.,
unmasking). Nowadays, these techniques have found a wide variety of applications,
Javier Calle-Martin and Antonio Miranda-Garcia are affiliated with the Department of English, University of
Malaga, Spain. Email: jcalle@uma.es; amiranda@uma.es
1Miranda-Garcı́a and Calle-Martı́n, 147.
2Stamatatos and Koppel, 1.
3Ibid, 1–2.
English Studies
Vol. 93, No. 3, May 2012, 251–258
ISSN 0013-838X (print)/ISSN 1744-4217 (online)  2012 Taylor & Francis
http://dx.doi.org/10.1080/0013838X.2012.668788
D
ow
nl
oa
de
d 
by
 [
U
ni
ve
rs
ity
 o
f 
A
eg
ea
n]
 a
t 0
5:
15
 2
5 
M
ay
 2
01
2 
not only as a means to seek the likely author of a disputed piece, but also from the
perspective of forensic linguistics and plagiarism.
Depending on the nature of the problem, the authorship of an anonymous piece
can be tested from the perspective of two experimental frameworks: authorship
attribution and authorship verification. In the former, considered to be the
fundamental problem by Koppel et al. in the present issue, a disputed text is known
to have been written by a closed set of authors, its authorship then determined on
the basis of the closest match. In authorship verification, on the other hand, the
anonymous work may not necessarily have any known candidate authors, there
being an open set of candidates instead, which substantially complicates the analyst’s
task.
The present issue is then conceived as a state of the art of the discipline, with nine
articles discussing a wide range of authorship problems, both in attribution and
verification, which are tested through the use of different methods and techniques.
The articles discuss topics of a long-standing tradition (such as the attribution of the
disputed Federalist Papers) together with others of a more innovative nature dealing,
among others, with questions of mixed authorship, cross-genre authorship
verification, character styles and the stylistic changes in authors with Alzheimer’s
disease.
In the opening article, Joseph Rudman looks back at Baayen et al.’s session at the
1977 ACH-ALLC Conference and at his own article published in Computers and the
Humanities in the year 19984 in order to assess the present state of non-traditional
authorship attribution studies fourteen years later. Based on an extensive list of
references, Rudman’s contribution discusses the achievements, failures, problems and
prospects in the field providing a comprehensive evaluation of what would then
constitute a valid attribution study, from the design of the experimental plan to the
handling of both the primary data and the control group(s), the inventory of style
markers and the selection of (often new) statistical techniques. In spite of its successes
and the vast number of publications, Rudman acknowledges that there is still a long
way ahead for non-traditional authorship attribution studies to find a successful
solution to resolve many of the controversies.
In line with Rudman’s view, Patrick Juola’s article acknowledges that stylometry is
still at the outset of this century an area with little theory and, more importantly,
without a consensus as to the most appropriate method or technique, a fact leading
him to complain about the ‘‘obvious need for proven techniques and best practices
with good track records’’. In his contribution, Juola proposes to fill this gap with the
application of large-scale experiments, which allows him to determine the method, or
the combination of methods, providing more reliable results for attribution purposes.
Juola addresses the topic using JGAAP (Java Graphical Authorship Attribution
Program), a modular Java-based program complying with a standard corpus which
gives room for many proposed methods for authorship attribution, yielding more
4Rudman.
252 J. Calle-Martı́n and A. Miranda-Garcı́a
D
ow
nl
oa
de
d 
by
 [
U
ni
ve
rs
ity
 o
f 
A
eg
ea
n]
 a
t 0
5:
15
 2
5 
M
ay
 2
01
2 
than five million potential stylometric algorithms in its latest version, and therefore
the ideal input for a large-scale testing. For the purpose, the author uses the Ad-hoc
Authorship Attribution corpus (AAAC), which is tested with more than twenty
thousand methods. The experiment tentatively concludes that the best technique
arises from the combination of compatible components.
The article by Moshe Koppel, Jonathan Schler, Shlomo Argamon and Yaron
Winter addresses the fundamental problem of authorship attribution, which consists
in attributing the authorship of two given documents to a single author within a
small closed set of candidate authors. They hypothesise that the solution to this
simple kind of authorship attribution problem becomes the vital touchstone for an
eventual success with other authorship attribution problems, both with closed and
open sets of candidate authors. Koppel et al. classify automated authorship
attribution techniques into similarity-based and machine-learning methods. While
the former takes some metric to measure the distance between two documents, in the
latter the known writings of each candidate author serve to construct a classifier that
eventually leads to the (successful) assignment of unknown documents. Given the
number of candidate authors, Koppel et al. adopt a similarity-based method to carry
out a twofold experiment, both with an open and with a closed candidate set.
In the open-set experiment, the study is based on ten thousand space-free character
4-grams, chosen on account of their frequency.5 The use of cosine similarity as a
proximity measure allows them to obtain a correct matching in 46 per cent of one
thousand snipets. Even though high in itself, the use of Koppel et al.’s approach
allows refinement of the results further, yielding 93.2 per cent precision at 39.3 per
cent recall.6 In the closed-set experiment, on the other hand, the authors address the
fundamental problem of authorship attribution with two sample texts (X and Y).
Once a set of impostors is generated (Y1, . . ., Yn), Koppel et al. apply the previous
method to determine whether text X was written by Y or by none of them. In this
fashion, the authors obtain a precision of 90 per cent and recall of 83 per cent, the
figures therefore tentatively pointing to the solvable nature of the fundamental
problem of authorship.
John Burrows and Hugh Craig’s ‘‘Authors and Characters’’ explores the
relationship between character styles and authorial styles in literary language,
considering that there is an intrinsic connection between the variety of character
styles and the consistency of authorial styles. Their contribution comes to answer
some dissenting voices arguing that the idiosyncrasies of characters’ speech have a
direct effect on the so-called singularity of the individual in language, an argument
which in the last decade or so has called into question the validity of attribution
studies, literary compositions in particular.7
5Keselj, Cercone, and Thomas.
6Koppel et al.
7McMullan, 449; Masten, 17; Lancashire, 256.
Stylometry and Authorship Attribution 253
D
ow
nl
oa
de
d 
by
 [
U
ni
ve
rs
ity
 o
f 
A
eg
ea
n]
 a
t 0
5:
15
 2
5 
M
ay
 2
01
2 
The corpus of analysis comprises the complete plays of five early modern English
playwrights (Chapman, Fletcher, Jonson, Middleton and Shakespeare), from which
the characters with more than two thousand words of dialogue are selected for the
study, amounting up to 306 characters altogether. A principal component analysis
based on a set of one hundred word-variables, chosen in terms of their frequency,
allows them to cluster the authorial groups of characters into distinct areas of the
chart.
Burrows and Craig carry out all the possible comparisons in order to pair each
dramatist with every other one, obtaining the number of characters misclassified in
terms of the Support Vector Machine cluster boundary. The average misclassification
is 7.7 per cent, ranging from 0.0 per cent (Middleton–Fletcher) to 18.8 per cent
(Jonson–Chapman). The results then corroborate that variation in terms of character
differentiation does not go hand in hand with authorial attribution, which is
validated in 92.3 per cent of the cases. In the light of this, Burrows and Craig’s
contribution proves, at least in the case of Renaissance drama, that the idiosyncrasy
of an author’s style transcends the likely variety of the characters’ idiolects, the latter
being best viewed as a source of internal variation, unable to contaminate the stability
of the authorial fingerprint.
The stylometric study of the Chard Reports on the Anglo-Zulu war of 1879 is
the focus of David I. Holmes and Elizabeth D. Johnson’s article. In their
contribution they summarise the historical underpinnings of the British invasion
towards the borders of Zululand and the red-coated defence of Rorke’s Drift led by
Lieutenant John Chard, who was then commissioned to submit a sequential report
concerning the attack on the mission station, elsewhere known as the first ‘‘Chard
Report’’. Back in England, Chard was required by Queen Victoria to write
another report, this one with the utmost detail, thenceforth referred to as the
second ‘‘Chard Report’’, submitted in February 1880. There are, however, some
discordant voices as to Lieutenant John Chard’s likely authorship of the reports
based on the assumption that it was ultimately the hand of another member of the
staff, Major Francis Clery in particular, on account of his experience as a report
writer.8
Holmes and Johnson’s contribution explores the stylistic differences between the
first and the second Chard Reports together with the similarities in style between the
first Chard Report and Clery’s writings. A number of control texts are selected for
comparison consisting of letters from men writing home during the Anglo-Zulu
campaign, both officers and private soldiers (i.e., Henry Curling, Walter Parke Jones,
William Weallens, Edward Woodgate and Francis Clery himself). For the task,
Holmes and Johnson make use of two well-known successful techniques in
stylometric analysis. On the one hand, J. F. Burrows’s approach is first used to
retrieve ‘‘the N most common words in the corpus and compute the occurrence rate
of these N words in each text . . . thus converting each text into an N-dimensional
8Greaves, 178.
254 J. Calle-Martı́n and A. Miranda-Garcı́a
D
ow
nl
oa
de
d 
by
 [
U
ni
ve
rs
ity
 o
f 
A
eg
ea
n]
 a
t 0
5:
15
 2
5 
M
ay
 2
01
2 
array of numbers’’.9 Principal components analysis and cluster analysis, on the other
hand, are next applied to Burrows’s dimensional array of numbers, limited to the use
of the sixty most common function words for convenience. These techniques come to
prove, with sufficient reliability, that a) there is no stylistic difference between the first
and the second Chard Reports, speaking for an individual hand, and b) the Chard
reports are found to be distinct enough from Francis Clery’s writings, thus
questioning the hypothesis of his intervention. Instead, Holmes and Johnson find
some close connection between Sergeant Frank Bourne’s hand and the first Chard
report, thus suggesting that Bourne could have been familiar with Chard’s first
report.
A typical case of mixed authorship is the focus of David L. Hoover’s article. His
contribution deals with Charles Kingsley’s The Tutor’s Story, an unfinished novel
which was later completed by his daughter, Mary St Leger Kingsley, writing under the
name of Lucas Malet. According to her own preface, the early chapters are
presumably Kingley’s while the late ones are mostly hers, short passages by both
authors being also interspersed. In the light of this, The Tutor’s Story conforms itself
as the ideal scenario for computational stylistics and authorship attribution. Hoover
uses some old and new methods for attributing authorship, that is, Burrows’s Delta,
Craig’s version of Burrows’s Zeta and the Student T-test, which prove to be effective
in distinguishing the style of Kingsley and his daughter, and thus appropriate for the
testing of The Tutor’s Story.
The novel is divided into eighteen hundred 524-word sections, all of which were
successfully identified at a rate above 90 per cent using fine-grained analysis. In line
with Malet’s own preface, Hoover finds that the beginning of the novel is by Kingsley
and the end by Malet, chapters twenty-eight through to forty-one in particular.
Hoover, therefore, comes to demonstrate that even the most difficult cases of mixed
authorship can be solved with computational stylistics, especially if tackled with the
appropriate technique.
The application and benefits of the unmasking technique to authorship verification
across genres is the focus of Mike Kestemont, Kim Luyckx, Walter Daelemans and
Thomas Crombez’s article. Even though the topic has been extensively analysed from
the perspective of single-text variety, it has been hitherto speculative across genres
and still in the need of further empirical investigation.10 In itself, unmasking is a
meta-learning approach to authorship verification according to which a piece of
work is divided into chunks in order to build a model of stylistic difference which
eventually serves to assess the magnitude of the differences between the input texts.11
For the purpose, the potential of this technique is tested with a collection of thirty-
four published texts by five contemporary authors (Edward Bond, David Mamet,
Harold Pinter, Sam Shepard and Arnold Wesker), both theatre and prose.
9Holmes and Johnson, present issue; also Miranda-Garcı́a and Calle-Martı́n, 159–60.
10Stamatatos, 553.
11Kestemount et al., present issue; Sanderson and Guenter.
Stylometry and Authorship Attribution 255
D
ow
nl
oa
de
d 
by
 [
U
ni
ve
rs
ity
 o
f 
A
eg
ea
n]
 a
t 0
5:
15
 2
5 
M
ay
 2
01
2 
Two different experiments are thus accomplished, one intra-genre and the other of
a cross-genre nature. The first intra-genre experiment, on the one hand, has been
carried out on the five authors’ eleven prose works, tentatively validating the
potential of this technique with an overall accuracy of 96.36 per cent, the different-
author curves becoming remarkably distinguishable from the same-author curves.
The same intra-genre experiment is tested with the set of theatrical compositions
which, in turn, show a less clear-cut differentiation, yielding an overall accuracy of
83.99 per cent. The cross-genre experiment, on the other hand, considers degradation
curves for pairs of texts belonging to different genres, obtaining that many curves are
situated in the central regions of the plot, in-between the blurred domain of same-
author and different-author curves, with an overall accuracy of 77.27 per cent. The
authors tentatively validate the reliability of unmasking with prose texts and, to a
lesser extent, with drama while the cross-genre experiment does not yield the level of
accuracy of prose, showing that the technique is still in the need of some
experimental refinements.
Graeme Hirst and Vanessa Wei Feng’s contribution explores the changes in
language associated with Alzheimer’s disease, assuming that the unique and invariable
signature that characterises an author’s style can be changed in Alzheimer’s-affected
authors, especially in terms of vocabulary richness and the frequency of certain
syntactic constructions. The study is based on a selection of novels by Agatha Christie
and Iris Murdoch, known to have had Alzheimer’s disease, while P. D. James is chosen
as the control author. For convenience, the novels are classified into three periods, that
is prime, transition and late periods, to facilitate their chronological comparison.
Hirst and Wei Feng’s hypothesis is tested within the framework of both authorship
attribution and authorship verification. Using unmasking, their experiment is based
on a set of 262 stylometric features, known to be effective for attribution purposes,
together with the 250 most frequent words. The study, however, does not offer
concluding evidence due to Alzheimer’s disease. In the authorship attribution
framework, on the one hand, the study successfully discriminates Christie’s work by
age, but not James’s nor Murdoch’s. In the authorship verification framework, on the
other hand, the Alzheimer’s-affected authors cannot be discriminated by age,
therefore coming to disprove the authors’ initial hypothesis. Notwithstanding the
poor reliability of unmasking for these purposes, the article still provides a set of
stylometric features which undoubtedly serve as the starting point for other insights
into the topic.
Antonio Miranda-Garcı́a and Javier Calle-Martı́n’s article discusses the potential of
annotated corpora in authorship attribution studies. For the purpose, an annotated
corpus of The Federalist Papers, where every running word is provided with lemma,
POS tag and textual reference, is used to calculate Burrows’s Delta and Hoover’s
adaptations of Delta (simplified Deltas 1 and 2) from a twofold perspective, lemma-
based, on the one hand, and POS-based, on the other.
From the perspective of lemma-based Delta, five experiments are carried out by
applying the following: a) standard Delta to 917 lemmas; b) simplified Delta (1) to
256 J. Calle-Martı́n and A. Miranda-Garcı́a
D
ow
nl
oa
de
d 
by
 [
U
ni
ve
rs
ity
 o
f 
A
eg
ea
n]
 a
t 0
5:
15
 2
5 
M
ay
 2
01
2 
917 lemmas; c) simplified Delta (2) to 917 lemmas; d) standard Delta to the 150 most
frequent function lemmas; and e) standard Delta to the 150 most frequent content
lemmas. The first succeeds in the assignment of ten disputed papers, D54 and D55
being the exception. In the second experiment, the use of simplified Delta 1
corroborates the Madisonian composition of the twelve disputed papers. In the third,
the disputed papers are also assigned to Madison, with the exception of D55. The
fourth experiment analyses the weight of the 150 most frequent function lemmas,
which also leads to a reliable association of the complete set of the disputed papers
with their likely compositor. Fifth, the 150 most frequent content lemmas, however,
do not yield similar results as four papers are not attributed to Madison.
From the perspective of POS-based Delta, the distribution of the different word
classes in the corpus is used to compute standard Delta and simplified Delta (1 and 2)
in three experiments. The one employing simplified Delta 2 offers the attribution of
the whole set to Madison. In the light of the results, Miranda-Garcı́a and Calle-Martı́n
come to confirm the potential of annotated corpora in non-traditional authorship
attribution studies, especially with the application of Delta, both standard and
simplified. In the particular case of The Federalist Papers, this methodology allows us
to assign, in the majority of cases, the hand responsible for the disputed papers, with
an exception made for paper 55, traditionally considered less Madisonian.
Acknowledgements
The present research has been funded by the Spanish Ministry of Science and
Innovation (grant numbers FFI2008-02336 and FFI2011-26492) and by the
Autonomous Government of Andalusia (grant numbers P07-HUM02609 and P11-
HUM7597). These grants are hereby gratefully acknowledged.
References
Greaves, A. Rorke’s Drift. London: Cassell, 2002.
Keselj, V. Fuchun Peng, Nick Cercone, and Calvin Thomas. ‘‘N-gram-based Author Profiles for
Authorship Attribution.’’ Computational Linguistics 3 (2003): 255–64.
Koppel, Moshe, Jonathan Schler, Shlomo Argamon, and Eran Messeri. ‘‘Authorship Attribution
with Thousands of Candidate Authors.’’ In Proceedings of the 29th ACM SIGIR Conference on
Research and Development in Information Retrieval, 659–60. New York: ACM Press, 2006.
Lancashire, Ian. Forgetful Muses: Reading the Author in the Text. Toronto: University of Toronto
Press, 2010.
Masten, Jeremy. Textual Intercourse: Collaboration, Authorship and Sexualities in Renaissance
Drama. Cambridge: Cambridge University Press, 1997.
McMullan, Gordon. ‘‘‘Our Whole Life is Like a Play’: Collaboration and the Problem of Editing.’’
Textus 9 (1996): 437–60.
Miranda-Garcı́a, Antonio, and Javier Calle-Martı́n. ‘‘A Survey of Non-traditional Authorship
Attribution Studies.’’ Ecdotica 5 (2008): 147–68.
Rudman, Joseph. ‘‘The State of Authorship Attribution Studies: Some Problems and Solutions.’’
Computers and the Humanities 31, no. 4 (1998): 351–65.
Stylometry and Authorship Attribution 257
D
ow
nl
oa
de
d 
by
 [
U
ni
ve
rs
ity
 o
f 
A
eg
ea
n]
 a
t 0
5:
15
 2
5 
M
ay
 2
01
2 
Sanderson, Conrad, and Simon Guenter. ‘‘Short Text Authorship Attribution via Sequence Kernels,
Markov Chains and Author Unmasking: An Investigation.’’ In Proceedings of the 2006
Conference on Empirical Methods in Natural Language Processing (EMNLP), 182–91. Sydney:
Association for Computational Linguistics, 2006.
Stamatatos, Efstathios. ‘‘A Survey of Modern Authorship Attribution Methods.’’ Journal of the
American Society for Information Science and Technology 60, no. 3 (2009): 538–56.
Stamatatos, Efstathios, and Moshe Koppel. ‘‘Plagiarism and Authorship Analysis: Introduction to
the Special Issue.’’ Language Resources and Evaluation 45, no. 1 (2011): 1–4.
258 J. Calle-Martı́n and A. Miranda-Garcı́a
D
ow
nl
oa
de
d 
by
 [
U
ni
ve
rs
ity
 o
f 
A
eg
ea
n]
 a
t 0
5:
15
 2
5 
M
ay
 2
01
2 
