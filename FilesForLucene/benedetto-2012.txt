The Unreasonable Effectiveness of Mathematics
in Human Sciences: the Attribution of Texts
to Antonio Gramsci
Dario Benedetto, Emanuele Caglioti and Mirko Degli Esposti
1 Style, where are you?
From the online Oxford vocabulary we can read the following definition:
[style] noun
a particular procedure by which something is done; a manner or way;
a way of painting, writing, composing, building, etc., characteristic of a partic-
ular period, place, person, or movement;
a way of using language;
a distinctive appearance, typically determined by the principles according to
which something is designed: a particular design of clothing.
Does it sound strange that mathematicians are interested in this? As we try to argue,
it is probably not completely silly that certain topics are faced with pure or almost
pure mathematical eyes. Creativity means generation of novel, original and, hope-
fully, coherent structures from the use of elementary elements and with the use of
old or newly created rules. This is, of course, a very general and debatable defini-
tion, but one that works not only for literature, but also for music, painting and any
other form of artistic creativity.
But generation of structures is exactly what mathematicians usually do and study
(well, roughly speaking) and we think that some of the aspects related to creativity,
style (whatever it means) and the like can be modeled, quantified and sometime
measured and simulated. Of course, we are researchers and we must be very careful
to not abandon too quickly the safe shore of a rigorous scientific method in trying
to catch the phlogiston of style and creativity. Asserting that a given author has a
unique and detectable style that can be measured in any of his creations is of course
not only a poor scientific statement, but also completely wrong in its generality.
Dario Benedetto, Emanuele Caglioti
Department of Mathematics, Sapienza University of Rome (Italy).
Mirko Degli Esposti
Department of Mathematics, University of Bologna (Italy).
Emmer M. (Ed.): Imagine Math. Between Culture and Mathematics
DOI 10.1007/978-88-470-2427-4 14, c© Springer-Verlag Italia 2012
144 D. Benedetto, E. Caglioti and M. Degli Esposti
This is why we say that, as for the concept of race, style does not exist. But still
in any creative process, nothing is really generated from scratch and any process of
content creation (a piece of a text, for example) is always the result of a complex
interaction between the author’s experience and skills from the past, what the author
has created up to now, the topic of the content, the author’s desire for originality, and
much more of course. Because of this, it is not completely foolish to imagine that
some patterns characterizing the author’s style might be hidden in the created work.
These features are probably not always sufficient to identify and discriminate the
author with respect the rest of the universe, but are probably sufficient to identify
and distinguish the author within a coherent and limited framework made of a few
properly selected authors and topics.
More precisely, in case of written texts, even if a general definition of style does
not means anything and probably it does not even exists, we believe that certain
abstract quantities, a little bit more general than the usual semantic or syntactic
(e.g. words) structures, sometimes contains useful information that allows use to
discriminate the real author of the text among a finite set of possible authors. This
is basically the aim of Authorship Attribution (often denoted by A.A), a quite old
area, a field where philology, computer science and (we believe) pure mathematics
and physics come together.
Again with the aim of being general and, even more, generic, let us start with a
very simple example in visual attribution. Look, for example, at the fragments of
picture in Fig. 1: two of them are from Henry de Toulouse-Lautrec and the other two
from Pierre-Auguste Renoir. Our guess is that it will take you just a small fraction
of a second to clusterize them with respect the author.
Can we do it with an algorithm? Well, in this case it should not be difficult to
recognize some very natural features, that can be extracted from each image and
makes it possible to discriminate between the artists. Here it would be enough to
extract very general and simple information about the statistical distribution of small
geometrical features, such as segments or circles and arcs. But things might be a
little bit more complicated: think about being able to distinguish a set of drawings
securely attributed to the great Flemish artist Pieter Bruegel the Elder (1525-1569)
from a set of imitation Bruegels, whose attribution is generally accepted among art
historians. Here the task is much more difficult, even for humans, and was attacked
Fig. 1 A simple problem in visual attribution [16]
The Unreasonable Effectiveness of Mathematics in Human Sciences 145
only very recently with quite sophisticated mathematical tools, such as wavelets and
sparse coding [5].
Computer science has in fact been grappling with the very general problem of
clustering and discriminating objects of different nature for very long time now and
a very fundamental type of approach has been developed in the last decades: first of
all, define and extract suitable features and then, in the spirit of machine learning,
train and use a suitable algorithm/machine (neural nets, supported vector machine,
Bayesian tools, etc...) to discriminate, classify and clusterize objects into several
known or unknown classes.
Here, as already stated, we would like to concentrate on literary texts and the
the task of using quantitative tools, either statistical or more purely mathematical,
to attribute a given anonymous or apocryphal text to a specific author. This area of
research has a quite long history but we can trace one of its crucial and fundamental
steps back to the work of the physicist Thomas Corwin Mendenhall (1841-1924).
As described and discussed in [6], in the article “The characteristic curves of com-
position” [8] T. C. Mendenhall was attracted by the similarity between the statistical
distribution of words of various lengths (how many words of length 1, 2, 3, and so
on) and the spectrum generated by the spectroscopic analysis, a very innovative and
much discussed technique in the last decades of the nineteenth century. In fact, as
he wrote in the 1887 issue of Science (see [6] and references therein):
It is proposed to analyse a composition by forming what may be called a “word spectrum” or
“characteristic curve” which shall be a graphic representation of the arrangement of words
according to their length and the relative frequency of their occurrence.
In 1901 T.C. Mendenhall published in The Popular Science Monthly an article with
the title A Mechanical Solution of a Literary Problem [7] where he studied and
compared body of works by Shakespeare, Marlowe and Bacon facing the already
classical open question regarding the real identity of the author of the literary works
traditionally transmitted under the name of Shakespeare. The aim of Mendenhall
was to verify whether the style of Shakespeare’s works was either unique and de-
tectable or if it was similar (if not identical) to the style expressed in the work of
Marlowe or Bacon, under the (wrong) assumption that the frequency distribution of
word lengths was a unique finger print of the author’s style (we now know that this
simple assumption is unfortunately very far from true).
In this contribution, following [1] and in particular [2], we want to describe the
method used to attribute articles whose author was unknown to Antonio Gramsci
(a famous politician, philosopher and journalist, who was one of the founders of
Fig. 2 Word spectra traced by Thomas Corwin Mendenhall in [8]
146 D. Benedetto, E. Caglioti and M. Degli Esposti
the Italian Communist Party in the 1921), which we have developed together with
M. Lana [6]. The techniques we used are not the mere result of experiments; on
the contrary they are based on some important ideas of modern mathematics that
we believe are useful for distinguishing this kind of research from the substantially
empirical approach generally used in this field, as we show in the following section.
2 The measure of information content
Information theory was born in 1948 with the article [10] by Claude E. Shannon “A
Mathematical Theory of Communication”, which poses and solves the problem of
defining the amount of information contained in a “message”, for example a text or
more generally any sequence of symbols (for a more extended account see the book
of Pierce [9]).
The unit of measurement of information is the bit (“binary unit”), it is the mea-
sure of the information which chooses one of the two elements of an alternative:
on/off, open/closed, right/wrong, true/false, 0/1 (which are the two symbols used in
the binary numeration system). With one bit available you can make just two dis-
tinct assertions; with two bits, four “words” can be made (in binary digits the four
words are: 00, 01, 10, 11); with three bits, eight words can be made, and so on.
The amount of information corresponding to eight bits is called byte; with one byte
you can generate 256 different words. With 256 possibilities, an entire alphabet of
a western language can be codified; indeed the letters (including capitals, accented
letters, punctuation marks, special symbols) are never more than 256. Each letter
is therefore represented by a sequence of eight bits, through universally accepted
“codings” (like ASCII and iso 8859-15).
An example: the DNA sequence AGCTTTTCATTCTGACTGCA is composed of 20
characters and a text file containing it is 20 byte large. One could therefore think
that this sequence contains 20× 8 = 160 bits of information. Actually to write a
DNA sequence an alphabet consisting of the 4 letters A,C,G,T is sufficient, and
since you can codify 4 letters with just 2 bits, the given sequence contains (at most)
20×2 = 40 bits of information.
So the coding affects the quantity of information used to write a message: while 8
bits per character are used for an English text, for a “genetic text” 2 bits per character
are enough. One can imagine the strangest codings: for the sequence
TTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTT
(50 times T), the information content is 400 bits if it is codified in the Latin alphabet,
100 bits if codified in the DNA alphabet, a few bytes in any programming language,
using a command which corresponds in human language to “write 50 T’s”. So the
question is: what is the information size of the sequence?
In his 1948 work Shannon determined that the quantity of information contained
in a message is the minimum number of bits needed to codify it, and defined entropy
as the minimum number of bits per character. There are programs which attempt to
The Unreasonable Effectiveness of Mathematics in Human Sciences 147
codify a message using the least possible number of bits: they are the data com-
pression programs (for example WinZip on Windows OS, gzip and bzip2 on Unix
OS; for a general description of compressors see for example [12]). The compres-
sion rate (obtained by comparing the dimension of the compressed text with that of
the original text) allows us estimate the entropy of a text (see also [13]). Shannon’s
theory has a rigorous and consistent formulation only for well-defined mathemat-
ical objects, but mathematicians find it natural to use his ideas in the field of text
analysis as well: one can indeed make the hypothesis that, by measuring the com-
pression rate of an author’s texts, an intrinsic quantity of it is measured. Shannon
himself, through an experiment, estimated that the the average quantity of informa-
tion of the “English language” is between 0.6 and 1.3 bits per character. Though the
entropic characteristics of an author’s writing are certainly interesting, they are not
very useful for attribution problems.
By developing Shannon’s ideas, one can obtain an effective instrument for the
attribution problem: the concept of relative entropy. In order to illustrate this concept
it is useful to analyse in detail how some methods (algorithms) for data compression
work. Those which were discovered first (Shannon-Fano, Huffman) use a priori
knowledge of the character statistics of the text and codify just one character (or
a few characters) at a time. The more frequent the character is used, the shorter
the code assigned to it. As an example, consider Morse code, which, even though
it is not a compression code, has been conceived to meet a similar requirement:
speeding up the transmission of messages in the English language. Morse code uses
5 characters: line, dot and short break to codify letters, medium break to separate
words, long break to separate sentences. The more frequently used letters in English
are codified with a shorter sequence, and so transmitted faster: “e” is codified with
“.” while “z” is codified with “–..”. The letter frequency distribution was studied a
priori: Morse visited a print shop to obtain it. The entropy is the minimal number
of bits per character needed to codify a sequence, so if the sequence is codified in
a non-optimal way more bits than necessary are used; given two sequences, their
relative entropy is precisely the number of bits per character which are added when
one sequence is codified with the code which is optimal for the other sequence. The
example of Morse code is useful to understand this concept. Let us suppose that
Morse code is optimal for the English language: if it is used to codify an Italian
message it gives a text longer than the one which would have been obtained by
using a Morse code optimized for the Italian language. The difference of length (per
character) is a measure of the relative entropy between English and Italian.
Relative entropy is a very powerful tool to quantify the difference among se-
quences, and therefore among authors. As early as 1993 Ziv and Merhav in [15]
had proposed the use of relative entropy to deal with problems of categorization and
suggested definite methods to measure it. These methods have been proposed and
used on more specific problems in the fields of biological sequence analysis and of
authorship attribution (see the survey of Stamatatos [11]).
In particular, we have used a method based on the ideas of the compression
algorithm LZ77 of Ziv and Lempel [14], which is the origin of the compression
softwares zip/WinZip/gzip (see [3] for an explanation of the method you can eas-
148 D. Benedetto, E. Caglioti and M. Degli Esposti
ily implement!). For example, as an estimate of the relative entropies of the tragedy
Oedipus at Colonus by Sophocles and the tragedy Alcestis by Euripides with respect
to Antigone by Sophocles, we obtain the following values:
D(Oedipus at Colonus||Antigone) = 0.130, D(Alcestis||Antigone) = 0.244
In this example the relative entropy of two texts by Sophocles is lower than that
between a text of Euripides and a text of Sophocles.
3 The statistics in the texts
Assuming that the text is “just” a symbol sequence means not taking into consider-
ation either the content of the text or its grammatical aspects: letters of the alphabet,
punctuation marks, blank spaces between words are just abstract symbols, without a
hierarchy. Moreover, as a basic constituent of the text, the word has no more mean-
ing than other aggregates of symbols, and its role as a unit of higher level than the
single character is described by the n-gram. Here are some useful examples:
by monogram (1-gram) we mean one single symbol of the alphabet;
by bigram (2-gram) we mean a sequence of two symbols, for example “me” but
also also “e ” (i.e. “e” followed by a blank space);
by trigram (3-gram) we mean a sequence of three symbols, for example “the”,
but also “e.L”;
by n-gram we mean any sequence of n symbols; for example “the entr” is
an 8-gram.
From a simplifying mathematical point of view, besides considering the text as an
abstract sequence of symbols, we also assume that it has been generated by a source,
symbol after symbol. The nature of the source is not the object of analysis, but is
only an abstract model of all the entities which can generate texts. The source emits
its messages (texts) choosing the symbol to be emitted each time according to prob-
abilistic rules. The difference between sources is due to the different probabilistic
rules used to generate the messages.
Obviously, this source/message scheme is too rigid and abstract to be a reason-
able interpretation of the author/text relationship. In particular, in the mathematical
models for symbol sources it is possible to make the rules for symbol generation
explicit, while it is at least doubtful that such rules exist for a real author writing
a text. On the other hand this approach gives some useful indications, as Shannon
showed in constructing the approximations of the texts [10].
He defined the approximation of “order 0” simply by extracting symbols ran-
domly, all with the same probability. Obviously the texts obtained in this way are
far from resembling an English text, as can be seen from the following example:
pmR!.ALvPRW;sVfjyaicGlWsN;lDADdHWiCAWEF.cbLG;UgdPYCFbUGmH:eMiVtK
The Unreasonable Effectiveness of Mathematics in Human Sciences 149
The “first order” approximation is obtained by extracting symbols with probabilities
equal to the relative frequencies with which they are found in the reference corpus.
An example of text obtained like this is:
orklpa tea yohhranKgoc suhoruhytenffari, ed e aelutnGb u.ifaaepn
With the “second order” approximation a significant difference is introduced: the
new character is chosen in relation to its antecedent. For example, to choose the
character following a c, we have to compute the frequencies of the bigrams begin-
ning with c in the corpus and divide them by the overall frequency of c; the values
obtained in this way are the conditioned frequencies. A text generated with such
rules is for example:
he cerye Huro ut thowaverowolesthirliror me g imen andy lind f g
Correspondingly, a model of third order is obtained by measuring the frequencies
of a character with respect to the two previous ones. An example is
at st the waid heithand by hinglittlyints napt th hothed that han
and an example of approximation of the 9th order is
and their guns across their wandering which would no more left
The number of the characteristics of the original texts which are preserved in the
models grows with the order of approximation: in the first order approximation
the separation into words is similar to the one of English language; in the sec-
ond order the syllables are substantially correct, and the beginning and end of
words are plausible; the ninth order approximation roughly respects grammatical
rules.
With this idea in mind, we can suppose that the “stylistic” differences among
authors must result in numerical differences between n-gram frequencies. In this
way, once the n-gram frequencies of an unknown text are measured and compared
with the “typical” n-gram frequencies of an author, it is possible to perform the
attribution by choosing the author for which the difference between the known and
calculated frequencies is minimal.
4 Mathematical methods for attribution
Using the description of texts as n-gram sequences and the entropy as a measure of
information content, one can develop procedures for the attribution of a text whose
author is unknown using two basical tools:
for n-grams: their frequencies in the text are measured and compared with the
ones of the available authors;
for entropy: the relative entropy of the text in respect to the available authors is
calculated.
150 D. Benedetto, E. Caglioti and M. Degli Esposti
Any mathematical method for attribution will be characterized, in brief, by the fol-
lowing two aspects:
1. choice of the “objects” for which the counting is significant, that is, of the ob-
jects which are supposed to be used with frequencies of occurrence significantly
different from that of the other authors;
2. choice of the way of translating the measures of the quantities described in 1.
into attributions.
The n-gram frequencies of occurrence and the relative entropy are two possible
choices for the counted objects in 1. The most used methods for the choices in 2 are
those involving probabilistic/statistical techniques and those of metrics or similarity
ones. Probabilistic and statistical methods start from the basic assumption that the
characteristics of a text (the ones chosen in point 1. are not univocally linked to an
author, but occur with different frequencies of occurrence for the different authors).
There are very well-established mathematical techniques (for example, Bayes’ for-
mula and more generally statistical tests) for the study of the inverse problem, that is
to calculate the probability that a text with certain observed characteristics has been
written by a given author.
A different approach consists in synthesizing as a single quantity the differ-
ence/dissimilarity observed measuring the quantities chosen in point 1). This value
will be a measure of the proximity of two texts or of a text and an author; in general,
the number is lower when the measured difference is smaller, i.e., when the texts
are closer to one another. At that point a mathematician will prefer to define this
proximity as a “distance” (or “metric”), which is a definite mathematical concept,
obtained by abstracting the characteristics of the usual distance between points in
space 1.
There are two advantages with respect to a generic measure of “proximity” are
two: “distance” is a mathematically solid, unambiguous concept, and it allows the
use of other mathematical tools that have been developed using the notion of dis-
tance. It is important to remark that the metric description allows among other things
the construction of “phylogenetic trees”, where attribution corresponds to the inclu-
sion in different branches of the tree (see e.g. [4]).
5 Gramsci or not Gramsci?
The basic ideas and considerations described up to now were further developed
and implemented for the attribution of journal articles whose author was unknown
but which were probably written by Antonio Gramsci (we did this work for the
new “Edizione nazionale degli scritti di Antonio Gramsci”, in collaboration with
“Fondazione Istituto Gramsci Onlus”2) While we do not go here into the details of
our attribution procedure (we refer the interested reader to [1] and [2] for further
1 Specifically the distance satisfies the “triangular inequality”, which in essence states that if going from
A to B one deviates passing through C, the path becomes longer.
2 http://www.fondazionegramsci.org/ag edizione nazionale.htm
The Unreasonable Effectiveness of Mathematics in Human Sciences 151
mathematical and methodological details), we would like to give here just a brief
overview of the fundamental steps, together with a sketchy graphical visualization
of some achievements.
We started with a tuning stage, in which we selected two methods, one based
on n-gram (with n=8) and the other based on entropic techniques, and we tested it
measuring the distance between any given text X out of a group of 50 Gramscian
and 50 known non-Gramscian texts and the other 99.
Having fixed a distance method (say the one based on n-grams) and having cho-
sen text X , we now have 99 numbers representing the distances of X from the indi-
vidual elements of the the corpus. This suggests two questions:
What can we expect about the distance of X from the 49 texts of the class to
which it belongs?
Is it possible to consider conveniently all the information contained in these
numbers, hence going beyond the simple (and inefficient) attribution given by
the author of the nearest text?
With these questions in mind one can in fact define, for any given text X and for each
distance method, a Gramscianity index −1 ≤ v(X)≤ 1 calculated from the above 99
numbers;the index value will be greater the closer the unknown text is to the group
of Gramscian texts. A value near to 1 (-1) provides a strong indication of a correct
attribution to Gramsci (to non-Gramsci), while values near to 0 are a mark of great
undecidability. The index allows a quite direct and useful graphical visualization of
the attribution, as shown for the training set in Fig. 3 (see [1, 2] for more details).
Fig. 3 Attribution of the 100 texts, using the Gramscianty index given by the n-grams method
152 D. Benedetto, E. Caglioti and M. Degli Esposti
We can now repeat the same procedure with the entropic distance, which is based
upon completely different principles. On the other hand, one might fear that they in
fact will give the same information, adding nothing to the accuracy of the global
method. We have therefore made sure, with suitable methods, of the statistical inde-
pendence of the rankings of the texts ordered following the two distances.
In the end, we have attributed to Gramsci only the texts that both methods assign
to him. Moreover, both methods give a numerical value for the attribution, so that
it is possible (and very useful) to give a two-dimensional graphical representation
of the overall results: the Gramscianity index obtained with the n-gram method is
plotted on the horizontal axis where positive values correspond to the attribution to
Gramsci, negative values to “non-Gramsci”. The rightmost points are the texts for
which the attribution to Gramsci is more certain, the leftmost are those for which the
method suggests with greatest certainty an attribution to authors other than Gramsci.
On the vertical axis the value of the analogous index given by the relative entropy
method is shown; in this case advancing from bottom up means moving from sug-
gested non-Gramscian texts to suggested Gramscian ones.
The results of the tuning stage is shown in Fig. 4.
The first quadrant, therefore, contains the texts that both method attribute to
Gramsci. In this case, for example, there is no triangular point among them, meaning
that there are no false positives (no wrong attributions to Gramsci). The number of
texts correctly attributed to Gramsci is 43, the 86% of the total. In the second quad-
rant lie the texts attributed to Gramsci by the relative entropy method but not by the
n-grams method. There are no texts in the fourth quadrant: these would be those
Fig. 4 Attributions for the 100 texts of the tuning stange
The Unreasonable Effectiveness of Mathematics in Human Sciences 153
Fig. 5 Attributions for the 40 texts of the blind test
attributed to Gramsci by the n-gram method but not by the entropic method. Finally,
the third quadrant contains the texts not attributed to Gramsci by either methods.
The second stage was a blind test, performed on 40 texts (attributions were known
but communicated to us only a posteriori). The results we obtained is shown in
Fig. 5. One can see that 18 Gramscian texts out of 20 are correctly attributed to
Gramsci, which is the 90%, with no false positives.
This was just a very brief description of the beginning of the analysis, which was
followed by a systematic attribution of thousands of actual unattributed articles. The
attributions obtained with these mathematical methods are at present in the hands of
experts of Gramsci, who are re-elaborating and re-discussing the results in light of a
more traditional philological approach. We do not intend to go here into the details
of this interesting (and regarding some aspects, original) interaction between math-
ematical based quantitative methods and philological methods, besides confirming
a fruitful coherence between the approaches, which will be discussed elsewhere.
Of course, it’s a long way to the top3 and a lot of interesting questions are still not
completely answered: for example, Why do these abstract methods work? Which n-
grams really contain the signature of Gramsci’s style?
To put it another way: style, style, where are you?
3 . . . if You Wanna Rock ’n’ Roll: AC/DC, from the album T.N.T.
154 D. Benedetto, E. Caglioti and M. Degli Esposti
References
1. C. Basile, D. Benedetto, E. Caglioti, M. Degli Esposti, An example of mathematical author-
ship attribution. Jour. Math. Phys. 49, 1–20, 2008.
2. C. Basile, D. Benedetto, E. Caglioti, M. Degli Esposti, L’attribuzione dei testi gramsciani:
metodi e modelli matematici. La matematica nella Società e nella cultura 3, 235–269, 2010.
3. D. Benedetto, E. Caglioti, V. Loreto, Language Trees and Zipping. Phys. Rev. Lett. 88 n. 4,
048702-1–048702-4, 2002.
4. L.L. Cavalli-Sforza, P. Menozzi, A. Piazza, The History and Geography of Human Genes.
Princeton University Press, Princeton, 1994; translated in Italian as: Storia e geografia dei
geni umani. Adelphi. Milano, 2000.
5. J.M. Hughesa, D.J. Graham, D.N. Rockmore, Quantification of artistic style through sparse
coding analysis in the drawings of Pieter Bruegel the Elder. PNAS and Science, 2010.
6. M. Lana, Individuare scritti gramsciani anonimi all’interno di un corpus giornalistico. Il ruolo
dei metodi quantitativi per l’attribuzione (preprint 2011).
7. T.C. Mendenhall, A Mechanical Solution of a Literary Problem. The Popular Science
Monthly LX(7), 97–105, 1901.
8. T.C. Mendenhall, The characteristic curves of composition. Science 214, 237–249, 1887.
9. J.R. Pierce, An Introduction to Information Theory: Symbols, Signals and Noise. Dover Pub-
lications, New York, 1980; traslated into Italian as: La Teoria dell’Informazione. Mondadori,
Milano, 1983.
10. C.E. Shannon, A Mathematical Theory of Communication. The Bell System Technical Jour-
nal 27, 379–423, 623–656, 1948.
11. E. Stamatatos, A Survey of Modern Authorship Attribution Methods. Jour. Am. Soc. Infor.
Sci. Tech. 60(3), 538–556, 2009.
12. I. H. Witten, A. Moffat, T.C. Bell, Managing Gigabytes, 2nd edition. Morgan Kaufmann
Publishers, 1999.
13. A.D. Wyner, Typical sequences and all that: Entropy, Pattern Matching and Data Compres-
sion. Shannon Lecture, IEEE Information Theory Society Newsletter, 1995.
14. J. Ziv, A. Lempel, A universal algorithm for sequential data compression. IEEE Transactions
on Information Theory IT-23(3), 337–343, 1977.
15. J. Ziv, N. Merhav, A measure of relative entropy between individual sequences with applica-
tion to universal classification. IEEE Transactions of Information Theory 39(4), 1270–1279,
1993.
16. Wikimedia Commons, su http://commons.wikimedia.org/wiki/:
File:Pierre-Auguste Renoir - Study for ’Dance in the Country’,
pencil, 1883.jpg Honolulu Academy of Arts;
File:Portrait de Suzanne Valadon par Henri de Toulouse-Lautrec.jpg;
File:Henri de Toulouse-Lautrec 053.jpg The Yorck Project: 10.000 Meister-
werke der Malerei. DVD-ROM, 2002. ISBN 3936122202. Distributed by DIRECTMEDIA
Publishing GmbH.;
File Renoir - Sitzendes M
