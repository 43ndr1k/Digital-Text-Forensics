A Corpus of Online Discussions for Research into
Linguistic Memes
Dayne Freitag
SRI International
freitag@ai.sri.com
Ed Chow
SRI International
edchow@ai.sri.com
Paul Kalmar
SRI International
kalmar@ai.sri.com
Tulay Muezzinoglu
SRI International
tulay@ai.sri.com
John Niekrasz
SRI International
niekrasz@ai.sri.com
ABSTRACT
We describe a 460-million word corpus of online discussions. The
data are collected from public news websites and community-of-
interest Internet forums, and are designed to support research on
the propagation of socially relevant ideas, a.k.a., “memes.” A struc-
tural and statistical description of the corpus is given, and the em-
ployed methods of website monitoring, collection, and extraction
are described. We also present preliminary linguistic research on
the corpus. We show that the corpus represents language from a
wide variety of social and psychological communities, that discus-
sion structure and popularity can be predicted in large part from
lexical analysis, and that standard epidemiological models provide
good fit for diachronic patterns of population-level lexical adop-
tion.
Categories and Subject Descriptors
H.2.4 [Database Management Systems]: Textual databases; H.3.1
[Information Storage and Retrieval]: Content Analysis and In-
dexing—Linguistic processing
General Terms
Corpus analytics, Memetics, Information diffusion
1. INTRODUCTION
Over the relatively short period since its inception, the Web has as-
sumed an increasingly central role in the dissemination of informa-
tion and the spread of ideas. The widespread adoption of social me-
dia, an even more recent phenomenon, has dramatically decreased
the friction with which both trivial and momentous ideas spread.
In the past, these socially relevant ideas, these memes, might have
gained most of their force through official promulgation. In the
modern landscape, there is a much stronger bottom-up component
to this spread, resulting in more turbulent and, arguably, more in-
teresting patterns in the diffusion of influence.
Information diffusion research has attempted to reconstruct and
model these influence patterns, exploiting the computational acces-
sibility of both the linguistic (tweets, blogs, wall posts) and social
(friend or follower networks) dimensions of social media. Much of
the early work focused on the relatively professional utterances of
bloggers, seeking to recover the transmission trajectories of memes
(typically URLs or phrases), and to quantify influence as a feature
of individual blogs or bloggers [6, 9]. An epidemiological analogy
is often applied to the spread of memes through such networks, and
models derived or borrowed from this analogy have shown some
success in accounting for observed patterns [2, 5]. With the increas-
ing popularity of microblogging, studies of information diffusion in
platforms such as Facebook and Twitter have yielded insight into
idea propagation and social network formation closer to the “grass
roots” [13, 10].
The work described in this paper continues this trend of research
away from the professional pundit toward the average citizen, with
an emphasis on online discussions. As a rule with a few notable ex-
ceptions, Web sites providing news and commentary include com-
ment boards where the reader can respond to specific articles or to
other commenters. Such discussions can also be found on special
interest Web sites, what we call “communities of interest” (COIs).
As will become clear, the harvesting of such discussions poses chal-
lenges that have impeded their widespread use in information diffu-
sion and computational linguistics research. But as we also attempt
to show, online discussions promise novel socio-linguistic insights.
Our “meme epidemiology” project pursues insights suggested by
the epidemiology analogy, attempting to elaborate it in several ways.
First, we are interested in what can be learned by treating discus-
sions as “outbreaks.” Like disease outbreaks, discussions grow over
time and at different rates. Some become truly huge, while many
fail to develop at all. We seek to identify the factors that produce
these differences, exploiting the overt connection between an arti-
cle and the discussion it engenders. Second, we assume that, just
as in epidemiology, the energy a discussion or idea exhibits is at
least partly attributable to the community or population that hosts
it—an assumption that our collection of COI data allows us to test.
Finally, we believe that conventional epidemiological models are
much more directly applicable to idea diffusion than existing re-
search might suggest. Later, we show that an SIR compartmental
model, borrowed with few modifications from epidemiology, accu-
rately models the temporal distribution of lexical expression pat-
terns over several years.
In this paper, we present a 460 million-word corpus of online dis-
cussions. We begin in Section 2 by describing the corpus contents
and data model. We develop a common vocabulary for corpus ele-
14
ments, and we provide an overview that reveals some of its salient
statistical properties. In Section 3, we present a purpose-built data
collection system that has been used to monitor, collect, and ex-
tract the data from multiple sources. In particular, our presentation
highlights some of the challenges we have encountered in the de-
sign of this system and the maintenance of a coherent corpus. Fi-
nally, Section 4 presents initial results from three areas of linguistic
research being conducted using the corpus: (1) modeling and pre-
diction of discussion structure, (2) linguistic variation between and
within website communities, (3) and meme propagation.
2. CORPUS DESCRIPTION
We have been collecting the corpus that is the focus of this paper for
nearly a year from public sources. Major features of the collection
system and database structure have been stable for approximately
six months. We continue to collect data from the sites listed below,
and to add to the list of sites.
2.1 Data model
We harvested from 24 distinct websites, each of which have their
own way of providing users with the ability to conduct discussions
online. As a result, the type and organization of data present on
each site may be different from one site to the next. It is there-
fore necessary as a first step in developing and studying the cor-
pus to develop a common representation for all the linguistic data
present—one which generalizes well across the multiple sites and
allows for discussion and analysis across the entire corpus.
The data model is centered on discussions as the main represen-
tational unit. Discussions are built from two types of discourse
unit—articles, which we use to refer to an initial posting of some
content (typically a news article or editorial) and comments, which
refer to any subsequent statements made in response. Each com-
ment also has an attachment relation linking it either to another
comment (when one commenter replies to another) or directly to
the initiating article (we refer to this latter type as root attachment).
All comments and articles are assigned a posting date (which may
include time-of-day information if it is available). Each comment’s
author is also obtained, using public user handles when available.
The authorship of news articles, in contrast, is not currently avail-
able, as we do not have a sufficiently robust mechanism for extract-
ing this information from its embedded position within article text.
We distinguish two main types of websites—community-of-interest
(COI) forums and news sites—each type providing certain advan-
tages of interest to the project. COIs explicitly group discussants
into more or less culturally homogeneous populations, while news
sites make explicit the connection between discussions and the real-
world events to which they respond. The two types are distin-
guished primarily by the way that discussions are initiated (and by
whom). For news sites, discussions are initiated by the posting of
news articles or editorials that are written by professional authors
who are typically not participants in subsequent discussion. Forum
discussions, on the other hand, are initiated by discussants them-
selves, which means the “articles” are usually better described as a
discussion “prompt” (though professionally-written articles, or hy-
perlinks to them, are sometimes posted as articles in forums). News
sites and COI forums are also typically distinguished by the nature
of their participant community. As the name suggests, COI forums
have a more targeted set of common interests, and therefore draw a
more focused set of participants.
We are interested in modeling discussions as linguistic objects in
their own right, particularly the reply or attachment structure they
display, but websites in the corpus often limit certain types of at-
tachment, thus constraining the set of possible discussion threading
structures. For example, some sites allow new comments to attach
only to the most recently posted comments. In other cases, the
recursive depth of the attachment tree is limited. Some web sites
eliminate structure altogether, and do not allow comments to at-
tach to other comments at all. These differences limit our ability to
generalize some of our findings about discussion structure, but also
provide an opportunity to learn about how such constraints affect
information propagation. Nonetheless, the applicability of the data
model just described is not affected by these differences.
2.2 Descriptive statistics
The corpus consists of approximately 460 million words extracted
from 24 websites.1 A list of the collected websites is shown in
Table 1, with those allowing for comment–comment attachment
marked with an asterisk (∗). As described in the previous section,
it is useful to classify the sites into two main types: news sites and
community-of-interest (COI) forums. In our selection of COIs, we
are interested in choosing sites with a pronounced point of view,
while sampling from as broad a range of persuasions as possible.
Table 2 presents summary statistics for each of these two compo-
nents of the corpus. The data show that comments tend to be longer
in COI forums, and that COI forum communities tend to be smaller.
Also note that the posting of articles is typical of news sites but not
COI forums, though there are some exceptions to this (the COIs
richarddawkins.net and vanguardnewsnetwork.com contain
posted articles, and some news sites have a few discussions without
a posted article).
For many of the websites (typically the news sites), historical data
are not made publicly available, so the corpus only contains articles
and posts from the period of the collection effort. This means that
our archives of such sites contain data spanning periods between 3
and 6 months (depending on when the site was introduced to the
collection queue.) Some sites (typically the COI forums) do pro-
vide this historical data. For these sites, the collected data spans pe-
riods ranging from 1 to 7 years. The website animalsuffering.
com has the longest archive and contains data going back to 2004.
An analysis of the distribution of discussion size (i.e., the number of
comments in a discussion) reveals interesting properties of the cor-
pus. Namely, we studied the relationship between discussion size
and discussion size frequency. In related internet phenomena such
as social network connectivity, popularity of websites, or number
of email contacts, it has been found that these distributions follow a
power-law distribution [1]. But contrary to this pattern, we find that
our data require a sub-logarithmic transformation of the two vari-
ables (discussion size and discussion size frequency) to produce a
linear relationship. This suggests that the stochastic processes that
are thought to underly some power-law distributions, such as pref-
erential attachment, may not apply in a straightforward manner to
our data [8]. We discuss this further in Section 4.
The data also reveal that temporal factors vary widely across sites.
Discussions on the news sites latimes.com and wsj.com, for ex-
ample, tend to dissipate rapidly, with 95% of comments occuring
1Collection of the corpus is an ongoing effort. Articles and com-
ments continue to be autonomously collected, and websites are still
being added to the collection effort. The description in this pa-
per therefore applies to the state of the corpus as of January 2012,
which represents about 6 months of data collection processing.
15
Table 1: A list of collected websites. Those allowing comment–
comment attachment are labelled with an asterisk (*).
News sites COI forums
bostonglobe.com animalrightsdiscussion.com
foxnews.com* animalsuffering.com
huffingtonpost.com* boston.com
lasvegassun.com conservativesforum.com
latimes.com* hindudharmaforums.com
miamiherald.com* kongregate.com
motherjones.com* mothering.com
npr.org mpacuk.org
nymag.com* richarddawkins.net
reuters.com thehighroad.org
washingtonpost.com* vanguardnewsnetwork.com
wsj.com* vegansoapbox.com
Table 2: Summary statistics for the two main components of
the corpus: news websites and community-of-interest discus-
sion forums.
News sites COI forums
# of websites 12 12
# of discussions 148,948 88,551
# of articles 116,449 13,842
# of comments 6,373,186 1,367,586
# of words in articles 53,241,204 6,965,108
# of words in comments 255,267,240 145,414,708
mean words per comment 40 106
mean words per article 457 503
mean unique commenters per site 26,525 5496
within 3 and 4 days, respectively, of the posting of an article. On
COI forums, however, discussions have a longer life, with the same
statistic for boston.com and mothering.com being 8 and 26 days
respectively. Interestingly, however, we find that data from all of
our sites fit well with a log-normal temporal distribution for com-
ments posted in a discussion, an observation that matches findings
in other dynamic processes on the internet, such as the evolution
of internet meme popularity [3]. Daily, weekly, and seasonal vari-
ations in activity are also readily apparent.
3. METHODS OF DATA COLLECTION
Almost all news sites engage their readers by allowing comments
to be attached to news articles. In fact, commenting has become
so essential that there are now hosted services such as Disqus2 and
Echo3 offering a comments platform. However, most of these web
applications uses AJAX technology and require user interaction,
making it very difficult to crawl such data [11].
Forum sites that create communities around a specific topic have
long been around. Platforms used by such sites are more or less
similar. While forum sites can be crawled using classical methods
and do not use AJAX, they tend to require registration in order to
access forum content.
Our data collection system shown in Figure 1 consists of a discov-
ery module and an extraction module. It is designed to satisfy two
2http://disqus.com
3http://aboutecho.com
Data Collection
RSS 
Reader
Web
Harvester
DB
Site
Settings
URL
Extraction
URL
Comment
  / Article
Embedded 
Browser
Embedded 
Browser
Content
Discovery
Figure 1: Data collection system
major goals: to discover new article URLs from sites of interest,
and to extract individual comments and articles. System capabil-
ities include programmatic login and using the Tor4 network for
anonymity.
All twelve of the news sites we harvested, and three COI sites, pro-
vide RSS feeds. For these sites, an RSS reader probes feeds for
new content, and stores the URLs in a database collection. For sites
lacking RSS feeds, or to gather archival data, the process is driven
by site-specific configuration files containing seed URLs. A web
harvester with an embedded browser starts with these seed URLs,
extracts all links and either stores them in a database or queues
them and continues navigation. Discovered URLs are then picked
up by the extraction module.
The extraction of the actual articles and comments from the HTML
pages is the most challenging part: first, AJAX-enabled sites re-
quire user interaction with pages to initiate data requests before
comments can be navigated; second, each site serves different meta-
data for comments, preventing the development of a unified data
model. We address the first issue with browser-based harvesting,
and the second issue with guided extraction and a schema-less doc-
ument storage.
A generic configuration file used by our system is shown in Fig-
ure 2. It consists of sections with key-value pairs, usually expressed
in JSON format.
While the meta and login settings are obeyed by both the harvest-
ing and extraction modules, the url-patterns section is mainly used
by the harvester. To limit the URL search space, only navigational
URLs, such as pagination links, are followed. Links that match ar-
ticle patterns actually point to a main news article or to the head of a
thread, and therefore are stored in the database for further process-
ing. The requestRate in the meta section defines the delay between
consecutive page requests from a single site; its default value is 15
seconds.
The remaining configuration sections are relevant to the extraction
4https://www.torproject.org/
16
[meta]
id = SiteID
seeds = {"urls":[seed1,seed2]}
tor = 1
requestRate = 25
[login]
username = {"by":"name","value":"username",
"send":"myusername"}
password = {"by":"name","value":"password",
"send":"mypasswd"}
url = http://login.url
[url-patterns]
navigation = {"urls":[regexp1,regexp2]}
article = {"urls":[regexp3],"save":"1"}
[articles]
showmore = //a[text()=’Single Page’]
[article]
title = //meta[@property=’og:title’]/@content
[comments]
root = //tr[starts-with(@id,’CommentKey:’)]
navigation = {"xpath":"//div[@id=’Paginator’]
//a[text()=’Next’]","loadfirst":1}
commentsLink = //td[@id=’CommentsHead’]/a
[comment]
author = .//td[@id=’profile’]/a
replyTo = .//a[@class=’reply-link’]/@href
Figure 2: Sample configuration for navigation and extraction
Comment Navigation
a c
ac
s
a   : page with article only
ac : page with article + comments
c   : page with comments only
Figure 3: Navigational finite state machine
system. Similar to harvester, the extraction module employs an em-
bedded browser. Although every site represents content differently,
they all share navigational patterns: with at most one click from
the landing page of an article, an initial set of comments can be
reached; remaining comments can be then accessed either by pag-
ination or expansion. See Figure 3. For example, foxnews.com
requires the user to click on “Load more”, and huffingtonpost.
com provides pagination via “Next” links. All these actions, how-
ever, increase the processing time of the page: a foxnews.com
article with thousands of comments might take an hour to load due
to the wait time after each click action. Once a comment page is
loaded in the browser data extraction takes place. For news content
extraction, boilerpipe [7], a parser also available in Tika, efficiently
and automatically detects the main article. However, for content
presented in a list form such as comments or forum posts, wrap-
pers provide better accuracy for our purpose as long as the page
layout does not change. Our extraction module uses the root pa-
rameter, found in the comments section of the configuration file, to
locate comment nodes. Then it iterates through the comment nodes
by extracting the fields based on name-XPath pairs in comment sec-
tion.
Aside from data such as author name and timestamp, some sites en-
able threaded discussion and present the dependency relationships
with other comments on the page. Our data collection system pre-
serves these conversational aspects by identifying the post to which
a comment replies, e.g., reply-to (parent and child) relationships.
Our data collection effort faced a number of challenges.
• With some COI sites, a requestRate even greater than the de-
fault was needed to avoid detection and subsequent blocking
of access.
• Many sites restrict discussion growth along either the time
or depth axis, necessitating a fast turnaround between article
detection and data extraction. For instance, reuters.com
disables commenting after around three days; and foxnews.
com refuses to even display comments after three days.
• Our XPath approach to extraction is sensitive to site re-design:
during the course of our data collection we experienced one
such incident.
• In order to do temporal analysis of the data, dates that the ar-
ticles and comments are published need normalization. How-
ever, every site employs a different format and precision for
date stamps: out of twenty sites we identified hundreds of
distinct patterns for date formats.
• Especially for sites with threaded commenting, we had to
perform extraction over the entire content to determine new
comments during our revisits. Previously seen comments
were identified by their unique ids within site. These ids are
exposed in HTML source to support functionalities such as
spam reporting. Content based duplicate detection failed due
to changing user signatures.
Our current corpus was collected on hardware with 4x2.66GHz
dual-core processors and 32GB RAM, running Linux. All soft-
ware modules were developed using Python. We chose the docu-
ment database MongoDB5 as our storage. We reached to 100GB
of database size, including indexes necessary to support crawling.
For analysis purposes, we stored snapshots on a local machine and
created more elaborate indexes. Firefox was used as an embedded
browser and controlled via the Python selenium web driver6.
4. LINGUISTIC ANALYSES
In the previous sections, we described the corpus and the manner of
its collection. In the remainder of the paper, we report preliminary
research concerning the linguistic and structural patterns associated
with meme propogation in online communities.
4.1 Discussion structure
The comments associated with an article form a discussion tree
with a structure that can vary in shape and size depending on vari-
ous factors. Learning how and why a discussion grows is helpful in
understanding the underlying community and the spread of ideas.
In sites that permit comment–comment attachment, we can observe
the propensity of authors to reply directly to other authors versus
5http://www.mongodb.org
6http://seleniumhq.org
17
Figure 4: Rate of Comment Attachment, by Frequency of Post-
ing, on foxnews.com
replying to the root article. We have found a split of roughly sixty
percent of comments attaching to other comments and forty per-
cent attaching directly to the root node. Moreover, at the author
level, we notice a clear relationship with frequency of posting: au-
thors who post more frequently are more likely to attach to other
comments as opposed to attaching to the root. Authors who have
submitted exactly one comment to a website are much more likely
to have replied to the root than to another author. Figure 4 plots
the observed rate of attachment to other comments, by number of
comments posted, for all authors posting to foxnews.com, along
with a smoothed trendline. (The scatter plot is rendered in gray
scale, with darker points representing higher conditional probabil-
ity given number of comments.) Figure 5 demonstrates that this
upward trend is characteristic of all sites studied.
What explains this behavior? It is likely that as an individual be-
comes more familiar with a website community, he or she is more
willing to engage other discussants in debate. Individuals who post
infrequently are more likely to have recently joined, and may there-
fore be uncomfortable participating in discussion. By contrast, the
’debater’ community will inevitably contain individuals who are
unwilling to let others have the last word. Another observation is
that among the participants who never bother to reply to—or even
read—others’ opinions, few are likely to contribute more than one
comment to any discussion.
4.2 Predicting Popularity and Attachment
Another of our goals in studying these data is to determine which
words, phrases, or other linguistic forms influence the amount of
attention the article receives, i.e., it’s popularity. We describe here
a simple experiment with this goal in mind. We formulate the ex-
periment as a machine learning prediction problem involving a re-
gression where the predictors (independent variables) are words in
the article text, and the output (dependent variable) is the number
Figure 5: Smooth trendlines for Rate of Comment Attachment,
by Frequency of Posting
of comments the article receives. We study 2,275 discussions from
wsj.com occurring in July, August, and September of 2011, train-
ing the predictor on 1,820 (80%) of the discussions, and testing it
on 455 (20%).
A central challenge to our prediction problem (and many others like
it) is that the number of unique word forms in the data far exceeds
the number of training samples. (The 2,275 articles in our current
dataset contain approximately 60,000 unique word forms.) This
means our focus needs to be on limiting the size of our model (reg-
ularization) in order to avoid overfitting. Support vector machines
(SVMs) are the state-of-the-art in classification and regression in
this setting. Interpreting their results, however, proves problem-
atic due to a lack of an easily interpretable relationship between
input features and model parameters. We therefore resort to sparse
regression techniques and feature selection approaches, a method
that has recently proven successful in the context of predicting de-
mographics from social media [4]. Specifically, we focus our effort
on an advance in this area called the elastic net [15], which is a re-
gression technique that employs a regularizer that is a linear com-
bination of the L2 norm (ridge regression) and L1 norm (lasso). We
use the R package glmnet to fit the model and run our experiments.
We find that elasic-net regression works remarkably well in com-
parison with SVMs, outperforming it in terms of mean predic-
tion error. After transforming the output variable (number of com-
ments) into a quantile (thus normalizing the output variable to the
interval (0,1)), the learned elastic-net regressor achieves a mean
error of .176 on the training set. On the other hand, SVM re-
gression7 achieves a mean error of .264. Analysis of the learned
sparse regression shows, for example, that for the selected period
of wsj.com, the words obama, taxes, and republicans are the most
7We used the libsvm package with the nu-SVR option. The nu
parameter was optimized on the test set by grid search.
18
effective positive predictors of popularity.
We have also begun to investigate the factors that drive the comment–
by–comment growth of discussions, i.e., attachment prediction. Our
goal here is to explain why particular branches of a discussion at-
tract different amounts of attention. Viewing the growth of a dis-
cussion as a series of attachment decisions, we can ask which of
the current nodes (including the original article, or root) is most
likely to receive the next reply. We can formalize discussion for-
mation as a generative process, in which each attachment decision
is made according to an unknown distribution over existing nodes,
and search for distributional models that best account for the ob-
served sequence of attachments. A natural performance metric un-
der these assumptions, borrowed from language modeling, is the
attachment perplexity.
Our experimentation in this area involved comparison between three
simple models. The first is a baseline uniform attachment model,
which considers every comment (as well as the article itself) equally
likely to receive the next comment. Second, we considered a pref-
erential attachment model, which assigns each comment a proba-
bility that is proportional to the number of comments already at-
taching to it. This latter model was then refined by incorporating
our prior findings about root attachment probability—we assigned
a forty percent probability to root attachment, and split the remain-
ing 60% probability among the remaining nodes according to pref-
erential attachment.
The order in which these models are listed above corresponds to
a consistent empirical ordering we observe on a range of datasets.
Simple preferential attachment yields a considerably lower attach-
ment perplexity than the uniform model, but is further improved by
the model that recognizes the special status of root attachment. As
we continue work in this area, we are searching for features of the
comments themselves–their lexical content, say, or the identify of
the commenter–that might allow us to refine further these simple
models.
4.3 Community variation and contrast
Because our corpus draws from many different online communi-
ties, each with a large collection of authors, there is great potential
in our corpus for studying linguistic variation amongst online com-
munities. Additionally, the conversational (and often controversial)
nature of the discussions provides a venue for studying contrasting
ideologies amongst groups. This section describes some of our pre-
liminary work in this area.
Exploratory analysis of lexical counts in comments shows that the
community of commenters within each website in our corpus has
remarkably distinct patterns of language use, particularly amongst
the COI forum sites. Importantly, the observed distinctions go be-
yond thematic variation (e.g., differences in topic of discussion),
and suggest marked sociological and stylistic contrasts among the
sites. For example, we find a large variation in the frequency of
personal pronouns, e.g., you, I, and we, which are known to be
stable high-frequency indicators of genre [12]. For example, the
word I ranges in frequency from 0.95% to 3.75% (a factor of 3.94)
across all sites, and the word we ranges in frequency from 0.15%
to 0.68% (a factor of 4.59).8 We also measured vocabulary size by
randomly sampling 100,000 words from the comments on each site
8The word I occurs at least 10,000 times in each of our websites
and the word we occurs at least 3,000 times.
Table 3: Psychometric analysis of websites using LIWC [14]
word class counts.
LIWC class Example Site with greatest relative freq.
ANXIETY ‘worry’ mothering.com
FRIENDS ‘buddy’ animalsuffering.com
SWEARING ‘piss’ vanguardnewsnetwork.com
CERTAINTY ‘always’ hindudharmaforums.com
DEATH ‘bury’ animalrightsdiscussion.com
INSIGHT ‘think’ richarddawkins.net
NEG. EMOTION ‘ugly’ reuters.com
POS. EMOTION ‘nice’ vegansoapbox.com
INHIBITION ‘block’ conservativesforum.com
and counting the number of unique words present in the sample (we
report mean results from repeating this procedure 100 times). The
resulting figure ranged from approximately 11,500 for the websites
motherjones.com, npr.org, and richarddawkins.net, to be-
low 9,000 for mothering.com. Both types of analysis suggest
strong distinctions between sites.
By analyzing counts of psychologically-relevant words, the data
also suggest distinct psychological characteristics of website com-
munities. In particular, we use a dictionary of word classes dis-
tributed with the Linguistic Inquiry and Word Count (LIWC) soft-
ware program [14]. LIWC is a system that performs psychomet-
ric analysis using counts of human-authored (and experimentally
validated) word classes such as FAMILY, POSITIVE EMOTION, and
CERTAINTY. Table 3 shows the results of applying a simple LIWC
analysis as follows. For a collection of LIWC word classes, we
list the website for which the word class has this highest relative
frequency. We find these results to match our intuitions about com-
munity psychology that have been gained from direct experience
with the comments.
4.3.1 Within-site contrasts
The analyses just described confirm that our corpus covers a wide
variety of communities. However, one of the central hypotheses we
ultimately wish to test with these data is that coherent but contrast-
ing ideological communities exist within each site. For example,
we expect that a controversial site like richarddawkins.net will
contain many debates between Darwinians and creationists, and we
want to be able to characterize the language use of these two ideo-
logical communities.
As a preliminary test of our hypothesis, we perform a simple anal-
ysis that contrasts the coocurrence of three-, two-, and one-word
phrases at varying levels of discussion structure. The technique
works by measuring how frequently two phrases co-occur in the
same discussion and contrasting this with how infrequently they
co-occur in the same comment. This allows us to identify pairs of
phrases that play opposing roles within conversations. We measure
this phenomenon using what we call the bifurcation of two phrases
x and y such that
bifurcation(x,y) = npmidiscussions(x,y)−npmicomments(x,y)
where npmiz(x,y) is the normalized pointwise mutual information
of the occurence of phrases x and y in the collection of corpus units
19
specified by z such that
npmiz =pmiz(x,y)/− log[max(pz(x), pz(y))]
pmiz =pz(x,y)/pz(x)pz(y)
where pz(w) is the proportion of units z in which the phrase w
occurs, and pz(w1,w2) is the proportion of units z in which both
phrases w1 and w2 occur.
The results of applying this analysis to our corpus show that some
interesting word pairs can be found. From an analysis of latimes.
com, for example, we find phrase pairs with high bifucation such
as “tea party movement”—“tea party people.” This pair seems to
reflect a positive and negative form of expression for the Tea Party.
It is apparent, however, that our approach warrants some refine-
ment, and the bifurcation analysis also draws out some interest-
ing but unexpected results. For example, the technique reveals
phrase pairs like “end of story”—“matter of fact” and “thanks in
advance”—“hope that helps,” both of which are indicative of dis-
course structure rather than opposing ideologies. Also, we find that
the technique is very good at distinguishing foreign language com-
ments. Analysis of animalsuffering.com, for example, revealed
several discussions in which comments were in both English and
French, generating word pairs like “she”—“elle.”
4.4 Linguistic meme epidemiology
Our discussion forums provide illustration of memetic outbreaks, in
which an idea or attitude propagates throughout a website’s reader-
ship. The biological metaphor is apt: a community of susceptible
individuals is exposed to an idea expressed by an “infected” indi-
vidual. Some individuals are “immune” and do not spread the idea,
whereas others readily adopt the meme in subsequent posts, be-
coming propagators of the idea. In discussion forums “exposure”
occurs when one individual reads a posting in which an “infected”
individual expresses the meme; the contact may or may not result
in transmission. As more infected individuals express the meme,
the number of contacts and hence infections increases and an “epi-
demic” ensues. The rate at which contact leads to transmission is
dependent on the likelihood that an individual post is viewed by
other community members, as well as the attractiveness of the idea
being expressed. In many cases the epidemic subsides as infected
individuals “recover”, no longer interested in active expression of
the meme. The duration of the epidemic is affected by this recovery
rate.
We have identified a number of memes that have attained currency
during the time periods spanned by our collections. These include
pithy epithets such as Party of No and catchphrases such as once
great nation. Our investigations focus on linguistic memes: phrases
or lexical entities that can be readily recognized in comments and
transmitted with little loss. An example is the family of insult
words containing the -tard suffix, such as libtard or religiotard.
Starting in approximately 2007, when this phenomenon was virtu-
ally non-existent, the use of -tard as a general-purpose pejorative
particle has seen rapid increase in several discussion forums. Our
analysis pools all of these forms into a single lexical meme. An-
other example of a lexical meme is cretinist, a derogatory form of
the word creationist.
Figure 6 depicts the number of authors expressing the -tard lexical
meme on the richarddawkins.net site as a function of time. The
adoption curve exhibits the classic shape of epidemic growth: rapid
initial increase, peak, and gradual decay. Figure 7 illustrates the
Figure 6: Adoption curve for -tard lexical meme
temporal growth in the number of authors expressing the idiom kick
the can down the road on the wsj.com site. The difference in time
scales for these two epidemics is noteworthy: evidently the kick the
can phrase went out of fashion relatively quickly.
Statistical and epidemiological techniques can be applied to model
meme outbreaks. Using a synchronic approach we might seek fac-
tors that predict some measure of severity of an outbreak, or that
predict the chance that an individual will be receptive to a particu-
lar meme; a diachronic approach might predict the evolution of an
outbreak as a function of history.
Our diachronic appproach adapts the familiar compartmental mod-
els from epidemiology to describe the dynamics of meme adop-
tion. We have found that the classic SIR model yields a qualita-
tively compelling fit to the observed adoption curve for a number
of meme outbreaks: If x(t), z(t), and w(t) denote the number of
susceptible, infectious, and recovered individuals at time t, then the
growth of these populations is modeled by the following system of
equations:
ẋ(t) = −ax(t)z(t)
ż(t) = bx(t)z(t)−dz(t)
ẇ(t) = dz(t)
for parameters a, b, and d. This classical epidemic behavior is of-
ten seen with novelty lexical memes, which tend to enjoy periods
of popularity and subsequent decline that are largely unaffected by
external events. For example, Figure 8 displays the fit of the SIR
model to the tard epidemic observed at six-month intervals begin-
ning in January 2008. Other memes are observed to follow the
classic trajectory, or to exhibit a “steady-state” background rate of
expression, but later experience a resurgence in popularity because
of an external event (e.g., a news item) that heightens the visibility
of the meme, and therefore alters the dynamics of adoption.
20
Figure 7: Adoption curve for kick the can down the road
Figure 8: Observed and fitted adoption curve for -tard lexical
meme
5. DISCUSSION AND FUTURE WORK
Online discussions provide fertile new ground for linguistic and
socio-linguistic research, but the collection of such discussions poses
more challenges than comparable social media. As this paper de-
scribes, we have worked through these challenges and amassed,
over the course of a few months, a corpus of approximately half a
billion words.
This data differs from other social media content in ways that open
new avenues of investigation. Unlike blogs, there is little or no
expectation that online comments will be carefully constructed or
even grammatical. Unlike Twitter, discussants are not consciously
broadcasting to the world, but are engaging in exchanges with the
author of an article or other discussants. Unlike Facebook, discus-
sants face no implicit pressure to maintain an identity. The low bar-
rier to participation, compared to these other forms of social media,
makes online discussion arguably more inclusive, contributing to a
sample of linguistic utterance from a much broader demographic
spectrum. Finally, the author-directed attachment of comments to
an article or other comments gives rise to an interesting collabora-
tive multi-document structure, the discussion, which other forms of
social media do not provide.
We have only begun to exploit the opportunity this data provides,
attempting to account for the spread of ideas, of memes, as an epi-
demiological phenomenon. None of this paper’s sections offers the
final word concerning its respective technical focus. Although our
harvesting pipeline has assembled a corpus of considerable size,
there are many lingering challenges, such as scaling to a larger
number of sites, automating site acquisition and maintenance, and
the normalization of comments to account for phenomena such as
quoting or excerpting. We have by no means accounted for all
the factors responsible for the rate and shape in which discussions
grow. We surmise, for example, that different users have different
effects on the propensity of a discussion to grow, some of it due to
their language, and some to their identity. We see clear linguistic
markers for community, but we have yet to measure the influence of
community on the spread of ideas. And we have demonstrated the
applicability of compartmental models to diachronic lexical adop-
tion, but not more directly to the spread of ideas. All of these ob-
jectives remain the focus of future work.
6. ACKNOWLEDGMENTS
This work was supported by the Intelligence Advanced Research
Projects Activity (IARPA) via Air Force Research Laboratory (AFRL)
contract number FA8650-11-C-7119. The U.S. Government is au-
thorized to reproduce and distribute reprints for Governmental pur-
poses notwithstanding any copyright annotation thereon. Disclaimer:
The views and conclusions contained herein are those of the au-
thors and should not be interpreted as necessarily representing the
official policies or endorsements, either expressed or implied, of
IARPA, AFRL, or the U.S. Government.
7. REFERENCES
[1] L. A. Adamic and B. A. Huberman. Zipf’s law and the
Internet. Glottometrics, 3:143–150, 2002.
[2] E. Adar and L. Adamic. Tracking information epidemics in
blogspace.
[3] C. Bauckhage. Insights into Internet memes. In Proc. 5th
Intl. AAAI Conference on Weblogs and Social Media
(ICWSM), pages 42–49, 2011.
[4] J. Eisenstein, N. A. Smith, and E. P. Xing. Discovering
21
sociolinguistic associations with structured sparsity. In Proc.
ACL 2011, 2011.
[5] M. Gomez-Rodriguez, J. Leskovec, and A. Krause. Inferring
networks of diffusion and influence. In Proceedings of the
16th ACM SIGKDD International Conference on Knowledge
Discovery and Data Mining (KDD 2010), 2010.
[6] D. Gruhl, R. Guha, D. Liben-Nowell, and A. Tomkins.
Information diffusion through blogspace. SIGKDD
Explorations, 6(2):43–52, 2004.
[7] C. Kohlschütter, P. Fankhauser, and W. Nejdl. Boilerplate
detection using shallow text features. In Proceedings of the
third ACM international conference on Web search and data
mining, WSDM ’10, pages 441–450, New York, NY, USA,
2010. ACM.
[8] P. L. Krapivsky and S. Redner. Organization of growing
random networks. Physical Review E, 63, 066123, 2000.
[9] R. Kumar, J. Novak, P. Raghavan, and A. Tomkins. On the
bursty evolution of blogspace. In Proceedings of WWW
2003, pages 568–576. ACM Press, 2003.
[10] K. Lerman and R. Ghosh. Information contagion: an
empirical study of the spread of news on Digg and Twitter
social networks. In Proceedings of the Fourth International
ICWSM Conference, 2010.
[11] A. Mesbah, E. Bozdag, and A. van Deursen. Crawling ajax
by inferring user interface state changes. In Web
Engineering, 2008. ICWE ’08. Eighth International
Conference on, pages 122 –134, july 2008.
[12] E. Stamatatos, N. Fakotakis, and G. Kokkinakis. Text genre
detection using common word frequencies. In Proc. 18th
Intl. Conf. on Computational Linguistics (COLING), pages
808–814, 2000.
[13] E. Sun, I. Rosenn, C. Marlow, and T. Lento. Gesundheit!
Modeling contagion through Facebook news feed. In
Proceedings of the Third International ICWSM Conference,
2009.
[14] Y. Tausczik and J. W. Pennebaker. The psychological
meaning of words: LIWC and computerized text analysis
methods. Journal of Language and Social Psychology, 29,
2010.
[15] H. Zou and T. Hastie. Regularization and variable selection
via the elastic net. Journal of the Royal Statistical Society B,
67, Part 2:301–320, 2005.
22
