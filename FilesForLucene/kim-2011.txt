Authorship Classification: A Discriminative Syntactic Tree
Mining Approach∗
Sangkyum Kim, Hyungsul Kim, Tim Weninger, Jiawei Han, Hyun Duk Kim
Department of Computer Science
University of Illinois at Urbana-Champaign
Urbana, IL 61801
{kim71, hkim21, weninge1, hanj, hkim277}@illinois.edu
ABSTRACT
In the past, there have been dozens of studies on auto-
matic authorship classification, and many of these studies
concluded that the writing style is one of the best indica-
tors for original authorship. From among the hundreds of
features which were developed, syntactic features were best
able to reflect an author’s writing style. However, due to the
high computational complexity for extracting and comput-
ing syntactic features, only simple variations of basic syn-
tactic features such as function words, POS(Part of Speech)
tags, and rewrite rules were considered. In this paper, we
propose a new feature set of k-embedded-edge subtree pat-
terns that holds more syntactic information than previous
feature sets. We also propose a novel approach to directly
mining them from a given set of syntactic trees. We show
that this approach reduces the computational burden of us-
ing complex syntactic structures as the feature set. Com-
prehensive experiments on real-world datasets demonstrate
that our approach is reliable and more accurate than previ-
ous studies.
Categories and Subject Descriptors
I.2.7 [Artificial Intelligence]: Natural Language Process-
ing—Text Analysis; H.3.3 [Information Search and Re-
trieval]: Clustering; H.2.8 [Database Applications]: Data
Mining
∗The work was supported in part by the Blue Waters
sustained-petascale computing project under the National
Science Foundation (award number OCI 07-25070) and
the state of Illinois, NDSEG Fellowship, NSF IIS-0905215,
NSF-CCF-0905014, U.S. Air Force Office of Scientific Re-
search MURI award FA9550-08-1-0265, and the U.S. Army
Research Laboratory under Cooperative Agreement No.
W911NF-09-2-0053 (NS-CTA). The views and conclusions
contained in this document are those of the authors and
should not be interpreted as representing the official poli-
cies, either expressed or implied, of the Army Research Lab-
oratory or the U.S. Government. The U.S. Government is
authorized to reproduce and distribute reprints for Govern-
ment purposes notwithstanding any copyright notation here
on.
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for profit or commercial advantage and that copies
bear this notice and the full citation on the first page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior specific
permission and/or a fee.
SIGIR ’11 July 24-28 2011, Beijing, China
Copyright 2011 ACM 978-1-4503-0757-4/11/07 ...$10.00.
General Terms
Algorithms, Experimentation
Keywords
Authorship Attribution, Text Mining, Text Categorization,
Authorship Discrimination, Authorship Classification
1. INTRODUCTION
In computational linguistics and text mining domains,
there are three classical classification problems: topic clas-
sification, genre classification, and authorship classification.
Among these three problems, arguably the most difficult is
the classification of documents in terms of their authorship
(known as authorship classification, authorship attribution
and/or authorship discrimination). This problem can be
thought of as classifying documents based on the writing
styles of the authors. This is a nontrivial problem even
for humans: while a human can easily identify the topic
and genre of a given document, identifying its authorship is
harder. If the documents are in the same topic and genre,
the task becomes much harder.
In the era of excessive electronic texts, authorship classi-
fication has become more important than ever before with
a wide variety of applications. Besides the early works of
analyzing the disputed plays of Shakespeare(1887) [22] or
anonymous documents of The Federalist Papers(1964) [24],
it could also be used to identify authors of short ‘for sale’
messages in a newsgroup [36] and even for forensic inves-
tigations by identifying authorship of e-mail messages [2].
Detecting plagiarism or copyright infringement of unautho-
rized reuse of source code by establishing a profile of an au-
thor’s style is another important application of authorship
classification [5].
Existing approaches to authorship classification use vari-
ous methods to extract effective features, the most common
of which include style markers such as function words [9,
33, 1, 12] and grammatical elements such as part of speech
(POS) tags [3, 11, 35]. Function words are common words
(e.g. articles, prepositions, pronouns) that have little seman-
tic content of their own but usually indicate a grammatical
relationship or generic property. Recently, there have been
several papers that claimed function words are more effec-
tive than other types of style markers [33, 35, 34].
Unfortunately, research on more complex syntactic struc-
tures has not been practical because of the lack of a reliable,
automatic tool which retrieves syntactic structures, and be-
S
S – simple declarative clause
NP – noun phrase
PP – prepositional phrase
IN – preposition
VP – verb phrase
VBD ‐ verb, past tense 
Example. The major indexes fell more than 2 percent, and the surge that had lifted the troubled indexes by more than 20 
percent in the last month showed signs of stalling as the reporting period for the first fiscal quarter of the year began.
Pattern t Syntactic Tree S
NP VP
PP
IN NP
VBD PP
NPIN
Figure 1: A 2-ee subtree t is mined from two The New York Times journalists Jack Healy and Eric Dash who
worked in the same business department. On average, 21.2% of Jack’s sentences contained t while only 7.2%
of Eric’s sentences contained t.
cause of the high computational cost associated with syntac-
tic structure-based algorithms. Instead, several variations of
POS tags [9, 11, 15] and rather simple syntactic structures
like rewrite rules [3, 11, 15] have been proposed. Among
them, bigram POS tags and rewrite rules showed reliable
performance in various dataset configurations.
Recently, several advanced techniques have been devel-
oped which greatly improved the performance of Natural
Language Processing(NLP) tools1 enabling reliable, highly
accurate sentence parsing into a syntactic tree of POS tags.
A syntactic tree is a rooted and ordered tree that is labeled
with POS tags that represent the syntactic structure of a
sentence. Based on the syntactic trees parsed by these tools,
we propose a novel syntactic feature set of tree fragments al-
lowing at most k-embedded edges (in short, a k-ee subtree).
We say there is an embedded edge between two nodes if and
only if they are in an ancestor-descendant relationship but
not in a parent-child relationship. Compared with previ-
ous feature sets that consist of parts of distinct connected
subtree components, our new feature set captures the re-
lationship between k+1 connected subtree components of
a syntactic tree, which leads to a better representation of
datasets consisting of long and complex sentences. Figure 1
gives an example of a k-ee subtree t for k = 2. Pattern t is
composed of three smaller subtrees, which are connected by
two embedded edges (S,NP) and (VP,PP). The differences
in pattern distributions between two authors suggest that a
set of k-ee subtrees can be utilized as a good feature set for
authorship classification.
To reduce the number of features, we only mine a set of
frequent and discriminative k-ee subtrees, which results in
higher accuracy by avoiding overfitting to the training data
and by not generating non-discriminative features that often
degrade the performance. This task is commonly referred to
as pattern-based classification. The original pattern-based
classification technique employed a two-step procedure called
generate-and-test which generates all frequent and closed
candidate patterns and then selects the discriminative pat-
1We used Stanford Parser (http://nlp.stanford.edu/
software/lex-parser.shtml), but there are more tools
available like Natural Language ToolKit (NLTK) package
(http://www.nltk.org).
terns among them [20]. Unfortunately, it is still intractable
to use this generate-and-test methodology to get discrimina-
tive patterns because there are simply too many candidate
patterns.
For this reason, there have been quite a few works which
directly mine discriminative patterns without generating all
candidates [7, 37, 29]. Yet, these existing works cannot be
directly applied to our problem setting because they require
the feature values to be binary. Instead, we require numeric
feature values because a (syntactic) feature can occur mul-
tiple times in a document and usually the number of occur-
rences implies its importance. Existing works are all based
on binary-valued features and their theorems and proofs are
not easily extendable to numeric-valued features. A recent
work ([18]) showed that it has more gain to use numeric
values than to discretize them into binary values. It also
proposed a new way to directly mining discriminative nu-
meric features by solving a linear programming optimization
problem. But all these previous works mine top-1 pattern
iteratively until the mined patterns cover the entire data.
To cope with this issue, we derive an upper bound of a dis-
criminative score of numeric-valued features, and develop
an efficient algorithm that mines in one iteration a set of
discriminative patterns to be used for classification purpose.
To validate the utility of our new feature set compared to
others, for fair comparisons, we apply the same SVM classi-
fication algorithm using various feature sets on several real
data collections. Because of its high and reliable perfor-
mance, SVM has commonly been used to compare the ef-
fectiveness of feature sets [11, 35, 15]. Experimental results
demonstrate the effectiveness of the proposed k-ee subtree
features in comparison to the well-known existing feature
sets of function words, POS tags, and rewrite rules. We
demonstrate that by using k-ee subtrees as the feature set
we outperform the existing feature sets by 8.23% on average
and show that it is significantly better from other approaches
by t-test with 95% confidence level.
In summary, the contributions of this paper are as follows:
• We propose a new feature set of k-ee subtrees for au-
thorship classification.
• We develop an efficient algorithm to directly mine dis-
criminative k-ee subtrees, which are not binary but
numeric valued features, in one iteration.
• Through comprehensive experiments on various datasets,
we demonstrate the utility of our proposed framework
to provide an effective solution for the authorship clas-
sification problem.
The rest of the paper is organized as follows. Section 2
presents an overview of the related works. In Section 3, we
introduce various preliminary concepts and define our new
feature set of k-ee subtrees. Section 4 explains a branch-
and-bound framework of discriminative k-ee subtree mining.
We report experimental results in Section 5, followed by
discussions in Section 6 and conclusions in Section 7.
2. RELATED WORKS
There are two main steps involved in any authorship clas-
sification algorithm: (1) the feature extraction step and (2)
the classification step based on features extracted from the
first step.
For the feature extraction step, since the earliest works of
the authorship attribution on the plays of Shakespeare(1887)
[22] and The Federalist Papers(1964) [24] that used a small
number of common words such as ‘and ’, ‘to’ as a feature set,
nearly 1,000 different feature sets have been studied includ-
ing sentence length, chi-square score, lexical richness [17],
vocabulary richness [8], function words [1], word n-grams
[27], character n-grams [13], and rewrite rules [3] with lots
of controversy on their effectiveness. Even though there is an
issue of fair comparison among feature sets because previous
works conducted experiments based on their own datasets
with different classification methods [33, 28], function words
and rewrite rules are generally considered to give reliable
and good results. In [35, 34], the authors compared func-
tion words with other feature sets (even combination of those
feature sets) to show that function words are better than the
other feature sets.
Even though many new features have been explored for
authorship classification, most of the classification algorithms
are simply adapted from other domains’ well-known classi-
fication algorithms such as PCA [16], k-nearest neighbor,
decision tree, bayesian networks [33], and SVM [9, 11, 35,
15]. In [35], a language model based authorship classification
framework was proposed, which showed comparable perfor-
mance to SVM. Because of its high and reliable performance,
SVM has commonly been used to compare the effectiveness
of feature sets [11, 35, 15], so in this paper we also use SVM
for fair comparison between our new feature set and existing
feature sets.
While most of the earlier works focused on binary au-
thorship classification problem (classifying documents from
two authors) which showed significantly good results, recent
works including [2, 19, 21, 33, 35] have brought up the prob-
lem of multiple authorship classification (classifying docu-
ments from more than two authors). Thus, in this paper,
we also show the effectiveness of our proposed k-ee subtrees
feature set by solving both binary and multiple authorship
classification problems.
Our proposed k-ee subtrees feature set can be considered
to be a variation of tree patterns. In the data mining do-
main, there have been several studies on tree pattern mining
[30, 31, 4]. TreeMiner [30] is one of the pioneering frequent
tree pattern mining algorithms. For tree classification, rule-
based classifiers (XRules [31]) and a decision tree based clas-
sifier (Tree2 [4]) were proposed. To the best of our knowl-
edge, mining k-ee subtrees has never been discussed before.
3. PRELIMINARIES
Previous authorship attribution approaches adopted func-
tion words, POS tags, and rewrite rules as a feature set
to build a classification model. Even though they achieved
good accuracy, there still exists room for a more meaningful
feature set to improve the performance. In this section, we
describe rewrite rules which are somewhat complex syntac-
tic structures that hold more syntactic information than the
other two feature sets. Also, we define our new feature set
of k-ee subtree patterns.
3.1 Rewrite Rule
In [3], rewrite rules were considered to be building blocks
of a syntactic tree, just as words are building blocks of a
sentence. Here, a syntactic tree is a rooted and ordered tree
which is labeled with POS tags that represents the syntactic
structure of a sentence. Its interior nodes are labeled by non-
terminals of the grammar, and the leaf nodes are labeled by
terminals.
Compared to previous approaches that utilized function
words and POS tags, rewrite rules can hold functional struc-
ture information of the sentence. In linguistics, a rewrite rule
is in the form of “X → Y ” where X is a syntactic category
label and Y is a sequence of such labels such that X can be
replaced by Y in generating the constituent structure of a
sentence. For example, “NP → DT+JJ+JJ+NN ” means
that a noun phrase (NP) consists of a determiner (DT ) fol-
lowed by two adjectives (JJ) and a noun (NN ).
There is a limit when using rewrite rules as features of a
classification model. First, because of the restriction that
the entire rule cannot be broken into smaller parts, no sim-
ilarity between rules are considered. A large number of
slightly different rules are all counted as independent fea-
tures. For instance, a rewrite rule “NP → DT+JJ+NN ”,
missing one JJ from the above example, becomes a separate
rewrite rule. Second, the expressibility of rewrite rules is
limited because they must adhere to a very strict two-level
tree structure, which does not allow the entire rule to be
broken into smaller parts. For example, the relationships
between rewrite rules are missing, which can hold more re-
fined syntactic information. For these reasons, we developed
a new feature set of k-ee tree patterns that are flexible and
complex enough to represent the syntactic structure infor-
mation of a sentence.
3.2 k-Embedded-Edge Subtree
To overcome the drawbacks of simple syntactic feature
sets used in previous approaches, we explore more complex
syntactic features. Induced subtrees of a syntactic tree are
one of the candidate feature sets whose features are multi-
level tree fragments used to model the complex syntactic
structure of a sentence. Here, we define a tree t to be an
induced subtree of a tree s if there exists an identity map-
ping from t to s preserving all parent-child relationships be-
tween the nodes of t. Our pilot experiments showed that
a small number of combinations of those induced subtrees
could achieve even higher accuracy, which motivated us to
define k-ee subtrees for our new feature set. Based on this
A
B B B B
A
B B
Pattern  t Syntactic Tree  S  
Figure 2: Example of overcounting overlapped k-ee
subtree occurrences
motivation, we designed a new tree pattern that can capture
this phenomenon.
Definition 1. We define an embedded edge e of a tree s
to be a pair of two nodes with an ancestor-descendant rela-
tionship. We define a k-embedded-edge subtree (shortly,
k-ee subtree) t of a tree s to be a set of induced subtrees of
s that can be connected by at most k embedded edges (not
with parent-child relationships) for a user specified value k.
The number of k-ee subtrees would be exponential on the
number of trees and their sizes. We define a minimum sup-
port θ to ensure we only mine general common patterns that
will be applicable to test data thus avoiding overfitting. We
define the support of a feature t (denoted by sup(t)) to be
the total number of sentences in training data that contains
t. We say t is frequent if and only if sup(t) ≥ θ for a user-
specified minimum support threshold θ.
3.3 Document Representation based on Dis-
criminative k-ee Patterns
The frequency of a pattern in a document (or a set of syn-
tactic trees) is quite important in the sense that it can be
a good measure to discriminate the writing styles of differ-
ent authors. Well-known features like function words, and
the POS tag-adapted bag-of-words approach use the num-
ber of occurrences in a document as their frequency measure.
However, unlike function words and POS tags, k-ee subtrees
cannot simply adapt the same frequency measure because it
generates overlapped occurrences, which would lead to an
exaggerated frequency value. Figure 2 is an illustration of
this overcounting problem. The syntactic tree S has only one
A and four Bs, but the number of occurrences of pattern t
becomes 6. More generally, if A has n Bs as its children in
S, then the occurrence count of pattern t becomes O(n2).
Since we allow k embedded edges for a k-ee subtree, this
overcounting problem will be even more amplified.
Our observation that a document is parsed into a set of
syntactic trees (of sentences) gave us an insight to define the
frequency measure of a k-ee subtree in a more natural way
by counting the number of syntactic trees of a document
that contain the pattern.
Definition 2. We define the frequency of a k-ee subtree
t in a document d (denoted by freq(t, d)) to be the number
of syntactic trees (i.e., parsed sentences) in d that contain t
over the total number of sentences in d.
We will discuss how to mine discriminative k-ee subtree
patterns in the following section (Section 4). For here, sup-
pose we already have them in a set P = {t1, · · · , tn}. Then,
we can express a document d as a vector of their frequencies
as d = (freq(t1, d), · · · , freq(tn, d)).
S3
S4
d2
A
B C
A
C
S1
S2
d1
A
B C
A
B
(a) A toy database D
with 2 documents. Each
document has 2 syntactic
trees.
A
B
A
t2 t4
t1
A
B C
t3
A
C
B
t5
C
t6
(b) Pattern growth of k-ee
subtrees with θ = 0.5 and
k=0
Figure 3: Database D and its frequent k-ee subtrees
4. DISCRIMINATIVE K-EE SUBTREE MIN-
ING
In the previous section, we introduced k-ee subtrees as
a new feature set for authorship classification. These pat-
terns hold more expressive syntactic information than other
features and are flexible enough to consider partial match-
ings of syntactic trees, but the number of k-ee subtrees is
above our control. Therefore, we need to directly mine a
small number of discriminative patterns not only to reduce
the number of features but also to mine significant patterns
which has been shown to improve classification accuracy [6].
In this section, we present a branch-and-bound framework
to solve this problem.
4.1 Mining Frequent k-ee Subtrees: Pattern-
Growth Approach
We do not generate candidate k-ee subtrees and check for
frequent attributes. Instead, we find a frequent k-ee subtree
and extend it by adding a node that is guaranteed to be fre-
quent in a depth-first manner, which enables several prun-
ing techniques for frequent and discriminative pattern min-
ing. We first introduce how to efficiently mine frequent pat-
terns based on pattern-growth approach by using projected
database [26, 38], and then explain pruning techniques to
mine discriminative patterns.
We illustrate the procedure for pattern-growth approach
as follows. First, find a size-1 frequent k-ee subtree t in the
training dataset D. Second, project the postfix of each oc-
currence of t in the syntactic trees of D into a new database
Dt. A postfix of an occurrence of t in a syntactic tree s is a
forest of the nodes of s appearing after the occurrence of t
in a pre-order scan of s. Third, find a frequent node v in Dt
that can be attached to the rightmost path of t that forms
a k-ee subtree. Once v is frequent in Dt, it ensures that the
extended pattern is also frequent, so we do not need to scan
the whole database D again. Note that, in this study, we
consider a node v attached to t by an (induced) edge differ-
ent from the one attached by an embedded edge. Fourth,
recursively go back to the second step with the extended
pattern for every frequent node we find. Note that the pro-
jected database of a pattern t keeps shrinking as the mining
process moves on and t becomes a bigger superpattern.
Example 1. Figure 3 shows an example of the pattern-
growth approach to mine 0-ee subtrees from a database D
of four syntactic trees when minimum support threshold is
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
FW POS BPOS RR 0‐ee 1‐ee 2‐ee
Figure 4: Binned information gain score distribution
of various feature sets
0.5. Each pattern is indexed in pattern-generation order.
We first search for size-1 frequent patterns, which are t1, t5
and t6. We choose t1 as a starting point, and find frequent
nodes that can be attached to t1 from its projected database.
We find that nodes B and C are frequent, and we extend t1
to t2 by adding a node B. Similar procedures are recursively
performed until we mine all frequent patterns.
4.2 Binned Information Gain Score
In previous subsections, we presented a pattern-growth
method to mine frequent patterns, but the resulted patterns
may still be too many. Based on the study that the patterns
with high discriminative score can improve the classification
performance [6], we first evaluate the discriminative power
of a k-ee subtree. Note that most of the well-known dis-
criminative scores (e.g. information gain, fisher score) have
upper bound on binary feature values not on numeric fea-
ture values [6, 7, 29, 25]. In this subsection, we define a
new discriminativeness score, binned information gain, and
derive its upper bound on the numeric feature values to en-
able a branch-and-bound framework to mine discriminative
patterns on numeric feature values.
Definition 3. For a user specified number n, we divide
range [0, 1] of the relative sentence frequency per document
of t into a partition p of equi-width n bins: p1 = [0,
1
n
),
p2 = [
1
n
, 2
n
), · · · , pn−1 = [n−2n ,
n−1
n
), pn = [
n−1
n
, 1]. For a
given partition p and m classes C1, · · · , Cm, we define the
binned conditional entropy of t by
H(C|X) = −
n∑
i=1
P (X ∈ pi)
m∑
k=1
P (Ck|X ∈ pi) log p(Ck|X ∈ pi)
and binned information Gain of t by IG(C|X) = H(C) −
H(C|X) where H(C) = −
∑m
k=1 p(Ck) log p(Ck).
A pattern t will have a large binned information gain score
if the frequency distribution imbalance between the classes
becomes bigger for each bin, which means t is significant to
discriminate classes.
Figure 4 presents binned information gain score distribu-
tions of various feature sets such as function words (FW),
POS tags (POS), bigram POS tags (BPOS), rewrite rules
(RR), and k-ee subtrees for k=0, 1, and 2 (0-ee, 1-ee, and
2-ee, respectively). We can easily see that the highest scores
are mostly from k-ee subtrees, which implies that they can
be more meaningful than other features – an assertion we
later test in the experiments section.
For a tree pattern t, we denote binned information gain
of t by IG(t) and information gain upper bound of t and
its superpatterns by IGub(t). Given a k-ee subtree t and a
partition p, we define (A,B, p) to be a frequency distribution
of t where A = (A1, . . . , An) and B = (B1, . . . , Bn) with
Ai and Bi being the number of documents in class C1 and
C2 respectively for each bin pi of a partition p. Denote
(A′, B′, p) as a frequency distribution of a super pattern t′
of t. The following two lemmas describe the properties of
(A,B, p) and (A′, B′, p) that will be used to prove the main
theorem to derive the upper bound of binned information
gain.
Lemma 1. For any k = 2, . . . , n, the following four in-
equalities hold for a k-ee subtree t and its superpattern t′:∑n
i=k A
′
i ≤
∑n
i=k Ai,
∑k−1
i=1 A
′
i ≥
∑k−1
i=1 Ai,
∑n
i=k B
′
i ≤∑n
i=k Bi, and
∑k−1
i=1 B
′
i ≥
∑k−1
i=1 Bi.
Proof. Since t′ is a superpattern of t,
∑n
i=k A
′
i ≤
∑n
i=k Ai
for k ≥ 2. Therefore,
∑k−1
i=1 Ai = |C1| −
∑n
i=k Ai ≤ |C1| −∑n
i=k A
′
i =
∑k−1
i=1 A
′
i where |Ci| is the number of documents
in class Ci. Similar proof for Bi.
The following lemma shows the condition to get the upper
bound of binned information gain for a special case when
only the first two bins of frequency distribution are different.
Lemma 2. For a given frequency distribution (A,B, p),
let (A′, B′, p) be a frequency distribution with A′1 = A1 +
x, A′2 = A2 − x (0 ≤ x ≤ A2) and the rest unchanged.
If A1
A1+B1
≥ A2
A2+B2
, then (A′, B′, p) achieves its minimum
conditional entropy when x = A2. Otherwise, it achieves its
minimum conditional entropy when x = 0.
Proof. Let f(x) be the conditional entropy of (A′,B′,p)
and N be the total number of documents. Then,
f(x) =
A1 + B1 + x
N
(
−
A1 + x
A1 + B1 + x
log
A1 + x
A1 + B1 + x
−
B1
A1 + B1 + x
log
B1
A1 + B1 + x
)
+
A2 + B2 − x
N
(
−
A2 − x
A2 + B2 − x
log
A2 − x
A2 + B2 − x
−
B2
A2 + B2 − x
log
B2
A2 + B2 − x
)
+
n∑
i=3
P (X ∈ pi)
2∑
k=1
P (Ck|X ∈ pi) log p(Ck|X ∈ pi)
f
′
(x) =
1
N
log
(
A1 + B1 + x
A1 + x
·
A2 − x
A2 + B2 − x
)
If A1
A1+B1
≥ A2
A2+B2
, f ′ (x) ≤ 0. Otherwise, f ′ (x) > 0.
The following theorem describes that the binned infor-
mation gain upper bound exists and is determined by the
frequency distribution of the first two bins.
Theorem 1. Given a tree pattern t, its super patterns
including itself have a conditional entropy lower bound in the
frequency distribution (A′, B′, p) of one of the following two
forms: (1) A′1 = A1 +A2, B
′
2 =
∑n
i=2 Bi, B
′
1 = B1, B
′
i = 0
(i = 2, . . . , n) and A′i = Ai (i = 3, . . . , n) (2) B
′
1 = B1 +B2,
A′2 =
∑n
i=2 Ai, A
′
1 = A1, A
′
i = 0 (i = 2, . . . , n) and B
′
i = Bi
(i = 3, . . . , n).
Proof. Suppose (Ā, B̄, p) is a frequency distribution of
a superpattern t̄ of t with minimum conditional entropy
whose form is in neither cases. Denote Pi =
Āi
Āi+B̄i
and
Qi =
B̄i
Āi+B̄i
(i = 1, . . . , n). By generalizing Lemma 2, ei-
ther Pi < Pi+1 or Pi+1 = 0 (i = 1, . . . , n − 1). Symmet-
rically, either Qi < Qi+1 or Qi+1 = 0 (i = 1, . . . , n − 1).
Then, for all i = 2, . . . , n, either Pi = 0 or Qi = 0. (∵ As-
sume Pi 6= 0 and Qi 6= 0 for some i. Then, Pi−1 < Pi and
Qi−1 < Qi. But, 1 − Pi−1 = Qi−1 < Qi = 1 − Pi which
is a contradiction.) Therefore, either P2 = 0 or Q2 = 0.
Without loss of generality, say P2 = 0. Then, we can get
another distribution (Ā′,B̄′,p) where B̄′2 =
∑n
i=2 B̄i, B̄
′
i = 0
for (i = 3, . . . , n), and the rest unchanged from (Ā,B̄,p).
Since its conditional entropy at each bin pi (i = 2, . . . , n)
becomes 0, it has smaller or the same conditional entropy
with (Ā,B̄,p). By the assumption that (Ā,B̄,p) has the min-
imum conditional entropy, their conditional entropy are the
same. By Lemma 1, Ā′1 ≥ A1 +A2 and B̄′1 ≥ B1 (∵ Ā′2 = 0
since P2 = 0). If either Ā
′
1 > A1 + A2 or B̄
′
1 > B1, then
the conditional entropy of (Ā′,B̄′,p) becomes higher than
the conditional entropy of (A′,B′,p) in the first form of the
theorem which is a contradiction to our assumption that the
conditional entropy of (Ā,B̄,p) is minimum. Similar contra-
diction can be derived when Q2 = 0.
4.3 Modified Sequential Coverage Method
The binned information gain measure and its upper bound
described in Section 4.2 enables a branch-and-bound frame-
work, and we can simply perform the feature selection proce-
dure in a traditional sequential coverage way as follows ([7,
29]). First, we mine the most discriminative k-ee subtree
and add it to the feature set. Second, we remove trees that
contain the extracted pattern and compute binned informa-
tion gain scores of the remaining patterns on the updated
database. In this way, redundant patterns will have a small
chance to be selected. Third, we go back to the first step un-
til either the dataset becomes empty or no more patterns are
mined. Once the feature selection procedure is complete, we
get a small number of discriminative k-ee subtrees. Based
on the feature set F of these patterns, we use the document
representation described in Section 3.3 to train a classifica-
tion model.
But this procedure is inefficient when many discriminative
patterns need to be mined because the sequential coverage
method described above is based on iteratively mining one
discriminative pattern for each iteration. We observe that
the object of iterative approach is to find non-repetitive dis-
criminative patterns. For this purpose, previous works sim-
ply applied the decision tree scheme of feature selection ei-
ther (1) to a sequential coverage method to be used for SVM
classification model [7, 29] or (2) to a decision tree classifi-
cation model directly [10]. The difference between them
is that the former recursively mines the dataset that does
not contain the pattern, and the latter recursively mines
both datasets containing and not containing the pattern.
But both approaches need to recompute discriminativeness
scores of the patterns on the updated database paying an
expensive computational cost, which does not really involve
removing repetitive patterns. We propose to use a modified
sequential coverage method which does not recompute the
binned information gain scores.
4.4 Direct Discriminative k-ee Subtree Min-
ing
In this section, we design a novel algorithm to efficiently
mine discriminative patterns in a single iteration. We com-
pute the binned information gain score only once, and apply
the sequential coverage method without recomputing the
binned information gain scores. Moreover, we propose an
efficient way of mining the discriminative patterns in one
iteration.
Here, we define some terms and symbols that will be used
for the rest of the section. We denote t |= s when a k-ee
subtree t is contained in a tree s. We define St = {s ∈
D|t |= s} to be a set of trees in a tree dataset D that contain
t. Also, we define At = {p : k-ee subtree|∃s ∈ St, p =
argmaxp|=sIG(p)} to be a set of patterns that achieve the
highest discriminative score among all patterns in some trees
that contain t, and Bt to be a set of arbitrary patterns from
each tree of St. We denote F to be a set of discriminative k-
ee subtrees in D mined by the modified sequential coverage
method.
The following lemma characterizes discriminative patterns
mined by sequential coverage.
Lemma 3. For a given tree dataset D,
F = {t|∃s ∈ D such that t = argmaxp|=sIG(p)}.
Proof. By the definition of the modified sequential cov-
erage method mentioned in Section 4.3.
Lemma 3 explains that the discriminative patterns mined
by the modified sequential coverage method are indeed the
most discriminative patterns for some trees of D. Based on
this observation, we derive a pruning method by branch-and-
bound approach in the following proposition.
Proposition 1. (Branch-and-Bound (BB) Pruning)
If IGub(t) < minp∈At IG(p), then no superpattern t
′ of t is
in F .
Proof. Since St ⊇ St′ , IGub(t) < minp∈At IG(p) ≤
minp∈At′ IG(p). That is, t
′ cannot be the most discrimi-
native pattern for any tree in St′ .
Corollary 1. If IGub(t) < minp∈Bt IG(p), then no su-
perpattern t′ of t is in F .
Proof. By definition of At, IGub(t) < minp∈Bt IG(p) ≤
minp∈At IG(p).
In case IGub(t) = minp∈Bt IG(p), we also skip mining
Dt since any tree containing a superpattern t′ of t will also
contain another pattern that has higher or the same discrim-
inative score.
Once we know an upper bound of the discriminative score
of t’s superpatterns, we can use the BB pruning method
described in Proposition 1. Unfortunately, as alluded to
earlier, this is a nontrivial task because the feature values
are numeric instead of binary. In Section 4.2, we partitioned
the numeric range [0, 1] into a finite number of bins and
derived the upper bound of binned information gain score
by checking a constant number of cases (at most 2 cases)
regardless to the number of bins.
In the mining process, since we do not know At, we set
Bt to be the set of current best patterns of St and apply
Corollary 1 as a BB pruning condition. For that reason, we
maintain current best patterns for each tree.
Example 2. Consider the example from Figure 3. Sup-
pose class c1 has a document d1 and class c2 has a document
d2 from a database D. Let the number of bins for binned in-
formation gain be 3 (i.e. n = 3). We first mine t1, compute
its discriminative score (IG(t1) = 0) and update current
Bt1 (Bt1 = ∅) by checking t1. Now, Bt1 = {t1}. Since
IGub(t1) = 1 > minp∈Bt1 IG(p) = 0, we move on to next
pattern t2 without pruning. We compute t2’s discriminative
score (IG(t2) = 1), and update Bt2 = {t1} to be Bt2 = {t2}.
Since IGub(t2) = 1 = minp∈Bt IG(p), we can skip generat-
ing t3.
Following the original sequential coverage methodology
mentioned in Section 4.3, when a k-ee subtree t is generated
the trees containing t are removed. But in real classification
tasks, we may want to generate multiple patterns to repre-
sent a tree to improve accuracy. To address this issue, we
use a minimum feature coverage threshold δ introduced in
[7], i.e., a tree is removed when it is covered by at least δ dis-
criminative patterns. Lemma 3 and Proposition 1 can easily
be adapted with the feature coverage parameter δ by main-
taining top-δ patterns for each tree and using δ-th highest
discriminative score as a cut-off threshold for each tree.
In summary, we proposed a branch-and-bound framework
of authorship classification. During the process, the algo-
rithm retains and updates the most discriminative patterns
Opt(s) of each tree input, and at the end they become F .
The basic framework is to expand the patterns from small
to large sizes in pattern-growth approach. Before we expand
current pattern t into a larger one, we compute the upper
bound of the binned information gain of all superpatterns
of t. Based on BB pruning described in Corollary 1, if the
upper bound value is not greater than the current minimum
Opt(s) from all trees (s) containing t, then we can safely
skip exploring superpatterns of t.
5. EXPERIMENTS
In this section, we present an empirical evaluation in or-
der to validate the performance of our k-ee subtree based
authorship classification. We also analyze the effect of the
parameters of k-ee subtree patterns presented in this paper.
The experiments are designed to test the usefulness of k-ee
subtrees, as a new feature set, for authorship classification.
5.1 Datasets
For the following experiments, we used public data collec-
tions extracted from the TREC corpus [14] and The New
York Times2.
Table 1: Characteristics of data collections
Data # Authors Doc Doc/Author Sentence Word
NTNews 4 400 100 19,161 381,450
Movie 4 2,177 415 – 598 51,086 1,299,682
TREC 7 6,336 804 – 1,003 169,767 3,964,865
From The New York Times we collected two different
types of datasets: news articles and movie reviews. For
the news articles, we randomly selected two journalists from
the business department, and two other journalists from the
health department who were the main contributors in their
departments.3 We collected datasets assuming that the jour-
2http://www.nytimes.com
3Eric Dash and Jack Healy from the business department,
and Denise Grady and Gina Kolata from the health depart-
ment.
nalists in the same department are likely to write articles on
the same topic and genre using similar words.
For the movie reviews, we used four movie critics from the
The New York Times. It has three main critics whom we
used. We added another randomly selected critic who is one
of the major contributors.4 We collected this data because
most of the movies reviewed by the critics overlapped. We
assumed movie reviews of the same movie will be on the
same topic and genre using similar words.
We also used news articles from the Associated Press (AP)
subcollection of the public TREC corpus. The AP collection
has over 200,000 documents by more than 2,380 distinct
authors. We followed the same experimental configurations
as previous works [33, 35] did by using the same datasets
from the same seven authors5 they used. The statistics of
each data collection are described in Table 1. Note that the
class distributions (or the number of documents per author)
are mostly balanced, and in this way we do not have to
consider the effect of skewed data.
5.2 Evaluation Methodology
To evaluate the performance, we performed multiclass
classification on each data collection using SVM with lin-
ear kernel. Specifically, we decomposed the multiclass prob-
lem into binary problems via one-versus-one method, and
paired the authors of each data collection and conducted
binary classification on these pairwise datasets. For each
dataset, we conducted 5-fold cross validation, and averaged
the accuracy as a measure of the performance. For each fold,
training data was used to mine the syntactic features and
to get a classification model while test data was only used
for evaluation purposes. For each training data, we used
another 5-fold cross validation to determine appropriate pa-
rameter values for the classification model (linear SVM). In
this way, our evaluation ensured that there is no information
leak from the test data for the classification task.
We used the number of occurrences of each feature as a
feature value for the syntactic features except k-ee subtrees
which used a new frequency measure defined in Definition 2.
For the fair comparison, we used the same classifier. In [9,
35], it is shown that SVM achieves reliable performance with
high accuracy for authorship classification and the choice of
the SVM kernel has little or no effect on the performance.
5.3 Comparison Feature Sets
To show how effectively our new feature set of k-ee sub-
trees works, we compared the authorship classification per-
formance with other syntactic features such as function words
(FW), unigram POS tags (POS), bigram POS tags (BPOS),
and rewrite rules (RR). As for function words, we took the
list of 308 function words from [23]. We used 74 POS tags
from from the stanford parser. 1,088 Bigram POS tags were
identified from the leaves of syntactic trees. Rewrite rules
and k-ee subtrees were generated by mining parsed sentences
of syntactic POS -tagged trees.
In the table 2, we show the average sizes of feature sets for
each data collection. To get the number of features of rewrite
4The three main critics of The New York Times are A. O.
Scott, Manohla Dargis, and Stephen Holden. The other
critic we used is Jeannette Catsoulis.
5The authors are Barry Schweid, Chet Currier, Dave Skid-
more, David Dishneau, Don Kendall, Martin Crutsinger,
and Rita Beamish.
Table 2: Number of features for FW, POS, RR and
k-ee feature sets
Data FW POS BPOS RR 0-ee 1-ee 2-ee
NTNews 308 74 1088 3929 119.2 257.8 453.1
Movie 308 74 1088 9029.2 306.2 575.1 1015.6
TREC 308 74 1088 8278 254.4 570.5 1107
Table 3: Accuracy Comparison on Different Number
of Authors and Various Data Collections
Data # Authors FW POS BPOS RR k-ee
NTNews
2 92.25 86.67 90.42 89.75 94.25
3 87.08 78.17 83.97 82.17 90.83
4 82.75 71.25 79.45 75.25 87.75
Movie
2 93.18 88.99 84.17 92.88 95.62
3 88.03 81.77 82.17 88.45 92.89
4 84.00 76.23 80.25 85.11 91.30
TREC
2 93.33 92.43 93.95 95.07 96.04
3 88.63 87.12 89.64 91.49 93.43
4 85.10 83.03 86.30 88.67 91.50
5 82.24 79.71 83.51 86.31 89.95
6 79.80 76.87 81.10 84.26 88.56
7 77.62 74.53 78.92 82.46 87.37
Average 86.14 81.40 84.45 86.87 91.62
rules and k-ee subtrees, we computed the average value of
the number of distinct features of 5-fold training data for
each feature set and dataset. As expected, rewrite rules
generated much larger number of features than all the other
feature sets. It is noticeable that the number of k-ee subtrees
are far less than the number of bigram POS tags and rewrite
rules, and sometimes even less than the number of function
words. For the rest of the section, we will show that our
small sized new feature set of k-ee subtrees outperforms all
the other feature sets.
5.4 Performance Evaluation
We first show accuracy comparison on various feature sets
and then analyze the effect of the parameters of k-ee subtree
approach. For the accuracy comparison with other feature
sets, we conducted binary authorship classification as well as
multiple authorship classification tasks. Table 3 shows the
accuracies of those authorship classification tasks for various
comparison feature sets and for three different data collec-
tions. By default, we used the number of embedded edge
k = 1, minimum support threshold θ = 0, the number of
bins n = 10, and minimum feature threshold δ = 3 for dis-
criminative k-ee subtree mining. In Tables 3 and 4, boldface
denotes the best result for each dataset.
5.4.1 Overall Effectiveness
Based on the accuracy results in Table 3, our new feature
set of k-ee subtrees achieved the highest performance of the
comparison feature sets. Overall, most feature sets showed
high accuracy on binary authorship classification tasks. But
when the number of authors was increased, the performance
gaps between k-ee subtree feature set and all the others be-
came larger.
It is true that bigram POS tags and rewrite rules catch
deeper insights of an author’s writing style since they are
more complex and have much larger number of features than
POS tags. But we conclude that a feature set of k-ee sub-
trees can characterize an author’s writing style even better
since (1) it allows even more complex syntactic structures
Table 4: Accuracy Comparison on binary author-
ship classification of The New York Times news ar-
ticles. Two journalists Dash and Healy from the
business department are denoted by B1 and B2, and
two journalists Grady and Kolata from the health
department are denoted by H1 and H2 respectively.
Author Pair FW POS BPOS RR k-ee
(B1,B2) 91.5 87 95 94 94
(B1,H1) 94 85 92 91 95
(B1,H2) 95.5 92.5 95 96 94
(B2,H1) 95 92.5 94.5 92.5 97.5
(B2,H2) 97 95.5 96.5 97.5 98
(H1,H2) 80.5 67.5 69.5 67.5 87
Average 92.25 86.67 90.42 89.75 94.25
than rewrite rules as features, (2) its size is much smaller
than the feature set of bigram POS tags and rewrite rules,
and (3) it achieved better accuracies. Note that the feature
set of function words reliably showed reasonable accuracies
as previous works mentioned [33, 35, 34]. It achieved better
than POS tags and sometimes even better than bigram POS
tags and rewrite rules. This is because function words have
two different aspects together (syntactic and lexical) while
POS tags only have a syntactic aspect. But complex syn-
tactic structures can complement the lack of lexical aspect
of the features, since the feature sets of rewrite rules and
k-ee subtrees showed higher accuracies than function words.
On average, the feature set of k-ee subtrees improved per-
formance over the other feature sets about 8.23% (overall),
6.36% (function word), 12.56% (POS), 8.49% (bigram POS)
and 5.50% (rewrite rule).
We also performed a significance test on the feature sets
over k-ee subtrees. We used two-tailed t-test on the ac-
curacy results in Table 3, and all their t values (FW:3.18,
POS:5.02, BPOS: 4.49, RR: 2.69) indicated that the per-
formance of k-ee subtree patterns are significantly different
from (or, better than) all the others (95% confidence inter-
val, threshold:2.07).
Note that we could mine k-ee subtrees even for minimum
support θ = 0, a task rarely done in previous works because
too many patterns were generated from the mining process.
Further discussions are described in Section 6.1.
5.4.2 Problem Difficulty Analysis
As we explained in Section 5.1, the datasets of The New
York Times news articles were collected to identify the dif-
ficulty of classification problem. We assumed that the jour-
nalists from the same departments will be hard to classify
because they might use similar terms on the same topic and
genre. As expected, classification results in Table 4 show
that classifying journalists from different departments was
easier than journalists from same departments.
Note that the last row of Table 4 shows extremely worse
performance than other cases. We manually analyzed the
news articles of H1 and H2, and found that their writing
styles were quite informal using several quotations which
made it the hardest dataset. Even for this hard task, our
approach got the highest accuracy with a big gap.
5.4.3 Parameter Analysis
In Figure 5, we analyze the role of each parameter used
0.5 0.4 0.3 0.2 0.1 0.0
80
85
90
95
10
0
Minsup
A
cc
ur
ac
y 
(%
)
0−ee
1−ee
2−ee
(a) Accuracy w.r.t. the minimum
support threshold θ
4 6 8 10 12 14 16
80
85
90
95
10
0
Number of Bins
A
cc
ur
ac
y 
(%
)
0−ee
1−ee
2−ee
(b) Accuracy w.r.t. the number of
bins n
1 2 3 4 5
85
90
95
10
0
Coverage
A
cc
ur
ac
y 
(%
)
0−ee
1−ee
2−ee
(c) Accuracy w.r.t. the minimum
coverage threshold δ
0.5 0.4 0.3 0.2 0.1 0.0
0
20
00
40
00
60
00
80
00
10
00
0
12
00
0
Minsup
R
un
ni
ng
 T
im
e 
(s
ec
)
0−ee
1−ee
2−ee
(d) Running time w.r.t. the mini-
mum support threshold θ
4 6 8 10 12 14 16
0
20
0
40
0
60
0
80
0
Number of Bins
R
un
ni
ng
 T
im
e 
(s
ec
)
0−ee
1−ee
2−ee
(e) Running time w.r.t. the number
of bins n
1 2 3 4 5
0
20
0
40
0
60
0
80
0
Coverage
R
un
ni
ng
 T
im
e 
(s
ec
)
0−ee
1−ee
2−ee
(f) Running time w.r.t. the mini-
mum coverage threshold δ
Figure 5: Performance Comparisons on Different Parameter Settings
to mine discriminative k-ee subtrees. All experiments were
conducted for binary classification of two movie critics Stephen
Holden and Jeannette Catsoulis. Similar trends could be
found from other datasets. For default values, we used
θ = 0.3, n = 10, and δ = 3. Overall, we found that 1-ee
subtree feature set showed the best performance. It could
be mined with almost in a constant time even with no min-
imum support threshold. But, when the number of embed-
ded edges increased (e.g. k = 2), k-ee feature set showed
worse accuracies because it tended to overfit to the training
data. Moreover, it took exponential time to run when mini-
mum support threshold gets smaller. It is good to know that
we do not need too complicated syntactic structures (with
a high k), because the computation would be too expensive
to make our proposed feature set useful.
There are two parameters, n and δ, which are related to
our binned information gain score. Based on Figure 5, they
did not significantly affect the running time, but somehow
affected the accuracy. However, since they achieved the peak
within a small range, it was not difficult to optimize their
values in our experiments.
6. DISCUSSION
6.1 Minimum Support Threshold
In the experiments, we could put minimum support θ to
be 0 to mine discriminative patterns regardless to any min-
imum support, which is almost impossible for generate-and-
test methodology that has to generate all patterns. We know
that mining frequent pattern is good to avoid overfitting ef-
fect, but it is hard to set a correct minimum support thresh-
old value. The authors in [6] show that features with low
support have low discriminative power. That is, the discrim-
inative patterns we mine even with no minimum support can
be considered to be frequent enough to overcome the over-
fitting problem.
6.2 Performance of NLP Tools
All current approaches using syntactic features have the
same limit of utilizing imperfect natural language processing
(NLP) tools. For example, to obtain syntactic features (in-
cluding k-ee subtrees), we rely on the performance of NLP
parsers. It would be a good follow-up work to apply our
approach to other informal datasets such as blogs and news-
groups where NLP parsers tends to show low performance.
We believe our approach will still show reasonably good per-
formance even on those messy datasets with informal word-
ing because the frequent pattern mining will not succumb to
parsing errors as shown in Table 4 for (H1, H2) author pair.
6.3 Feature Combination
In this paper, we did not consider feature combinations
since the main target of this paper is to introduce a new fea-
ture set and its effect in authorship classification. In fact,
feature combination for authorship classification itself is a
different topic with some previous work [32]. Simply apply-
ing fixed weights for different feature sets to classify various
datasets might not achieve good results because some au-
thors have their own stylistic habits that may be captured
in one feature set that is more distinctive than others [35].
7. CONCLUSION
In this paper, we proposed a new syntactic feature set of k-
ee subtrees to classify documents based on their authorship.
To mine k-ee subtrees, we developed a direct discriminative
k-ee subtree mining algorithm via a branch-and-bound ap-
proach. Our novel algorithm could perform a discriminative
score based feature selection procedure to mine discrimina-
tive patterns in one step, not iteratively. To directly mine
discriminative patterns, we theoretically derived an upper
bound of binned information gain score of the numeric fea-
ture values.
An experimental study has been performed on public real
data collections, which were purposefully chosen to contain
the same topics and genres and thus use similar terms. Our
k-ee subtree-based classification achieved the best results
compared to other feature sets. Overall, we conclude that
k-ee subtrees are meaningful features for authorship clas-
sification that achieved high accuracy across various data
collections.
8. REFERENCES
[1] S. Argamon and S. Levitan. Measuring the usefulness of
function words for authorship attribution. In ACH/ALLC,
2005.
[2] Shlomo Argamon, Marin Šarić, and Sterling S. Stein. Style
mining of electronic messages for multiple authorship
discrimination: first results. In KDD, 2003.
[3] H. Baayen, H. van Halteren, and F. Tweedie. Outside the
cave of shadows: using syntactic annotation to enhance
authorship attribution. Literary and Linguist Computing,
11(3):121–132, 1996.
[4] Björn Bringmann and Albrecht Zimmermann. Tree2 -
decision trees for tree structured data. In PKDD, 2005.
[5] Steven Burrows, Alexandra L. Uitdenbogerd, and Andrew
Turpin. Application of information retrieval techniques for
source code authorship attribution. In DASFAA, 2009.
[6] Hong Cheng, Xifeng Yan, Jiawei Han, and Chih-Wei Hsu.
Discriminative frequent pattern analysis for effective
classification. In ICDE, 2007.
[7] Hong Cheng, Xifeng Yan, Jiawei Han, and Philip S. Yu.
Direct discriminative pattern mining for effective
classification. In ICDE, 2008.
[8] O. de Vel, A. Anderson, M. Corney, and G. Mohay. Mining
e-mail content for author identification forensics. SIGMOD
Record, 30(4):55–64, 2001.
[9] Joachim Diederich, Jörg Kindermann, Edda Leopold, and
Gerhard Paass. Authorship attribution with support vector
machines. Applied Intelligence, 19(1-2):109–123, 2003.
[10] Wei Fan, Kun Zhang, Hong Cheng, Jing Gao, Xifeng Yan,
Jiawei Han, Philip Yu, and Olivier Verscheure. Direct
mining of discriminative and essential frequent patterns via
model-based search tree. In KDD, 2008.
[11] Michael Gamon. Linguistic correlates of style: authorship
classification with deep linguistic analysis features. In
COLING, 2004.
[12] Antonio Miranda Garćıa and Javier Calle Mart́ın. Function
words in authorship attribution studies. Literary and
Linguistic Computing, 22(1):49–66, 2007.
[13] Jack Grieve. Quantitative authorship attribution: An
evaluation of techniques. Literary and Linguistic
Computing, 22(3):251–270, 2007.
[14] Donna Harman. Overview of the second text retrieval
conference (trec-2). Information Processing &
Management, 31(3):271–289, 1995.
[15] Graeme Hirst and Ol’ga Feiguina. Bigrams of syntactic
labels for authorship discrimination of short texts. Literary
and Linguistic Computing, 22(4):405–417, 2007.
[16] D. L. Hoover. Statistical stylistics and authorship
attribution: an empirical investigation. Literary and
Linguistic Computing, 16(4):421–444, 2001.
[17] D. L. Hoover. Another perpective on vocabulary richness.
Computers and the Humanities, 37(2):151–178, 2003.
[18] Hyungsul Kim, Sangkyum Kim, Tim Weninger, Jiawei
Han, and Tarek Abdelzaher. Ndpmine: efficiently mining
discriminative numerical features for pattern-based
classification. In ECML PKDD, 2010.
[19] Moshe Koppel, Jonathan Schler, Shlomo Argamon, and
Eran Messeri. Authorship attribution with thousands of
candidate authors. In SIGIR, 2006.
[20] David Lo, Hong Cheng, Jiawei Han, Siau-Cheng Khoo, and
Chengnian Sun. Classification of software behaviors for
failure detection: a discriminative pattern mining
approach. In KDD, 2009.
[21] Kim Luyckx and Walter Daelemans. Authorship
attribution and verification with many authors and limited
data. In COLING, 2008.
[22] T. C. Mendenhall. The characteristic curves of
composition. Science, 11(214):237–246, 1887.
[23] Roger Mitton. Spelling checkers,spelling correctors and the
misspellings of poor spellers. Information Processing and
Management, 23(5):495–505, 1987.
[24] Frederick Mosteller and David L. Wallace. Inference &
Disputed Authorship: The Federalist. Addison Wesley,
1964.
[25] Siegfried Nijssen, Tias Guns, and Luc De Raedt.
Correlated itemset mining in roc space: a constraint
programming approach. In KDD, 2009.
[26] Jian Pei, Jiawei Han, Behzad Mortazavi-asl, Helen Pinto,
Qiming Chen, Umeshwar Dayal, and Mei chun Hsu.
Prefixspan: Mining sequential patterns efficiently by
prefix-projected pattern growth. In ICDE, 2001.
[27] Conrad Sanderson and Simon Guenter. Short text
authorship attribution via sequence kernels, markov chains
and author unmasking: an investigation. In EMNLP, 2006.
[28] Efstathios Stamatatos. A survey of modern authorship
attribution methods. Journal of the American Society for
Information Science and Technology, 60(3):538–556, 2009.
[29] Xifeng Yan, Hong Cheng, Jiawei Han, and Philip S. Yu.
Mining significant graph patterns by leap search. In
SIGMOD, 2008.
[30] Mohammed J. Zaki. Efficiently mining frequent trees in a
forest. In KDD, 2002.
[31] Mohammed J. Zaki and Charu C. Aggarwal. Xrules: an
effective structural classifier for xml data. In KDD, 2003.
[32] Ying Zhao and Phil Vines. Authorship attribution via
combination of evidence. In ECIR, 2007.
[33] Ying Zhao and Justin Zobel. Effective and scalable
authorship attribution using function words. In AIRS,
2005.
[34] Ying Zhao and Justin Zobel. Searching with style:
authorship attribution in classic literature. In Proceedings
of the thirtieth Australasian conference on Computer
science, 2007.
[35] Ying Zhao, Justin Zobel, and Phil Vines. Using relative
entropy for authorship attribution. In AIRS, 2006.
[36] Rong Zheng, Jiexun Li, Hsinchun Chen, and Zan Huang. A
framework for authorship identification of online messages:
Writing-style features and classification techniques. Journal
of the American Society for Information Science and
Technology, 57(3):378–393, 2006.
[37] Albrecht Zimmermann and Bjorn Bringmann. Ctc —
correlating tree patterns for classification. In ICDM, 2005.
[38] Lei Zou, Yansheng Lu, Huaming Zhang, Rong Hu, and
Chong Zhou. Mining frequent induced subtrees by
prefix-tree-projected pattern growth. In WAIMW, 2006.
