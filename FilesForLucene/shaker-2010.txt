Authorship Attribution in Arabic using a Hybrid of Evolutionary Search and 
Linear Discriminant Analysis 
 
 
Kareem Shaker and David Corne 
School of Mathematical and Computer Sciences, Heriot-Watt University 
Edinburgh, EH14 4AS, UK 
ks113@hw.ac.uk, d.w.corne@hw.ac.uk  
 
 
Abstract 
 
Authorship Attribution is the problem of 
determining the authorship of one or more texts. 
Applications include disputed authorship, or deciding 
which of a collection of pieces of text were by the same 
author. A popular and successful approach is to 
characterize a specific author in terms of the usage 
pattern of function words. These are common words 
that are unrelated to subject matter, and tend to be 
used in specific ways by different authors. In English, a 
well-known collection of 70 function words is often 
used for this purpose. Previously, using a hybrid of 
evolutionary search and linear-discriminant analysis 
(LDA), we have shown excellent performance in 
authorship attribution in English based on a function 
word approach.  Here, for the first time, we propose 
and test a set of Arabic function words for use in 
Arabic authorship attribution. Tests indicate that the 
chosen collection forms an effective basis for 
authorship attribution in Arabic.  
  
 
1. Introduction 
 
The Authorship Attribution problem is the task of 
determining the authorship of a given piece of text. In 
cases of disputed authorship, two (or maybe more) 
distinct individuals may claim authorship, and there are 
several historical examples of such conflicting 
authorship claims. For example, two well-known cases 
of disputed texts in English include the disputed 
Federalist papers [1] and the 15th Book of Oz [2].   
A wide variety of methods have been researched for 
authorship attribution (e.g. see [3] for a survey). The 
main issue of interest is how to represent an author’s 
‘fingerprint’, which overlaps almost completely with 
the issue of how to encode a piece of text as a feature 
vector. A subsidiary issue is the choice of machine 
learning method that will then be used to produce 
classifiers, that will in turn attempt to predict 
authorship for disputed stretches of text. As yet there is 
no clear convergence on any particular encoding or 
machine learning approaches, but a certain approach to 
the encoding of text is particularly popular and 
successful; this relates to the use of function words.  
 
Table I: Mosteller and Wallace [1] function words. 
 
a all also an and 
any are as at be 
been but by can do 
down even every  for from 
had has have her his 
if in into is it 
its may more must my 
no not now of on 
one only or our shall 
should so some such than 
that the their then there 
thing this to up upon 
was were what when which 
who will with would your 
 
The use of so-called function words for authorship 
attribution was introduced by Mosteller and Wallace 
[1]. The idea is that an author’s style can be 
characterised in terms of the frequencies with which 
that auhor uses each of a relatively small number of 
specific words. These are ‘function words’ in the sense 
that their use should be independent of the content or 
subject matter of any given text. E.g. if a writer writes 
one essay about cars, and another essay about flowers, 
these two essays will show quite different overall 
distributions of words, however when only the 
distributions of the function words are considered, we 
might expect no significant differences for these two 
essays, given that they were written by the same 
author. However, the hypothesis behind function words 
is that there may be significant differences in the 
function word usage between different authors. This 
hypothesis has been borne out in several studies [4]. 
The primary list of 70 function words used by 
Mosteller and Wallace [1] is provided in Table I. 
Typically, given an authorship attribution or related 
task, researchers will choose a set of function words, 
and construct datasets consisting of frequency vectors 
of function word usage, for each of several sections of 
texts with known authorship. A statistical and/or a 
machine learning method is then applied to these data, 
yielding a classifier. The classifier is then applied to 
test data, which, in a real case of disputed authorship, 
will be function word frequency vectors associated 
with the disputed text(s). The familiar range of 
classification methods have been attempted, including 
neural networks [5], support vector machines [6], and 
various statistical and probabilistic approaches [7, 8, 
9], including linear discriminant analysis [17, 19] and 
evolutionary search [11, 12, 13, 17].  
In recent work [17] we explored a hybrid of 
evolutionary search with linear discriminant analysis 
for authorship attribution in English, where the 
emphasis was on attempting to find minimal stylistic 
fingerprints (i.e. a small set of function words) that 
were sufficient for the cases studied.  In that work, we 
evolved feature subsets for classification by linear 
discriminant analysis (LDA), using the area under the 
ROC-curve (Receiver Operator Characteristic) as our 
fitness measure following the training of the classifier. 
This hybrid EA/LDA approach, which we use here, 
involves steps to ensure good generalisation 
performance in the parameterisation of the LDA, and 
found excellent results for the celebrated disputed 
authorship (in English) cases that were studied (the 
Federalist papers and the Book of Oz). The approach 
was particularly good at finding minimal subsets of 
English function words that could support accurate 
classification; this is of particular interest in the general 
study of stylometry [10]. However in this paper we are 
only concerned with predictive accuracy. 
Finally, we note that there has been very little 
study of function words in alternative languages, and 
certainly no studies can be found that attempt to posit 
and test function words for authorship attribution in 
Arabic. In this paper we introduce and test function 
words in Arabic, motivated in part by a number of 
disputed authorship scenarios in the Arabic religious 
literature (although it is proving hard work to obtain 
the associated texts in electronic form). There are 
clearly other applications for an Arabic function word 
set, including (as with any language) questions of 
stylistic analysis, plagiarism investigations, and other 
investigations.   
The remainder is set out as follows. In section 2 we 
provide further background on Authorship Attribution 
and function words, while in section 3 we expand on 
our hybrid EA/LDA classifier. Section 4 describes our 
dataset of Arabic novels, and section 5 reports 
experiments and results that refined and tested sets of 
Arabic function words. We summarise and discuss in 
section 6. 
 
 
2. Background and Related Work  
  
Authorship attribution studies began in 1887, when 
Mendenhall [14] reported using word-length 
distributions to study certain of the works of John 
Stuart Mill, comparing them to work by others on the 
same topic. Mendenhall followed this up in 1901, by 
applying his method to certain works of Shakespeare 
and of Bacon [15]. Though seminal, Mendenhall’s 
work can be criticised [16] for mistakenly revealing 
differences in word-length distributions between poetry 
and prose, rather than between different author’s styles.  
      The first to examine sentence-length distribution 
(rather than word-length) was Yule [20], who 
attempted to characterise authorship in terms of, for 
example, mean and standard deviation of number of 
words per sentence. This method showed some 
success, leading to more sentence-length based studies,  
however such studies were supplanted in the 1960s by 
characterisations in terms of function words [1], and 
more generally on vocabulary distribution [21, 22], 
which measures the diversity of an author's vocabulary. 
Typically, vocabulary distribution is modelled by 
frequency distributions of the number of words 
appearing exactly r times (for example) for various r. 
The function words approach [1], in contrast, deals 
only with specific words (such as pronouns, 
conjunctions, prepositions, and so forth) that have no 
significant meaning, but are grammatically and 
syntactically important.     
       Research in function word based authorship 
attribution flourished following Mosteller and 
Wallace’s demonstration of their use for the case of the 
disputed Federalist Papers [1]. Work in this area still 
tends overwhelmingly to concern English texts, and 
focuses on the comparison of different learning 
methods and/or augmentations to a function word 
approach .  
 
3. The EA/LDA Classifier 
 
One of the main challenges for machine learning 
approaches in authorship attribution is the typically 
small size of datasets in terms of number of samples 
(frequency vectors). Methods that incorporate careful 
handling of over-fitting are therefore common, such as 
linear discriminant analysis and support vector 
machines. In this article we use the hybrid 
Evolutionary Algorithm / Linear Discriminant 
Analysis classifer (EA/LDA) described in [17], using 
the variant that evaluates fitness using the area under 
the ROC curve returned by the LDA classifier.  The 
role of the EA is to find a subset of the function words 
that are in turn used to train the LDA. The LDA works 
simply by finding a linear function of the frequency 
vectors that defines a hyperplane which separates the 
data as well as possible, minimising the ratio of within-
class variance to between-class variance. The weights 
for the discriminating hyperplane are learned by 
minimizing the cross-entropy error function.  
  In straightforward terms, the role of the LDA 
classifier is as follows. First, a subset of function 
words is supplied by the EA (i.e. a chromosome 
defines a subset of the function words). The input to 
the LDA is then the set of labelled training vectors, 
reduced in dimension (i.e. retaining only the elements 
indicated in the EA chromosome). The LDA then 
learns a weight vector, characterising a good separating 
hyperplane for the two classes (authors). The weight 
vector is then used for classification simply via 
considering its dot product with a test vector. The dot 
products are transformed between 0 and 1 by the 
logistic equation, and this value essentially represents a 
fuzzy decision (with one author associated with 0, and 
the other associated with 1). Following consideration 
of all test inputs (leave-one-out cross-validation is 
used), by considering a series of threshold values, an 
ROC curve is then constructed (equivalently, the curve 
indicating the tradeoff profile between false positives 
and true negatives). 
Further detail is given in [17]. Finally, we describe 
aspects of the Evolutionary Algorithm (EA) used. A 
simple EA is wrapped around the LDA training 
process; as indicated, the EA supplies the chromosome 
(a subset of the available function words) and the LDA 
evaluates it, supplying in the end an ROC curve 
summarizing performance on the accumulated 
validation cases during leave-one-out cross-validation. 
The EA simply uses the area under this curve (AUC) 
as the fitness value to be maximised. As in [17], the 
EA is otherwise a straightforward steady-state 
evolutionary algorithm with a population size of 5, a 
mutation (only) operator that, with equal probability, 
either deletes a random feature, changes a feature, or 
includes a new feature,   binary tournament selection, 
and replace-worst replacement, breaking ties by 
number of features (preferring fewer). In each 
generation, a parent is chosen via binary tournament 
selection, a mutant is then generated and evaluated, 
and then enters the population if it is no worse than the 
current worst. In the case of a tie between mutant and 
current worst fitness, the mutant is retained only if it 
does not contain more features than the current worst. 
Finally, the initial population contains only randomly 
chosen singleton feature vectors.   
 
4. Arabic Text Datasets 
 
To derive and test a collection of Arabic function 
words we procured a dataset of 14 books by six 
different writers. These were obtained from the website 
of the Arab Writers Union (www.amu-dam.net). The 
books ranged in size from 13,987 words to 37,567 
words, with a mean of 23,942 words. Each of these 
books (details in Table II) were downloaded and 
processed to convert them into a string of Arabic words 
without extraneous characters and spaces.   
 
5. Experiments: Refining the Arabic 
Function-Word Set 
 
The initial set of Arabic function words was based on 
creating a collection of common prepositions and 
conjunctions, mirroring the semantic structure of the 
Mosteller and Wallace set for English. This led to a 
collection of 106 Arabic words.  
We then investigated the frequencies of each 
of these 104 words over the complete collection of 14 
books. This revealed that around 40 of the words were 
particularly common among all of the books, with 
patterns of usage that (on first sight) appeared roughly 
uniform, while a further 40 of these words tended to be 
of particularly low frequency. In preliminary work not 
reported here in detail, we used the test cases (Table 
III) to evaluate two subsets of words in turn. First, a 
collection of 64 words (omitting only the most frequent 
ones), and secondly a collection of 65 words (omitting 
only the least frequent). Only the latter set was found 
to be particularly promising, and we include results 
from this collection of 65 words below. Meanwhile, 
this set (which we call AFW65) is given in Table IV, 
which gives a numeric ID, the Arabic representation, 
and (in most cases) a ‘ballpark’ translation into 
English. 
 
 
Table II: Details of the Arabic books dataset; includes 
shortened IDs for books and authors used later in 
presentations of results. 
Authors Book details and IDs 
Ibrahim 
Khalil 
 
Haris Al Maiz  
(HAM: 14,679 words 
Sodom Sebake Al Awez 
(SSAA: 2 parts, 28156 words and 29518 
words) 
Basem 
Ibrahim 
Abdo 
 
Gesr Al Mawt 
(GAM, 37567 words 
Zahra fi Al Remal 
(ZFAR: 2 parts, 23241 words and 26061 
words) 
Taleb 
Omran 
Ahzan Al Sinbad 
(AAS, 20389 words) 
AlBood Al Khamis 
(AAK, 13987 words) 
Madina Kharig Al Zaman 
(MKAZ, 14513 words) 
Al Fetiah Al Aghrar we Asfar al Kashf 
(AFAA, 19063 words) 
Mary 
Show 
Defly (DE, 24062 words) 
Awel Hob and Akheir Hob 
(AHAH: 2 parts, 18848 & 19807 words) 
Mohamed 
Youssef 
Salibi 
Al Taih (AT, 36892 words) 
Sebahaa fi Al Wahl 
(SFAW: 2 parts, 25647 & 28274 words) 
Hessen 
Abd Al 
Kareem 
 
Al Nabaa (AN: 2 Parts 29644 and 29472 
words) 
Shagaret al Toot (SAT: 2 parts, 19024 
words and 19998 words) 
  
 
At this point, some preliminary notes about 
experimental setup is in order. The common way in 
which a set of function words is employed (and which 
we do here) is to transform a section of text (a ‘chunk’) 
into a vector of n numbers in the interval [0, 1], each 
indicating the frequency of a function word as a 
proportion of the total words in that chunk. That is, if 
the chunk of text contains 1,000 words, and element i 
of this vector is 0.022, this indicates that function word 
i occurs 22 times in that chunk. To formulate an 
authorship attribution problem (or simply a simulated 
such problem) as a data mining task, a large section of 
text, such as a book, is partitioned into chunks of c 
words, for some c, and a frequency vector is built for 
each chunk. Each such frequency vector then is then 
associated with a target class, which in turn is simply 
the author of that chunk.  
 
 
Table III: Details of the test cases; in each, books from 
two authors constitute the training set, and different 
books from the same authors comprise the test set. 
Test case Train and test set details 
A Training set: Books AAK and HAM  
Test set: Books MKAZ and SSAA 
B Training set: Books AHAH and SATP1 
Test set: Books DE and ANP1 
C Training set: Books GAM and SFAWP2 
Test set: Books ZFARP1 and AT 
D Training set: Books ANP1 and AAS 
Test set: Books ANP1 and AFAA 
E Training set: Books AFAA and ZFARP2 
Test set: Books MKAZ and GAM 
 
 
  Hence, in each test case, an authorship 
dispute is simulated by supposing that we have two 
authors, Author1 and Author2, who both claim to have 
written each of Book1 and Book2. The training set 
comprises an undisputed book from each of the two 
authors, while Book1 and Book2 comprise the test set.   
An important consideration is the size of the 
chunks. A feel for this can be gained from considering 
the extremes. If very small, function word frequencies 
would be very low, and often zero, and we would 
expect that each chunk would be too small to capture 
the stylistic fingerprint of an author. If the chunk sizes 
were very large (e.g. we could transform an entire book 
into a single frequency vector), we would have too few 
samples to do reliable machine learning, and could 
expect poor generalization performance. 
Preliminary experiments were done with 
different chunk sizes, and we report here the more 
successful sizes, which were 1,000 and 2,000 words 
respectively. Table V summarises results on the five 
test cases for AFW65, for each of 1,000 and 2,000 
word chunks. Each entry in the table corresponds to the 
mean of five trial runs, each of which ran for a specific 
parameterization of the hybrid classifier (determined in 
advance from preliminary experiments, and similar to 
the configuration that achieved best results for English 
authorship attribution in [17]). The result of an 
experiment is a percentage accuracy figure, which 
indicates the percentage of chunks in the test set that 
were correctly labeled by the classifier; this figure is 
always the mean over 5 trials.  Notice that, in one 
sense, the accuracy figures understate the potential 
performance of set AFW65 for authorship attribution. 
If the authorship of a book is disputed, and the 
‘decision’ of the experiment was made on the basis of 
the author to whom most chunks were attributed, then, 
every experiment reported below would yield the 
correct result) In interpreting these results, higher 
accuracy therefore tends to indicate better reliability – 
i.e. the degree to which we might expect a correct 
attribution when only a relatively small number of 
words are available in the disputed text.    
To further refine the set, we examined the 
occurrences of each of the 65 words on AFW65 in the 
dataset, and considered the variance of their 
frequencies across the set of 2,000 word chunks from 
different authors. That is, if a function word has a low 
variance across chunks for different authors, then 
different authors tend to use that word with the same 
frequency, and it may not contribute materially to 
authorship attribution. We found 11 such low variance 
words, and composed the set AFW54 by eliminating 
them. AFW54 comprises the set shown in Table IV, 
with the following removed: 16, 18, 30, 39, 40, 45, 48, 
58, 63, 64, 65. Table V also shows the corresponding 
results on the five test cases when using AFW54. 
As mentioned previously, each trial of each 
experiment for each test case was able to accurately 
predict the authorship of each of the test books, in the 
case that we regard the authorship attribution decision 
as the majority vote of predicted authorship of a book’s 
chunks. In finer detail, the accuracy results (percentage 
of chunks with accurately predicted authorship) 
indicate the reliability of the underlying method, which 
is of particular interest when there is a need to attribute 
the authorship of a relatively small test body of text. It 
is not straightforward to compare these accuracy 
figures with other authorship attribution studies, but we 
report that they compare very favourably with 
accuracies reported, for example in [18] for Greek texts 
using a variety of methods, and in [19] for Dutch texts 
using a linear discriminate classifier. Finally, given the 
number of trial runs and case studies, we cannot 
indicate any statistically significant difference between 
function word sets AFW65 and AFW54, however each 
is  statistically superior to the original complete set of 
104 words. 
Table IV: AFW65 – 65 Arabic function words, from a 
collection of 104 candidates after removing those with 
low frequency in a collection of Arabic books 
1        2     3    4    5 	
  
In from about over to 
 6   7   8   9   10   
Till Not since no then 
11   12   	 13   14    15   
 But Or Or that 
16   17   
  18 
  19   20 	  
as if The therefore So that not 
21 	  22     23   24   25   
no What Any Not  
26   27 
  28 !
  29    "	  30 "	  
  If If  
31   32 #  33 $%  34     35 !  
Is? Oh Yes without this 
36    *	 37 +  38 *<  39 =>  40  *@	
that this Such they those 
41 	!  42 	!  43 #	!  44 "  45     
whom which Whose he them 
46    47 Q%  48   %  49 %  50 X%  
she You you are I we 
51 \!  52 ^  53   54 _  55   
now between Here there been 
56 `^	  57 {|}  58 ~  59 !  60 !	  
not became Keep what why 
61 ^  62   63    # 64   65   
How how many Where when whatever 
 
     
 
Table V: Summary results of experiments on the five 
test cases using function word set AFW65 (Table IV). 
 
Test case 1,000 word 
chunks 
2,000 word 
chunks 
AFW65 AFW54 AFW65 AFW54 
A 76.14% 78.51% 87.74% 93.82% 
B 90.12% 84.34% 89.50% 86.27% 
C 80.19% 81.82% 82.13% 82.67% 
D 86.44% 85.05% 84.57% 85.21% 
E 89.83% 89.53% 88.38% 90.21% 
 
6.  Summary, Discussion and Conclusion 
 
We introduced the use of Arabic function words for 
use in Arabic authorship attribution and related studies. 
Our starting point for a set of Arabic function words 
was based on a collection of 104 words reflecting the 
semantics of the English function words from 
Mosteller & Wallace [1]. Following  experiments and 
analyses, using a dataset of Arabic novels, we refined 
this to two sets of words AFW65 (Table IV), and 
AFW54 (Table IV, with 11 words omitted as detailed 
in section 5).  Each of AFW65 and AFW54 was used 
as the basis to transform a number of Arabic texts into 
frequency vectors, and the ‘performance’ of these word 
sets was assessed by experiments that used a hybrid of 
an EA and LDA to produce a classifier, and then tested 
that classifier on unseen data. The resulting 
performance was clearly in line with results of 
authorship attribution studies in other languages. Set 
AFW54 is arguably a better choice, however we cannot 
make that claim with any statistical significance. For 
the cases considered here, only limited investigation is 
reported for assessing the appropriate ‘chunk’ size. For 
real applications this will likely depend on several 
factors, but we have determined (partly from 
preliminary experiments) that at least around 1,000-
word chunks are necessary to obtain adequate 
characterization of function word usage for Arabic 
authors. 
Arguably, this work has confirmed that the concept 
of function words translates suitably well into the 
Arabic language. I.e. different authors use this set of 
words in sufficiently different ways, enabling us to 
capture the stylistic fingerprints of individual authors 
and use these to distinguish between authors.  
 
References 
 
[1] Mosteller, F., Wallace, D. (1964) Inference and Disputed 
Authorship: The Federalist, Reading: Addison-Wesley.  
[2] Binongo, J. (2003) Who Wrote the 15th Book of Oz? An 
Application of Multivariate Analysis to Authorship 
Attribution, Chance, 16(2):9—17. 
[3] Juola, P., Sofko, J., Brennan, P. (2006). A Prototype for 
Authorship Attribution Studies. Literary and Linguistic 
Computing 21:169-178 
[4] Argamon, S.,  Levitan, S. (2005). Measuring the 
usefulness of Function Words for Authorship 
Attribution. Proc. Joint Conf. Ass.Comp.Hum.& Lit. 
Ling. Comp. 
[5] Kjell, B. (1994). Authorship Determination Using Letter-
pair Frequency Features with Neural Network 
Classifiers. Literary & Linguistic Comp, 9, 119 – 124 
[6]  Fung, G., Olvi, M. (2003) The Disputed Federalist 
Papers: SVM Feature Selection via Concave 
Minimization (2003). 
[7] Brainerd, B. (1975). Statistical anlaysis of Lexical data 
using Chi-squared and related distributions. Computers 
and the Humanities, 9, 161 – 178 
[8] Burrows, J. (1987). Word Patterns and Story Shapes: The 
Statistical Analysis of Narrative Style. Literary and 
Linguistic Computing, 2, 61 -67. 
[9] Doležel, L., Bailey, R. (Eds.). (1969). Statistics and Style. 
New York: Elsevier. 
[10] Holmes, D. (1998) The Evolution of Stylometry in 
Humanities Scholarship, Literary & Linguistic Comp, 
13(3):111-117 
[11] Holmes, D., Forsyth, R. (1995) The Federalist 
Revisited: New Directions in Authorship Attribution, 
Literary & Linguistic Computing, 10(2):111-127 
[12] Li, J., Zheng, R., Chen, H. (2006) From fingerprint to 
writeprint, Communications of the ACM, 49(4):76—82. 
[13] Efimovich, S., Gennadyevich, S. (2003) Automatic 
search of indicators of text authorship, Proc. Korea-
Russia International Symposium, 185—188. 
[14] Mendenhall, T.C. (1887) The Characteristic Curves of 
Composition, Science, IX, 237-249. 
[15] Mendenhall, T.C. (1901) A mechanical solution to a 
literary problem, Pop. Sci. Monthly, 60: 97—105. 
[16] Williams, C.B. (1975) Mendenhall’s studies of word-
length distribution in the works of Shakespeare and 
Bacon, Biometrika, 62(1): 207—212.  
[17] Shaker, K., Corne, D., Everson, R. (2007) Investigating 
hybrids of evolutionary search and linear discriminant 
analysis for authorship attribution, Proc. 2007 IEEE 
Congress on Evol. Computation, pp. 2071—2077. 
[18] Stamatatos, E., Fakotakis, N., Kokkinakis, G. (2001) 
Computer-based authorship attribution without lexical 
measures, Computers & the Humanities, 35, 193—214. 
[19] H. Baayen, H.van Halteren, A. Neiht, F. Tweedie (2002) 
An experiment in authorship attribution, in Proc. 6th 
Int’l Conf. on the Statistical Analysis of Textual Data, 
(JADT). 
[20] Yule, G, (1939) On sentence-length as a statistical 
characteristic of style in prose, ... Biometrika, 30: 363—
390. 
[21] Morton, A.Q. (1978) Literary Detection, New York: 
Scribners. 
[22] Sichel, H.S. (1975) On a distribution law for word 
frequencies, J. of the American Statistical Association, 
70: 542—547. 
 
   
 
