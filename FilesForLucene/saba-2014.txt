ORIGINAL ARTICLE
Annotated comparisons of proposed preprocessing techniques
for script recognition
Tanzila Saba • Amjad Rehman • Ayman Altameem •
Mueen Uddin
Received: 14 March 2013 / Accepted: 24 March 2014 / Published online: 11 July 2014
 Springer-Verlag London 2014
Abstract Offline cursive script recognition and their
associated issues are still fresh despite of last few decades’
research. This paper presents an annotated comparison of
proposed and recently published preprocessing techniques
with reported work in the offline cursive script recognition.
Normally, in the offline script analysis, the input is a paper
image or a word or a digit and the desired output is ASCII
text. This task involves several preprocessing steps, and
some of them are quite hard such as line removal from text,
skew removal, reference line detection (lower/upper base-
lines), slant removal, scaling, noise elimination, contour
smoothing and skeleton. Moreover, subsequent stage of
segmentation (if any) and recognition is also highly depen-
dent on these preprocessing techniques. This paper presents
an analysis and annotated comparison of latest preprocess-
ing techniques proposed by authors with those reported in
the literature on IAM/CEDAR benchmark databases.
Finally, future work and persist problems are highlighted.
Keywords Script preprocessing  Line removal 
Reference line detection  Slant removal and skew
correction  Script recognition
1 Introduction
Indeed handwriting is non-natural means of communication
among civilized human. It is used both for personal (letters,
notes, addresses on envelopes, etc.), official communica-
tions (bank checks, tax form, postal services, admission
forms, etc.) and for communications written to ourselves
(reminders, lists, diaries, etc.) [58]. Extensive research has
been carried out in terms of technical research papers and
reports by various researchers around the globe. Despite the
intensive research efforts of decades, still there are no
commercial solutions to deal with totally unconstrained
cursive script recognition on static surface such as bank
checks, postal envelopes and paper-based forms [30]. The
literature is replete with promising recognition results by the
research community, and research in this area is continually
mounting toward its maturity. Consequently, a number of
research results are published, addressing different prob-
lems associated with the process of offline cursive script
recognition such as character recognition, character seg-
mentation, word segmentation and word recognition [1, 4–6,
8, 9, 12, 16, 19, 26–28, 31, 32, 39, 44–47, 50, 59–61, 65, 68,
76]. Additionally, several survey papers are published to
provide an update development in this domain [43, 57, 80].
Moreover, international conferences on frontiers in hand-
writing recognition and international journal on document
analysis and recognition are continually updating with
T. Saba
College of Computer and Information Sciences, Prince Sultan
University, Riyadh, KSA
A. Rehman
Faculty of Computing, Universiti Teknologi Malaysia,
Johor Bahru, Malaysia
A. Rehman (&)
MIS Department CBA, Salman bin Abdul Aziz University KSA,
165, Alkharj 11942, KSA
e-mail: ar.khan@sau.edu.sa
A. Altameem
College of Applied Studies and Community Services, King Saud
University, Riyadh, KSA
M. Uddin
Kulliah of Information and Communication Technology,
International Islamic University Malaysia, Kuala Lumpur,
Malaysia
e-mail: mueenmalik9516@gmail.com
123
Neural Comput & Applic (2014) 25:1337–1347
DOI 10.1007/s00521-014-1618-9
new findings. Although some researchers presented very
encouraging results for isolated alphabets and digits recog-
nition, however, the same accuracy rate is not attainable in
cursive handwriting recognition. It is mainly due to the
inherited problems in cursive handwriting such as touching,
overlapped, broken, incomplete and ambiguous characters
in cursive handwriting which is the main cause of segmen-
tation errors as shown in Fig. 1.
2 Preprocessing
Preprocessing is mandatory to remove noise and unwanted
variations in script word pattern [52, 63]. The preprocess-
ing could be divided into individual tasks such as thres-
holding, slant, skew detection and removal, baseline
detection (upper and lower), smoothing and resizing. Fol-
lowing normalization of script words, accuracy of sub-
sequent segmentation and classification is increased [7].
The main goal of such preprocessing tasks is to reduce the
huge variability of handwriting [53] and to make the
writing style as uniform possible [56]. In this regard,
Watanabe et al. [81] conducted comparative experiments
showing that normalization minimizes the error of recog-
nition, as input of Cirsive Word Recognition (CWR) sys-
tem supposed to be written horizontally and descenders
aligned along the vertical direction. Nevertheless, in real
world, its rules are rarely respected [71].
Hence, in handwriting segmentation/recognition sys-
tems, a preprocessing stage is normally included. Literature
is replete with preprocessing techniques and encouraging
results that include the following:
• Line removal from text
• Skew removal
• Reference line detection (lower/upper baselines)
• Slant estimation and correction
• Scaling and noise elimination
• Contour smoothing
• Skeleton
2.1 Line removal from printed text and script
‘‘In document images, printed lines are frequently used
overlapping with hand written elements, especially in case
of signatures. Basically, these lines are used to align the
writer on the horizontal axis. Typical examples of such
images are bank cheque, receipts and payment slips.
However, these lines create critical problems for the OCR
system and therefore are required to be detected and
removed properly [63]. Several approaches have been
proposed for underline removal in the literature. Most of
them detached underline from binarized image by the
dilation and erosion operators of the mathematical mor-
phology [83]. Dilation was applied until all the lines longer
than a fixed threshold are removed from the underline
region. On the other hand, this operator shattered the
characters, and therefore, it became difficult to recognize.
Hence, erosion was applied to recover the lost parts of the
characters. However, broken characters could not restore
correctly [30]. Govindaraju and Srihari [29] achieved
underline removal by using the ‘‘good continuity crite-
rion.’’ The criterion first detects the smooth strokes in the
image and then identifies the spine of the image as the
smooth stroke with maximum length and finally is
removed. However, this approach worked out on thinned
images, and therefore, it requires a preliminary time-con-
suming process. Secondly, global properties of textual
word shapes and those of interfering strokes were used to
separate them. Yu and Jain [84] have proposed a method
for line removal and character restoration using block
adjacency graph representation of the input binary image.
The horizontal form lines were located by finding long
straight lines based on the block adjacency graph. Form
line separation and character reconstruction were also
implemented from this graph.
Yoo et al. [83] have classified the various types of
junction points at the point of contact or crossing over of
the characters and the line. After line removal, the junction
points are detected and restored based on their classifica-
tion type. Koerich and Ling [42] have detected and
removed the lines using horizontal projection profile
(HPP). The removed regions are rectified by checking the
neighbors for every pixel that could be fitted into the erased
line. Based on whether the neighboring pixels satisfy cer-
tain condition or not, they decide to leave the pixel on or
off.
Blumenstein et al. [7] introduced new preprocessing
techniques for underline removal and restoration based on
horizontal black pixel runs. However, it is supposed that
stroke thickness is the same as thickness of the underlines
occurred in the word. However, this assumption is not true
in all cases particularly for printed documents/forms.
Finally, authors acknowledged that underline removal and
restoration did not perform well on some of the more
erratic underlines that were present in some word images.
Therefore, remainders of undetected underlines were
removed manually to facilitate further processing.
Fig. 1 Touched, overlapped, broken characters in cursive script
samples from IAM benchmark database [68]
1338 Neural Comput & Applic (2014) 25:1337–1347
123
In some algorithms such as proposed by Wang et al.
[82], broken characters are restored. If result that character
recognizer is performed with the restored characters is
wrong, restored characters are sent back to the restoration
algorithm stage. In such methods, the processing time was
increased because it has feedback paths. In addition,
characters are sometimes recognized incorrectly such as
‘‘h’’ and ‘‘b.’’
Bai and Huo [3] used strategies of connected component
and bottom edge analysis to detect underline in printed
text. Prior to removal of detected underline, an OCR engine
is used to recognize and verify the input text line. However,
the approach dealt with underline in printed text and failed
in script line removal.
Recently, Arvind et al. [2] detect multiple printed lines
with varying thickness present in the word image using
horizontal projection profile. Restoration of the smashed
characters is performed by using Bresenham line drawing
algorithm [25]. However, technique cannot deal with res-
toration of printed characters and skewed images. To
conclude, common problems with techniques developed so
far are as follows:
1. Computationally expensive as consists of two stages:
line removal and restoration of smashed characters.
2. Deal with underline removal in printed text rather line
removal.
3. Cannot deal with line removal in script writing.
4. Cannot deal with skewed line removal in script
writing’’ [61, 62].
To overcome existing problems of various types of line
removal in printed and script text, recently, Rehman et al.
[62] have proposed a generic approach to line removal.
Prior to detected line removal, strokes were preserved to
avoid restoration stage. Additionally, the technique was
quite generic that could deal with skewed, dashed and
straight line removal in printed and script writing. Figure 2
presents some samples of printed and script writing over-
lapped with different forms of lines, while results are
shown in Fig. 3 and a comparison is presented in Table 1.
2.2 Reference line detection
‘‘Reference line detection in script writing is one of the
important preprocessing techniques. There are four refer-
ence lines: upper line, upper baseline, lower baseline and
lower lines shown in Fig. 4. Reference lines are employed
by research community for various objectives such as
height of word, core region detection, position of ascenders
and descenders, feature extraction for character segmen-
tation/recognition. The crucial part in this process is the
detection of upper baseline and lower baseline of the word
image, commonly known as core region. The accurate
estimation of core region is of worth importance in cursive
handwriting segmentation/recognition performance [49]. It
determines the relative character height which is essential,
for example, to discriminate characters such as ‘‘e’’ and
‘‘I.’’ However, few strokes in an image exist either above
or below core region termed as ascenders and descenders,
Fig. 2 Line embedded in the script/text
Fig. 3 Line identification and removal
Table 1 Comparison (% error) in the state of art for line removal in
words
Line removal % Error
Morphological shape analysis [83] 3
Mathematical morphology [21] 3
Foreground pixels analysis [7] 2.84
Proposed approach 1.75
Fig. 4 Four reference lines and core region [74]
Neural Comput & Applic (2014) 25:1337–1347 1339
123
respectively [74]. Consequently, core region of a script
image is an area that does not contain ascenders and
descenders and occupied by upper baseline and baseline
[11] such as e, i, v and u as shown in Fig. 4.
Core region served for variety of operations such as
slant/skew removal, feature extraction for Latin and Arabic
character segmentation and recognition [7, 10, 14, 18, 20,
23, 49, 53, 79].
First, historically first, Bozinovic and Srihari [10]
detected reference lines based on horizontal density histo-
gram commonly known as BSM. The core zone is esti-
mated with the help of horizontal densities using horizontal
density histogram [51]. Few more techniques are proposed
in Cote et al. [20] and Vinciarelli and Luettin [80]. Vinc-
iarelli and Luettin [80] use the Otsu method to find a
threshold distinguishing between core region lines (above
the threshold) and other lines [7].
Moreover, Rehman et al. [63] have proposed a new
approach based on enhanced horizontal density histogram
embedded with quantile features to detect core region of
deskewed word image. Initially, middle line of the image is
detected by constructing horizontal density histogram. The
peak of horizontal histogram (HH) is the middle line. A
threshold is calculated using quantile on the sorted data of
HH. In the HH from first to middle line, the line with count
[number of pixel greater or equal to threshold (third
quantile) is detected as upper baseline. Similarly, from last
[row] to middle line, the line greater than or equal to
threshold is the baseline. The proposed technique is slightly
modified, but it demonstrates to be more effective than
Bozinovic and Srihari [10] even in the presence of long
horizontal strokes, erratic characters and irregular charac-
ters as shown in Fig. 5’’ [60, 63]. Table 2 presents detailed
comparison of proposed line removal results in script/text
line in the state of art.
2.3 Skew estimation and correction
Skew estimation is mandatory preprocessing stage in
almost all types of script segmentation and recognition
techniques [71]. Furthermore, it improves performance of
the classification system [26, 27]. Skew correction is con-
cerned with to first detect either script word is at zero slope
with the x-axis or not. If not, then it implies that slope
exists as shown in Fig. 6.
The slope removal approaches tries to correct this angle
by obtaining a text aligned with the horizontal direction.
However, for skew estimation, the crucial step is to find
skew angle correctly.
In the literature, most of the skew correction techniques
are based on projection profile (horizontal/vertical). How-
ever, core zone detection is prerequisite for skew estima-
tion [80]. Caesar et al. [14] fit a straight line through
extreme values in the vertical direction to detect reference
lines for skew correction. Some more examples of tech-
niques for slope correction are described in Senior [73] and
Brown and Ganapathy [11]. Senior and Robinson [74] and
Morita et al. [51] obtain a pseudo-convex hull image based
on morphological operation to detect minima points, and
reference lines are fitted through those points.
Cote et al. [20] computed entropy for several histo-
grams based on Y projections. The histogram with the
lowest entropy determined the slope angle. Likewise,
Kavallieratou et al. [34] employed Wigner–Ville distri-
bution to calculate several horizontal projection histo-
grams. The slope angle was selected by Wigner–Ville
distribution with the maximal intensity. However, high
computational cost was an issue of such approaches. Cai
and Liu [15] rotated the image for each angle in an
interval, and finally, image was thought desloped, if the
rotated image created the highest peak of the first deriv-
ative of the horizontal density histogram. Vinciarelli and
Luettin [80] proposed new techniques for both slant and
Fig. 5 Core region detection embedded with quantile feature [63]
Table 2 Comparison of proposed line removal results in script/text
line
Line in printed text (342)
Underline (127) Overlap line (173) Broken line (42)
Line detected 127 (100 %) 170 (98.3 %) 41 (97.6 %)
Correctly removed 127 (100 %) 162 (95.4 %) 37 (90.2 %)
Line in script writing (226)
Underline (73) Overlap line (119) Broken line (34)
Line detected 73 (100 %) 113 (94.9 %) 31 (91.17 %)
Correctly removed 73 (100 %) 97 (85.8 %) 29 (93.54 %)
Fig. 6 Slope and slant [26]
1340 Neural Comput & Applic (2014) 25:1337–1347
123
slope angle estimation without any heuristics and manual
parameters. Indeed, it reduced efforts to estimate excellent
parameters. However, the approach was based on a cost
function which measures slant absence across the word
image. However, it is computationally heavy and high
memory demanding [22]. Dong et al. [22] presented a
novel approach for script word skew correction using
random transform which was equally suitable for long and
short length while the previous work failed. Additionally,
it is computationally more efficient.
Recently, Gatos et al. [26] introduced skew correction
technique based on horizontal projection. Accordingly, the
skewed word was bisected, and horizontal projection for
each part was calculated (see Fig. 7). Due to word skew,
the distribution of the left and the right horizontal word
projections exhibits a vertical offset. The skew angle was
calculated by the following formula.
h ¼ tan1 yR1 þ yR2  yL1  yL2
xmax
 
where xmax is the width of the image.
Indeed, projection profile-based approaches proved to be
effective and accurate. However, projection profiles are
strictly based on straight lines (reference lines). If the
image is noised and contained more ascenders and
descenders characters, then PP-based approaches cannot
bring fruitful results for skew detection and correction [53].
In this regard, Nicchiotti and Scagliola [53] employed
generalized projections (GP) extension of projection profile
(PP) for skew detection and removal but made the whole
process computational heavy.
Blumenstein et al. [7] introduced new preprocessing
technique for skew removal by dividing the word image
into two equal parts (see Fig. 8). Skew angle was detected
by drawing a line between the centers of each part.
Furthermore, skew detection was achieved through elimi-
nation of word ascenders and descenders information that
increase computational burden.
Recently, Rehman et al. [63] proposed a new fast
approach to detect skew angle based on structure features
of the handwritten word. The approach can handle positive
and negative skew efficiently with minimum processing.
The proposed approach initially detects upper, lower points
and connects them by a straight line. The slope of straight
line is the skew angle (see Fig. 9).
To conclude, in most of the literature reviewed, pre-
processing techniques are described as part of an overall
system for handwriting recognition [40, 48, 75], and
therefore, it is really hard to compare the results. Few
results of the proposed technique of the authors are pre-
sented in Fig. 10. Additionally, Table 3 presents detailed
Fig. 7 Horizontal projection of left and right part of the word [26]
Fig. 8 Skew detection by dividing word into two segments [7]
Fig. 9 Skew angle estimation based on extreme point’s detection
[63]
Fig. 10 Skew correction [61]
Table 3 Comparison of results (% error) for skew removal
Skew removal % Error
Generalized projection [53] 2.3
Projection profile [46] 0.91
Mathematical formulation [7] 3.88
Principal component analysis [72] 1.48
Connected component analysis [55] 0.50
Peak and valley analysis [72] 0.91
Proposed approach 1.00
Neural Comput & Applic (2014) 25:1337–1347 1341
123
comparison of results (% error) for skew removal in the
state of art.
2.4 Slant estimation and correction
‘‘Slant estimation and correction is a mandatory prepro-
cessing step as script words are usually characterized by
slanted characters and therefore requires to be normalized
[66]. Slant is the clockwise or anticlockwise angle
between the vertical direction and the vertical text strokes
[56]. In an ideal model of handwriting, strokes are sup-
posed to be vertical. However, detection of correct slant
angle is a crucial step. Handwritten text is usually char-
acterized by slanted characters and therefore requires to
be normalized. The slant is the clockwise or anticlockwise
angle between the vertical direction and the vertical text
strokes [56].
Literature is full of slant angle detection and correction
approaches for script word normalization. These approa-
ches either perform either local or global slant correction.
Initially, Bozinovic and Srihari [10] calculated slant
angle with the help of vertical strokes and average angle
of these strokes to rotate script word for slant correction.
This idea was followed by many researchers such as Kim
and Govindaraju [41], Senior and Robinson [74], Vinc-
iarelli and Luettin [80] and Paster et al. [56]. For each
profile, vertical projection is estimated and the profile with
highest variation is considered as deslanted image. This
method is sufficiently fast but depends heavily on heu-
ristics so not highly accurate. Additionally, such approa-
ches require the detection of the edges of the characters
and its accuracy that depends on the included characters in
the word [85].
In this regard, Kavallieratou et al. [34–37] proposed a
slant correction technique based on hybrid approach of
Wigner–Ville distribution and projection profile technique.
Wigner–Ville distribution is used to calculate degree of
variation through the different vertical projection profiles.
Finally, the hybrid approach was presented in a complete
system for script recognition [38]. Cote et al. [20] com-
puted several histograms for different y projections. Then
the entropy is calculated for each of them. The histogram
with the lowest entropy will determine the slant angle.
Likewise, few more approaches are detailed in [15, 24].
Additionally, an average slant angle is calculated using
structure features of characters composing the word;
however, it is invalid to all characters.
Last, approaches distinguish from all predecessors to
correct non-uniform slant. Uchida et al. [78] and Taira
et al. [77] tackled the problem of non-uniform slant
with dynamic programming techniques. Dong et al. [22]
presented a new fast and robust technique for word slant
correction based on random transform. However, it is
computationally more efficient’’ [60, 63]. Common prob-
lems in the existing slant angle estimation approaches are
as follows:
1. Computationally heavy and therefore slow.
2. Heavily depend on heuristics and therefore not robust.
3. Compute an average slant angle that is not suitable for
all characters in the word.
Recently, Rehman et al. [63] ‘‘proposed a new technique
that targets uniform slant angle estimation based on
structural features analysis of the first character. This not
only reduces complexity but also yields good results.
Structural features, left most and the top pixel of the first
character in slanted word are detected and connected by a
straight line to estimate slant angle (see Fig. 11). It is
mention worthy that technique has no negative impact to
non-slanted words and is equally suitable for the slanted
characters slope either from right to left or vice versa’’.
Few results of the new proposed approach for slant cor-
rection are presented in Fig. 12.
2.5 Scaling
Scaling may sometimes be necessary to produce charac-
ters/words of relative size. Burges et al. [13] used a neural
network for the segmentation stage of their system. The
input to ANN was the core region of the word. Since ANN
takes fixed size of the input (core region), therefore, all
words scaled to fixed size to make all cores to uniform
height [26, 33]. However, this preprocessing technique is
out of scope of this research.
Fig. 11 Clockwise and anticlockwise slant angle estimation [63]
Fig. 12 Slant correction [63]
1342 Neural Comput & Applic (2014) 25:1337–1347
123
2.6 Noise detection and elimination
Noise emerged in document images through various sour-
ces such as physical degradation of the paper, dust due to
manual dealing and mechanical problems in the scanner,
camera [67]. Existing noise detection and removal
approaches use morphological operations to remove obvi-
ous noises while ignore small noises such as pepper-
and-salt noise [60]. O’Gorman [54] proposed the k-Fill
algorithm which is a manually designed approach and has
been used by several other researchers. Experiments show
it is effective for removing salt-and-pepper noise. Chen
et al. [17] used morphological opening operations to
remove noise in handwritten words. Kim et al. [40] iden-
tified noise in a word image by comparing the sizes and
shapes of connected components in an image to the average
stroke width. Madhvanath et al. [48] also analyze the size
and shape of connected components in a word image and
compare them to a threshold to remove salt-and-pepper
noise. In postal address words and other real-world appli-
cations, larger noise is sometimes present such as under-
lines. Therefore, to remove noise, few researchers have
also applied some form of underline removal to their word
images [7, 21, 69, 70].
Moreover, it is difficult to apart noise from compatible
sized text. Zheng et al. [86] divided document image into
blocks, and each block is classified into text or script or
noise. Structural features, Gabor features and run-length
histogram features are extracted from discriminated script
and text. The noise blocks are simply identified as they
Fig. 13 Noise removal results
of proposed technique a original
IAM form, b thresholding and
5 % noise addition, c noise
detection, d noise removal [64]
Neural Comput & Applic (2014) 25:1337–1347 1343
123
have short strokes. Two sets of bi-level texture features
were used for classification. A complete comparison of all
noise identification and removal approaches for document
images is presented in Figs. 13 and 14. The detailed results
based on PSNR are presented in Table 4.
3 Conclusion
The goal for normalization/preprocessing techniques is to
eliminate the handwriting variability that is inherited in
cursive script to smooth line further processing. Conse-
quently, it enhances accuracy of further process of seg-
mentation (if exists) and feature extraction for classification.
Hence, preprocessing techniques are normally included in all
document analysis and recognition systems to enhance
accuracy. Recently developed new preprocessing/normal-
ization techniques by the authors are also presented. This
paper has presented an annotated comparison of currently
published preprocessing techniques for cursive script
recognition in the state of art. Comparison of new normali-
zation techniques of authors with the old ones reported in the
literature exhibits their worth in sense of accuracy and
computational complexity using IAM benchmark database.
The ongoing research in this domain exhibits that still there is
a room of improvements. Additionally, new researchers
must focus on novel preprocessing techniques and compare
results on benchmark databases.
Acknowledgments Our deepest thanks and appreciation to the
Deanship of Scientific Research at King Saud University (KSU)
Riyadh Kingdom of Saudi Arabia for funding this research. We are
also thankful to our colleague researchers for their assistance in neural
network training and testing phases.
References
1. Arica N, Yarman-Vural FT (2002) Optical character recognition
for cursive handwriting. IEEE Trans Pattern Anal Mach Intell
24(6):801–813
Fig. 14 Noise removals using
morphological operation
a morphological opening,
b morphological closing [64]
Table 4 PSNR comparison on
text images
Noise variance Adaptive filter Median Morphological opening Morphological closing Proposed
approach
0.03 9.763 10.974 10.639 10.997 11.419
0.04 9.529 10.701 10.281 10.792 11.271
0.05 9.246 10.303 9.973 10.614 11.015
0.06 9.015 10.002 9.681 10.495 10.913
1344 Neural Comput & Applic (2014) 25:1337–1347
123
2. Arvind KR, Kumar J, Ramakrishnan AG (2007) Line removal
and restoration of handwritten strokes. In: Proceedings of the
international conference on computational intelligence and mul-
timedia applications, pp 208–214
3. Bai Z-L, Huo Q (2004) Underline detection and removal in a
document image using multiple strategies. In: Proceedings of the
17th international conference on pattern recognition (ICPR04),
vol 2, pp 578–581
4. Blumenstein M, Verma B (1999) Neural solutions for the seg-
mentation and recognition of difficult words from a benchmark
database. In: Proceedings of the 5th international conference on
document analysis and recognition (ICDAR’99), Bangalore,
India, pp 281–284
5. Blumenstein M, Verma B (1999) A new segmentation algorithm
for handwritten word recognition. In: Proceedings of the inter-
national joint conference on neural networks, Washington, DC,
vol 4, pp 878–882
6. Blumenstein M, Verma B (2001) Analysis of segmentation per-
formance on the CEDAR benchmark database. In: Proceedings of
6th international conference on document analysis and recogni-
tion, pp 1142–1146
7. Blumenstein M, Cheng CK, Liu XY (2002) New preprocessing
techniques for handwritten word recognition. In: Proceedings of
2nd international conference on visualization, imaging and image
processing, ACTA Press, Calgary, pp 480–484
8. Blumenstein M, Verma B, Basli H (2003) A novel feature
extraction technique for the recognition of segmented handwrit-
ten characters. In: Proceedings of the seventh international con-
ference on document analysis and recognition, pp 137–141
9. Blumenstein M, Liu XY, Verma B (2004) A modified direction
feature for cursive character recognition. In: Proceedings of the
international joint conference on neural networks, Budapest,
Hungary, pp 2983–2987
10. Bozinovic RM, Srihari SN (1989) Offline cursive script word
recognition. IEEE Trans Pattern Anal Mach Intell 11(1):68–83
11. Brown MK, Ganapathy S (1983) Preprocessing techniques for
cursive script word recognition. Pattern Recogn 16(5):447–458
12. Britto A Jr, Sabourin R, Bortolozzi F, Suen CY (2004) Fore-
ground and background information in an HMM-based method
for recognition of isolated characters and numeral strings. In:
Proceedings of the 9th international workshop on frontiers in
handwriting recognition, pp 371–376
13. Burges CJC, Be JI, Nohl CR (1992) Recognition of handwritten
cursive postal words using neural networks. In: Proceedings of
the 5th United States postal service (USPS) advanced technology
conference, pp 117–124
14. Caesar T, Gloger JM, Mandler E (1993) Preprocessing and fea-
ture extraction for a handwriting recognition system. In: Pro-
ceedings of international conference on document analysis and
recognition, pp 408–411
15. Cai J, Liu Z-Q (2000) Offline unconstrained handwritten word
recognition. Int J Pattern Recognit Artif Intell 14(3):259–280
16. Camastra F, Vinciarelli A (2003) Combining neural gas and
learning vector quantization for cursive character recognition.
Neuro-computing 51:147–159
17. Chen M-Y, Kundu A, Zhou J, Srihari SN (1992) Offline hand-
written word recognition using hidden markov model. In: Pro-
ceedings of the 5th USPS advanced T
18. Cheng CK, Blumenstein M (2005) Improving the segmentation of
cursive handwritten words using ligature detection and neural
validation. In: Proceedings of the fourth Asia Pacific international
symposium on information technology (APIS 2005), Gold Coast,
Australia, pp 56–59
19. Cheriet M, Kharma N, Liu C-L, Suen C-Y (2007) Character
recognition systems (OCR). Wiley, New York, pp 204–206
20. Cote M, Lecolinet E, Cheriet M, Suen CY (1998) Automatic
reading of cursive scripts using a reading model and perceptual
concepts—the PERCEPTO system. Int J Doc Anal Recogn
1(1):3–17
21. Dimauro G, Impedovo S, Pirlo G, Salzo A (1997) Removing
underlines from handwritten text: an experimental investigation.
In: Downton AC, Impedovo S (eds) Progress in handwriting
recognition. World Scientific Publishing, Singapore, pp 497–501
22. Dong J-X, Dominique P, Krzyyzak A, Suen C-Y (2005) Cursive
word skew/slant corrections based on Radon transform. In: Pro-
ceedings of the 8th international conference on document ana-
lysis and recognition, pp 478–483
23. El-Hajj R, Likforman-Sulem L, Mokbel C (2005) Arabic hand-
writing recognition using baseline dependant features and hidden
Markov modeling. In: Proceedings of the 2005 eight international
conference on document analysis and recognition (ICDAR’05),
pp 893–897
24. El-Yacoubi A, Gilloux M, Sabourin R, Suen CY (1999) An
HMM-based Approach for online unconstrained handwritten
word modeling and recognition. IEEE Trans Pattern Anal Mach
Intell 21(8):752–760
25. Foley JD, Dam AV, Feiner SK, Hughes JF (1996) Computer
graphics: principles and practice in C, 2nd edn. Addison-Wesley,
Pearson Education, Boston
26. Gatos B, Pratikakis I, Perantonis SJ (2006) Hybrid offline cursive
handwriting word recognition. In: Proceedings of 18th interna-
tional conference on pattern recognition (ICPR’06), vol 2,
pp 998–1002
27. Gatos B, Pratikakis I, Kesidis AL, Perantonis SJ (2006) Efficient
offline cursive handwriting word recognition. In: Proceedings of the
tenth international workshop on frontiers in handwriting recognition
28. Gatos B, Antonacopoulos A, Stamatopoulos N (2007) ICDAR
2007 handwriting segmentation context. In: Proceedings of the
international conference on document analysis and recognition,
pp 1284–1288
29. Govindaraju V, Srihari SH (1992) Separating handwritten text
from interfering strokes. In: Impedovo S, Simon JC (eds) From
pixels to features III—frontiers in handwriting recognition.
North-Holland Publication, Amsterdam, pp 17–28
30. Guillevic D, Suen CY (1993) Cursive script recognition: a fast
reader scheme. In: Proceedings of the 3rd international confer-
ence on documents analysis and recognition, pp 311–314
31. Hamamura T, Akagi T, Irie B (2007) An analytic word recog-
nition algorithm using a posteriori probability. Proc Int Conf Doc
Anal Recogn 02:669–673
32. Hanmandlu M, Murali KRM, Chakraborty S, Goyal S, Choudh-
ury DR (2003) Unconstrained handwritten character recognition
based on fuzzy logic. Pattern Recogn 36(3):603–623
33. Indira K, Selvi S (2007) An off line cursive script recognition
system using Fourier-wavelet features. In: International confer-
ence on computational intelligence and multimedia applications,
pp 506–511
34. Kavallieratou E, Fakotakis N, Kokkinakis G (1999) New algo-
rithms for skewing correction and slant removal on word level.
In: Proceedings of 6th IEEE international conference on elec-
tronics, circuits and systems, vol 2, pp 1159–1162
35. Kavallieratou E, Fakotakis N, Kokkinakis G (2000) A slant
removal algorithm. Pattern Recogn 33(7):1261–1262
36. Kavallieratou E, Stamatatos E, Fakotakis N, Kokkinakis G (2000)
Handwritten character segmentation using transformation-based
learning. In: Proceedings of 15th international conference on
pattern recognition, vol 2, pp 634–637
37. Kavallieratou E, Fakotakis N, Kokkinakis G (2001) Slant esti-
mation algorithm for OCR system. Pattern Recogn 34(12):
2515–2522
Neural Comput & Applic (2014) 25:1337–1347 1345
123
38. Kavallieratou E, Dromazou N, Fakotakis N, Kokkinakis G (2003)
An integrated system for handwritten document image process-
ing. Int J Pattern Recognit Artif Intell 17(4):617–636
39. Kapp MN, de Almendra Freitas C, Sabourin R (2007) Method-
ology for the design of NN-based month-word recognizers writ-
ten on Brazilian bank checks. Image Vision Comput 25(1):40–49
40. Kim G, Govindaraju V, Srihari SN (1999) Architecture for hand-
written text recognition systems. Adv Handwrit Recogn 163–182
41. Kim G, Govindaraju V (1997) A Lexicon Driven approach to
handwritten word recognition for real time application. IEEE
Trans Pattern Anal Mach Intell 19(4):366–379
42. Koerich AL, Ling LL (1998) a system for automatic extraction of
the user-entered data from bank checks. In: Proceedings of
international symposium on computer graphics, image processing
and vision, pp 270–278
43. Koerich AL, Sabourin R, Suen CY (2003) Large vocabulary
offline handwriting recognition: a survey. Pattern Anal Appl
6(2):97–121
44. Koerich AL, Britto A, Oliveira LES, Sabourin R (2006) Fusing
high- and low-level features for handwritten word recognition. In:
Proceedings of the tenth international workshop on frontiers in
handwriting recognition
45. Lee L, Coelho S (2005) A simple and efficient method for global
handwritten word recognition applied to Brazilian bank checks.
In: Proceedings of the 8th international conference on document
analysis and recognition, pp 950–955
46. Liolios N, Fakotakis N, Kokkinakis G (2002) On the general-
ization of the form identification and skew detection problem.
Pattern Recognition 35:253–264
47. Liu C-L, Fujisawa H (2005) Classification and learning for
character recognition: comparison of methods and remaining
problems. In: Proceedings of the international workshop on
neural networks and learning in document analysis and recogni-
tion, pp 5–7
48. Madhvanath S, Kleinberg E, Govindaraju V (1999) Holistic
verification of handwritten phrases. IEEE Trans Pattern Anal
Mach Intell 21:1344–1356
49. Madhvanath S, Shrihari S (1996) A technique for local baseline
determination. In: Proceedings of the 5th international workshop
on frontiers in handwriting recognition, pp 445–448
50. Marinai S, Gori M, Soda G (2005) Artificial neural networks for
document analysis and recognition. IEEE Trans Pattern Anal
Mach Intell 27(1):23–35
51. Morita M, Facon J, Bortolozzi F, Garnes S, Sabourin R (1999)
Mathematical morphology and weighted least squares to correct
handwriting baseline skew. In: Proceedings of the international
conference on document analysis and recognition, vol 1, Ban-
galore, pp 430–433
52. Neamah K, Mohamad, D, Saba T, Rehman A (2014) Discrimi-
native features mining for offline handwritten signature verifi-
cation. 3D Research 5(3). doi:10.1007/s13319-013-0002-3
53. Nicchiotti G, Scagliola C (1999) Generalised projections: a tool
for cursive handwriting normalization. In: Proceedings of 5th
international conference on document analysis and recognition,
ICDAR’99, Bangalore India, pp 729–732
54. O’Gorman L (1993) The document spectrum for page layout
analysis. IEEE Trans Pattern Anal Mach Intell 15(11):1162–1173
55. Okun O, Pietikainen M, Sauvola J (1999) Robust skew estimation
on low-resolution document images. In: 5th International con-
ference on document analysis and recognition, pp 621–624
56. Paster M, Toselli A, Vidal E (2004) Projection profile based
algorithm for slant removal. In: Proceedings of the international
conference on image analysis and recognition, pp 183–190
57. Rehman A, Dzulkifli M, Kurniawan F (2008) Line and skew
removal from off-line cursive handwritten words. Int J Res (Sci)
24(2):28–33
58. Rehman A, Alqahtani S, Altameem A, Saba T (2013) Virtual
machine security challenges: case studies. Int J Mach Learn
Cybernet. doi:10.1007/s13042-013-0166-4
59. Rehman A, Saba T (2012) Evaluation of artificial intelligent
techniques to secure information in enterprises. Artif Intell Rev.
doi:10.1007/s10462-012-9372-9
60. Rehman A, Saba T (2012) Neural network for document image
preprocessing. Artif Intell Rev. doi:10.1007/s10462-012-9337-z
61. Rehman A, Saba T (2011) Document skew estimation and cor-
rection: analysis of techniques, common problems and possible
solutions. Appl Artif Intell 25(9):769–787
62. Rehman A, Kurniawan F, Saba T (2011) An automatic approach
for line detection and removal without characters smash-up.
Imaging Science Journal 59(3):171–182
63. Rehman A, Mohamad D, Sulong G, Saba T (2009) Simple and
effective techniques for core zone detection and slant correction
in script recognition. In: The IEEE international conference on
signal and image processing applications (ICSIPA’09), pp 15–20
64. Saba T (2012) Offline cursive touched script recognition. PhD
Thesis, submitted to Universiti Teknologi Malaysia, pp 73–80
65. Saba T, Alzorani S, Rehman A (2012) Expert system for offline
clinical guidelines and treatment. Life Sci J 9(4):2639–2658
66. Saba T, Rehman A (2012) Effects of artificially intelligent tools
on pattern recognition. Int J Mach Learn Cybernet 4:155–162.
doi:10.1007/s13042-012-0082-z
67. Saba T, Rehman A (2012) Machine learning and script recogni-
tion. Lambert Academic Publisher, ISBN-10: 3659111708,
pp 78–91
68. Saba T, Rehman A, Elarbi-Boudihir M (2011) Methods and
strategies on off-line cursive touched characters segmentation: a
directional review. Artif Intell Rev. doi:10.1007/s10462-011-
9271-5
69. Saba T, Rehman A, Sulong G (2011) Improved statistical features
for cursive character recognition. Int J Innov Comput Inf Control
(IJICIC) 7(9):5211–5224
70. Saba T, Rehman A, Sulong G (2011) Cursive Script Segmenta-
tion with Neural Confidence. Int J Innov Comput Inf Control
(IJICIC) 7(8):4955–4964
71. Sarfraz M, Mahmoud SA, Rasheed Z (2007) On skew estimation
and correction of text. In: Proceedings of international conference
on computer graphics, imaging and visualization, pp 308–313
72. Sarfraz M, Zidouri A, Shahab SA (2005) A novel approach for
skew estimation of document images in OCR system. In: Pro-
ceedings of IEEE conference on computer graphics, imaging and
vision: new trends (CGIV’05), pp 175–180
73. Senior AW (1994) Offline cursive handwriting recognition using
recurrent neural networks. PhD Dissertation, University of
Cambridge, England
74. Senior AW, Robinson AJ (1998) An offline cursive handwriting
recognition system. IEEE Trans Pattern Anal Mach Intell
20(3):309–321
75. Senior W, Robinson AJ (2002) An offline cursive handwriting
recognition system. IEEE Trans Pattern Anal Mach Intell
20(3):309–321
76. Suen CY, Tan J (2005) Analysis of errors of handwritten digits
made by a multitude of classifiers. Pattern Recogn Lett
26(3):369–379
77. Taira E, Uchida S, Sakoe H (2004) Non-uniform slant correction
for handwritten word recognition. IEICE Trans Inf Syst E87-
D(5):1247–1253
78. Uchida S, Taira E, Sakoe H (2001) Non-uniform slant correction
using dynamic programming. In: Proceedings of 6th international
conference on document analysis and recognition, vol 1,
pp 434–438
79. Verma B (2002) A contour character extraction approach in
conjunction with a neural confidence fusion technique for the
1346 Neural Comput & Applic (2014) 25:1337–1347
123
segmentation of handwriting recognition. In: Proceeding of the
9th international conference on neural information processing,
vol 5, pp 2459–2463
80. Vinciarelli A, Luettin J (2001) A new normalization technique for
cursive handwritten words. Pattern Recogn Lett 22:1043–1050
81. Watanabe MM, Hamammoto Y, Yasuda T, Tomita S (1997)
Normalization techniques of handwritten numerals for Gabor
filters. In: Proceedings of the international conference on docu-
ment analysis and recognition, ICDAR IEEE, Los Alamitos, CA,
vol 1, pp 303–307
82. Wang L, Wang X, Feng J (2006) On image matrix based feature
extraction algorithms. IEEE Trans Syst Man Cybernet Cybernet
36(1):194–197
83. Yoo J-Y, Kim M-K, Han SY, Kwon Y-B (1997) Line removal
and restoration of handwritten characters on the form documents.
In: Proceedings of the fourth international conference on docu-
ment analysis and recognition, vol 1, pp 128–131
84. Yu B, Jain AK (1996) A generic system for form dropout. IEEE
Trans Pattern Anal Mach Intell 18(11):1127–1132
85. Zeeuw FD (2006) Slant correction using histogram. Bachelor
thesis, pp 3–4
86. Zheng Y, Li Y, Doermann D (2006) Detecting text lines in
handwritten documents. In: Proceedings of 18th international
conference on pattern recognition, vol 2, pp 1030–1033
Neural Comput & Applic (2014) 25:1337–1347 1347
123
