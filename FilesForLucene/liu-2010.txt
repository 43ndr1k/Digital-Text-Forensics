Degraded Character Recognition by Image Quality Evaluation 
 
 
Chunmei Liu 
Department of Computer Science and Technology,  
Tongji University 
Shanghai, China 
E-mail: chunmei.liu@tongji.edu.cn
 
 
Abstract—The character image quality plays an important role 
in degraded character recognition which could tell the 
recognition difficulty. This paper proposed a novel approach to 
degraded character recognition by three kinds of independent 
degradation sources. It is composed of two stems: character 
image quality evaluation, character recognition. Firstly, it 
presents the dual-evaluation to evaluate the image quality of 
the input character. Secondly, according to the input 
evaluation result, the character recognition sub-systems 
adaptively act on. These sub-systems are trained by character 
sets whose image qualities are similar to the input’s quality, 
and have special features and special classifiers respectively. 
Experiment results demonstrate the proposed approach highly 
improved the performance of degraded character recognition 
system. 
Keywords- character recognition; degraded character 
recognition; image quality evaluation 
I.  INTRODUCTION 
With rapid progress of digital imaging technology and 
variety of image acquisition conditions, character recognition 
becomes increasingly important. The character recognition 
for low-quality becomes a bottleneck in OCR field. Images 
having luminance variations, noise, and random degradation 
of text are difficult to read by OCR systems because 
traditional methods can not provide satisfactory recognition 
performance.  
Most previous degraded character recognition methods 
mainly concentrated on image enhancement. For scanned 
images of old manuscripts, A.Gupta et al. [7] presented an 
algorithm based on matched wavelets and MRF model to 
automatically identify and extract the low contrast text 
regions from scanned manuscript images and enhance them 
using a histograms matching technique. E.Kavallieratou et al. 
[8] proposed a hybrid binarization approach for improving 
the quality of old documents using a combination of global 
and local thresholding. J.Banerjee et al. [9] proposed an 
approach to restore severely degraded document images 
using a probabilistic contextual model. H.S. Baird et al. [11] 
presented an approach to propagating groundtruth 
information from an original collection allowing the reuse of 
groundtruth information using of degradation models for 
data generation. Elisa Barney Smith et al. [13] statistically 
compared pairs of populations of degraded character images 
created with different model parameters. It showed that the 
amount of variation in the characters correlated highly with 
the change in the edge spread degradation.  
The research work in feature extraction also made some 
progresses for degraded character recognition, which can be 
divided into two categories. One is to extract the character 
feature from the binary character image by degradation 
recovery and advanced binarization [1,2]. These processes 
will inevitably result in information loss because it is very 
difficult to get the clear binary form of a degraded character 
image. In order to avoid the information loss, another 
method is proposed that the features were extracted directly 
from the gray scale image, such as structural features and 
frequency features. Structural features include direction 
feature, skeleton feature, topological feature and so on [3,4]. 
Structural features can precisely describe the structure of a 
character, but it is difficult to extract invariable structural 
features because of deform and variation. Frequency features 
are very effective for degraded character recognition, such as 
Fourier transform and wavelet transform. Xuewen Wang et 
al. [5] utilized Gabor filters to extract the basic structures of 
character, and modified the non-linear function to regulate 
the outputs of Gabor filters adaptively to improve the 
performance for low quality images. Hamamoto and 
Uchimura et al. [6] proposed a Gabor filter-based feature 
extraction method for handwritten numeral character 
recognition. These applications show frequency features 
demonstrated the good behavior in degraded character 
recognition. 
This paper takes into account three kinds of degradation, 
low resolution, fuzziness on focus and blur by motion. The 
whole recognition system is composed of two stems: dual-
evaluation on image quality, degraded character recognition. 
Fig. 1 shows the structure of the proposed approach. In dual-
evaluation part, the edge density ratio feature is proposed to 
evaluate the input image quality. According to the evaluation 
result, the recognition part adaptively selects the recognition 
sub-system. It makes the classification have the higher 
probability of being the correct decision. 
The paper is organized as follows. In section 2, the dual-
evaluation method is presented, and the degraded character 
recognition system is described in section 3. Section 4 
discussed the experiment results. In the final section 
conclusions are provided. 
2010 International Conference on Pattern Recognition
1051-4651/10 $26.00 © 2010 IEEE
DOI 10.1109/ICPR.2010.470
190812
 
Figure 1.  Flow chart of the proposed approach. 
II. DUAL-EVALUATION OF IMAGE QUALITY 
For degraded character recognition, it is desirable to 
match the special classifier by training dataset with the same 
image quality as a input character image’s. So this part 
proposed a dual-valuation method to evaluate the image 
quality of character. According to degradation source and 
degradation degree, we classified the character sets into 
seven levels, which are clear level, light blur level, heavy 
blur level, light blur level in horizontal direction, heavy blur 
level in horizontal direction, light blur level in vertical 
direction and heavy blur level in vertical direction which are 
respectively abbreviated to L1, L2, L3, L4, L5, L6 and L7 
for short as seen from Fig. 1. Thus, the input character image 
is evaluated by image quality level identification. The dual-
evaluation system is performed by two steps: blur evaluation 
and motion-blurred evaluation. 
A. Blur evaluation 
In this step, it can be evaluated the blur degradation by 
low resolution or lack of focus. Here the gray distribution 
feature is applied to evaluate the blur degree in this part [10]. 
The algorithm is performed by three steps: preprocess, gray 
distribution feature extraction and classification. After the 
blur evaluation, clear level and heavy blur level can be 
evaluated, and the other levels are evaluated into one big 
level. So this one big level need to be further evaluated. 
B. Motion-blurred evaluation 
After blur evaluation, the rest five image quality levels 
can be further evaluated. Here edge density ratio feature is 
proposed to evaluate the motion-blurred direction and the 
motion-blurred degree. 
 
Figure 2.  Gray histograms distribution of some samples 
There are some samples in Fig. 2 which shows the 
different gray histogram distribution. Fig.2 (a) is original 
image blurred in horizontal direction. Fig.2 (b) is original 
image blurred in vertical direction. Fig.2 (c) and Fig.2 (d) are 
the horizontal edge image and the vertical edge image of 
Fig.2 (a) respectively. Fig.2 (e) and Fig.2 (f) are the 
horizontal edge image and the vertical edge image of Fig.2 
(b) respectively. Fig.2 (g, h, i, j) are the gray histograms of 
edge images Fig.2 (c, d, e, f) respectively. 
It is different the gray histograms distribution of a blurred 
image in different direction. For a blurred image in 
horizontal direction, the gray histograms of its horizontal 
edge have compact distribution. Conversely, the gray 
histograms of its vertical edge have sparse distribution. For 
the blurred image in vertical direction, the situation is 
contrary. The gray histograms of its vertical edge have more 
compact distribution than that of the horizontal edge. 
According to this gray distribution characteristic, the edge 
density ratio feature is proposed to evaluate the motion-
blurred direction and motion-blurred degree. 
The details are performed by following steps. 
1． The character image is preprocessed to form a uniform 
image I (64*64pixels).  
2． Sobel edge operators are used to get the edge image Eh 
in horizontal and the edge image Ev in vertical 
directions. 
3． The gray distribution features hdh and hdv of Eh and Ev 
are extracted by computing the gray histograms hh and 
hv as in (1) and (2). 
 
⎩
⎨
⎧
≤
>
=
 ;)(           ,0
;)(           ,1
vv
vv
dv Tih
Tih
h  (1) 
 
⎩
⎨
⎧
≤
>
=
 ;)(           ,0
;)(           ,1
hh
hh
dh Tih
Tih
h  (2) 
Here, Th and Tv are the thresholding to display the gray 
distribution characteristic of the edge images in the 
horizontal and vertical direction. 
4． The edge density ratio feature are exacted as in (3): 
 
∑
∑=
dh
dv
d h
h
r  (3) 
190913
The edge density ratio feature described that the 
different motion-blurred image has the different gray 
histograms distribution and different ratio in the 
horizontal and vertical direction. 
5． The one big level after blur evaluation can be further 
evaluated as follows: 
⎪
⎪
⎩
⎪
⎪
⎨
⎧
⎪
⎪
⎩
⎪
⎪
⎨
⎧
≤
>>
≥>
≥>
≥
.     
;     
;  
;     
;     
    ,
directionhorizontalinlevelblurheavy
directionhorizontalinlevelblurlight
levelblurlight
directionverticalinlevelblurlight
directionverticalinlevelblurheavy
then
Tr
TrT
TrT
TrT
Tr
If
htd
htdhl
bldvl
vldvt
vtd
 
Here Tvt，Tvl，Tht and Thl are the top thresholding and 
low thresholding for evaluation in the vertical and 
horizontal direction. 
After the above five steps,  light blur level, light blur 
level in horizontal direction, heavy blur level in horizontal 
direction, light blur level in vertical direction and heavy blur 
level in vertical direction can be evaluated by the edge 
density ratio feature. 
III. DEGRADED CHARACTER RECOGNITION  
It is difficult to extract universal and effective features 
for various degraded character recognition. So it is ideal to 
match the special classifier by training the dataset with the 
same image quality as the input character image. According 
to the above 7 image quality levels, 7 sub-systems are 
designed for character recognition. These sub-systems are 
trained by 7 character sets with 7 image quality levels 
respectively. Each sub-system has its own special feature and 
classifier which adapts to corresponding image quality. In 
this paper, for the comparison of experiment in all 
recognition sub-systems the same feature and the same 
classifier are adopted, which are Gabor filters-based feature 
[5] and minimum distance classifier. 
The degraded character classification mainly consists of 
two steps: the first classification, the second classification. 
The first classifier is achieved by training all sub-datasets. 
After the first classification, it is assumed that m candidates 
can be generated. In these m candidates, it is the most 
possible to get the correct recognition result. So in the 
second classification, the given image is recognized only in 
these candidates for saving the computing. We define the 
adaptive classification weights W as in (4), which are used to 
adaptively adjust every sub-system’s action. 
 ( )1,... ,...i nW w w w=  (4) 
Here n is the number of recognition sub-systems, wi is the 
weight of the ith classifier’s operation. If the image quality 
of the ith sub-dataset is more similar to the input character 
image quality than the other, we set the weight wi larger. 
Inversely the other weights are set smaller. Thus the second 
classification can be accomplished by adjusting the adaptive 
classification weights based on the input image quality level. 
IV. EXPERIMENT  
In order to evaluate the effectiveness of the proposed 
method several experiments are carried out on printed 
Chinese character images, which include 3755 categories. 
Here, the degraded character dictionary is generated by 
three degradation models. The blurred character images with 
low resolution are generated by scaling model as in [10]. The 
character images vary in size from 10*10 to 64*64 pixels. A 
pill-box Gaussian filter is applied to simulate the real-life 
blur degradation by lack of focus, which regards a point-
spread function (PSF) as the blur degradation. We used 8 
blur runs to simulate 8 blur degrees. For the motion-blurred 
degradation, the same method is applied as motion-blurred 
degradation model. Here 5 kinds of blur runs and 2 
directions simulated 10 blur degrees. 
By the above three degradation models, there are 26 
character sets with 18 blurring degrees, which are 8 blur 
degrees by low resolution mixed with 8 blur by lack of focus, 
10 blur degrees by camera motion. Every character set 
includes 3755 Chinese characters. 
A. Dual-evaluation experiment on degraded character 
We use 3*1000 samples from 3 blur degrees as training 
data, and the other 94,630(2775*3+3775*23) samples as 
testing data. These data are evaluated into 7 blur levels. The 
experiment parameters of the motion-blurred part are applied 
as in Table I. 
The final result is shown in Fig. 3. Horizontal axis is the 
blur run r by PSF, namely 18 blur degrees. Vertical axis is 
the evaluation ratio to 7 levels. It is the distribution of 26 
character sets with 18 blur degrees by dual-evaluation using 
7 image quality levels. 
TABLE I.  PARAMETERS OF DUAL-EVALUATION 
T Th, Tv Tht, Tvt Thl, Tvl T 
30 0,0 2,2 0.5,0.5 30 
c0 b1 b2  b3 b4 b5 b6 b7 bh5 bh8 bh10 bh12 bh15 bv5 bv8 bv10 bv12 bv1
0
1
  
 
Figure 3.  Recognition rate distribution of character sets with different blur 
scources and different blur degrees  
19104
Figure 4.  Parameters of adaptive classification weights 
WL1 [1,0,0,0,0,0,0] WL4 [0,0,0,1,0,0,0] 
WL2 [0,1,0,0,0,0,0] WL5 [0,0,0,0,1,0,0] 
WL3 [0,0,1,0,0,0,0] WL6 [0,0,0,0,0,1,0] 
  WL7 [0,0,0,0,0,0,1] 
Figure 5.  Recognition rates of degraded characters 
 ST AT 
Recognition rate 13.20 92.51 
 
The evaluation result on 26 character sets in Fig. 3 shows 
recognitions ratios of 26 character sets are respectively 
subject to the normal distribution of 7 image quality levels. 
The images with light blur degree mostly locate at light level 
scope. And most of the images with heavy blur degree 
distribute in heavy blur level scope.  Experiment result 
demonstrates the proposed algorithm of dual-evaluation can 
effectively be applied on the image quality evaluation of the 
degraded characters. 
B. Degraded character recognition experiment 
There are 52 sub-datasets with different blur degrees, and 
every sub-dataset includes 3755 Chinese characters. We use 
26 sub-datasets as training dataset, and the other 26 sub-
datasets as testing dataset. The experiment parameters of 
adaptive classification weights W are preset in advance as in 
Table II. 
In Table III, the recognition result of the proposed 
method is compared with the single template (ST) method, 
which is to compute the template by using the whole training 
datasets without distinguishing the image quality. AT is the 
proposed method that automatically selects the appropriate 
training dataset to join recognition. Experiment demonstrates 
the proposed method highly improved the performance of 
the degraded character recognition system. 
V. CONCLUSIONS 
In this paper, we proposed an approach to the degraded 
character recognition for three independent degradation 
sources: low resolution, blur by lack of focus, blur by camera 
motion. According to degradation source and degradation 
degree, we classified the degraded character sets into 7 levels. 
The recognition sub-system adaptively acted on according to 
the image quality of the input character. The dual-evaluation 
is proposed to evaluate the character image quality. It is 
objective no-reference method with low computational 
complexity and with anti-noise ability. Furthermore it is 
independent of the image content. The experiment on the 
degraded character set shows that the proposed approach 
highly improved the performance of the degraded character 
recognition system. 
In the future research, for the image quality evaluation 
system, it is necessary to find effective features to evaluate 
the more degradation sources, such as noise and distortion 
which is usually appears in real life. For the degraded 
character recognition system, one is to improve the 
performance of sub-system by special feature and classifier 
selection. The other is to improve the performance of whole 
system by the excellent integration of sub-systems, such as 
learning method of adaptive classification weights. 
REFERENCES 
[1] Taylor,M.J. and Dance,C.R., “Enhancement of document 
images from cameras,” Proc. Of SPIE, 23305: 230–241, 1998. 
[2] T. Kanungo, RM Haralick, H. Baird, W. Stuezle and D. 
Madigan., “A statistical, nonparametric methodology for 
document degradation model validation,” IEEE. Trans. 
PAMI, 22 (11):1209–1223, 2002. 
[3] L. Wang, and T. Pavlidis, “Direct gray-scale extraction of 
features for character recognition,” IEEE Trans. PAMI, 15 
(10): 1053–1066, 1993. 
[4] S.-W. Lee and Y.-J. Kim. “Direct Extraction of Topographic 
Features for Gray Scale Character Recognition,” IEEE Trans. 
PAMI, 17 (7): 724-729, 1995. 
[5] Xuewen Wang, Xiaoqing Ding, and Changsong Liu, “Gabor 
filters-based feature extraction for character recognition,” 
Pattern Recognition, 29 (7): 369–379, 2005. 
[6] Hamamoto, Y., S. Uchimura, M. Watanabe, T. Yasuda, Y. 
Mitani, and S. Tomita. “A Gabor filter-based method for 
recognizing handwritten numerals,” Pattern Recognition, 31 
(4): 395-400, 1998. 
[7] A.Gupta, S.Kumar, R.Gupta, S.Chaudhury, and S.D.Joshi, 
“Enhancement of Old Manuscript Images,” Proc. of ICDAR 
2007, 2:744 – 748, 2007. 
[8] E. Kavallieratou and E. Stamatatos, “Improving the Quality of 
Degraded Document Images,” Proc. of DIAL 2006, pp:340 – 
349, 2006. 
[9] J.Banerjee, A.M.Namboodiri, and C.V.Jawahar, “Contextual 
restoration of severely degraded document images,” Proc. of 
CVPR 2009, pp:517 – 524, Miami,US, 2009. 
[10] C.M. Liu, C.H. Wang, and R.W. Dai, “Low Resolution 
Character Recognition by Image Quality Evaluation,” Proc. of 
ICPR 2006, 1:864 – 867, Aug.2006. 
[11] T. Kanungo, R.M. Haralick, H.S. Baird, W. Stuezle, and D. 
Madigan, “A statistical, nonparametric methodology for 
document degradation model validation,” IEEE Trans. PAMI, 
22 (11): 1209-1223, Nov.2000. 
[12] Ho TK and Baird HS., “Large-scale simulation studies in 
image pattern recognition,” IEEE Trans. PAMI, 19(10): 1067-
1079, 1997. 
[13] Elisa H. Barney Smith and Xiaohui Qiu, “Statistical 
imagedifferences, degradation features and character 
distancemetrics,” International Journal of Document 
Analysisand Recognition, Vol.6, No. 3, pp. 146-153, 2004. 
 
19115
