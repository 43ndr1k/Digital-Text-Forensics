ar
X
iv
:1
20
8.
62
68
v2
  [
cs
.C
L
] 
 3
1 
A
ug
 2
01
2
Authorship Identification Using Stylometry Analysis
in Bengali Literature
Tanmoy Chakraborty
Abstract—Stylometry is the study of the unique linguistic styles
and writing behaviors of individuals. It belongs to the core task of text
categorization like authorship identification, plagiarism detection etc.
Though reasonable amount of works have been studied in English
for a long time, no major work has been done so far in Bengali.
In this work, we present a strategy for authorship identification of
the documents written in Bengali. It takes into account a writer-
independent model and builds a robust system which reduces the
pattern-recognition problem. We adopt a set of fine-grained stylistic
features for the analysis of the text and use them to develop two
different models: statistical similarity model consisting of three
measures and their combination, and machine learning model with
Decision Tree, Neural Network and SVM. Experimental results show
that SVM outperforms others with average 83.3% of accuracy after
10-fold cross validations using same set of features. We also validate
the relative importance of each stylistic feature to show some of
them remain consistently significant in every model used in this
experiment.
Keywords—Stylometry, Authorship Identification, Vocabulary
Richness, Machine Learning.
I. INTRODUCTION
RECENTLY, the rapid growth of text in electronic formin blogs, social media, forums etc creates anonymously
or under unverified names. In the framework of forensic appli-
cations, it is needed to group texts written by the same author
or track texts written under different names but belonging
to the same person. Authorship identification supported by
computational analysis of texts attracts increasing attention
since it may offer quick answers to these problems. Stylometry
is an approach that analyses text in text mining e.g., novels,
stories, dramas that the famous author wrote, trying to measure
the author’s style, rhythm of his pen, subjection of his desire,
prosody of his mind by choosing some attributes that are
consistent throughout his writing, which plays the linguistic
fingerprint of that author. Simply, Stylometry is the application
of the study of linguistic style, usually to written language
which concerns the way of writing rather than its contents.
Stylistic analysis that has been done by Croft [5] claimed that
for a given author, the habits “of style” are not affected “by
passage of time, change of subject matter or literary form.
They are thus stable within an authors writing, but they have
been found to vary from one author to another”. Authorship
identification belongs to the subtask of Stylometry detection
where a correspondence between the predefined writers and
the unknown articles has to be established taking into account
Tanmoy Chakraborty is with the Department of Computer Science and
Engineering, Indian Institute of Technology, Kharagpur, 721302, India, e-mail:
its tanmoy@cse.iitkgp.ernet.in.
various stylistic features of the documents. In order to identify
the author, one must extract the most appropriate features
to represent the style of that author. In this context, the
Stylometry offers a strong support to define a discriminative
feature set. The literature shows that most of the features
are drawn from the lexical aspects, and they are strongly
dependent on the length of the document under study and are
difficult to apply reliably.
The main target in this study is to build a decision
making system that enables users to predict and to choose
the right author from a specific anonymous authors’ novels
under consideration, by choosing various lexical, syntactic,
analytical features called as stylistic markers. Two directions
of standard NLP techniques have been studied to model the
authorship identification task—(i) statistical model using three
well-established similarity measures- cosine-similarity, chi-
square measure, euclidean distance, and (ii) machine learning
approach with Decision Tree, Neural Network and Support
Vector Machine (SVM). The conventional vocabulary richness
function for stylometry analysis has been adopted for baseline
measure. Taking into account same feature sets for both
models, the performance of SVM overshadows others with
reasonable improvement of accuracy. The observation of the
effect of each stylistic feature over 10-cross validations relies
on that fact that some of them are inevitable for authorship
identification task especially in Bengali, and few of the rare
studied features could accelerate the performance of this
mapping task.
Though the purpose of this study is to make a language
independent authorship identification system, it is proved to
be well-behaved for Bengali language. The penultimate focus
of our study is to detect a set of discriminative features suitable
for Bengali language and build a fine-grained mapping system
that can find out the author of the unplugged, unpublished
documents (letters, poems, plays, novels) without considering
the text genre and writing time period which, in tern, ensures
that the success of the learners would entail that texts can be
classified on the style or the “textual fingerprint” of authors
alone. More specifically, we will try to unfold the stylistic arts
of great Indian novel laureate Rabindranath Tagore as a tribute
to his 150th birth anniversary.
II. RELATED STUDY
Stylometry, which may be considered as an investigation of
“Who was behind the keyboard when the document was pro-
duced?” or “Did Mr. X wrote the document or not?” is a long
term study mainly in forensic investigation department started
from late Nineties. In the past, where Stylometry emphasized
the rarest or most striking elements of a text, contemporary
techniques can isolate identifying patterns even in common
parts-of-speech. The pioneering study on authorship attributes
identification using word-length histograms appeared at the
very end of nineteen century [10]. After that, a number of
studies based on content analysis [9], computational stylistic
approach [14], exponential gradient learn algorithm [1],
Winnow regularized algorithm [18], Support Vector Machine
based approach [12] have been proposed for various languages
like English, Portuguese (see [16] for reviews).
As a beginning of Indian language Stylometry analysis,
Chanda et al., (2010) [2] started working with handwritten
Bengali texts to judge authors. Das and Mitra, (2011) [6]
proposed an authorship identification task in Bengali using
simple n-gram token counts. They argued that simple unigram
and bi-gram features along with vocabulary richness are rich
enough to discriminate amongst authors. But this approach is
restrictive when considering authors of the same period and
same genre. The challenges of discriminating documents (of
same genre) of the authors of same time period may blur the
system when considering only the token counts. Anonymous
signature reflecting as a mirror of that time priors in various
authors’ writings may bias the system towards some specific
authors. The texts we have chosen are of the same genre and of
the same time period to ensure that the success of the learners
would infer that texts can be classified only on the style,
not by the prolific discrimination of text genres or distinct
times of writing. Moreover, we introduce various statistical and
machine learning models for the first time in Bengali language.
III. CLASSIFICATION MODELS
Efstathios Stamatatos (2000) [15] stated that there is no
computational system as of today that can distinguish the texts
of a randomly-chosen group of authors without the assistance
of a human in the selection of both the most appropriate set of
style markers and the most accurate disambiguation procedure.
Although there is a large variety in the methodology of
stylometry, the techniques may be roughly divided into two
classes: statistical methods and automated pattern recognition
methods. The statistical group of methods normally features
the application of Bayes Rule in various ways to predict the
probability of authorship; yet non-Bayesian statistical analyses
have also been done by setting weights to different features.
Statistical grouping techniques such as cluster analysis have
proven to be useful by seeking to form clusters of individuals
such that individuals within a cluster are more similar in some
sense than individuals from other clusters. As aforementioned,
we use two models to produce a comparative study on author-
ship identification task in Bengali. In this section, we briefly
discuss the functionalities of two models: statistical similarity
model and machine learning model.
A. Statistical similarity based model
Three well-known statistical similarity based metrics are
used to get their individual effect on classifying documents,
and their combined effort has also been compared with the
others. These three measures are highlighted briefly in this
section.
1) Cosine-Similarity (COS): Cosine-similarity is a measure
of similarity between two vectors of n dimensions by finding
the cosine of the angle between them. It is often used to
compare documents in text mining. Given two vectors R and
T with same number of attributes, the cosine similarity is
represented using a dot product and magnitude as:
Similarity(R, T ) = cos(θ) =
R.T
|R|.|T |
=
∑
n
i=1
ri.ti
√
∑
n
i=1
r2
i
×
√
∑
n
i=1
t2
i
(1)
The resulting similarity ranges from -1 meaning exactly
opposite, to 1 meaning exactly the same, with 0 usually
indicating independence, and in-between values indicating
intermediate similarity or dissimilarity.
2) Chi-Square measure (CS): Chi-square is a statistical test
commonly used to compare observed data with the expected
data according to a specific hypothesis. That is, chi-square
(χ2) is the sum of the squared differences between observed
(O) and the expected (E) data (or the deviation, d), divided
by the expected data in all possible categories.
χ2 =
n
∑
i=1
(Oi − Ei)
2
Ei
(2)
Here, the mean of each cluster is used as the observation
data for that cluster and used as reference O. n is the number
of features and Oi is the observed value of the ith feature. The
Chi Square test gives a value of χ2 that can be converted to
Chi Square (c2) using chi-square table which is an n×n matrix
with row representing the degree of freedom (i.e., difference
between number of rows and columns of the contingency
matrix) and column representing the probability we expect.
This can be used to determine whether there is a significant
difference from the null hypothesis or whether the results
support the null hypothesis. After comparing the chi-squared
value in the cell with our calculated χ2 value, if the χ2 value is
greater than the 0.05, 0.01 or 0.001 column, then the goodness-
of-fit null hypothesis can be rejected, otherwise accepted.
3) Euclidean Distance (ED): The Euclidean distance be-
tween two points, p and q is the length of the line seg-
ment. In Cartesian coordinates, if p = (p1, p2, ..., pn) and
q = (q1, q2, ..., qn) are two points in Euclidean n-space, then
the distance from p to q is given by:
d(p, q) =
√
√
√
√
n
∑
i=1
(pi − pi)2 (3)
The position of a point in a Euclidean n-space is a Euclidean
vector. So, p and q are Euclidean vectors, starting from the
origin of the space, and their tips indicate two points.
B. Machine Learning model
1) Decision Trees (DT): Decision trees are rule based, ex-
plicit learners. It is a decision support tool that uses a tree-like
graph or model of decisions and their possible consequences.
Two decision trees are made to learn the styles of the authors.
Text categorization uses decision trees extensively, but they
have not been used in author identification. Due to their rule-
based nature, it is easy to read and understand a decision tree.
Thus, it is possible to “see the style” in the texts with these
trees. Also, the results indicate that the unconventional features
we used are quite useful in classification of the authors.
2) Neural Networks (NN): Neural networks are powerful
pattern matching tools. They are basically very complex
non-linear modeling equations. They are especially good in
situations where the “concept” to be learned is very difficult
to express as a well-defined, simple formulation; but rather is
a complex, highly interrelated function of the inputs which is
usually not easily transparent. This feature makes them ideal
to learn a concept like “style” which is inherently intangible.
The network takes all input attributes into consideration si-
multaneously, though some are more heavily weighted than
others. This differs from decision tree construction in that the
style of an author is taken to be the joint product of many
different features. Artificial Neural Network has the ability to
invent new features that are not explicit in the input, yet it
also has the drawback that its inductive rules are inaccessible
to humans.
3) Support Vector Machine (SVM): The concept of Support
Vector Machine was developed by Vapnik [17]. Let us suppose
we have a given set of l samples distributed in Rn space, where
n is the dimensionality of the sample space, and for each xi
sample, there is an associated label yi ∈ {−1, 1}. This sample
space can be described by a hyper plane separating the samples
according to their label. This hyper plane can be modeled
using only a few samples from the sample space, namely the
support vectors. So training an SVM is simplified to identify
the support vectors within the training samples. After that, a
decision function written below can be used to predict the
label for a given unlabeled sample.
f(x) =
∑
i
αi.yi.k(x.xi) + b (4)
The function parameters αi and b are found by quadratic
programming, x is the unlabeled sample and xi is a support
vector. The function K(x, xi) is known as kernel function and
maps the sample space to a higher dimension. In this way,
samples that are not linearly separable in the higher dimen-
sional space can become linearly separable. Although there
are several kernel functions applicable to different applications
namely Linear, Polynomial, Gaussian, Tangent Hyperbolic
etc, we use polynomial kernel function. Though SVM was
initially best reported as binary classification model, it can
be well tuned to fit into multi-class classification problem
using one-to-one or one-to-all model. In this study, one-
to-one classification approach for classification followed by
combined voting for class disambiguation have been used for
final mapping between the articles and authors.
IV. PROPOSED METHODOLOGY
As mentioned, the proposed stylistic markers used in this
study take full advantage of the analysis of the distributed
contextual clues as well as full analysis by Natural Language
Processing tools. The system architecture of the proposed sty-
lometry detection system is shown in Figure 1. In this section,
we first describe brief properties of different components of
the system architecture and then analytically present the set of
stylistic features.
Bengali Corpus                     Cleaned Corpus
                       Pre−processing
                      Parsed Corpus
           Bengali
            Shallow
         Parser
         Feature Extraction
Training
Model
Testing
Model
                  Classification Model
              Classification
Author R Author A Author O 
Fig. 1. Proposed system architecture
A. Textual analysis
Basic pre-processing before actual textual analysis is re-
quired so that stylistic markers are clearly viewed to the
system for further analysis. Token-level markers discussed
in the next subsection are extracted from this pre-processed
corpus. Bengali Shallow parser1 has been used to separate the
sentence and the chunk boundaries and to identify parts-of-
speech of each token. From this parsed text, chunk-level and
context-level markers are also demarcated.
B. Stylistic features extraction
Author attribution of documents —the most popular use of
author recognition using stylometry—usually involves attribut-
ing an author to a document when there is some doubt about
its authorship. This usually involves proving (or disproving)
that the document was written by a particular author (to
whom it has previously been attributed to) [11]. At times, this
also would involve deciding between two authors. So, usually
author recognition is done to learn the style of one (or two)
author(s). This is inherently different from learning the styles
of a number of authors (or in “learning the style”) because
in case of one (or two) authors, the list of features chosen
may simply represent the authors’ particular idiosyncrasies.
However, these may not be in general good features that can
be taken to be representative of authors’ style. There is no
consensus in the discipline as to what characteristic features
to use or what methodology or techniques to apply in standard
research, which is precisely the greatest problem confronting
stylometry. Rudman (1997) [13] claimed that there is no
clear agreement on which style markers are significant. Many
1http://ltrc.iiit.ac.in/analyzer/bengali
TABLE I
SELECTED FEATURES USED IN THE CLASSIFICATION MODEL
No. Feature Explanation Normalization
To
ke
n
L
ev
el
1. L(w) Avg. length of the word Avg. len.(word)/ Max len.(word)
Intersection of the keywords
2. KW1 of cluster 1 and the given |KW (doc)
⋂
KW (cluster1)|
document
Intersection of the keywords
3. KW2 of cluster 2 and the given |KW (doc)
⋂
KW (cluster2)|
document
Intersection of the keywords
4. KW3 of cluster 3 and the given |KW (doc)
⋂
KW (cluster3)|
document
5. HL Hapex Legomena (No of count(HL)/count(word)
words with frequency=1)
6. Punc. No of punctuations count(punc)/count(word)
P
hr
as
e
L
ev
el 7. NP Detected Noun Phrase count(NP)/count of all phrase
8. VP Detected Verb Phrase count(VP)/count of all phrase
9. CP Detected Conjunct Phrase count(CP)/count of all phrase
10. UN Detected unknown word count(POS)/count of all phrase
11. RE Detected reduplications count(RDP+ECHO)/count of
and echo words all phrase
P
hr
as
e
L
ev
el 12. Dig Number of the dialogs Count(dialog)/ No. of
sentences
13. L(d) Avg. length of the dialog Avg. words per dialog/ No. of
sentences
14. L(p) Avg. length of the Avg. words per para/ No. of
paragraph sentences
different kinds of tests have been proposed for use in author
identification. Angela Glover (1996) [8] gave a comprehensive
table of the features that took into account all kinds of textual
information very tactfully. In this experiment, we use stylistic
features; some of them (hapex legomena, punctuations) are
considered beyond constructional properties of a text that
could finely reflect the subconscious mind of the authors.
Stylistic features have been proposed as more reliable
style markers than for example, word-level features since the
stylistic markers are sometime not under the conscious control
of the author. To allow the selection of the linguistic features
rather than n-gram terms, robust and accurate text analysis
tools such as lemmatizers, part-of-speech (POS) taggers, chun-
kers etc are needed. We have used the Shallow parser, which
gives a parsed output of a raw input corpus. It tokenizes the
input, performs a part-of-speech analysis, looks for chunks,
inflections and a number of other grammatical relations. The
stylistic markers which have been selected in this experiment
are discussed in Table I.
The selected features (the feature vector) are coarsely classi-
fied into three categories, i.e., (1) token-level, (2) phrase-level
and (3) context-level. Token level features constitute trivial
characteristics of row text including length of the word, num-
ber of common keywords corresponding to each of the three
considered clusters, count of hapax legomena i.e., the words
appearing single time in a document (it is one of the rarest
features used so far in any study) and punctuations. Phrase-
level features include count of selected POSs and chunks from
the parsed corpus. Context level features consist of count of the
conversations, average length of the dialog and average length
of the paragraph. Sentences are generally separated by birama
symbols like ‘dari’ (|), question marks (‘?’) or exclamation
notation (‘!’) in Bengali. Sentence-length, word-count are the
traditional and well-established features in authorship attribute
studies. However, the problem occurs when identifying key-
words of individual clusters2 as there is no standard tool to
extract keywords for Bengali documents. For this, we have
identified top fifty high frequent words (excluding stop-words
in Bengali) for every cluster using TF ∗ IDF 3 method which
act as the list of keywords of that cluster corresponding to that
author. Then a list of top fifty high frequent words (excluding
stop-words) from a testing document are extracted, and in-
tersecting them with the keywords of cluster 1, cluster 2 and
cluster 3 yield the count of the features KW1, KW2 and KW3
respectively. Note that, all the features are normalized to make
the system independent of document length. Since Shallow
parser is an automated text-processing tool, the style markers
of the above levels are measured approximately. Depending
on the complexity of the text, the provided measures may
vary from real values which can only be measured using
manual intervention. Making the system fully automated, the
system fully believes on the performance of the parser for the
extraction of all POS and chunk level features. It is reasonable
that stylometers would not agree on the characteristic features
to be analyzed in stylometry. Human languages are subtle, with
many unquantifiable yet salient qualities. Idiolects, moreover,
complicate the picture by highlighting particular features that
are not shared by the whole language community. Individual
studies on specific authors, understandably, rely on completely
2“Clusters” means groups of writings of the authors; here we have used
three clusters.
3TF ∗IDF of the term t in document d = TF ∗IDF (t, d) = count(t)
|d|
×
log( |D|
nt
), where |d|=no. of tokens in document d, |D|=no. of the documents
in the cluster, nt =no of documents where term t is present.
different measures to identify an author.
C. Building classification model
A number of discriminative models as discussed in section
III based on statistical and machine learning measures are
incorporated in this study. The cause of adapting these models
together in a single study is to compare their individual
significance in Bengali language. As the study of stylometry in
Bengali language has enough scope of exploration, the effect
of individual features in a single module and across modules
are worthwhile for further research.
The See5 package by Quinlan4 is used in this experiment to
generate decision trees, which extends the basic ID3 algorithm
of Quinlan. It infers decision trees by growing them from the
root downward, greedily selecting the next best attribute for
each new decision branch added to the tree. Thus, decision
tree learning differs from other machine learning techniques
such as neural networks, in that attributes are considered
individually rather than in connection with one another. The
feature with the greatest information gain is given priority
in classification. Therefore, decision trees should work very
well if there are some salient features that distinguish one
author from the others. Neuroshell - the commercial software
package5 created by the Ward Systems Group, Inc. which is a
package that creates and runs various types of neural networks,
was used for neural network model in this experiment. We
have deployed SVM that performs classification by construct-
ing an n-dimensional hyperplane and optimally separates data
into two categories. Our general classification system includes
two main phases: training and classification. The training
has been carried out by YamCha6 toolkit, an SVM based
tool for detecting classes in documents and formulating the
authorship identification task as a sequential labeling problem.
For classification, we have used TinySVM- 0.077 classifier that
seems to be the best optimized among publicly available SVM
toolkits. Here, the pairwise multi-class decision method and
the polynomial kernel function have been used.
V. EXPERIMENTAL RESULTS
A. Corpus
Resource acquisition is one of the challenging obstacles to
work with electronically resource constrained languages like
Bengali. However, this system has used 150 stories in Bengali
written by the noted Indian Nobel laureate Rabindranath
Tagore8. We choose this domain for two reasons: firstly, in
such writings the idiosyncratic style of the author is not
likely to be overshadowed by the characteristics of the cor-
responding text-genre; secondly, in the previous research [3],
the author has worked on the corpus of Rabindranath Tagore
to explore some of the stylistic behaviors of his documents.
To differentiate them from other authors articles, we have
selected 150 articles of Sarat Chandra Chottopadhyay and 150
4http://www.rulequest.com/see5-info.html
5http://www.neuroshell.com/
6http://chasen-org/ taku/software/yamcha/
7http://cl.aist-nara.ac.jp/taku-ku/software/TinySVM
8http://www.rabindra-rachanabali.nltr.org
articles9 of a group of other authors (excluding previous two
authors) of the same time period . We divide 100 documents
in each cluster for training and validation purpose and rest for
testing. In this way, we get three clustered documents called
as articles of Author R (cluster 1), Author A (cluster 2) and
Author O (cluster 3). The statistics of the entire dateset is
tabulated in Table II. Statistical similarity based measures use
all 100 documents for making representatives of the clusters.
In machine learning models, we use 10-fold cross validation
method discussed later for better constructing the validation
and testing submodules. This paper focuses on two topics: (a)
the effort of many authors on feature selection and learning
and (b) the effort of limited data in authorship detection.
TABLE II
STATISTICS OF THE USED DATASET
Clusters Authors No. of No. of No. of
documents tokens unique tokens
Rabindranath
Cluster 1 Tagore 150 6,862,580 4,978,672
(Author R)
Sarat Chandra
Cluster 2 Chottopadyhay 150 4,083,417 2,987,450
(Author A)
Cluster 3 Others 150 3,818,216 2,657,813
(Author O)
B. Baseline system (BL)
In a review paper [7], the author asserted that: “... yet, to
date, no stylometrist has managed to establish a methodology
which is better able to capture the style of a text than based
on lexical items.” In order to set up a baseline system, we,
therefore, use traditional lexically-based methodology called
vocabulary richness. Among the various measures like Yules
K measure, Honores R measure, we have taken most typical
one as the type-token ratio (V/N), where V is the size of the
vocabulary of the sample text and N is the number of tokens
which forms the simple text. We gather dimensional features
of the articles of each cluster and average them to create a
representative vector for every cluster. Now, for every testing
document, similar features are extracted and a test vector of
features is prepared. By using nearest-neighbor algorithm, the
baseline system tries to map the each of testing documents
to one author. The results of the baseline system are depicted
using confusion matrix in Table III. The rows indicate actual
authors and the columns indicated authors identified by the
system. The diagonal elements denote the correct classifica-
tion. Each row contains classification of the 50 test documents
of the corresponding authors. The baseline system achieves
44% average accuracy which is quite promising considering
the simplicity of the system.
C. Performance of statistical similarity measures
We have discussed earlier that our statistical classification
model is based on three similarity measures. A voting ap-
proach combining the decision of the three models for each test
9http://banglalibrary.evergreenbangla.com/
TABLE III
CONFUSION MATRIX OF BASELINE SYSTEM (CORRECT MAPPINGS ARE
ITALICIZED DIAGONALLY)
Baseline System
R A O error (in%)
R 26 14 10 48%
A 17 21 12 58%
O 16 20 14 72%
Avg. error 56%
document have also been measured for expecting better results.
The confusion matrices in Table IV show that chi-square
measure is relatively less error prone (35.3%) compared to
other measures. A majority voting technique has an accuracy
of 67.3% which is relatively better than others. In case where
combined voting has not reached to the maximum consensus,
the result of chi-square measure has been granted as a final
result since it has given better accuracy compared to the others
also on the development set.
D. Performance of machine learning models
In this subsection, we analyze the performance of three
machine learning models separately. Since the attributes tested
are continuous, all the decision trees are constructed using the
fuzzy threshold parameter, so that the knife-edge behavior for
decision trees is softened by constructing an interval close
to the threshold. For neural network, many structures of the
multilayer network were experimented with before we came
up with our best network. Backpropogation feed forward
networks yield the best result with the following architecture:
14 input nodes, 8 nodes on the first hidden layer, 6 nodes
on the second hidden layer, and 6 output nodes (to act as
error correcting codes). Two output nodes are allotted to a
single author (this increases the Hamming distance between
the classifications - the bit string that is output with each bit
corresponding to one author in the classification- of any two
authors, thus decreasing the possibility of misclassification).
Out of 100 training samples, 30% are used in the validation
set which determines whether over-fitting has occurred and
when to stop training. It is worth noting that the reported
results are the average of 10-fold cross validations. We will
discuss the comparative results of individual cross validation
phase in the next section. Table V reports the error rate of
individual model in three confusion matrices. At a glance, ma-
chine learning approaches especially SVM (83.3% accuracy)
perform tremendously well compared to the other models.
E. Comparative analysis
The performance of any machine learning tool highly de-
pends on the population and divergence of training samples.
Limited dataset can overshadowed the intrinsic productivity
of the tool. Because of the lack of large number of dataset,
we divide the training data randomly into 10 sets and use 10-
fold cross validation technique to prevent overfitting for each
machine learning model. The boxplot in Figure 2(a) reports the
performance of each model on 10-fold cross validation phrase
with mean accuracy and variance. In three cases, since the
notches in the box plots overlap, we can conclude, with certain
confidence, that the true medians do not differ. The outliers
are marked separately with the dotted points. The difference
between lower and upper quartiles in SVM is comparatively
smaller than the others that shows relative low variance of
accuracies in different iterations.
We also measure the pairwise agreement in mapping three
types of authors using Cohen’s Kappa coefficient [4]. Cohen’s
kappa measures the agreement between two raters each of
them classify N items into C mutually exclusive categories.
The equation of this measure in as follows:
κ =
Pr(a)− Pr(e)
1− Pr(e)
(5)
where Pr(a) is the relative observed agreement among raters,
and Pr(e) is the hypothetical probability of chance agreement,
using the observed data to calculate the probabilities of each
observer randomly saying each category. If the raters are in
complete agreement then κ=1. If there is no agreement among
the raters other than what would be expected by chance (as
defined by Pr(e)), κ=0. In Figure 2(b), the high correlation
between Decision Tree and Neural Network models, which
is considerably high compared to the others signifies that the
effects of both of these models in author-document mapping
task are reasonably identical and less efficient compared to
SVM model.
           
 
 
 
   
 
 
 
  
0.65
0.7
0.75
A
vg
. i
nt
er
−
m
od
el
 a
gr
ee
m
en
t
(b)
72
74
76
78
80
82
84
A
ve
ra
ge
 a
cc
ur
ac
y 
(in
 %
)
(a)
DT vs. SVMDT vs. NNSVMDT NN vs. SVMNN
Fig. 2. (a) Boxplot of average accuracy (in %) of three machine learning
modules on 10-fold cross validations; (b) pair-wise average inter-model
agreement of the models using Cohen’s Kappa measure.
L(w) KW1 KW2 KW3 HL Punc. NP VP CP UN RE Dig L(d) L(p)  
 
60
 
 
60
 
60
 
Dropped features
V
ar
ia
tio
n 
of
 a
cc
ur
ac
y
 
 
DT
SVM
NN
Fig. 3. (Color online) Average accuracy after deleting features one at a
time (the magnitude of the error bar indicates the difference of the accuracies
before and after dropping one feature for each machine learning model).
TABLE IV
CONFUSION MATRICES OF STATISTICAL SIMILARITY MEASURES ON TEST SET
Statistical similarity models
Cosine similarity Chi-square measure Euclidean distance Majority voting
(COS) (CS) (ED) (COM)
R A O error (in%) R A O error (in%) R A O error (in%) R A O error (in%)
R 30 12 8 40 34 9 7 32 27 15 8 46 34 7 9 28
A 15 27 8 46 14 30 6 40 18 26 6 48 11 32 7 36
O 12 9 29 42 9 8 33 34 17 6 27 46 6 11 33 34
Avg. error 42.7 Avg. error 35.3 Avg. error 46.6 Avg. error 32.7
TABLE V
CONFUSION MATRICES OF MACHINE LEARNING MODELS ON TEST SET (AVERAGED OVER 10-FOLD CROSS VALIDATIONS)
Machine Learning models
Decision Tree Neural Networks Support Vector Machine
R A O error (in%) R A O error (in%) R A O error (in%)
R 35 8 6 28 38 9 3 24 44 3 3 12
A 7 37 6 26 10 35 5 30 8 40 2 20
O 6 5 39 22 9 5 36 28 2 7 41 18
Avg. error 25.3 Avg. error 27.3 Avg. error 16.7
BL COS CS ED COM DT NN SVM
0
10
20
30
40
50
Different models
E
rr
or
 r
at
e
 
 
Author R
Author A
Author O
Fig. 4. (Color online) Error analysis: percentage of error occurs due to wrong
identified authors.
As a pioneer of studying different machine learning models
in Bengali authorship task, it is worth measuring the relative
importance of individual feature in each learning model that
gets some features high privilege and helps in feature ranking.
We have dropped each feature one by one and pointed out
its relative impact on accuracy over 10-fold cross validations.
The points against each feature in the line graphs in Figure 3
show percentage of accuracy when that feature is dropped,
and the magnitude of the corresponding errorbar measures the
difference between final accuracy (when all features present)
and accuracy after dropping that feature. All models rely on
the high importance of length of the word in this task. All of
them also reach to the common consensus of the importance
of KW1, KW2, KW3, NP and CP. But few of the features
typically perform unpredictable behavior in different models.
For instance, length of the dialog and unknown word count
show larger significance in SVM, but they are not so significant
in other two models. Similar characteristics are also observed
in Decision tree and Neural network models. This rigorous
testing definitely prevents the future experiments of taking
insignificant features depending upon the used model.
Finally, we study the responsibility of individual authors
for producing erroneous results. Figure 4 depicts that almost
in every case, the system has little overestimated the authors
of documents as author R. It may occur due to the acquisition
of documents because the documents in cluster 2 and cluster
3 are not so diverse and well-structured as the documents of
Rabindranath Tagore. Developing appropriate corpus for this
study is itself a separate research area specially when dealing
with learning modules, and it takes huge amount of time. The
more the focus will be on this language, the more we expect
to get diverge corpus of different Bengali writers.
VI. CONCLUSION AND FUTURE WORK
This paper attempts to recognize three authors in Bengali
literature based on their style of writing (without taking into
account the author’s profile, genre or writing time). We have
incorporated both statistical similarity based measures and
three machine learning models over same feature sets and
compared them with the baseline system. All of the machine
learning models especially SVM yield a significantly higher
accuracy than other models, which shows that the assumption
is well justified that there is a quantifiable unconscious aspect
in an authors style. We achieved 74.7%, 72.7% and 83.3%
accuracy on the test set using Decision Trees, Neural Networks
and SVM respectively. Although the SVM yielded a better
numerical performance, and are considered inherently suitable
to capture an intangible concept like style, the decision trees
are human readable making it possible to define style. Most
of the previous studies of stylometry analysis in other lan-
guage input a large number of attributes. While more features
could produce additional discriminatory material, the present
study proves that artificial intelligence provides stylometry
with excellent classifiers that require fewer and relevant input
variables than traditional statistics. We also showed that the
significance of the used features in authorship identification
task are relative to the used model. This preliminary study
is the journey to reveal the intrinsic style of writing of the
Bengali authors based upon which we plan to build more
robust, generic and diverge authorship identification tool.
REFERENCES
[1] Argamon, Shlomo and Marin Šarić and Sterling S. Stein, Style mining of
electronic messages for multiple authorship discrimination: first results,
Proceedings of the ninth ACM SIGKDD international conference on
Knowledge discovery and data mining, pp. 475–480, 2003.
[2] Chanda, Sukalpa, Franke, Katrin, Pal, Umapada and Wakabayashi, Tet-
sushi, Text Independent Writer Identification for Bengali Script, Proceed-
ings of the 2010 20th International Conference on Pattern Recognition,
ICPR, pp. 2005–2008, IEEE Computer Society, Washington, DC, USA,
2010.
[3] Chakaraborty, Tanmoy and Sivaji Bandyopadhyay, Inference of Fine-
grained Attributes of Bengali Corpus for Stylometry Detection, Polibits,
pp. 79–83, 2011.
[4] Cohen, Jacob., A Coefficient of Agreement for Nominal Scales, Educa-
tional and Psychological Measurement, 20(1), 1960.
[5] Croft, D.J., Book of Mormon ‘word prints’ reexamined, Stone Publishers
(6), pp. 15–22, 1981.
[6] Das, Suprabhat and Mitra, Pabitra, Author identification in Bengali
literary works, Proceedings of the 4th international conference on Pattern
recognition and machine intelligence, PReMI’11, pp. 220–226, Springer-
Verlag, 2011.
[7] David Holmes, Review: Attributing Authorship: An Introduction, LLC,
19(4), pp. 528–530, 2004.
[8] Glover, Angela and Graeme Hirst, Detecting Stylistic Inconsistencies in
Collaborative Writing, pp. 147–168, Springer-Verlag, 1995.
[9] Krippendorff, K., Content Analysis: An Introduction to Its Methodology,
SAGE Publications, 2003.
[10] Malyutov, M. B., Authorship attribution of texts: a review, Ahlswede,
Rudolf and Bäumer, Lars and Cai, Ning and Aydinian, Harout and
Blinovsky, Vladimir,pp. 362–380, Springer-Verlag, 2006.
[11] Merriam, T., Heterogeneous authorship in early Shakespeare and the
problem of Henry V., Literary and Linguistic Computing, 13(1), pp. 15–
27, 1998.
[12] Pavelec, Daniel, Justino, Edson J. R. and Oliveira, Luiz S., Author
Identification using Stylometric Features, Inteligencia Artificial, Revista
Iberoamericana de Inteligencia Artificial, 36(11), pp. 59–66, 2007.
[13] Rudman, Joseph., The State of Authorship Attribution Studies: Some
Problems and Solutions, Computers and the Humanities, 31(4), pp. 351–
365, Springer Netherlands, 1997.
[14] Stamatatos E. and N. Fakotakis and G. Kokkinakis, Automatic author-
ship attribution, Proceedings of the ninth conference on European chapter
of the Association for Computational Linguistics, pp. 158–164, 1999.
[15] Stamatatos, E., Kokkinakis, George and Fakotakis, Nikos, Automatic text
categorization in terms of genre and author, Comput. Linguist., 26(4),pp.
471–495, 2000.
[16] Efstathios Stamatatos, A survey of modern authorship attribution meth-
ods, Journal of the American Society of Information Science and Tech-
nology,60(3), pp. 538–556, John Wiley & Sons, Inc., New York, NY,
USA, 2009.
[17] Vapnik, Vladimir N., The nature of statistical learning theory, Springer-
Verlag New York, Inc., New York, NY, USA, 1995.
[18] Zhang, Tong, Fred Damerau and David Johnson, Text Chunking based
on a Generalization of Winnow, Journal of Machine Learning Research,
pp. 615–637, 2002.
Tanmoy Chakraborty is currently a Google India
Ph.D Scholar in Indian Institute of Technology,
Kharagpur, India. He received his B. Tech. degree
in Computer Science and Engineering from Kalyani
Government Engineering College, Kalyani, India in
2009 and M.E. in Computer Science and Engi-
neering from Jadavpur University, Kolkata, India in
2011. His current research interests include Complex
Network, Web Mining, Natural Language Processing
and Artificial Intelligence.
