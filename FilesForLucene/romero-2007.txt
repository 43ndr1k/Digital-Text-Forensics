Computer Assisted Transcription for Ancient Text
Images
Verónica Romero1, Alejandro H. Toselli1, Luis Rodrı́guez2, and Enrique Vidal1
1 Instituto Tecnológico de Informática
Universidad Politécnica de Valencia
Camı́ de Vera s/n, 46022 València (Spain)
{vromero,ahector,evidal}@iti.upv.es
2 Departamento de Sistemas Informáticos
Universidad de Castilla La Mancha. Spain
luisr@info-ab.uclm.es
Abstract. Paleography experts spend many hours transcribing ancient docu-
ments and state-of-the-art handwritten text recognition systems are not suitable
for performing this task automatically. We propose here a new interactive, on-
line framework which, rather than full automation, aims at assisting the experts
in the proper recognition-transcription process; that is, facilitate and speed up
the transcription of old documents. This framework combines the efficiency of
automatic handwriting recognition systems with the accuracy of the experts,
leading to a cost-effective perfect transcription of ancient manuscripts.
Keywords: Automatic Transcription of Ancient Documents, Computer Assisted
transcription, handwritten text image recognition.
1 Introduction
The increasing number of on-line digital libraries publishing a large quantity of digi-
tized legacy documents makes also necessary to transcribe these document images, in
order to provide historians and other researchers new ways of indexing, consulting and
querying these documents.
These transcriptions are usually carried out by experts in paleography, who are spe-
cialized in reading ancient scripts, characterized, among other things, by different hand-
written/printed styles from diverse places and time periods. How long experts takes to
make a transcription of one of these documents depends on their skills and experience.
For example, to transcribe many of the pages of the document used in the experiments
reported in sections 4.1, they would spend several hours per page.
On the other hand, up-to-date handwritten text recognition systems (HTR) cannot
substitute the experts in this task, because there are no efficient solutions to perform an
automatic ancient document transcription with a good accuracy. The difficulties to seg-
ment text lines, the variability of the handwriting, the complexity of the styles and the
open vocabulary explain most of the issues encountered by these recognition systems.
M. Kamel and A. Campilho (Eds.): ICIAR 2007, LNCS 4633, pp. 1182–1193, 2007.
c© Springer-Verlag Berlin Heidelberg 2007
Computer Assisted Transcription for Ancient Text Images 1183
An interactive on-line scenario can allow for a more effective approach. Here, the
automatic HTR system and the human transcriptor cooperate to generate the final tran-
scription of the text line images. The rationale behind this approximation is to combine
the accuracy provided by the human transcriptor with the efficiency of the HTR sys-
tem. This approach is called “Computer Assisted Transcription of Handwritten Text
Images” (CATOTI) in this article. It follows similar ideas as those previously applied
to computer assisted translation (CAT) [1,2,3], and computer assisted speech transcrip-
tion (CATS) [4,5], where experiments have shown that these kind of systems can save
significant amounts of human effort.
The HTR system employed here is based on Hidden Markov Models (HMMs) [6],
in the same way as in the current speech recognition systems [7]. The most important
difference is that the input feature vector sequence of the HTR system represents a
handwritten text line image, rather than an acoustic speech signal.
This paper is divided as follows. First, the CATOTI framework is introduced in sec-
tion 2 and formalized in section 2.1. An initial implementation is described in sec-
tion 2.3. Then, a general description of the HTR system used is given in section 3.
The experiments and results are commented in section 4. Finally, some conclusions are
drawn in the section 5.
2 Foundations of CATOTI
This section overviews our approach to CATOTI. As illustrated in figure 1, the process
starts when the HTR system proposes a full transcription ŝ (or a set with N-best tran-
scriptions) of a suitable segment of the feature vectors sequence x, extracted from a
handwritten text line image (see section 3). Then, the human transcriptor (named user
from now on) reads this transcription until he or she finds a mistake; i.e, he or she vali-
dates a prefix ŝp of the transcription which is error-free. Now, the user can enter a word
(or words), c, to correct the erroneous text that follows the validated prefix. This action
produces a new prefix p (the previously validated prefix, ŝp, followed by c). Then, the
system takes into account the new prefix to suggest a suitable continuation (or a set of
best possible continuations) to this prefix (i.e., a new ŝ), thereby starting a new cycle.
This process is repeated until a correct, full transcription t of x is accepted by the user.
A key point in this interactive process is that, at each user-system iteration, the system
can take advantage of the prefix validated so far to attempt an improved prediction.
2.1 Formal Framework
The traditional handwritten text recognition problem can be formulated as the problem
of finding a most likely word sequence, ŵ, for a given handwritten sentence image
represented by a feature vector sequence x, i. e., ŵ = argmaxw Pr(w|x). Using the
Bayes’ rule we can decompose the probability Pr(w|x) into two probabilities, Pr(x|w)
and Pr(w), representing morphological-lexical knowledge and syntactic knowledge,
respectively:
ŵ = argmax
w
Pr(w|x) = argmax
w
Pr(x|w) · Pr(w) . (1)
1184 V. Romero et al.
x
INTER-0 (p) ()
(ŝ) (antiguos y gas que en el castillo sus llamadas )
(ŝp) (antiguos)
INTER-1 (c) (ciudadanos)
(p) (antiguos ciudadanos)
(ŝ) (que en el castillo sus llamadas )
(ŝp) (que en)
INTER-2 (c) (castilla)
(p) (antiguos ciudadanos que en castilla)
(ŝ) (se llamaban )
FINAL (c) (#)
(p ≡ t) (antiguos ciudadanos que en castilla se llamaban )
Fig. 1. Example of CATOTI operation. Starting with an initial recognized hypothesis ŝ, the user
validates its longest well-recognized prefix ŝp and corrects the following erroneous word c; next,
the validated prefix p (c concatenated to ŝp) is submitted as additional help information to the
recognition system, which based on this emits a new recognized hypothesis ŝ. This process goes
on until the final error-free transcription t is obtained. Underlined boldface words in the final
transcription are those which were corrected by user.
Pr(x|w) is typically approximated by concatenated character models (usually hidden
Markov models [8,7]) and Pr(w) is approximated by a word language model (usually
n-grams [8]).
In the CATOTI framework, in addition to the given feature sequence, x, a prefix p
of the transcription (validated and/or corrected by the user) is available and the HTR
should try to complete this prefix by searching for a most likely suffix ŝ as:
ŝ = argmax
s
Pr(s|x, p) = arg max
s
Pr(x|p, s) · Pr(s|p) . (2)
Equation (2) is very similar to (1), being w the concatenation of p and s. The main
difference is that now p is given. Therefore, the search must be performed over all
possible suffixes s of p and the language model probability Pr(s|p) must account for
the words that can be written after the prefix p.
In order to solve equation (2), the signal x can be considered split into two fragments,
xb1 and x
m
b+1, where m is the length of x. By further considering the boundary point b
as a hidden variable in (2), we can write:
ŝ = arg max
s
∑
1≤b≤m
Pr(x, b|s, p) · Pr(s|p) . (3)
We can now make the naive (but realistic) assumption that xb1 does not depend on
the suffix and xmb+1 does not depend on the prefix, to rewrite (3) as:
ŝ ≈ argmax
s
∑
1≤b≤m
Pr(xb1|p) · Pr(xmb+1|s) · Pr(s|p) . (4)
Computer Assisted Transcription for Ancient Text Images 1185
Finally, the sum over all the possible segmentations can be approximated by the domi-
nating term, leading to:
ŝ ≈ argmax
s
max
1≤b≤m
Pr(xb1|p) · Pr(xmb+1|s) · Pr(s|p) . (5)
This optimization problem entails finding an optimal boundary point, b̂, associated
with the optimal suffix decoding, ŝ. That is, the signal x is actually split into two seg-
ments, xp =xb̂1 and xs =xmb̂+1. Therefore, the search for the best transcription suffix that
completes a prefix p can be performed just over segments of the signal corresponding to
the possible suffixes and, on the other hand, we can take advantage of the information
coming from the prefix to tune the language model constraints modelled by Pr(s|p).
This is discussed in the next subsections.
2.2 Adapting the Language Model
Perhaps the simplest way to deal with Pr(s|p) is to adapt an n-gram language model to
cope with the consolidated prefix. Given that a conventional n-gram models the prob-
ability Pr(w) (where w is the concatenation of p and s, i.e the whole sentence), it is
necessary to modify this model to take into account the conditional probability Pr(s|p).
As discussed in [4], assuming an n-gram model for Pr(w) leads to the following de-
composition:
Pr(s|p) 
k+n−1∏
i=k+1
Pr(wi|wi−1i−n+1) ·
l∏
i=k+n
Pr(wi|wi−1i−n+1) . (6)
where the consolidated prefix is wk1 = p and w
l
k+1 = s is a possible suffix. The first
term of (6) accounts for the probability of the n−1 words of the suffix, whose probability
is conditioned by words from the validated prefix, and the second one is the usual n-
gram probability for the rest of the words in the suffix.
2.3 Searching
In this section, a possible implementation of a CATOTI decoder is described. In the first
iteration of the CATOTI process, p is empty. Therefore, the decoder has to generate a
full transcription of x as shown in equation (1). Afterwards, the user-validated prefix
p has to be used to generate a suitable continuation s in the following iterations of the
interactive-transcription process.
As discussed in [4], we can explicitly rely on equation (5) to implement a decoding
process in one step, as in conventional HTR systems. The decoder should be forced
to match the previously validated prefix p and then continue searching for a suffix ŝ
according to the constraints (6). This can be achieved by building a special language
model which can be seen as the “concatenation” of a linear model which strictly ac-
counts for the successive words in p and the “suffix language model” (6). An example
of this language model is shown in figure 2.
Owing to the finite-state nature of this special language model, the search involved
in equation (5) can be efficiently carried out using the well known Viterbi algorithm [8].
1186 V. Romero et al.
Training samples (L)
de la edad media
de edad media
de la epoca media
de la epoca actual
de la actual
de actual
Prefix (LP ) = en la
Original Bigram (L)
de la la
media
actualepoca
edad media
actual
m
ed
ia
epoca
eda
d
de
edad
actual
Model for the Prefix (Lp)
en la laen
Final Combined Model (LpLs)
en la la
media
actualepoca
edad media
actual
m
ed
ia
epoca
eda
d
en
Fig. 2. Example of a CATOTI dynamic language model building. First, an n-gram (L) for the
training set of the figure is built. Then, a linear model (Lp) which accounts for the prefix “en la”
is constructed. Finally, these two models are combined into a single model (LpLs) as shown.
Apart from the optimal suffix decoding, ŝ, a correspondingly optimal segmentation of
the x is then obtained as a byproduct.
It should be noted that a naive Viterbi adaptation to implement these techniques
would lead to a computational cost that grows quadratically with the number of words
of each sentence. However, using word-graph techniques similar to those described
in [3] for Computer Assisted Translation, very efficient, linear cost search can be easily
achieved.
3 HTR System Overview
The HTR system used here follows a classical architecture composed of three mod-
ules: a preprocessing module in charge to filter out noise, recover handwritten strokes
from degraded images and reduce variability of text styles; a feature extraction module,
where a feature vector sequence is obtained as the representation of a handwritten text
image; and finally, a recognition module, which obtains the most likely word sequence
for the sequence of feature vectors. In addition, the recognition module used in this
work has been adapted to solve (5) using (6) as a suffix model for each consolidated
prefix. The following subsections describe each of these modules in detail.
3.1 Preprocessing
It is quite common for ancient documents to suffer from degradation problems [9].
Among these are the presence of smear, background of big variations and uneven illu-
mination, spots due to the humidity or marks resulting from the ink that goes through
the paper (generally called bleed-through). In addition, other kinds of difficulties appear
in these pages as different font types and sizes in the words, underlined and/or crossed-
out words, etc. The combination of these problems contributes to make the recognition
process difficult, therefore a preprocessing module becomes essential.
Computer Assisted Transcription for Ancient Text Images 1187
Concerning the preprocessing module used in this work, the following steps take
place: skew correction, background removal and noise reduction, line extraction, slant
correction and size normalization.
We understand “skew” as the angle between the horizontal direction and the direction
of the lines on which the writer aligned the words. Skew correction is carried out on each
document page image, by aligning their text lines with the horizontal direction [10].
Background removal and noise reduction are performed applying a bi-dimensional
median filter [11] on the whole page image, followed by a grey-level normalization to
increase the foreground/background image contrast (see figure 3 panel b).
The next step consists in dividing the page image into separate line images. The
method used is based on the horizontal projection profile of the input image. Local
minimums in this projection are considered as potential cut-points located between con-
secutive text lines (see panel c on figure 3). When the minimum values are greater than
zero, no clear separation is possible. This problem has been solved using a method based
in connected components [12]. The panel d on figure 3 shows the resulting line images
(from the highlighted region in panel c) after applying the method above mentioned.
Finally, the slant correction and size normalization processes are applied on each
previously separated line image. The slant is the clockwise angle between the vertical
direction and the dominant direction of the written vertical strokes. This angle is de-
termined using a method based on vertical projection profile (see [13]), and used then
by the slant correction process to put the written text strokes in an upright position.
On the other hand, the size normalization process tries to make the system invariant to
character size and to reduce the areas of background pixels which remain on the im-
age because of the ascenders and descenders of some letters [14]. The three panels in
figure 3 show these last steps in the preprocessing module.
3.2 Feature Extraction
As our HTR system is based on Hidden Markov Models (HMMs), each preprocessed
text line image has to be represented as a sequence of feature vectors. To do this, the
feature extraction module applies a grid to divide the text line image into N×M squared
cells. In this work, N =40 is chosen empirically and M must satisfy the condition that
M/N is equal to the original line image aspect ratio [10]. Each cell is characterized
by the following features: normalized gray level, horizontal gray level derivative and
vertical gray level derivative.
To obtain smoothed values of these features, feature extraction is not restricted to the
cell under analysis, but extended to a 5 × 5 cells window, centered at the current cell.
To compute the normalized gray level, the analysis window is smoothed by convolution
with a 2-d Gaussian filter. The horizontal derivative is calculated as the slope of the line
which best fits the horizontal function of column-average gray level. The fitting criterion
is the sum of squared errors weighted by a 1-d Gaussian filter which enhances the role
of central pixels of the window under analysis. The vertical derivative is computed in a
similar way.
Columns of cells (also called frames) are processed from left to right and a fea-
ture vector is constructed for each frame by stacking the three features computed in its
constituent cells. Hence, at the end of this process, a sequence of M 120-dimensional
1188 V. Romero et al.
(b)(a)
(d)(c)
Fig. 3. Preprocessing example: a) original image; b) skew correction, background removal, noise
reductions and increase of contrast; c) image with cutting lines; d) separated line images from the
highlighted region
Computer Assisted Transcription for Ancient Text Images 1189
(e)
(f)
(g)
Fig. 3. (continued) e) a separated line image); f) slant correction; g) size normalization
feature vectors (40 normalized gray-level components and 40 horizontal and vertical
derivatives components) is obtained. This process is similar to that followed in [6]. On
the top of figure 1 an example of the feature vectors sequence for a separate line image
is shown graphically.
3.3 Recognition
Characters are modelled by continuous density left-to-right HMMs, with 6 states and a
mixture of 64 Gaussian densities per state. This Gaussian mixture serves as a probabilis-
tic law to the emission of feature vectors on each model state. The number of Gaussian
densities as well as the number of states were empirically chosen after tuning the sys-
tem. It should be noted that the number of Gaussians and states define the number of
parameters to be estimated, and this number strongly depend on the amount of training
vectors available. The character HMMs are trained using a well-known instance of the
EM algorithm called forward-backward or Baum-Welch re-estimation [8].
Each lexical word is modelled by a stochastic finite-state automaton which represents
all possible concatenations of individual characters that may compose the word. On the
other hand, according to section 2.2 text line sentences are modelled using back-off
bi-grams, with Kneser-Ney back-off smoothing [15,16], which are estimated using the
given transcriptions of the trained set.
All these finite-state (HMM character, word and sentence) models can be easily in-
tegrated into a single global model on which the search for decoding the input feature
vectors sequence x into the output words sequence w is performed. This search is opti-
mally done by using the Viterbi algorithm [8]. This algorithm can be easily adapted also
for the search required in the CATOTI interactive framework explained in section 2.3.
4 Experimental Results
In order to test the effectiveness of the CATOTI approximation proposed in this paper
on legacy documents, different experiments were carried out. The corpus used in the
experiments, as well as the different measures and the obtained experimental results are
explained in the following subsections.
1190 V. Romero et al.
4.1 Corpus
The corpus was compiled from the legacy handwriting document identified as “Cristo-
Salvador”, which was kindly provided by the Biblioteca Valenciana Digital (BIVALDI)1.
This corpus is composed of 53 text page images, written by only one writer and
scanned at 300dpi. Some of these page images are shown in the figure 4. As has been
Fig. 4. Examples of corpus “Cristo-Salvador”
explained in section 3, the page images have been preprocessed and divided into lines,
resulting in a data-set of 1,172 text line images. The transcriptions corresponding to
each line image are also available, containing 10,911 running words with a vocabulary
of 3,408 different words.
Two different partitions were defined for this data-set. In the first one, called soft, the
test set is formed by 491 samples corresponding to the last ten lines of each document
page, whereas the training set is composed of the 681 remaining samples. On the other
hand, in the second partition, called hard, the test set is composed of 497 line samples
belonging to the last 20 document pages, whereas the remaining 675 were assigned to
the training set. All this information is summarized in the table 1.
The soft partition is considered to be easier to recognize than the hard one because its
text line samples were extracted from the same pages that the training text line samples.
On the other hand, hard partition better approaches a realistic transcription process.
1 http://bv2.gva.es
Computer Assisted Transcription for Ancient Text Images 1191
Table 1. Basic statistics of the database and its soft and hard partitions
Soft Hard
Number of: Training Test Training Test Total Lexicon
text lines 681 491 675 497 1,172 –
words 6,432 4,479 6,222 4,689 10,911 3,408
characters 36,699 25,460 35,845 26,314 62,159 78
That is, the CATOTI system is initially trained with the first document pages, and then
as more page images are transcribed, a greater amount of samples (line images and tran-
scriptions) become available to retrain the system and therefore improve the assistance
to the transcription of the rest of the document.
4.2 Assessment Measures
Two kinds of measures have been adopted. On the one hand, the quality of the tran-
scription without any system-user interactivity is given by the well known word error
rate (WER). It is defined as the minimum number of words that need to be substituted,
deleted or inserted to convert a sentence recognized by the system into the correspond-
ing reference transcription, divided by the total number of words in the reference tran-
scription.
On the other hand, the effort needed by a human transcriptor to produce correct
transcriptions using the CATOTI system is assessed by the word stroke ratio (WSR).
The WSR is computed using a reference transcription of the text image considered.
After a first CATOTI hypothesis, the longest common prefix between this hypothesis
and the reference is obtained and the first unmatching word from the hypothesis is
replaced by the corresponding reference word. This process is iterated until a full match
with the reference is achieved. Therefore, the WSR can be defined as the number of
(word level) user interactions that are necessary to achieve the reference transcription
of the text image considered, divided by the total number of reference words.
This definition makes WST and WER comparable. Moreover, the relative difference
between WER and WSR gives us an estimation of the reduction in human effort that
can be achieved by using CATOTI with respect to using a conventional HTR system
followed by human postediting.
4.3 Results
As previously mentioned, different evaluation measures have been adopted. The WER,
which is the conventional automatic HTR result and the CATOTI result called WSR.
Table 2 shows the different results obtained with both the soft and the hard partitions.
Several comments about these results are in order. First, as expected given the high
difficulty of the transcription problem, conventional HTR yields too many errors for
human post-editing to be considered a viable, cost-effective approach to produce error-
free transcriptions. In contrast, the assitive nature of CATOTI places the user always
in command of the whole process: if predictions are not good enough, then the user
simply keeps typing at her own pace; otherwise, she can accept (partial) predictions
1192 V. Romero et al.
Table 2. Results obtained with soft and hard partitions
Soft Hard
WER (%) 46.8 50.3
WSR (%) 44.1 48.7
and thereby save raw typing effort. According to the results, more than 51% of raw
typing effort of paleography experts is expected to be saved. In addition, if we ignore
the inadequacy of a human expert to post-edit a text where half of its words have to
be corrected, the interactive approach would be more effective even in this case: using
CATOTI, the estimated relative reductions in words to be corrected are 5.8% and 3.2%
for the soft and hard settings, respectively.
5 Remarks and Conclusions
In this paper, we have proposed a new interactive, on-line framework, which combines
the efficiency of automatic HTR systems with the accuracy of the paleography experts
in the transcription of ancient documents. In this proposal, the words corrected by the
expert become part of a increasingly longer prefixes of the final target transcription.
These prefixes are used by the CATOTI system to suggest new suffixes that the expert
can iteratively accept or modify until a satisfactory, correct target transcription is finally
produced.
The results reported in the last section should be considered preliminary. Because
of the large vocabulary of the corpus and the limited number of training samples avail-
able in this experiment, n-gram models are clearly undertrained. Despite this severe
sparse data condition, and given the extreme difficulty of the task, the preliminary re-
sults achieved in this work are encouraging.
In fact, much better results are expected if more training text is available for language
modeling, as shown by an informal experiment carried out by training the n-gram models
with the whole data-set (1,172 text line images). In this case, WER and WSR were 30.0%
and 19.9%, respectively, leading to an estimated reduction in human effort of 33.8%
Current work is under way to apply this approach to the transcription of very much
larger documents and document collections, involving bigger vocabularies and rela-
tively larger amounts of training material
Acknowledgments. This work has been partially supported by the EC (FEDER), the
Spanish MEC under grant TIN2006-15694-CO2-01, by Consellerı́a d’Empresa, Uni-
versitat i Ciència - Generalitat Valenciana under contract GV06/252 and by the Uni-
versitat Politècnica de València (FPI grant 2006-04)
References
1. Cubel, E., Civera, J., Vilar, J.M., Lagarda, A.L., Vidal, E., Casacuberta, F., Picó, D.,
González, J., Rodrı́guez, L.: Finite-state models for computer assisted translation. In: Pro-
ceedings of the 16th European Conference on Artificial Intelligence (ECAI04), Valencia,
Spain, 2004, pp. 586–590. IOS Press, Amsterdam (2004)
Computer Assisted Transcription for Ancient Text Images 1193
2. Civera, J., Vilar, J.M., Cubel, E., Lagarda, A.L., Barrachina, S., Casacuberta, F., Vidal, E.,
Picó, D., González, J.: A syntactic pattern recognition approach to computer assisted transla-
tion. In: Fred, A., Caelli, T.M., Duin, R.P.W., Campilho, A., de Ridder, D. (eds.) Structural,
Syntactic, and Statistical Pattern Recognition. LNCS, vol. 3138, pp. 207–215. Springer, Hei-
delberg (2004)
3. Barrachina, S., Bender, O., Casacuberta, F., Civera, J., Cubel, E., Khadivi, S., Lagarda, A.L.,
Ney, H., Tomás, J., Vidal, E., Vilar, J.: Statistical approaches to computer-assited translation.
In: Computational Linguistic (Submitted 2006)
4. Rodriguez, L., Casacuberta, F., Vidal, E.: Computer Assisted Speech Transcription. In: Pro-
ceedings of the third Iberian Conference on Pattern Recognition and Image Analysis, Girona
(Spain). LNCS, Springer, Heidelberg (2007)
5. Alabau, V., Benedı́, J., Casacuberta, F., Juan, A., Martı́nez-Hinarejos, C., Pastor, M.,
Rodrı́guez, L., Sánchez, J., Sanchis, A., Vidal, E.: Pattern Recognition Approaches for
Speech Recognition Applications. In: Pla, F., Radeva, P., Vitrià, J. (eds.) Pattern Recognition:
Progress, Directions and Applications. Centre de Visió per Computador, pp. 21–40 (2006)
ISBN 84-933652-6-2
6. Bazzi, I., Schwartz, R., Makhoul, J.: An Omnifont Open-Vocabulary OCR System for En-
glish and Arabic. IEEE Trans. on PAMI 21(6), 495–504 (1999)
7. Rabiner, L.: A Tutorial of Hidden Markov Models and Selected Application in Speech
Recognition. In: Proc. IEEE, vol. 77, pp. 257–286 (1989)
8. Jelinek, F.: Statistical Methods for Speech Recognition. MIT Press, Cambridge (1998)
9. DRIRA, F.: Towards Restoring Historic Documents Degraded Over Time. In: DIAL ’06.
Proceedings of the Second International Conference on Document Image Analysis for Li-
braries (DIAL’06), Washington, DC, USA, pp. 350–357. IEEE Computer Society Press, Los
Alamitos (2006)
10. Toselli, A.H., Juan, A., Keysers, D., González, J., Salvador, I., Ney, H., Vidal, E., Casacu-
berta, F.: Integrated Handwriting Recognition and Interpretation using Finite-State Models.
Int. Journal of Pattern Recognition and Artificial Intelligence 18(4), 519–539 (2004)
11. Kavallieratou, E., Stamatatos, E.: Improving the quality of degraded document images. In:
DIAL ’06. Proceedings of the Second International Conference on Document Image Anal-
ysis for Libraries (DIAL’06), Washington, DC, USA, pp. 340–349. IEEE Computer Society
Press, Los Alamitos (2006)
12. Marti, U.-V., Bunke, H.: Using a Statistical Language Model to improve the preformance of
an HMM-Based Cursive Handwriting Recognition System. Int. Journal of Pattern Recogni-
tion and Artificial Intelligence 15(1), 65–90 (2001)
13. Pastor, M., Toselli, A., Vidal, E.: Projection profile based algorithm for slant removal. In:
Campilho, A., Kamel, M. (eds.) ICIAR 2004. LNCS, vol. 3211, pp. 183–190. Springer, Hei-
delberg (2004)
14. Romero, V., Pastor, M., Toselli, A.H., Vidal, E.: Criteria for handwritten off-line text size
normalization. In: Procc. of The Sixth IASTED international Conference on Visualization,
Imaging, and Image Processing (VIIP 06), Palma de Mallorca, Spain (2006)
15. Katz, S.M.: Estimation of Probabilities from Sparse Data for the Language Model Com-
ponent of a Speech Recognizer. IEEE Trans. on Acoustics, Speech and Signal Process-
ing ASSP-35, 400–401 (1987)
16. Kneser, R., Ney, H.: Improved backing-off for N-gram language modeling. International
Conference on Acoustics, Speech and Signal Processing (ICASSP) 1, 181–184 (1995)
