SCRIPT IDENTIFICATION IN
HANDWRITTEN SOUTH INDIAN
DOCUMENT IMAGES
A MINOR RESEARCH PROJECT FINAL REPORT SUBMITTED
TO UNIVERSITY GRANTS COMMISSION, NEW DELHI
(MRP(S)-477/09-10/KAGU013/UGC-SWRO, Dated 8/01/2010)
by
Dr.Mallikarjun Hangarge
Department of Computer Science
Karnatak Arts, Science and Commerce College, Bidar, Karnataka, India
June 2013
Acknowledgements
I wish to express my sincere gratitude to University Grants Commission, New Delhi, for
providing the financial assistance to carry out this project. I extend my gratitude to
the Management of KRE Society, and Principal, Karnatak Arts, Science and Commerce
College, Bidar for their support and encouragement extended during this project.
My heartfelt thanks are also due to Dr. B. V. Dhandra, Professor and Chairman,
P.G.Department of Studies and Research in Computer Science, Gulbarga University,
Gulbarga, for his continuous support, encouragement and valuable guidance during the
project.
I wish to thank Dr. P. S. Hiremath, Professor, P.G.Department of Studies and Research
in Computer Science, Gulbarga University, Gulbarga, for his valuable guidance, sug-
gestions and encouragement which enabled me to break through the problems in this
project.
I extend my deep gratitude to Dr. K.C. Santosh, INRIA, LORIA Campus Scientifique,
BP - 239, 54506 Vandoeuvre les Nancy Cedex, FRANCE for his cooperation and working
with us to complete this task.
I thank to Sri. Srikanth Doddamani, Associate Professor, and other teaching and non
teaching staff members of the Department of Computer Science, Karnatak College, Bidar
for their support and cooperation.
My heartfelt thanks to Sri. Gururaj R. Mukarambi, and Smt. Vijaylaximi B. Research
Scholars, P.G.Department of Studies and Research in Computer Science, Gulbarga Uni-
versity, Gulbarga for working with me to complete this project.
I also thank to Mr. Rajmohan Pardeshi, M.Sc IV sem. Karnatak College, Bidar, for his
support extended during the project work.
Lastly, I am very much thankful to my wife and my daughter Kum. Mayuri and younger
son Vishal for their patience and support extended during this project.
i
Contents
Acknowledgements i
List of Figures iv
List of Tables vi
1 Introduction 1
1.1 What is a Document? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1
1.2 Document Image Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . 2
1.3 Optical Character Recognition . . . . . . . . . . . . . . . . . . . . . . . . 3
1.4 Script and Language Classification . . . . . . . . . . . . . . . . . . . . . . 4
1.4.1 Indian Scripts and Languages . . . . . . . . . . . . . . . . . . . . . 7
1.4.2 A System for Script and Language Identification . . . . . . . . . . 7
1.5 Previous Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9
1.5.1 Handwritten and Printed Text Separation . . . . . . . . . . . . . . 9
1.5.2 Script Identification . . . . . . . . . . . . . . . . . . . . . . . . . . 10
1.6 Motivation and Contribution . . . . . . . . . . . . . . . . . . . . . . . . . 12
1.7 Proposed System . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12
1.7.1 Preprocessing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13
1.7.2 Feature Extraction . . . . . . . . . . . . . . . . . . . . . . . . . . . 14
1.7.3 Classification . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15
1.7.3.1 Linear Discriminant Analysis (LDA) . . . . . . . . . . . . 15
1.7.3.2 K-Nearest Neighbor . . . . . . . . . . . . . . . . . . . . . 16
1.7.3.3 Gaussian Mixture Model . . . . . . . . . . . . . . . . . . 16
1.7.4 Evaluation Protocol . . . . . . . . . . . . . . . . . . . . . . . . . . 16
1.8 Organization of the Report . . . . . . . . . . . . . . . . . . . . . . . . . . 17
1.9 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17
2 Proposed Feature Exaction Methods 18
2.1 Feature Extraction Techniques . . . . . . . . . . . . . . . . . . . . . . . . 18
2.1.1 Statistical Texture Features . . . . . . . . . . . . . . . . . . . . . . 18
2.1.2 Spatial Features . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20
2.1.3 Gabor Features . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22
2.1.4 Directional Energy Features . . . . . . . . . . . . . . . . . . . . . . 24
2.2 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25
3 Experiments 26
ii
Contents iii
3.1 Experimental Results and Discussion . . . . . . . . . . . . . . . . . . . . . 26
3.1.1 Handwritten and Printed Text Classification . . . . . . . . . . . . 26
3.1.1.1 Dataset . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26
3.1.1.2 Results and Discussion . . . . . . . . . . . . . . . . . . . 26
3.1.2 Text Block Level Script Identification . . . . . . . . . . . . . . . . 28
3.1.2.1 Dataset . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28
3.1.2.2 Results and Discussion . . . . . . . . . . . . . . . . . . . 28
3.1.3 Text Blocks and Line Level Script Identification . . . . . . . . . . 30
3.1.3.1 Dataset . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30
3.1.3.2 Results and Discussion . . . . . . . . . . . . . . . . . . . 31
3.1.4 Word Level Script Identification . . . . . . . . . . . . . . . . . . . 33
3.1.4.1 Dataset . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33
3.1.4.2 Results and Discussion . . . . . . . . . . . . . . . . . . . 33
3.2 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34
4 Conclusion and Future Work 37
4.1 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37
4.2 Future Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38
A Output of the Project: Publications 39
Bibliography 40
List of Figures
1.1 A hierarchy of document processing sub-areas listing the types of docu-
ment components dealt within each sub area . . . . . . . . . . . . . . . . 3
1.2 A view of the types of documents used in Document Image Analysis . . . 3
1.3 An example of machine printed mono script (Kannada) document. . . . . 5
1.4 An example of machine printed bi-scripts document image of Malayalam
and Roman scripts. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5
1.5 An example of handwritten bi-scripts document image of Devanagari and
Roman scripts. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5
1.6 An example of handwritten bi-scripts document image of Kannada and
Roman scripts. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5
1.7 An example of handwritten bi-scripts document image of Devanagari and
Roman scripts. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6
1.8 An example of multi-script document. . . . . . . . . . . . . . . . . . . . . 7
1.9 A block diagram of Multi-script Multi-lingual OCR technologies. . . . . . 8
1.10 A screen-shot of an overall work-flow of the system. . . . . . . . . . . . . . 13
1.11 A couple of samples showing each document containing handwritten and
printed texts. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13
1.12 An example showing word segmentation using Kannada script . . . . . . . 14
2.1 An example of features spread plot of Devanagari,Roman and Urdu scripts 22
2.2 An example of Gabor filtered responses for 0, 30 degree orientations with
frequency 0.5 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24
3.1 A sample multi-script dataset of handwritten and printed text words. . . 27
3.2 Sample binarized image blocks of size 512 x 512 pixels of six scripts. . . . 29
3.3 Sample thinned image blocks of size 512 x 512 pixels of Roman, Devana-
gari and Kannada scripts. . . . . . . . . . . . . . . . . . . . . . . . . . . . 29
3.4 A sample miss classified Devanagari text block as English script. . . . . . 32
3.5 Illustrates the percentage of script identification accuracy in case of multi-
scripts (a) Percentage of Roman script identification with different values
of order of GMM; (b) Percentage of Kannada script identification with
different values of order of GMM; (c) Percentage of Devanagari script
identification with different values of order of GMM; (d) Percentage of
Telugu script identification with different values of order of GMM.. . . . . 35
3.6 A sample word images of (a) English, (b) Devanagari, (c) Kannada and
(d) Telugu scripts. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35
iv
List of Figures v
4.1 An example of features spread plot (a) horizontal features of Indian Ro-
man and Kannada script, (b) horizontal features of IAM Roman and
Kannada scrip. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38
List of Tables
3.1 Recognition accuracy of handwritten and printed word separation using
multilingual dataset for k-NN with k = 1, 3, 5, 7. . . . . . . . . . . . . . . 27
3.2 Confusion matrix of handwritten and printed word separating using mul-
tilingual dataset for k = 5. . . . . . . . . . . . . . . . . . . . . . . . . . . . 27
3.3 Script wise recognition accuracy of handwritten and printed word sepa-
ration for k = 5. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27
3.4 Tri-script Average Recognition accuracy using 2 fold cross validation with
KNN classifier k = 1. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30
3.5 Confusion matrix of tri-script recognition using 2 fold cross validation
with KNN classifier k = 1. . . . . . . . . . . . . . . . . . . . . . . . . . . . 30
3.6 Text block level bi-script identification results with k = 3. . . . . . . . . . 32
3.7 Text block level tri-script identification results with k = 5. . . . . . . . . . 32
3.8 Text line level bi-script identification results with k = 3. . . . . . . . . . . 32
3.9 Text line level tri-script identification results with k = 3. . . . . . . . . . . 33
3.10 The comparative study of text block level script identification. . . . . . . 33
3.11 Average Percentage of Bi-script Identification accuracy with GMM of
order 128. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34
3.12 Average Percentage of Tri-script Identification accuracy with GMM of
order 128. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34
3.13 Average Percentage of Multi-script Identification accuracy with GMM of
order 128. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34
vi
Chapter 1
Introduction
1.1 What is a Document?
The document is anything which symbolizes the thoughts of a person through a set of
symbols. In other words, it transmits thinking of a person through a set of graphical
symbols using mediums like stone tablets, clay tablets, wax tablets, vellum, parchment,
clothes, paper, copper plates, styluses, quills, ink brushes, pencils, and pens. The docu-
ment plays a vital role in our day today activities such as communication, documentation
and information processing. At present, a large number of people and organizations are
using paper documents for ease of communication because of its light weight and easy
availability. In day-to-day life, we come across various types of documents like books,
newspapers, journals, magazines, postal mails, application forms, land records, railway
reservation forms, passports, maps, fax messages, web pages, court judgments, accounts,
handwritten texts, shorthand, musical score papers. The traditional way of preserving,
organizing, indexing and retrieving of documents is the difficult and prolonged task when
we have large amount of documents. To overcome this, the advent of computer and
electronic storage mechanisms has made document processing fast and efficient. Hence
transformation of paper document into an electronic format that a computer can process
is an important task of any office automation system. As the world is moving towards
the concept of paperless office, more and more communications and storage of docu-
ments are to be performed digitally. Thus, the conversion of physical (paper) document
into electronic form is needed to facilitate faster additions, searches, and modifications,
as well as to preserve documents or records for a longer period. Thus, in recent years,
there is an increasing demand for tools that digitize, recognize, search and retrieve the
written and spoken sources of multilingual information. As a result, digital document
processing has become more popular in office and library automation, bank and postal
1
Chapter 1. Introduction 2
services, publishing houses and communication managements etc. Hence, there is a lot of
demand for software that automatically extracts, analyzes, and stores information from
physical documents for later use. All of these tasks fall under the general heading of
document image analysis, which is a fast growing area of research in recent years. Thus,
document image analysis pertains to the processing and understanding of the contents
present in the documents that are in the form of papers, microfilms, faxes, web pages,
emails, etc.
1.2 Document Image Analysis
The document image analysis is defined as Algorithms and techniques that are applied
to images of documents to obtain a computer-readable description from pixel data, [2].
Document image analysis has been an active research area from a few decades, and
that facilitates the establishment of paperless offices across the world. It is the subfield
of digital image processing that aims to recognize the text and graphic components
in images of documents, and extracts the required information as human being would
do. The task of document image analysis is of two folds; one deals with processing
of text components and another graphic components. All the text components exists
in images of the documents are interpreted by text component processing algorithms
whereas graphical components processing techniques deals with non-textual components.
The block diagram of document image analysis is depicted in Fig.1.1. Throughout the
project, for experimentation, we have used only text components to extract the intended
information. In other words, analysis of graphical components is out of scope of this
project. The first step of text document image analysis involves the physical layout
analysis, where the document image is segmented into different zones based on the
spatial relations (usually spacing). Then each zone is labeled as text, graphics, table,
or form. Traditional document image analysis works only on the text zone, and the
analysis can be extended to table and form zones. To facilitate further analysis, the text
zone is partitioned into a hierarchy of physical components containing text lines, words
and characters. Further, the text to be recognized may be printed and/or handwritten
(off-line) or on-line. The on-line text can be produced by PDA or electronic blackboard
or light pen devices. The types of text documents are shown in Fig.1.2. To read such
complex documents a multilingual OCR is essential. The detail discussion on optical
character recognition is given in the following Section.
Chapter 1. Introduction 3
Figure 1.1: A hierarchy of document processing sub-areas listing the types of docu-
ment components dealt within each sub area
Figure 1.2: A view of the types of documents used in Document Image Analysis
1.3 Optical Character Recognition
The recognition of these documents is an active research area of document image anal-
ysis and hence the Optical Character Recognition (OCR) is said to be the core of the
pattern recognition discipline [24]. The process of converting textual symbols present
on printed and/ or handwritten paper to a machine understandable format is known as
optical character recognition (OCR). The Optical Character Recognition (OCR) system
has various practical applications: (1) Reading aid for the blind, (2) Automatic text
entry into the computer for desktop publication, library cataloging, ledgering etc., (3)
Automatic reading for sorting of postal mail, bank cheques and other documents, (4)
Document data compression, (5) Language processing, (6) multi-media system design,
etc. The origin of character recognition can be found way back in 1870, when Carey
invented the retina scanner - an image transmission system using a mosaic of photocells
Chapter 1. Introduction 4
[28]. Later, Nipkow in 1890 invented the sequential scanner, which is the major break-
through for both modern television and reading machines. However, initially the charac-
ter recognition system was considered an aid for the visually handicapped. The Russian
scientist Tyurin made the early successful attempts in 1900. Many sophisticated Optical
Character Recognition systems are available for non-Indian scripts [2, 16, 17, 28, 45, 46]
and commercial products like Omni Page Pro from Scan Soft, Inc [40] and Fine Readers
from Abbyy Software House [15] are also available to recognize almost all Latin based
languages.
The OCR technology for Indian scripts is in infant stage and some pieces of research
work for Indian script recognition is reported in [3, 4, 8, 50]. Most of these OCR sys-
tems can read the documents written in single script and /or language only. Most of
the official and commercial documents of Asian countries are multi-script/multi-lingual
in nature. The variation or interlacing of different scripts and / or languages in a single
document may be at paragraph, line, and word and / or character level. Some typical
examples of mono-script and bi-script documents of machine printed and handwritten
are shown in. Fig.1.3, Fig.1.4, Fig.1.5, Fig.1.6, Fig.1.7. The recognition of text from
such documents becomes a challenging problem due to the variations of different scripts
at different levels in a single document. The monolingual OCR systems will not process
such multilingual documents without human intervention for demarcating different script
and / or language zones of multi-lingual pages before activating the script and language
specific OCR engine. The need for such manual intervention can be labor intensive,
which results in greater expense and significantly slows down the overall image-to-text
conversion. Thus, an automatic routing is required for the incoming document images to
assign the particular OCR engine depending on the knowledge of the underlying scripts
and / or languages of the documents. In view of this, identification of script and/ or
language is one of the primary tasks for multi-script document processing. A script
recognizer, therefore, eases the task of OCR by enhancing the accuracy of recognition
and reducing the computational complexity.
1.4 Script and Language Classification
Script is a set of symbols and rules used to express or convey the information in a graphic
form using mediums like stone tablets, clay tablets, wax tablets, vellum, parchment,
clothes, paper, copper plates, styluses, quills, ink brushes, pencils, and pens. There is
confusion in the minds of people that the language and script are same, even though
they are completely different things. ”Script is only the outer clothing of language” says
Pattanayak [23, 37]. Language is intrinsic to human beings but not so the alphabet.
Script is independent of any specific language; different languages may use the same
Chapter 1. Introduction 5
Figure 1.3: An example of machine printed mono script (Kannada) document.
Figure 1.4: An example of machine printed bi-scripts document image of Malayalam
and Roman scripts.
Figure 1.5: An example of handwritten bi-scripts document image of Devanagari and
Roman scripts.
Figure 1.6: An example of handwritten bi-scripts document image of Kannada and
Roman scripts.
Chapter 1. Introduction 6
Figure 1.7: An example of handwritten bi-scripts document image of Devanagari and
Roman scripts.
script. For example, Sanskrit, Marathi, and Hindi use the Devnagari script. The same
language may use different script at different points in time or space. For example,
Sindhi is written in Devnagari as well as Perso-Arabic scripts. Many languages in
the world share the same script. For example, English, German, French, Ao Naga,
Thadou, and Mizo languages are written using the Roman script. However, generally
a script is used to represent a language. Furthermore, Roman script has an alphabetic
representation whereas others (most of the Indian scripts) are in phonetic form. Owing
to the diversity of Indian scripts and languages the number of real life documents, which
we come across in day-to-day life are multi-script multi-lingual in nature. Most of the
Government records belonging to the border area of a state are multi-script and / or
multi-lingual. As per the trilingual formula of Indian constitution [34, 48], every state
Government has to produce an official document containing a national language (Hindi),
official language (English) and regional language (or state language). For example, an
official document of Karnataka state contains Hindi, English and Kannada scripts. The
use of English with local languages is more frequently seen in a number of commercial
and official documents. Thus, the occurrences of bi-script, tri-script and multi-script
documents are common in Indian context. The variation of different scripts may be
in the form of numerals and/ or text words or alpha numerals in a single document
page. It is observed that the probability of using English numerals with local scripts is
comparatively high as that of using English text words with local scripts. The processing
of such complex multi-script multi-lingual documents is a challenging problem for DIA
researchers. The script and / or language identification and separation is an important
task of document image analysis. This task has a number of advantages to simplify the
DIA algorithms. Some of these are: 1) Automatic text retrieval based on script and
/or language of the underlying document. 2) Sorting of text documents based on the
knowledge of its script and /or language 3) Script and / or language identification and
separation reduces the time complexity and enhances the accuracy of Optical Character
Reader (OCR) 4) Automatic script and / or language identification facilitates indexing
of documents 5) Multilingual document archives are also facilitated by the automatic
Chapter 1. Introduction 7
Figure 1.8: An example of multi-script document.
script identification.
1.4.1 Indian Scripts and Languages
In countries like India, most of the official documents are multi-script/multi-lingual in
nature. Besides, there are other Asian countries where multi-script/multi-lingual docu-
ments exist. In India, there are 22 official languages (Accepted by Indian Constitution),
namely Assamese, Bengali, Bodo, Dogri, Gujarati, Hindi, Kannada, Kashmiri, Konkani,
Maithili, Malayalam, Marathi, Meitei, Nepali, Oriya, Eastern Punjabi, Sanskrit, Santali,
Sindhi, Tamil, Telugu, and Urdu. Among these, Hindi and Bangala are the first and
second popular languages in India and fourth and fifth popular languages in the world.
Twelve different scripts are used for writing these official languages. Most of the Indian
scripts originated from ancient Brahmi script through various transformations [49]. A
typical example of multi-script document can be seen in Fig.1.8
1.4.2 A System for Script and Language Identification
To design a multi-script multi-lingual OCR for a multilingual country like India, it is
necessary to design an automatic preprocessing model which identifies different script
zones in a single document image and passes them to a script specific OCR engine.
However, only script separation is not enough for designing a multi-script multi-lingual
Chapter 1. Introduction 8
Figure 1.9: A block diagram of Multi-script Multi-lingual OCR technologies.
OCR system, since in India the correspondence between scripts and languages is not
one to one. Some scripts are used for writing several languages and some languages are
written in more than one script. For example, Devnagari script is used to write Sanskrit,
Hindi, Marathi, and Konkani, Nepali and Sindhi languages, while Bangla script is used
to write Assamese, Manipuri and Bangla (Bengali) languages. Therefore, after script
separation, language identification must be carried out to design a successful multi-
script multi-lingual OCR system. This originates the problem of script and language
identification in multilingual document analysis. Multi-script multi-lingual OCR for such
document pages can be developed in two ways: (1) Development of a generalized OCR
system, which can recognize all characters of the alphabets of the possible scripts and /or
language present in the document pages. (2) Development of a script and/or language
separation scheme to identify different scripts and/or languages present in the document
pages and generation of individual OCR for each script and/or language character.
Development of a generalized OCR system for Indian languages is a difficult task, since
the number of characters in each script alphabet is voluminous. Therefore, the second
option is simple and economic for a country like India. The multi-script multi-lingual
OCR technology development generally has two stages: (1) identification of different
script and /or language regions from a document (2) forwarding of individual script
and /or language region as input image to appropriate OCR system. A diagrammatic
presentation of a multi-script multi-lingual OCR system is given in Fig.1.9.
Chapter 1. Introduction 9
1.5 Previous Work
1.5.1 Handwritten and Printed Text Separation
In [13], a well-known technique is employed to compute histogram of width, height, gap
and centre distance of extracted connected components. A polynomial classifier is used
for classification of data fields, to decide that whether the data field is handwritten or
printed. Another method is presented using a layered feed forward neural network [22].
It uses a set of features via histograms of gradient vector directions and luminance levels
of gray scale image. The scheme classifies handwritten character, printed character,
photograph and images in document image. However, it does not explicitly explain in
those cases when handwritten and printed text zones or characters are intersected or
overlapped. In [26], authors computed straightness of horizontal and vertical oriented
lines and symmetric relative different points and these were used to discriminate between
handwritten and printed character using feed forward neural network. Violante et al.,
1955 reported a scheme for separation of handwritten and printed address blocks of
envelopes [52]. In particular, region, edge straightness, horizontal profile and dimensions
of address box such as area, height, and width are computed. Classification task is
carried out using multilayer preceptron neural network. Pal et al., 2001 [32] developed
an algorithm for identification of machine printed and handwritten text line for two
major Indian scripts: Devangari and Bangla using projection profile and statistical
features with tree classifier. Hidden Markov Models (HMMs) with projection profiles
are employed to separate handwritten text form machine printed text in document
images on a word level basis [18]. In [54], authors are focused on structural features,
a co-occurrence histogram, 2 × 2 grams, pseudo run lengths and Gabor filters. Fisher
classifier is used for classification and Markov Random Fields (MRFs) are used for post
processing to improve results. E. Kavallieratou et al., 2004 [25] developed a scheme
for classification of handwritten and printed Greek text using structural features and
discriminant analysis. In some cases, Gabor filters are used for feature extraction and
probabilistic neural networks for classification of handwritten and printed text in Arabic
document images [14]. Features such as shape characteristics are dominantly used for
handwritten and printed text separation via k-NN classifier [12, 36]. In [9], a system
using chain code features and support vector machine (SVM) classifier is reported where
texts are presented as sparse content and arbitrary oriented document fragments. As a
reminder, computing chain code (for 8 different direction) is very expensive in case the
boundary of the characters is not smooth enough. The Radon transform has also been
used to represent text that goes word-wise together with SVM for classification [53]. As
reported in [39], eigen-faces features have been popularly used for text separation while
defining the local threshold.
Chapter 1. Introduction 10
Based on our quick review made in the aforementioned paragraph, without a surprise,
one can notice that several different works use script dependent features and these may
not accommodate in case when new scripts are included. This in primarily due to the fact
that shape of the characters of one script will differ from another. Besides, the reported
woks are addressed the problem in different ways like character level [13], word level [9,
12, 36] and bock/line level separation. However, one cannot not cleanly judge which one
is really convincing. Furthermore, it is important to repeat that the approaches that deal
with the text separation problem application dependent. Considering our context i.e.,
Indian scripts, word level handwritten and printed text separation would be interesting
choice since there exists texts are interlaced in word level.
1.5.2 Script Identification
Over the last three decades, most of the published works relate printed text. However,
few works are reported on handwritten text script identification of Indic scripts. Almost
all the methods either employed global or local or glocal (combinations of global and
local) approaches. Malaviya et al.[1] have proposed a unified syntactic approach for
multi-script recognition. The fuzzy pattern description language FOHDEL is used to
store fuzzy features in the form of fuzzy rules. First they briefly described the proposed
recognition methodology for Latin, Devanagari and Kanji scripts by analyzing their
characteristic properties. Further they presented the main features of FOHDEL by a
comparative rule generation of three scripts under experiment. Finally the system inte-
gration of the proposed multi-script recognition scheme is presented with existing Latin
script recognition system. A system for automatically identifying the script used in a
handwritten document image is described by Hochberg et al.[21]. The system was de-
veloped using a 496-document dataset representing six scripts, eight languages, and 279
writers. These documents were characterized by the mean, standard deviation and skew
of the connected component features. A linear discriminant analysis is used to classify
new documents and performed writer-sensitive cross-validation. The same method, ap-
plied within the Roman sub corpus, and discriminated English and German documents.
U. Pal [33] have presented a machine-printed and hand-written text classification scheme
for Bangla and Devanagari, the two most popular Indian scripts. The scheme is based
on the structural and statistical features of the machine-printed and hand-written text
lines. Singhal et al.[33] have proposed to pre-process the input document images so as
to compensate for the variations due to writing style and thereby making them suit-
able for analysis on the basis of their visual appearance. Accordingly, they applied
de-noising, thinning, pruning, m-connectivity and text size normalization in sequence.
Multi-channel Gabor filtering is used to extract texture features that characterize the
Chapter 1. Introduction 11
visual appearance of the document images. K.Roy et al.[47] have proposed a scheme
that at first detects and corrects the skew of a document image. Non-text parts are then
segmented from the document using run length smoothing algorithm (RLSA). Next,
using a piece-wise projection method the destination address block (DAB) is segmented
into lines and then lines into words. Using water reservoir concept the busy-zone of
the word is computed. Finally, a tree classifier was generated for word-wise Bangla/De-
vanagari and English scripts identification based on matra /Sirorekha features. U.Pal
et al.[43] have evolved an automatic scheme for word-wise identification of hand-written
Roman and Oriya scripts for Indian postal automation. In their proposed scheme, skew
of the document is corrected and a piecewise projection method is used to segment the
document into lines and then lines into words. Finally, different features based on water
reservoir concept, fractal dimension, topological features and scripts characteristics are
used. A Neural Network (NN) classifier is applied for word-wise script identification.
Jain et al.[29] have proposed a method to classify words and lines in an on line hand-
written document into one of the six major scripts: Arabic, Cyrillic, Devanagari, Han,
Hebrew, or Roman. The classification is based on 11 different spatial and temporal
features extracted from the strokes of the words. The proposed system performance
is assessed with 5-fold cross validation on a data set containing 13,379 words. They
reported that the classification accuracy increases as the number of words in the test
sample increases. Lijun Zhou et al.[55] have discussed a technique for Bangla/English
script identification with applications to the destination address block of Bangladesh en-
velope images. The proposed approach is based on the analysis of connected component
profiles extracted from the destination address block images, however, this method does
not place any emphasis on the information provided by individual characters themselves
and does not require any character/line segmentation.
Primarily, global approaches used in [5, 35, 38, 41, 51] are based on DCT, DWT, Ga-
bor, Steerable Pyramids, and Radon transform. The local features, for example, shape
features of connected components are employed in [5, 19, 27, 43, 44]. The combination
of these are used in [6] and called it as glocal method. A detailed review of literature
of script identification is presented in [10], and especially, a brief review on Indic hand-
written script identification in [11]. Based on the analysis of the above techniques, we
understand that, aforementioned methods have their own merits and demerits. Explic-
itly, local features are script dependent, sensitive to noise, skew, segmentation and are
slower in computation. But, they are efficient in extracting dominant features, particu-
larly, directional strokes of small size images [19], for instance, connected components.
Global features are efficient in characterizing large size texture patterns, for example,
text blocks. They are robust to noise, small skew, and are faster in computation. How-
ever, they are weak in extracting directional energies of small size images, connected
components, for instance. In particular, the DCT and wavelet features employed in [41]
Chapter 1. Introduction 12
for classifying text blocks are not potential to sustain their performance in case of word
image. The glocal method i.e., the cpmbination of local and global techniques proposed
in [6] method also suffers with the issues like time complexity, segmentation, and image
size. These quick observations indicate that global method is the better choice than the
local [10].
1.6 Motivation and Contribution
The quick observations made on the state of the art motivated to work on the classifi-
cation of handwritten scripts instead of printed text. The state of the art revealed that
the global methods are better than the local. As a consequence, we have contributed
four novel feature extraction techniques. Our contribution involves global and glocal
(the combination of global and local methods) methods used to solve the issues of script
classification at block, line and word levels. The contributed algorithms are:
1. Statistical texture features for handwritten and printed text separation, it is im-
portant because separation of handwritten text from printed, makes the script
identification problem easier,
2. Spatial features for text block, text line and word level script identification,
3. Text blocks script identification based on Gabor filters, and
4. Diagonal decomposition of image (DDI) for word level script identification.
1.7 Proposed System
We primarily aim to classify the different zones of south Indian scripts in a document.
To handle it, text blocks, text lines and words are first extracted from the scanned
document. For each extracted text block, text line and word, various features such
as spatial , Gabor and directional features are computed. These features are used to
classify the different scripts via k-NN , LDA and Gaussian mixture model. For better
understanding, we refer readers to Fig. 1.10 where it provides a schematic work-flow of
the system.
Chapter 1. Introduction 13
Input document
sample
↓
Pre-processing ⇒ Features computation ⇒ Classifier
↓
Output.
Figure 1.10: A screen-shot of an overall work-flow of the system.
1.7.1 Preprocessing
The preliminary task is to do pre-processing. Pre-processing techniques are application
dependent. In our case, we aim for segmenting words from the scanned documents. As
an example, Fig. 1.11 shows a couple of sample images where handwritten and printed
texts are shown in a single document. To handle it, it consists of a three-step process.
We first binarised the the document using Otsu’s threshold selection method [30] and
employed basic morphological operators to remove outliers such as commas, semicolons,
single and double quotations. Similarly, long lines are removed based on connected
component analysis. Word segmentation is then applied by using dilation so that words
separation is possible where connected component rule can basically be applied. In
Fig. 1.12, for visual understanding, we provide bounding boxes to all words taken from
a sample document.
Figure 1.11: A couple of samples showing each document containing handwritten and
printed texts.
Chapter 1. Introduction 14
(a) Input image
=⇒
(b) Binarisation
⇓
(d) Output
⇐=
(c) Line removal
Figure 1.12: An example showing word segmentation using Kannada script
1.7.2 Feature Extraction
The proposed feature extraction techniques namely statistical texture features, spatial,
Gabor, and directional energy features are explained in 2.1. The statistical texture
features 2.1.1 are employed for the classification of handwritten and printed text words.
The use of these features extended for the classification of text blocks of various scripts
and observed its poor performance. In purview of this, we switched over to another
traditional feature extraction technique that is Gabor filters. The state of the art reveals
that the Gabor features are more potential in various pattern classification. With this,
we have used fine tuned Gabor features 2.1.3 to classify different script text blocks.
However, Gabor features have shown moderate performance. This has motivated us to
think of the combination of local and global features that yields spatial features 2.1.2 and
are utilized in discriminating different script text blocks and text lines. Furthermore, the
over all performance of the preceding techniques are not encouraging in case of word level
script identification. Therefore, directional energy features 2.1.4 are investigated based
on the dominant visual discriminating factors such as edges. These features shown the
predominant role in classification of word image of different south Indian scripts using
Gaussian mixture model.
Chapter 1. Introduction 15
1.7.3 Classification
In this project we have employed three traditional classifiers such as linear discriminant
analysis (LDA), K nearest neighbor and Gaussian mixture model to classify the differ-
ent scripts. The implementation details of each classifier is explained in the following
subsections.
1.7.3.1 Linear Discriminant Analysis (LDA)
Linear Discriminant Analysis is one of the most commonly used classification technique.
It preserves class discriminating information to the higher extent by reducing dimension-
ality of feature space. It also maximizes separability between the classes by maximizing
the ratio of between-class variance to the withinclass variance. In this paper, LDA is
employed on a dataset X=[x1, .., xi] of dimension N × 12 (N=9000) and the samples xi
are belongs to one of the class Ci, where i = 1, ..., 6. Further, the dimension of xi is
mxp, where m = 1, ..., 1500 and p = 1, ..., 12. Then the classification function is defined
as
g(X) = W TX, (1.1)
where W is the linear projection, and which maximizes between-class scatter
Sb = S1 + S2 + ...+ S6 =
6∑
i=1
6∑
x∈ci
(X − µi)(X − µi)T , (1.2)
whereas it minimizes the within-class scatter
Sw =
6∑
i
mi(µi − µ)(µi − µ)T , (1.3)
where µi is the mean over class Ci, µ is the mean over all samples, and mi is the number
of samples in class Ci. The classification of a new sample x of class label ω ∈ Ci is
done based on the nearest neighbor classification rule. For this purpose, the Euclidean
distance d of g(X) and the centers Vi = W
Tµi in LDA space are compared
ω = argmin1≤i≤c d(g(X), Vi) (1.4)
To comprehend the performance of LDA, another traditional classifier i.e., K-NN (K-
Nearest Neighbor classifier) is used.
Chapter 1. Introduction 16
1.7.3.2 K-Nearest Neighbor
BasicallyK-NN stores the training dataX. Then finds the minimumD distance between
training sample X and testing pattern Y using
D(X,Y ) =
√
(X − Yi)T (X − Yi). (1.5)
1.7.3.3 Gaussian Mixture Model
Mainly, Gaussian Mixture Model (GMM) based script identification is a script classifier.
Each script is modeled by GMM and script classification is carried out according to
the likelihood score calculated by GMM against a given feature vector of unknown
script. The Gaussian mixture model is a weighted sum of multivariate Gaussian mixture
components. It forms the probability density function for a given set of feature vector
and it is defined as
p(y|λ) =
N∑
i=1
wibi(y) (1.6)
where wi is the weight matrix,y is N dimensional feature vector, i is the mixture com-
ponent index and is an N-variate Gaussian density function. The complete GMM is
defined by
λ =
(
wi, µi,
∑
i
)
(1.7)
The GMM parameters, lambda is computed by an iterative method using expectation
maximization (EM) algorithm. Using this model, given an unknown script word X=
~y1, ~y2, ~y3, .....~yt is classified based on the average log likelihood score and is given by
L̂ = arg max︸︷︷︸
i<l<L
1
T
T∑
t=1
logp(yt|λt) (1.8)
where λt is GMM of script i and L be the number of scripts the system could identify.
1.7.4 Evaluation Protocol
To evaluate the performance of the method, K-fold cross validation (CV) has been
implemented unlike traditional dichotomous classification. In K-fold CV, the original
sample for every dataset is randomly partitioned into K sub-samples. Of the K sub-
samples, a single sub-sample is used for validation, and the remaining K−1 sub-samples
are used for training. This process is then repeated for K-folds, with each of the K sub-
samples used exactly once. Eventually, a single value results from averaging all. In our
experimental tests, the value of K = 10.
Chapter 1. Introduction 17
1.8 Organization of the Report
The organization of the report is as follows: The first Chapter summarizes the problem
domain, problem analysis and its importance in addition to the motivation, objectives
and state of the art. The feature extraction techniques proposed are systematically
presented in Chapter second. The detailed result analysis and discussion is elaborated
in Chapter three. The report is concluded with the highlights of future work in Chapter
four.
1.9 Summary
In this chapter, problem domain, problem analysis and its relevance in context of Indian
scripts are highlighted. The motivation and objectives of the proposed work are defined.
The state of the art on handwritten/ printed text separation and script identification at
various levels such as text block, text line and word level is summarized. In addition,
the proposed system and its components are explained.
Chapter 2
Proposed Feature Exaction
Methods
This Chapter presents various feature extraction techniques employed for the classifica-
tion of handwritten text blocks,text lines, and words. Besides, it highlights the problem
of word level handwritten and printed text separation.
2.1 Feature Extraction Techniques
2.1.1 Statistical Texture Features
The problem of handwritten and printed text separation is considered as a problem of
texture analysis. Human perception on discriminating between handwritten and printed
text is exploiting the texture properties of the text. Thus, we take advantage of texture
features for feature extraction.
Texture features are first reported in [20] for image classification. For better understand-
ing, texture can also be defined as: it is property which contains important information
about structural arrangement of surfaces and their relationship with surrounding envi-
ronment. In this paper, we use simple statistical measure of texture from image, which
observe texture as quantitative measure of arrangement of intensity level in image region.
Statistical properties of the intensity histogram such as (F1.) mean, (F2.) standard de-
viation, (F3.) smoothness, (F4.) third moment, (F5.) uniformity, (F6.) entropy, (F7.)
neighborhood standard deviation, (F8.) local range and (F9.) local entropy. These set
18
Chapter 2. Proposed Feature Exaction Methods 19
of nine statistical texture features collectively used to generate a feature vector. We
have calculated these statistical properties using statistical moments 1 .
Let ri be the discrete random variable which denotes the intensity levels in image and
h(ri), i = [0, 1, 2, . . . , k − 1], be the corresponding normalised histogram, where k is the
possible intensity value. To describe the shape of histogram with principal approach is
via its central moment and the expression of nth moment for mean can be expressed as
follows,
µi =
K−1∑
i=0
(ri −m)n. (2.1)
In the following, the above stated nine features are defined and calculated for a given n.
1. F1. is a measure of average intensity, used for calculation of average intensity of
word image,
m =
K−1∑
i=0
rip(ri). (2.2)
2. F2. is taken as measure of average contrast and is expressed as,
σ =
√
σ2. (2.3)
3. F3. measures the relative smoothness of the intensity in a region which is defined
as,
R = 1− 1
1 + σ2
. (2.4)
4. F4. measures the skewness of an intensity histogram which can be expressed as,
µ3 =
K−1∑
i=0
(ri −m)3h(r). (2.5)
5. F5. measures the uniformity of pixels which is defined as,
U =
K−1∑
i=0
p2(ri). (2.6)
1This work has been published with a title ”Statistical Texture Features based Handwritten and
Printed Text Classification in South Indian Documents” in proceedings of International Conference on
Emerging Trends in Electrical, Communication, and Information Technologies, Anantpur, A.P, Dec-
2012, pp.no. 215-221
Chapter 2. Proposed Feature Exaction Methods 20
6. F6. computes the entropy i.e., randomness of pixels in image and is expressed as,
e =
K−1∑
i=0
p(ri)log2p(ri). (2.7)
7. F7 computes local standard deviation of an image.
8. F8 determines local range of an image.
9. F9 determines local entropy of an image.
2.1.2 Spatial Features
Properties of Indian Scripts:
Devanagari : Most of the characters of Devanagari script have a horizontal line at the
upper part. In Devanagari, this line is called sirorekha. However, we shall call them as
headlines. When two or more Devanagari characters sit side by side to form a word,
the sirorekha or headline touch one another and generates a big headline [10] in case of
printed documents, whereas in handwritten documents, these lines are usually drawn
after the word is written.
Roman : The important property of the Roman (English) script is the existence of the
vertical strokes in its characters and has less number of horizontal strokes as compared
to Devanagari and Urdu scripts. The right and left diagonal strokes are also plays an
important role in distinguishing Roman from Devanagari and Urdu scripts.
Urdu :The Urdu characters have strong base line as well as right diagonal strokes. Urdu
script has less number of holes as compared to other two scripts.
These directional visual discriminating features are extracted from the image or pattern
for discrimination of proposed scripts. In the following, we describe the features and
their method of computation. To extract the strokes in vertical, horizontal, right and
left diagonal directions, we have performed the opening operation on the input binary
image with the line-structuring element. The length of the structuring element is ex-
perimentally fixed for text block as vertical-10, horizontal-7, left and right diagonal -5
each. For line wise feature extraction the structuring element length is thresholded to
70% of the average height of the connected components of an image (empirically fixed).
Chapter 2. Proposed Feature Exaction Methods 21
Stroke Density : The stroke length is defined as the number of pixels in a stroke as the
measure of its length [18], for the strokes in vertical, horizontal, right and left diagonal
directions of the image. Further, the stroke density is defined as the total length of all
the strokes divided by the size of the image. Throughout the discussion N is referred
as number of on pixels. The values of 13 features extracted here, are real numbers.
The average feature vector of 25 sample images is shown by a line chart in Fig. 2.1,
to visualize the strength of the feature set for discriminating the proposed scripts. Let
on-pixels of vertical, horizontal, right and left diagonal patterns be µ, α, β, γ. And let
δ be the on-pixels of the pattern yields after fill holes.
1. Vertical Stroke Density (VSD)
V SD =
∑N
i µi
Size(Image)
, (2.8)
2. Horizontal Stroke Density (HSD)
HSD =
∑N
i αi
Size(Image)
, (2.9)
3. Right Diagonal Stroke Density (RDSD)
RDSD =
∑N
i βi
Size(Image)
, (2.10)
4. Left Diagonal Stroke Density (LDSD)
LDSD =
∑N
i γi
Size(Image)
, (2.11)
Pixel Density of an image after fill holes: This is the ratio between the number
of on pixels left after performing fill hole operation on input pattern, to its size.
For fill holes, we choose the marker image (erode image), fm, to be 0 everywhere
except on the image border, where it is set to 1-f. Here f is the image of a connected
component. Let g be the reconstructed image of f.
5. Pixel Density of the Pattern after fill holes (PD)
PD =
∑N
i gi
Size(g)
, (2.12)
The remaining (sixth to thirteenth) features are extracted by top-hat and bottom-hat
morphological filtering (transformations) in four directions. The features are computed
Chapter 2. Proposed Feature Exaction Methods 22
Figure 2.1: An example of features spread plot of Devanagari,Roman and Urdu
scripts
in similar way as discussed in equation 2.8-2.11. The top-hat transformation, due to
F.Meyer, aims to extract the objects that have not been eliminated by the opening. It
can be defined as the residue between the identity and an opening. This transformation
is preferred here to decompose an input image in four directions at three levels to
extract fine textural primitives for discrimination of scripts. The sample feature vector
of English, Devanagari and Urdu is given below2.
Devanagari = [0.0021 0.0443 0.0554 0.0114 0.0350 0.0167 0.0984 0.0068 0.0396 0.0065
0.0096 0.0368 0.0039]
English = [0.0047 0.0222 0.0175 0.0011 0.0258 0.0140 0.0354 0.0092 0.0178 0.0035 0.0085
0.0184 0.0040]
Urdu = [0.0003 0.0274 0.0156 0.0014 0.0264 0.0078 0.0287 0.0097 0.0180 0.0008 0.0022
0.0256 0.0013]
2.1.3 Gabor Features
The process of feature extraction is one of the important components in any recognition
system. In this paper, features are extracted by transforming the input time domain
image into frequency domain. The term frequency refers to variation in brightness or
color across the image, i.e. it is a function of spatial coordinates, rather than time. The
following is the feature extraction method i.e. Gabor filter Bank.
The use of Gabor filters in image analysis is biologically motivated as they model the
2This work has been published with a title ”Off-line Handwritten Script Identification in Document
Images. International Journal of Computer Applications 4(5):15, July 2010. Published By Foundation
of Computer Science
Chapter 2. Proposed Feature Exaction Methods 23
response of the receptive fields of the orientation-selective simple cells in the human
visual cortex. Furthermore, they provide the best possible trade off between spatial and
frequency resolution. Gabor filters are formed by modulating a complex sinusoid by a
Gaussian function with different frequencies and orientations. A two dimensional Gabor
function consists of a sinusoidal plane wave of some frequency.3
g(x, y) =
[
− 1
2πσxσy
]
exp
[
− 1
2
(
x′2
σ2x
+
y′2
σ2y
)
2πjWx′
]
, (2.13)
where
x′ = x cos θ + y sin θ, y′ = −x sin θ + y cos θ. (2.14)
Where σ2x and σ
2
y control the spatial extent of the filter, θ is the orientation of the filter
and W is frequency of the filter. Two dimensional Gabor filters are used to extract the
features from input text block image .The preprocessed input binary image is convolved
with Gabor filters considering six different orientations (0◦, 30◦, 60◦, . . . , 150◦) and four
different frequencies (a=0.5, b=0.125, c=0.25 and d=0.0625) with = 2 and = 4. The
values of these parameters are experimentally fixed. Then 24 output images are obtained
after convolution with Gabor bank of filters. These output images are used for computing
the standard deviation and stored as a feature vector of 24 dimensions. Further, these
features are used to train and test the K-NN classifier. Samples of filtered images for
0◦, 30◦ degree orientations with frequencies are 0.5 are shown in Fig. 2.2. First line shows
for 0 degree and second for 30 degree.
Algorithm: Gabor Feature Based Script identification in Trilingual documents
Input : Gray scale images of text blocks of different scripts
Output : Identified script of the text block
Begin
1. Convert gray scale image into binary image using Otsus method (see figure 2(b)).
2. Remove small objects around the boundary of the image by using morphological
opening operations.
3. Perform thinning operation (see figure 2 (c)).
4. Create Gabor filter Bank by considering six different orientations and four different
frequencies to obtain 24 filters.
5. Perform convolution with the input image and Gabor filter banks (see Fig. 2.2).
3 This work has been published in Multimedia Processing,Communication and Computing Applica-
tions, Lecture Notes in Electrical Engineering 213,DOI:10.1007/978-81-322-1143-3-3, @ Springer India
2013
Chapter 2. Proposed Feature Exaction Methods 24
(a) Thinned binary image
(b) Gabor output for 0 degree and frequency 0.5
(c) Gabor output for 30 degree and frequency 0.5
Figure 2.2: An example of Gabor filtered responses for 0, 30 degree orientations with
frequency 0.5
6. For each output image of step 5, compute standard deviation of the entire output
images and obtain a feature set of 24 dimensions.
7. Store feature vector of each script of each text block for classification.
end
2.1.4 Directional Energy Features
Diagonally Decomposed Image (DDI). Here, each input word image matrix is
converted into a square matrix by appending zeros in case of non square matrix. Then,
the standard deviations are computed on each left and right diagonals.The complete
process of feature extraction is summarized in the following paragraph.4.
Let A be the square matrix of input image of size N × N . Let the principal diagonal
of A be µ. Let β and α be N-2 upper and lower diagonals of A respectively. Then the
computation of six features which are denoted by f1,....,f6 is discussed below. Firstly,
extracted a principal diagonal µ of A and computed its standard deviation σ1 using
σ1 =
√
1
n− 1
n∑
u=1
(u− ū)2, (2.15)
4This work has been published with a title ”Gaussian Mixture Model for Handwritten Script Identi-
fication” in proceedings of International Conference on Emerging Trends in Electrical, Communication,
and Information Technologies, Anantpur, A.P, Dec- 2012, pp.no. 64-69
Chapter 2. Proposed Feature Exaction Methods 25
where u = 1, 2, ..., n and n is the number of pixels in u. The standard deviation σ1
is a scalar value. Secondly, β number of upper right diagonals of A are extracted.The
standard deviations of β diagonals are obtained using
σβ =
√
1
n− 1
n∑
u=1
(uβ − ūβ)2, (2.16)
where u = 1, ., n and β = 1, ...., N −2. σβ is a column vector of size N −2×1. Then, by
appending the value of σ1 and a zero into σβ, we get first feature f1 of dimension N ×1.
Similarly, α number of lower left diagonals of A are extracted and computed standard
deviations of α using
σα =
√
1
n− 1
n∑
u=1
(uα − ūα)2, (2.17)
wherem = 1, ..., N−2 and σα is a column vector of size N−2×1. By appending two zeros
into σα, we get second feature f2 of dimension N × 1. In this way, features f3 and f4
are computed by filliping the input matrix A. The filliped matrix is denoted by Af and
upper, lower and principal diagonals are by βf , αf and µf respectively. Finally, standard
deviations of horizontal and vertical energies of A are computed to obtain features f5
and f6 respectively. Thus, an integrated feature vector F={f1N×1, ..., f6N×1} of size
N × 6 is formed. To reduce the dimension of the feature vector, again computed mean
and standard deviations of f1N×1, ...., f6N×1 and reduced dimension N × 6 to 12 × 1
(six means and six standard deviations) as the central tendency measure values of each
word image and the same is used for classification.
2.2 Summary
This Chapter summarizes the various feature extraction methods such as Statistical
texture features in 2.1.1 and spatial features extraction is elaborated in 2.1.2. Besides,
the computation of Gabor and directional energy features are explained in 2.1.3 and 2.1.4
respectively. These features are employed to conduct the exhaustive experimentations
on text block,line and word level of South Indian scripts. The experimental results and
discussion is given in the following Chapter.
Chapter 3
Experiments
3.1 Experimental Results and Discussion
3.1.1 Handwritten and Printed Text Classification
3.1.1.1 Dataset
Due to the unavailability of data set, we have created a dataset of 5000 printed and
5000 handwritten word images. A sheet of A4 size, which contains few lines of machine
printed text at the top and the same, is provided to 100 writers of different professions.
Then, writers are asked to write the same text in the blank space provided below the
printed text region. These 100 A4 size pages were digitized by scanning at 300 dpi.
By applying segmentation algorithm as discussed in Section 1.7.1, obtained a dataset
of 1000 printed and 1000 handwritten text word images of each script. For English,
IAM DB 3.0 dataset is used and extracted 1000 handwritten and 1000 printed text
words. In this way, a dataset of size 2000 word images of each script namely Kannada,
Telugu, Malayalam, Hindi and Roman were created. Further, 5000 printed and 5000
handwritten text words of five scripts are mixed to generate a multilingual dataset. A
few sample of multilingual dataset is shown in Fig. 3.1.
3.1.1.2 Results and Discussion
To observe the script independent behavior of our algorithm, a comprehensive study
has been made from the thorough experimental tests that are conducted on multilingual
word dataset. Having the dataset of 5000 handwritten and 5000 printed words from five
scripts, our experimental tests will go like this.
26
Chapter 3. Experiments 27
Figure 3.1: A sample multi-script dataset of handwritten and printed text words.
1. Use multilingual dataset for different values of k and select an optimal value of it.
2. The selected value is then used for script-wise test. The second test attests the
fact that which script does not show discriminant behavior between handwritten
and printed text, considering the similar statistical texture features.
Table 3.1: Recognition accuracy of handwritten and printed word separation using
multilingual dataset for k-NN with k = 1, 3, 5, 7.
k=1 k=3 k=5 k=7
Handwritten 98.92 98.90 99.00 98.92
Printed 99.54 99.54 99.52 99.50
Average 99.23 99.22 99.26 99.21
Table 3.2: Confusion matrix of handwritten and printed word separating using mul-
tilingual dataset for k = 5.
Handwritten Printed Total
Handwritten 4950 50 5000
Printed 24 4976 5000
Table 3.3: Script wise recognition accuracy of handwritten and printed word separa-
tion for k = 5.
Roman Hindi Kannada Telugu Malayalam
Handwritten 97.40 100 98.20 100 100
Printed 98.60 100 98.90 100 100
Average 98.00 100 98.55 100 100
In Table ??, multilingual dataset is used for different values of k = 1, 3, 5, and 7 in k-
NN classifier. In this test, we have found an optimal performance of the k-NN classifier
happens for k = 5. For deeper analysis, we have provided its confusion matrix in
Table 3.2. As soon as we have received an optimal selection of the value of k, another
Chapter 3. Experiments 28
experiment i.e., script-wise test has been made with it. Such a script-wise experimental
results are provided in Table 3.4. Based on results reported in Table 3.4, tests over
scripts like Hindi, Telugu and Malayalam show promising performance, compared to
Roman and Kannada scripts. We have found that false recognition of handwritten
exists confusion of clean handwritings of any individuals with the printed ones and vice-
versa. This type of confusion is occurred between Kannada handwritten and printed
text.
3.1.2 Text Block Level Script Identification
3.1.2.1 Dataset
The standard database is not available for handwritten Indian scripts, hence collected
handwritten documents of different scripts from different professionals belonging to
schools, colleges and officials. The documents collected are scanned at 300 DPI and
stored as gray scale images. A block of image of size 512 x 512 pixels is extracted man-
ually from different areas of the document image. The handwritten text block region
contains only text, and numerals that may appear in the text are not considered. The
digitized images are in gray tone and we have used Otsus global thresholding approach
to convert them into two tone images. The two-tone images are then converted into 0 1
label where the label 1 represents the object and 0 represents the background. The small
objects (less than are equal to 30 pixels) like, single or double quotation marks, hyphens
etc. are removed using morphological opening operations. A total of 600 handwritten
image blocks, 100 blocks for each of the six scripts are considered for experimentation.
A sample of handwritten text block images representing different scripts is shown in
Fig. 3.2 and preprocessed images is shown in Fig. 3.3 respectively.
3.1.2.2 Results and Discussion
Experimentations are carried out with KNN classifier. This is a straightforward ex-
tension of nearest neighbor. Basically we try to find the k nearest neighbors and do
a majority voting. Typically k is odd when the number of classes is 2. Choosing of
appropriate values of K is critical. The smaller value of K have high influence of noise
on the classification result whereas larger the value of K increases the time complexity
of the algorithm. Therefore to know the optimal performance of the KNN classifier, we
have extended our experimentation with varying number of neighbors (K= 1, 3, 5) and
found optimal result when K = 1. The proposed script identification problem can be ex-
perimented in three ways: 1) bi-script, 2) tri-script and 3) multi-script. However, in this
Chapter 3. Experiments 29
(a) Roman Script (b) Devanagari Script (c)Kannada Script (d) Malayalam Script
(e) Telugu Script (f) Tamil Script
Figure 3.2: Sample binarized image blocks of size 512 x 512 pixels of six scripts.
(a) Roman Script (b) Devanagari Script (c) Kannada Script
Figure 3.3: Sample thinned image blocks of size 512 x 512 pixels of Roman, Devana-
gari and Kannada scripts.
paper we have made an exhaustive experimentation on trilingual documents, because as
per the Indian constitution the rule of trilingual is in governance with each State of the
Country. More frequently tri-script documents could be seen in South Indian States.
Therefore, identification of scripts of the trilingual documents is the decisive solution.
In case of multi-script identification the recognition accuracy will decrease. Out of cu-
riosity, extended our experimentation on dataset of [41] and noticed the classification
average accuracy as 99% in trilingual case. This result shows how the performance of
the algorithm is dependent on the dataset used for experimentation. It is very difficult
to justify the performance of the algorithms without testing it on a benchmark dataset
with similar experimental conditions. Hence, our claim of average classification accu-
racy of 91.99% has the place of justification. A total of 600 text block images (each
script 100 text blocks) are considered for experimentation. Half of the text block images
are used for training and the remaining for testing. The Table 3.4 shows the average
recognition accuracy for script identification from trilingual document images. The error
distribution (Confusion matrix) among different scripts using KNN classifier (i.e k=1)
with 2 fold cross validation is shown in the Table 3.5. From Table 2 we could observe
the confusion of the classifier in discriminating the tri-script. It can be noticed that
Chapter 3. Experiments 30
considerable confusion has occurred in case of English with regional languages like Kan-
nada, Tamil, Telugu and Malayalam. The reason is straightforward, that is most of the
native regional language writers have written English text characters in circular shape
which influences the classifier for misclassification. Furthermore, in all the cases Hindi
script identification has high accuracy because of Sirorekha (horizontal line at the top
of the word) feature which is absent in other scripts. These observations also clarify the
importance of directional energies in characterizing the shapes of characters of different
scripts.
Table 3.4: Tri-script Average Recognition accuracy using 2 fold cross validation with
KNN classifier k = 1.
Tri-script Groups Recognition Accuracy
Roman, Devanagari, Kannada 91.33
Roman, Devanagari,Telugu 96.00
Roman, Devanagari,Tamil 90.33
Roman, Devanagari, Malayalam 90.33
Average 91.99
Table 3.5: Confusion matrix of tri-script recognition using 2 fold cross validation with
KNN classifier k = 1.
Scripts Roman Devanagari Kannada
Roman 87 0 13
Devanagari 0 98 2
Kannada 10 1 89
Scripts Roman Devanagari Telugu
Roman 95 1 4
Devanagari 1 97 2
Telugu 0 4 96
Scripts Roman Devanagari Tamil
Roman 90 1 9
Devanagari 1 91 0
Tamil 14 4 82
Scripts Roman Devanagari Malayalam
Roman 91 1 8
Devanagari 1 93 6
Malayalam 5 8 87
3.1.3 Text Blocks and Line Level Script Identification
3.1.3.1 Dataset
A sample of 150 writers is chosen from schools, colleges and professionals for collecting
the handwritten documents. The writers are not imposed by any constraint like type
of pen and style of writing etc., and the purpose of data collection is also not disclosed.
Chapter 3. Experiments 31
Writers are provided with the unrolled papers and are asked to write 10 lines of text
matter in Devanagari, English and Urdu scripts. A total of 300 handwritten document
images are created from 150 handwritten document pages. The collected documents are
scanned using HP Scanner at 300 DPI, which usually yields a low noise and good quality
document image. The digitized images are in gray tone and we have used Otsus global
thresholding approach to convert them into two-tone images. Otsus method chooses the
threshold to minimize the interclass variance of the thresholded black and white pixels.
The two-tone images are then converted into 0-1 labels where the label 1 represents the
object and 0 represents the background. The small objects (less than are equal to 40
pixels) like, single or double quotation marks, hyphens and periods etc. are removed
using morphological opening. The next step in pre-processing is skew detection and
correction and is performed using the algorithm [7].
3.1.3.2 Results and Discussion
Experimentations are carried out with KNN classifier by varying the number of neigh-
bours (K= 3, 5, 7, 9, 11, 13, 15) and the performance of the algorithm is found optimal
when K = 5 for text blocks and K = 3 for text lines respectively. To evaluate the
performance of the classifier the data set containing 300 text blocks and 400 text lines
are randomly divided into five groups and a 5-fold cross validation was done for 100 it-
erations to get optimum results. For experimentation, 300 handwritten document pages
obtained from 150 writers are used with an assumption that the document pages con-
tain only text lines. These document pages are scanned using a flatbed HP scanner
at a resolution of 300 dpi. A sample image of size 128x128 pixels is selected manually
from each document image and created 300 text block images. Out of these 300 images
Devanagari, English, and Urdu are 100 each. The accuracy of the classification achieved
for script identification at text block level as well as at text lines is presented in Tables
3.6, 3.7, 3.8 and 3.9 . From the experimentation, we noticed that the text blocks of
Devanagari containing connected components of weak headlines and without headlines
are miss classified as Roman script (see Fig. 3.4). The English script miss classified
as Devanagari due to the text blocks containing the connected components of strong
horizontal stroke at the top of the character. Urdu script miss classified as Devana-
gari due to long base lines used by some writers at the bottom of the characters. The
algorithms proposed by [21], for identification of six scripts and [55], for two scripts
have shown an accuracy of 88% and 95% respectively. The algorithm proposed in this
paper achieves the maximum average accuracy of 97.50% for the combination of Roman
and Urdu scripts. The minimum average recognition accuracy is 89.00% for Roman and
Devanagari scripts. However, overall accuracy of the proposed algorithm is as high as
Chapter 3. Experiments 32
Figure 3.4: A sample miss classified Devanagari text block as English script.
88.67% and 97.5% for tri-script and bi-script classification. Further, we observed that
when the size of the image increases the results of recognition also increases and hence
the text line wise script identification results are high as compared to text block script
identification results. The text line level bi-script and tri-script identification results are
shown in Table 3.8 and 3.9 The performance comparison of the proposed algorithm
with other methods is presented in Table 3.10 . The proposed algorithm is implemented
in MAT-LAB 6.1. The average time taken to recognize the script of a text block image
is 0.2187 seconds and for text lines 0.8734 seconds on a Pentium-IV with 128 MB RAM
based machine running at 1.80 GHz.
Table 3.6: Text block level bi-script identification results with k = 3.
Bi-script Combinations Recognition Accuracy(%)
Roman, Devanagari 89.00
Roman, Urdu 97.50
Devanagari, Urdu 96.50
Table 3.7: Text block level tri-script identification results with k = 5.
Tri-script Recognition Accuracy(%)
Roman 86.00
Devanagari 83.00
Urdu 97.00
Average 88.67
Table 3.8: Text line level bi-script identification results with k = 3.
Bi-script Combinations Recognition Accuracy(%)
Roman, Devanagari 96.68
Roman, Urdu 99.20
Devanagari, Urdu 98.97
Chapter 3. Experiments 33
Table 3.9: Text line level tri-script identification results with k = 3.
Tri-script Recognition Accuracy (%)
Roman 97.83
Devanagari 93.00
Urdu 95.78
Average 95.54
The abbreviation details used in the following Table 1
Table 3.10: The comparative study of text block level script identification.
Algorithms Scripts Acc.(%) T.C V.T.
Hochberg A,Ch,Cy,
D,R and J 88.00 NR RP
Lijun Zhou R and D 95.00 NR NR
Proposed R and D 89.00 0.2086 sec. RP
R and U 97.50 0.2086 sec. RP
D and U 95.50 0.2086 sec. RP
R,D and U 88.67 0.2187 sec. RP
3.1.4 Word Level Script Identification
3.1.4.1 Dataset
We have created a dataset of 800 word images of four scripts due to non availability of
a benchmark dataset for Indic script. Ten handwritten pages of each script (Roman,
Devanagari, Kannada and Telugu) written by 40 writers were collected and scanned at
300 dpi. The scanned documents are binarized using Outs method [31]. Then words
are segmented using the algorithm employed in [6]. A sample dataset of four scripts is
shown in Fig 3.6.
3.1.4.2 Results and Discussion
An exhaustive experimentation has been carried out on a dataset of 800 word images. A
Gaussian mixture model is designed for each script. It is trained with 400 samples out of
800 (100 samples of each script) and the remaining is used for testing. An experimental
setup has been made in three phases, namely bi-script, tri-script and multi-script. In
case of bi-script, Roman-Devanagari, Roman-Kannada and Roman-Telugu combinations
are considered for experimentation. An average percentage of bi-script classification
1A- Arabic, Ch-Chinese, Cy-Cyrillic, D-Devanagari, R-Roman, J-Japanese, B-Bangla, U-Urdu, Acc-
Accuracy, T.C-Time complexity, V.T- validation test, N.R-not reported, RP-reported, sen-seconds
Chapter 3. Experiments 34
accuracy is 98.7% with GMM of order 128 and is reported in Table 3.11. The tri-
script classification problem involves the combinations of Roman-Devanagari-Kannada
and Roman-Devanagari-Telugu. In this case, average tri-script classification accuracy is
98.16% and it is shown in Table 3.12. The problem of multi-script identification is the
classification problem of Roman, Devanagari, Kannada and Telugu scripts. The multi-
script classification accuracies are reported in Table 3.13. Besides, experimentations are
extended on multi-script classification to observe the performance of GMM with different
orders of mixtures. And their respective results are illustrated in Fig. 3.5. These results
indicate that the performance of the GMM is dependent on the number of mixture com-
ponents considered for classification. The uniqueness of the algorithm is its robustness
against image size, size of characters, character slants, unconstrained gaps between the
words, writer style. The experimental results exhibits that the performance of the di-
rectional energy features are significant in classifying different handwritten text words
as compared with [41, 42]. Meanwhile, the decrease in classification accuracy is noticed
in case of multi-script classification when scripts are increased and an investigation is
on to overcome this problem.
Table 3.11: Average Percentage of Bi-script Identification accuracy with GMM of
order 128.
Scripts Devanagari Kannada Telugu Average (%)
Roman 97.00 100.00 99.0 98.7
Table 3.12: Average Percentage of Tri-script Identification accuracy with GMM of
order 128.
Tri-script Roman Devanagari Kannada
Roman 97.00 - -
Devanagari - 99.00 -
Kannada - - 97.00
Tri-script Roman Devanagari Telugu
Roman 98.00 - -
Devanagari - 100.00 -
Telugu - - 98.00
Table 3.13: Average Percentage of Multi-script Identification accuracy with GMM of
order 128.
Scripts Roman Devanagari Kannada Telugu Average (%)
Average(%) 96.00 95.00 97.67 99 96.91
3.2 Summary
In this Chapter, the classification of handwritten and printed text is discussed and
the observations made during the experimentation are reported. The performance of
Chapter 3. Experiments 35
(a) (b)
(c) (c)
Figure 3.5: Illustrates the percentage of script identification accuracy in case of multi-
scripts (a) Percentage of Roman script identification with different values of order of
GMM; (b) Percentage of Kannada script identification with different values of order of
GMM; (c) Percentage of Devanagari script identification with different values of order
of GMM; (d) Percentage of Telugu script identification with different values of order of
GMM..
(a)
(b)
(c)
(c)
Figure 3.6: A sample word images of (a) English, (b) Devanagari, (c) Kannada and
(d) Telugu scripts.
Chapter 3. Experiments 36
spatial features is highlighted in classification of text blocks and text lines. Further, the
traditional Gabor is employed and tested its performance on text block classification.
A novel method based on directional energy distribution is presented. The idea of the
existence of directional strokes in each character of each Indic script has motivated to
design a DDI method. This method has shown a remarkable performance compared
to the existing techniques. The comprehensive experiments reported in this Chapter
accomplishes the objectives of the project in total.
Chapter 4
Conclusion and Future Work
4.1 Conclusion
In this project, we have accomplished the objectives of the project by conducting various
experiments using different techniques. We have proposed four novel techniques and
tested them on a large dataset. Based on statistical texture features classification of
handwritten and printed text in document is carried out. Then the script classification
is performed. To realize the robustness of the presented techniques, a comprehensive
experiment is conducted on block level, line level and word level. Meanwhile, we have
observed some interesting factors that manipulates the performance of the techniques.
Some influencing factors in classification of text blocks and text lines are:
1. the coverage of the text,
2. the slant of the characters,
3. the size of the text block, and
4. the gaps between lines and words,
5. improper segmentation,
6. writing style, mode of the writer, age and profession of the writer.
Further, one more exciting observation is that, when an Indian native writer writes
Roman script, he mimics his style of writing native script, that can be realized through
Fig. 4.1. In this figure, Kannda and Indian Roman (written by Indians) and Kannada
and IMA database Roman scripts are used to view difference. Further, in case of word
level classification the following major difficulties are posed:
37
Chapter 4. Conclusion and Future Wok 38
1. word size i.e., number of characters in a word,
2. the slant of the characters,
3. similarity between shape of the characters of different scripts,
4. improper segmentation,
5. writing style, mode, age and profession of the writer.
3 6 9 12 15 7 8 9 10 11
0.06
0.08
0.1
0.12
0.14
0.16
0.18
Images
H
or
iz
on
ta
l f
ea
tu
re
s
 
 
Indian Roman
Kannada
(a)
3 6 9 12 15 7 8 9 10 11
0.06
0.08
0.1
0.12
0.14
0.16
0.18
Images
H
or
iz
on
ta
l f
ea
tu
re
s
 
 
IAM database Roman
Kannada
(b)
Figure 4.1: An example of features spread plot (a) horizontal features of Indian
Roman and Kannada script, (b) horizontal features of IAM Roman and Kannada scrip.
Among the presented four techniques , the performance of directional energy decom-
position method shows out-performance in all the cases of the problem. However, the
statistical texture features and spatial features are also shown moderate performance in
classification of text blocks. Besides, the spatial features have shown better performance
compared to Gabor features when employed for the classification of text blocks and text
lines.
4.2 Future Work
In future, we develop a generic model to classify the scripts at word level. We are working
on developing a novel method based on global approach. The global methods are faster
than local and local methods are very much sensitive to noise, improper segmentation,
image size and writer style. As a consequence, global methods such as DCT and DWT
( discrete wavelet transform) are using to design a novel method. In addition, we are
also investigating rotation and scale invariant features for script identification.
Appendix A
Output of the Project:
Publications
1. Offline Handwritten Script Identification in Document Images. International Jour-
nal of Computer Applications 4(5):15, July 2010. Published By Foundation of
Computer Science, USA.
2. Gaussian Mixture Model for Handwritten Script Identification, In Proceedings of
International Conference on Emerging Trends in Electrical, Communication and
Information Technologies(ICECIT-2012), Published by Elsevier Ltd. Anantpur,
AP. India, pp no.64-69.
3. Statistical Texture Features based Handwritten and Printed Text Separation in
South Indian Documents, In Proceedings of International Conference on Emerg-
ing Trends in Electrical, Communication and Information Technologies(ICECIT-
2012), Published by Elsevier Ltd. Anantpur, AP. India, pp no. 215-221, 2012.
4. South Indian Handwritten Script Identification at Block Level from Trilingual
Script Document Based on Gabor Features,In Proceedings of Multimedia Pro-
cessing, Communication and Computing Applications (Springer:Lecture Notes in
Electrical Engineering), Bangalore, pp. no.25-33, 2013.
39
Bibliography
[1] C.Leja A.Malaviya and L.Peters. Multi script handwriting recognition with fohdel.
In Proceedings of New Frontiers in Fuzzy Logic and Soft Computing Biennial Con-
ference of the North American Fuzzy Information Processing Society - NAFIPS,
pages 147–151, 2006.
[2] A. Amin. Off-line arabic character-recognition: The state of the art. Pattern
Recognition, 131:517–530, 1998.
[3] T. V. ASHWIN and P. S. SASTRY. A font and size-independent ocr system for
printed kannada documents using support vector machines. Sadhana, 27:35–58,
2002.
[4] V. Bansal and R. M. K. Sihna. Integrating knowledge sources in devnagari text
recognition system. smca, 30:500–505, 2000.
[5] Salehpour Mehdi Behrad Alireza, Khoddami Malike. A novel framework for farsi
and latin script identification and farsi handwritten digit recognition. Journal of
Automatic Control, 20(1):17–25, 2010.
[6] Mallikarjun Hangarge B.V. Dhandra. Global and local features based handwritten
textwords and numerals script identification. In Proceedings of ICCIMA, pages
471–475, 2007.
[7] Mallikarjun Hangarge Ravindra Hegadi B.V.Dhandra, V.S.Malemath. Skew de-
tection in binary image documents based on image dilation and region labeling
approach. In Proceedings of ICPR, pages 954–957, 2006.
[8] S. M.Kumar C.Bhagvati, T.Ravi and A.Negi. On developing high accuracy ocr
systems for telugu and other indian scripts. In Proceedings of Language Engineering
Conference, pages 18–23, 2002.
[9] Sukalpa Chanda, Katrin Franke, and Umapada Pal. Structural handwritten and
machine print classification for sparse content and arbitrary oriented document
fragments. In Proceedings of the ACM Symposium on Applied Computing, pages
18–22, 2010.
40
Appendix A. Output of the Project: Publications 41
[10] T Dube D Ghosh and A P Shivaprasad. Script recognition a review. IEEE PAMI.,
32(12):2142–2161, 2010.
[11] B H Harish D. S. Guru, M Ravikumar. A review on offline handwritten script iden-
tification. In Proceedings of IJCA on National Conferecne on Advanced Computing
and Communications, pages 13–16, 2012.
[12] Lincoln Faria da Silva, Aura Conci, and Ángel Sánchez. Automatic discrimination
between printed and handwritten text in documents. In Proceedings of the XXII
Brazilian Symposium on Computer Graphics and Image Processing, pages 261–267,
2009.
[13] J. Fanke and M. Oberlander. Writing style detection by statistical combination of
classifier in form reader applications. pages 581–585, 1993.
[14] Faisal Farooq, Karthik Sridharan, and Venu Govindaraju. Identifying handwritten
text in mixed documents. In Proceedings of International Conference on Pattern
Recognition, pages 1142–1145, 2006.
[15] Finereaders. :http://www.abbyy.com.
[16] G.Nagy. Chinese character recognition -a twenty five years retrospective. In Pro-
ceedings of I9th International Conference on Pattern Recognition, pages 109–114,
1988.
[17] G.Nagy. At the frontiers of ocr. In Proceedings of the IEEE, volume 80, pages
1093–1100, 1992.
[18] Jinhong Katherine Guo and Matthew Y. Ma. Separating handwritten material from
machine printed text using hidden markov models. In Proceedings of International
Conference on Document Analysis and Recognition, pages 439–443, 2001.
[19] Mallikarjun Hangarge and B.V.Dhandra. Offline handwritten script identification
in document images. IJCA, 4(6):1–5, 2008.
[20] Robert M. Haralick, K. Shanmugam, and Its’Hak Dinstein. Textural features for
image classification. IEEE Transactions on Systems, Man, and Cybernetics, SMC-
3(6):610 –621, 1973.
[21] Judith Hochberg, Kevin Bowers, Michael Cannon, and Patrick Kelly. Script and
language identification for handwritten document images. IJDAR, 2(2-3):45–52,
1999.
[22] S. Imade, S. Tatsuta, and T. Wada. Segmentation and classification for mixed
text/image documents using neural network. In Proceedings of International Con-
ference on Document Analysis and Recognition, pages 930 –934, oct 1993.
Appendix A. Output of the Project: Publications 42
[23] J.C.Sharma. Language and script in india: Some challenges.
:http://www.languageinindia.com/sep2001/jcscript.html.
[24] Rangachar Kasturi, Lawrence Ogorman, and Venu Govindaraju. Document image
analysis: A primer. Sadhana, 27(1):3–22, 2002.
[25] Ergina Kavallieratou, Efstathios Stamatatos, and Hera Antonopoulou. Machine-
printed from handwritten text discrimination. In Proceedings of IEEE International
Workshop on Frontiers in Handwriting Recognition, pages 312–316, 2004.
[26] K. Kuhnke, L. Simoncini, and Z. M. Kovacs-V. A system for machine-written and
hand-written character distinction. In Proceedings of International Conference on
Document Analysis and Recognition, pages 811 – 814, 1995.
[27] Chew Lim Tan Lijun Zhou, Yue Lu. Bangla/english script identification based on
analysis of connected component profiles. In Proceedings of the Seventh ICDAR,
pages 243–254, 2006.
[28] J. Mantas. An overview of character recognition methodologies. Pattern Recogni-
tion, 19:425–430, 1986.
[29] Anoop M. Namboodiri and Anil K. Jain. Online handwritten script recognition.
IEEE Trans. Pattern Anal. Mach. Intell., 26(1):124–130, 2004.
[30] N. Otsu. A threshold selection method from gray-level histograms. IEEE Transac-
tions on Systems, Man, and Cybernetics, 9(1):62 –66, 1979.
[31] Nobuyuki Otsu. A threshold selection method from gray-level histograms. IEEE
PAMI., 9(1):62–66, 1979.
[32] U. Pal and B. B. Chaudhuri. Machine-printed and hand-written text lines identifi-
cation. Pattern Recognition Letters, 22(3/4):431–441, 2001.
[33] U. Pal and B. B. Chaudhuri. Machine-printed and hand-written text lines identifi-
cation. Pattern Recognition Letters, 22(3/4):431–441, 2001.
[34] U. Pal and B. B. Chaudhuri. Script line separation from indian multi-script docu-
ments. IETE Journal of Researc, 49:3–11, 2003.
[35] Peeta Basa Pati and A G Ramakrishnan. Word level multi-script identification. PR
Letters., 29(9):1218–1229, 2008.
[36] U. patil and M. Begum. Word level handwritten and printed text separation based
on shape features. International Journal of Emerging Technology and Advanced
Engineering, 2(4):590 –594, 2012.
Appendix A. Output of the Project: Publications 43
[37] D. P. PATTANAYAK. Multilingualism and mother tongue education. Oxford Uni-
versity Press, Delhi, 1981.
[38] A. G. Ramakrishnan Peeta Basa Pati. Hvs inspired system for script identification
in indian multi-script documents. In Proceedings of the Seventh ICDAR, pages
380–389, 2006.
[39] Samuel J. Pinson and William A. Barrett. Connected component level discrimina-
tion of handwritten and machine-printed text using eigenfaces. In Proceedings of
International Conference on Document Analysis and Recognition, pages 1394–1398,
2011.
[40] O. Pro. :http://www.scansoft.com.
[41] G G Rajput and Anith H B. Handwritten script recognition using dct and wavelet
features at block level. In IJCA Special issue on RTIPPR, pages 158–163, 2010.
[42] G G Rajput and Anith H B. Handwritten script recognition using dct and wavelet
features at block level. In Proceedings of the International Workshop on Soft Com-
puting Applications and Knowledge Discovery (SCAKD), pages 94–101, 2011.
[43] K. Roy, A. Banerjee, and U. Pal. A system for word-wise handwritten script identifi-
cation for indian postal automation. In India Annual Conference, 2004. Proceedings
of the IEEE INDICON 2004. First, pages 266–271, 2004.
[44] K. Roy, Szilárd Vajda, Umapada Pal, and Bidyut Baran Chaudhuri. A system
towards indian postal automation. In IWFHR, pages 580–585, 2004.
[45] C. Y. Suen S. Mori and K. Yamamoto. Historical review of ocr research and devel-
opment. In Proceedings of the IEEE, volume 80, pages 1029–1058, 1992.
[46] K. Yamamoto S. Mori and M. Yasuda. Research on machine recognition of hand
printed characters. IEEE Transactions on Pattern Analysis and Machine Intelli-
gence, 6:386–405, 1984.
[47] V. Singhal, N. Navin, and D. Ghosh. Script-based classification of hand-written text
documents in a multilingual environment. In Research Issues in Data Engineering:
Multi-lingual Information Management, 2003. RIDE-MLIM 2003. Proceedings. 13th
International Workshop on, pages 47–54, 2003.
[48] S. Sinha U. Pal and B. B. Chaudhuri. Multi-script line identification from indian
documents. pages 880–884, 2003.
[49] U.Pal. Automatic script identification: A survey. Vivek, 16:26–35, 2006.
Appendix A. Output of the Project: Publications 44
[50] U.Pal and B.B.Chaudhuri. Indian script character recognition: A survey. Pattern
Recognition, 37:1887–1899, 2004.
[51] D. Ghosh V. Singhal, N. Navin. Script-based classification of hand-written text doc-
ument in a multilingual environment. In Proceedings of 13th International Workshop
RIDE’03, pages 47–54, 2003.
[52] S. Violante, R. Smith, and M. Reiss. A computationally efficient technique for
discriminating between hand-written and printed text. pages 1–17, 1995.
[53] E. Zemouri and Y. Chibani. Machine printed handwritten text discrimination using
radon transform and svm classifier. In Proceedings of the International Conference
on Intelligent Systems Design and Applications, pages 1306 –1310, 2011.
[54] Yefeng Zheng, Huiping Li, and David S. Doermann. Machine printed text and
handwriting identification in noisy document images. IEEE Transactions on Pat-
tern Analysis and Machine Intelligence, 26(3):337–353, 2003.
[55] Lijun Zhou, Yue Lu, and Chew Lim Tan. Bangla/english script identification based
on analysis of connected component profiles. In Document Analysis Systems, pages
243–254, 2006.
