Genetic Heuristic Development:  
Feature Selection for Author Identification
Joshua Adams, Henry Williams, Joi Carter, Gerry Dozier 
North Carolina A&T State University 
1601 E. Market St. 
Greensboro, NC, USA 
jcadams2|hcwillia|jncarte1@aggies.ncat.edu, gvdozier@ncat.edu
 
 
Abstract—Author identification is the process of recognizing an 
author based on a sample of text.  Feature selection is the process 
of selecting the most salient features required for recognition. In 
many cases, this results in an increase in recognition accuracy. In 
this paper, we apply Genetic and Evolutionary Feature Selection 
with Machine Learning (GEFeSML) to author identification.  We 
then introduce Genetic Heuristic Development (GHD), a process 
to improve the matching process.  GHD uses subsets of features 
found by GEFeSML to create a high performing heuristic for 
feature selection.  This technique successfully increases 
recognition accuracy while significantly reducing the number of 
features required for recognition. 
 Keywords— Author identification; Biometrics; Classification 
algorithms; Evolutionary Computation; Feature Extraction; 
Genetic Algorithms (GAs); Heuristic algorithms 
I.  INTRODUCTION 
Author identification has a long history [17].  Bosch and 
Smith worked on categorizing authorship of the Federalist 
papers [6].  Not only is this important for historical reference, it 
can be important for public safety as well.  For example, the 
FBI used author identification techniques to help identify the 
Unabomber [7].  O. de Vel et al. also explored author 
categorization techniques on e-mail content for digital forensics 
[1].     
Author identification is a form of biometric recognition 
[23].  There are four primary components to any biometric 
system: a sensor module, a feature extraction module, a 
matching module, and a database module [15].  Feature 
selection is the process of finding subsets of features that 
improve recognition accuracy.   
Genetic and Evolutionary Computations (GECs) have been 
successfully used in the area of, particularly in feature 
extraction [4] and selection [5], [12], [16]. The goal of our 
work is to apply genetic and evolutionary feature selection 
techniques to author identification.  To our knowledge, very 
little work has been done using genetic algorithms (GAs) for 
feature selection within the context of author identification, 
however in [12], Li et al. used a GA for feature selection.  They 
obtained 99.01% while reducing the required number of 
features by over 50%.  For their dataset, they used a small set 
of 10 authors with 30 - 40 messages each and they trained on 
their entire dataset.   
The ultimate goal of this research is to create a heuristic for 
feature selection.  By developing a heuristic, we are able to 
determine the features in a specific feature extraction technique 
that are salient across most text samples.  
The remainder of this paper is as follows.  Section II 
provides a formal definition of the feature selection problem as 
well as background information on the techniques used in this 
paper, including authorship analysis, genetic and evolutionary 
computation, cross validation, and genetic and evolutionary 
feature selection.  Section III details the process of Genetic 
Heuristic Development.  Our experiments and results are 
provided in Section IV and V respectively.  Finally, in Section 
VI, we present our conclusions and future work. 
II. BACKGROUND 
A. The Feature Selection Problem 
The Feature Selection Problem (FSP) [16], [18], [21], [22], 
[27] can be viewed as a five tuple <S,X,T,V, > where S 
represents a set of n subjects, S = {s0, s1, …, sn-1}, X represents 
a set of n times q instances X = {x0,0, x0,1, …, xn-1,q-1}, where 
each si  S has q instances in X, and where T, V, and  are 
mutually exclusive subsets of X representing the training, 
validation, and test sets of instances taken from X.  
Given the above definition, three forms of FSPs can be 
defined:  
• In the Feature Selection Optimization Problem (FSOP), T 
= X (V and  are empty).  The objective in solving the 
FSOP is to reduce the number of features while increasing 
recognition accuracy. The resulting feature mask can then 
be used for the development of a Gentile-based two stage 
hierarchical biometric recognition system as presented in 
[18, 22].    
• In the Type I Feature Selection Generalization Problem 
(FSGP-I), the objective is to generalize to unseen 
instances of subjects. Therefore, the sets T, V, and  are 
mutually exclusive subsets of X; however, each contains 
instances of each of the n subjects of S.     
• In the Type II Feature Selection Generalization Problem 
(FSGP-II), the objective is to generalize to unseen 
subjects. Therefore, T, V, and  are mutually exclusive 
subsets of X as well as being mutually exclusive in terms 
of the subjects in S.    
36978-1-4673-5879-8/13/$31.00 c©2013 IEEE
Of these three FSPs, FSGP-II is the most difficult to solve. This 
is the type of problem addressed in this paper. 
B. Author Identification 
Authorship analysis is a discipline that can be used to 
examine text samples [11].  We are particularly interested in 
the topic of author identification, also known as authorship 
categorization. Authorship categorization is defined by O. de 
Vel et al. [1] as “the task of determining the author of a piece 
of work.” The focus of this paper, like theirs, is to identify the 
author of digital text. Handwritten text also has a long history 
of authorship categorization as explained in [29], but cannot be 
applied to our purposes.  
The process of author identification is typically completed 
by analyzing and comparing anonymous text samples with 
other pieces of text from known authors [17].  Characteristics 
of a text sample can be represented as a feature vector.  A 
simple distance metric, such as Manhattan or Euclidean 
distance, can be used to measure the distance between two 
feature vectors.  If there is a small distance between two 
samples of text, it is likely that both samples were created by 
the same author.  If there is a large distance, it is unlikely that 
both samples have the same author.  The magnitude of the 
distance depends primarily on the Feature Extractor (FE) used.  
Common features used in FEs are function words, 
typographical characters, stylistic metrics, and rarely occurring 
words [6], [8]-[10]. 
In [1], the proposed FE extracted 170 style based features 
along with 21 structural features.  The style based features 
included the number of blank lines, the average sentence 
length, the total number of function words as well as the 
frequency distribution of 122 different function words.  The 
structural features included e-mail specific attributes such as 
the number of attachments, HTML tag frequency distributions 
and different acknowledgements.   
C. Genetic and Evolutionary Computation 
Genetic and Evolutionary Computations (GECs) are 
problems solvers that operate by simulating evolution [2], [3].  
In natural selection, the best individuals within a population 
have a higher probability of surviving and reproducing [3], 
[24].  GECs simulate evolution in the following way:  First, a 
population of candidate solutions (CSs) is randomly generated.  
Each CS is then evaluated and assigned a fitness.  CSs are then 
selected to be parents and are allowed to reproduce. This 
reproduction process results in the creation of a set of 
offspring.  Each of the offspring are then evaluated and 
assigned a fitness.  Individuals in the population are selected 
and replaced by the offspring.  This process continues until a 
user specified stopping condition is satisfied. 
D. Cross Validation 
Cross Validation is a technique commonly used in machine 
learning to prevent overfitting of training data [26].    
Overfitting causes a machine learning technique to perform 
well on seen instances but poorly on unseen instances.  Cross 
validation allows a machine learning technique to generalize 
well to unseen instances. 
In this paper, cross validation is performed by dividing the 
instances of a dataset into three mutually exclusive sets: a 
training set, a validation set and a test set.  Training is 
performed on the training set.  The validation set is used to 
keep track of solutions that perform well on unseen instances.  
The test set is used to test how well solutions generalize to 
unseen instances.  By using cross validation, we can solve 
feature selection generalization problems (FSGP-I & FSGP-II) 
instead of just the feature selection optimization problem. 
E. Feature Selection with Cross Validation 
Genetic and Evolutionary Feature Selection using Machine 
Learning (GEFeSML) uses a GEC to evolve a population of 
candidate Feature Masks (FMs) [13]. It also uses cross 
validation to solve the feature set generalization problem. 
In GEFeS, each FM is represented by a set of genes, where 
each gene is a real value between 0 and 1.  A masking 
threshold is used to determine if a feature will contribute to the 
matching process.  If a gene is less than the masking threshold, 
the corresponding feature is given a weight of 0 so it does not 
contribute to the distance when comparing subjects using a 
distance metric.  If a gene is greater than or equal to the 
masking threshold, a weight of 1 is given so the feature fully 
contributes to the distance. 
An evaluation function is used determine the fitness of a 
FM by calculating the weighted Manhattan distance between 
each instance in a probe set and each instance in a gallery set.  
The weighted Manhattan distance is shown in (2), where w is 
the set of weights, v1 is one feature vector and v2 is the other.   
 
dm =  wi * | v1,i – v2,i |  (2) 
 
When comparing a single probe instance to each instance in 
the gallery, the smallest distance is recorded as the match. If 
the matching subjects are different, an error is recorded. The 
result of the evaluation function, shown in (3), is the number of 
errors (e) times ten, plus the percent of features being used. The 
number of errors is multiplied by 10 so that the error rate has a 
larger effect on the fitness than the percentage of features. 
Without this, the fitness of a candidate solution with five errors 
using 100% of the features would be the same as a different 
candidate solution with six errors using none of the features. 
The goal of the genetic algorithm is to minimize the fitness. 
Cross validation is used in an effort to evolve FMs that 
generalize well the unseen subjects. 
 
fitness = 10  + (usedFeatures/totalFeatures) (3) 
 
In implementing cross validation, GEFeSML also calculates 
the fitness of a FM with respect to a validation set.  If the  
fitness of an evaluated FM is better than the  fitness of the best 
FM on the validation set, the  newer FM replaces the current 
best FM. The performances (fitnesses) of the FMs on the 
validation set are never assigned to a candidate FM.  After the 
stopping condition for the GEC has been met, the best FM 
2013 IEEE Symposium on Computational Intelligence in Biometrics and Identity Management (CIBIM) 37
within the population, FMts, and the best performing FM on the 
validation set, FM* are extracted.  These FMs are then applied 
to the test set to see how well they generalize to unseen 
subjects.  
III. GENETIC HEURISTIC DEVELOPMENT 
The process of Genetic Heuristic Development (GHD) 
begins with GEFeSML.  After running GEFeSML a number of 
times, a heuristic can be developed.  The first step to 
developing this heuristic is collecting all of the best feature 
masks from the validation set.  A Feature Frequency Histogram 
(FFH) can then be generated.  Each value within this FFH 
represents the percentage of times a single feature was used in 
all of the best feature masks.  For example, if GEFeSML was 
run 30 times, each value in the FFH would be a whole number 
between 0 and 30.  If the first feature was used 27 times, the 
first value in the histogram would be 27.  The percentage with 
which it appeared would be 90%. 
Once a FFH has been created, a feature frequency threshold 
must be selected.  A new feature mask can be created so that a 
feature will be turned on if its value within the FFH is greater 
than, or equal to, the feature frequency threshold.  For example, 
if a feature’s FFH value is 0.7 and the feature frequency value 
is 0.9, then the feature will be masked. 
IV. EXPERIMENTS 
The dataset used in our experiments was collected from 
blog posting on several news related websites and is composed 
of 300 instances from 100 authors [19], [20].  100 total unique 
blog posts were collected, at random times, from 
huffingtonpost.com [19] and cnn.com [20].  Each of these blog 
post instances were then evenly divided by lines into three 
separate instances.  Next, ten random permutations were 
created for the ordering of the subjects and their associated 
instances.  For each of the random sets, 60 subjects (and their 
associated 180 instances) were used to form the training set, 20 
subjects (60 instances) were used to form the validation set, 
and 20 subjects (60 instances) were used to form the test set.  
The first instance of each subject was placed into a probe set 
and the remaining two instances were placed into the gallery 
set.  
Our feature extraction technique is similar to that described 
by O. de Vel et al. [1].  It extracted 170 style based features.  
We did not include the 21 structural features because we were 
using blog posts that had no specific e-mail structure such as 
greeting/farewell acknowledgements, quoted reply text, or 
HTML tags.  A list of these features is shown in Fig 1 where M 
is the total number of words, V is the total number of distinct 
words, and C is the total number of characters in document. 
 
 
 
 
 
 
Stylometric Features 
Number of blank lines/total number of lines 
Average sentence length 
Average word length(number of characters) 
Vocabulary richness i.e., V/M 
Total number of function words/M 
Function words (122) 
Total number of short words/M 
Count of hapax legomena/M 
Count of hapax legomena/V 
Number of characters in words/C 
Number of alphabetic characters in words/C 
Number of upper-case chars/C 
Number of digit characters in words/C 
Number of white space characters/C 
Number of space characters/C 
Number of space characters/white space characters 
Number of tab spaces/C 
Number of tabs spaces/number of white spaces 
Number of punctuations/C 
Word length frequency distribution/M (30) 
Fig 1:  Description of features extracted using proposed 
feature extraction  
 
V. RESULTS 
In order to generate the results presented in this section we 
did the following: For training, we used the Steady-State 
Genetic Algorithm (SSGA) provided in X-TOOLSS [28] (the 
eXploration Toolset for the Optimization Of Launch and Space 
Systems).  This software package contains a variety of GECs to 
be used with any type of optimization problem.  The splash 
screen for this application is shown in Fig 2.  The SSGA 
provided uses binary tournament selection [3], uniform 
crossover and Gaussian mutation [25]. 
Our SSGA used a population size of 20 with mutation 
usage rate of 1.0 and crossover usage rate of 1.0.  We also 
selected a mutation range of 0.2.  An example of these settings 
is provided in Fig 3.  Our population size is the number of 
individuals in our population at any given generation.  The 
crossover usage rate represents the probability that crossover 
will be applied to an individual and mutation usage rate is the 
probability that an individual will be mutated.  The mutation 
rate indicates the probability of mutating an individual gene 
and the mutation range describes how much a gene will be 
mutated.  The number of total evaluations represents our 
stopping condition. 
 
38 2013 IEEE Symposium on Computational Intelligence in Biometrics and Identity Management (CIBIM)
Fig 2: X-TOOLSS (http://nxt.ncat.e
 
Fig 3:  This figure shows the paramet
the SSGA in X-TOOLSS
 
Because our preliminary results showe
difference between 500, 1,000 and 2,000 func
only 500 function evaluations were used in the
total of 30 runs were performed on each of t
datasets for a total of 300 runs. 
After training was completed, the best fea
the validation set (300 feature masks total) wer
respective test set.   A heuristic was then deve
300 best feature masks on the validation set.  
Our experimental results are provided in Ta
For each of our tables, the first column indic
used with a specific dataset.  The second colu
accuracy or average accuracy of that metho
column gives the average percentage of baselin
Table I provides the baseline results (using
for each of the 10 permuted datasets.  The ave
21.50%.   The worst accuracy is 0.00% on per
The best accuracy is 35.00% on permuted Da
One can see from the random permutations o
accuracy of the test set varies greatly dependin
in the set.  Table II provides the accuracy of
can see that GEFeSML more than doubles the a
 
du/) 
 
ers used for 
. 
d no statistical 
tion evaluations, 
 experiments.  A 
he ten permuted 
ture masks from 
e applied to their 
loped from those 
bles I, II and III.  
ates the method 
mn provides the 
d, and the third 
e features used. 
 all 170 features) 
rage accuracy is 
muted Dataset 8.  
tasets 9 and 10.  
f the dataset, the 
g on the subjects 
 GEFeSML.  One 
verage accuracy 
of the baseline while using less th
features.  Average accuracy ranges
Table III provides the average acc
and compares it to GEFeSML and 
heuristic performs the best, achievi
57.00% while using only 17.86% mo
 
TABLE I.  BASEL
Baseline Test Set 
Method Accurac
Baseline-1 30.00%
Baseline-2 20.00%
Baseline-3 25.00%
Baseline-4 15.00%
Baseline-5 15.00%
Baseline-6 25.00%
Baseline- 7 15.00%
Baseline-8 00.00%
Baseline-9 35.00%
Baseline-10 35.00%
Average Test Baseline 
(de Vel, 170 Features) 21.50%
TABLE II.  GEFES
GEFeSML Validation-Gener
Method Average Acc
GEFeSML-1 52.67%
GEFeSML-2 43.33%
GEFeSML-3 41.00%
GEFeSML-4 34.67%
GEFeSML-5 48.67%
GEFeSML-6 41.50%
GEFeSML-7 44.33%
GEFeSML-8 45.67%
GEFeSML-9 39.83%
GEFeSML-10 42.67%
GEFeSML (Average) 43.43%
TABLE III.  GENETIC & EVOLUTI
Genetic Heuristic Test
Method Average Acc
Average Test Baseline 21.50%
GEFeSML (Average) 43.43%
Genetic Heuristic 57.00%
 
an half of the original 170 
 from 34.67% to 52.67%.  
uracy of our best heuristic 
the baseline method.  Our 
ng an average accuracy of 
re features than GEFeSML. 
INE RESULTS 
Results 
y Percent of Baseline Features 
 100.00% 
 100.00% 
 100.00% 
 100.00% 
 100.00% 
 100.00% 
 100.00% 
 100.00% 
 100.00% 
 100.00% 
 100.0% 
ML RESULTS 
alization Results 
uracy Percent of Baseline Features 
 46.35% 
 47.06% 
 47.02% 
 46.33% 
 46.98% 
 47.76% 
 46.06% 
 47.29% 
 47.16% 
 47.08% 
 46.91% 
ONARY HEURISTIC RESULT 
 Set Results 
uracy Percent of Baseline Features 
 100.00% 
 46.91% 
 55.29% 
2013 IEEE Symposium on Computational Intelligence in Biometrics and Identity Management (CIBIM) 39
Fig 4 shows the FFH.  In this figure, the frequency 
with which each feature is provided.  A frequency of 0.5 
indicates that the feature was used 150 out of 300 times.  Fig 5 
shows the accuracy of our heuristic with different feature 
frequency thresholds.  With a feature frequency threshold of 
47%, we were able to achieve an average validation set 
accuracy of 62.5%.  This same feature mask was then applied 
to each of the random test sets, achieving an average accuracy 
of 57%. 
 
 
Fig 4:  This figure shows the frequency in which each 
feature was used by the 300 best validation masks. 
 
 
Fig 5:  This figure shows the average accuracy of the 
heuristic based feature masks at different frequency 
thresholds when applied to the validation and test sets. 
VI. CONCLUSIONS & FUTURE WORK 
The developed genetic heuristic outperformed the baseline 
feature extraction technique in terms of accuracy on every 
random permutation of our dataset.  The average accuracy of 
GEFeSML is more than double the average accuracy of the 
baseline technique with less than 50% of the features.  Our 
genetic heuristic had an improved accuracy of more than 
31.25% over the accuracy obtained by GEFeSML.  This is a 
significant improvement when generalizing to unseen subjects. 
For future work, we would like to adapt GEFeWML and 
GEFeWSML for creating heuristics for both feature weighting 
and selection.  Other future work will consist of gathering a 
larger dataset to see how this technique scales with a larger 
population of subjects.   
ACKNOWLEDGMENT 
This research was funded by The Office of the Director of 
National Intelligence (ODNI), Center for Academic Excellence 
(CAE) for the multi-university, Center for Advance Studies in 
Identity Sciences (CASIS) and by the National Science 
Foundation (NSF), Science & Technology Center. 
Bio/Computational Evolution in Action Consortium 
(BEACON). The authors would like to thank the ODNI and the 
NSF for their support of this research. 
 
  
REFERENCES 
[1] O. de Vel, A. Anderson, M.Corney, and G. Mohay, “Mining e-mail 
conten for author identification forensics,”  SIGMOD Record, vol. 30, 
no. 4, 2001, pp. 55-64. 
[2] D. E. Goldberg, “Genetic algorithms in search, optimization & machine 
learning”, Addison-Wesley Publishing Company, Inc., Reading, 
Massachusetts, 1989. 
[3] G. Dozier, A. Homaifar, E. Tunstel and D. Battle, “An introduction to 
evolutionary computation”, intelligent control systems using soft 
computing methodologies, chapter 17, A. Zilouchian and M. Jamshidi 
(Eds.), pp. 365-380, CRC press, 2001. 
[4] J. Shelton, G. Dozier, K. Bryant, L. Small, J. Adams, K. Popplewell, T. 
Abegaz, A. Alford, D. Woodard, K. Ricanek, “Genetic and Evolutionary 
Feature Extraction via X-TOOLSS,”  The 8th International Conference 
on Genetic and Evolutionary Methods (GEM), 2011. 
[5] A. Alford, K. Bryant, T. Abegaz, G. Dozier, J. Kelly, J. Shelton, L. 
Small, J. Williams, and D. L Woodard, “Genetic & Evolutionary 
Methods for Biometric Feature Reduction,” Special Issue on 
Computational Intelligence in Biometrics: Theory, Methods and 
Applications, Guest Editor: Qinghan Xiao, International Journal of 
Biometrics, 2011. 
[6] R. Bosch and J. Smith, “Separating hyperplanes and the authorship of 
the disputed federalist papers”, American Mathematical Monthly, 
105(7):601-608, 1998. 
[7] C. Crain. “The Bard's fingerprints”, Lingua Franca, pages 29 - 39, 1998. 
[8] P. Sallis, S. MacDonell, G. MacLennan, A. Gray, and R. Kilgour. 
“Identifed: Software Authorship Analysis with Case-Based Reasoning". 
In Proc. Addendum Session Int. Conf. Neural Info. Processing and 
Intelligent Info. Systems, pages 53-56, 1997. 
[9] I. Krsul. “Authorship analysis: Identifying the author of a program". 
Technical report, Department of Computer Science, Purdue University, 
1994. Technical Report CSD-TR-94-030. 
[10] I. Krsul and E. Spa_ord. “Authorship analysis: Identifying the author of 
a program". Computers and Security, 16:248-259, 1997. 
[11] A. Gray, P. Sallis, and S. MacDonell. “Software Forensics: Extending 
Authorship Analysis Techniques to Computer Programs". In Proc. 3rd 
Biannual Conf. Int. Assoc. of Forensic Linguists (IAFL'97), pages 1-8, 
1997. 
[12] J. Li, R. Zheng, and H. Chen, “From Fingerprint to Writeprint,” In 
Communications of the ACM, Vol. 90, No. 4, Pages 76-82, April, 2006. 
[13] A. Alford, C. Steed, M. Jeffrey, D. Sweet, J. Shelton, L. Small, D. 
Leflore, G. Dozier, K. Bryant, T. Abegaz, J. Kelly, and K. Ricanek, 
“Genetic & Evolutionary Biometrics: Hybrid Feature Selection and 
0
0.2
0.4
0.6
0.8
1
1 13 25 37 49 61 73 85 97 10
9
12
1
13
3
14
5
15
7
16
9
Fr
eq
ue
nc
y
Feature
Feature Frequency Histogram
0
0.2
0.4
0.6
0.8
0
0.
12
0.
24
0.
36
0.
48 0.
6
0.
72
0.
84
0.
96
A
cc
ur
ac
y
Feature Frequency Threshold
Feature Frequency Threshold Accuracies
Avg. Test Set 
Accuracy
Avg. Val. Set 
Accuracy
40 2013 IEEE Symposium on Computational Intelligence in Biometrics and Identity Management (CIBIM)
Weighting for a Multi-Modal Biometric System,” Southeastcon, 2012 
Proceedings of IEEE, pp. 1-8, March 15-18, 2012. 
[14] X-TOOLSS (eXploration Toolset for the Optimization Of Launch and 
Space Systems), http://nxt.ncat.edu/, Nov. 20, 2012. 
[15] A. K. Jain and A. Ross. Introduction to biometrics. Handbook of 
Biometrics (EDs: Jain, Flynn, and Ross), pages 1–22, 2008. 
[16] J. Adams, D.L. Woodard, G. Dozier, P. Miller, K. Bryant, and G. Glenn, 
“Genetic-based type II feature extraction for periocular biometric 
recognition: less is more,” In Proc. Int. Conf. on Pattern Recognition, , 
Istanbul, pp. 205 – 208, 2010. 
[17] E. Stamatatos, “A survey of modern authorship attribution methods,” 
Journal of the American Society for Information Science and 
Technology, Dec. 16, 2008. 
[18] A. Alford, K. Bryant, T. Abegaz, G. Dozier, J. Kelly, J. Shelton, L. 
Small, J. Williams, D. Woodard, K. Ricanek, “Genetic and evolutionary 
methods for biometric feature selection,” International Journal of 
Biometrics, Vol. 4, Pages 220-245, July 9, 2012. 
[19] Huffington Post, http://www.huffingtonpost.com/the-blog/, Aug 29 – 
Sept 18, 2012. 
[20] CNN.com Opinon, http://www.cnn.com/opinion/ Aug 29 – Sept 18, 
2012. 
[21] A. Alford, K. Popplewell, G. Dozier, K. Bryant, J. Kelly, J. Adams, T. 
Abegaz, J. Shelton, K. Ricanek, D. Woodard, “A comparison of GEC-
based feature selection and weighting for multimodal biometric 
recognition,” IEEE Congress on Evolutionary Computation (CEC), 
pp.2725-2728, June 5 - 8, 2011. 
[22] J. Gentile, N. Ratha, J. Connell, “An efficient, two-stage iris recognition 
system,” IEEE 3rd International Conference on Biometrics: Theory, 
Applications, and Systems, BTAS, pp. 1-5, Sept. 28-30, 2009. 
[23] N. Ali, M. Hindi, R. Yampolskiy, “Evaluation of Authorship Attribution 
Software on a Chat Bot Corpus,” 2011 XXIII International Symposium 
on Communication and Automation Technologies (ICAT), pp. 1-6, Oct. 
27-29, 2011. 
[24] C. Darwin, “The origin of species,” London: John Murray, 1872. 
[25] G. Syswerda, “Uniform crossover in genetic algorithms,” Proceedings of 
the 3rd International Conferene on Genetic Algorithms, San Francisco, 
CA, 1989. 
[26] T. Mitchell, Machine Learning, McGraw Hill, 1997. 
[27] A. Alford, J. Adams, J. Shelton, G. V. Dozier, K. Bryant, and J. C. 
Kelly, “Genetic & Evolutionary Biometrics: Exploring Value Preference 
Space for Hybrid Featrue Weighting and Selection,”  to appear in the 
International Journal of Intelligent Computing & Cybernetics Vol. 6, 
Issue 1. 
[28] http://nxt.ncat.edu 
[29] V. Pervoichine and G. Leedham, “Extraction and analysis of forensic 
document examiner features used for writer identification,” Pattern 
Recognit., vol. 40, pp. 1004–1013, 2007. 
 
2013 IEEE Symposium on Computational Intelligence in Biometrics and Identity Management (CIBIM) 41
