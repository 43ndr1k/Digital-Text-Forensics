171H. Chen, Dark Web: Exploring and Data Mining the Dark Side of the Web, 
Integrated Series in Information Systems 30, DOI 10.1007/978-1-4614-1557-2_10, 
© Springer Science+Business Media, LLC 2012
 1  Introduction 
 Analysis of Web content is becoming increasingly important due to augmented 
communication via computer-mediated communication (CMC) Internet sources 
such as e-mail, Web sites, forums, and chat rooms. The numerous benefi ts of the 
Internet and CMC have been coupled with the realization of some vices, including 
cybercrime. In addition to misuse in the form of deception, identity theft, and the 
sales and distribution of pirated software, the Internet has also become a popular 
communication medium and haven for extremist and hate groups. This problematic 
facet of the Internet is often referred to as the Dark Web (Chen  2006 ) . 
 Stormfront, what many consider to be the fi rst hate group Web site (Kaplan and 
Weinberg  1998 ) , was created around 1996. Since then, researchers and hate watch 
organizations have begun to focus their attention toward studying and monitoring 
such online groups (Leets  2001 ) . Despite the increased focus on analysis of such 
group’s Web content, there has been limited evaluation of forum postings, with the 
majority of studies focusing on Web sites. Burris et al.  ( 2000 ) acknowledged that 
there was a need to evaluate forum and chat room discussion content. Schafer  ( 2002 ) 
also stated that it was unclear as to how much and what kind of forum activity was 
going on with respect to hateful cyber activist groups. Due to the lack of under-
standing and current ambiguity associated with the content of such groups’ forum 
postings, analysis of extremist group forum archives is an important endeavor. 
 Sentiment analysis attempts to identify and analyze opinions and emotions. 
Hearst  ( 1992 ) and Wiebe  ( 1994 ) originally proposed the idea of mining direction-
based text, i.e., text containing opinions, sentiments, affects, and biases. Traditional 
forms of content analysis, such as topical analysis, may not be effective for forums. 
Nigam and Hurst  ( 2004 ) found that only 3% of Usenet sentences contained topical 
information. In contrast, Web discourse is rich in sentiment-related information 
(Subasic and Huettner  2001 ) . Consequently, in recent years, sentiment analysis 
has been applied to various forms of Web-based discourse (Agrawal et al.  2003 ; 
 Chapter 10 
 Sentiment Analysis 
172 10 Sentiment Analysis
Efron  2004 ) . Application to extremist group forums can provide insight into signifi cant 
discussions and trends. 
 In this study, we propose the application of sentiment analysis techniques to 
hate/extremist group’s forum postings. Our analysis encompasses classifi cation of 
sentiments on two forums: a US supremacist and Middle Eastern extremist group. 
The remainder of this chapter is organized as follows. Section  2 presents a review of 
current research on sentiment classifi cation. Section  3 describes research gaps and 
questions, while Sect.  4 presents our research design. Section  5 describes the EWGA 
algorithm and our proposed feature set. Section  6 presents experiments used to eval-
uate the effectiveness of the proposed approach and discussion of the results. 
Section  7 concludes with closing remarks and future directions. 
 2  Related Work 
 Extremist groups often use the Internet to promote hatred and violence (Glaser et al. 
 2002 ) . The Internet offers a ubiquitous, quick, inexpensive, and anonymous means 
of communication for such groups (Crilley  2001 ) . Zhou et al.  ( 2005 ) did an in-depth 
analysis of US hate group Web sites and found signifi cant evidence of fundraising, 
propaganda, and recruitment-related content. Abbasi and Chen  ( 2005 ) also corrobo-
rated signs of Web usage as a medium for propaganda by US supremacist and 
Middle Eastern extremist groups. These fi ndings provide insight into extremist 
group Web usage tendencies; however, there has been little analysis of Web forums. 
Burris et al.  ( 2000 ) acknowledged the need to evaluate forum and chat room discus-
sion content. Schafer  ( 2002 ) was also unclear as to how much and what kind of 
forum activity was going on with respect to extremist groups. Automated analysis 
of Web forums can be an arduous endeavor due to the large volumes of noisy infor-
mation contained in CMC archives. Consequently, previous studies have predomi-
nantly incorporated manual or semiautomated methods (Zhou et al.  2005 ) . Manual 
examination of thousands of messages can be an extremely tedious effort when 
applied across thousands of forum postings. With increasing usage of CMC, the 
need for automated text classifi cation and analysis techniques has grown in recent 
years. While numerous forms of text classifi cation exist, we focus primarily on 
sentiment analysis for two reasons. First, Web discourse is rich in opinion and emo-
tion-related content. Second, analysis of this type of text is highly relevant to propa-
ganda usage on the Web since directional/opinionated text plays an important role 
in infl uencing people’s perceptions and decision making (Picard  1997 ) . 
 2.1  Sentiment Classifi cation 
 Sentiment analysis is concerned with analysis of direction-based text, i.e., text con-
taining opinions and emotions. We focus on sentiment classifi cation studies which 
attempt to determine whether a text is objective or subjective, or whether a subjective 
1732 Related Work
text contains positive or negative sentiments. Sentiment classifi cation has several 
important characteristics including the various tasks, features, techniques, and appli-
cation domains. These are summarized in the taxonomy presented in Table  10.1 . 
 We are concerned with classifying sentiments in extremist group forums. Based 
on the proposed taxonomy, Table  10.2 shows selected previous studies dealing with 
sentiment classifi cation. We discuss the taxonomy and related studies in detail 
below. 
 2.2  Sentiment Analysis Tasks 
 There have been several sentiment polarity classifi cation tasks. Three important 
characteristics of the various sentiment polarity classifi cation tasks are the classes, 
classifi cation levels, and assumptions about sentiment source and target (topic). The 
common two-class problem involves classifying sentiments as positive or negative 
(Pang et al.  2002 ; Turney  2002 ) . Additional variations include classifying messages 
as opinionated/subjective or factual/objective (Wiebe et al.  2001,  2004 ) . A closely 
related problem is affect classifi cation which attempts to classify emotions instead 
of sentiments. Examples of affect classes include happiness, sadness, anger, horror, 
etc. (Subasic and Huettner  2001 ; Grefenstette et al.  2004 ; Mishne  2005 ) . 
 Sentiment polarity classifi cation can be conducted at the document, sentence, or 
phrase (part of sentence) level. Document-level polarity categorization attempts to 
 Table 10.1  A taxonomy of sentiment polarity classifi cation 
 Tasks 
 Category  Description  Label 
 Classes  Positive/negative sentiments or objective/subjective texts  C1 
 Level  Document- or sentence-/phrase-level classifi cation  C2 
 Source  Whether source/target of sentiment is known or extracted  C3 
 Features 
 Category  Examples  Label 
 Syntactic  Word/POS tag n-grams, phrase patterns, punctuation  F1 
 Semantic  Polarity tags, appraisal groups, semantic orientation  F2 
 Link-based  Web links, send/reply patterns, and document citations  F3 
 Stylistic  Lexical and structural measures of style  F4 
 Techniques 
 Category  Examples  Label 
 Machine learning  Techniques such as SVM, naïve Bayes, etc.  T1 
 Link analysis  Citation analysis and message send/reply patterns  T2 
 Similarity score  Phrase pattern matching, frequency counts, etc.  T3 
 Domains 
 Category  Description  Label 
 Reviews  Product, movie, and music reviews  D1 
 Web discourse  Web forums and blogs  D2 
 News articles  Online news articles and Web pages  D3 
174 10 Sentiment Analysis
classify sentiments in movie reviews, news articles, or Web forum postings (Wiebe 
et al.  2001 ; Pang et al.  2002 ; Mullen and Collier  2004 ; Pang and Lee  2004 ; Whitelaw 
et al.  2005 ) . Sentence-level polarity categorization attempts to classify positive and 
negative sentiments for each sentence (Yi et al.  2003 ; Mullen and Collier  2004 ; Pang 
and Lee  2004 ) or whether a sentence is subjective or objective (Riloff et al.  2003 ) . 
There has also been work on phrase-level categorization in order to capture multiple 
sentiments that may be present within a single sentence (Wilson et al.  2005 ) . 
 In addition to sentiment classes and categorization levels, different assumptions 
have also been made about the sentiment sources and targets (Yi et al.  2003 ) . In this 
study, we focus on document-level sentiment polarity categorization (i.e., distin-
guishing positive and negative sentiment texts). However, we also review related 
sentence-level and subjectivity classifi cation studies due to the relevance of the fea-
tures and techniques utilized and the application domains. 
 Table 10.2  Selected previous studies in sentiment polarity classifi cation 
 Study  Features 
 Reduce 
features  Techniques  Domains 
 Number of 
languages 
   F1  F2  F3  F4  Yes/No  T1  T2  T3  D1  D2  D3  1-n 
 Subasic and Huettner 
 2001 
     No      1 
 Tong  2001      No      1 
 Morinaga et al.  2002    Yes      1 
 Pang et al.  2002    No      1 
 Turney  2002      No      1 
 Agrawal et al.  2003      No        1 
 Dave et al.  2003    No        1 
 Nasukawa and Yi  2003      No      1 
 Riloff et al.  2003      No      1 
 Yi et al.  2003      Yes        1 
 Yu and Hatzivassiloglou 
 2003 
     No        1 
 Beineke et al.  2004    No        1 
 Efron  2004      No        1 
 Fei et al.  2004    No      1 
 Gamon  2004      Yes      1 
 Grefenstette et al.  2004      No      1 
 Hu and Liu  2004      No      1 
 Kanayama et al.  2004      No      1 
 Kim and Hovy  2004    No      1 
 Pang and Lee  2004      No        1 
 Mullen and Collier  2004      No      1 
 Nigam and Hurst  2004      No      1 
 Wiebe et al.  2004      Yes          1 
 Liu et al.  2005      No      1 
 Mishne  2005        No      1 
 Whitelaw et al.  2005      No      1 
 Wilson et al.  2005      No      1 
1752 Related Work
 2.3  Sentiment Analysis Features 
 There are four feature categories that have been used in previous sentiment analysis 
studies. These include syntactic, semantic, link-based, and stylistic features. Along 
with semantic features, syntactic attributes are the most commonly used set of fea-
tures for sentiment analysis. These include word n-grams (Pang et al.  2002 ; Gamon 
 2004 ) , part-of-speech (POS) tags (Pang et al.  2002 ; Yi et al.  2003 ; Gamon  2004 ) , 
and punctuation. Additional syntactic features include phrase patterns, which make 
use of POS tag n-gram patterns (Nasukawa and Yi  2003 ; Yi et al.  2003 ; Fei et al. 
 2004 ) . They noted that phrase patterns such as “n + aj” (noun followed by positive 
adjective) typically represented positive sentiment orientation while “n + dj” (noun 
followed by negative adjective) often expressed negative sentiment (Fei et al.  2004 ) . 
Wiebe et al.  ( 2004 ) used collocations, where certain parts of fi xed word n-grams 
were replaced with general word tags, thereby also creating n-gram phrase patterns. 
For example, the pattern “U-adj as-prep” would be used to signify all bigrams con-
taining a unique (once occurring) adjective followed by the preposition “as.” 
Whitelaw et al.  ( 2005 ) used a set of modifi er features (e.g., very, mostly, not); the 
presence of these features transformed appraisal attributes for lexicon items. 
 Semantic features incorporate manual/semiautomatic or fully automatic annota-
tion techniques to add polarity or affect intensity-related scores to words and 
phrases. Hatzivassiloglou and McKeown  ( 1997 ) proposed a semantic orientation 
(SO) method later extended by Turney  ( 2002 ) that uses a mutual information calcu-
lation to automatically compute the SO score for each word/phrase. The score is 
computed by taking the mutual information between a phrase and the word “excel-
lent” and subtracting the mutual information between the same phrase and the word 
“poor.” In addition to pointwise mutual information, the SO approach was later also 
evaluated using latent semantic analysis (Turney and Littman  2003 ) . 
 Manually or semiautomatically generated sentiment lexicons (e.g., Tong  2001 ; 
Fei et al.  2004 ; Wilson et al.  2005 ) typically use an initial set of automatically gen-
erated terms which are manually fi ltered and coded with polarity and intensity 
information. The user-defi ned tags are incorporated to indicate whether certain 
phrases convey positive or negative sentiment. Riloff et al.  ( 2003 ) used semiauto-
matic lexicon generation tools to construct sets of strong subjectivity, weak subjec-
tivity, and objective nouns. Their approach outperformed the use of other features, 
including bag-of-words, for classifi cation of objective versus subjective English 
documents. Appraisal groups (Whitelaw et al.  2005 ) are another effective method 
for annotating semantics to words/phrases. Initial term lists are generated using 
WordNet, which are then fi ltered manually to construct the lexicon. Developed 
based on appraisal theory (Martin and White  2005 ) , each expression is manually 
classifi ed into various appraisal classes. These classes include attitude, orientation, 
graduation, and polarity of phrases. Whitelaw et al.  ( 2005 ) were able to get very 
good accuracy using appraisal groups on a movie review corpus, outperforming 
several previous studies (e.g., Mullen and Collier  2004 ) , the automated mutual-
information-based approach (Turney  2002 ) , as well as the use of syntactic features 
176 10 Sentiment Analysis
(Pang et al.  2002 ) . Manually crafted lexicons have also been used for affect analysis. 
Subasic and Huettner  ( 2001 ) used affect lexicons along with fuzzy semantic typing 
for affect analysis of news articles and movie reviews.  Abbasi and Chen  ( 2007, 
 2008 ) used manually constructed affect lexicons for analysis of hate and violence in 
extremist Web forums. 
 Other semantic attributes include contextual features representing the semantic 
orientation of surrounding text, which have been useful for sentence-level sentiment 
classifi cation. Riloff et al.  ( 2003 ) utilized semantic features that considered the sub-
jectivity and objectivity of text surrounding a sentence. Their attributes measured 
the level of subjective and objective clues in the sentence prior to and following the 
sentence of interest. Pang and Lee  ( 2004 ) also leveraged coherence in discourse by 
considering the level of subjectivity of sentences in close proximity to the sentence 
of interest. 
 Link-based features use link/citation analysis to determine sentiments for Web 
artifacts and documents. Efron  ( 2004 ) found that opinion Web pages heavily link-
ing to each other often shared similar sentiments. Agrawal et al.  ( 2003 ) observed 
the exact opposite for Usenet newsgroups discussing issues such as abortion and 
gun control. They noticed that forum replies tended to be antagonistic. Due to the 
limited usage of link-based features, it is unclear how effective they may be for 
sentiment classifi cation. Furthermore, unlike Web pages and Usenet, other forums 
may not have a clear message link structure, and some forums are serial (no 
threads). 
 Stylistic attributes include lexical and structural attributes incorporated in numer-
ous prior stylometric/authorship studies (e.g., De Vel et al.  2001 ; Zheng et al.  2006 ) . 
However, lexical and structural style markers have seen limited usage in sentiment 
analysis research. Wiebe et al.  ( 2004 ) used hapax legomena (unique/once occurring 
words) effectively for subjectivity and opinion discrimination. They observed a 
noticeably higher presence of unique words in subjective texts as compared to 
objective documents across a Wall Street Journal corpus and noted “Apparently, 
people are creative when they are being opinionated” (p. 286). Gamon  ( 2004 ) used 
lexical features such as sentence length for sentiment classifi cation of feedback sur-
veys. Mishne  ( 2005 ) used lexical style markers such as words per message and 
words per sentence for affect analysis of Web blogs. While it is unclear whether 
stylistic features are effective sentiment discriminators for movie/product reviews, 
style markers have been shown to be highly prevalent in Web discourse (Abbasi and 
Chen  2005 ; Zheng et al.  2006 ; Schler et al.  2006 ) . 
 2.4  Sentiment Classifi cation Techniques 
 Previously used techniques for sentiment classifi cation can be classifi ed into three 
categories. These include machine learning algorithms, link analysis methods, and 
score-based approaches. 
1772 Related Work
 Many studies have used machine learning algorithms, with support vector machines 
(SVM) and naïve Bayes (NB) being the most commonly used. SVM has been used 
extensively for movie reviews (Pang et al.  2002 ; Pang and Lee  2004 ; Whitelaw et al. 
 2005 ) while naïve Bayes has been applied to reviews and Web discourse (Pang et al. 
 2002 ; Pang and Lee  2004 ; Efron  2004 ) . In comparisons, SVM has outperformed 
other classifi ers such as NB (Pang et al.  2002 ) . While SVM has become a dominant 
technique for text classifi cation, other algorithms such as Winnow (Nigam and Hurst 
 2004 ) and AdaBoost (Wilson et al.  2005 ) have also been used in previous sentiment 
classifi cation studies. 
 Studies using link-based features and metrics for sentiment classifi cation have 
often used link analysis. Efron  ( 2004 ) used cocitation analysis for sentiment clas-
sifi cation of Web site opinions while Agrawal et al.  ( 2003 ) used message reply link 
structures to classify sentiments in Usenet newsgroups. An obvious limitation of 
link analysis methods is that they are not effective where link structure is not clear 
or links are sparse (Efron  2004 ) . 
 Score-based methods are typically used in conjunction with semantic features. 
These techniques generally classify message sentiments based on the total sum of 
comprised positive or negative sentiment features. Phrase pattern matching 
(Nasukawa and Yi  2003 ; Yi et al.  2003 ; Fei et al.  2004 ) requires checking text for 
manually created polarized phrase tags (positive and negative). Positive phrases are 
assigned a plus one while negative phrases are assigned a minus one. All messages 
with a positive sum are assigned to the positive sentiment while negative messages 
are assigned to the negative sentiment class. The semantic orientation approach 
(Hatzivassiloglou and McKeown  1997 ; Turney  2002 ) uses a similar method to score 
the automatically generated polarized phrase tags. Score-based methods have also 
been used for affect analysis where the affect features present within a message/
document are scored based on their degree of intensity for a particular emotion class 
(Subasic and Huettner  2001 ) . 
 2.5  Sentiment Analysis Domains 
 Sentiment analysis has been applied to numerous domains including reviews, Web 
discourse, and news articles and documents. Reviews include movie, product, and 
music reviews (Morinaga et al.  2002 ; Pang et al.  2002 ; Turney  2002 ) . Sentiment 
analysis of movie reviews is considered to be very challenging since movie review-
ers often present lengthy plot summaries and also use complex literary devices such 
as rhetoric and sarcasm. Product reviews are also fairly complex since a single 
review can feature positive and negative sentiments about particular facets of the 
product. 
 Web discourse sentiment analysis includes evaluation of Web forums, news-
groups, and blogs. These studies assess sentiments about specifi c issues/topics. 
Sentiment topics include abortion, gun control, and politics (Agrawal et al.  2003 ; 
178 10 Sentiment Analysis
Efron  2004 ) . Robinson  ( 2005 ) evaluated sentiments about 9/11 in three forums in 
the United States, Brazil, and France. Wiebe et al.  ( 2004 ) performed subjectivity 
classifi cation of Usenet newsgroup postings. 
 Sentiment analysis has also been applied to news articles (Yi et al.  2003 ; Wilson 
et al.  2005 ) .  Henley et al. ( 2002 ) analyzed newspaper articles for biases pertaining 
to violence-related reports. They found that there was a signifi cant difference 
between the manner in which the Washington Post and the San Francisco Chronicle 
reported news stories relating to antigay attacks, with the reporting style refl ecting 
newspaper sentiments. Wiebe et al.  ( 2004 ) classifi ed objective and subjective news 
articles in a Wall Street Journal corpus. 
 Some general conclusions can be drawn from Table  10.2 and the literature review. 
Most studies have used syntactic and semantic features. There has also been little 
use of feature reduction/selection techniques which may improve classifi cation 
accuracy. In addition, most previous studies have focused on English data, predomi-
nantly in the review domain. 
 3  Research Gaps and Questions 
 Based on our review of previous literature and conclusions, we have identifi ed several 
important research gaps. First, there has been limited previous sentiment analysis 
work on Web forums, and most studies have focused on a sentiment classifi cation of a 
single language. Second, there has been almost no usage of stylistic feature categories. 
Finally, little emphasis has been placed on feature reduction/selection techniques. 
 3.1  Web Forums in Multiple Languages 
 Most previous sentiment classifi cation of Web discourse has focused on Usenet and 
fi nancial forums. Applying such methods to extremist forums is important in order 
to develop a viable set of features for assessing the presence of propaganda, anger, 
and hate in these online communities. Furthermore, there has been little evaluation 
on non-English content, with the exception of Kanayama et al.  ( 2004 ) performing 
sentiment classifi cation on Japanese text. Even in that study, machine translation 
software was used to convert the text to English. Thus, multiple language features 
have not been used for sentiment classifi cation. The globalized nature of the Internet 
necessitates more sentiment analysis across languages. 
 3.2  Stylistic Features 
 Previous work has focused on syntactic and semantic features. There has been little 
use of stylistic features such as word-length distributions, vocabulary richness mea-
sures, character- and word-level lexical features, and special character frequencies. 
1794 Research Design
Gamon  ( 2004 ) and Pang et al.  ( 2002 ) pointed out that many important features may 
not seem intuitively obvious at fi rst. Thus, while prior emphasis has been on adjec-
tives, stylistic features may uncover latent patterns that can improve classifi cation 
performance of sentiments. This may be especially true for Web forum discourse, 
which is rich in stylistic variation (Abbasi and Chen  2005 ; Zheng et al.  2006 ) . Stylistic 
features have also been shown to be highly prevalent in other forms of computer-
mediated communication, including Web blogs (Herring and Paolillo  2006 ) . 
 3.3  Feature Reduction for Sentiment Classifi cation 
 Different automated and manual approaches have been used to craft sentiment clas-
sifi cation feature sets. Little emphasis has been given to feature subset selection 
techniques. Gamon  ( 2004 ) and Yi et al.  ( 2003 ) used log likelihood to select impor-
tant attributes from a large initial feature space. Wiebe et al.  ( 2004 ) evaluated the 
effectiveness of various potential subjective elements (PSEs) for subjectivity clas-
sifi cation based on their occurrence distribution across classes. However, many 
powerful techniques have not been explored. Feature reduction/selection techniques 
have two important benefi ts (Li et al.  2006 ) . They can potentially improve classifi ca-
tion accuracy and also provide greater insight into important class attributes, result-
ing in a better understanding of sentiment arguments and characteristics (Guyon and 
Elisseeff  2003 ) . Using feature reduction, Gamon  ( 2004 ) was able to improve accu-
racy and narrow in on a key feature subset of sentiment discriminators. 
 3.4  Research Questions 
 We propose the following research questions.
 1.  Can sentiment analysis be applied to Web forums in multiple languages? 
 2.  Can stylistic features provide further sentiment insight and classifi cation 
power? 
 3.  How can feature selection improve classifi cation accuracy and identify key senti-
ment attributes? 
 4  Research Design 
 In order to address these questions, we propose the use of a sentiment classifi cation 
feature set consisting of syntactic and stylistic features. Furthermore, utilization of 
feature selection techniques such as genetic algorithms (Holland  1975 ) and informa-
tion gain (Shannon  1948 ; Quinlan  1986 ) is also included to improve classifi cation 
accuracy and gain insight into the important features for each sentiment class. Based 
on the prevalence of stylistic variation in Web discourse, we believe that lexical and 
180 10 Sentiment Analysis
structural style markers can improve the ability to classify Web forum sentiments. 
Integrated stylistic features include attributes such as word-length distributions, 
vocabulary richness measures, letter usage frequencies, use of greetings, presence of 
requoted content, use of URLs, etc. 
 We also propose the use of an entropy weighted genetic algorithm (EWGA) that 
incorporates the information gain (IG) heuristic with a genetic algorithm (GA) to 
improve feature selection performance. GA is an evolutionary computing search 
method (Holland  1975 ) that has been used in numerous feature selection applica-
tions (Siedlecki and Sklansky  1989 ; Yang and Honavar  1998 ; Li et al.  2006 ;  2007 ) . 
Oliveira et al.  ( 2002 ) successfully applied GA to feature selection for handwritten 
digit recognition.  Vafaie and Imam  ( 1994 ) showed that GA outperformed other heu-
ristics such as greedy search for image recognition feature selection. Like most 
random search feature selection methods (Dash and Liu  1997 ) , it uses a wrapper 
model where the performance accuracy is used as the evaluation criterion to improve 
the feature subset in future generations. 
 In contrast, IG is a heuristic based on information theory (Shannon  1948 ) . It uses 
a fi lter model for ranking features which makes it computationally more effi cient 
than GA. IG has outperformed numerous feature selection techniques in head-to-
head comparisons (Forman  2003 ) . Since our experiments will use the SVM classi-
fi er, we also plan to compare the proposed EWGA technique against the use of 
SVM weights for feature selection. In this method, the SVM weights are used to 
iteratively reduce the feature space, thereby improving performance (Koppel et al. 
 2002 ) . SVM weights have been shown to be effective for text categorization 
(Koppel et al.  2002 ; Mladenic et al.  2004 ) and gene selection for cancer classifi ca-
tion (Guyon et al.  2002 ) . GA, IG, and SVM weights have been used in several 
previous text classifi cation studies as shown in Table  10.3 . A review of feature 
selection for text classifi cation can be found in Sebastiani  ( 2002 ) . 
 A consequence of using an optimal search method such as GA in a wrapper 
model is that convergence toward an ideal solution can be slow when dealing with 
very large solution spaces. However, as previous researchers have argued, feature 
selection is considered an “offl ine” task that does not need to be repeated constantly 
(Jain and Zongker  1997 ) . This is why wrapper-based techniques using genetic algo-
rithms have been used for gene selection with feature spaces consisting of tens of 
thousands of genes (Li et al.  2007 ) . Furthermore, hybrid GAs have previously been 
used for product design optimization (Alexouda and Papparrizos  2001 ; Balakrishnan 
et al.  2004 ) and scheduling problems (Levine  1996 ) to facilitate improved accuracy 
 Table 10.3  Text classifi cation studies using GA, IG, and SVM weights 
 Technique  Task  Study 
 GA  Stylometric analysis  Li et al.  2006 
 IG  Topic classifi cation  Efron et al., 2003 
 Stylometric analysis  Juola and Baayen,  2005 
 Koppel and Schler  2003 
 Abbasi and Chen  2006 
 SVM weights  Topic classifi cation  Mladenic et al.  2004 
 Gender categorization  Koppel et al.  2002 
1815 System Design
and convergence effi ciency (Balakrishnan et al.  2004 ) . We developed the EWGA 
hybrid GA that utilizes the information gain (IG) heuristic with the intention of 
improving feature selection quality. More algorithmic details are provided in the 
next section. 
 5  System Design 
 We propose the following system design (shown in Fig.  10.1 ). Our design has two 
major steps: extracting an initial set of features and performing feature selection. 
These steps are used to carry out sentiment classifi cation of forum messages. 
 5.1  Feature Extraction 
 We incorporated syntactic and stylistic features in our sentiment classifi cation attri-
bute set. These features are more generic and applicable across languages. For 
instance, syntactic, lexical, and structural features have been successfully used in 
 Fig. 10.1  Sentiment classifi cation system design 
 
182 10 Sentiment Analysis
stylometric analysis studies applied to English, Chinese (Peng et al. 2003; Zheng 
et al.  2006 ) , Greek (Stamatatos et al. 2003), and Arabic (Abbasi and Chen  2005 ; 
 2006 ) . Link-based features were not included since our messages were not in 
sequential order (insuffi cient cross-message references). These types of features are 
only effective where the test bed consists of entire threads of messages and mes-
sage-referencing information is available. Semantic features were not used since 
these attributes are heavily context-dependent (Pang et al.  2002 ) . Such features are 
topic and language specifi c. For example, the set of positive polarity words describ-
ing a good movie may not be applicable to discussions about racism. Unlike stylis-
tic and syntactic features, semantic features such as manually crafted lexicons 
incorporate an inherent feature selection element via the human involvement. Such 
human involvement makes semantic features (e.g., lexicons and dictionaries) very 
powerful for sentiment analysis. Lexicon developers will only include features that 
are considered to be important and weight these features based on their signifi cance, 
thereby reducing the need for feature selection. For example, Whitelaw et al.  ( 2005 ) 
used WordNet to construct an initial set of features, which were manually fi ltered 
and weighted to create the lexicon. Unfortunately, the language specifi city of seman-
tic features is particularly problematic for application to the Dark Web, which con-
tains text in dozens of languages (Chen  2006 ) . We hope to overcome the lack of 
semantic features by incorporating feature selection methods intended to isolate the 
important subset of stylistic and syntactic features and remove noise. 
 5.1.1  Determining Size of Initial Feature Set 
 Our initial feature set consisted of 14 different feature categories which included 
POS tag n-grams (for English), word roots (for Arabic), word n-grams, and punctua-
tion for syntactic features. Style markers included word- and character-level lexical 
features, word-length distributions, special characters, letters, character n-grams, 
structural features, vocabulary richness measures, digit n-grams, and function words. 
The word-length distribution includes the frequency of 1–20 letter words. Word-
level lexical features include total words per document, average word length, average 
number of words per sentence, average number of words per paragraph, total number 
of short words (i.e., ones less than four letters), etc. Character-level lexical features 
include total characters per document, average number of characters per sentence, 
average number of characters per paragraph, percentage of all characters that are in 
words, and the percentage of alphabetic, digit, and space characters. Vocabulary 
richness features include the total number of unique words used, hapax legomena 
(number of once occurring words), dis legomena (number of twice occurring words), 
and various previously defi ned statistical measures of richness such as Yule’s K, 
Honore’s R, Sichel’s S, Simpson’s D, and Brunet’s W measures. The structural fea-
tures encompass the total number of lines, sentences, and paragraphs, as well as 
whether the document has a greeting or a signature. Additional structural attributes 
include whether there is a separation between paragraphs, whether the paragraphs 
1835 System Design
are indented, the presence and position of quoted and forwarded content, and whether 
the document includes e-mail, URL, and telephone contact information. Further 
descriptions of the lexical vocabulary richness and structural attributes can be found 
in De Vel et al.  ( 2001 ) , Zheng et al.  ( 2006 ) , and Abbasi and Chen  ( 2005 ) . The Arabic 
function words were Arabic words translated from the English function word list, as 
done in previous research (e.g., Chen and Gey  2002 ) . Only words were considered; 
for convenience, no affi xes were included. 
 Many feature categories are predefi ned in terms of the number of potential fea-
tures. For example, there are only a certain number of possible punctuation and 
stylistic lexical features (e.g., words per sentence, words per paragraph, etc.). In 
contrast, there are countless potential n-gram-based features. Consequently, some 
shallow selection criterion is typically incorporated to reduce the feature space for 
n-grams. A common approach is to select features with a minimum usage frequency 
(Mitra et al.  1997 ; Jiang et al.  2004 ) . We used a minimum frequency threshold of 10 
for n-gram-based features. Less common features are sparse and likely to cause 
overfi tting. In addition, we only used unigrams, bigrams, and trigrams as these 
higher level n-grams tend to be redundant. Using only up to trigrams has been shown 
to be effective for stylometric analysis (Kjell et al.  1994 ) and sentiment classifi cation 
(Pang et al.  2002 ; Wiebe et al.  2004 ) . Based on this criterion for n-gram features, 
Table  10.4 shows the English and Arabic feature sets. 
 5.1.2  Feature Extraction Component 
 Due to the challenging morphological characteristics of Arabic, our attribute extrac-
tion process features a component for tracking elongation as well as a root extrac-
tion algorithm (illustrated in Fig.  10.2 ). 
 Table 10.4  English and Arabic feature sets 
 Category  Feature group  English  Arabic  Examples 
 Syntactic  POS n-grams  Varies  –  Frequency of part-of-speech tags (e.g., NP_VB) 
 Word roots  –  Varies  Frequency of roots (e.g., slm, ktb) 
 Word n-grams  Varies  Varies  Word n-grams (e.g., senior editor, editor in chief) 
 Punctuation  8  12  Occurrence of punctuation marks (e.g., !,;, :, and ?) 
 Stylistic  Letter n-grams  26  36  Frequency of letters (e.g., a, b, c, etc.) 
 Char. n-grams  Varies  Varies  Character n-grams (e.g., abo, out, ut, ab, etc.) 
 Word lexical  8  8  Total words,% char. per word 
 Char. lexical  8  8  Total char.,% char. per message 
 Word length  20  20  Frequency distribution of 1–20 letter words 
 Vocab. richness  8  8  Richness (e.g., hapax legomena and Yule’s K) 
 Special char.  20  21  Occurrence of special char. (e.g., @, #, $,%, ^, 
&, *, and +) 
 Digit n-grams  Varies  Varies  Frequency of digits (e.g., 100, 17, and 5) 
 Structural  14  14  Has greeting, has URL, requoted content, etc. 
 Function words  250  200  Frequency of function words (e.g., of, for, and to) 
184 10 Sentiment Analysis
 Elongation is the process of using a dash-like “kashida” character for stylistic 
word stretching (shown in step 1 in Fig.  10.2 ). The use of elongation is very prevalent 
in Arabic Web forum discourse (Abbasi and Chen  2005 ) . In addition to tracking the 
presence and extent of elongation, we fi lter out these “kashida” characters in order to 
ensure reliable extraction of the remaining features (step 2 in Fig.  10.2 ). The fi ltered 
words are then passed through a root extraction algorithm (Abbasi and Chen  2005 ) 
that compares each word against a root dictionary to determine the appropriate word-
root match (step 3). Root frequencies are tracked in order to account for the highly 
infl ective nature of Arabic which reduces the effectiveness of standard bag-of-words 
features. The remaining stylistic and syntactic features are then extracted in a similar 
manner for English and Arabic (step 4). 
 5.2  Feature Selection: Entropy Weighted Genetic 
Algorithm (EWGA) 
 Most previous hybrid GA variations combine GA with other search heuristics such as 
beam search, where the beam search output is used as part of the initial GA population 
(Alexouda and Papparrizos  2001 ; Balakrishnan et al.  2004 ) . Additional hybridiza-
tions include modifi cation of the GA’s crossover (Aggarwal et al.  1997 ) and mutation 
operators (Balakrishnan et al.  2004 ) . The entropy weighted genetic algorithm (EWGA) 
Incoming
Text
Filtered
Text
Elongation
Feature Values
Selected
Root
All Remaining
Features Values
Root Dictionary
Similarity Scores (SC)
3
1
2
4
Elongation Filter
Root Extraction
Algorithm
Generic Feature
Extractor
0.364
0.182
0.182
Feature Set
 Fig. 10.2  Arabic extraction component 
 
1855 System Design
uses the information gain (IG) heuristic to weight the various sentiment attributes. 
These weights are then incorporated into the GA’s initial population and crossover 
and mutation operators. The major steps for the EWGA are as follows: 
 Figure  10.3 shows an illustration of the EWGA process. A detailed description of 
the IG, initial population, evaluation and selection, crossover, and mutation steps is 
presented in Fig.  10.3 . 
 EWGA Steps 
 1.  Derive feature weights using IG. 
 2.  Include IG selected features as part of initial GA solution population.  
 3.  Evaluate and select solutions based on fi tness function. 
 4.  Crossover solution pairs at point that maximizes total IG difference 
between the two solutions. 
 5.  Mutate solutions based on feature IG weights. 
 6.  Repeat steps 3–5 until stopping criterion is satisfi ed. 
 Fig. 10.3  EWGA illustration  
186 10 Sentiment Analysis
 5.2.1  Information Gain 
 For information gain (IG), we used the Shannon entropy measure (Shannon  1948 ) 
in which:
  ( ) ( ) ( )= −IG C,A H C H C | A   
where: 
 ( , )IG C A   information gain for feature  A ; 
 
=
= − = =∑ 2
1
( ) ( ) log ( )
n
i
H C p C i p C i  entropy across sentiment classes  C ; 
 
=
= − = =∑ 2
1
( | ) ( | ) log ( | )
n
i
H C A p C i A p C i A  specifi c feature conditional entropy; 
  n  total number of sentiment classes. 
 If the number of positive and negative sentiment messages is equal,  H(C) is 1. 
Furthermore, the information gain for each attribute A will vary along the range 0–1 
with higher values indicating greater information gain. All features with an infor-
mation gain greater than 0.0025 (i.e.,  IG(C,A) > 0.0025) are selected. The use of 
such a threshold is consistent with prior work using IG for text feature selection 
(Yang and Pederson  1997 ) . 
 5.2.2  Solution Structure and Initial Population 
 We represent each solution in the population using a binary string of length equal to 
the total number of features, with each binary string character representing a single 
feature. Specifi cally, 1 represents a selected feature while 0 represents a discarded 
one. For example, a solution string representing fi ve candidate features, “10011,” 
means that the fi rst, fourth, and fi fth features are selected, while the other two are 
discarded (Li et al.  2006 ) . In the standard GA, the initial population of n strings is 
randomly generated. In the EWGA, n-1 solution strings are randomly generated 
while the IG solution features are used as the fi nal solution string in the initial 
population. 
 5.2.3  Evaluation and Selection 
 We use the classifi cation accuracy as the fi tness function used to evaluate the quality 
of each solution. Hence, for each genome in the population, tenfold cross- validation 
with SVM is used to assess the fi tness of that particular solution. Solutions for the 
next iteration are selected probabilistically with better solutions having a higher prob-
ability of selection. While several population replacement strategies exist, we use the 
generational replacement method originally defi ned by Holland ( 1975 ) in which the 
entire population is replaced every generation. Other replacement alternatives include 
1875 System Design
steady-state methods where only a fraction of the  population is replaced every 
 iteration, while the majority is passed over to the next generation (Levine  1996 ) . 
Generational replacement is used in order to maintain solution diversity and prevent 
premature convergence attributable to the IG seed solution dominating the other 
solutions (Bentley 1990; Aggarwal et al.  1997 ; Balakrishnan et al.  2004 ) . 
 5.2.4  Crossover 
 From the  n solution strings in the population (i.e.,  n /2 pairs), certain adjacent string 
pairs are randomly selected for crossover based on a crossover probability  cP  . In 
the standard GA, we use single-point crossover by selecting a pair of strings and 
swapping substrings at a randomly determined crossover point  x . 
S = 010010 
T = 110100
S = 010 | 010
T = 110 | 100
x = 3
S = 010100
T = 110010
 The IG heuristic is utilized in the EWGA crossover procedure in order to improve 
the quality of the newly generated solutions. Given a pair of solution strings  S and 
 T , the EWGA crossover method selects a crossover point  x that maximizes the dif-
ference in cumulative information gain across strings  S and  T . Such an approach is 
intended to create a more diverse solution population: those with heavier concentra-
tions of features with higher IG values and those with fewer IG features. The cross-
over point selection procedure can be formulated as follows:
  = =
− + −∑ ∑
1
argmax ( , )( ) ( , )( )
x m
A A A A
x A A x
IG C A S T IG C A T S
  
where:  ( , )IG C A  information gain for feature  A ;  AS   A th character in solution string  S; 
 AT   A th character in solution string  T; m total number of features;  x crossover point in 
solution pair  S and  T, where 1  < x < m. 
 Maximizing the IG differential between solution pairs in the crossover process 
allows the creation of potentially better solutions. Solutions with higher IG contain 
attributes that may have greater discriminatory potential while the lower IG solu-
tions help maintain the diversity balance in the solution population. Such balance is 
important to avoid premature convergence of solution populations toward local 
maxima (Aggarwal et al.  1997 ) . 
188 10 Sentiment Analysis
 5.2.5  Mutation 
 The traditional GA mutation operator randomly mutates individual feature charac-
ters in a solution string based on a mutation probability constant  mP  . The EWGA 
mutation operator factors the attribute information gain into the mutation probabil-
ity as shown below. This is done in order to improve the likelihood of inclusion into 
the solution string for features with higher information gain while decreasing the 
probability of features with lower information gain. Our mutation operator sets the 
probability of a bit to mutate from 0 to 1 based on the feature’s information gain, 
whereas the probability to mutate from 1 to 0 is set to the value one minus the fea-
ture’s information gain. Balakrishnan et al.  ( 2004 ) demonstrated the potential for 
modifi ed mutation operators that favored features with higher weights in their hybrid 
genetic algorithm geared toward product design optimization.
  
[ ]
[ ]
( , ) , 0
( )
1 ( , ) , 1
A
m
A
B IG C A if S
P A
B IG C A if S
⎧ =⎪= ⎨
− =⎪⎩   
where  ( )mP A  probability of mutation for feature  A ; ( , )IG C A  information gain for 
feature  A ; AS   A th character in solution string  S ; B constant in the range 0–1. 
 5.3  Classifi cation 
 Because our research focus is on sentiment feature extraction and selection, in all 
experiments, SVM is used with tenfold cross-validation and bootstrapping to clas-
sify sentiments. We chose SVM in our experiments because it has outperformed 
other machine learning algorithms for various text classifi cation tasks (Pang et al. 
 2002 ; Abbasi and Chen  2005 ; Zheng et al.  2006 ) . We use a linear kernel with the 
sequential minimal optimization (SMO) algorithm (Platt  1999 ) included in the 
Weka data mining package (Witten and Frank  2005 ) . 
 6  System Evaluation 
 Experiments were conducted on English and Arabic Web forums. The overall accu-
racy was the average classifi cation accuracy across all tenfold where the classifi ca-
tion accuracy was computed as follows:
  
= Number of Correctly Classified DocumentsClassification Accuracy
Total Number of Documents    
1896 System Evaluation
 In addition to tenfold cross-validation, bootstrapping was used to randomly 
select 50 samples for statistical testing, as done in previous research (e.g., Whitelaw 
et al.  2005 ) . For each sample, we used 5% of the instances for testing and the other 
95% for training. Pairwise t tests were performed on the bootstrap values to assess 
statistical signifi cance. 
 We conducted two experiments to evaluate the effectiveness of our features as well 
as feature selection methods for sentiment classifi cation of messages from English 
and Arabic extremist Web forums. SVM was run using tenfold cross-validation, with 
900 messages used for training and 100 for testing in each fold. Bootstrapping was 
performed by randomly selecting 50 messages for testing and the remaining 950 for 
training, 50 times. In experiment 1a, we evaluated the effectiveness of syntactic and 
stylistic features. Experiment 1b focused on evaluating the effectiveness of feature 
selection for sentiment analysis across English and Arabic forums. 
 6.1  Test Bed 
 Our test bed consists of messages from two major extremist forums (one US and 
one Middle Eastern) collected as part of the Dark Web project (Chen  2006 ) . This 
project involves spidering the Web and collecting Web sites and forums relating to 
hate and extremist groups. The initial list of group URLs is collected from authorita-
tive sources such as government agencies and the United Nations. These URLs are 
then used to gather additional relevant forums and Web sites. 
 The US forum  www.nazi.org is an English forum that belongs to the Libertarian 
National Socialist Green Party (LNSG). This is an Aryan supremacist group that 
gained notoriety when a forum member was involved in a school shooting in 2004. 
The Middle Eastern forum  www.la7odood.com is a major Arabic-speaking partisan 
forum discussing the war in Iraq and support for the insurgency. The forum’s con-
tent includes numerous al-Qaeda speeches and beheading videos. 
 We randomly selected 1,000 polar messages from each forum, which were man-
ually tagged. The polarized messages represented those in favor of (agonists) and 
against (antagonists) a particular topic. The number of messages used is consistent 
with previous classifi cation studies (Pang et al.  2002 ) . In accordance with previous 
sentiment classifi cation experiments, a maximum of 30 messages was used from 
any single author. This was done in order to ensure that sentiments were being clas-
sifi ed as opposed to authors. For the US forum, we selected messages relating to 
racial issues. Agonistic sentiment messages were considered to be those in favor of 
racial diversity. In contrast, antagonistic sentiment messages had content denounc-
ing racial diversity, integration, interracial marriages, and race mixing. For the 
Middle Eastern forum, we selected messages relating to the insurgency in Iraq. 
Agonistic messages were considered to be those opposed to the insurgency. These 
messages had positive sentiments about the Iraqi government and US troops in Iraq. 
Antagonistic sentiment messages were those in favor of the insurgents and against 
190 10 Sentiment Analysis
the current Iraqi government and US forces. These messages had negative senti-
ments about the Iraqi government and US troops. The occurrence of messages with 
opposing sentiments is attributable to the presence of agitators (also referred to as 
trolls) and debaters in these forums (Donath  1999 ; Herring et al.  2002 ; Viegas and 
Smith  2004 ) . Thus, while the majority of the forum membership may have negative 
sentiments about a topic, a subset has opposing sentiment polarity. For the sake of 
simplicity, from here on, we will refer to agonistic messages as “positive” and 
antagonistic messages as “negative” as these terms are more commonly used to 
represent the two sides in most previous sentiment analysis research. Here, we use 
the terms positive and negative as indicators of semantic orientation with respect to 
the specifi c topic; however, the “positive” messages may also contain sentiments 
about other topics (which may be positive or negative) as described by Wiebe et al. 
 ( 2005 ) . This is similar to the document-level annotations used for product and movie 
reviews (Pang et al.  2002 ; Yi et al.  2003 ) . Using two human annotators, 500 positive 
(agonistic) and 500 negative (antagonistic) sentiment messages were incorporated 
from each forum. Both annotators/coders were bilingual, fl uent in English and 
Arabic. The message annotation task by the independent coders had a kappa (k) 
value of 0.90 for English and 0.88 for Arabic, which is considered to be reliable, 
suggesting suffi cient intercoder reliability. Table  10.5 shows some summary statis-
tics for our English and Arabic Web forum test bed. 
 6.2  Experiment 1a: Evaluation of Features 
 In our fi rst experiment, we repeated the feature set tests previously performed on the 
movie review dataset. The three permutations of stylistic and syntactic features 
were used. Table  10.6 shows the results for the three feature sets across the US and 
Middle Eastern forum message datasets. 
 Table 10.5  Characteristics of English and Arabic test bed 
 Forum  Messages  Authors  Average length (char.)  Data range 
 US  1,000  114  854  3/2004–9/2005 
 Middle Eastern  1,000  126  1,126  11/2005–3/2006 
 Table 10.6  Characteristics of English and Arabic test bed 
 US forum 
 Features  Accuracy (%)  Bootstrap (%)  Standard dev.  Number features 
 Stylistic  71.40  71.07  3.324  867 
 Syntactic  87.00  87.13  2.439  12,014 
 Stylistic + syntactic  90.63  90.59  2.042  12,881 
 Middle Eastern forum 
 Features  Accuracy (%)  Bootstrap (%)  Standard dev.  Number features 
 Stylistic  80.20  80.01  4.145  1,166 
 Syntactic  85.42  85.23  2.457  12,645 
 Stylistic + syntactic  90.81  90.69  2.093  13,811 
1916 System Evaluation
 The best classifi cation accuracy results using SVM were achieved when using 
both syntactic and stylistic features. The combined feature set statistically outper-
formed the use of only syntactic or stylistic features across both datasets. The increase 
was more prevalent in the Middle Eastern forum messages, where the use of stylistic 
and syntactic features resulted in a 5% improvement in accuracy over the use of 
syntactic features alone. Surprisingly, stylistic features alone were able to attain over 
80% accuracy for the Middle Eastern messages, nearly a 9% improvement in the 
effectiveness of these features as compared to the English forum messages. This 
fi nding is consistent with previous stylometric analysis studies that have also found 
signifi cant stylistic usage in Middle Eastern forums, including heavy usage of fonts, 
colors, elongation, numbers, and punctuation (Abbasi and Chen  2005 ) . 
 Table  10.7 shows the pairwise t tests conducted on the bootstrap samples to eval-
uate the statistical signifi cance of the improved results using stylistic and syntactic 
features. As expected, syntactic features outperformed stylistic features when both 
were used alone. However, using both feature categories signifi cantly outperformed 
the use of either category individually. The results suggest that stylistic features are 
prevalent and important in Web discourse, even when applied to sentiment 
classifi cation. 
 6.3  Experiment 1b: Evaluation of Feature Selection Techniques 
 This experiment was concerned with evaluating the effectiveness of feature selec-
tion for sentiment classifi cation of Web forums. The same experimental settings as 
experiment 1a were used for all techniques. Table  10.8 shows the results for the four 
feature reduction methods and the number feature selection baseline applied across 
the US and Middle Eastern forum messages. All four feature selection techniques 
improved the classifi cation accuracy over the baseline. The EWGA had the best 
performance across both test beds in terms of overall accuracy, resulting in a 3–4% 
improvement in accuracy over the number feature selection baseline. Furthermore, 
the EWGA was also the most effi cient in terms of the number of features used, 
improving accuracy while utilizing a smaller subset of the initial feature sets. 
EWGA-based feature selection was able to identify a more concise set of key fea-
tures that was 50–70% smaller than IG and SVM weights (SVMW) and 75–90% 
smaller than the baseline. GA also used a smaller number of features; however, the 
use of EWGA resulted in considerably improved accuracy. 
 Table 10.7  P values for pairwise t tests on accuracy (n = 50) 
 Features/test bed  US  Middle Eastern 
 Sty. vs. syn.  <0.0001*  <0.0001* 
 Sty. vs. syn + sty.  <0.0001*  <0.0001* 
 Syn. vs. syn + sty  <0.0001*  <0.0001* 
 * P -values signifi cant at alpha = 0.05 
192 10 Sentiment Analysis
 Table  10.9 shows the pairwise t tests conducted on the bootstrap values to evalu-
ate the statistical signifi cance of the improved results using feature selection. 
 EWGA outperformed the baseline and GA for both datasets signifi cantly. In 
addition, EWGA provided signifi cantly better performance than IG and SVMW on 
the English Web forum messages. EWGA also outperformed IG and SVMW on the 
Middle Eastern forum dataset, though the improved performance was not statisti-
cally signifi cant. 
 6.4  Results Discussion 
 Fig.  10.4 shows the selection accuracy and number of features selected (out of over 
12,800 potential features) for the US forum using EWGA as compared to GA across 
the 200 iterations (average of tenfold). The Middle Eastern forum graphs looked 
 Table 10.8  Experiment 1b results 
 US forum 
 Technique  Tenfold CV (%)  Bootstrap (%)  Standard dev.  Number features 
 Base  90.61  90.56  1.831  12,881 
 IG  92.22  92.10  1.612  1,057 
 GA  91.83  91.64  1.396  511 
 SVMW  92.33  92.28  1.512  1,000 
 EWGA  94.72  94.94  1.671  502 
 Middle Eastern forum 
 Technique  Tenfold CV (%)  Bootstrap (%)  Standard dev.  Number features 
 Base  90.79  90.57  1.932  13,811 
 IG  93.41  93.38  1.665  1,045 
 GA  92.14  92.24  1.438  462 
 SVMW  93.28  93.26  1.337  1,000 
 EWGA  93.62  93.84  2.831  338 
 Table 10.9  P values for pairwise t tests on accuracy (n = 50) 
 Technique/test bed  US  Middle Eastern 
 Base vs. IG  <0.0001*  <0.0001* 
 Base vs. GA  0.0001*  0.0134* 
 Base vs. EWGA  <0.0001*  <0.0001* 
 Base vs. SVMW  <0.0001*  <0.0001* 
 IG vs. GA  0.0356*  0.0685 
 IG vs. EWGA  <0.0001*  0.2783 
 IG vs. SVMW  0.2934  0.4130 
 GA vs. EWGA  <0.0001*  0.0456* 
 GA vs. SVMW  0.0279*  0.0728 
 SVMW vs. EWGA  <0.0001*  0.2025 
 * P -values signifi cant at alpha = 0.05 
1936 System Evaluation
similar to the US forum and were hence not included. The EWGA accuracy declines 
initially despite being seeded with the IG solution. This is due to the use of genera-
tion replacement which prevents the IG solution from dominating the other solutions 
and creating a stagnant solution population. As intended, the IG solution features are 
gradually disseminated to the remaining solutions in the population until the new 
solutions begin to improve in accuracy around the 20th iteration. Overall, the EWGA 
is able to converge on an improved solution while only using half of the features 
originally transferred from IG. It is interesting to note that EWGA and GA both 
converge to a similar number of features when applied to the US forum; however, 
the EWGA is better able to isolate the more effective sentiment discriminators. 
 6.4.1  Analysis of Key Sentiment Features 
 We chose to analyze the EWGA features since they provided the highest perfor-
mance with the most concise set of features. Thus, the EWGA-selected features are 
likely to be the most signifi cant discriminators with the least redundancy. Figure  10.5 
shows the number of each feature category selected by the EWGA for the English 
and Arabic feature set. As expected, more syntactic features (POS tags, n-grams, 
word roots) were used since considerably more of these features were included. 
 While Fig.  10.5 shows the number of features selected by the EWGA for each 
feature category, Fig.  10.6 shows the percentage of the overall number of features in 
each category that were selected. For example, the EWGA selected 12 structural 
features from the US (English) feature set; however, this represents 86% percent of 
the structural features, as shown in Fig.  10.6 . 
 Looking at theusage percentage, stylistic features were more effi cient than word 
n-grams and POS tags/roots. Many of the stylistic feature groups had over 40% 
usage whereas syntactic features rarely had such high usage with the exception of 
punctuation. For the US feature set, some categories such as word length, vocabu-
lary richness, special characters, and structural features had well over 80% repre-
sentation in the fi nal feature subset. Comparing across regions, US features had 
higher usage rates than the Middle Eastern feature set. Approximately 10% of the 
Middle Eastern features were used by the EWGA versus 25% of the US attributes. 
Features Selected: U.S. Forum
0
200
400
600
800
1000
1200
F
ea
tu
re
s
GA
EWGA
Selection Accuracy: U.S. Forum
84
0 50 100 150 200
86
88
90
92
94
96
Iteration
0 50 100 150 200
Iteration
A
cc
ur
ac
y
GA
EWGA
 Fig. 10.4  US forum results using EWGA and GA 
 
194 10 Sentiment Analysis
Function Words
Structural
Letters
0 50 100 150 200 250 300 350
Spec. Characters
Vocab Richness
Word Length
Char. Lexical
Word Lexical
Punctuation
Word N-grams
POS/Roots
# Features
U.S.
Middle Eastern
S
yn
ta
ct
ic
S
ty
lis
ti
c
 Fig. 10.5  Key feature usage frequencies by category 
Function Words
Structural
Letters
0 0.2 0.4 0.6 0.8 1
Spec.
Vocab Richness
Word Length
Char. Lexical
Word Lexical
Punctuation
Word N-grams
POS/Roots
% Usage
U.S.
M.E.
S
ty
lis
ti
c
S
yn
ta
ct
ic
 Fig. 10.6  Key feature usage percentage by category 
 6.4.2  Key Stylistic Features 
 Figure  10.7 shows some of the important stylistic features for the US forum. The 
diagram to the left shows the normalized average feature usage across all positive 
and negative sentiment messages. The table to the right shows the description for 
each feature as well as its IG and SVM weight. 
 The positive sentiment messages (agonists, in favor of racial diversity) tend to be 
considerably shorter (feat. 1), containing a few long sentences. These messages also 
feature heavier usage of conjunctive function words such as “however,” “therefore,” 
and “nevertheless” (feat. 6–8). In contrast, the negative sentiment messages are 
nearly twice as long and contain lots of digits (feat. 5) and special characters (feat. 
2–4). Higher digit usage in the negative messages is due to references to news arti-
cles used to stereotype. Article snippets begin with a date, resulting in the higher 
digit count. The negative messages also feature shorter sentences. The stylistic fea-
ture usage statistics suggest that the positive sentiment messages follow more of a 
 
 
1956 System Evaluation
debating style with shorter, well-structured arguments. In contrast, the negative sen-
timent messages tend to contain greater signs of emotion. The following verbal 
joust between two members in the US forum exemplifi es the stylistic differences 
across sentiment classes. It should be noted that some of the content in the messages 
has been sanitized for vulgar word usage; however, the stylistic tendencies that are 
meant to be illustrated remain unchanged. 
 Negative 
 You are a total%#$*@ idiot!!! You walk around thinking you’re doing humanity a 
favor, sympathizing with such barbaric slime. They use your sympathy as an excuse 
to fail. They are a burden to us all!!! Your opinion means nothing. 
 Positive 
 Neither does yours. But at least my opinion is an educated and informed one backed 
by well-reasoned arguments and careful skepticism about my assumptions. Race is 
nothing more than a social classifi cation. What have you done for society that allows 
you to deem others a burden? 
 Figure  10.8 shows some of the important stylistic features for the Middle Eastern 
forum. 
 There are a few interesting similarities between the US and Middle Eastern forum 
feature usage tendencies across sentiment lines. The positive sentiment messages in 
the Middle Eastern forum (agonists, opposed to the insurgency) also tend to be con-
siderably shorter than the negative sentiment messages in terms of total number of 
characters (feat. 2). Additionally, like their US forum counterparts, the negative 
Arabic messages contain heavy digit usage attributable to news article snippets (feat. 
5). The negative sentiment messages make greater use of stylistic word stretching 
(elongation) which is done in order to emphasize key words (feat. 3). Consequently, 
the negative messages include greater use of words longer than 10 characters (feat. 
4) while the positive messages are more likely to use shorter words, less than 4 char-
acters in length (feat. 1). The negative sentiment messages also have higher vocabu-
lary richness (feat. 6–9, various vocabulary richness formulas). 
U.S. Forum Usage
0.0
1 2 3 4 5 6 7 8
0.2
0.4
0.6
0.8
1.0
Feature #
N
or
m
al
iz
ed
 U
sa
ge
 
Positive
Negative
Feature  
total char.
$
&
{
digit count
therefore
however
nevertheless
0.027
0.029
0.017
0.017
0.014
0.012
0.015
0.021
0.243
0.130
0.141
-0.120
-0.119
0.126
0.316
-0.104
IG SVM 
 Fig. 10.7  Key stylistic features for US forum 
 
196 10 Sentiment Analysis
 6.4.3  Key Syntactic Features 
 Table  10.10 shows the key word n-grams for each sentiment class selected by the 
EWGA. Many of the terms and phrases were racist content that was not included 
in the table but rather represented using a description label. Items in quotes indicate 
actual terms (e.g., “criminals”) while nonquoted items signify term descriptions 
(e.g., racist terms). For the Middle Eastern forum, sentiments seem to be drawn 
along sectarian lines. In contrast, US forum sentiments are not clearly separated 
along racial lines. While the majority of the negative sentiments toward racial 
issues are generated by white supremacists, many of the positive sentiments are 
also presented by those with the same self-proclaimed racial affi liations. This 
reduced the amount of racial name calling across sentiments in the US forums, 
resulting in the need for considerably larger numbers of n-grams to effectively 
discern sentiment classes. Consequently, the number of n-grams used for the US 
feature set (332) is nearly threefold those used for the Middle Eastern sentiment 
classifi cation (117). 
Middle Eastern Forum Usage
0.0
1 32 4 5 6 7 8 9
0.2
0.4
0.6
0.8
1.0
Feature #
N
or
m
al
iz
ed
 U
sa
ge
Positive
Negative
short words
total char.
elongation
long words
digits
Simpson
Yule
Brunet
Honore
Feature  
0.026
0.039
0.037
0.023
0.027
0.024
0.035
0.014
0.029
-0.020
0.210
0.319
0.137
0.109
0.140
0.362
0.086
0.135
IG SVM 
 Fig. 10.8  Key stylistic features for Middle Eastern forum 
 Table 10.10  Key n-grams for various sentiment classes 
 US forum  Middle Eastern forum 
 Positive (agonist)  Negative (antagonist)  Positive (agonist)  Negative (antagonist) 
 Racist terms:  Racist terms:  Racist Shia terms:  Racist Sunni terms: 
 “Racism”  “Criminals”  “Terrorists”—
 
 “Freedom 
fi ghters”—  
 “Subhuman racist”  “Whites”  “Shia”—   “Martyrdom”—  
 “Anti-Semitism”  “Americans”  “Shiite”—   “Zarqawi”—  
 “Ignorant slime”  “Get a job”  “Sunni”—  
 “lmwao”  “American”—  
 “Odin’s rage”  “Iraq”—  
 “International forces”—
  
 “Urban jungle” 
 
197References
 7  Conclusions and Future Directions 
 In this study, we applied sentiment classifi cation methodologies to English and 
Arabic Web forum postings. In addition to syntactic features, a wide array of English 
and Arabic stylistic attributes including lexical, structural, and function word style 
markers were included. We also developed the entropy weighted genetic algorithm 
(EWGA) for effi cient feature selection in order to improve accuracy and identify 
key features for each sentiment class. EWGA signifi cantly outperformed the  number 
feature selection baseline and GA on all test beds. It also outperformed IG and 
SVMW on all three datasets (statistically signifi cant for the movie review and US 
forum datasets) while isolating a smaller subset of key features. EWGA demon-
strated the utility of these key features in terms of classifi cation performance and for 
content analysis. Analysis of EWGA-selected stylistic and syntactic features 
allowed greater insight into writing style and content differences across sentiment 
classes in the two Web forums. Our approach of using stylistic and syntactic fea-
tures in conjunction with the EWGA feature selection method achieved a high level 
of accuracy, suggesting that these features and techniques may be used in the future 
to perform sentiment classifi cation and content analysis of Web forum discourse. 
Applying sentiment analysis to Web forums is an important endeavor, and the cur-
rent accuracy is promising for effective analysis of forum conversation sentiments. 
Such analysis can help provide a better understanding of extremist group usage of 
the Web for information and propaganda dissemination. 
 In the future, we would like to evaluate the effectiveness of the proposed senti-
ment classifi cation features and techniques for other tasks such as sentence- and 
phrase-level sentiment classifi cation. We also intend to apply the technique to other 
sentiment domains (e.g., news articles and product reviews). Moreover, we believe 
the suggested feature selection technique may also be appropriate for other forms of 
text categorization and plan to apply our technique to topic, style, and genre classi-
fi cation. We also plan to investigate the effectiveness of other forms of GA hybrid-
ization, such as using the SVM weights instead of the IG heuristic. 
 References 
 Abbasi, A., and Chen, H . 2005. Identifi cation and comparison of extremist-group web forum mes-
sages using authorship analysis,  IEEE Intelligent Systems 20, 5, 67–75. 
 Abbasi, A., and Chen , H. 2006. Visualizing authorship for identifi cation, In  Proceedings of the 4  th  
 IEEE International Conference on Intelligence and Security Informatics , San Diego, CA, 
60–71. 
 Abbasi, A., and Chen , H. 2007. Affect intensity analysis of Dark Web forums, In  Proceedings of the 
5  th   IEEE International Conference on Intelligence and Security Informatics , New Brunswick, 
NJ, 282–288. 
 Abbasi, A., and Chen, H . 2008. Analysis of affect intensities in extremist group forums, In  Terrorism 
Informatics, (Eds.) H. Chen, E. Reid, H. Chen, J. Sinai, A. Silke, B. Ganor, Springer-Verlag . 
198 10 Sentiment Analysis
 Alexouda, G., and Papparrizos, K . 2001. A genetic algorithm approach to the product line design 
problem using the seller’s return criterion: An extensive comparative computational study, 
 European Journal of Operational Research 134, 165–178 . 
 Aggarwal, C.C., Orlin, J., and Tai, R.P . 1997. Optimized crossover for the independent set prob-
lem,  Operations Research 45, 2 , 226–234 . 
 Agrawal, R., Rajagopalan, S., Srikant, R. and Xu, Y . 2003. Mining newsgroups using networks 
arising from social behavior, In  Proceedings of the 12  th   International World Wide Web 
Conference, 529–535 . 
 Balakrishnan, P.V., Gupta, R., and Jacob, V.S . 2004. Development of hybrid genetic algorithms for 
product line designs,  IEEE Transactions on Systems, Man, and Cybernetics 34, 1 , 468–483 . 
 Beineke, P., Hastie, T., and Vaithyanathan, S . 2004. The sentimental factor: Improving review clas-
sifi cation via human-provided information, In  Proceedings of the 42  nd   Annual Meeting of the 
Association for Computational Linguistics, 263 . 
 Burris, V., Smith, E. and Strahm, A . 2000. White supremacist networks on the Internet,  Sociological 
Focus 33, 2 , 215–235 . 
 Chen, A. and Gey, F . 2002. Building an Arabic stemmer for information retrieval, In  Proceedings 
of the 11  th   Text Retrieval Conference, Gaithersburg, MD , 631–639 . 
 Chen, H . 2006.  Intelligence and Security Informatics for International Security: Information 
Sharing and Data Mining , London, Springer Press. 
 Crilley, K . 2001. Information warfare: New battle fi elds, terrorists, propaganda, and the Internet, 
 Aslib Proceedings 53, 7, 250–264 . 
 Dash, M. and Liu, H . 1997 . Feature selection for classifi cation,  Intelligent Data Analysis 1, 
131–156 . 
 Dave, K. Lawrence, S. and Pennock, D.M . 2003. Mining the peanut gallery: Opinion extraction 
and semantic classifi cation of product reviews, In  Proceedings of the 12  th   International 
Conference on the World Wide Web, 519–528 . 
 De Vel, O., Anderson, A., Corney, M., and Mohay, G . 2001 . Mining e-mail content for author 
identifi cation forensics,  ACM SIGMOD Record 30 , 4, 55–64. 
 Donath, J. 1999. Identity and deception in the virtual community, In Kollock, P., and Smith, M. 
(Eds.), Communities in Cyberspace, London: Routledge, 27–58 . 
 Efron, M . 2004. Cultural orientations: Classifying subjective documents by cocitation analysis. 
In  Proceedings of the AAAI Fall Symposium Series on Style and Meaning in Language, Art, 
Music, and Design , 41–48. 
 Efron, M., Marchionini, G., and Zhiang, J . 2003. Implications of the recursive representation prob-
lem for automatic concept identifi cation in on-line government information, In  Proceedings of 
the ASIST SIG-CR Workshop . 
 Fei, Z., Liu, J., and Wu, G.  2004. Sentiment classifi cation using phrase patterns,  In Proceedings of 
the 4  th   IEEE International Conference on Computer Information Technology , 1147–1152 . 
 Forman, G . 2003 . An extensive empirical study of feature selection metrics for text classifi cation, 
 Journal of Machine Learning Research 3 , 1289–1305. 
 Gamon, M . 2004. Sentiment classifi cation on customer feedback data: Noisy data, large feature 
vectors, and the role of linguistic analysis, In  Proceedings of the 20th International Conference 
on Computational Linguistics , 841. 
 Glaser, J., Dixit, J., and Green, D. P.  2002 . Studying hate crime with the Internet: What makes rac-
ists advocate racial violence?  Journal of Social Issues 58 , 1, 177–193. 
 Grefenstette, G.., Qu, Y., Shanahan, J. G.. and Evans, D. A . 2004. Coupling niche browsers and 
affect analysis for an opinion mining application, In  Proceedings of the 12th International 
Conference Recherche d’Information Assistee par Ordinateur, 186–194. 
 Guyon, I., Weston, J., Barnhill, S., and Vapnik, V . 2002. Gene selection for cancer classifi cation 
using support vector machines,  Machine Learning  46 , 389–422. 
 Guyon, I., and Elisseeff, A . 2003 . An introduction to variable and feature selection,  Journal of 
Machine Learning Research 3 , 1157–1182. 
 Hatzivassiloglou, V. and McKeown, K. R . 1997. Predicting the semantic orientation of adjectives, 
In  Proceedings of the 35  th   Annual Meeting of the Association of Computational Linguistics , 
174–181 . 
199References
 Hearst, M. A . 1992. Direction-based text interpretation as an information access refi nement. 
In P. Jacobs (Ed.) ,  Text-Based Intelligent Systems: Current Research and Practice in Information 
Extraction and Retrieval . Mahwah, NJ, Lawrence Erlbaum Associates . 
 Henley, N. M., Miller, M. D., Beazley, J. A., Nguyen, D. N., Kaminsky, D., and Sanders, R . 2002. 
Frequency and specifi city of referents to violence in news reports of anti-gay attacks,  Discourse 
and Society 13 , 1, 75–104. 
 Herring, S., Job-Sluder, K., Scheckler, R., and Barab, S . 2002 . Searching for safety online: 
Managing “trolling” in a feminist forum,  The Information Society 18 , 5, 371–384 . 
 Herring, S. and Paolillo, J. C . 2006. Gender and genre variations in weblogs,  Journal of 
Sociolinguistics ,  10 , 4, 439. 
 Holland, J . 1975.  Adaptation in natural and artifi cial systems . Ann Arbor, University of Michigan 
Press. 
 Hu, M. and Liu, B . 2004. Mining and summarizing customer reviews. In  Proceedings of the ACM 
SIGKDD International Conference, 168–177. 
 Jain, A. and Zongker, D . 1997. Feature selection: Evaluation, application, and small sample per-
formance.  IEEE Transactions on Pattern Analysis and Machine Intelligence 19 , 2, 153–158. 
 Jiang, M., Jensen, E., Beitzel, S. and Argamon, S . 2004. Choosing the right bigrams for informa-
tion retrieval, In  Proceedings of the Meeting of the International Federation of Classifi cation 
Societies . 
 Juola, P. and Baayen, H.  2005 . A controlled-corpus experiment in authorship identifi cation by 
cross-entropy,  Literary and Linguistic Computing 20, 59–67. 
 Kanayama, H., Nasukawa, T., and Watanabe , H. 2004. Deeper sentiment analysis using machine 
translation technology, In  Proceedings of the 20th International Conference on Computational 
Linguistics , 494–500. 
 Kaplan, J., and Weinberg, L . 1998.  The Emergence of a Euro-American Radical Right ., 
New Brunswick, NJ, Rutgers University Press. 
 Kim, S. and Hovy, E . 2004. Determining the sentiment of opinions, In  Proceedings of the 20th 
International Conference on Computational Linguistics , 1367–1373. 
 Kjell, B., Woods, W.A., and Frieder, O . 1994 . Discrimination of authorship using visualization, 
 Information Processing and Management 30 , 1, 141–150. 
 Koppel, M., Argamon, S., and Shimoni, A.R . 2002. Automatically categorizing written texts by 
author gender,  Literary and Linguistic Computing 17 , 4, 401–412. 
 Koppel, M. and Schler, J . 2003 . Exploiting stylistic idiosyncrasies for authorship attribution, 
In  Proceedings of the IJCAI Workshop on Computational Approaches to Style Analysis and 
Synthesis , Acapulco, Mexico. 
 Levine, D . 1996. Application of a hybrid genetic algorithm to airline crew scheduling,  Computers 
and Operations Research 23, 6, 547–558. 
 Leets, L . 2001. Responses to Internet hate sites: Is speech too free in cyberspace?  Communication 
Law and Policy 6 , 2, 287–317. 
 Li, J., Zheng, R., and Chen, H . 2006 . From fi ngerprint to writeprint,  Communications of the ACM 
49 , 4, 76–82. 
 Li, J. Su, H., Chen, H., and Futscher, B . 2007. Optimal search-based gene subset selection for gene 
array cancer classifi cation,  IEEE Transactions on Information Technology in Biomedicine 11 , 
4, 398–405. 
 Liu, B., Hu, M., and Cheng, J . 2005. Opinion observer: Analyzing and comparing opinions on the 
web, In  Proceedings of the 14th International World Wide Web Conference, 342–351. 
 Martin, J. R. and White, P.R.R. 2005.  The Language of Evaluation: Appraisal in English , London, 
Palgrave. 
 Mishne, G . 2005. Experiments with mood classifi cation, In  Proceedings of the 1  st   Workshop on 
Stylistic Analysis of Text for Information Access , Salvador, Brazil. 
 Mitra, M., Buckley, C., Singhal, A. and Cardie, C . 1997. An analysis of statistical and syntactic 
phrases, In  Proceedings of the 5th International Conference Recherche d’Information Assistee 
par Ordinateur, Montreal, Canada, 200–214. 
200 10 Sentiment Analysis
 Mladenic, D., Brank, J., Grobelnik, M., and Milic-Frayling, N . 2004. Feature selection using linear 
classifi er weights: Interaction with classifi cation models, In  Proceedings of the 27  th   ACM 
SIGIR Conference on Research and Development in Information Retrieval , Sheffi eld, UK, 
234–241. 
 Morinaga, S., Yamanishi, K., Tateishi, K., and Fukushima, T . 2002. Mining product reputations on 
the web, In  Proceedings of the Eighth ACM SIGKDD International Conference on Knowledge 
Discovery and Data Mining , Edmonton, Canada, 341–349. 
 Mullen, T., and Collier, N . 2004. Sentiment analysis using support vector machines with diverse 
information sources, In  Proceedings of the Empirical Methods in Natural Language Processing, 
Barcelona, Spain, 412–418. 
 Nasukawa, T., and Yi, J . 2003. Sentiment analysis: Capturing favorability using natural language 
processing, In  Proceedings of the 2nd International Conference on Knowledge Capture , 
Sanibel Island, Florida, 70–77. 
 Nigam, K., and Hurst, M . 2004. Towards a robust metric of opinion, In  Proceedings of the AAAI 
Spring Symposium on Exploring Attitude and Affect in Text . 
 Oliveira, L.S., Sabourin, R., Bortolozzi, F., and Suen, C.Y . 2002. Feature selection using multi-
objective genetic algorithms for handwritten digit recognition, In  Proceedings of the 16th 
International Conference on Pattern Recognition , 568–571. 
 Pang, B., Lee, L., and Vaithyanathain, S . 2002. Thumbs up? Sentiment classifi cation using machine 
learning techniques, In  Proceedings of the Conference on Empirical Methods in Natural 
Language Processing , 79–86. 
 Pang, B., and Lee, L . 2004. A sentimental education: Sentimental analysis using subjectivity sum-
marization based on minimum cuts, In  Proceedings of the 42  nd   Annual Meeting of the 
Association for Computational Linguistics, 271–278. 
 Peng, F., Schuurmans, D., Keselj, V., and Wang, S. 2003.  Automated authorship attribution with 
character level language models. Paper presented at the 10th Conference of the European 
Chapter of the Association for Computational Linguistics (EACL 2003) . 
 Picard, R. W. 1997.  Affective Computing , Cambridge, MA, MIT Press. 
 Platt, J . 1999. Fast training on SVMs using sequential minimal optimization,  In Scholkopf, B., 
Burges, C., and Smola, A. (Ed.) , Advances in Kernel Methods: Support Vector Learning , 
Cambridge, MA, MIT Press, 185–208. 
 Quinlan, J. R . 1986. Induction of decision trees,  Machine Learning 1 , 1, 81–106. 
 Riloff, E., Wiebe, J., and Wilson, T . 2003. Learning subjective nouns using extraction pattern 
bootstrapping, In  Proceedings of the Seventh Conference on Natural Language Learning 
Conference , Edmonton, Canada, 25–32. 
 Robinson, L . 2005. Debating the events of September 11th: Discursive and interactional dynamics 
in three online for a,  Journal of Computer-Mediated Communication 10, 4. 
 Schafer, J . 2002. Spinning the web of hate: Web-based hate propagation by extremist organiza-
tions,  Journal of Criminal Justice and Popular Culture 9, 2, 69–88. 
 Schler, J., Koppel, M., Argamon, S., and Pennebaker, J . 2006. Effects of age and gender on blog-
ging, In  Proceedings of the AAAI Spring Symposium Computational Approaches to Analyzing 
Weblogs, Menlo Park, CA, 191–197. 
 Sebastiani, F . 2002. Machine learning in automated text categorization,  ACM Computing Surveys 
34, 1, 1–47. 
 Shannon, C. E . 1948. A mathematical theory of communication,  Bell System Technical Journal 27, 
4, 379–423. 
 Siedlecki, W. and Sklansky, J.  1989. A note on genetic algorithms for large-scale feature selection, 
 Pattern Recognition Letters 10, 5, 335–347. 
 Stamatatos, E., Fakotakis, N., & Kokkinakis, G. 2001. Computer-based authorship attribution 
without lexical measures.  Computers and the Humanities 35 , 2, 193–214. 
 Subasic, P., and Huettner, A . 2001. Affect analysis of text using fuzzy semantic typing,  IEEE 
Transactions on Fuzzy Systems 9, 4, 483–496. 
 Tong, R . 2001. An operational system for detecting and tracking opinions in on-line discussion, 
In  Proceedings of the ACM SIGIR Workshop on Operational Text Classifi cation. 1–6. 
201References
 Turney, P. D . 2002. Thumbs up or thumbs down? Semantic orientation applied to unsupervised 
classifi cation of reviews, In  Proceedings of the 40th Annual Meetings of the Association for 
Computational Linguistics , Philadelphia, PA, 417–424. 
 Turney, P, D., and Littman, M, L.  2003. Measuring praise and criticism: Inference of semantic 
orientation from association,  ACM Transactions on Information Systems 21, 4, 315–346. 
 Vafaie, H. and Imam, I. F . 1994. Feature selection methods: Genetic algorithms vs. greedy-like 
search, In  Proceedings of the International Conference on Fuzzy and Intelligent Control 
Systems , 1994. 
 Viegas, F.B., and Smith, M . 2004. Newsgroup crowds and AuthorLines: Visualizing the activity of 
individuals in conversational cyberspaces,  In Proceedings of the 37th Hawaii International 
Conference on System Sciences, Hawaii, USA. 
 Whitelaw, C., Garg, N., and Argamon, S . 2005. Using appraisal groups for sentiment analysis, 
In  Proceedings of the 14  th   ACM Conference on Information and Knowledge Management , 
625–631. 
 Wiebe, J.  1994. Tracking point of view in narrative,  Computational Linguistics 20, 2, 233–287. 
 Wiebe, J., Wilson, T., and Bell, M.  2001. Identifying collocations for recognizing opinions, 
In  Proceedings of the ACL/EACL Workshop on Collocation , Toulouse, France. 
 Wiebe, J., Wilson, T., Bruce, R., Bell, M., and Martin, M . 2004. Learning subjective language, 
 Computational Linguistics 30, 3, 277–308. 
 Wiebe, J., Wilson, T., and Cardie, C . 2005. Annotating expressions of opinions and emotions in 
language,  Language Resources and Evaluation 1, 2, 165–210. 
 Witten, I. H., and Frank, E . 2005.  Data Mining: Practical machine learning tools and techniques, 
2nd Edition,, San Francisco, CA, Morgan Kaufmann. 
 Wilson, T., Wiebe, J., and Hoffman, P . 2005. Recognizing contextual polarity in phrase-level senti-
ment analysis, In  Proceedings of the Human Language Technology Conference and Conference 
on Empirical Methods in Natural Language Processing , British Columbia, Canada, 347–354. 
 Yang, Y. and Pederson, J. O . 1997. A comparative study on feature selection in text categorization, 
In  Proceedings of the 14  th   International Conference on Machine Learning, 412–420. 
 Yang, J. and Honavar, V.  1998. Feature subset selection using a genetic algorithm,  IEEE Intelligent 
Systems 13, 2, 44–49. 
 Yi, J., Nasukawa, T., Bunescu, R. and Niblack, W . 2003. Sentiment analyzer: Extracting senti-
ments about a given topic using natural language processing techniques, In  Proceedings of the 
3 rd IEEE International Conference on Data Mining , 427–434. 
 Yu, H. and Hatzivassiloglou, V . 2003. Towards answering opinion questions: Separating facts from 
opinions and identifying the polarity of opinion sentences, In  Proceedings of the Conference on 
Empirical Methods in Natural Language Processing , 129–136. 
 Zheng, R., Li, J., Huang, Z., and Chen, H . 2006 . A framework for authorship analysis of online 
messages: Writing-style features and techniques,  Journal of the American Society for 
Information Science and Technology 57 , 3, 378–393. 
 Zhou, Y., Reid, E., Qin, J., Chen, H., and Lai, G . 2005. U.S. extremist groups on the web: Link and 
content analysis,  IEEE Intelligent Systems 20, 5, 44–51. 
