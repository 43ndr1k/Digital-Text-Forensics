Chapter 8
Web Genre Analysis: Use Cases, Retrieval
Models, and Implementation Issues
Benno Stein, Sven Meyer zu Eissen, and Nedim Lipka
8.1 Introduction
The genre of a Web document provides information related to the document’s form,
purpose, and intended audience. Documents of the same genre can address differ-
ent topics and vice versa, and several researchers consider genre and topic as two
orthogonal concepts. Though this claim does not hold without exceptions, genre
information attracted much interest as positive or negative filter criterion for Web
search results.
Though the undoubted potential of an automatic genre identification for Web
pages, retrieval models for genre could not convince in the Web retrieval practice by
now. The reasons for this are threefold. First, as was also observed by Santini [32],
the proposed genre classifier technology is corpus-centered: their application within
Web retrieval scenarios shows a significant degradation of the classification per-
formance, rendering the technology largely useless for genre-enabled Web search.
Second, the existing genre retrieval models are computationally too expensive to be
applied in an ad-hoc manner. Third, there is no genre palette that fits for all users
and all purposes. Ideally, a user should be able to adapt a genre classifier to his or
her information need, e.g. by labeling documents as being of an interesting genre or
not.
From the mentioned deficits the first one is the most severe: put in a nutshell,
the existing Web genre retrieval models generalize insufficiently. Also the second
deficit is crucial since it makes the important use case of a genre-enabled Web search
unattractive for users who expect a result list from a search engine by the press of a
button. We argue that the problems can be overcome, and this chapter will introduce
elements of the necessary technological means.
B. Stein (B)
Faculty of Media/Media Systems, Bauhaus-Universität Weimar, Weimar, Germany
e-mail: benno.stein@uni-weimar.de
A. Mehler et al. (eds.), Genres on the Web, Text, Speech and Language
Technology 42, DOI 10.1007/978-90-481-9178-9_8,
C© Springer Science+Business Media B.V. 2010
167
168 B. Stein et al.
8.1.1 Contributions
Section 8.2 outlines use cases where knowledge about a Web document’s genre is
exploited to satisfy an information need in question. The scenarios show that genre
analysis is not only amenable for standard Web search but represents a universal and
powerful instrument for information extraction tasks.
The most important contributions of this chapter relate to the first two deficits
mentioned at the outset: we propose concentration characteristics of genre-specific
core vocabularies as both generalizable and efficiently computable features for genre
retrieval models. In this connection Section 8.3 introduces methods for mining tai-
lored core vocabularies as well as particular statistics as a means for sensible feature
quantization. Section 8.4 then investigates the generalization capability of our genre
retrieval model and presents new kinds of experiments and analysis methods.
Section 8.5 discusses two alternative realization approaches of a service for
genre-enabled Web search. The presented approaches have been put into practice;
an implementation in the form of a browser add-on can be downloaded from our
Web site.1
8.2 Use Cases: Genre Analysis in the Retrieval Practice
Web genre analysis is of highly practical interest. In this section we underpin this
statement and outline use cases where Web genre analysis forms an essential build-
ing block in the information processing chain. From an information retrieval view-
point, a genre analysis is operationalized by means of a tailored retrieval model; see
Section 8.3 for the respective definition and technical background.
The following use cases show the broad spectrum of genre applications, rang-
ing from new kinds of retrieval services to auxiliary technology for information
extraction. Section 8.2.1 illustrates topic-centered search technology which has been
empowered by genre labeling. Section 8.2.2 shows the role of genre information
in vertical search tasks. Section 8.2.3 reports on a feasibility study dealing with
the identification of the governing classification principle in a document collection.
Longterm objective is the development of smart document classification tools. In
Section 8.2.4 genre information is used as a high-level feature for the tailored ren-
dering of Web pages for visually handicapped people. The applications have been
operationalized in our research group, and some have reached a mature development
state.2
1 http://www.webis.de/research/projects/wega
2 While the use cases outlined here focus on the exploitation of genre in texts, the chapter of
Paolillo et al. investigates genre emergence in Flash animations posted to Newgrounds.com.
8 Web Genre Analysis 169
8.2.1 Genre-Enabled Web Search
Search engines are the most influential and important applications for the World
Wide Web. It stands to reason that an integration of genre-enabling technology may
evolve into the most popular Web genre application. Such an integration can happen
according to two different paradigms, namely filtering and Web search. Under the
filtering paradigm, a user declares his or her information need in terms of a genre
preference, and the retrieval process accounts for this constraint. Under the classical
Web search paradigm using Google, Live Search, or Yahoo, Web genre information
is introduced by assigning genre labels to the snippets in the search results (see
Fig. 8.1 for an illustration). Both approaches have their pros and cons, pertaining
to retrieval time and retrieval precision. Different Web genre palettes along with
technology to identify the genre classes are compiled in Table 8.1.
8.2.2 Information Extraction Based on Genre Information
Web genre palettes provide a diversification of documents into text types that is
oriented at search habits on the one hand and the emerged culture of Web presences
on the other. In a technical sense, Web genre models can be understood as a col-
lective term for retrieval models that quantify arbitrary structure- and presentation-
related document features – while being topic-orthogonal at the same time. We have
developed such retrieval models for high-level Web services that need a special text
type as input. Examples:
Fig. 8.1 Genre labels are superimposed a few seconds after the result list is returned by the search
engine. The snapshot shows the Firefox-add-on of WEGA, an acronym for “Web-based Genre
Analysis”
170 B. Stein et al.
Table 8.1 Research in the field of automatic genre classification for Web-based corpora and digital
libraries. An important use case is the development of a richer retrieval result representation in the
search interface
Author
analysis basis Web genre palette Q Document representation d
Bretan et al. [4] user
study with 102
interviewees
Private, public/commercial,
journalistic, report, other texts,
interactive, discussion, link
collection, FAQ, other listing
Simple part-of-speech features,
emphatic and down-toning
expressions, relative number of
digits, average word length,
number of images, proportion
of links
Lee and Myaeng
[19] 7,615
documents
FAQ, home page, reportage,
editorial, research article,
review, product specification
Genre-specific core vocabulary
Rehm [26] 200
documents
Hierarchy with three granularity
levels for academic home pages
HTML meta data, presentation
related tags, linguistic features
Meyer zu Eissen
and Stein [21]
user study with
286 interviewees,
800 documents
Article, discussion, shop,
help, personal home page,
non-personal home page, link
collection, download
Word frequency class,
part-of-speech, genre-specific
core vocabulary, other
close-classed word sets, text
statistics, HTML tags
Kennedy and
Shepherd [15]
321 documents
Personal, corporate,
organizational
HTML tags, phone, email,
presentational tags, CSS, URL,
link, script, genre-specific core
vocabulary
Boese and Howe [3]
342 documents
Abstract, call for papers, FAQ,
sitemap, job description,
resume, statistics, syllabus,
technical paper
Readability scales, part-of-speech,
text statistics, HTML tags, bow,
HTML title tag, URL, number
types, closed-world sets,
punctuation
Lim et al. [20]
1,224 documents
Home page, public, commercial,
bulletin, link collection, image
collection, simple list, input,
journalistic, research, official
material, FAQ, discussion,
product specification, informal
Part-of-speech, URL, HTML tags,
token information, most
frequent function words, most
frequent punctuation marks,
syntactic chunks
Freund et al. [13]
800 documents
Best practice, cookbook, demo,
design pattern, discussion,
documentation, engagement,
FAQ, manual, presentation,
problem, product page,
technical, technote, tutorial,
whitepaper
Bag of words
Santini [32] 1,400
documents
Blog, listing, eshop, home page,
FAQ, search page, online
newspaper front page
Most frequent English words,
HTML tags, part-of-speech,
punctuation symbols,
genre-specific core vocabulary
Santini [32] 2,480
documents
[as before] Text type analysis plus a
combination of layout and
functionality tags
8 Web Genre Analysis 171
WWW
S
VP
TV
NP
Det N NP
Det N
1999
2001
January
2.5.03
...
100,000 DM
two Mio Euro
11 Thousand
68,200 USD
...
Collecting
candidate
documents
Report
filtering
Report
filtering
Time and
money
identification
Phrase
analysis
Fig. 8.2 A four stage approach to market forecast summarization. The second step, “Report filter-
ing”, is achieved with a genre analysis
• Market Forecast Summarization. Market forecasting seeks to anticipate the future
development of new technologies at an early stage. It is vital for most companies
in order to develop reasonable business strategies and to make appropriate cor-
porate investments. Market forecasting can be supported by automatically col-
lecting, assessing, and summarizing information from the World Wide Web into
a comprehensive presentation of the expected market volume. For this purpose
we developed and implemented a four step approach [36]: collecting candidate
documents, report filtering, time and money identification, and phrase analysis
along with template filling (see Fig. 8.2).
The third as well as the fourth step are computationally very demanding, and
the rationale of our approach is to reduce unnecessary NLP effort by a reliable
identification of interesting business reports published on the Web. The heart of
this strategy is a genre analysis in the report filtering step.
• Retrieval of Scholar Material. Specialized search engines and technology for
vertical search are building blocks of future information extraction applications
for the retrieval of scholar material. They shall be able to identify, synthesize,
and present Web documents related to exercises, FAQs, introductory readings,
definitions, or sample solutions – given a topic in question. The driving force is
a reliable document type and genre analysis.
• Focused Crawling for Plagiarism Analysis. The discriminative power of a genre
classifier can also be utilized at the crawling stage. Here, the challenges result
from a retrieval model that must get by with few and small document snippets.
An interesting application is plagiarism analysis, for which we are developing
crawling technology that focuses on research articles, book chapters, and theses.
8.2.3 Organizing Collections in Both Topic and Genre Dimensions
The categorization of documents, bookmarks, or digital document identifiers in
general can happen topic-centered, genre-centered, or in a combined fashion. Hav-
ing identified the categorization paradigm one can support automatic classification,
provide user guidance for insertion (This is not the correct genre!), give hints or
special views for browsing and searching, and identify classes that are not properly
organized. In [37] we have broken down this and similar analysis to the following
question:
172 B. Stein et al.
Given a categorization C of documents (or bookmarks, links, document identifiers), can we
provide a reliable assessment whether C is governed by topic or by genre considerations?
The question can be answered in the following five steps, where essentially a
model fitting problem is solved. Let D be a set of documents, and let C be a catego-
rization of D that is either governed by topic or by genre considerations.
1. Construct for each d ∈ D two retrieval models, one under the genre retrieval
model, RG , and one under the topic retrieval model, RT .
2. Construct two similarity graphs GG and GT . The edge weights in these graphs
result from the similarity computations under RG and RT respectively.
3. Apply a clustering algorithm to the graphs GG and GT . The resulting clusterings
are designated as CG and CT .
4. Compute the F-measure (or another external reference measure) to quantify the
congruence between C and CG as well as between C and CT . The resulting values
are designated as FCG and FCT .
5. If |FCG − FCT | is significant, C is organized under genre considerations if FCG >
FCT , and under topic considerations otherwise.
The analysis in [37] revealed that a definite answer to the above question can be
given, if the impurity ratio, i.e., the ratio between topic classes and genre classes (or
vice versa) is larger than 1:2.
8.2.4 Empower Web Page Abstraction with Genre Information
Web page abstraction is concerned with the preparation of Web pages in a consistent
and clearly arranged form. Possible applications for such a technology are mobile
Internet devices with small displays, but also the simplification of Web pages for
visually handicapped people whose access to the World Wide Web is managed with
Fig. 8.3 The browser add-on for Web page abstraction BAT, an acronym for “Blind Accessibility
Tool”. The left picture shows the original Web page, the right picture the related abstraction, where
navigational areas and main elements have been identified and reorganized in textual form
8 Web Genre Analysis 173
a braille reader. Since the use and the organization of a Web page’s content elements
is genre-dependent, the identification of the underlying genre class gives valuable
hints for a fully-automated Web page abstraction. Figure 8.3 illustrates the use of
the Blind Accessibility Tool add-on BAT that has been developed in our working
group.3
The underlying retrieval model is based on the document object model, DOM: the
genre-revealing features are computed heuristically from the DOM tree, exploiting
node types, node neighborhoods, node depth information, and node content.
8.3 Construction of Genre Retrieval Models
It is necessary to distinguish between a real-world document d and its computer
representation d. d can stand for a paper, a book, or a Web site, while d may be a
vector of terms, concepts, or high-level features, but also a suffix tree or a signature
file. Likewise, D denotes a collection of real-world documents, and D denotes the
set of the related computer representations.
Given an information need in question a retrieval model R provides the rationale
for constructing a particular representation d from a real-world document d. Exam-
ples for retrieval models are the vector space model, the binary independence model,
or the latent semantic indexing model [30, 28, 7]. Note that document representa-
tions and retrieval models are orthogonal concepts: d defines the features computed
from d while R explains the retrieval performance of d against the background of
the retrieval task and linguistic theories.
A genre retrieval model is a retrieval model that addresses queries related to a
palette of genre classes [38]; it is defined as follows.
Definition 1 (Genre Retrieval Model) Let D be set of documents, and let Q, Q =
{c1, . . . , ck}, be a set of genre class labels, also called genre palette. A genre retrieval
model R for D and Q is a tuple 〈D, γR〉 :
1. D is the set of representations of the documents D.
2. γR is a classifier and assigns one or more genre class labels to a document rep-
resentation d ∈ D :
γR : D → P({c1, . . . , ck})
The most important part of a genre retrieval model R cannot be made explicit
in the definition, namely, the theoretical basis and the rationale behind the mapping
α : D → D which computes the representation d for a document d ∈ D.
The development of genre retrieval models is an active research field with several
open questions, and only little is known concerning a user’s information need and
the adequacy of a retrieval model R. Early work in automatic genre classification
dates back to 1994, where Karlgren and Cutting presented a feasibility study
3 http://www.webis.de/research/projects/bat
174 B. Stein et al.
for a genre analysis based on the Brown corpus [14]. Later on followed several
publications investigating different corpora, using more intricate or less complex
retrieval models, stipulating other concepts of genre, or reporting on new applica-
tions [1, 8, 12, 16, 25, 34, 41].
Genres on the Web have been investigated since 1999 [4]. Table 8.1 compiles
research that received attention: the table lists the basis of the analysis, the genre
palette Q, and the document representation d. The underlying use case is a genre-
enabled Web search. The approaches from Crowston and Williams, Roussinov et al.,
Dimitrova et al., Chapter 3 by Rosso and Haas (this book) were not included since
the authors provided suggestions rather than a technical specification about their
genre retrieval models [6, 9, 29].
8.3.1 Problems of Genre Retrieval Models and Lessons Learned
In the following we concentrate on two problems:
1. the insufficient generalization capability of current genre retrieval models R, and
2. the high computational effort of the mapping d → d.
With respect to the third problem mentioned at the outset, the inadequacy of a
unique, single-label genre palette, we propose no special solution but follow the
argument of Santini [32]: Web page diversity and Web page evolution can be cap-
tured by a flexible genre classification palette, capable of performing a zero-, one-,
or multi-label genre assignment. In this book, the problem of defining a suitable text
typology for the Web is discussed by Sharov or by Rosso and Haas among others.
karlgrens and Crowston et al. point out reasons why it is so difficult to develop a
commonly accepted Web genre taxonomy.
Insufficient Generalization Capability
The authors of the approaches listed in Table 8.1 reported on classification results
for the correct assignment of genre classes. The obtained (cross-validated) perfor-
mances are surprisingly high, reaching from 75% with |Q| = 16 genre labels [20]
up to 90% with |Q| = 7 genre labels [19]. These and similar results were achieved
with rather small training corpora, containing between several hundred and a few
thousand documents.
Let γR1 be the genre classifier of a genre retrieval model R1 trained with corpus
D1, and let γR2 be the genre classifier of a genre retrieval model R2 trained with cor-
pus D2. With respect to the common genre labels of two concrete retrieval models
Santini investigated the generalization capability of classifier γR1 to corpus D2 and,
vice versa, of classifier γR2 to corpus D1.4 It turned out that the retrieval precision
4 Santini uses the term “exportability” in this connection. Actually, she measured the agreement
between γR1 and γR2 , which is a particular facet of the generalization capability [39].
8 Web Genre Analysis 175
decreased by more than one order of magnitude, a truly disappointing result [32].
In this book Santini provides an extended analysis in this respect, by cross-testing a
genre classifier’s performance on single labels.
The classification knowledge that is operationalized within a genre retrieval
model 〈D1, γR1〉 can be exported to a corpus D2 if the model captures the inten-
sional semantics of the concept “genre”. The intensional semantics of a genre
retrieval model can be understood as its capability to comply with the extensional
semantics of genre in different worlds, say, as its capability to correctly classify
documents from different corpora. If so, the model provides a high generalization
capability. The generalization capability of a genre retrieval model depends on its
bias, which in turn can be understood as the size of the hypotheses space wherein
the learning algorithm is searching for the model.
The bias of a learning algorithm can be assessed with respect to two dimen-
sions: the size and the exploration strategy of the hypothesis space. Different
authors use different names for both types of biases, Table 8.2 gives an overview.
The table also shows the impact of the bias strength: while a strong bias of
Type I raises a classifier’s generalization capability, a strong bias of Type II
raises the sensitivity of a learning algorithm with respect to the training data.
The former is a highly appreciated property, whereas the latter is absolutely to be
avoided.
There is also the question of the correctness of a biased learning algorithm [40].
Independent of its type, a strong bias decreases the probability of finding the correct
hypothesis. In particular, a strong bias of Type I will inevitably compromise the
correctness – simply due to the construction of a coarse hypothesis space, whereas
a strong bias of Type II leaves – at least theoretically – the chance of choosing the
correct hypothesis.
Most of the Web genre models listed in Table 8.1 have a very weak bias of
Type I. If one analyzes the proportion between the number of training samples
and the size of the underlying hypothesis space, running the risk of rote learn-
ing becomes obvious – despite sophisticated learning technology such as support
vector machines. The generalization capability of a genre retrieval model can be
Table 8.2 Two types of biases can be distinguished, pertaining to search space size and search
space exploration. The table lists the synonyms that are used in the literature (upper row) and
illustrates the impact of the bias strength towards the generalization capability of the learning
algorithm and its training data sensibility (lower row)
Type I Type II
Bias search space size search space exploration
Synonyms Exclusive bias Rendell [27] Preferential bias Rendell [27]
Representational
bias
Quinlan [24] Procedural bias Quinlan [24]
Restriction bias Mitchell [22] Search bias Mitchell [22]
weak
Strength
<————————> strong weak
Strength
<————————> strong
low
Generali zation capabili t y
<————————> high low
T raining data sensibili t y
<————————> high
176 B. Stein et al.
measured by the “stability” and “efficiency” of its construction process with respect
to training samples; Section 8.4.2 introduces the theoretical means and reports on
respective experiments.
High Computational Effort
Table 8.1 lists a wide range of feature types to compute the document representation
d for retrieval models:
• Presentation-related Features. Frequency counts for figures, tables, paragraphs,
headlines, captions. HTML-specific analysis regarding colors, hyperlinks, URLs,
or mail addresses.
• Simple Text Statistics. Frequency counts for clauses, paragraphs, delimiters, ques-
tion marks, exclamation marks, and numerals.
• Special Closed-Class Word Sets and Core Vocabularies. Use of currency sym-
bols, help phrases, shop phrases, calendar, or countries.
• Word Frequency Class Analysis. Use of special words, common words, or mis-
spelled words.
• Part-of-Speech Analysis. Frequency counts for nouns, verbs, adjectives, adverbs,
prepositions, or articles.
• Syntactic Group Analysis. Use of tenses, relative clauses, main clauses, adverbial
phrases, or simplex noun phrases.
The effort to compute the mentioned features is between linear time in the text
length, e.g. for simple frequency counts, and ranges up to cubic effort and higher
for the parsing of syntactic groups. The usefulness and, even more importantly, the
cost-benefit ratio of these features with respect to a reliable genre analysis is unclear.
Hence the researchers who build genre retrieval models tend to include a feature
instead of leaving it out. In this sense the model formation task is shifted to the
learning algorithm, which identifies and weights the most discriminating features
based on the training data. This strategy is acceptable if training data is plentiful
and – with respect to the classification task – sensibly distributed. Both requirements
are not fulfilled here: the construction of training corpora is expensive, as the small
sample sizes in Table 8.1 show (see the first column). Moreover, considering the
different user- and task-specific genre palettes and the impracticality to estimate the
document type distribution on the World Wide Web, very little can be stated about
the a-priori probabilities of document types.
The combination of rich feature models with small training corpora is crucial
in two respects: it compromises generalization capability and makes the learning
process sensible to the training data. A way out is the use of few features with a
coarse domain.
8.3.2 New Elements for Genre Retrieval Models
The potential of features related to genre-specific core vocabularies are
underestimated. The reasons for this are twofold: (i) till now genre-specific core
8 Web Genre Analysis 177
vocabularies are compiled manually, following intuition. (ii) The evaluation of core
vocabularies is limited to simple count statistics. This subsection outlines new ele-
ments for the construction of robust and lightweight genre retrieval models: an
automatic extraction of core vocabularies and new features that quantify distribution
information. Details can be found in [38].
For the set D of documents let C = {C1, . . . , Ck} be an exclusive genre catego-
rization of D. I.e.,
⋃
C∈C C = D and ∀Ci , C j, j =i ∈ C : Ci ∩ C j = ∅. For a genre
class C ∈ C, let TC denote the core vocabulary specific for C . Similar to Broder we
argue that TC is comprised of navigational, transactional, structural, and informative
terms [5]. The combination, distribution, presence or absence of these terms encode
a considerable part of the genre information.
• Navigational Terms. Appear in labels of hyperlinks and in anchor tags of Web
pages. Examples: “Windows”, “Mac”, or “zip” in download sites, links to “refer-
ences” in articles.
• Transactional Terms. Appear in sites that interact with databases, and manifest in
hyperlink labels, forms, and button captions. Examples: “add to shopping cart”,
“proceed to checkout” in online shops, buttons labeled “download” on download
pages.
• Structural Terms. Appear in sites that maintain meta information like time and
space. Examples include the meta information of posts in a discussion forum
(“thread”, “replies”, “views”, parts of dates) and terms that appear in addresses
on home pages (“address”, “street”).
• Informative Terms. Appear not in functional HTML elements but imply func-
tionality though. Examples include “kb” or “version” on download sites, “price”
or “new” on shopping sites, and “management”, “technology”, or “company” on
commercial sites.
The terms in TC are both predictive and frequent for C . Terms with such
characteristics can be identified in C with approaches from topic identification
research, in particular Popescul’s method and the weighted centroid covering
method [17, 18, 23, 35]. In order to mine genre-specific core vocabulary both meth-
ods must be adapted: they do not quantify whether a term is representative for C ;
a deficit, which can be repaired without compromising the efficient O(m log(m))
runtime of the methods, where m designates the number of terms in the
dictionary [38].
Concentration Measures
In the simplest case, the relation between TC and a document d can be quantified by
computing the fraction of d’s terms from TC , or by determining the coverage of TC
by d’s terms. However, if genre-specific vocabulary tends to appear concentrated
in certain places on a Web page, this characteristic is not reflected by the men-
tioned features, and hence it cannot be learned by a classifier γR. Examples for Web
pages on which genre-specific core vocabulary appears concentrated: private home
pages (e.g. address vocabulary), discussion forums (e.g. terms from mail headers),
178 B. Stein et al.
and non-personal home pages (e.g. terms related to copyright and legal informa-
tion). The following two statistics quantify two different vocabulary concentration
aspects:
1. Maximum Term Concentration. Let d ∈ D be represented as a sequence of terms,
d = {w1, . . . , wm}, and let Wi ⊂ d be a text window of length l in d starting with
term i , say, Wi = {wi , . . . , wi+l−1}. A natural way to measure the concentration
of terms from TC in different places of d is to compute the following function
for different Wi :
κTC (Wi ) =
|Wi ∩ TC |
l
, κTC (Wi ) ∈ [0, 1]
The overall concentration is defined as the maximum term concentration:
κ∗TC = maxWi ⊂d κTC (Wi ), κ
∗
TC ∈ [0, 1]
2. Gini Coefficient. In contrast to the κTC statistic, which quantifies the term concen-
tration strength within a text window, the Gini coefficient can be used to quantify
to which extent genre-specific core vocabulary is distributed unequally over a
document. Again, let Wi be a text window of size l sliding over d. The number
of genre-specific terms from TC in Wi is νi = |TC ∩ Wi |. Let A denote the area
between the uniform distribution line and the Lorenz curve of the distribution
of νi , and let B denote the area between the uniform distribution line and the
x-axis. The Gini coefficient is defined as the ratio g = A/B, g ∈ [0, 1]. A value
of g = 0 indicates an equal distribution; the closer g is to 1 the more unequal νi
is distributed.
Discussion
Concentration measures capture distribution information of different subsets of a
document’s terms. These subsets, called core vocabularies here, as well as their con-
centration analysis, form the basis for non-linear features that cannot be constructed
by the state of the art machine learning technology. This is the reason why our
research focuses on the idea of sensible genre retrieval models, instead of resorting
to the standard bag of word model where the learning algorithms accomplishes a
low-level feature (= term) selection. Note that in Chapter 6 by Kim and Ross (this
book) also propose features that consider the word distribution in a document.
8.4 Evaluation
This section addresses evaluation-related issues of Web genre identification. We dis-
cuss approaches for improving the generalization capability and propose statistics to
quantify this property for genre retrieval models. These statistics are used to evaluate
different genre retrieval models with respect to two popular Web genre corpora.
8 Web Genre Analysis 179
8.4.1 Improving Generalization Capability
Improving a classifier’s generalization capability means to restrict its representa-
tional bias. In practice, this goal is achieved by (i) reducing the number of features,
(ii) reducing the number of values a feature can take, and (iii) replacing weak fea-
tures by discriminative features.
The proposed concentration measures, i.e. maximum concentration and Gini
coefficient of core vocabulary distributions, impose one feature per genre class,
resulting in eight features for a document of a collection with eight genre classes.
In comparison to a standard text classification approach with SVMs, the number of
features introduced by these concentration measures is orders of magnitude smaller,
addressing Point (i), and, as our experiments show, Point (iii).
Point (ii) can be tackled by discretizing continuous features. A standard approach
is the substitution of categorical or nominal features for continuous features [11,
2]; see [10] for an overview of such methods. Although these methods might be
powerful their evaluation for Web genre analysis is out of the scope of this chapter.
8.4.2 Measuring Generalization Capability
In the following, the concepts predictive accuracy, classifier agreement, and export
accuracy are defined; the notation is adapted from [39]. Simply put, the concepts
quantify the classification performance, the impact of classifier variation, and the
impact of corpus variation.
Definition 2 (Predictive Accuracy) Let D be a document set organized according to
a genre palette Q. Moreover, let α : D → D be a mapping that computes a document
representation, and let 〈D, γR〉 be a genre retrieval model for D. Then the predictive
accuracy aγR of the classifier γR is the probability that γR will assign the correct
genre class label to an unseen example (d, c∗) ∈ D × Q:
aγR := P(γR(d) = c∗)
The predictive accuracy is estimated by classifying unseen examples from D ×
Q, and it may not be confused with the training set accuracy. It is possible that
two classifiers that have the same predictive accuracy may disagree on predicting
particular samples.
Definition 3 (Classifier Agreement) Let D be a document set organized according
to a genre palette Q. Moreover, let α1 : D → D1 and α2 : D → D2 be two map-
pings that compute two document representations, and let 〈D1, γR1〉 and 〈D2, γR2〉
be two genre retrieval models for D. Then the agreement of the classifiers γR1 and
γR2 is defined as follows:
agree(γR1 , γR2) := P
(
γR1(d1) = γR2(d2)
)
,
where d1 ∈ D1 and d2 ∈ D2 are representations of the same document d ∈ D.
180 B. Stein et al.
That is, the classifier agreement is the probability that two genre retrieval models
make the same decision on the genre of a document. Consider that α1 = α2 and
hence D1 = D2 can hold: the two genre retrieval models rely on the same document
representation, but differ with respect to their machine learning settings. In particu-
lar, γR1 and γR2 can result from training on different samples while using the same
classifier type. In this important analysis case the classifier agreement quantifies the
training data sensibility of a genre retrieval model (see also Table 8.2, right column).
Definition 4 (Export Accuracy) Let D1 ⊂ D and D2 ⊂ D be two document sets
organized according to the genre palettes Q1 and Q2, Q1 ∩ Q2 = ∅. Moreover, let
α : D → D be a mapping that computes the document representations D1 ⊂ D
and D2 ⊂ D, and let 〈D1, γR1〉 be a genre retrieval model for D1. Then the export
accuracy of the genre retrieval model 〈D1, γR1〉 with respect to D2 is defined as
follows:
eγR1 ,D2 := P
(
γR1(d2) = c∗
)
,
where d2 ∈ D2 is the representation of a document d2 ∈ (D2 \ D1) with genre class
c∗ ∈ (Q1 ∩ Q2).
That is, the export accuracy is the probability that the assigned genre of a docu-
ment of an external corpus is correct. Note that the export accuracy is affected by the
homogeneity of the training corpus. The export accuracy of a genre retrieval model
〈D1, γR1〉 with respect to D2 quantifies whether the combination of D1, α, and γR1
captures the gist of the genre classes in Q1 ∩ Q2. Only if the document set D1 is
representative, if the mapping α is sensible, and if γR1 generalizes sufficiently, the
classifier γR1 will perform acceptably for the documents in D2. Typically, D2 is
compiled by different users, and the claimed conditions are not fulfilled. Hence we
observe eγR1,D2 < aγR1 in most cases.
8.4.3 Experiments
We now discuss the generalization capability of genre retrieval models regarding the
measures introduced in the Definitions 2, 3, and 4. Our empirical analysis illustrates
the theoretical observation from above: the stronger the representational bias of a
retrieval model the higher is its generalization capability.
The analysis is based on the Web genre corpora “KI-04” with 8 Web genre classes
[21], denoted as A, and the “7-Webgenre collection” [31], denoted as B.5 These
corpora are sketched in Table 8.1, row 4 and row 8. The questions to be answered
refer to the generalization capabilities of different genre retrieval models. In par-
ticular, the following retrieval models are examined, which differ in the computed
representation of a document:
5 KI-04 can be downloaded from http://www.webis.de/research/corpora. In the experiments the
extended version of this corpus (1,200 Web pages) was used.
8 Web Genre Analysis 181
1. GenreVSM. The vector space model using t f · id f term weighting scheme, com-
prising about 3,500 features.
2. GenreVoc. A genre retrieval model based on the core vocabulary analysis as
introduced in Section 8.3, comprising a total of 26 features.
3. GenreBasic. A basic genre retrieval model based only of HTML features, link
features, and character features, comprising a total of 54 features.
4. GenreRich. A rich genre retrieval model based on the features of GenreBasic
along with part-of-speech features and vocabulary concentration features, com-
prising a total of 98 features.
5. GenreRichNoVoc. The GenreRich retrieval model without the vocabulary con-
centration features, comprising a total of 72 features.
Each experiment was repeated and averaged using 10 random draws of the
respective number of training documents; the applied machine learning technology
was a support vector machine.
The presumably most important property of a Web genre retrieval model is a
high export accuracy. Consider in this connection Fig. 8.4: the left plot shows the
predictive accuracy of the retrieval models GenreVSM and GenreRich – trained on
and applied to documents of corpus A containing 1,200 documents. The right plot
shows the export accuracy of these classifiers with respect to corpus B containing
600 documents, with Q A ∩ Q B = {shop, personal home page, link list}. In both
plots the x-axis shows the sample size of the training set taken from corpus A; the
y-axis shows corresponding test set accuracies on corpus A (left plot) and the test
set accuracies on corpus B (right plot), called the export accuracy.
Observe that the GenreVSM model achieves a significantly higher predictive
accuracy than the GenreRich model (see Fig. 8.4, left plot); with respect to the
sample size both show the same consistency characteristic. We explain the high
predictive accuracy of GenreVSM with its higher training data sensibility, which is
beneficial in homogeneous corpora. Even under a successful cross validation test
the predictive accuracy and the export accuracy will considerably diverge.
Fig. 8.4 Predictive accuracy (left) and export accuracy (right) of the retrieval models GenreVSM
and GenreRich, depending on the size of the training set, which is always drawn from corpus A
(KI-04). The predictive accuracy is estimated on a test set of corpus A, while the export accuracy
is estimated on a test set of corpus B (7-Webgenre collection)
182 B. Stein et al.
A corpus may be homogeneous because of the following reasons:
1. The corpus is compiled by a small group of editors who share a similar under-
standing of genre.
2. The editors introduce subconsciously an implicit correlation between topic and
genre.
3. The editors collect their favored documents only.
4. The editors rely on a single search engine whose ranking algorithm is biased
towards a certain document type.
Corpus homogeneity is unveiled when analyzing the export accuracy, which
drops significantly (by 21%) for the GenreVSM model (see Fig. 8.4, right plot).
For the GenreRich model the export accuracy drops only by 8%. The robustness
of the GenreRich model is a consequence of its small number of features, which is
more than an order of magnitude smaller compared to the GenreVSM model.
The plots shown in Fig. 8.5 quantify also the drop in export accuracy (left plot
→ right plot), but analyze different retrieval model variants whose feature sets are
subset of the GenreRich model:
• The GenreVoc model shows a small drop in the export accuracy, which is rooted
in the fact that the core vocabulary has a small – but acceptable – corpus depen-
dency.
• For the GenreRichNoVoc model the export accuracy remains pretty constant.
The reasons for this stability are the small hypothesis space and a small corpus
dependency of the features.
• For the GenreBasic model the export accuracy is significantly higher than the
predictive accuracy. We explain this behavior with the high discriminative power
of the HTML features and link features with respect to the genre classes shop,
personal home page, and link list.
Figure 8.6 shows results from an agreement analysis for classifiers of the Gen-
reVSM model and the GenreRich model. The x-axis denotes the the size of the
training set, which is always drawn from corpus A (KI-04). As expected, both plots
show the monotonous characteristic of the classifiers subject to the training set size.
Fig. 8.5 Predictive accuracy (left) and export accuracy (right) of the retrieval models GenreVoc,
GenreRichNoVoc, and GenreBasic, using the same settings as in the experiments shown in Fig. 8.4
8 Web Genre Analysis 183
Fig. 8.6 Classifier agreement of the retrieval models GenreVSM and GenreRich, depending on
the size of the training set, which is always drawn from corpus A. In the left plot the agreement is
analyzed on corpus A, while in the right plot the agreement is analyzed on corpus B
Observe in the left plot in Fig. 8.6 that the agreement of both classifiers is
quite similar, although the representational bias of the GenreVSM model is weaker
than the bias of the GenreRich model. Again, this behavior can be explained by
the homogeneity of the corpus. However, the situation is different if the classifier
agreement is analyzed on a test corpus different from the training corpus (see the
right plot in Fig. 8.6): the agreement of classifiers under the GenreRich model is
much better than the agreement of classifiers under the GenreVSM model. That
is, classifiers under the GenreVSM model are corpus-specific (overfitted) whereas
classifiers under the GenreRich model are not, they provide a much higher general-
ization capability.
A key measure for evaluating Web genre retrieval is the export accuracy. Using
an independent corpus for the accuracy evaluation of a genre retrieval model gives
consolidated findings and a significant model selection criterion. In this respect the
GenreRich model is superior to the other genre retrieval models in our analysis.
The high classifier agreement of the GenreRich model on corpus A and particularly
on corpus B shows that the chance of being misled by the training set, and the
overfitting risk, is low.
8.5 Implementing Genre-Enabled Web Search
The aim of a genre-enabled Web search is to combine genre information with the
standard list-based topic search. To implement a solution for this use case several
design decision have to be made:
1. What are useful classes in a genre palette?
2. Shall a user be able to define new or own genre classes?
3. How shall genre information be integrated into the search process?
4. Is a distributed software architecture suited or necessary?
WEGA, a software for Web-based genre analysis that has been developed in our
working group, can be characterized as follows: it implements the genre palette
184 B. Stein et al.
shown in the fourth row in Table 8.1, and the classification results are integrated
as genre labels into a standard result list (see Fig. 8.1). Based on such a kind of
user interface, new and user-definable genre classes can be conveniently integrated,
and a future version of WEGA shall provide this feature. Of course other visualiza-
tion paradigms are conceivable: within the categorizing search engine AIsearch we
employ a filter-based interface paradigm where documents are visualized as nodes
of a hyperbolic graph, which can be faded in and out.6 Presumably, a general way to
combine genre and topic information cannot exist, and the information visualization
paradigm must be tailored to the use case. In the remainder we concentrate on the
fourth, software-technical question.
The first prototypes of WEGA were implemented according to the client-server-
paradigm, simply because the sophisticated feature computation should not be car-
ried out by the Web browser but by a powerful Web service. If the execution of high-
level operations is shifted to a third party one speaks from “operation shipping” – in
contrast to “data shipping” where even computationally intensive tasks are executed
at the client site. Various issues are bound up with the decision to pursue the one
or other strategy, and the advantages of one paradigm turn to disadvantages of the
other [33]. Figure 8.7 illustrates the key difference between an operation shipping
implementation and a data shipping implementation: in the former, presentation and
application form a distributed system, while in the latter both are located at the
client site.
Fig. 8.7 The genre-enabled Web search WEGA was implemented according to two different soft-
ware engineering paradigms: operation shipping (left) and data shipping (right)
6 http://www.webis.de/research/projects/aisearch
8 Web Genre Analysis 185
The actual version of WEGA follows the data shipping paradigm; it is realized
as a Firefox add-on and implements a lightweight GenreRich model, i.e. the fea-
tures of a GenreRich model without the part-of-speech features along with a linear
discriminant analysis γR. It can be downloaded from our Web site.7 Under either
paradigm the same functionality is realized in WEGA, however, by using different
technical means:
• Operation Shipping WEGA. Presentation layer: DOM + AJAX (= Asynchronous
JavaScript and XML). Retrieval model computation: Java servlet in servlet con-
tainer. To learn more about the software architecture Figs. 8.8 and 8.9 provide an
UML diagram for both the component deployment and the component interplay.
• Data Shipping WEGA. Presentation layer: DOM + AJAX. Retrieval model com-
putation: JavaScript.
The data shipping paradigm came within the realms of possibility with the new
elements for light-weight genre retrieval models, outlined in Section 8.3.2. However,
the computationally means within a Web browser are inferior to that of the servlet
technology; to get an idea of the effective difference Table 8.3 contrasts selected
characteristics of the implementations.
Note that one of the biggest disadvantages of an operation shipping implemen-
tation for a Web genre analysis is the possible infringement of privacy and the
Fig. 8.8 The deployment diagram of WEGA under the operation shipping paradigm. A servlet
container provides the necessary components for the analysis service
7 http://www.webis.de/research/projects/wega
186 B. Stein et al.
Fig. 8.9 The sequence diagram of WEGA under the operation shipping paradigm. The middle part
of the diagram show the an synchronous interaction realized with AJAX
Table 8.3 Operation shipping versus data shipping: comparison of computational characteristics
of the associated implementations
Characteristic Operation shipping Data shipping
Language Java JavaScript
Code size Medium Small
Runtime
Feature computation 342 [kB/s] 134 [kB/s]
Classification <1 [d/ms] <1 [d/ms]
implementation of adequate counter measures: private queries and search results
are sent to a public server, a fact which will never be accepted by the majority of the
users.
8.6 Conclusion
Web genre analysis has various applications – not only as a filter criterion for Web-
based search, but also as preprocessing technology for advanced information extrac-
tion and document organization tasks. We use the term “genre retrieval model” as
a collective term for the combination of a set of document representations D and
a classifier γ that maps a document representation d ∈ D on a set of genre class
labels. Most of the existing genre retrieval models exploit high-level features, such
8 Web Genre Analysis 187
as part-of-speech, tailored text statistics, or information about the document struc-
ture. However, aside from the high computational effort a negative consequence is
that the resulting genre retrieval models tend to generalize unsatisfactorily.
Especially because of the last point retrieval models for genre did not convince
in the Web retrieval practice. Our research addresses this issue by providing a for-
mal means to measure the generalization capability of genre retrieval models. We
also propose a feature type which quantifies the concentration of genre-specific core
vocabulary in a document, and which has the potential to improve the generalization
capability of existing genre retrieval models. Our analysis shows that this new kind
of feature class is successful in this respect.
The chapter discussed also software engineering aspects: the authors have devel-
oped and compared browser add-ons that implement genre-enabled Web search.
Our implementation shows the feasibility of the technology and gives an idea of
how genre information can be integrated into standard search technology.
References
1. Antunes, P., C.J. Costa, and J. Ferreira Dias. 2001. Applying genre analysis to ems design:
The example of a small accounting firm. In Proceedings of the 7th International Workshop on
Groupware, CRIWG 2001, 74–81. Darmstadt: IEEE CS Press.
2. Bay, S.D. 2000. Multivariate discretization of continuous variables for set mining. In KDD
’00: Proceedings of the 6th ACM SIGKDD International Conference on Knowledge Dis-
covery and Data Mining, 315–319, New York, NY: ACM Press. ISBN 1-58113-233-6. doi:
http://doi.acm.org/10.1145/347090.347159
3. Boese, E.S., and A.E. Howe. 2005. Effects of web document evolution on genre classification.
In Proceedings of the CIKM’05, Nov 2005. ACM Press.
4. Bretan, I., J. Dewe, A. Hallberg, N. Wolkert, and J. Karlgren. 1998. Web-specific genre visu-
alization. In Proceedings of the Webnet World Conference on the WWW and Internet.
5. Broder, A.Z. 2002. A Taxonomy of Web Search. SIGIR Forum 36(2):3–10.
6. Crowston, K., and M. Williams. 2000. Reproduced and emergent genres of communication on
the World-Wide Web. The Information Society 16(3):201–216.
7. Deerwester, S.C., S.T. Dumais, T.K. Landauer, G.W. Furnas, and R.A. Harshman. 1990.
Indexing by latent semantic analysis. Journal of the American Society of Information Science
41(6):391–407.
8. Dewdney, N., C. VanEss-Dykema, and R. MacMillan. 2001. The form is the substance: Clas-
sification of genres in text. In Proceedings of ACL Workshop on HumanLanguage Technology
and Knowledge Management. Toulouse, France.
9. Dimitrova, M., A. Finn, N. Kushmerick, and B. Smyth. 2002. Web genre visualization. In
Proceedings of the Conference on Human Factors in Computing Systems. Minneapolis, Min-
nesota, USA.
10. Dougherty, J., R. Kohavi, and M. Sahami. Jul 1995. Supervised and unsupervised discretiza-
tion of continuous features. In Proceedings of the 12th International Conference on Machine
Learning, eds. A. Prieditis and S. Russell, 194–202, Menlo Park, CA: Morgan Kaufmann.
11. Fayyad, U.M., and K.B. Irani. 1993. Multi-interval discretization of continuous-valued
attributes for classification learning. In Proceedings of the International Joint Conference on
Uncertainty in AI (IJCAI), 1022–1027. Chambery, France.
12. Finn, A., and N. Kushmerick. 2003. Learning to classify documents according to genre. In
IJCAI-03 Workshop on Computational Approaches to Style Analysis and Synthesis. Acapulco,
Mexico.
188 B. Stein et al.
13. Freund, L., C.L.A. Clarke, and E.G. Toms. 2006. Towards genre classification for IR in the
workplace. In Proceedings of the 1st International Conference on Information Interaction in
Context, 30–36. New York, NY: ACM Press. ISBN 1-59593-482-0.
14. Karlgren, J., and D. Cutting. 1994. Recognizing text genres with simple metrics using dis-
criminant analysis. In Proceedings of the 15th. International Conference on Computational
Linguistics, Coling 94, vol. II, 1071–1075. Kyoto.
15. Kennedy, A., and M. Shepherd. 2005. Automatic identification of home pages on the web. In
Proceedings of the 38th Annual Hawaii International Conference on System Sciences, HICSS-
38. Big Island, Hawaii.
16. Kessler, B., G. Nunberg, and H. Schütze. 1997. Automatic detection of text genre. In Pro-
ceedings of the 35th Annual Meeting of the Association for Computational Linguistics and 8th
Conference of the European Chapter of the Association for Computational Linguistics, eds.
P.R. Cohen and W. Wahlster, 32–38. Somerset, NJ: Association for Computational Linguistics.
17. Lawrie, D., W.B. Croft, and A.L. Rosenberg. 2001. Finding topic words for hierarchical sum-
marization. In SIGIR 2001: Proceedings of the 24th Annual International ACM SIGIR Confer-
ence on Research and Development in Information Retrieval, 9–13 Sept 2001, 349–357. New
Orleans, LA.
18. Lawrie, D.J., and W.B. Croft. 2003. Generating hierarchical summaries for web searches.
In SIGIR 2003: Proceedings of the 26th Annual International ACM SIGIR Conference
on Research and Development in Information Retrieval, Jul 28–Aug 1, 2003, 457–458.
Toronto, ON.
19. Lee, Y.-B., and S.H. Myaeng. 2002. Text genre classification with genre-revealing and subject-
revealing features. In SIGIR 2002: Proceedings of the 25th Annual International ACM SIGIR
Conference on Research and Development in Information Retrieval, 145–150. ACM Press.
ISBN 1-58113-561-0. doi: http://doi.acm.org/10.1145/564376.564403
20. Lim, C.S., K.J. Lee, and G.C. Kim. 2005. Automatic genre detection of web documents. In
Proceedings of Natural Language Processing, IJCNLP 2004, eds. K. Su, J. Tsujii, J. Lee, and
O.Y. Kwong, 310–319. Springer.
21. Meyer zu Eißen, S., and B. Stein. 2004. Genre classification of web pages: User study and
feasibility analysis. In KI 2004: Advances in Artificial Intelligence, Sept 2004, eds. S. Biundo,
T. Frühwirth, and G. Palm, LNAI of Lecture Notes in Artificial Intelligence, vol. 3228,
256–269, New York, NY: Springer. ISBN 0302-9743.
22. Mitchell, T.M. 1997. Machine learning. New York, NY: McGraw-Hill Higher Education.
ISBN 0070428077.
23. Popescul, A., and L.H. Ungar. Automatic labeling of document clusters. http://
citeseer.nj.nec.com/popescul00automatic.html, 2000
24. Quinlan, J.R. 1993. C4.5: Programs for machine learning. San Mateo, CA: Morgan Kaufmann
Publishers.
25. Rauber, A., and A. Müller-Kögler. 2001. Integrating automatic genre analysis into digital
libraries. In ACM/IEEE Joint Conference on Digital Libraries, 1–10. Roanoke, Virginia, USA.
26. Rehm, G. 2002. Towards automatic web genre identification. In Proceedings of the 35th
Hawaii International Conference on System Sciences (HICSS’02), Jan 2002. IEEE Computer
Society.
27. Rendell, L.A. 1986. A general framework for induction and a study of selective induction.
Machine Learning 1:177–226.
28. Robertson, S.E., and K. Sparck-Jones. 1976. Relevance weighting of search terms. American
Society for Information Science 27(3):129–146.
29. Roussinov, D., K. Crowston, M. Nilan, B. Kwasnik, J. Cai, and X. Liu. 2001. Genre based
navigation on the web. In Proceedings of the 34th Hawaii International Conference on System
Sciences. Maui, Hawaii.
30. Salton, G., A. Wong, and C.S. Yang. 1975. A vector space model for automatic indexing.
Communicaitons of the ACM 18(11):613–620.
31. Santini, M. 2006. Common criteria for genre classification: Annotation and granularity. In
Proceedings of the ECAI-Workshop TIR-06. Riva del Garda.
8 Web Genre Analysis 189
32. Santini, M. 2007. Automatic identification of genre in web pages. PhD thesis, University of
Brighton.
33. Sellentin, J. 1999. Konzepte und Techniken der Datenversorgung für komponentenbasierte
Informationssysteme. PhD thesis, University of Stuttgart, Stuttgart.
34. Stamatatos, E., N. Fakotakis, and G. Kokkinakis. 2000. Text genre detection using common
word frequencies. In Proceedings of the 18th International Conference on Computational Lin-
guistics. Saarbrücken.
35. Stein, B., and S. Meyer zu Eißen. 2004. Topic identification: framework and application. In
Proceedings of the 4th International Conference on Knowledge Management (I-KNOW 04),
Graz, Austria, July 2004, eds. K. Tochtermann and H. Maurer, Journal of Universal Computer
Science, 353–360. Graz: Know-Center.
36. Stein, B., and M. Busch. 2005. Density-based cluster algorithms in low-dimensional and
high-dimensional applications. In Proceedings of the 2nd International Workshop on Text-
Based Information Retrieval (TIR 05), Fachberichte Informatik, Sept 2005, eds. B. Stein and
S. Meyer zu Eißen, 45–56. Universität Koblenz-Landau.
37. Stein, B., and S. Meyer zu Eissen. 2006. Distinguishing topic from genre. In Proceedings
of the 6th International Conference on Knowledge Management (I-KNOW 06), Graz, Sept
2006, Journal of Universal Computer Science, eds. K. Tochtermann and H. Maurer, 449–456.
Springer.
38. Stein, B., and S. Meyer zu Eißen. 2008. Retrieval models for genre classification. Scandina-
vian Journal of Information Systems (SJIS) 20(1):91–117. ISSN 0905-0167.
39. Turney, P.D. 1995. Technical note: Bias and the quantification of stability. Machine Learning
20(1–2):23–33.
40. Utgoff, P.E. 1986. Shift of bias for inductive concept learning. In Machine learning: An arti-
ficial intelligence approach, eds. R.S. Michalski, J.G. Carbonell, and T.M. Mitchell, vol. II,
107–148. Los Altos, CA: Kaufmann.
41. Yoshioka, T., and G. Herman. Coordinating information using genres. CCS WP 214. Cam-
bridge, MA: Massachusetts Institute of Technology (MIT), Sloan School of Management,
Aug 2000.
