Cross Lingual Text Reuse Detection
Based on Keyphrase Extraction
and Similarity Measures
Rambhoopal Kothwal and Vasudeva Varma
International Institute of Information Technology, Hyderabad
bhupal iiit@research.iiit.ac.in, vv@iiit.ac.in
Abstract. Information on web in various languages is growing fast, but
large amount of content still exists in English. There are several cases of
English text re-use (cross language plagiarism) observed in non-English
languages. Detecting text re-use in non-English languages is a challeng-
ing task due to complexity of the language used. Complexity further
increases for less resource languages like Arabic and Indian languages.
In this paper, we address the problem proposed in FIRE1 CL!TR 20112
task of detecting plagiarized documents in Hindi language which was
reused from English language source documents. We proposed three ap-
proaches using classification and key-phrase retrieval techniques. Our
winning approach attained 0.792 F-measure.
1 Introduction
Growing information on the web in different languages provide many options for
people searching for content. Sometimes similarity between content is observed
due to myriad reasons. But reuse or plagiarism of text can be biggest concern for
the original publishers. Lot of content on web in the form of text is sometimes
re-written in to different languages from source English documents without any
acknowledgment. Text reuse can be at various granularities. It can be a direct
copying of phrases, paragraphs or complete document.
Challenge here is to identify granularity at which document was plagiarized.
Imagining the size of web, it is a tedious task to identify the plagiarized text man-
ually. Thus, systems which can detect text reuse automatically come to rescue.
We submitted three runs in FIRE CL!TR 2011 task to solve above mentioned
problems. In this paper, we present approaches used for runs which can automat-
ically detect the plagiarized documents in Hindi language that are copied from
English language source documents. Our third approach which secured first rank
in the task differ from other approaches [2] on the following points.
 This work is partially funded by the European Commission as part of the WIQEI
IRSES project (grant no. 269180) within the FP 7 Marie Curie People Framework.
1 http://www.isical.ac.in/~fire/2011/index.html
2 http://users.dsic.upv.es/grupos/nle/fire-workshop-clitr.html
P. Majumder et al. (Eds.): FIRE 2010 and 2011, LNCS 7536, pp. 71–78, 2013.
c© Springer-Verlag Berlin Heidelberg 2013
72 R. Kothwal and V. Varma
(1) It uses key-phrases instead of n-grams. Key-phrases are considered to be
topics that captures the essence of a document [1].
(2) It uses less feature space, therefore less complex.
Our other two approaches which attained high precision are based on classifica-
tion [3] techniques which maps cross-language documents to possible plagiarized
documents of originals.
Remainder of this paper is organized into following sections. Related work
Section 2 mention about earlier works similar to the task. Next Section 3 discuss
about our approaches using retrieval and classification techniques. Experimen-
tal setup Section 4 give information about the collection used for experiments
and evaluation metrics used to evaluate the system. Experimental results are
explained in Section 5, while result analysis is done in Section 6. Conclusions
and future work is discussed in Section 7.
2 Related Work
Plagiarism detection has been of interest for a long time. In this context, cross-
language plagiarism detection also plays an important role as most of reused text
is found in languages other than English. Martin-Potthast.et.al [4] approach use
a comprehensive retrieval process and large-scale evaluation models to measure
cross-language text similarity. Similar approach in [5] represented common text
with a set of features that denotes its relevance and fragmentation with con-
junction to supervised learning algorithms. Another approach [6] used a moving
window of four word sequence and chunk ratio for identifying plagiarism pas-
sages. This approach work at finer grain level of a document than aforementioned
approaches. Alberto-Barron-Cedeno.et.al [7] detected plagiarism across distant
language pairs using machine translation and monolingual similarity measure.
Some other approaches achieved external plagiarism detection [8] by comparing
different similarity measures.
In this paper, we proposed a new approach which use automatically extracted
key-phrases from documents [1] to identify the plagiarized documents in Hindi
language having source language as English.
3 Approach
Most of the earlier approaches concentrated on detecting plagiarized documents
where source and target documents share common language. Task proposed in
FIRE CL!TR 2011 aim in detecting plagiarized documents in cross-language
where suspicious documents are present in Hindi, while source documents are
in English. Major challenge here is projection of source language documents
to target language. This inherently creates a dependency on translation systems
which can efficiently project. But, resource scarce languages like Hindi lack state-
of-art machine translation systems which can project entire document to English
effectively.
Cross Lingual Text Reuse Detection Based on Keyphrase Extraction 73
In-order to solve above mentioned problems, we designed different approaches
mentioned below.
3.1 Classification Based Approach with Stemming (Approach 1)
Our first approach treats plagiarism detection task as a classification problem.
Word features are extracted from translated Hindi documents to build a training
model. Before finalizing the word features, they are stemmed to reduce the re-
dundant words and also to reduce the dimensionality of feature vector. Features
are weighed using cosine similarity between the translated Hindi documents and
source English documents. Final features are then used to build a model using
J48 Decision tree classifier [9]. Built model is applied on the test set of Hindi doc-
uments to detect the possible plagiarized documents. If a document gives a classi-
fication error below a certain threshold, it is considered as plagiarized document.
3.2 Classification Based Approach without Stemming (Approach 2)
Our second approach also treats plagiarism detection task as a classification
problem. Approach is similar to method mentioned in Section 3.1, but without
stemming of words. Also, it differs from earlier approach in weighing features. It
calculates the relevance score [5], length and quantity of the word sequences of
unigram features.
3.3 Cross-Lingual Key-Phrase Mapping (Approach 3)
Key-phrases in documents are used for various tasks such as document classifica-
tion [10], clustering [11] and summarization [12]. In our third approach, we use key-
phrases to detect cross-language plagiarized documents. Initially, pre-processed is
done on English documents to eliminate junk characters and stop words. Remain-
ingwords are converted to lowercasing tominimize the redundancy.Now to extract
key-phrases, n-gram filtration and term weighing scheme [1] is used.
N-gram filtration technique extracts n-grams using data compression tech-
niques which uses simple refinements and pattern filtration algorithms. To for-
mulate n-gram list, LZ78 [13,14] a data compression technique is used with
minor modifications. Words are used in place of characters and spaces are used
as delimiter between words. But all n-grams extracted cannot be key-phrases
like regular verbs 3. Such n-grams are removed to form new n-grams list. In-
order to calculate the weight of possible key-phrases from new n-gram lists, we
borrow an idea from earlier approaches which states that position of phrase in
document can influence its importance. So, for weighing a phrase importance
is given to phrase position in the sentence and document. Apparently, count of
n-grams differ as we vary value of “n“. In-order to reduce the bias of n-gram
counts on weighing, we employ a strategy which treats each n-gram differently
for key-phrase extraction.
3 http://englishclub.com
74 R. Kothwal and V. Varma
Key-phrases are extracted from suspicious Hindi documents after translation
into English language using Google Translation API4. Key-phrases are then used
to query using pre-created index of source English documents using Nutch5.
Each key-phrase of translated and plagiarized Hindi document return source
English documents. For all the key-phrases in a translated Hindi document,
we get N possible unique documents of source English document. All translated
Hindi documents mapping to the retrieved source English documents are termed
plagiarized. Figure 1 depicts the approach.
Fig. 1. Cross-lingual key-phrase mapping
4 Experimental Setup
For cross-language plagiarism task, we need a set of potential source language
documents and set of suspicious target language documents. Section 4.1 show
the collection used, while section 4.2 explains the evaluation metrics followed to
evaluate the system.
4.1 Collection
Table 1 and Table 2 show the train and test collection used for experiments.
Collection contains a plain text files encoded in UTF-8. The source documents
are taken from English Wikipedia6 which also include Wiki-mark up.
4 https://developers.google.com/translate/
5 http://nutch.apache.org/
6 http://www.wikipedia.org/
Cross Lingual Text Reuse Detection Based on Keyphrase Extraction 75
Table 1. Training Data
Training Data
Source Suspicious
English 5032 -
Hindi - 198
Table 2. Testing Data
Testing Data
Source Suspicious
English 5032 -
Hindi - 190
4.2 Evaluation
Evaluation of the system which detects cross-language text-reuse is measured in
terms of Precision (P), Recall (R), and F-measure (F). Identifying the correct
re-used documents with its corresponding source document give the performance
of the system. Some of the parameters on which evaluation is done is listed below.
(1) total detected to be the set of suspicious-source pairs detected by the system.
(2) correctly detected to be the subset of pairs detected by the system which
actually compose cases of re-use.
(3) total re-used to be the gold standard, which includes all those pairs which
compose actual re-used cases.
So P, R and F are defined following equations.
P =
correctly − detected
total − deteted (1)
R =
correctly − detected
total − re − used (2)
F −measure = 2 ∗R ∗ P
P +R
(3)
5 Experiments
Experiments were conducted using the collection mentioned in Section 4.1. Our
aim is to identify the set of suspicious documents in Hindi from English source
documents. Before applying our approaches, target Hindi documents of training
and testing are translated to English.
5.1 Approach 1
To find the plagiarized documents, we built a model on both training and testing
collection using J48 classifier with Weka7 as mentioned in section 3.1. When a
7 http://www.cs.waikato.ac.nz/ml/weka/
76 R. Kothwal and V. Varma
trained model of training data applied on translated Hindi collection of training
data, we found 130 documents are classified as positive cases of text re-use and
68 documents as negative cases of text re-use. Similar experiment was performed
on trained model of test data. It was found that classifier correctly identified 117
documents as re-used out of 190 in Hindi collection of test data. This approach
ranked sixth in the task.
5.2 Approach 2
To find the plagiarized documents, we built a model on both training and testing
collection using J48 classifier with Weka as mentioned in section 3.2. When a
trained model of training data applied on translated Hindi collection of training
data, we found 130 documents are classified as positive cases of text re-use and
68 documents as negative cases of text re-use. Similar experiment was performed
on trained model of test data. It was found that classifier correctly identified 125
documents as re-used out of 190 in Hindi collection of test data. This approach
ranked third in the task.
5.3 Approach 3
To find the plagiarized documents, we followed an approach mentioned in sec-
tion 3.3 on testing data. Initially indexed documents of English collection of
testing data is used to query key-phrases extracted from translated Hindi doc-
uments. We kept a minimum threshold frequency score that dictates number of
times a document appears for key-phrases taken from single translated Hindi
document to label the document plagiarized. During experimentation it was
found that frequency score of 31 holds good to achieve better accuracies. Out of
possible 190 suspicious translated Hindi documents, our approach identified 147
documents as re-used. This approach ranked first in the task.
Below we compare Precision, Recall and F-measure of our approaches with
other teams participated in the task. Table 3 show the results.
6 Result Analysis
From the table 3 it can be observed that even though our approach in Run 3
have high F-measure, it falls behind 26.7% and 7.6% on precision and recall
on best results respectively. This can be attributed to the algorithm of our
approach which maintained equal balance of recall and precision. While other
best performing approaches concentrated on either recall or precision. When we
compare our three runs, it is observed that Run 1 attained high precision and
beatsRun 3 by 3.92%.Run 1 was able to achieve best precision due to efficiency
of classification algorithm in plagiarized documents with less error. But, it lacks
recall as it was not able to map all possible results in the collection. Run 3 was
able to achieve good recall due to better ability of key-phrases in distinguishing
documents than normal n-grams. Approach 3 was tested with different frequency
score thresholds to obtain best threshold. Table 4 lists the observations made.
Cross Lingual Text Reuse Detection Based on Keyphrase Extraction 77
Table 3. Results Comparison among Teams for CL!TR Task
Comparison among Teams for CL!TR Task
Team Run Precision Recall F-measure Rank
IIIT Hyderabad 1 0.820 0.657 0.730 6
IIIT Hyderabad 2 0.816 0.699 0.753 3
IIIT Hyderabad 3 0.789 0.795 0.792 1
Zhytomyr State University / SkyLine Inc. 1 0.907 0.664 0.767 2
Zhytomyr State University / SkyLine Inc. 2 1.000 0.575 0.730 7
Zhytomyr State University / SkyLine Inc. 3 0.853 0.596 0.702 9
DERI Galway and UPM Madrid 1 0.658 0.856 0.744 4
DERI Galway and UPM Madrid 2 0.642 0.836 0.726 8
UPV & DA-IICT 1 0.521 0.678 0.589 11
UPV & DA-IICT 2 0.653 0.849 0.738 5
UPV & DA-IICT 3 0.652 0.692 0.671 10
Jadavpur University 1 0.145 0.171 0.157 14
Jadavpur University 2 0.434 0.315 0.365 12
Jadavpur University 3 0.434 0.315 0.365 13
Hong Kong University of science and technology 1 0.000 0.000 0.000 15
Table 4. Comparison of Frequency Scores
Comparison of Frequency Scores
Threshold Precision Recall F-measure
28 0.761 0.808 0.784
29 0.776 0.808 0.792
30 0.785 0.801 0.793
31 0.789 0.795 0.792
32 0.791 0.780 0.786
33 0.850 0.780 0.814
34 0.856 0.773 0.813
35 0.850 0.739 0.791
7 Conclusion and Future Work
In this paper, we present different approaches to detect suspicious documents in
cross-language which are plagiarized from source language English documents.
Our winning approach differed from other proposed approaches in using key-
phrases instead of n-grams. Other approaches used by us are based on text
classification algorithms which ranked third and sixth. Future work involves
semantic analysis of the text to further improve F-measure.
Acknowledgement. We would like to thank Srikanth Reddy Vaddepally and
Aditya Mogadala for their constant help and discussions in improving the quality
and presentation of the paper.
78 R. Kothwal and V. Varma
References
1. Kumar, N., Srinathan, K.: Automatic Keyphrase Extraction from Scientific Docu-
ments Using N-gram Filtartion Technique. In: ACM DocEng. (2008)
2. Stamatatos, E.: Intrinsic plagiarism detection using character n-gram profiles.
Threshold 2, 1–500 (2009)
3. Lukashenko, R., Graudina, V., Grundspenkis, J.: Computer-based plagiarism de-
tection methods and tools: an overview. In: International Conference on Computer
Systems and Technologies (2007)
4. Potthast, M., Barron-Cedeno, A., Stein, B., Rosso, P.: Cross-language Plagiarism
Detection. Springer Science+Business Media B.V. (2010)
5. Sánchez-Vega, F., Villaseñor-Pineda, L., Montes-y-Gómez, M., Rosso, P.: Towards
Document Plagiarism Detection based on the Relevance and Fragmentation of the
Reused Text. In: Sidorov, G., Hernández Aguirre, A., Reyes Garćıa, C.A. (eds.)
MICAI 2010, Part I. LNCS, vol. 6437, pp. 24–31. Springer, Heidelberg (2010)
6. Devi, S.L., Rao, P.R.K., Ram, V.S., Akilandeshwari, A.: External Plagiarism De-
tection. Lab Report for PAN at CLEF (2010)
7. Cedeno, A.B., Rosso, P., Agirre, E., Labaka, G.: Plagiarism Detection across Dis-
tant Language Pairs. In: Proceedings of the 23rd International Conference on Com-
putational Linguistics (2010)
8. Hoad, T.C., Zobel, J.: Methods for identifying versioned and plagiarized docu-
ments. Journal of the American Society for Information Science and Technology
(JASIST) 54(3), 203–215 (2003)
9. Rozinat, A., van der Aalst, W.M.P.: Decision mining in proM. In: Dustdar, S., Fi-
adeiro, J.L., Sheth, A.P. (eds.) BPM 2006. LNCS, vol. 4102, pp. 420–425. Springer,
Heidelberg (2006)
10. Karanikolas, N.N., Skourlas, C.: Key-phrase extraction for classification. In: Medi-
con and Health Telematics: X Mediterranean Conference on Medical and Biological
Engineering (2004)
11. Zhang, D., Dong, Y.: Semantic, hierarchical, online clustering of web search results.
In: Yu, J.X., Lin, X., Lu, H., Zhang, Y. (eds.) APWeb 2004. LNCS, vol. 3007, pp.
69–78. Springer, Heidelberg (2004)
12. D’Avanzo, E., Magnini, B., Vallin, A.: Keyphrase extraction for summarization
purposes: The LAKE system at DUC-2004. In: Document Understanding Confer-
ence (2004)
13. Sayood, K.: Introduction to Data Compression, 2nd edn. Elsevier (2000)
14. Pu, I.M.: Fundamental data Compression, 1st edn. Elsevier (2006)
