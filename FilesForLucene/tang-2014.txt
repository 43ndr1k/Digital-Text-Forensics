Expert Systems with Applications 41 (2014) 7805–7819Contents lists available at ScienceDirect
Expert Systems with Applications
journal homepage: www.elsevier .com/locate /eswaMining language variation using word using and collocation
characteristicshttp://dx.doi.org/10.1016/j.eswa.2014.05.018
0957-4174/ 2014 Elsevier Ltd. All rights reserved.
⇑ Corresponding author. Tel.: +852 34427756; fax: +852 27887791.
E-mail addresses: ptang@ee.cityu.edu.hk (P. Tang), eetchow@cityu.edu.hk
(T.W.S. Chow).Peng Tang, Tommy W.S. Chow ⇑
Department of Electronic Engineering, City University of Hong Kong, Hong Kong
a r t i c l e i n f o a b s t r a c tArticle history:
Available online 2 June 2014
Keywords:
Language variation
Text mining
Frequency Rank Ratio
Overall IntimacyTwo textual metrics ‘‘Frequency Rank’’ (FR) and ‘‘Intimacy’’ are proposed in this paper to measure the
word using and collocation characteristics which are two important aspects of text style. The FR, derived
from the local index numbers of terms in a sentences ordered by the global frequency of terms, provides
single-term-level information. The Intimacy models relationship between a word and others, i.e. the
closeness a term is to other terms in the same sentence. Two textual features ‘‘Frequency Rank Ratio
(FRR)’’ and ‘‘Overall Intimacy (OI)’’ for capturing language variation are derived by employing the two
proposed textual metrics. Using the derived features, language variation among documents can be
visualized in a text space. Three corpora consisting of documents of diverse topics, genres, regions, and
dates of writing are designed and collected to evaluate the proposed algorithms. Extensive simulations
are conducted to verify the feasibility and performance of our implementation. Both theoretical analyses
based on entropy and the simulations demonstrate the feasibility of our method. We also show the
proposed algorithm can be used for visualizing the closeness of several western languages. Variation of
modern English over time is also recognizable when using our analysis method. Finally, our method is
compared to conventional text classification implementations. The comparative results indicate our
method outperforms the others.
 2014 Elsevier Ltd. All rights reserved.1. Introduction
Different kind of text documents covering diverse topics and
genres are created with the development of Web 2.0 (Chang
Yang & Hong Lee, 2005; Thelwall & Buckley, 2013). The increasing
size and amount of data make text processing more challenging
than before, which requires more effective and efficient
approaches of organization and presentation of huge amount of
texts. In documents retrieval, data items are often organized by
ranking texts according to the users’ queries, or given keywords
(Jansen & Pooch, 2001; Manning, Raghavan, & Schütze, 2008).
The text classification and categorization, from another angle,
measure and classify documents according to the document topics
such as science, business, sports, and genres such as narrative,
argumentative or hybrid texts (Bing Xue & Hua Zhou, 2009).
Besides these classification and categorization methods, drift of
the semantic units in documents, i.e. language variation, leads to
variations in languages, and can be very important clues that
differentiate documents. For example, this type of cues can behelpful in telling whether an article was composed by native
English speakers, or the article is informal or formal. Here, word
using and collocation expressing the vocabulary and word combi-
nations that generate semantic units can be very important clues
that differentiate documents. The language variation delivered by
the two textual characteristics, word using and collocation, differ-
ent from genres or topics, are apparently affected by genre and
topic information of specified documents, as well as the writers.
Previous studies on analyzing topic and genre characteristics
share similar mechanism with our study. The original unstructured
texts cannot be used as training data in empirical Natural Language
Processing. First, training text data are first processed to generate
structured data that machine can understand. Then, useful textural
features are extracted from the preprocessed data. Next, machine
learning approaches, combined with the extracted features, output
trained models to handle users’ requirements. Generally, text pre-
processing techniques treat text documents as a set of arbitrary
tokens which have little meanings or structures. The Term Fre-
quency (TF) and Term Frequency-Inverse Document Frequency
(TF-IDF), are the most important and popular features in text anal-
ysis such as document classifications and clustering. TF-IDF is
applied to most document models like Vector Space Models or
Probabilistic Models (Chowdhury, 2010; Rajan, Ramalingam,
7806 P. Tang, T.W.S. Chow / Expert Systems with Applications 41 (2014) 7805–7819Ganesan, Palanivel, & Palaniappan, 2009). A wide range of docu-
ment analysis methods also rely on TF. Statistical Language Model
(SLM) techniques, for example N-gram (Clement & Sharp, 2003),
have been used in many Natural Language Processing (NLP) appli-
cations, e.g., machine translation, automatic text generation, and
information retrieval (IR).
In extracting appropriate textual features, genre-based
approaches and topic-based measures exhibit similar ideas, in
which features are usually derived from simple term-level statis-
tics of texts. Among most of literatures on document analysis, it
can be found that the features, like TF, TF-IDF, stop words and
length of sentences, are the most widely used. For instance, word
and sentence lengths have been employed in classification of text
genre and authorship detection (Brinegar, 1963; Morton, 1965).
Syntactic and semantic features (Finn & Kushmerick, 2006) have
been used in genre text classification tasks. The POS tagging
(POS) techniques can tag the words with diverse categories, like
pronoun, verb, article, adverbs, corresponding to a particular part
of speech based on its neighboring words in a natural sentence.
Many previous researches have been established with the assis-
tance of POS tagging. N-gram measures cooperating with POS
tagged texts are used to evaluate the influence of syntax structure
on classification results (Clement & Sharp, 2003). For example, POS
tagging texts are utilized to detect genre information in documents
(Kessler, Numberg, & Schütze, 1997). It has been proved that the
POS approach outperforms the conventional TF-IDF features (Finn
& Kushmerick, 2006). The concept of ‘‘style markers’’ are proposed
as a set of measurable patterns in Biber (1995) and be used in
many applications on text analysis. Kessler further categorized dif-
ferent style markers into four generic cues: structural cues, charac-
ter-level cues, lexical cues, and derivative cues (Kessler et al.,
1997). It is usually hoped that the document analysis are able to
handle unrestricted text with low computational cost. Terms of
high-frequency are also considered in document analysis. Using
the TF and TF-IDF of the most frequently used words of a corpus
has been investigated (Stamatatos, Fakotakis, & Kokkinakis, 2000;
van Halteren, Tweedie, & Baayen, 1996). These studies indicate
that the high frequency words are reliable discriminators for text
analysis task. Textual features with deep structure and sematic
meanings are also studied. For example, hierarchical concept dic-
tionaries are employed to recognize and classify topics of docu-
ment collections (Gelbukh, Sidorov, & Guzmán-Arenas, 1999).
Ontology-based knowledge base is also proved efficient for capture
text characteristics (Kitamura & Mizoguchi, 2003; Shing Lee, Juan
Chen, & Wei Jian, 2003). The proximity-based information between
words is also utilized to yield extra features. For example, Petkova
and Croft propose a document representation model using the
proximity between occurrences of entities and terms (Petkova &
Croft, 2007). Neuhaus and Bunke used edit distance based string
kernel to extract textual structural features (Neuhaus & Bunke,
2006). Lv and Zhai raised a so-called Positional Language Model
using the proximity information among words, then use this model
to propagate the word count (Lv & Zhai, 2009). There is a belief that
authors can be an important factor in affecting results of docu-
ments analysis. Some research work has been done to identify
the authorship of documents collections. Style markers are used
in an authorship-based classification task, and a 50% or above accu-
racy has been reported when a 10-author corpus are processed
(Stamatatos et al., 2000). Character-level n-gram features for
authorship detection are also raised to deal with both western
and Chinese texts, which deliver an overall accuracy about 75%
(Peng, Schuurmans, Wang, & Keselj, 2003).
Machine learning approaches output trained models, using the
extracted features, to meet users’ requirements. Existing machine
learning techniques, such as Naive Bayesian (Bum Kim, Soo Han,
Chang Rim, & Hyon Myaeng, 2006), k-nearest neighbor (k-NN)(Han, Karypis, & Kumar, 2001; Tan, 2005), neural networks (NN)
(Li, Song, & Park, 2009; Ou & Murphey, 2007; Rajan et al., 2009),
genetic algorithms (Song, Li, & Park, 2009), and support vector
machine (SVM) (Joachims, 1999b), deliver reasonable results.
Unsupervised feature discretization and feature selection algo-
rithms for feature reduction in documents are implemented in
Ferreira and Figueiredo (2012), Shang et al. (2007) and Ogura,
Amano, and Kondo (2009). A supervised feature selection approach
based on conditional mutual information is also explored in text
clustering (Martínez Sotoca & Pla, 2010). Peng et al. also Naive
Bayes classifier and n-gram language models to conduct text clas-
sification (Peng, Schuurmans, & Wang, 2004). Self-organizing Map
(SOM) are also utilized in document clustering (Corrêa & Ludermir,
2008). Joachims also use SVM to improve the performance of doc-
ument classification (Joachims, 1999a).
The above reviewed approaches are able to output promising
results on topic-based and genre-based analysis. Dealing with lan-
guage variation in documents, as mentioned previously, however,
differs from the topic-based and genre-based document classifica-
tion. It is clear that generic and topic-based textual features are not
accurate in describing the language variation cues in documents.
Previous studies on such characteristic extraction highly rely on
TF with respects to term occurrence and co-occurrence in a corpus.
Seretan used syntactic patterns to recognize word collocations in
different languages. This approach takes advantages of the recent
advance in natural language parsing tools aiming to construct deep
syntactic structures of texts (Seretan, 2010). An approach for
selecting multi-word collocation candidates based on the syntacti-
cal bound collocation bigrams and patterns is also proposed in
Seretan, Nerima, and Wehrli (2003). A set of diverse extension
patterns are also defined using n-gram POS-tagged patterns for
selecting word collocations (Petrović, Šnajder, & Bašić, 2010).
The conventional TF and TF-IDF are important single-term fea-
tures for text mining and information retrieval. High frequency
words, usually referring to function words and stop words, can
be effective style markers for extracting word using characteristics
of document genres. But in most topic and content classification
studies, the high frequency words are excluded from bags of
words; otherwise they can overshadow meaningful words due to
their huge proportion. In addition, certain meaningless words usu-
ally count most in the whole document, while the most meaningful
words usually occupy a relatively small proportion (Manning &
Schütze, 1999). The language variation can then be impacted by
both the topics and genres of documents. Hence the improve-
ments, which can make the best of high-frequency terms and at
the same time to balance high and low frequency words, are thus
needed to be designed. In this study, to balance the high and low
frequency words and avoid the sparsity problem caused by the
low frequency words, we introduce a textual metric named Fre-
quency Rank (FR). FR can deliver single-term-level information of
documents, as well as balance the high and low frequency words.
Most of existing implementations for obtaining higher textual
features other than single-term features heavily rely on n-gram
features with POS taggers can deliver reliable grammatical or syn-
tactic information. N-gram models are built on a basis that one
word depends only on its last n 1 words while is independent
from the rest of the words. This assumption significantly alleviates
the computational problem of calculating all tokens in long
sequences (Wikipedia, 2011). However, in practical applications,
the value of n is usually set to less than 4, otherwise the computa-
tional demanding would become unbearably high. A small value of
n means the relations between distant words are missing. Hence it
limits the ability of extract inter-term level statistics, which is a
major drawback for n-grams aiming to capture inter-term-level
features. In this paper, Intimacy is introduced to measure popular-
ity discriminating compatibility of a word and its neighbors, and its
P. Tang, T.W.S. Chow / Expert Systems with Applications 41 (2014) 7805–7819 7807neighbors neighbors, etc., namely, its environment. Our algorithm
models the associations of words by using all the word pairs of
sentences. Therefore, the information overlooked by n-gram fea-
tures is taken into account in our methods.
We in this study mainly focus on extracting two characteristics
for analyzing language variation: inter-term-level and single-term-
level characteristics. Two textual metrics ‘‘Frequency Rank’’ (FR)
and ‘‘Intimacy’’ are proposed to measure the word-using and
word-collocation information, respectively. The FR, derived from
the local index numbers of terms in a sentences ordered by the glo-
bal frequency of terms, provides single-term-level information.
The Intimacy models relationship between a word and others, i.e.
the closeness of a word is to other words in the same sentence.
Two textual features ‘‘Frequency Rank Ratio (FRR)’’ and ‘‘Overall
Intimacy (OI)’’ for extracting language variation are derived by
employing the two proposed textual metrics. The original unstruc-
tured texts are firstly split into pieces of a pre-set length (namely,
slices with n sentences). Subsequently, textural features are
extracted by using our two proposed metrics and comparing to
the baseline. Different from the conventional n-gram approaches
that only concern adjacent terms, the calculation of Intimacy
involves the neighbors, the neighbors’ neighbors of a given term.
Thus, Intimacy delivers more accurate useful word collocation
information. The slices of documents can be easily visualized in a
text space with the assistant of the two textual features FRR and
OI. The simulation results are promising as illustrated in later sec-
tions. The entropy based analysis proves that more information can
be obtained using our method compare to the conventional n-gram
features. Our extensive simulation results also suggest that the size
of the training corpora are not necessarily large. Also, the classifi-
cation results do not vary much when the training corpora are
altered. Therefore, a small training corpus can always be used to
conduct the text characteristics analysis. This brings benefit that
the time complexity of our method is significantly reduced com-
pared to other approaches. The computational complexity of our
algorithm is further reduced because of the exclusion of syntactic
and semantic information based textual features. The simulation
results prove that the proposed method can recognize the differ-
ence caused by the language variation among documents of the
same genre. Further, the experimental result indicates that the
proposed algorithm can differentiate the western languages under
the circumstance that the semantic and syntactic information is
hidden. Variation of modern English over time is also recognizable
when using our analysis method. Our method is also compared to
conventional text classification implementations. The comparative
results indicate our method outperforms the others.
The FR can balance the high and low frequency words and avoid
the sparsity problem caused by the low frequency words. And the
FRR, derived by using FR, can deliver more effective single-term-
level information of documents than the conventional textual fea-
tures for analyzing language variation. Meanwhile, our algorithm
for measuring connections between words models the associations
of words by using all the word pairs of sentences. Therefore, the
information abandoned by traditional methods is taken into
account in our proposed textual feature OI, and the hidden lan-
guage variations among words can be captured.
This paper is organized as follows. In Section 2, two metrics Fre-
quency Rank and Intimacy for recognizing word using and colloca-
tion characteristics are elaborated. In Section 3, entropy based
analysis on the two proposed metrics proves that the two metrics
can capture more uncertainty than conventional popular n-gram
based features. In Section 4, the calculation of two textual features
Frequency Rank Ratio and Overall Intimacy is detailed. The begin-
ning of Section 5 addresses the simulation settings. Consequently,
a group of intuitive visualization results is given in Section 5. The
impacts of parameters in our implementation are illustrated aswell. Language variation existing in different scenarios, i.e. differ-
ent genres, topics, regions, dates of writings are all extracted and
displayed in figures. Finally our method is compared with others.
We conclude this paper in Section 6.
2. Metrics for recognizing word using and collocation cues
Our reading experience often tells us that (1) vocabulary that
construct complete documents, i.e. the word-using, and (2) rela-
tionship among words, i.e. the word-collocation, separate different
types of documents. In the rest of this paper, we will elaborate our
method using only the two features to output promising results.
In this section, we introduce two new metrics, namely, Fre-
quency Rank (FR) which measures the vocabulary statistics using
local ranking index of each word, and Intimacy which represents
association among words of documents. Here, the FR and Intimacy
are derived for extracting the single-term and inter-term statistics
of given documents, respectively. The proposed textual features
which will be described later are based on these two metrics.
The mechanisms of the two metrics are detailed in the following.
2.1. Frequency Rank
TF and TF-IDF in documents are important features for text clas-
sification, clustering and information retrieval. High frequency
words, usually referring to function words and stop words, can be
effective style markers for genre based classification. In most topic
and content classification studies, however, the high frequency
words are excluded from bags of words; otherwise they can over-
shadow meaningful words, due to their huge proportion. Due to
the power-law distribution of word frequency, certain meaningless
words, such as IS/A/THE/OF, count most in the whole document,
while the most meaningful words usually occupy a relatively small
proportion. For instance, ‘‘THE/A’’ appears in 200,000 times and
10,000 times in corpora, respectively, while the meaningful phrase
‘‘DATA MINING’’ appears only 2 times. This phenomenon is often
referred as Zipf’s law (Manning & Schütze, 1999).
To make the best of high-frequency terms and at the same time
to balance high and low frequency words and avoid the sparsity
problem caused by the low frequency words, we introduce a tex-
tual metric named Frequency Rank (FR). The ‘‘action scope’’ of FR
can be adjusted from a single sentence to a paragraph, one page,
or even a whole chapter or book. In this paper, we confine the
‘‘action scope’’ to every sentence. FR of a word in a sentence is
defined as the index of each word that indicates the presence of
the corresponding words in the sorted word list by their global
TF. The global TF here refers to the TF in given training corpus,
i.e., we tune the weight of each words. For example, we attempt
to obtain FRs of each word in the short sentence ‘‘The pen is on
the desk.’’. The global TF values are bracketed after each word. In
our study, punctuations are considered as words in our study, thus
have corresponding FR values.
Myð960Þ penð15Þ isð5734Þ onð2320Þ yourð534Þ deskð6Þ :ð3479Þ
By ascending reorder words using the global TF, we obtain
deskð6Þ penð15Þ yourð534Þ myð960Þ onð2320Þ :ð3479Þ isð5734Þ
1 2 3 4 5 6 7
The index number of each word is the FR value. The FR of each
word is
Myð4Þ penð2Þ isð7Þ onð5Þ yourð3Þ deskð1Þ :ð6Þ
The FR is capable to evaluate local ‘‘popularity’’ of terms in cor-
pora. Another advantage of FR is that the FR values are positive
integers, which is preferable in computational stages.
7808 P. Tang, T.W.S. Chow / Expert Systems with Applications 41 (2014) 7805–7819Generally, a sentence is denoted S ¼ fw1;w2;w3; . . . ;wng, where
w1; . . . ;wn are n tokens in the given sentence. A Normalized FR
(NFR) is defined as:
NFRðwi; SÞ ¼
FRðwiÞ
maxwj2SðFRðwjÞÞ
; ð1Þ
where wi and wj are an arbitrary tokens in sentence S. It can be eas-
ily observe that the value of NFRðwi; SÞ is always between 0 and 1.
2.2. Intimacy
FR provides single-term-level information of documents. FR can
balance the high and low frequency words, however, like most of
conventional single term based text characteristics, it only consid-
ers the whole texts as ‘‘bags of words’’, in which most inter-term
associations are abandoned. In this section, we describe our
attempt to design a new type of metric aiming to mine inter-
term-level connections, by using which the higher level textual fea-
tures, e.g. sentence-level, paragraph-level can be derived. There
have been many implementations for obtaining higher textual fea-
tures other than single-term-level features. For example, n-gram
language model with POS features can deliver reliable grammatical
or syntactic information. Some other complex methodologies are
also proposed, including maximum entropy based approaches
(Ratnaparkhi et al., 1996) and Bayesian theory based methods
(Goldwater & Griffiths, 2007). Intimacy is introduced to measure
popularity discriminating compatibility of a word and its neighbors,
and its neighbors’ neighbors, etc., namely, its environment. For
example, one type of disorder in English such as ‘‘a plastic white
toy’’ (should be ‘‘a white plastic toy’’) can be recognized by English
speakers easily, because the combination ‘‘plastic white’’ is unusual
according to our reading experience. In such a scenario, POS fea-
tures is not capable to spot these discrepancies because both
‘‘white’’ and ‘‘plastic’’ are adjectives. Another example is that when
proficient readers reading a text document, they are able to tell
whether it is composed by sophisticated English or naive English
writers, or classify whether it is written in formal or informal style.
N-gram models which calculate the probability of item when
given n 1 items ahead of the item, i.e., it calculate
Pðxijxiðn1Þ; . . . ; xi1Þ of xi based on xiðn1Þ; . . . ; xi1. N-gram models
are built on a basis that one word depends only on its last ‘‘n 1’’
words. This assumption significantly alleviates the computational
problem of calculating all tokens in long sequences (Wikipedia,
2011). n-gram models are popular and widely used in NLP areas.
In practical applications, however, the value of n is usually set to
less than 4, otherwise the computational demanding would
become unbearably high. A small value of ‘‘n’’ limits the ability of
extract inter-term level statistics, which is a major drawback for
n-grams aiming to capture inter-term-level features.
The idea of Intimacy is based on a simple assumption that
occurrence of a word can affect its environment, i.e. its neighbors,
and the neighbors of its neighbors. Previously studies also use sim-
ilar idea for evaluate connections among words (Lv & Zhai, 2009;
Petkova & Croft, 2007). Different from those methods, our algo-
rithm models the associations of given documents on bases of
weighted word pairs. Here, the weight of word pair refers to the
closeness between the two terms of the word pairs. The weight
is estimated using a concept named cumulative influence (CI)
which is also applied as proximity-based kernels (Lv & Zhai,
2009; Petkova & Croft, 2007). The influence of a term pair is rele-
vant to the distance between the two terms. The shorter distance
between the two terms, the larger influence they have; conversely,
the longer the distance between a given term pair, the weaker
influence is. We use pðwi;wj; SÞ to denote the influence of two
words wi and wj in a sentence S. The influence pðwi;wj; SÞ varies
with the influence function dðxÞ, which is a similar concept tostring kernel (Lv & Zhai, 2009). The influence decreases with
defined functions, such as Gaussian, or simply linear. In this paper,
the decreasing rate is assumed to be Gaussian, because Gaussian
function ensures every term of a long sentence receives a non-zero
influence factor, whereas polynomial and linear functions will deli-
ver zero influence factor at a finite distance.
It is assumed that the influence is accumulative. For instance,
given a sentence
\að1Þ bigramð2Þ isð3Þ að4Þ sequenceð5Þ of ð6Þ twoð7Þ itemsð8Þ
fromð9Þ að10Þ givenð11Þ sequenceð12Þ:"
Each bracketed number is the corresponding index of the word.
We assume that a word affects its direct neighbor with an influ-
ence factor 1.0, the next one with 0.9, and the further next one with
0.8, and so on. For example, the influence between the 4th term ‘‘a’’
and the 5th term ‘‘sequence’’ is 1.0, while the interaction between
10th term ‘‘a’’ and 12th terms ‘‘sequence’’ is 0.9. As a result, the
cumulative influence of the term pair ‘‘a’’ and ‘‘sequence’’ is 1.9.
It must be noted that the above approach is not strictly probabilis-
tically defined. But using the above method, the word combina-
tional information can be effectively collected.
To elaborate the feature Intimacy, we introduce the cumulative
influence (CI) C between word pairs. First, we introduce the concept
of Intimacy. For a given sentence Sc; C can be yielded by (2) and (3).
In (2), + means to get C between 2 particular words w and w0 when w0
appears after w; in (3),  means w0 occurs ahead of w.
Cþðw;w0Þ ¼
Xs
c¼1
X
i<j
wi ;wj2Sc
dði jÞ: ð2Þ
Cþðw;w0Þ ¼
Xs
c¼1
X
i>j
wi ;wj2Sc
dði jÞ: ð3Þ
Here, dðxÞ is a function representing the decreasing of the influ-
ence between the two words as the above mentioned, where x is
the distance between two words. The i; j are the index numbers
of word wi; wj, respectively. Note that C is not statistically defined.
Therefore, C can be larger than 1. In the above definition, C can col-
lect relationship between word pairs more effectively than n-gram.
We can observe that C considers not only the direct neighborhood
of a word, the CI can thus take the occurrence of all the words
appeared in a sentence into account. Note that C for all words
can be calculated and stored in another lexicon for further use.
In most cases, the dðxÞ is defined as an axisymmetrical function.
Hence, Cþðw;w0Þ ¼ Cðw;w0Þ.
For nðn > 2Þ words w1;w2; . . . ;wn, we defined Cðw1;w2; . . . ;wnÞ
as:
Cðw1;w2;w3Þ ¼
XS
c¼1
X
i<j<k
wi ;wj ;wk2Sc
wi¼w1 ;wj¼w2 ;
wk¼w3
dði jÞ  dðj kÞ
Cðw1;w2;w3;w4Þ
¼
XS
c¼1
X
i<j<k<l
wi ;wj ;wk ;wl2Sc
wi¼w1 ;wj¼w2 ;
wk¼w3 ;wl¼w4
dði jÞ  dðj kÞ  dðk lÞ
..
.
Cðw1;w2; . . . ;wnÞ ¼
XS
c¼1
X
n1<...<nn
wn1 ;wn2 2Sc
wn1 ¼w1 ;...;
wnn ¼wn ;
Yn1
i¼1
dðni  niþ1Þ
8>>>>>>>>>>>><
>>>>>>>>>>>>>:
ð4Þ
Bayes’ theorem is a popular tool in document classification and
other classification area. For events A and B, provided that PðBÞ – 0.
PðAjBÞ ¼ PðBjAÞPðAÞ
PðBÞ : ð5Þ
P. Tang, T.W.S. Chow / Expert Systems with Applications 41 (2014) 7805–7819 7809Inspired by Bayes’ theorem and n-gram model, we can express
the Intimacy of a sentence Si as
IðSiÞ ¼
Xn
i¼1
Xn
j¼1
Cðwi;wjÞpðwjÞ
pðwiÞ
; ð6Þ
where PðwijwjÞ in the Bayes’ theorem is replaced by Cðwi;wjÞ. In (6),
only word pairs are considered in calculating of Intimacy. The local
Cþ and C is calculated, which means only words in specified action
scope, such as in a sentence scope and in a passage scope, is consid-
ered. They are subsequently compared with the previous lexicon,
and the difference will be sorted. The smaller the differences,
the more intimate the words within the specified area are. Here the
training corpus is considered sophisticated and regarded as the
‘‘ruler’’. We must explain that all the above described features
are not statistically defined. Strictly speaking, Intimacy, inspired
by the Bayes’ theorem, is empirical defined. It is worth noting that
the computational complexity for calculating FR is Oðn log nÞ when
quick sort algorithm is utilized. The time complexity for intimacies
is Oðn2Þ, where n is the word count of the sentence. The value of n is
usually set to 3 to 20 which is far less than the total numbers of
words used in a given document. This explains why our feature
extraction algorithm is fast.
Sparsity of words is due to words appeared only once or twice
in a corpus. The sparsity of words in language models is always
problematic, which often needs smoothing techniques to solve
the zero probability terms. In this study, we use an effective pre-
processing method mentioned in previous text to minimize the
issue. Low frequent words are merged to a special term acting as
a placeholder. In other words, low frequent words are regarded
as the same term when Intimacy is calculated. Extreme individual
that still appears as a zero-probability item in the trained lexicon
will be abandoned directly. Using this method, the sparsity of
words can be solved without using smoothing technique. Our pre-
sented simulation results corroborate that improved classification
accuracy is obtained by using this approach.
3. Textual metric analysis based on entropy
In this section, we use entropy to prove that our CI is capable to
extract more uncertainty of sentences compared with other n-
gram based approaches.
In information theory, entropy is a measure of uncertainty in a
random variable that can evaluate information content of docu-
ments. Generally, let S ¼ fs1; s2; . . . ; sng be an n-sentence slice of a
document. The vocabulary V ¼ fv1;v2;v3 . . . ;v jV jg is the vocabu-
lary that constructs the document. An arbitrary sentence ti is
denoted by a sequence of words fw1;w2;w3; . . . ;wng where n is
the length of the sentence ti. Word collocations starting with the
word wi examined in a sentence is represented by fðwi;wiþ1Þ;
ðwi;wiþ2Þ; ðwi;wiþ3Þ; . . . ; ðwi;wiþLÞg, where L is the length of colloca-
tion window.
Let Nðv i;v jÞ be the number of term pairs with the first word v i
and the second word v j. The probability that the word v j occurs as
the second word given v i as the first word is
pðv jjv iÞ ¼
pðv i;v jÞ
pðv iÞ
¼ pðv i;v jÞPj¼jVi j
j¼1 pðv i;v jÞ
¼ Nðv i;v jÞPj¼jVi j
j¼1 Nðv i;v jÞ
; ð7Þ
where jVij is the number of term pairs with Vi as the first word.
By using the conditional entropy, the uncertainty in the occur-
rence of a term as the second word of a collocation given the first
word v i can be expressed as
Hðv i;VJÞ ¼ 
Xj¼jVJ j
j¼1
pðv jjv iÞ ln pðv jjv iÞ; ð8Þ
where jVJj is the number of unique words from the vocabulary in
the collocations with v i as the first word.Using our CI, the Nðv ;v 0Þ is replaced with Cðv ;v 0Þ ¼
P
wi ;wj2sk
dði jÞ, where v ¼ wi;v 0 ¼ w0 and sk 2 S. Because Cðv;v 0ÞP
Nðv ;v 0Þ, substituting N0ðv i;v jÞ ¼ Cðv i;v jÞ into (7), we can obtain
that pðv jjv iÞ decrease. Note that
f ðxÞ ¼ x  ln x: ð9Þ
The function is monotonic decreasing. Subsequently, after
Nðv ;v 0Þ is replaced by Cðv ;v 0Þ; Hðv i;VJÞ will increase.
It can be observed that (7) is the definition of bigram model.
When the length L is set to 2, i.e., only the word collocations that
constructed by two adjacent words are considered. In this scenario,
the CI is transformed to bigram model, i.e. n-gram for n ¼ 2. For an
n-gram model (n > 2), given v1;v2; . . . ;vn1 as the first, second, . . .
and ðn 1Þth words, respectively, the probability that the word vn
occur as the nth words is
Pðvnjvn11 Þ ¼
Pðvn11 vnÞ
Pðvn11 Þ
¼ Nðv
n1
1 vnÞ
Nðvn11 Þ
¼ Nðv
n1
1 vnÞPn¼jVn j
n¼1 Nðvn11 vnÞ
: ð10Þ
The conditional entropy can be expressed as
Hðvn11 ;VNÞ ¼ 
Xn¼jVN j
n¼1
pðvnjvn11 Þ ln pðvnjvn11 Þ:
Similar to bigram, for an n-gram model, Cðvn11 ;vnÞ ¼ C
ðv1;v2; . . . ;vnÞ is always no less than Nðvn11 ; vnÞ according to (6).
By substituting Nðvn11 ; vnÞ with Cðvn11 ;vnÞ into (10), Pðvnjvn11 Þ
will decrease. Consequently, Hðvn11 ;VNÞ will increase.
The above derived results prove that we will obtain a larger
value H when using our CI, which results in extracting more
information from the text, which means more distinct word-
collocations will be scanned by using our CI.
4. Textual feature extraction
In this section, we design two textual features, namely
Frequency Rank Ratio (FRR) and Overall Intimacy (OI), by employing
the above two text metrics FR and Intimacy elaborated in Section 2.
A ‘‘Baseline’’ is prepared in the calculation procedures of extracting
features. Our algorithm is language-independent, in which deep
level features such as semantic structures are unknown, the
manual defined grammatical and semantic rules are ignored. The
proposed approach can handle unrestricted text.
4.1. Text preprocessing
All tokens, including stop words, punctuations, function word
and meaningful terms, are preserved for calculating the textual
features in our implementation. Note that the ‘‘stemming’’ technol-
ogy, which maps derived words to their root form (e.g. doing, done,
did are all stemmed to do), usually employed in NLP applications,
are not adopted in our implementation. That is to say, plural or sin-
gular forms of nouns and tenses of verbs, etc. are preserved in our
algorithm. In most cases, the given derived forms of terms reflect
the word-collocation characteristics, while the ‘‘stemming’’ reveals
original forms of tokens from their given forms in the original
texts, which might drop useful information.
Merging low frequency terms to a unified placeholder, as men-
tioned in previous section, shrinks the numbers of low occurrence
frequency terms. This brings an advantage that the computational
cost are significantly cut. Another important improvement by
using the merging strategy is that a large proportion of meaningful
words can be replaced by a placeholder, therefore, changing topics
or content will not significantly affect our algorithm. For example,
the word ‘‘ honorificabilitudinitas’’ occurs only once in Shake-
speare’s works. This type of low frequency words, in fact, works
only like placeholders as people often ignore them when reading.
In this paper, the least 10–20% frequent terms are merged in the
7810 P. Tang, T.W.S. Chow / Expert Systems with Applications 41 (2014) 7805–7819merging processing. Similarly, numerical terms, e.g., 0, 20, 0.3, I, III,
IV, X, are merged to a special ‘‘numerical term’’ due to their similar
usage which do not affect the algorithm.
The preprocessing procedures guarantee that our approach
safely handle the input unrestricted documents and delivers
reliable analysis results. The preprocessing techniques employed
in our implementation are listed in Table 1:
4.2. ‘‘Baseline’’ generation
The baseline is constructed by a set of Lexicons storing defined
textual statistics of training corpora. The baseline acts as rulers for
textual feature extraction. In analysis stage, the features of testing
documents are calculated using the corresponding information in
the baseline. Training corpus is first preprocessed. The corpus is
not necessarily large, which will further discussed. The main pur-
pose of the Baseline Generation step is to obtain a TF list LF ; Pþ
and P lexicons. LF stores the TF information of training corpus.
Pþ and P include the Cþ and C results, respectively. Suppose that
there are n words in the training corpus and the average sentence
length is l. The computational complexity for generating LF is OðnÞ
and OðnlÞ for yielding Pþ and P lexicons. The complete procedure
of generating baseline are illustrated in Algorithm 1.
Algorithm 1. The Procedure of Baseline Generation
Require: training texts
Ensure: LF ; Pþ; P
1. LF ; Pþ; P (£
2. Tokenize the original sample texts using the preprocessing
steps to tokenized strings T.
3. Calculate the frequency fi of a token ti 2 T
4. LF ( ðti; fiÞ, where i ¼ 1;2;3; . . . ;n
5. Split T into a list of sentences S
6. For a sentence Si in S, calculate Cþðw;w0Þ and Cðw;w0Þ,
where w;w0 2 Si
7. Pþ ( ðw;w0; CþÞ, where Si 2 S; w;w0 2 Si
8. P ( ðw;w0; CÞ, where Si 2 S; w;w0 2 Si
return LF ; Pþ; P4.3. Calculation of Frequency Rank Ratio
Textual features of testing corpus, or input documents, can be
extracted by using our algorithm and prepared baseline. All texts
are firstly preprocessed and then split into slices with m sentences.
The FRR and OI are extracted from the slices. To avoid the problem
of sparsity, only words with high word frequency are taken into
account. In our implementation, a parameter ‘‘TOP’’, used to fetch
the top x percentage of words from a vocabulary, is introduced to
tune the actual number of terms when calculating the textual
feature. The merging of these low frequent words in the text pre-
processing step has an advantage of reducing the problem of spar-
sity. A word which has never appeared in lexicons is treated as a
placeholder term.Table 1
Preprocessing techniques.
All letters in documents are converted to lower case
A ‘‘header’’ term is attached to the head of every sentence
All numerical terms, e.g., 0, 20, 0.3, I, III, IV, X, are merged to a special
‘‘numerical term’’
Punctuations are preserved and treat as common terms
Terms with low frequencies are merged to a placeholder term called
‘‘unknown term’’For a slice A with n sentences S1; S2; . . . ; Sn, the FRR of A given a
lexicon LF in a baseline is calculated in the following steps.
FRRðAjLFÞ ¼
1
n
Xn
i¼1
X
w2Si
w2topðLF Þ
NFRðw; SiÞ; ð11Þ
where the TOP (; r) operator specifies the proportion of top fre-
quent words of the whole vocabulary is employed for calculating
textual features. The parameter r ðr 2 ð0;1Þ is the proportion.
Meanwhile, the TOP (; r) is a parameter that configures the merging
of the proportion words with low frequency, i.e. the least frequent
words accounting for a proportion of 1 r are considered as the
placeholder term. When r is set to 1, all terms are utilized in the
algorithm and no term is merged.
The calculation of FRR requires LF obtained by using the training
corpora, because we use the TF of a given word in LF instead of the
corresponding global TF in given document to calculate the FRR.
Note that when the original documents are split to slices contain-
ing constant n sentences, (11) can be simplified as
FRR0ðAjLFÞ ¼
Xn
i¼1
X
w2Si
w2topðLF Þ
NFRðw; SiÞ: ð12Þ4.4. Calculation of Overall Intimacy
Similar to FRR, The Overall Intimacy (OI, I) is empirical defined,
in which I is derived with constraints Pþ and P lexicons. In the
calculation of OI, the original term pair information is replaced
by the corresponding value in the two lexicon Pþ and P. For a slice
A with n sentences S1; S2; . . . ; Sn, only term pairs contained in the
two lexicons Pþ and P are taken into account to calculate the OI.
Note that the number of word n in the training corpus is
constant. Consequently, the ðÞ=n in (4) can be omitted. Thus (6)
can be simplified as
IðSijPþ; PÞ ¼
Xn
i¼1
Xn
j¼1
Cðwi;wjÞf ðwjÞ
f ðwiÞ
: ð13Þ
The OI I ¼
Pn
i¼1IðSijPþ; PÞ=n is used as one of the features for
further text analysis. As all the slices are of the same length, the
divisor in (13) can be eliminated as
Isum ¼
Xn
i¼1
IðSijPþ; PÞ: ð14Þ
The slices can be easily mapped to a text space with the
assistance of the two extracted features. The similarity among
slices can then be intuitively observed. FRR and OI, cooperating
with other style markers, can construct higher dimensional vectors
for further analysis. In this case, higher dimensional vectors can be
processed using dimensionality reduction algorithms such as PCA
and LDA to extract the top two or three principle components for
visualization.
5. Simulations and results
To evaluate the feasibility and performance of our implementa-
tion, we present visualization results on language variation of
corpora of diverse authors and genre. In this section, several groups
of simulations are designed and conducted.
5.1. Simulation configuration
5.1.1. Corpus preparation
Few popular existing corpora are collected for language
variation evaluation. For example, the Brown corpus focuses on
Table 3
The components of Corpus 2.
Component contents Count
Native English Media (CNN, Guardian, NYTimes, Telegraph) 3000
English Media in CJK (Chinese, Japanese, and Korean) areas 3000
Newsgroup Topics 1000
Table 4
The components of Corpus 3. All the items in Corpus 3 are free public news reports
P. Tang, T.W.S. Chow / Expert Systems with Applications 41 (2014) 7805–7819 7811the alternation of topics, while the writing habit is overlooked. The
Wall Street Journal corpus takes only native news and reports into
account. In this paper, we design and collect two new corpora for
training and testing our algorithm in different perspectives. The
two corpora, namely Corpus 1, Corpus 2 and Corpus 3, comprise
some components in existing corpora, and copyright-free data col-
lected from the internet. The components of each corpus are listed
in Tables 2–4.
In our simulations, the components of the corpora can be added
or removed as needed.covering breaking news, politics, sports, arts, culture, business, education, society,
science fetched from the internet.
Component Contents Count
News reports from CNN 1000
News reports from New York Times 1000
News reports from Guardian 1000
News reports from Telegraph 1000
News reports from The Times 1000
e 
In
tim
ac
y
 
5.1.2. Evaluation methods
The language variation of the slices of documents is delivered
by the extracted textual features. An intuitive overall impression
of the language variation can be obtained by directly visualizing
using our textual features. The closeness that represents the
similarity of styles among slices can be observed directly by their
distance from each other.
We use classification and clustering approach to perform
numerical analysis of our visualization results. We employed three
popular classifiers in our study, namely, k-NN, Naive Bayesian, and
Decision Tree. The classification accuracy is used to measure the
effectiveness of different classification results. The higher
classification accuracy, the more efficient group of features that
deliver information of language variation. The parameters and
implementations of k-NN, naive Bayesian and decision tree are
detailed in Aha, Kibler, and Albert (1991), John and Langley
(1995) and Quinlan (1993).Average Normalized Frequency Rank
A
ve
ra
g
 
Diary
Reportage from English Media
Newsgroups Topics
Abstracts of FYP Reports
Fig. 1. Visualization of the four components in Corpus 1.5.2. Language variation in different generic documents
In this experiment, the famous novel Pride and Prejudice is
selected as the training corpus to prepare the ‘‘baseline’’. Corpus
1 is the testing corpus to evaluate the performance of our algo-
rithm for separate documents according to language variation of
different contents. All documents are first split into slices, then,
the two features are calculated using the proposed algorithm.
The components in Corpus 1, except the novel components, are
visualized in a 2D text space displayed in Fig. 1. In this figure, each
color point represents a slice. Every category can be distinguished
by the colors of the points that they are distributed in recognizable
different areas of the 2D space. From Fig. 1, we have the following
observations.
 The feature FRR, i.e. the word using features, can separate
‘‘Diary’’ and ‘‘Abstract of FYP Reports’’ from the other two
components.
 Two components ‘‘Newsgroup Topics’’ and ‘‘English news and
reports’’ of Corpus 1 cannot be separated from each other the
word using information.
 Two components ‘‘Newsgroup Topics’’ and ‘‘English news and
reports’’ of Corpus 1 can be distributed into different areas by
using feature OI, i.e. the word collocation feature that delivers
the inter-term association information.Table 2
The components of Corpus 1.
Component contents
C-I Novels (Pride and Prejudice (Pride), The Adventures of Huckleberry Finn, G
the Wild)
C-II English diaries by Chinese Learners from a Chinese website for Chinese u
C-III Newsgroup Topics
C-IV Abstracts of undergraduate students final year project (FYP) reports of an
C-V News and reports available on CNN.com and Guardian.co.ukFor the two components ‘‘Diary’’ and ‘‘Abstract of FYP Reports’’,
the vocabularies used to compose the texts are significantly differ-
ent from the ‘‘Report from English Medias’’ and ‘‘Newsgroups Top-
ics’’. Hence, the word using feature FRR can separate the two
components from the rest ones. Despite of the similarity of vocab-
ularies of Newsgroup Topics and English news and reports, the
word collocation feature OI can classify them. To sum up, the com-
bination of FRR and OI separate the four components of Corpus 1
effectively.
We also display all the five components in Corpus 1 including
the novel components in Fig. 2. In this figure, the novels are dis-
played in black color. The distribution of the four components
except novel is the same to Fig. 1. It can be observed that some
black points are scattered in the domains of other categories. This
phenomenon is common in very long documents like a full-text
novel, in which the long body text consists of many types ofCount
one with the Wind (Gone), Wuthering Heights (Wuthering), The Call of 5
sers who want to improve their English 200
400
Asian University 400
400
Average Normalized Frequency Rank
A
ve
ra
ge
 In
tim
ac
y
 
 
Diary
Reportage from English Media
Newsgroups Topics
Novels
Abstracts of FYP Reports
Fig. 2. Visualization of results of Corpus 1.
7812 P. Tang, T.W.S. Chow / Expert Systems with Applications 41 (2014) 7805–7819vocabulary using as well as styles like narrative style, dialog style,
and critical style, etc. After a long document is split, a distinct slice
may be different from other novel slices.
5.3. Language variation of texts of documents of the same genre
We perform another experiment to demonstrate the impact of
genre information of documents on the visualization. Different
from the previous experiment which involves documents of differ-
ent genre, six components of the 20 Newsgroups corpus, namely
atheism, computer sciences on Windows OS, forsale, sports, space
sciences and religions, are selected to form the testing corpus. That
is, we use document of the same genre to conduct this simulation.
The training corpus is still Pride and Prejudice. The slices of the six
components are visualized in Fig. 3(a). The following observations
can be obtained.
 The 6 categories of articles are largely overlapped.
 The distribution of each type of points is not uniform, indicating
the word-using and word-collocation features are not
homogeneous.
All data points congregate and overlap due to the same genre
(Newsgroup Topics) of the slices of different components. This0.35 0.4 0.45 0.5 0.55 0.6 0.65 0.7
−0.04
−0.02
0
0.02
0.04
0.06
0.08
0.1
0.12
0.14
Average Normalized Frequency Rank
A
ve
ra
ge
 In
tim
ac
y
 
 
alt.atheism.txt
comp.windows.x.txt
misc.forsale.txt
rec.sport.hockey.txt
sci.space.txt
talk.religion.misc.txt
(a) Visualization Result of Selected 6 Corpus from 20 Newsgroups
Dataset. Basically, the six categories of articles are overlapped.
But the distributions of points are still not homogeneous. Points
concerning about atheism and religion slices are totally overlapped
while rarely scattered in the domain of computer and space science,
which implies that the word collocation characteristics change with
the change of the topics of newsgroups.
(b
D
cr
ar
Fig. 3. Visualization result of selected 6 coimplies the change of language with topics is not as significant as
with genre of documents. Despite different categories of topics
overlapped, the distribution of color points is not homogeneous.
We can observe that slices about atheism and religion, appeared
in red and pink, respectively, are totally overlapped, but they rarely
appear in the region of computer and space sciences. This suggests
that the writing styles between religion/atheism and computer/
space sciences vary significantly. We visualize the full-text Holy
Bible representing in black cross in Fig. 3(b). It is clear that the
slices of texts of the Holy Bible, do not completely overlap with
the 6 categories of Newsgroup Topics, because they are of different
word collocation and using. But it is interesting to notice that the
Holy Bible, are located in the close vicinity of atheism and religion,
and are far from the regions that refers to sciences and engineering.
These observations are interesting as they corroborate that the text
characteristics information of documents is affected by the topics,
that is, the documents of similar topics can have similar language
styles.
Two components of Corpus 2 consist of only news and reports
from famous English Media covering diverse topics. Here, we use
Corpus 2 to conduct another experiment to illustrate the
performance of our algorithms. The novel Pride and Prejudice is still
taken as the training corpus. All categories of texts in Corpus 2 is
visualized in Fig. 4, in which there are following observations.
 A portion of color points representing Native Media and CJK
English Media are overlapped.
 Few slice representing Newsgroup Topics is overlapped with
the Native Media and CJK English Media.
 The average distance between Native Media and Newsgroup
Topics are smaller than the distance of Newsgroup Topics and
CJK English Media.
In Fig. 4, the overlap of Native Media and CJK English Media
indicates the language characteristics of the two categories of texts
are similar. Nevertheless, an observable percentage of the CJK
English slices distribute in different area from the native English
Media, which means our algorithm can still capture the difference
between the native English and the English from ESL (English as
Second Language) authors. The text of Newsgroup Topics in native
English represented in green color displayed in Fig. 4. Observe that0.35 0.4 0.45 0.5 0.55 0.6 0.65 0.7
−0.04
−0.02
0
0.02
0.04
0.06
0.08
0.1
0.12
0.14
Average Normalized Frequency Rank
A
ve
ra
ge
 In
tim
ac
y
 
 
alt.atheism.txt
comp.windows.x.txt
misc.forsale.txt
rec.sport.hockey.txt
sci.space.txt
talk.religion.misc.txt
the Holy Bible
) Visualization Result of Selected 6 Corpora From 20 Newsgroups
ataset and the Holy Bible. The Holy Bible is represented in black
oss. The slices of Holy Bible are close to atheism and religion, but
e far from sciences and engineering.
rpora from the 20 Newsgroups dataset.
Average Normalized Frequency Rank
A
ve
ra
ge
 In
tim
ac
y
 
 
Native Media
Newsgroup Topics
CJK English Media
Fig. 4. Visualization results of Corpus 2.
P. Tang, T.W.S. Chow / Expert Systems with Applications 41 (2014) 7805–7819 7813Newsgroup Topics are seldom overlapped with the other compo-
nents. It is worth noting that, the average distance between Native
Media and Newsgroup Topics are smaller than the distance of
Newsgroup Topics and CJK English Media, which indicate that
Newsgroup Topics in native English is more similar to the native
English Media than the CJK English Media. This comes to an agree-
ment to our common knowledge.
5.4. Parameter adjustment
5.4.1. Alternative training corpora
We have mentioned earlier that using different training corpora
to prepare the baseline will not significantly affect the extracted
features. To quantitatively analyze the impact of alternative train-
ing corpus, we use classifiers to analyze the impact of alternative
baselines on textual feature extraction. Four testing corpus, includ-
ing Corpus 1 without novel component, Corpus 1, Corpus 2, and
Corpus 2 without Newsgroup Topics,are denoted by Test1, Test2,
Test3 and Test4, respectively. The training corpora and the corre-
sponding classification accuracy are listed in Table 5. We can
observe from the result that the classification accurate do not
change greatly substantially with different baseline. As discussed
before, a few words with high frequencies, most of which are
function words, makes up a high proportion of the vocabulary.
They have major impact on features on word collocation. Previous
studies have suggests that the proportion of these function words
is relatively constant among various corpora either in topics or in
styles (Manning & Schütze, 1999). This characteristic indicates that
we do not need to employ large training corpora to handle testing
data. Such an improvement can effectively improve the computa-
tional cost.
5.4.2. Parameter TOP and LEN
There are two parameters in our implementation, namely top
words (TOP) and length of slices (LEN). To test the two parameters,
classifiers are used to evaluate the data of extracted features usingTable 5
Classification accuracy of visualization results using different baseline.
Baseline Test1 Test2 Test3 Test4
Pride and Prejudice 0.773 0.744 0.752 0.712
Gone with the Wind 0.780 0.747 0.759 0.720
Wuthering Heights 0.764 0.741 0.739 0.698
FYP reports 0.755 0.731 0.756 0.707
Diaries 0.736 0.704 0.748 0.713
CNN (1000 items) 0.805 0.753 0.771 0.734
CNN (200 items) 0.792 0.748 0.769 0.731
CNN (100 items) 0.788 0.743 0.767 0.726different pre-set parameters. Length of slices, namely the number
of sentences in a slice, can be an effective factor for visualization.
The comparative classification results using different values of
LEN are displayed in Fig. 5. In this group of simulations, the TOP
is set to 0.7. In this paper, cross-validation is performed to evaluate
the classification accuracy. The number of folds for cross-validation
is set to 10. It can be observed that when LEN increases, the num-
bers of slices get smaller, while the overall classification results
appear to be more accurate. It is natural that with a smaller pre-
set value of LEN, the slice points are more overlapped due to the
fact that smaller slices may be of similar language characteristics
to slices in other categories. This phenomenon can be observed
in Fig. 5. Fig. 5(a) and (b) are the samples of real visualized distri-
butions of text slices. Fig. 5(c) and (d) are the accuracy curves using
Corpus 2 and Corpus 1, respectively. Compared to points in
Fig. 5(a), a number of slice points in Fig. 5(b) are scattered in their
neighbored categories. This feature can actually be used in two
ways: if we want to extract the overall style of texts, LEN can be
set larger; if we intend to capture the detailed genre information,
the length can be set smaller so that detailed information in a text
can be displayed. From Fig. 5(c) and (d), the overall accuracy using
Corpus 1 is better than using Corpus 2. It is intuitively understood
that it is an easier task to classify different word collocation cate-
gories of text of significantly different genres and topics than to
separate slices of the same genre. From the accuracy curves it
can also be observed that the decision tree classifier delivers better
classification results when LEN is set a small value.
The parameter TOP specifies the proportion of the top
frequency words in the vocabulary. Fig. 6 displays the classification
accuracy with the adjustment of TOP. It can be observed in this
figure that a ‘‘turning point’’ appears when TOP is set to 60% to
70%. When TOP is greater than 0.7, the accuracy will not be not sig-
nificantly improved substantially with the increasing TOP. Our
experience implies that it is reliable to utilize terms that occupy
the top 70% to 80% of the whole vocabulary to calculate FR and
merging the rest of words in the implementation.5.5. Language evolution in different western languages
A large number of western languages are written in Latin
alphabet, for instance, English, French, Spanish and German. Much
evidence has already proved that the modern English language is
evolved from the old German and French, and French/Spanish
come from the Roman language, say, Latin language. In order to
provide an easy comparative platform, we in this section use trans-
lations of Holy Bible in different languages for the study. This study
aims to unveil the similarity among the four Indo-European lan-
guages using our algorithm. The Holy Bible in Italian is chosen to
be the training corpus.
Different translations of the Holy Bible are used because they all
describe the identical contents, even their format, e.g., length,
layout and text alignment, is the same. Therefore, the Bible trans-
lations can be regarded as perfect parallel corpora, and the bias
caused by different topics and writing styles can be eliminated.
To simplify our work, only translations written in Latin alphabet
are chosen. They are Spanish, German, French, English, Danish, Por-
tuguese and Italian. The Italian translation is selected to be the
training corpus, because Italian can be treated as the modern Latin
language. The Versio Vulgata, the Latin translation of the Bible, is
not taken to be the training corpus, because the Versio Vulgata is
mainly written in old Latin texts, in which spellings are quite dif-
ferent from the other selected translations. Therefore, there will
be rarely common terms, i.e. common words or phrases which
are essential when computing the FRR and OI, between the Versio
Vulgata and testing corpus.
0.35 0.4 0.45 0.5 0.55 0.6 0.65 0.7
−3
−2.5
−2
−1.5
−1
−0.5
0
x 10
4
Average Normalized Frequency Rank
A
ve
ra
ge
 In
tim
ac
y
 
 
Diary
Reportage from English Media
Newsgroups Topics
Abstracts of FYP Reports
(a) LEN=100, Corpus 2 is utilized.
0.4 0.45 0.5 0.55 0.6 0.65 0.7 0.75
−2000
−1800
−1600
−1400
−1200
−1000
−800
−600
−400
−200
0
Average Normalized Frequency Rank
A
ve
ra
ge
 In
tim
ac
y
 
 
Diary
Reportage from English Media
Newsgroups Topics
Abstracts of FYP Reports
(b) LEN=20, Corpus 2 is utilized.
10 20 30 40 50 60 70 80 90 100
0.4
0.45
0.5
0.55
0.6
0.65
0.7
0.75
0.8
Lengths of Slices
C
la
ss
ifi
ca
tio
n 
A
cc
ur
ac
y
 
 
1−nn
10−nn
Naive Bayesian
Decision Tree
(c) Classification Accuracy with differ-
ent values of LEN. Corpus 2 is utilized.
10 20 30 40 50 60 70 80 90 100
0.72
0.74
0.76
0.78
0.8
0.82
0.84
0.86
0.88
0.9
0.92
Lengths of Slices
C
la
ss
ifi
ca
tio
n 
A
cc
ur
ac
y
 
 
1−nn
10−nn
Naive Bayesian
Decision Tree
(d) Classification Accuracy with differ-
ent values of LEN. Corpus 1 is utilized.
Fig. 5. Classification results using different LEN.
10 20 30 40 50 60 70 80 90 100
0.4
0.45
0.5
0.55
0.6
0.65
0.7
0.75
0.8
0.85
Values of TOP (Percentage)
C
la
ss
ifi
ca
tio
n 
A
cc
ur
ac
y
 
 
1−nn
10−nn
Naive Bayesian
Decision Tree
(a) Classification Result using Corpus 2
10 20 30 40 50 60 70 80 90 100
0.5
0.55
0.6
0.65
0.7
0.75
0.8
0.85
0.9
0.95
Values of TOP (Percentage)
C
la
ss
ifi
ca
tio
n 
A
cc
ur
ac
y
 
 
1−nn
10−nn
Naive Bayesian
Decision Tree
(b) Classification Result using Corpus 1
Fig. 6. Classification results using different TOP.
7814 P. Tang, T.W.S. Chow / Expert Systems with Applications 41 (2014) 7805–7819In this study, we treat letters with modifiers and the corre-
sponding original letters different. For example, é and e are
regarded as different letters. Therefore, café and cafe are different
words. And there is no conversion from the modified letters to
the corresponding original letters. The TOP and LEN are set to
0.95 and 300, respectively. The visualization results is displayed
in Fig. 7.
In Fig. 7(a), seven translations are visualized. The visualization
result of the seven western languages is interesting. The visualiza-
tion result shows that our method can separate the seven lan-
guages under the circumstance that the semantic and syntacticinformation is hidden to the algorithm. Observe that there is a dis-
tance between the Italian Bible and the other languages. As men-
tioned before, Italian is the training corpus, the OI and FRR are
highly different when Italian itself is used for testing, for the com-
mon terms are far more between the training and testing corpus
compared with other studied languages. It is interesting to note
that the Portuguese/French/Spanish translations appear to be clo-
ser to the Italian, i.e. the Latin language, compared with English/
Danish/German languages. These results indicate that Portu-
guese/French/Spanish are fairly closer to the traditional Latin lan-
guage than the other three studied languages.
Average Normalized Frequency Rank
A
ve
ra
ge
 In
tim
ac
y
 
 
Spanish
German
French
English
Danish
Portuguese
Italian
(a) Visualization Results of 7 Bible Translations
Average Normalized Frequency Rank
A
ve
ra
ge
 In
tim
ac
y
 
 
Spanish
German
French
English
Danish
Portuguese
(b) Visualization Results of 6 Bible Translation
     (Italian is excluded)
Fig. 7. Visualization result of 7 holy bible translations.
0.84
1
Average Normalized Frequency Rank
A
ve
ra
ge
 In
tim
ac
y
 
 
news of 1980s
news of 1990s
news of 2000s
news of 1990s
news of 2000s
news of 1980s
Fig. 8. Visualization result of news in NYTimes.
P. Tang, T.W.S. Chow / Expert Systems with Applications 41 (2014) 7805–7819 7815From Fig. 7(b), we can observe that the six languages are nicely
demarcated into two groups: Group 1: French/Spanish/Portuguese;
and Group 2: English/Danish/German. From this figure we can see
that Portuguese shares the same word-collocation characteristics
with Spanish, and the mainly difference between the two lan-
guages is the vocabulary. Contrast to Spanish and Portuguese,
French and Spanish share more common vocabulary, while their
word-collocation is not as close as Portuguese and Spanish, i.e.,
though Spanish and French share a range of similar words. It is
the word-collocation information, say, OI, that separates Spanish
from French language. Similar observations are found on Group
2: English/Danish/German. English, German and Danish are almost
scattered on the same area, which indicates that the three lan-
guages are similar. It is also observed that the distance between
English and German, however, is longer than the distance between
Danish and German. This suggests that German has more influence
on Danish than on English.
The visualization result also shows that the ‘‘genetic relation-
ship’’ within a group is more French/ Spanish/ Portuguese than
the inter-group relationship. This view from the visualization
result is consistent with many previous studies (Delbecque,
1990; Wikipedia, 2012). In fact, in the linguistic research area,
French, Portuguese and Spanish are both belong to the Latin lan-
guage family (Alkire & Rosen, 2010), while English, Danish and
German are three members of West Germanic language family
(Robinson, 1992). Another interesting observation is that despite
English being closer to the German language, English locates in
the middle of the other languages, i.e. Spanish, Danish, French
and German. This indicates that English is a must language which
probably has more than one original source in its evolution. This
view is also supported by many literatures (Renfrew, 1990). Note
that the English, Danish and German are not completely separated
in the Intimacy-axis direction, because there are only a few com-
mon words between the Germanic languages and Latin languages.
This is mainly caused by the gradual shift of word spelling. Thus, it
suggests that when there are only a few common words between
training and testing corpora, the OI and FRR cannot completely
separate the languages.
5.6. Language changes of modern languages
Languages are dynamic and vary gradually over time, even
within a short duration when compared to the time that a language
evolves to another. For example, parents can feel weird whenchildren talks in online language, though they do speak English.
We take modern English as an example. A corpus is constructed
to simulate this scenario. To avoid the visualization bias caused
by different topics and types of texts, 1000 random news items
from the beginning of 1980s, 1000 from the 1990s, 1000 from
the 2000s, and publicly available news from nytimes.com are
fetched. The three components are visualized in our text space,
which is shown in Fig. 8. The three components appear to be scat-
tered in the same area and cannot be told from one another. The
cluster centers of each component, which are located at the ends
of the arrows in Fig. 8 drift, though not as dramatic as changes
among different languages in the previous section. There is a small
distance between the centers of orange points (news of 1990s) and
red points (news of 1980s), while the yellow points (news of
2000s) are still further than the orange points. This indicates that
the writing styles gradually vary with time.
A similar phenomenon also happens in British and American
English. We use Corpus 3 to conduct our simulation. 1000 random
news and reports from CNN.com, 1000 from Telegraph, 1000 from
the Times, 1000 from New York Times, and 1000 from the Guard-
ian fetched in 2013 are visualized and compared in Fig. 9. From
these figures, though the components are largely overlapped, the
Average Normalized Frequency Rank
A
ve
ra
ge
 In
tim
ac
y
 
 
CNN
Telegraph
New York Times
New York Times
Telegraph
CNN
(a)
Average Normalized Frequency Rank
A
ve
ra
ge
 In
tim
ac
y
 
 
The Times
Guardian
CNN
CNN
The Times
Guardian
(b)
Average Normalized Frequency Rank
A
ve
ra
ge
 In
tim
ac
y
 
 
Guardian
CNN
Telegraph
CNN
Guardian
Telegraph
(c)
Fig. 9. Visualization result of news from different English Media.
Table 7
Comparison of classification results: FRR and OI and other style markers.
Features Used C-I C-II C-III C-IV C-V
FRR, OI 0.821 0.691 0.734 0.853 0.776
7816 P. Tang, T.W.S. Chow / Expert Systems with Applications 41 (2014) 7805–7819cluster centers indicate that British English is different from Amer-
ican English. The cluster centers of the two British media (i.e. The
Guardian, the Times and Telegraph) are closer to each other than
to the American media CNN and New York Times.M1, M2, M3, M4 0.691 0.638 0.600 0.764 0.745
M5, M6 0.312 0.525 0.553 0.711 0.727
M1, M2, . . . ,M6 0.729 0.677 0.659 0.770 0.732
M7, M8, . . . ,M23 0.675 0.689 0.681 0.764 0.743
M24, M25, . . . ,M23 0.742 0.687 0.711 0.860 0.781
FRR, OI, M1, . . . ,M4 0.844 0.751 0.769 0.862 0.801
FRR, OI, M5, M6 0.841 0.698 0.757 0.854 0.795
FRR, OI, M1, . . . ,M6 0.848 0.764 0.772 0.870 0.809
FRR, OI, M7, . . . ,M23 0.857 0.776 0.780 0.871 0.813
FRR, OI, M24, . . . ,M40 0.864 0.791 0.787 0.882 0.819
Table 8
Comparison of classification results: cumulative influence (CI), trigram, bigram, bag of
words (BOW), the Positional Language Models (PLMs).
Method used C-I C-II C-III C-IV C-V
Gaussian-CI 0.821⁄ 0.691 0.734 0.853⁄ 0.776
Linear-CI 0.817 0.689 0.730 0.837 0.757
Trigram 0.790 0.712⁄ 0.731 0.817 0.781⁄
bigram 0.774 0.615 0.689 0.826 0.727
Gaussian-PLM 0.809 0.663 0.739⁄ 0.825 0.764
Triangle-PLM 0.808 0.651 0.724 0.823 0.759
BOW 0.675 0.472 0.591 0.720 0.5245.7. Comparative analysis
5.7.1. FRR + OI versus conventional style markers
Few studies have been done for analyzing automatic language
variation. In this section we attempt to conduct analysis on word
using and collocation using other conventional style markers, and
then compare the effectiveness with our proposed algorithms.
The selected conventional widely used in text analysis (Finn &
Kushmerick, 2006; Kelih, Antić, Grzybek, & Stadlober, 2005;
Kessler et al., 1997; Lim, Lee, & Kim, 2005) are illustrated in Table 6.
Among the listed style markers, M1–M6 are term-level features.
M7–M40 are syntax oriented. PCA is to extract the principle com-
ponents from the extracted features of the listed style markers. For
our approach, the TOP and LEN are set to 0.7 and 100, respectively.
Corpus 1 is chosen to be the testing corpus. The k-NN classifier is
used to analyze the accuracy. The classification is displayed in
Table 7, in which we can observe that our method outperforms
the combinations of other style markers. It is also worth noting
that our proposed approach requires far less computational time
than the grammatical and semantic based methods. Note that
the more features are included, the higher accuracy can be output.
The computational cost, however, increases rapidly when more
style markers are employed, especially syntactic and semantic
features.5.7.2. Calculation of textual features
Notice that the n-gram language model is a special case of the
cumulative influence when only the neighbors of a specified word
are taken into account. Here, several different language models areTable 6
The selected style markers.
Feature used Description
M1 Frequency of 30 most frequently used fun
M2 Frequency of 20 most frequently used pun
M3 Number of usual words/total number of w
M4 Number of distinct words/total number of
M5 Number of imperative sentences/number o
M6 Number of question sentences/number of
M7, M8, . . . ,M23 Number of phrase/total number of phrases
M24, M25, . . . ,M40 Average number of words per phrase for 1compared with our proposed models. The CI, trigram, bigram, bag
of words (BOW), the Positional Language Models (PLMs) (Lv & Zhai,
2009) are employed for the text classification task. In this group of
simulations, a 1-nn classifier is used for performing classification.
The classification result is shown in Table 8. It can be observed that
in most cases the Gaussian-CI outperforms the other language
models.ction words/total frequency of function words
ctuations/total frequency of punctuations
ords
words
f total sentences
total sentences
in a document for 17 phrases: NP, VP, AJP, AUXP, AVP, CONJP, SENT, IMPR, etc.
7 phrases: NP, VP, AJP, AUXP, AVP, CONJP, SENT, IMPR, etc.
0.35 0.4 0.45 0.5 0.55 0.6 0.65 0.7
−0.04
−0.02
0
0.02
0.04
0.06
0.08
0.1
0.12
0.14
Average Normalized Frequency Rank
A
ve
ra
ge
 In
tim
ac
y
 
 
alt.atheism.txt
comp.windows.x.txt
misc.forsale.txt
rec.sport.hockey.txt
sci.space.txt
talk.religion.misc.txt
(a) Cumulative influence
0.35 0.4 0.45 0.5 0.55 0.6 0.65
0
0.2
0.4
0.6
0.8
1
1.2
1.4
Average Normalized Frequency Rank
A
ve
ra
ge
 In
tim
ac
y
 
 
alt.atheism.txt
comp.windows.x.txt
misc.forsale.txt
rec.sport.hockey.txt
sci.space.txt
talk.religion.misc.txt
(b) Bigram
0.35 0.4 0.45 0.5 0.55 0.6 0.65
0
0.2
0.4
0.6
0.8
1
1.2
1.4
Average Normalized Frequency Rank
A
ve
ra
ge
 In
tim
ac
y
 
 
alt.atheism.txt
comp.windows.x.txt
misc.forsale.txt
rec.sport.hockey.txt
sci.space.txt
talk.religion.misc.txt
(c) Trigram
Fig. 10. Visualization results using cumulative influence, bigram and trigram.
P. Tang, T.W.S. Chow / Expert Systems with Applications 41 (2014) 7805–7819 7817We also display visualization results using different calculations
of OI. The 20 Newsgroups Topics are chosen as the testing corpus.
Here, bigram and trigram are compared with our cumulative influ-
ence method. From the visualization result, it can be observed that
the results using bigram and cumulative influence can display the
religions and atheisms topics in the same area, while atheism and
religion are separated in the results using trigram From the
perspective of a general reader, the writing style of the two compo-
nents is similar, though they concern of different topics. Therefore,
the result using trigram is actually a visualization results on docu-
ment topics, not on the styles of documents. Also, by comparing
Fig. 10(a) and (b), we can observe that the result of bigram is
slightly messier than cumulative influence based approach.
A quantitative analysis result is given using the ratio of mean
inter-style distance and mean intra-style distance
r ¼mean inter-style distance
mean inter-style distance
: ð15Þ
A larger r means a better visualization result. Here, we do not
employ the classification accuracy as the metric because the styles
of documents of the same genres are very similar. Thus, the styles
of different components of corpus should be treated as continuous
variables, but not discrete variables. The comparative result is
shown in Fig. 11.Selected 20 Newsgroups Corpus 1 Corpus 2
0
0.2
0.4
0.6
0.8
1
1.2
1.4
1.6
1.8
 
 
Our proposed CI method
Bigram
Trigram
Fig. 11. Comparison of our proposed method with n-grams.In Fig. 11, we consider atheisms and religions as one style; com-
puter science and space science as another style. The y-axis is
r ¼ mean inter-style distancemean inter-style distance as defined in the above. We can observe that,
using our proposed algorithm, higher accuracy than using n-gram
approaches can be obtained for all the test corpora.
6. Discussions and conclusion
In this paper, language variation is analyzed using two novel
proposed features FRR and OI. The FR used for calculating FRR
provides single-term characteristic. The Intimacy, a metric used
for calculating OI and modeling connection among terms, aims to
capture the inter-term features of documents. The proposed FR is
able to deliver balanced weights of terms according to their fre-
quencies, while the drawbacks caused by the power-law distribu-
tion of the term frequencies are minimized. The Intimacy,
compared to conventional n-gram approaches, have no indepen-
dent assumption that one term is only dependent on its previous
n 1 neighbors while independent from the rest of terms. In such
a scenario, the connections between distant words are able to be
collected. Therefore, the results of the text analysis are able to be
improved. The entropy based analysis indicates that more uncer-
tainty, i.e. more information, can be captured using the proposed
method.
By employing the same baseline, different FRR of single-
term-level feature values and OI of inter-term-level feature can
be calculated on the bases of FR and Intimacy when a baseline is
given. Meanwhile, extensive simulations are performed to evaluate
our text analysis method based on FRR and OI. Promising analyzing
results are delivered with our proposed approaches. Compared to
other style markers covering term-level and syntax-levels features,
FR and Intimacy are proved to be more capable of capturing useful
language variation characteristics.
An advantage of our algorithm is that the change of different
baseline does not impact the final visualization or classification
results significantly, regardless of the topics/genre and size of the
training corpora. This property allows us to build a baseline using
a small training corpus. Consequently, fewer terms and word
combinations will be considered in the baseline, resulting in
improvement of the computational cost of the testing procedure.
It is natural that the using of language varies with the types of
the documents, i.e., different documents have diverse language
characteristics. Therefore, the proposed method for analyzing lan-
guage styles can be applied to the classical text mining tasks such
as text classification and clustering. Our simulations have shown
that, by using our approach, promising visualization can be plotted.
The visualization results imply that our method is able to not only
capture language variations among documents of different genres
7818 P. Tang, T.W.S. Chow / Expert Systems with Applications 41 (2014) 7805–7819and different topics, but also can be used for text classification and
clustering tasks, for that different components of the testing cor-
pora are clearly distributed.
Besides, reading experiences tell that the styles of language of
documents of the same genre, though slightly, are different. This
issue is usually overlooked in previous research works. It is worth
noting that our proposed algorithm can captured the difference
caused by the alternative word-using and word collocation charac-
teristics among documents of the same genre and topics which are
seldom researched by previous studies.
At last, the visualization result of the seven western languages
is interesting. The proposed implementation can differentiate the
seven western languages under the circumstance that semantic
and syntactic information is hidden to the algorithm. The drift of
modern English can also be detected using our algorithms. More
importantly, the distribution results of the studied languages are
highly consistent to our common knowledge. This simulation also
shows the effectiveness of our proposed algorithms.
It is worth pointing out that the classification accuracy first
decreases and then increases when the value of the parameter
TOP in our algorithm. However, the mechanism of this change is
still unknown and needs further research. Besides, since our pro-
posed features can clearly visualize document slices in a two
dimensional space, the visualization results can be helpful when
create index for document retrieval tasks. Such applications are
also our future work.References
Aha, D., Kibler, D., & Albert, M. (1991). Instance-based learning algorithms. Machine
Learning, 6(1), 37–66.
Alkire, T., & Rosen, C. (2010). Romance languages: A historical introduction.
Cambridge University Press.
Biber, D. (1995). Dimensions of register variation: A cross-linguistic comparison.
Cambridge University Press.
Bing Xue, X., & Hua Zhou, Z. (2009). Distributional features for text categorization.
IEEE Transactions on Knowledge and Data Engineering, 21, 428–442. http://
dx.doi.org/10.1109/TKDE.2008.166.
Brinegar, C. (1963). Mark Twain and the quintus curtius snodgrass letters: A
statistical test of authorship. Journal of the American Statistical Association,
85–96.
Bum Kim, S., Soo Han, K., Chang Rim, H., & Hyon Myaeng, S. (2006). Some effective
techniques for Naive Bayes text classification. IEEE Transactions on Knowledge
and Data Engineering, 18, 1457–1466. http://dx.doi.org/10.1109/TKDE.2006.180.
Chang Yang, H., & Hong Lee, C. (2005). A text mining approach for automatic
construction of hypertexts. Expert Systems With Applications, 29, 723–734.
http://dx.doi.org/10.1016/j.eswa.2005.05.003.
Chowdhury, G. (2010). Introduction to modern information retrieval. Facet Publishing.
Clement, R., & Sharp, D. (2003). Ngram and Bayesian classification of documents for
topic and authorship. Literary and Linguistic Computing, 18(4), 423–447.
Corrêa, R., & Ludermir, T. (2008). A quickly trainable hybrid som-based document
organization system. Neurocomputing, 71(16), 3353–3359.
Delbecque, N. (1990). Word order as a reflection of alternate conceptual construals
in French and Spanish. similarities and divergences in adjective position.
Cognitive Linguistics (includes Cognitive Linguistic Bibliography), 1(4), 349–416.
Ferreira, A., & Figueiredo, M. (2012). An unsupervised approach to feature
discretization and selection. Pattern Recognition, 45(9), 3048–3060.
Finn, A., & Kushmerick, N. (2006). Learning to classify documents according to
genre. Journal of The American Society for Information Science and Technology, 57,
1506–1518. http://dx.doi.org/10.1002/asi.20427.
Gelbukh, A., Sidorov, G., & Guzmán-Arenas, A. (1999). A method of describing
document contents through topic selection. In Proceedings of the String
processing and information retrieval symposium & international workshop on
groupware, SPIRE ’99 (pp. 73). Washington, DC, USA: IEEE Computer
Society<http://dl.acm.org/citation.cfm?id=519452.830776>.
Goldwater, S., & Griffiths, T. (2007). A fully Bayesian approach to unsupervised part-
of-speech tagging. In Annual meeting-association for computational linguistics
(Vol. 45, p. 744).
Han, E., Karypis, G., & Kumar, V. (2001). Text categorization using weight adjusted
k-nearest neighbor classification. Advances in Knowledge Discovery and Data
Mining, 53–65.
Jansen, B. J., & Pooch, U. W. (2001). A review of web searching studies and a
framework for future research. Journal of The American Society for Information
Science and Technology, 52, 235–246.
Joachims, T. (1999a). Making large-scale support vector machine learning practical.
In Advances in kernel methods (pp. 169–184). Cambridge, MA, USA: MIT Press.Joachims, T. (1999b). Transductive inference for text classification using support
vector machines. In Machine learning-international workshop then conference
(pp. 200–209). Morgan Kaufmann Publishers, Inc.
John, G. H., & Langley, P. (1995). Estimating continuous distributions in Bayesian
classifiers. In Proceedings of the 11th conference on uncertainty in artificial
intelligence, UAI’95 (pp. 338–345). San Francisco, CA, USA: Morgan Kaufmann
Publishers Inc<http://dl.acm.org/citation.cfm?id=2074158.2074196>.
Kelih, E., Antić, G., Grzybek, P., & Stadlober, E. (2005). Classification of author and/or
genre? The impact of word length. In Classification – the ubiquitous challenge
(pp. 498–505). Heidelberg: Springer.
Kessler, B., Numberg, G., & Schütze, H. (1997). Automatic detection of text genre. In
Proceedings of the 35th annual meeting of the association for computational
linguistics and eighth conference of the European chapter of the association for
computational linguistics, ACL ’98, association for computational linguistics (pp.
32–38). Stroudsburg, PA, USA. http://dx.doi.org/10.3115/976909.979622. URL:
<http://dx.doi.org/10.3115/976909.979622>.
Kitamura, Y., & Mizoguchi, R. (2003). Ontology-based description of functional
design knowledge and its use in a functional way server. Expert Systems
With Applications, 24, 153–166. http://dx.doi.org/10.1016/S0957-
4174(02)00138-0.
Lim, C., Lee, K., & Kim, G. (2005). Multiple sets of features for automatic genre
classification of web documents. Information Processing & Management, 41(5),
1263–1276.
Li, C. H., Song, W., & Park, S. C. (2009). An automatically constructed thesaurus for
neural network based document categorization. Expert Systems With
Applications, 36, 10969–10975. http://dx.doi.org/10.1016/j.eswa.2009.02.006.
Lv, Y., & Zhai, C. (2009). Positional language models for information retrieval. In
Proceedings of the 32nd international ACM SIGIR conference on research and
development in information retrieval (pp. 299–306). ACM.
Manning, C. D., Raghavan, P., & Schütze, H. (2008). Introduction to information
retrieval (Vol. 1). Cambridge: Cambridge University Press.
Manning, C. D., & Schütze, H. (1999). Foundations of statistical natural language
processing (Vol. 999). MIT Press.
Martínez Sotoca, J., & Pla, F. (2010). Supervised feature selection by clustering using
conditional mutual information-based distances. Pattern Recognition, 43(6),
2068–2081.
Morton, A. (1965). The authorship of greek prose. Journal of the Royal Statistical
Society. Series A (General), 128(2), 169–233.
Neuhaus, M., & Bunke, H. (2006). Edit distance based kernel functions for structural
pattern classification. Pattern Recognition, 39, 1852–1863. http://dx.doi.org/
10.1016/j.patcog.2006.04.012.
Ogura, H., Amano, H., & Kondo, M. (2009). Feature selection with a measure of
deviations from Poisson in text categorization. Expert Systems With Applications,
36, 6826–6832. http://dx.doi.org/10.1016/j.eswa.2008.08.006.
Ou, G., & Murphey, Y. L. (2007). Multi-class pattern classification using neural
networks. Pattern Recognition, 40, 4–18. http://dx.doi.org/10.1016/
j.patcog.2006.04.041.
Peng, F., Schuurmans, D., Wang, S., & Keselj, V. (2003). Language independent
authorship attribution using character level language models In Proceedings of
the tenth conference on European chapter of the association for computational
linguistics: Vol. 1. EACL ’03, association for computational linguistics (pp. 267–274).
Stroudsburg, PA, USA. http://dx.doi.org/10.3115/1067807.1067843, URL:
<http://dx.doi.org/10.3115/1067807.1067843>.
Peng, F., Schuurmans, D., & Wang, S. (2004). Augmenting Naive Bayes classifiers
with statistical language models. Information Retrieval, 7(3), 317–345.
Petkova, D., & Croft, W. B. (2007). Proximity-based document representation for
named entity retrieval. In Proceedings of the sixteenth ACM conference on
information and knowledge management, CIKM ’07 (pp. 731–740). New York, NY,
USA: ACM. http://dx.doi.org/10.1145/1321440.1321542<http://doi.acm.org/
10.1145/1321440.1321542>.
Petkova, D., & Croft, W. (2007). Proximity-based document representation for
named entity retrieval. In Proceedings of the sixteenth ACM conference on
information and knowledge management (pp. 731–740). ACM.
Petrović, S., Šnajder, J., & Bašić, B. (2010). Extending lexical association measures for
collocation extraction. Computer Speech & Language, 24(2), 383–394.
Quinlan, J. R. (1993). C4.5: Programs for machine learning. San Francisco, CA, USA:
Morgan Kaufman Publishers Inc.
Rajan, K., Ramalingam, V., Ganesan, M., Palanivel, S., & Palaniappan, B. (2009).
Automatic classification of tamil documents using vector space model and
artificial neural network. Expert Systems With Applications, 36, 10914–10918.
http://dx.doi.org/10.1016/j.eswa.2009.02.010.
Ratnaparkhi, A. et al. (1996). A maximum entropy model for part-of-speech tagging.
In Proceedings of the conference on empirical methods in natural language
processing (Vol. 1, pp. 133–142).
Renfrew, C. (1990). Archaeology and language: The puzzle of Indo-European origins.
Cambridge University Press.
Robinson, O. W. (1992). Old English and its closest relatives: A survey of the earliest
Germanic languages. Stanford University Press.
Seretan, V. (2010). Syntax-based collocation extraction (Vol. 44). Springer-Verlag New
York Inc.
Seretan, V., Nerima, L., Wehrli, E., et al. (2003). Extraction of multi-word collocations
using syntactic bigram composition. In Proceedings of the fourth international
conference on recent advances in NLP (RANLP-2003) (pp. 424–431).
Shang, W., Huang, H., Zhu, H., Lin, Y., Qu, Y., & Wang, Z. (2007). A novel feature
selection algorithm for text categorization. Expert Systems With Applications, 33,
1–5. http://dx.doi.org/10.1016/j.eswa.2006.04.001.
P. Tang, T.W.S. Chow / Expert Systems with Applications 41 (2014) 7805–7819 7819Shing Lee, C., Juan Chen, Y., & Wei Jian, Z. (2003). Ontology-based fuzzy event
extraction agent for Chinese e-news summarization. Expert Systems With
Applications, 25, 431–447. http://dx.doi.org/10.1016/S0957-4174(03)00062-9.
Song, W., Li, C. H., & Park, S. C. (2009). Genetic algorithm for text clustering using
ontology and evaluating the validity of various semantic similarity measures.
Expert Systems With Applications, 36, 9095–9104. http://dx.doi.org/10.1016/
j.eswa.2008.12.046.
Stamatatos, E., Fakotakis, N., & Kokkinakis, G. (2000). Automatic text categorization
in terms of genre and author. Computational Linguistics, 26(4), 471–495.
Tan, S. (2005). Neighbor-weighted K-nearest neighbor for unbalanced text corpus.
Expert Systems With Applications, 28, 667–671. http://dx.doi.org/10.1016/
j.eswa.2004.12.023.Thelwall, M., & Buckley, K. (2013). Topic-based sentiment analysis for the social
web: The role of mood and issue-related words. Journal of the American Society
for Information Science and Technology, 64(8), 1608–1617. http://dx.doi.org/
10.1002/asi.22872.
van Halteren, H., Tweedie, F., & Baayen, H. (1996). Outside the cave of shadows:
Using syntactic annotation to enhance authorship attribution. Computers and
the Humanities, 28(2), 87–106.
Wikipedia. (2011). N-gram – wikipedia, the free encyclopedia (Online; accessed 8-
October-2011). URL: <http://en.wikipedia.org/w/index.php?title=N-gram>.
Wikipedia. (2012). Lexical similarity – wikipedia, the free encyclopedia (Online;
accessed 6-November-2012). URL: <http://en.wikipedia.org/w/index.php?title=
Lexical_similarity>.
