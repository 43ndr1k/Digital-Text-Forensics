Author Identification in Bengali Literary Works
Suprabhat Das and Pabitra Mitra
Department of Computer Science and Engineering
Indian Institute of Technology Kharagpur
West Bengal, Pin - 721302, India
{suprabhat,pabitra}@cse.iitkgp.ernet.in
Abstract. In this paper, we study the problem of authorship identifi-
cation in Bengali literary works. We considered three authors namely
Rabindranath Tagore, Bankim Chandra Chattopadhyay and Sukanta
Bhattacharyay. It was observed that simple unigram and bi-gram fea-
tures along with vocabulary richness were rich enough to discriminate
amongst these authors. Although results degraded slightly when train-
ing set size was considerably small. For larger training set, a classification
accuracy of above 90% for unigram feature and almost 100% for bi-gram
feature was achieved. Results could be improved further by using more
sophisticated features.
Keywords: Stylometry, authorship attribution, Bengali literary works,
unigram, bi-gram.
1 Introduction
Stylometry is the study of the unique linguistic styles and writing behaviors of
individuals. Author identification is one of the important problems in stylomet-
rics and it can be seen as a single-label multi-class text categorization problem.
It has many academic and literary applications, like author verification, plagia-
rism detection, genre classification etc. It has legal applications too, like forensic
linguistics, detection of genuine confessions. In the last few years it has success-
fully been applied to broader areas, ranging from blogs, forums, wikis, email,
chat and other forms of digital content to music and fine-art paintings.
Stylometry has been studied on English for long time. It was started by
Mendenhall [1], in the 19th century, with his work on the plays of Shake-
speare. He had reported few authorship attribution method by some charac-
teristic curves, based on sentence length counts and word length counts. It was
followed by some statistical studies by Zipf [2] and Yule [3] in the first half of 20th
century. One of the most influential works in authorship attribution was done by
Mosteller and Wallace [4] on the authorship of ‘The Federalist Papers’ (a series
of articles published in 1787-88, written by John Jay, Alexander Hamilton and
James Madison). They had employed Bayesian statistical analysis on a small
set of function words such as prepositions, conjunctions and articles as discrim-
inators. Burrows [5,6] first applied multivariate analysis (MVA) and principle
S.O. Kuznetsov et al. (Eds.): PReMI 2011, LNCS 6744, pp. 220–226, 2011.
c© Springer-Verlag Berlin Heidelberg 2011
Author Identification in Bengali Literary Works 221
components analysis (PCA) on some function words for attributing authorship,
followed by Binongo & Smith [7], Holmes et al. [8] and also by Burrows [9,10]
to resolve many authorship problems. Kjell et al. [11] used neural networks and
k-nearest neighbors on character n-grams, whereas Baayen et al. [12] used only
neural networks on the syntax of the sentence. Juola & Baayen [13] used cross
entropy as classification method on function words. Zhao & Zobel [14] reported
a different distance measure on function words and part-of-speech (POS) tags.
Stamatatos [15] used support vector machines (SVM) on character n-grams to
classify English and Arabic news corpus. Koppel et al. [16] reported approach of
authorship attribution for thousands of candidate authors.
In Bengali no major work has been done. Mansur et al. [17] proposed an
n-gram based text categorization algorithm and also analyzed its efficiency on
few Bengali newspaper corpus. We make initial attempts on a collection of docu-
ments consisting of Rabindranath Tagore, Bankim Chandra Chattopadhyay and
Sukanta Bhattacharyay. We found that using unigram and bi-gram words and
vocabulary richness we could achieve a satisfactory result.
The rest of this paper is organized as follows: Section 2 gives a brief overview
of stylometric features we have used for evaluation. In Section 3, we focus on
the classifier algorithm. The details of the collection are given in Section 4.
Section 5 describes the details of the experimental results. In Section 6, we have
concluded about our evaluation result and also about some other features that
can be included in future works for the betterment of our research work.
2 Stylometric Features
A wide variety of relevant features have been reported in many earlier works.
Stamatatos [18] has surveyed on almost all stylometric features used till now and
modern authorship attribution methods. There are different types of stylometric
features to quantify the writing style. Character features are the simplest and
basic stylometric feature, as this can be applied in any natural language without
any prior knowledge about the language. Lexical features are most commonly
used feature for authorship attribution problems whereas syntactic and semantic
features are used for more advanced and complicated tasks like POS tagging,
parsing. Application-specific features are used for some specialized applications,
like lemmatizer or specialized dictionaries.
Feature selection and extraction is one of the biggest challenges in author-
ship attribution problems. Many types of features are often combined to select
respective feature set. Some lexical features are used to build the feature set in
our experiment. In first stage of the experiment, unigram words and vocabu-
lary richness are taken as the feature set to quantify the authorship. A relevant
tokenizer is used to segment text into tokens or unigram words. Punctuation
marks, white space, mathematical notations and special characters are taken as
separator to the consecutive tokens. Bi-gram words are nothing but combination
of two consecutive unigram words. Bi-gram words and vocabulary richness are
combined to use as feature set in the next stage of the experiment. For example,
222 S. Das and P. Mitra
the test sentences “John is a good boy. He likes to play cricket” would be com-
posed of following unigram and bi-gram words, tabulated in Table 1.
Table 1. Unigram and bi-gram words from the test sentence
Unigrams John, is, a, good, boy, He, likes, to, play, cricket
Bi-grams John is, is a, a good, good boy, boy He, He likes, likes to, to play, play cricket
Vocabulary richness is a measurement of diversity of the vocabulary of a text.
It is defined by VN , where V is number of unique tokens and N is the total number
of tokens of the text. An example of calculating vocabulary richness from the
test sentences “Tom always harasses Jerry. Jerry is intelligent. Mickey is friend
of Jerry” is given in the Table 2.
Table 2. Frequencies of unigram words and corresponding vocabulary richness
Unigram words Frequencies Vocabulary richness
Tom 1 112
always 1 112
harasses 1 112
Jerry 3 14
is 2 16
intelligent 1 112
Mickey 1 112
friend 1 112
of 1 112
3 Classifier Algorithm
Classification is the next important step after feature selection. Test documents
are attributed to a known author from the set of candidate authors. Starting
from very basic statistical measures, like distance measure, Naive Bayes classi-
fier, some advanced measures like neural networks, k-nearest neighbors are also
used to quantify authorship. In our experiment, we have used a probabilistic clas-
sification method, which is variation of Naive Bayes classification method [19]. In
our experiment, classification feature is measured by a simple probability metric
PA =
SA
FA × T (1)
where, PA is probability of test document being written by Author A, SA is
total occurrence of test document tokens in training set of Author A, FA is total
frequency of tokens in training set of the corresponding author and T is total
number of tokens in test document.
In the above formula, T , being a constant denominator, will have no effect
on the probability PA in a relative scale. The division by T will normalize the
Author Identification in Bengali Literary Works 223
probability for documents of different size and it will be effective only when we
would like to find out the more likely document for a candidate author from a
set of test documents.
To calculate the probability metric of a test document for a candidate author,
we need to find out correct tokens from test and training document first. In
our experiment, initially unigram words are considered as the feature set for
classification. In this step, all unigram words are taken as individual tokens to
calculate the simple probability metric PA mentioned earlier. In the next step,
bi-gram words are considered as the feature set for classification and all the
bi-gram words are taken as individual tokens to calculate the same.
The metric measures the probability of a test document being written by
a candidate author. This classification metrics are calculated for all candidate
authors to quantify the authorship of a test document. A test document is at-
tributed to a candidate author, if the classification metric for that author is
greater than that of other candidate authors.
Suppose there are N candidate authors (A1, A2, . . . , AN ) for a test corpus. A
test document is attributed to a candidate author by using the following formula.
If (PAi > PAj) for j = 1 to N and i = j
Test document is attributed to author Ai
The authorship attribution approaches are distinguished in mainly two ways
according to the extraction of authors’ style cumulatively or individually. In
profile-based approach, all the training texts per author are concatenated in a
file. On the other hand, each training text is individually represented in sep-
arate files for instance-based approach. We prefer instance-based approach for
attributing authorship from the test collection.
4 Details of the Collection
We used test collection of Bengali documents consisting of Rabindranath Tagore
and Bankim Chandra Chattopadhyay’s novels and Sukanta Bhattacharyay’s po-
ems in our experiment. There are total 36 documents (13 novels by Rabindranath
Tagore (RT), 14 novels by Bankim Chandra Chattopadhyay (BCC) and 9 poems
by Sukanta Bhattacharyay (SB)) in the complete set of test collection. Detailed
statistics of the test collection are given in the Table 3.
Table 3. Detailed statistic of the test collection
Author Name Genre No. of Docs Total No. of Tokens No. of Unique Tokens
Rabindranath Tagore (RT) Novel 13 594757 40626
Bankim Chandra Chattopadhyay (BCC) Novel 14 381119 36016
Sukanta Bhattacharyay (SB) Poem 9 1093 691
There are several steps in our experiment. In each steps, we choose 30%, 50%
and 70% documents respectively from the collection of each candidate authors
224 S. Das and P. Mitra
as training data set. The selection of training data set was done randomly. The
remaining documents are attributed on the basis of this training data set. Divi-
sion of the whole corpus into training set and test set are tabulated in Table 4,
when 30%, 50% and 70% of data from individual authors are used for training.
Table 4. Division of whole corpus into training set and test set when 30%, 50% and
70% data used for training
30% data used for training 50% data used for training 70% data used for training
Author
Name
No. of
docs
No. of docs in
training set
No. of docs
in test set
No. of docs in
training set
No. of docs
in test set
No. of docs in
training set
No. of docs
in test set
RT 13 4 9 7 6 9 4
BCC 14 4 10 7 7 10 4
SB 9 3 6 4 5 6 3
Total 36 11 25 18 18 25 11
5 Experimental Results
All the experiments have been done on the test corpus, mentioned earlier. In
the first stage of our experiment, unigram words and vocabulary richness are
taken as feature set. In this case at first 30% of documents from the collection
of each candidate authors are selected randomly to train the classifier. So out
of total 36 documents, 11 documents are selected for training set. Remaining
25 documents are classified on the basis of the training data set. In the next
step, 50% and 70% data from each author are used for training and remaining
documents are classified. Lastly each and every document is classified when all
the remaining documents are used as training set. The percentages of correctly
classified documents, taken unigram words as the feature set, are tabulated in
the Table 5.
Table 5. Rate of correctly classified documents when unigram words are taken as
feature set
No. of docs in training set No. of docs to
be classified
No. of correctly
classified docs
Percentage of cor-
rect classification
11(30% from each candidate authors) 25 19 76.00%
18 (50% from each candidate authors) 18 14 77.78%
25 (70% from each candidate authors) 11 9 81.82%
35 (All the documents except the test case) 36 33 91.67%
From this observation, it is seen that the percentage of correct classification
is improved with increasing size of training set.
In the next stage, same thing has been done except the selection of feature set.
As feature set, bi-gram words and vocabulary richness are selected in this case.
Similarly 30%, 50% and 70% data from individual authors is trained to classify
remaining documents on the basis of new feature set. Then every document is
Author Identification in Bengali Literary Works 225
classified separately when remaining documents are used as training data. In this
case, there was a huge improvement in the percentage result. The percentages
of correctly classified documents, taken bi-gram words as the feature set, are
tabulated in the Table 6.
Table 6. Rate of correctly classified documents when bi-gram words are taken as
feature set
No. of docs in training set No. of docs to
be classified
No. of correctly
classified docs
Percentage of cor-
rect classification
11(30% from each candidate authors) 25 25 100.00%
18 (50% from each candidate authors) 18 18 100.00%
25 (70% from each candidate authors) 11 11 100.00%
35 (All the documents except the test case) 36 36 100.00%
From this observation, it is obvious that as a feature set, bi-gram words are
good enough to classify authorship of the Bengali corpus. Even a small size of
training data can quantify the authorship of test documents correctly.
6 Conclusion
It is evident from our experiment that the attribution results strongly depend on
the size of test corpus as well as proper feature set selection. In our experiments,
only some lexical features are taken into account. Using some advanced feature
or combination of some features on Bengali test collection may result better.
Many machine learning techniques like principle components analysis (PCA),
support vector machines (SVM) can be used to quantify authorship of Bengali
test documents in recent future. The application of the well-known tf-idf (term
frequency*inverse document frequency) [20] principle for unigram and bi-gram
features can also be useful. The main problem with the resource is the unavail-
ability of Bengali literary works by different authors. The three candidate au-
thors in our experiment (RT(1861-1941), BCC(1838-1894) and SB(1926-1947))
belong to distinct generation. So there are some differences in their vocabulary
and style. The availability of many documents by different candidate authors
from the same age and of similar style will validate the effectiveness of this
method. In general, this result can be generalized to classify blog writers, detect
plagiarism in Bengali also.
References
1. Mendenhall, T.C.: The characteristic curves of composition. Science ns-9, 237–246
(1887)
2. Zipf, G.K.: Selected Studies of the Principle of Relative Frequency in Language.
Harvard University Press, Cambridge (1932)
3. Yule, G.U.: The Statistical Study of Literary Vocabulary. Cambridge University
Press, Cambridge (1944)
226 S. Das and P. Mitra
4. Mosteller, F., Wallace, D.L.: Inference and Disputed Authorship: The Federalist.
Addison-Wesley, Reading (1964)
5. Burrows, J.F.: Word patterns and story shapes: The statistical analysis of narrative
style. Literary and Linguistic Computing 2, 61–70 (1987)
6. Burrows, J.F.: Not unles you ask nicely: The interpretative nexus between analysis
and information. Literary and Linguistic Computing 7, 91–109 (1992)
7. Binongo, J.N.G., Smith, M.W.A.: The application of principal component analysis
to stylometry. Literary and Linguistic Computing 14, 445–466 (1999)
8. Holmes, D.I., Robertson, M., Paez, R.: Stephen crane and the new-york tribune:
A case study in traditional and non-traditional authorship attribution. Computers
and the Humanities 35, 315–331 (2001)
9. Burrows, J.F.: Delta: a measure of stylistic difference and a guide to likely author-
ship. Literary and Linguistic Computing 17, 267–287 (2002)
10. Burrows, J.F.: The englishing of juvenal: Computational stylistics and translated
texts. Style 36, 677–699 (2002)
11. Kjell, B., Woods, W.A., Frieder, O.: Information retrieval using letter tuples with
neural network and nearest neighbor classifiers. In: IEEE International Conference
on Systems, Man and Cybernetics, Vancouver, BC, vol. 2, pp. 1222–1225 (1995)
12. Baayen, H., Van Halteren, H., Tweedie, F.: Outside the cave of shadows: Using
syntactic annotation to enhance authorship attribution. Literary and Linguistic
Computing 11, 121–132 (1996)
13. Juola, P., Baayen, H.: A controlled-corpus experiment in authorship identification
by cross-entropy. Literary and Linguistic Computing 20, 59–67 (2005)
14. Zhao, Y., Zobel, J.: Searching with style: Authorship attribution in classic lit-
erature. In: Proceedings of 30th Australasian Conference on Computer Science,
vol. 62, pp. 59–68 (2007)
15. Stamatatos, E.: Author identification: Using text sampling to handle the class
imbalance problem. Information Processing & Management 44, 790–799 (2008)
16. Koppel, M., Schler, J., Argamon, S., Messeri, E.: Authorship attribution with thou-
sands of candidate authors. In: Proceedings of the 29th ACM SIGIR, pp. 659–660.
ACM Press, New York (2006)
17. Mansur, M., UzZaman, N., Khan, M.: Analysis of n-gram based text categorization
for bangla in a newspaper corpus. In: Proceedings of 9th International Conference
on Computer and Information Technology, Dhaka, Bangladesh (2006)
18. Stamatatos, E.: A survey of modern authorship attribution methods. Journal of
the American Society for Information Science and Technology 60, 538–556 (2009)
19. Mitchell, T.M.: Machine Learning. McGraw-Hill, New York (1997)
20. Manning, C., Raghavan, P., Schutze, H.: Introduction to Information Retrieval.
Cambridge University Press, Cambridge (2008)
