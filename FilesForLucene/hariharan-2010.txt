V.V Das et al. (Eds.): BAIP 2010, CCIS 70, pp. 497–500, 2010. 
© Springer-Verlag Berlin Heidelberg 2010 
Detecting Plagiarism in Text Documents  
Shanmugasundaram Hariharan1, Sirajudeen Kamal2, Abdul Vadud Mohamed Faisal2, 
Sheik Mohamed Azharudheen2, and Bhaskaran Raman2 
1 Assistant Professor, Department of Information Technology 
B.S. Abdur Rahman University, Chennai-48, Tamilnadu, India 
2 Student, Department of Information Technology 
B.S. Abdur Rahman University, Chennai-48, Tamilnadu, India 
{mailtos.hariharan,kamal66077,ramancre}@gmail.com, 
{azhar_cres,bruce_faisal}@yahoo.com 
Abstract. Plagiarism aims at identifying the amount of information that is 
copied or reproduced in modified representation of original documents. This 
is quiet common among students, researchers and academicians that leads to a 
kind of unrecognizing. Though there exits some commercial tools to detect 
plagiarism, still plagiarism is tricky and quiet challenging task due to 
abundant information available online. Commercially existing softwares 
adopt methods like paraphrasing, sentence matching or keyword matching. 
This paper focuses its attention on identifying some key parameters that 
would help to identify plagiarism in a better manner and to report plagiarism 
in an effective way. The result seems to be promising and have further scope 
in detecting the plagiarism.  
Keywords: Plagiarism, similarity metric, paraphrasing, sentence matching. 
1   Introduction 
Plagiarism defined as the use or close imitation of language and thoughts of another 
author and the representing them as their one's work. Plagiarism affects the education 
quality of the students and there by reduce the economic status of the country which is 
done by techniques like paraphrasing or similarities between keywords and verbatim 
overlaps, change of sentences from one form to another form [7]. Internet has 
changed the student’s life and also has changed their learning style. It allows the 
student to deeper the approach towards learning and making their task easier. 
Detecting plagiarism in a mass of students is difficult and also they are expensive too. 
Hence automated tools like Beagle were created [10] that work on the basis of similar 
text that matches, automated computer algorithms [8, 9] were proposed for automatic 
plagiarism detection. Students do learn the art of cheating and in common practice 
these plagiarism methods are hard to identify. Some of these methods includes 
copying of textual information, paraphrasing (representing same content in different 
words), using content without reference to original work, artistic (presenting same 
work using different forms),code plagiarism, misinformation of references (adding 
reference to incorrect or non existing source)[5].  
498 S. Hariharan et al. 
2   Related Works 
Dominic Keuskamp et al. [1] examined how well text-matching software can 
contribute to the academic language and learning in developing integrity among 
students. This software generates the report which contains the percentage of text that 
matches with the source document with percentage of matching text shown as 
highlights. Benno Stein et al [2] presented a workshop on topic plagiarism analysis, 
authorship identification, and high similarity search. They prefer similarity based 
metric to detect plagiarism. The authors distinguished between the corpus based 
approach and the intrinsic analysis. They also check the suspicious document against 
the original document. Hybrid plagiarism detection approach using diagonal line and 
simplified Smith-Waterman algorithm is also considered as a classical tool in 
identifying similarities [4].  
Romans Lukashenko et al. [5] have mainly focused on the corpus used, as it is 
needed to assign numeric value, so called, similarity score to each document. These 
obtained score is used for contents analysis either based on semantics or statistical 
approach. The advancement in information technologies made huge amount of data to 
be gathered in the internet at a rapid speed [6]. People use search engines to find what 
they need in order to solve the data overloading problem. Plagiarist can be 
reassembled, grabbed and redistributed without much difficulty. As a prelude an 
intelligent system to reduce the misapplication of search engines was also developed. 
Suspicious documents were tested by collaboration with plagiarism detection system 
and search engines. The extracted text segments are given different priorities with a 
proper design and pattern.  
3   Experimental Section 
The corpus for detecting plagiarism was collected from set of 120 students, spitted 
into 40 groups from various departments like Electrical, Electronics, Mechanical, 
Computer Science, Information Technology and Civil engineering. There were 414 
words, 33 sentences and 9 words in a sentence on an average for the corpus 
constituted. The proposed system design performs the following tasks. 
• Tokenization of documents into sentence format. 
• Preprocessing of documents by removal of stop words & stemming [3]. 
• Measuring the similarity of each sentence using cosine metric[3]  
• Detecting plagiarism among sentences. 
We focus on comparing our approach with that of article checker. Commercial tools 
do search for the exact words or sentences online. If those words are not available, 
they fail report plagiarism. We made a study pertaining to assignments collected by 
the students and asked them even to quote the exact reference from which they have 
copied. All these data’s were stored in the warehouse and retrieved for processing. 
We could find that by significantly removing the stop words and applying stemming, 
we would identify plagiarism in a better way. Table 1 presents a sample sentence 
pairs showing the original and plagiarized sentence. The percentage of plagiarism  
 
 Detecting Plagiarism in Text Documents 499 
detected is also reported. Our approach forms the term frequency table and measures 
the relevancy among sentences using the cosine metric, which is used as default 
standard for measuring content relevancy in Vector Space model. Please note this 
value is obtained after preprocessing. Based on the term frequency table obtained, the 
cosine similarity value is 0.89 (i.e. 22/ 24.64).  
Table 1. Plagiarism detected using commercial tool and our approach 
Article 
Checker 
Our  
Approach 
Original sentence: In electrical engineering and computer 
science, image processing is any form of signal processing for which 
the input is an image, such as photographs or frames of video; 
the output of image processing can be either an image or a set of 
characteristics or parameters related to the image. 
Plagiarised sentence: Image processing is modifying the input image 
such as photographs or frames of video to image or a set of 
characteristics or parameters related to the image. 
Reference  source:http://en.wikipedia.org/wiki/Image_processing 
19% 89.28% 
4   Conclusion and Future Improvements 
The proposed algorithm focuses on to preprocess the documents effectively and then 
identifies plagiarism in a better way as compared to commercial Article checker tool. 
When the content is represented as non textual forms like tables, forms or as images, 
we do not report such plagiarism which is left for future extensions. Improper editing 
of reference and detecting plagiarism from it is also left for future work. 
References 
1. Keuskamp, D., Sliuzas, R.: Plagiarism prevention or detection? The contribution of text-
matching software to education about academic integrity. Student Learning Centre, 
Flinders University, Adelaide SA 5001, Australia, pp. 91–99 (2007) 
2. Stein, B., Koppel, M.: Plagiarism Analysis, Authorship Identification and Near-Duplicate 
Detection. ACM SIGIR Forum 41(2), 68–71 (2007) 
3. Hariharan, S., Srinivasan, R.: A Comparison of Similarity Measures for Text Documents. 
J. Information & Knowledge Management 7(1), 1–8 (2008) 
4. Su, Z., Ahn, B.R., Eom, K.O., Kang, M.K., Kim, J.P., Kim, M.K.: Plagiarism Detection 
Using the Levenshtein Distance and Smith-Waterman Algorithm. In: Proceedings of 
Intetnational Conference on Innovative Computing Information and Control, ICICIC 2008 
(2008) 
5. Lukashenko, R., Graudina, V., Grundspenkis, J.: Computer-Based Plagiarism Detection 
Methods and Tools: An Overview. In: Proceedings of International Conference on 
Computer Systems and Technologies - CompSysTech 2007, pp. IIIA.18-1– IIIA.18-6 
(2007) 
6. Liu, Y.T., Zhang, H.R., Chen, T.W., Teng, W.G.: Extending Web Search for Online 
Plagiarism Detection. In: Proceedings of International Conference on Information Reuse 
and Integration, pp. 164–169 (2007) 
500 S. Hariharan et al. 
7. Uzuner, O., Katz, B., Nahnsen, T.: Using Syntactic Information to Identify Plagiarism. 
Massachusetts Institute of Technology Computer Science and Artificial Intelligence 
Laboratory Cambridge, pp. 37–44 (2005) 
8. Parker, A., James Hamblen, O.: Computer Algorithms for Plagiarism Detection, pp. 94–99 
(1989) 
9. Engels, S., Lakshmanan, V., Craig, M.: Plagiarism Detection Using Feature-Based Neural 
Networks (2007) 
10. Adeva, J.J.G., Carroll, N.L., Calvo, R.A.: Applying Plagiarism Detection to Engineering 
Education. School of Electrical and Information Engineering, University of Sydney (2006) 
