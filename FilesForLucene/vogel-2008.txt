Computational Stylometry:
Who’s in a Play?
Carl Vogel and Gerard Lynch
Centre for Computing and Language Studies,
School of Computer Science and Statistics,
Trinity College Dublin, Dublin 2 Ireland
{vogel,gplynch}@tcd.ie
Abstract. Automatic text classification techniques are applied to the problem of
quantifying strength of characterization within plays, using a case study of the
works of four sample playwrights that are freely available in machine-readable
form. Strong characters are those whose speeches constitute homogeneous cate-
gories in comparison with other characters—their speeches are more attributable
to themselves than to their play or their author.
Keywords: Computational stylistics, text classification, forensic linguistics.
1 Introduction
We report on experiments in text classification for computational stylistics. Automatic
text classification techniques are fervently under research, development and exploita-
tion, widely used in their current state for a wide range of tasks: authorship attribution,
lexicography, news analysis, spam filtering, sentiment analysis, ontology extraction,
social network analysis. The tasks, whatever similarity metric is employed, in general
have common features: assessment of similarity of a text to a category of texts with a
quantifiable degree of certainty, assessment of homogeneity of categories. In our work,
we have been extending methods from the literature in assessing the former, and have
adopted a common-sense approach to the latter, with respect to both the a priori cate-
gory appropriate to a category, and the categories that are appropriate post hoc by virtue
of clustering under the objective similarity metrics. Interestingly, many of the successful
similarity metrics are based on comparisons of distributions of sub-lexical features—
letter n-gram distributions and not directly lexical or part of speech distributions.
The work described here uses computational stylometry to assess the homogene-
ity of individual textual contributions of characters in dramatic works, and hence the
heterogeneity of characters and plays constructed by authors, thus contributing a new
kind of analysis to computational stylistics. Moreover, the techniques discussed here
have applications outside dramatic or other literary works. We have, for example, ap-
plied them to measuring a spectrum of non-governmental political parties on the basis
of their election manifestos, for example [23], within a robust area of research in con-
temporary political science [13,12]. The methods are related to those explored in work
on forensic linguistics for authorship attribution [2,3]. They have further potential ap-
plication in the domain of human-computer interaction in assessing intelligent avatars.
A. Esposito et al. (Eds.): HH and HM Interaction 2007, LNAI 5042, pp. 169–186, 2008.
c© Springer-Verlag Berlin Heidelberg 2008
170 C. Vogel and G. Lynch
Recent work in this area focuses on alignment of behavior (verbal and nonverbal) of
artificial agents interacting with humans [17], as humans experience some degree of
conversational alignment in human-human interactions. Just as these techniques have
been applied to measuring the degree of alignment in such human interactions [8], they
can also be used to evaluate the levels of realism in alignment in human-machine inter-
actions. Presumably one would like to parameterize the functionality of avatars’ adap-
tive verbal behaviors so that some may become indistinguishable from those of their
interlocutor, and others may retain their designed distinctive style of communication.
Here we examine these techniques as applied to questions of stylistics. This follows
on from recent work in classifying poems within a single author’s writings in terms of
the poetic persona constructed within and across poems [26]. There it was found using
directly comparable techniques that distinctive persona could be individuated within
and across poems in the canon of Brendan Kennelly, clustering in positive correlation
with subjective reading of the poetry. Separate from the questions of whether one indi-
vidual is responsible for the complete works of Shakespeare, or whether that one indi-
vidual was William Shakespeare, there are questions about that canon associated with
its attributed greatness that are worth exploring using objective techniques. The ques-
tion of whether the corpus of Shakespeare plays is homogeneous is really one about the
probability that all of the works were authored by the same person. More finely grained
questions can be posed with respect to characterization within the plays. For example,
it may well be the case that the constraints of iambic pentameter impose constraints on
sub-lexical features of the texts that render individual characterization impossible, bar
use of proper nouns.
We explore characterization within plays that are confined to metric verse, (Jonson
and Shakespeare) and those not in verse at all (Wilde and Shaw). Of course, in such a
limited sample, any results that emerge might have to do with the issue of being verse
or prose, time of writing, national heritage of the author, or other predictable or un-
predicted confounding factors. Nonetheless, we think this is a useful starting point in a
larger scale analysis of this sort. In particular, we are interested in applying the ques-
tion of textual similarity and homogeneity to characters within plays. We quantify the
extent to which, for example, the texts associated with Romeo are most like Romeo,
as opposed to texts of other Shakespearean characters or characters of the other play-
wrights analyzed, most like Romeo and Juliet as opposed to the other plays considered,
and most like the Shakespearean canon. We do so for each character, play and author.
The findings are that the characterization provided by George Bernard Shaw was
significantly distinctive. The specific results depend on the number of files under con-
sideration, as elaborated in the rest of the paper. For example, individuating files into
unbroken word units of approximately 1,000 letters, spaces and punctuation marks, the
most homogeneous character in the set of plays considered was Merc in Cynthia’s Rev-
els. The next most distinctive characters are: Tuc from Jonson’s Poetaster (ironically
enough); Octavius from Shaw’s Man and Superman, Rufio from Caesar and Cleopa-
tra, and Androcles from Androcles and the Lion; Shakespeare’s King Henry from Henry
the VII, Part I. If the files are individuated at twice the size, then some characters are
removed from consideration (see “Methods” section) because there is insufficient as-
sociated text to have at least five files in that a priori category, and this has an impact
Computational Stylometry: Who’s in a Play? 171
on homogeneity of the remainder, yet Shaw’s Rufio remains consistent. Jonson has the
most distinctive character, and Shaw the greatest number of such characters.
If one were to apply an aesthetic judgment to the form of analysis constructed here it
would be attached to the capacity of a writer to develop distinct homogeneous charac-
ters. On this analysis, the playwright is remarkable to the extent that the characters are
distinct and more identifiable with the rest of the character’s constructed speech than
with their playwright. Identifiability of characters with their play, on the basis of textual
similarity alone, is a measure of the individuality of that play within the writer’s canon.
That is, the background aesthetic considered here is that a combination of internal ho-
mogeneity within characterization and within-canon heterogeneity of texts jointly con-
tribute to objectively measurable indices of a writer’s control over language. In terms
of methodology, the outcome is clear that the number of categories chosen from has
an impact on the likelihood of homogeneous categories emerging, and correspondingly
interacts with the method used for assessing homogeneity.
We briefly describe the background to the analytical tools we use, then give details on
the exact method we used to individuate files and analyze them. The file sizes employed
are small, in part because this is representative of the demands of attribution tasks in
forensic linguistics; first we report on an experiment with files of about 1000 bytes
per file, and five files per character, then a second set of experiments replicates the
study with double the file size, and a third set of experiments limits the total number
of available files (some sources are larger and have more possibilities from which to
sample). We present the results in more detail, and then emphasize the main results.
The methods do appear to reveal homogeneity in author style in that the plays are more
distinctive of their authors, in general, than the characters are to their plays, in the small
pool of literature considered here. Secondly, the precise findings per character, given
their heterogeneity, is highly dependent on the sampling parameters, particularly the
number of files to draw on to constitute an a priori category.1
2 Background
We assume a method for parsing plays into the contributions of their characters [15].
This method allows us to individuate characters of plays by their entire textual contri-
bution, separated into files of balanced size. The text associated with characters in the
plays is divided into units that we can sample arbitrarily. The analysis we employ is
based on letter n-gram distributions. This follows from our exploration of suggestions
in the literature that this level of tokenization is most efficacious for authorship attribu-
tion tasks in forensic linguistics, and because of replicability, fit for the Daubert test of
expert evidence in a court of law [2]. The suite of programs we have developed allows
tokenization by n-grams for arbitrary values of n at the level of letter, word, or part of
speech tag (we use TreeTagger [21] and its English parameter file, in general; however,
here we report only on letter unigram analysis). At first blush, comparison of letter
1 For ease of expression, we refer to files of a character “finding their character”, “finding their
play” or “finding their author” among natural a priori classifications, and we also examine
instances of maximal similarity to alternative categories (other characters, plays or authors)
represented in the data set.
172 C. Vogel and G. Lynch
unigram distributions do not seem to offer great face validity as a procedure through
which to measure textual similarity. However, an individual with a Latinate vocabulary
may be more inclined to use the words “equestrian” or “aquifer” than “horse-riding”
or “water-table”, and will thus have a distinctive distribution of the letters Q and U, for
example. Letter bigram analysis perhaps more directly approximates English morphol-
ogy expressed orthographically; however, bigrams have unigrams as constituents, and
not all morphemes are limited to two-letter sequences. This is not to say that bigram
analysis is fruitless. On the contrary, we employ it regularly. For example, [7] uses
an analysis quite like the one reported here, but addressed to documents rather than
characters within documents, employing mainly letter bigrams in an analysis of a large
diachronic corpus of Latin texts to date “The Donation of Constantine”; there the tech-
niques evaluate favorably, corroborating philological theory dating from the 15th Cen-
tury [4], placing the text as a relatively good 8th century forgery of a 4th century style.
One could also use word level analysis (and words also have letters as constituents), but
this introduces the problem of lemmatization of words, and other issues about how to
individuate distinct types, issues that do not emerge at the level of letters. Part-of-speech
analysis would also be possible, but reliable automatic tagging of Shakespearean text
is not promising, and hand tagging is prohibitive. Independent evidence also exists for
a relationship between part of speech distributions and letter sequence distributions, to
the extent that orthography is representative of natural language phonology: recently
it has been shown that nouns and verbs tend to cluster as grammatical categories on
the basis of phonological properties of the words in those categories [5]. Thus, sub-
lexical features are relevant to higher level linguistic categories in a number of respects.
Whichever level of tokenization chosen, selecting larger values for n creates greater
data sparseness problems. We have argued (and are not alone in arguing) for the mer-
its of letters as an appropriate and efficacious level of tokenization, and within that we
have worked with unigrams and bigrams extensively.2 As the results have largely been
consistent across choices of n for letter-tokenization, we have tended to report, as we
do here, on representative results within a single choice for n. Here, it is letter unigram
analysis.
The assessment of similarity among distributions of tokens in general is adopted
from work using word frequency distributions [11,10]. The method [25] computes a
χ2 value (which thus relativizes to file size) that accumulates for each token compared
between two files and in the end divides by the total number of comparisons. Suppose
one has two files, 1 and 2, | 1 | and | 2 | denote the number of tokens in each file and
|| 1 || and || 2 || denote the total number of distinct tokens in each file (or in other
words, the total number of token-types in each file; necessarily, || i ||≤| i | for any file
i). The total number of token-types (TTT ) between the two files is given in (1)
(1) TTT
.=|| 1 || + || 2 ||
If k token-type and i is a file, let o(i, k) denote the number of observed instances of
that type in file i. If two files come from the same population, then taking into account
file size differences, the observed value for any token type should yield expected values
2 Nonetheless, we also explore the other levels of tokenization and sequence length, but do not
undertake each level of analysis for each study.
Computational Stylometry: Who’s in a Play? 173
within a certain range. Let e(i, k) be the expected number of observations of tokens of
type k in file i. Thus (2) gives the expected number of occurences of an individual type
in the first file, and (3) gives the method to calculate the expected values for the second
file in the two files being compared.
(2) e(1, k) .= (o(1, k) + o(2, k)) ∗ |1||1|+|2|
(3) e(2, k) .= (o(1, k) + o(2, k)) ∗ |2||1|+|2|
So, suppose two files of different sizes—file 1 might have 100 instances of Q in its 1000
letters and 2 might have 12 instances of Q in its 4000 letters. The expected value of Q
for 1 is 112 * 1000/5000, or about 22, while the expected value for file 2 is 112 * 4/5, or
about 90. The actual χ2 value pools expected and observed values across token types as
in (4), to measure how far the distribution actually is from what it would be if the texts
are drawn from the same population at random.
(4)
TTT∑
k=1
(
(o(1, k) − e(1, k))2
e(1, k)
+
(o(2, k) − e(2, k))2
e(2, k)
)
The sum in (4), divided by the number of degrees of freedom, (TTT − 1) gives a cu-
mulative χ2 value as a measure of similarity between the two files. When the value is
less than the significance cut off point (3.86) normally used to assess whether two dis-
tributions are significantly different, one can infer that the two files are not significantly
different in their distributions of the tokens.3 The value is computed for all pairwise
comparisons of files and can be used as a rank index of similarity of files within cate-
gories. Given a collection of files, the files have natural a priori categories (all speeches
by the same politician [9], all segments of the same political party manifesto [23], all
texts on a comparable legislative topic [16] all composed by the same writer, all com-
prising the text of one character’s contribution, etc). This averaged χ2 value provides
an index that can be used to rank order the compatibility of each file with respect to
its a priori category and alternatives. A file treated in this respect can have statistically
significant compatibility (using the Mann-Whitney rank ordering test) with a number
of categories. A separate test is conducted to quantify the significance of a subset of
files from a category being classified in the same way. The common-sense method we
use to assess category homogeneity, whether evaluation of an a priori category or to
test the likelihood of objective clustering on the basis of mutual similarity using the χ2
method with some other category, is in relation to the fairness of a c-sided coin (where
c is the number of possible categories) in repeated experiments of n tosses (where n is
the number of files in the category; and r is the number of times that the category comes
3 It is an average χ2 over each comparison of individual token-types and their frequencies in
the two files. It is also possible to examine the specific points, the specific token types, at
which the files differ significantly. But for this reasoning and rejecting the null hypothesis of
similarity, the normal constraints on χ2 hypothesis testing apply, like having a minimum of
five observed values in both cells. This constraint does not apply when using the value as an
index of similarity instead.
174 C. Vogel and G. Lynch
up as a best fit). The Bernoulli formula is given in (5), where the fairness/randomness
hypothesis associated with the c-sided coin can be rejected when a category comes up
often enough for the value of p such that p ≤ 0.05. In practice, we actually simulate
the experiments of tossing c-sided coins for the category size related number of tosses
hundreds of times to establish the cut-off point to use in determining significance for
some number of files to be classified within a priori or a posteriori categories [24].
(5) p
.= n!r!(n−r)! × (1c )r × (1 − 1c )n−r
We thus begin by individuating a corpus under scrutiny into individual files, and relevant
categories. In the experiments here the files are of balanced size, and with an equal
number of files in each category. In each case, the files are determined by arbitrary
selection of contiguous subsets of a character’s contributions to a play. We explore
whether the files so constructed for a character are more like the other files of that
character or some other character in the pool; whether the files of that character are more
like those of the rest of the play the character appears in or the other plays; whether the
files of character are more like those of the rest of the author of the character than those
of the other authors under consideration.
3 Method
Project Gutenberg4 provides the source of the plays considered here: Androcles and
the Lyon, Caesar and Cleopatra, Candida, Man and Superman and Pygmalion (Shaw);
An Ideal Husband, The Importance of Being Earnest, Lady Windermere’s Fan and A
Woman of No Importance (Wilde); The Alchemist, Cynthia’s Revels and Poetaster (Jon-
son). We also include a gamut of Shakespeare’s plays.5 Selections were made to have
three or four Shakespeare works at a time for some experiments, as described below.
We did not control for type by selecting from among the histories only, or tragedies
only, say. The plays were parsed into files of the consecutive lines of speech associated
with individual characters [15]. Sampling from the characters was constrained to occur
only when the character was represented by sufficient text for the experiment at hand.
In the first instance, each character was represented by five thousand letters (including
spaces and punctuation), divided into five files each.
A second range of experiments replicated this using double the file size. Similarly,
we look at whether the characters’ files find firstly their plays and secondly authors. To
examine the role of sampling, we repeat the experiment with an alternative sampling
from the same data set. Importantly, the sampling in each case is randomized, so the
same segments of each character are not necessarily repeated in each experiment. This
4 http://www.gutenberg.org/ – Last verified October 27, 2007.
5 They were: Anthony and Cleopatra, As You Like It, Comedy of Errors, Coriolanus, Cymbeline,
Hamlet, Henry the 4th Part1, Henry the 4th Part2, Henry the 6th Part1, Henry the 6th Part2,
Henry The Eighth, Henry The Fifth, Julius Caesar, King John, King Lear, Loves Labor Lost,
Macbeth, Measure for Measure, Merchant of Venice, A Midsummernight’s Dream, Much Ado
about Nothing, Othello, Richard The Second, Richard The Third, Romeo and Juliet, Taming of
the Shrew, The Tempest, Timon of Athens, Titus Andronicus, Twelfth Night, The Winter’s Tale.
Computational Stylometry: Who’s in a Play? 175
is because if the character is homogeneous, for example, then homogeneity should be
robust across samples. This sampling method resulted in a total of 1240 files used in
the experiments in their entirety. In testing characters finding their authors, we first con-
sider sampling from Shakespeare plays that balance samples against those available from
other playwrights. We are interested in the best match and the most significant alternative
match. As there were significantly more Shakespeare plays available via Project Guten-
berg than those of the other writers, we constructed average comparisons using groups
of four Shakespeare plays chosen arbitrarily in a series of 100 comparable experiments.
Thus, the Shakespeare plays changed, while those of the other writers were held fixed.
The files are individuated as described above for all of the experiments. What varies
is the sampling from them, and the relevant a priori category. In reporting results in the
next section, it is sometimes helpful to present them using category cross-classification.
Experiment 1: Characters to themselves.
The a priori category assigned to sets of files is the name of the character speak-
ing. This is repeated three times, each with five files per character and the number
of characters per play depending on the availability of sufficient text. In the first
test, the file sizes are 1KB and in the subsequent two independent samplings, the
file sizes are balanced at 2KB. In this experiment, balancing by playwright is not
performed. Thus, Shakespeare has many more characters under consideration. That
should not impact a study of characters finding themselves (as opposed to charac-
ters finding their authors). While the same character or play may be represented
in each of the three experiments, the same speech may well not, because of the
balance in the size of the files sampled.
Experiment 2: Plays to their plays
The a priori category assigned to a file is the name of the play containing the
speech. Thus, there are 42 categories. This is repeated three times exactly as above.
We identify the play that is the overall significantly most similar in its constituent
text (which is not necessarily the play itself), and the best matching alternative.
Experiment 3: Characters to their play.
The a priori category of a file is the name of the play the speech is part of. Sampling
is based just on 2K file sizes. Of interest is which characters within plays are the
strong ones: which characters’ speeches are significantly identifiable with their play
via overall textual similarity. Again, the “best match” alternative is noted.
Experiment 4: Characters to their author.
The a priori category is the author’s name. Sampled files were 2K. We note which
characters are significantly attributed to their author, and significant alternatives.
Experiment 5: Authors to themselves.
The a priori category is the author’s name. Sampling is based just on 2K file sizes.
We use 10 characters per playwright, 5 files to each character. Results shown aver-
age over 100 such samplings. Best alternatives are examined.
4 Results and Discussion
4.1 Experiment 1: Characters Find Themselves
Table 1 indicates the number of characters examined across the 42 plays addressed who
turned up as distinctive. In this table, we consider by play, a number of characters from
176 C. Vogel and G. Lynch
Table 1. Number of Homogeneous Characters from Each Play ( # Homogeneous# Considered )
Play 1K 2K I 2K II
TheAlchemist 0/6 1/3 1/3
CynthiasRevels 3/10 3/5 2/5
Poetaster 4/10 1/4 1/4
Androcles 1/4 n/a n/a
CaesarCleo 1/6 2/3 2/3
Candida 0/4 1/3 1/3
ManAndSuperman 6/13 4/7 4/7
Pygmalion 1/6 2/3 1/3
AWomanOfNoImportance n/a 3/5 3/5
AnIdealHusband 2/7 1/4 2/4
Earnest 2/6 3/5 2/5
LadyWindermeresFan 0/5 1/4 2/4
AntCleo (WS) 0/4 1/4 2/4
AsYouLike 0/6 0/4 0/4
ComedyErrors 0/5 3/3 1/3
Coriolanus 1/7 3/6 0/6
Cymbeline 0/6 0/6 2/6
Hamlet 0/7 1/4 1/4
Henry4thPart1 0/5 2/4 1/4
Henry4thPart2 0/5 0/2 0/2
Henry6thPart1 3/5 0/2 0/1
Henry6thPart2 0/5 0/5 2/5
Play 1K 2K I 2K II
HenryTheEighth 1/5 0/3 1/3
HenryTheFifth 1/3 0/2 1/2
JuliusCaesar 1/4 0/3 0/3
KingJohn 1/3 2/3 0/3
KingLear 2/5 1/4 0/4
LovesLabor 1/8 0/4 0/4
Macbeth 0/3 0/2 0/2
Measures 0/4 0/4 0/4
MerchantVenice 2/6 0/3 0/3
MidSummerDream 1/6 0/1 n/a
MuchAdo 1/5 0/5 0/5
Othello 0/6 0/4 0/4
Richard2 0/7 0/3 0/3
RichardTheThird 1/8 0/5 0/5
RomeoJuliet 0/6 1/5 1/5
TameShrew 0/8 1/2 0/2
TheTempest 1/5 0/1 0/1
Timon 1/3 0/1 0/1
TitusAndronicus 1/6 0/4 1/4
TwelfthNight 1/6 1/5 1/5
WinterTale 0/8 2/5 2/5
the play with sufficient text to analyze. The entries indicate how many times the char-
acters found themselves as their most similar category. Examining the results in terms
of the plays they originate from provides a sense of the playwright’s construction of
strong characters across plays. The table’s columns indicate results with file size selec-
tion at 1KB each, at twice that, and at twice that with a secondary arbitrary selection,
as discussed above. The effect of doubling the selection size between the first column
and the second two meant that some characters within plays did not supply sufficient
text for the comparison. Where a play or characters from a play have been excluded
on these grounds, because of insufficient data, the number of characters (indicated in
the denominator in the ratios in the tabular entries) reduces from one column to the
next. Results within a sampling size are stable. It is evident that few characters are par-
ticularly strong. A strikingly large number of Shaw’s characters are self-homogeneous
compared to other writers’ characters and the total number of plays and characters con-
sidered. Jonson’s are also strong.
The individual characters and their level of homogeneity are depicted in Table 2. In
this table, just the results for the small file size is reported. The category sizes (five
files per character) and total number of categories is such that homogeneity achieves
significance in the c-sided fair coin tossing experiment described above for about one
sixth of the characters considered. The first column of this table indicates the name
of a character and the play from which the character originates. Only the significantly
(p < 0.05) homogeneous characters are reported. There are 248 characters in total, so
the changes of two files from its category out of the five, that each character is split into
is already significant. Greater levels of consistent assignment (three, four or five of five)
are very significant, and it is thus safe to reject the hypothesis that the files randomly
fall into that character’s category. This leaves the 41 characters reported in the table
Computational Stylometry: Who’s in a Play? 177
Table 2. Files Assigned Correctly to Their Character
Character Correct
AARONTitusAndronicus 2/5
AGUECHEEKTwelfthNight 2/5
APEMANTUSTimon 2/5
AUFIDIUSCoriolanus 2/5
BeatMuchAdo 2/5
CALIBANTheTempest 2/5
CONSTANCEKingJohn 2/5
OBERONMidSummerDream 2/5
PRINCESSOFFRANCELovesLabor 2/5
TALBOTHenry6thPart1 2/5
PUCELLEHenry6thPart1 2/5
KINGHENRYHenry6thPart1 4/5
PUCKMidSummerDream 2/5
QUEENELIZABETHRichardTheThird 2/5
PORTIAMerchantVenice 2/5
SHYLOCKMerchantVenice 2/5
ANTONYJuliusCaesar 3/5
BUCKINGHAMHenryTheEighth 3/5
CHORUSHenryTheFifth 3/5
LearKingLear 3/5
GlouKingLear 2/5
Character Correct
AlbPoetaster 2/5
HorPoetaster 2/5
VirgPoetaster 2/5
TucPoetaster 4/5
ASOCynthiasRevels 2/5
CRICynthiasRevels 3/5
MERCynthiasRevels 5/5
ANDROCLESAndroclesLion 4/5
RUFIOCaesarCleo 4/5
ANAManAndSuperman 2/5
ANNManAndSuperman 3/5
DONJUANManAndSuperman 2/5
OCTAVIUSManAndSuperman 4/5
THESTATUEManAndSuperman 2/5
STRAKERManAndSuperman 2/5
MRSPEARCEPygmalion 2/5
LadyBracknellEarnest 2/5
GwendolenEarnest 3/5
MRSCHEVELEYAnIdealHusband 2/5
LADYCHILTERNAnIdealHusband 2/5
whose results were significant. What is interesting here is that most of the most famous
Shakespearean characters do not make the list as self-homogeneous.
4.2 Experiment 2: Plays Find Their Play
Tables 3 shows the outcome for files finding their play. This is a measure of the distinc-
tiveness of each play. All of the plays are listed, not just the ones that were significantly
homogeneous. The results show that few plays are internally homogeneous: the play
is not the thing. As an indication of how homogeneous an author’s text is, it is use-
ful to note the best match for false negatives (in this case, constituent files of a play
assigned to some other play) with respect to the a priori category of play, happens to
be to another play by the same author or another. Experiment 5 returns to this issue,
but here it is clear that the Shakespeare plays find other Shakespeare plays, and Wilde
plays find other Wildes, but Shaw’s find Wilde about as much as Shaw, and Jonson finds
mainly Shakespeare. This suggests heterogeneity in the text of Shaw, self-homogeneity
for Shakespeare and Wilde, and homogeneity with respect to Shakespeare for Jonson.
This is demonstrated in Table 4. Only the best alternative indicated—this is individu-
ated as the most frequently nominated alternative category with highest rank ordering
significance for each of the files not most similar to its a priori category. Consider Ham-
let. Only eight of the 35 files in the 1K sample found the same play. Of the remaining
27, the most frequent alternative was Cymbeline. Both of the 2K samplings were such
that none of the Hamlet files were most like other Hamlet files. In one, the best alterna-
tive for half was Coriolanus and in the other the best alternative was only one quarter
of the files being most similar to Cymbeline. Cymbeline and Coriolanus were sampled
178 C. Vogel and G. Lynch
Table 3. Files of Plays Find Their Play ( # Correct# Files )
Play 1K 2K I 2K II
TheAlchemist 1/30 7/15 3/15
CynthiasRevels 16/50 8/25 11/25
Poetaster 4/50 1/20 3/20
AndroclesLion 3/20 Excl. Excl.
CaesarCleo 16/30 8/15 9/15
Candida 4/20 3/15 3/15
ManAndSuperman 14/65 7/35 5/35
Pygmalion 9/30 3/15 1/15
WomanOfNoImportance Excl. 17/25 17/25
AnIdealHusband 30/35 9/20 3/20
Earnest 4/30 3/25 6/25
LadyWinderemeresFan 5/25 2/20 2/20
AntCleo 4/20 16/20 19/20
AsYouLike 4/30 9/20 11/20
ComedyErrors 7/25 9/15 8/15
Coriolanus 16/35 15/30 15/30
Cymbeline 15/30 3/30 6/30
Hamlet 8/35 0/20 0/20
Henry4thPart1 0/25 4/20 5/20
Henry4thPart2 0/25 0/10 0/10
Henry6thPart1 16/25 1/10 4/10
Play 1K 2K I 2K II
Henry6thPart2 8/25 12/25 14/25
HenryTheEighth 2/30 5/15 1/15
HenryTheFifth 0/15 0/10 1/10
JuliusCaesar 2/20 7/15 7/15
KingJohn 0/15 0/15 1/15
KingLear 1/25 3/20 2/20
LovesLabor 1/40 1/20 1/20
Macbeth 1/15 1/10 0/10
Measures 0/20 3/20 0/20
MerchantVenice 4/30 0/15 0/15
MidSummerDream 2/30 0/5 Excl.
MuchAdo 6/25 13/25 11/25
Othello 3/30 1/20 2/20
Richard2 4/35 4/15 3/15
RichardTheThird 8/40 3/25 1/20
RomeoJuliet 1/30 0/25 2/25
TameShrew 3/40 1/10 0/10
TheTempest 1/25 0/5 0/5
Timon 3/15 0/5 0/5
TitusAndronicus 7/30 5/20 6/20
TwelfthNight 6/30 11/25 7/25
WinterTale 10/40 8/25 8/25
for all three of the experiments. Where the sampling results in variability in the results,
in this construction, it suggests that the plays themselves are not homogeneous. It is
consistent with the possiblity that variance depends on the presence of strong charac-
ters from a play in the samples. Recall from Experiment 1 that none of the characters
of Hamlet were strong in the sense studied here. The variablity within the author’s
canon is also consistent with homogeneity of the canon, and correspondingly weak
characterization.
4.3 Experiment 3: Characters Find Their Play
There are 42 categories (plays), with five files per character (2K each), three out of
five matching a category (whether a priori or a posteriori) achieves significance (p ≤
0.05). The tables in (5)-(8) show the results for the characters considered which were
significantly similar to their play (or to some other alternative play). It is evident that
a few of the characters of Jonson and Shaw find their play, and that most of the strong
characters in Shakespeare and Wilde are actually homogeneous with respect to some
other play by the same author. In the tables here, ratios are bracketed in the “correct”
column to show the level of significance for the a priori category when an alternative
category showed actual significance. Also, “n/a” means that there was no significantly
homogeneous alternative. In Table 5, where a cell contains “n/a” and an indication of
a play in parentheses, then two out of the five files matched the play, but that is not
statistically significant. The reason the play is listed is that certain plays are frequently
best matches.
Computational Stylometry: Who’s in a Play? 179
Table 4. Best Alternative Assignment of Files of Plays to Their Play
Play Results for 1k Results for 2k 1 Results for 2k 2
TheAlchemist Henry6thPart1 7/29 Corio. 2/8 Henry6thPart2 5/1
CynthiasRevels Henry6thPart1 7/34 Corio. 4/17 Poetaster 4/14
Poetaster Henry6thPart1 12/46 Corio. 4/19 Henry6thPart2 4/17
AndroclesLion Husband 7/17 Excl. Excl.
CaesarCleo Husband 6/14 Husband 5/7 Husband 5/6
Candida Husband 8/16 CaesarCleo 3/12 CaesarCleo 3/12
ManAndSuperman Husband 18/51 Husband 10/28 Husband 10/30
Pygmalion Husband 8/21 Candida 3/12 Candida 3/14
Woman Excl. Husband 5/8 Husband 5/8
Husband Earnest 2/5 Woman 9/11 Woman 16/17
Earnest Husband 23/26 Husband 13/22 Husband 10/19
LadyWinderemeresFan Husband 9/20 Woman 6/18 Woman 6/18
AntCleo Cymbeline 6/16 Corio. 4/4 Cymbeline 1/1
AsYouLike Cymbeline 8/26 Corio. 5/11 AntCleo 3/9
ComedyErrors Cymbeline 5/18 AsYouLike 2/6 Henry6thPart2 3/7
Corio. AntCleo 7/19 AntCleo 14/27 AntCleo 14/15
Cymbeline Corio. 5/15 AntCleo 14/27 AntCleo 16/24
Hamlet Cymbeline 11/27 Corio. 10/20 Cymbeline 5/20
Henry4thPart1 Henry6thPart1 10/25 Corio. 4/16 Cymbeline 6/15
Henry4thPart2 Henry6thPart1 10/25 Corio. 3/10 AntCleo 3/10
Henry6thPart1 Cymbeline 3/9 AntCleo 2/9 Cymbeline 3/6
Henry6thPart2 Henry6thPart1 8/17 Corio. 4/13 AntCleo 7/14
HenryTheEighth Corio. 7/28 Corio. 6/10 AsYouLike 3/9
HenryTheFifth Henry6thPart1 9/15 Henry6thPart2 5/10 AsYouLike 3/9
JuliusCaesar Henry6thPart1 7/18 Corio. 4/8 AntCleo 3/8
KingJohn Henry6thPart1 6/15 Corio. 7/15 Cymbeline 4/14
KingLear Cymbeline 8/24 Corio. 6/17 AntCleo 9/18
LovesLabor Cymbeline 7/39 Corio. 6/19 Henry6thPart2 4/19
Macbeth Corio. 3/14 Corio. 6/9 Corio. 4/10
Measures Corio. 4/20 Corio. 8/17 Henry6thPart2 5/20
MerchantVenice Henry6thPart1 6/26 Corio. 5/15 Henry6thPart2 5/15
MidSummerDream Henry6thPart1 7/28 HenryTheEighth 2/5 Excl.
MuchAdo AsYouLike 4/19 Corio. 3/12 ComedyErrors 4/14
Othello Henry6thPart1 6/27 MuchAdo 6/19 Cymbeline 6/18
Richard2 Henry6thPart1 11/31 Corio. 3/11 Cymbeline 5/12
RichardTheThird Henry6thPart1 8/32 Corio. 8/22 Henry6thPart2 11/19
RomeoJuliet Cymbeline 9/29 AntCleo 6/25 AntCleo 10/23
TameShrew Henry6thPart1 12/37 Corio. 3/9 Henry6thPart2 5/10
TheTempest Corio. 6/24 Corio. 3/5 Corio. 3/5
Timon Cymbeline 5/12 HenryTheEighth 2/5 Cymbeline 2/5
TitusAndronicus Corio. 6/23 Corio. 7/15 Henry6thPart2 7/14
TwelfthNight Cymbeline 9/24 Cymbeline 4/14 Cymbeline 6/18
WinterTale Cymbeline 10/30 Corio. 6/17 Cymbeline 8/17
4.4 Experiment 4: Characters Find Their Author
Given the results of Experiment 3, one expects (and finds) that characters do tend to find
their author. Because there are only four categories, one for each of the playwrights, and
five files per character, four out of five matches only approaches statistical significance
(p ≤ 0.06). Again, it is interesting to reflect on which characters find their author and
which do not. In Tables 9 and 10, no column is provided for the best alternative, as
none achieved statistical significance for either Jonson or Shakespeare. Reconsider the
results of Experiment 1. Of the characters who were significantly homogeneous in their
speech samples, with 248 categories in competition, only Shaw’s Rufio and Don Juan
and Wilde’s Mrs. Cheveley and Lady Chiltern also found their play.
180 C. Vogel and G. Lynch
Table 5. Characters find their play: Results for Shakespeare
Character Play Correct Alternative
Antony AntCleo 3/5 n/a
Caesar AntCleo 4/5 n/a
Cleopatra AntCleo 5/5 n/a
Enobarbus AntCleo 4/5 n/a
Orlando AsYouLike 3/5 n/a
Touchstone AsYouLike 3/5 n/a
Adriana ComedyErr 3/5 n/a
Antipholos ComedyErr 3/5 n/a
Dromi ComedyErr 3/5 n/a
Aufidius Coriolanus (2/5) AntCleo (3/5)
Cominius Coriolanus (2/5) AntCleo (3/5)
Coriolanus Coriolanus 3/5 n/a (AntCleo)
Menenius Coriolanus 3/5 n/a (AntCleo)
Sicinius Coriolanus (2/5) AntCleo (3/5)
Voluminia Coriolanus 3/5 n/a (AntCleo)
Belarius Cymbeline (0/5) AntCleo (3/5)
Cymbeline Cymbeline (0/5) AntCleo (5/5)
Iachimo Cymbeline (0/5) Coriolanus (4/5)
King Hamlet (0/5) Coriolanus (5/5)
Polonius Hamlet (0/5) Coriolanus (3/5)
King Hen4p1 (0/5) Coriolanus (3/5)
Prince Hen4p1 3/5 n/a
King Hen4p2 (0/5) Coriolanus (3/5)
King Hen6p2 4/5 n/a
King Hen8 (1/5) Coriolanus (3/5)
QueenKatherine Hen8 3/5 n/a
KingHenry Hen5 (0/5) Hen6p2 (4/5)
Character Play Correct Alternative
Cassius Julius Caesar 3/5 n/a
Constance KingJohn (0/5) Hen6p2 (3/5)
KingJohn KingJohn (0/5) Coriolanus (4/5)
Edg KingLear (0/5) AntCleo (3/5)
King LovesLabor (0/5) Coriolanus (4/5)
LadyMacbeth Macbeth (0/5) Coriolanus (4/5)
Angelo Measures (0/5) Coriolanus (3/5)
Isabella Measures (0/5) Coriolanus (3/5)
Bassani MerchantVenice (0/5) Coriolanus (3/5)
Bene MuchAdo 3/5 n/a
Leon MuchAdo 3/5 n/a (Coriolanus)
Pedro MuchAdo 3/5 n/a
Desdemona Othello (0/5) MuchAdo (3/5)
Othello Othello (0/5) Cymbeline (3/5)
KingRichard Richard2 3/5 n/a
QueenMargaret Richard3 (0/5) Cymbeline (3/5)
Nurse RomeoJuliet (0/5) KingLear (3/5)
Tranio TameShrew (0/5) Coriolanus (3/5)
Prospero Tempest (0/5) Coriolanus (3/5)
Marcus TitusAndronicus (0/5) Coriolanus (4/5)
Clown TwelfthNight 3/5 n/a
Malvolio TwelfthNight 3/5 n/a
Autolycus WinterTale 3/5 n/a
Leontes WinterTale (2/5) AntCleo (3/5)
Paulina WinterTale (0/5) AntCleo (3/5)
Table 6. Characters find their play: Results for Wilde
Character Play Correct Matches Alternative
Gerald WomanOfNoImportance 5/5 n/a
LadyHunt. WomanOfNoImportance 4/5 n/a
LordDillingsworth WomanOfNoImportance (2/5) IdealHusband (3/5)
MrsArbuthnot WomanOfNoImportance 5/5 n/a
LadyChiltern Ideal Husband 3/5 n/a
LordGoring Ideal Husband 3/5 n/a
MrsCheveley Ideal Husband (2/5) WNI (3/5)
SirRobert Ideal Husband (1/5) WNI (3/5)
LordWindermere Lady Wind. (0/5) WNI (3/5)
Algernon Earnest (0/5) IdealHusband (3/5)
Gwendolen Earnest (0/5) IdealHusband (4/5)
Jack Earnest (1/5) IdealHusband (3/5)
LadyBracknell Earnest (1/5) IdealHusband (1/5)
4.5 Experiment 5: Authors Find Themselves
In this experiment, we used four categories for the speeches and balanced the samples:
10 characters for each playwright, five files for each character (samples of 2K each); 20
out of 50 achieves significance (p ≤ 0.025). We ran 100 such experiments and report
below the average response. The column headed by “Average” in Table 13 shows each
of the authors to be significantly self-similar in comparison with the others. Shaw is
Computational Stylometry: Who’s in a Play? 181
Table 7. Characters find their play: Results
for Shaw
Character Play Correct Alternative
Caesar Caesar and Cleopatra 3/5 n/a
Cleopatra Caesar and Cleopatra 3/5 n/a
Rufio Caesar and Cleopatra 4/5 n/a
DonJuan Man and Superman 4/5 n/a
Octavius Man and Superman (0/5) Candida (3/5)
Ramsden Man and Superman (0/5) Ideal Husband (4/5)
Table 8. Characters find their play: Results
for Jonson
Character Play Correct Alternative
Amorphus Cynthias Revels 4/5 n/a
Cupid Cynthias Revels 3/5 n/a
Caesar Poetaster (0/5) Coriolanus (3/5)
FACE The Alchemist 4/5 n/a
Table 9. Jonson’s characters find
Jonson
Character Play Correct
Amorphus Cynthias Revels 4/5
Asotus Cynthias Revels 4/5
Crites Cynthias Revels 4/5
Cupid Cynthias Revels 5/5
Mercury Cynthias Revels 5/5
Caesar Poetaster 5/5
Crispinus Poetaster 5/5
Horace Poetaster 5/5
Tucca Poetaster 5/5
FACE The Alchemist 4/5
Mammon The Alchemist 4/5
Subtle The Alchemist 4/5
Table 10. Shakespeare’s find
Shakespeare
Character Play Correct
Camillo A Winters Tale 4/5
Paulina A Winters Tale 4/5
Polixenes A Winters Tale 4/5
Hamlet Hamlet 5/5
Horatio Hamlet 5/5
King Hamlet 4/5
Polonius Hamlet 4/5
Helena MidSummerDream 4/5
Cassio Othello 5/5
Desdemona Othello 5/5
Iago Othello 5/5
Othello Othello 5/5
Table 11. Shaw’s characters find Shaw
Character Play Corr. Alternative
Cleopatra Caesar and Cleo 4/5 n/a
Rufio Caesar and Cleo 4/5 n/a
Candida Candida 4/5 n/a
Morell Candida 4/5 n/a
Ann Man and Sman 4/5 n/a
Ramsden Man and Sman (0/5) Wilde(4/5)
Higgins Pygmalion 3/5 Wilde(2/5)
Liza Pygmalion 5/5 n/a
Table 12. Wilde’s characters find Wilde
Character Play Corr. Alternative
Algernon Earnest 5/5 n/a
Cecily Earnest 4/5 n/a
Gwendolen Earnest 5/5 n/a
Jack Earnest 4/5 n/a
L.Bracknell Earnest 5/5 n/a
L.Chiltern I. Husband 5/5 n/a
LordGor. I. Husband 5/5 n/a
M.Cheveley I. Husband 5/5 n/a
SirRobert I. Husband 4/5 n/a
DuchessB. Lady Wind. 4/5 n/a
LadyWind. Lady Wind. 3/5 Shaw(2/5)
LordWind. Lady Wind. 5/5 n/a
interestingly less homogeneous than the others considered here. The final four columns
of Table 13 show the breakdown of the best match alternatives over the 100 samplings.
Given constrained verse style, it perhaps is not surprising that Shakespeare and Jonson
are each other’s own best alternative. It is curious that Shakespeare is the best alternative
for Shaw nearly twice as often as Wilde is; that the best alternative for Wilde is nearly
evenly split between Shakespeare and Shaw; that Jonson is rarely the best alternative
for either Wilde or Shaw.
182 C. Vogel and G. Lynch
Table 13. Playwright and best alternatives
Average Best Alternative
Playwright Jonson Shakespeare Shaw Wilde
Jonson 44.8/50 n/a 100 0 0
Shakespeare 40.33/50 100 n/a 0 0
Shaw 30.03/50 2 68 n/a 30
Wilde 43.01/50 5 47 48 n/a
5 General Discussion
In this work we have constructed a set of experiments to establish baselines for the ex-
ploration of the issue of small sample sizes in computing similarity across texts in the
larger context of stylistic analysis. Our task has been one of computational stylometry.
We wanted to know if the effects of iambic pentameter in Shakespeare would constrain
the language sufficiently to make the individual characters indiscriminable when using
letter unigram distributions as the basis of similarity assessment. It has been noted [22,
p. 268] that Milman Parry [20] argued of Homeric verse that it was susceptible to other-
wise inappropriate descriptive epithets, evidently with preservation of meter being the
best explanation of occurrence. Thus, we pool the characters of several Shakespearean
plays with some of the verse plays of Jonson (a contemporary who is a contender in
the literature as “the real Shakespeare”, or the author of the works with primary attri-
bution dispute [6]), and along with those non-contemporary prose plays. The metric of
characterization that we wished to explore within the work is whether characterization
is strong to the extent that characters find themselves, and to a lesser extent their plays,
and that characterization is weak if the files of a character more easily find their au-
thor. By the results reported here, the works of Shaw analyzed herein reveal interesting
clusters: some characters themselves cluster in themselves as homogeneous, but Shaw’s
files are the least likely to find their author of the writers considered (even though as
an author, his files find him as author to a significant extent). Thus, the quantificational
analysis we offer suggests that his control of character is markedly greater than that of
the other writers considered. The suggestion is that in the alternative case, the author is
less prone to separate the authorial voice from that of the created characters.
Table 14 pools results across experiments. The characters listed are those which were
internally homogeneous, and the first column recapitulates the strength of homegeneity
in that regard (Experiment 1). The second column indicates the strength of homogene-
ity of that character with respect to its play, and the third column indicates strength with
respect to author in the weak sense of being significantly homogeneous with respect to
another play by the same author (Experiment 3). The final column displays the charac-
ters homogeneity frequency using authorship as a category (Experiment 4). From this
perspective, using the measure of strength outlined here, Jonson and Wilde are similar
in that their strong characters find them as authors more reliably than those characters
find their plays. Shakespeare’s strong characters are more likely to find a play another
Shakespeare play than the one in which they appear, if they find a play at all, but not
their author. Shaw’s strong characters (except Rufio) also do not find their author, but
do find their play or another Shaw play. Using the aesthetic outlined at the outset, this
Computational Stylometry: Who’s in a Play? 183
Table 14. Characters across experiments
Character Self Play Author (another play) Author (total corpus)
AARONTitusAndronicus 2/5 × × ×
AGUECHEEKTwelfthNight 2/5 × × ×
APEMANTUSTimon 2/5 × × ×
AUFIDIUSCoriolanus 2/5 × 3/5 ×
BeatMuchAdo 2/5 × × ×
CALIBANTheTempest 2/5 × × ×
CONSTANCEKingJohn 2/5 × 4/5 ×
OBERONMidSummerDream 2/5 × × ×
PRINCESSOFFRANCELovesLabor 2/5 × × ×
TALBOTHenry6thPart1 2/5 × × ×
PUCELLEHenry6thPart1 2/5 × × ×
KINGHENRYHenry6thPart1 4/5 × 3/5 ×
PUCKMidSummerDream 2/5 × × ×
QUEENELIZABETHRichardTheThird 2/5 × × ×
PORTIAMerchantVenice 2/5 × × ×
SHYLOCKMerchantVenice 2/5 × × ×
ANTONYJuliusCaesar 3/5 × × ×
BUCKINGHAMHenryTheEighth 3/5 × × ×
CHORUSHenryTheFifth 3/5 × × ×
LearKingLear 3/5 × × ×
GlouKingLear 2/5 × × ×
AlbPoetaster 2/5 × × ×
HorPoetaster 2/5 × × 5/5
VirgPoetaster 2/5 × × ×
TucPoetaster 4/5 × × 5/5
ASOCynthiasRevels 2/5 × × 4/5
CRICynthiasRevels 3/5 × × 4/5
MERCynthiasRevels 5/5 × × 5/5
ANDROCLESAndroclesLion 4/5 × × ×
RUFIOCaesarCleo 4/5 4/5 × 4/5
ANAManAndSuperman 2/5 × × ×
ANNManAndSuperman 3/5 × × ×
DONJUANManAndSuperman 2/5 4/5 × ×
OCTAVIUSManAndSuperman 4/5 × 3/5 ×
THESTATUEManAndSuperman 2/5 × × ×
STRAKERManAndSuperman 2/5 × × ×
MRSPEARCEPygmalion 2/5 × × ×
LadyBracknellEarnest 2/5 × × 5/5
GwendolenEarnest 3/5 × 4/5 5/5
MRSCHEVELEYAnIdealHusband 2/5 × 3/5 5/5
LADYCHILTERNAnIdealHusband 2/5 3/5 × 5/5
places Shakespeare and Shaw in the same pigeon-hole in having strong characters that
do not find their author. But, it merits repeated emphasis that that the strong characters
in this sense are not the famous ones. Recall that the ratios that count as significant
depend on the parameters of the test. We have not presented in this table the charac-
ters which turned up as strong according to subsequent tests, but not with respect to
character internal homogeneity.
6 Final Remarks
Note that this study depended solely on letter unigram analysis. The efficacy of letter
unigram analysis within the forensic linguistics literature has been noted above. Ad-
ditional arguments for the face validity of this level of tokenization were provided.
184 C. Vogel and G. Lynch
Further, it has proven robust in a range of other experiments as well ([9,19] supplement
experiments cited earlier). It would be useful to replicate the experiments of this paper
at other levels of token individuation. However, letter n-gram analysis does seem to
be an apt level of objective sub-lexical tokenization of texts in order to assess stylistic
properties of texts that associate to meter. Of course, this is not a definitive study on
the topic. For example, it does not take into the temporal dislocation of the construction
of the plays even within a single author’s own canon. Yet, it is representative of the
sort of analyses we intend to pursue within computational stylometry. Our immediate
ongoing work here is a replication of this study in a context with a larger pool of plays
and playwrights and characters to consider. In this paper, we controlled for drama com-
posed as verse versus prose, and Elizabethan versus the modern era; however, in this
experiment the categories overlapped in that the prose works were the modern ones and
verse, Elizabethan. It is difficult to identify a data set in which those categories can be
independently controlled for, but if the overall data set is expanded, it will be interesting
to know if the few strong characters from this study will remain so.
This article has introduced a novel form of computational stylistic analysis, applying
techniques for assessing homogeneity from corpus linguistics to evaluating the homo-
geneity of speeches of characters in plays, with respect to their character, their play
and their author. The approach is consistent with prior quantitative analyses of style,
for example it is an instance of local vs. pervasive characteristics in fiction as discussed
by [14], which are there not individuated as measures of strength of characterization.
Variations in style have been amply qualified and quantified in the past; [1] for example
addresses register in non-fiction and types of communication, work that transfers partly
to the present sort of study in that it is about communication at least one level closer to
the intended audience. And, of course [18] provides a compact survey of the extent to
which statistical methods have been applied to analyze style and authorship in literary
analysis. We are not aware of other work which is more directly comparable in terms
of trying to quantify the strength of characterization within an author’s canon using
these objective measures and for the set of authors we have addressed herein. Normally,
the questions addressed computationally in this area are about global properties of a
writer’s corpus, perhaps by genre within the corpus—for example, linguistic complex-
ity in general or changes in complexity over time—not features like distinctiveness of
characterization. We apply our analysis to iconic characters of landmark playwrights to
consider whether this allows an assessment of the extent to which a writer composes
characters that are distinct from each other and from the writer’s prose voice in general.
In this small set of experiments we found that playwrights tend not to write distinctive
characters. We noted Shaw and Jonson as exceptions within this study, in one sense, and
Shakespeare and Shaw in another. In contrast, the texts of each of the four authors was
significantly homogeneous as an individual corpus. These results suggest immediately
replication of the experiments with a larger pool of works under consideration. Orthog-
onally, we need to discuss with literature experts whether the distinctions revealed here
have any relevance to debate on interpretive approaches to the works considered. Sepa-
rately, we need to extend the baselines provided here much further if they are to become
useful in constructing metrics of independence of character voice from author voice in
assessing the realism of avatar communications.
Computational Stylometry: Who’s in a Play? 185
Acknowledgements. We are grateful to Science Foundation Ireland (RFP 05/RF/
CMS002). This research has benefited from collaboration with Sofie Van Gijsel, Geral-
dine Herbert, Lucy Hogan, Jerom Janssen, Cormac O’Brien, Niamh McCombe, Julia
Medori, Myriam Mencke and Mary Ronner. Suggestions from anonymous reviewers
have been very helpful, and this paper has benefited from attempting to address them.
References
1. Biber, D.: Dimensions of Register Variation. Cambridge University Press, Cambridge (1995)
2. Chaski, C.: Who Wrote It? Steps Toward a Science of Authorship Identification. National
Institute of Justice Journal 233, 15–22 (1997)
3. Chaski, C.: Empirical Evaluations of Language-based Author Identification Techniques.
Forensic Linguistics 8(1), 1–65 (2001)
4. Coleman, C.: The Treatise Lorenzo Valla on the Donation of Constantine: Text and Transla-
tion. Russell & Russell, New York (1971); First published 1922
5. Farmer, T., Christiansen, M., Monaghan, P.: Phonological Typicality Influences On-line Sen-
tence Comprehension. Proceedings of the National Academy of Sciences of the United States
of America 103(32), 12203–12208 (2006)
6. Foster, D.: Author Unknown. On the Trail of Anonymous. Macmillan, London (2001)
7. Frontini, F., Lynch, G., Vogel, C.: Revisiting the Donation of Constantine. In: Kibble, R.,
Rauchas, S. (eds.) 2008 Artificial Intelligence and Simulation of Behavior – Symposium:
Style in Text
8. Healey, P.G.T., Vogel, C., Eshghi, A.: Group Dialects in an Online Community. In: Arnstein,
R., Vieu, L. (eds.) DECALOG 2007, The 10th Workshop on the Semantics and Pragmatics
of Dialogue, Università di Trento (Italy), May 30 – June 1, 2007, pp. 141–147 (2007)
9. Hogan, L.: A Corpus Linguistic Analysis of American, British and Irish Political Speeches.
Master’s thesis, Centre for Language and Communication Studies, Trinity College, Univer-
sity of Dublin (2005)
10. Kilgarriff, A., Salkie, R.: Corpus Similarity and Homogeneity via Word Frequency. In: Pro-
ceedings of Euralex 1996 (1996)
11. Kilgarriff, A.: Comparing Corpora. International Journal of Corpus Linguistics 6(1), 97–133
(2001)
12. Laver, M. (ed.): Estimating the Policy Position of Political Actors. Routledge (2001)
13. Laver, M., Garry, J.: Estimating Policy Positions from Political Texts. American Journal of
Political Science 44(3), 619–634 (2000)
14. Leech, G.N., Short, M.H.: Style in Fiction: A Linguistic Introduction to English Fictional
Prose. Longman, London (1981)
15. Lynch, G., Vogel, C.: Automatic Character Assignation. In: Bramer, M. (ed.) AI-2007
Twenty-seventh SGAI International Conference on Artificial Intelligence, pp. 335–348.
Springer, Heidelberg (2007)
16. Mencke, M.: Benchmarking a Text Classification Technique. Master’s thesis, Computational
Linguistics Group, Trinity College Dublin (2007)
17. Nijholt, A., Reidsma, D., Ruttkay, Z., van Welbergen, H., Bos, P.: Non-verbal and Bodily
Interaction in Ambient Entertainment. In: Esposito, A., Keller, E., Marinaro, M., Bratanic,
M. (eds.) The Fundamentals of Verbal and Non-Verbal Communication and the Biometrical
Issue, pp. 343–348. IOS Press, Amsterdam (2007)
18. Oakes, M.P.: Statistics for Corpus Linguistics. Edinburgh Textbooks in Empirical Linguis-
tics. Edinburgh University Press, Edinburgh (1998)
186 C. Vogel and G. Lynch
19. O’Brien, C., Vogel, C.: Spam Filters: Bayes vs. Chi-squared; Letters vs. Words. In: Alesky,
M., et al. (ed.) Proceedings of the International Symposium on Information and Communi-
cation Technologies, pp. 298–303 (2003)
20. Parry, A.: The making of Homeric verse: the collected papers of Milman Parry. Oxford Uni-
versity Press, Oxford (1971) (Reprinted 1987)
21. Schmid, H.: Probabilistic Part-of-Speech Tagging using Decision Trees. In: International
Conference on New Methods in Language Processing (1994)
22. Smith, J.D.: Winged Words Revisited: Diction and Meaning in Indian Epic. Bulletin of the
School of Oriental and African Studies, University of London 62(2), 267–305 (1999)
23. Van Gijsel, S., Vogel, C.: Inducing a Cline from Corpora of Political Manifestos. In: Aleksy,
M., et al. (eds.) Proceedings of the International Symposium on Information and Communi-
cation Technologies, pp. 304–310 (2003)
24. Vogel, C.: Corpus Homogeneity and Bernoulli Schema. In: Mining Massive Data Sets for
Security. NATO Advanced Study Institute, pp. 93–94 (2007)
25. Vogel, C.: N-gram Distributions in Texts as Proxy for Textual Fingerprints. In: Esposito, A.,
Keller, E., Marinaro, M., Bratanic, M. (eds.) The Fundamentals of Verbal and Non-Verbal
Communication and the Biometrical Issue, pp. 189–194. IOS Press, Amsterdam (2007)
26. Vogel, C., Brisset, S.: Hearing Voices in the Poetry of Brendan Kennelly. In: Varieties of
Voice, 2006. 3rd international BAAHE conference. Leuven, Revised version Belgian Journal
of English Language & Literature, December 7-9 (to appear, 2006)
