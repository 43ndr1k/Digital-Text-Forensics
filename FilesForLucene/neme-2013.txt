Computational Study of Stylistics: Visualizing
the Writing Style with Self-Organizing Maps
Antonio Neme1,2, Sergio Hernández3, Teresa Dey4,
Abril Muñoz5, and J.R.G. Pulido6
1 Complex Systems Group, Universidad Autónoma de la Ciudad de México
San Lorenzo 290, México, D.F. México
2 Institute for Molecular Medicine, Finland
neme@nolineal.org.mx
3 Postgraduation Program in Complex Systems,
Universidad Autónoma de la Ciudad de México
4 Faculty of Literary Creation, Universidad Autónoma de la Ciudad de México
5 CINVESTAV IDS, México D.F.
6 Facultad de Telemática, Universidad de Colima, México
Abstract. The style authors follow to express their ideas has been a
subject of great debate. Several perspectives have been followed to try
to analyze the style. In this contribution we present a computational
methodology to study the writing style in a collection of hundreds of
texts. For each text several attributes, which include different time series,
are extracted and a battery of tools from the signal processing and the
machine learning communities are applied to identify a set of features
that may define a candidate style space. We applied self-organizing maps
to visualize how several authors are distributed in the high-dimensional
space associated to the style, and to visually prospect the similarities
between styles from different authors.
Keywords: computational stylistics, authorship attribution, visualiza-
tion, self-organizing maps, mutual information.
1 Introduction
The automatic identification of the style authors follow in their texts has proven
to be elusive. The study of stylistics has attracted the attention of different
practitioners from diverse areas. An experimented reader may be able to easily
recognize the general style of his/her favorite author, but declaring the procedure
they followed to recognize the style is a much harder task [1]. The style authors
follow, namely the use of certain words, the avoidance of certain others, the
preferential use of some grammatical structures, or any other measurable pattern
is what defines the stylistics [2].
A closely related concept is that of authorship attribution (AA), which refers
to the task of identifying the author of a text from a group of possible candidate
authors [1]. This task is strongly based on the cited concept of stylistics. Stylistics
P.A. Estévez et al. (Eds.): Advances in Self-Organizing Maps, AISC 198, pp. 265–274.
DOI: 10.1007/978-3-642-35230-0 27 c© Springer-Verlag Berlin Heidelberg 2013
266 A. Neme et al.
may be seen as the identification of attributes that define a high-dimensional
space in which authors can be distinguished from each other.
The relevance of computational stylistics pervades several areas. The first one
is that of literature theory, in which experts struggle to dig into the patterns that
the analyzed writers tend to follow in their texts. Also, the evolution of that style
is of academic interest. A second impacted field is on forensic linguistics in which
it has to be determined the authorship of a text either for historical reasons or
criminal charges [1,3]. Also, as a consequence of web dissemination, with several
hundreds of thousands of public documents, there are several situations in which
it is relevant to identify the author of particular texts or situations in which it
is necessary to confirm the existence of apocrypha documents.
The impact of stylistics also reaches psychiatry. It has been stated that some of
the early symptoms in certain mental disorders can already be detected in writing
[4]. For example, a detailed analysis over the novels of Iris Murdoch shows that
there are qualitative and quantitative differences in her novels prior to the disease
and in the early stages of it. Being aware of the general patterns of evolution in
stylistics may help psychiatrists and other mental health professionals to early
detect symptoms of mental disorders.
Different algorithms have been proposed to identify the author of a given
text [1]. However, most of those algorithms lack of explanatory properties. For
example, some kernel methods present good performance, but those models are
unable to show what attributes are really relevant as it is only focused in finding a
high-dimensional space in which points representing texts are linearly separable.
In this contribution, we present some results associated to a project focused
on the study of computational stylistics. In this project, machine learning and
data mining tools are applied to a corpus of hundreds of texts covering dozens
of authors. The first objective of the project is to identify those attributes that
can summarize the stylistics of authors at the time that are relevant to the au-
thorship attribution task. Also, we are interested in the analysis of the evolution
of stylistics for individual authors. As the stylistics space is high-dimensional,
a visualization tool is of the greatest relevance. We have applied self-organizing
maps in the data exploration phase and we have been able to identify some
attributes that are relevant in the definition of the minimum list of attributes.
Several attributes have been proposed as relevant in order to discern the
stylistics of an author. Also, many features have been proposed to be relevant
for the AA task. In this contribution, we focus our attention on attributes about
the way authors make use of words. Here, we refer to words as the vocabulary
but also to punctuation signs. One of the open questions is the identification
of the minimum set of attributes that can lead to the identification of authors.
Several attributes have been proposed, for example, the use of certain words and
the lack of use of other [1]. In general, the concept of bag of words is frequently
mentioned and, although relevant results have emerged, there are even more
questions to be answered [2,5]. Writers use language following different ways to
express their ideas. This variation in language allows authorship attribution to
be possible [6].
SOM for Visualization of Style 267
The rest of this contribution is presented as follows. In section 2 we describe
the attributes that define stylistics as well as the relevant aspects of SOM. In
section 3 some results are described and we present a proposal to select subspaces
from the stylistics space able to distinguish between texts from different authors.
Finally, in section 4 some conclusions are discussed and we pinpoint to ongoing
and future work.
2 Attributes, Stylistics and Data Analysis Tools
The style authors follow in their texts is described by several attributes. In this
contribution we aim to identify a high-dimensional space of attributes, also called
the stylistics space, in which authors can be distinguished from each other. Each
text is transformed into a set of time series and from them, several tools from the
signal processing and data mining fields are applied. Each text is then mapped
to a point in that high-dimensional space of attributes.
The most common approach in the field of computational linguistics and
natural language processing is to deal with texts under the perspective of bag of
words. There, the relevant quantities are the relative frequencies of each word,
sentence, or any other relevant structure [7]. There are several works in which
texts are analyzed and classified with self-organizing maps based on very high-
dimensional vectors containing the relative frequency of appearance of words [8].
In this contribution we are not only interested in the relative frequency of
words, but also in the cadence authors follow when using certain words or sym-
bols (we will refer to words also as symbols). That is, we are interested in the time
series defined as the distance between consecutive instances of several relevant
symbols. By that distance, we refer to the number of words that separates con-
secutive appearances of a given word or symbol. We are interested in obtaining
those time series for the following symbols:
– the comma
– sentence length (number of words in each sentence)
– number of sentences per paragraph
– the most common word excluding the comma and the word the/el
– the most common word excluding articles and prepositions
– the word the/el
Besides the time series for certain symbols, we defined another time series, that
we call simply T . It is defined as follows. Each text is transformed into a sequence
of integers: each word or symbol is associated to an integer in order of appearance.
The first word to appear in the text will be assigned a 0, the second non-repeated
word will be associated to a 1, and so on. For example, the sentence S1 = My
baptismal name is Egaeus; that of my family I will not mention. is transformed to
the sequence T = {0, 1, 2, 3, 4, 5, 6, 7, 0, 8, 9...}. The word My is assigned to code
0 as it is the first word. The second appearance of my is also assigned code 0. In
this contribution, there is no difference between upper and lower cases. This time
series is positive definite, and presents some properties that prevent the use of
268 A. Neme et al.
time series analysis tools over it, for example it is not stationary. However, from
time series T a new time series B can be constructed: It is a sequence of 0 and 1,
where 1 indicates the appearance of a previously unseen word and a 0 reflects the
appearance of a repeated word within the analyzed text.
Other attributes are also considered, for example, the entropy of the text, the
ratio between vocabulary and text length, maximum sentence length, probability
distribution of the most common words, among others. The complete list of the
attributes is shown in table 1. From this list a high-dimensional stylistics space
S is constructed, and each text is then mapped to that space.
Table 1. Attributes definining the stylistics space S
Attribute Description No. var
V Vocabulary size 1
T Text length in words 1
V/T Ratio V/T 1
H Entropy 1
MPL Maximum paragraph length (sentences per paragraph) 1
APL Average paragraph length 1
mPL Minimum paragraph length 1
PDPL Probability distribution of paragraph length (up to 30 sent. per paragr.) 30
MSL Maximum sentence length (words per sentence) 1
ASL Average sentence length 1
mSL Minimum sentence length 1
PDSL Probability distribution of sentences length (up t 200 words per sentence) 200
pMFSL Probability of the most frequent sentence length 1
PkMCW Probability distribution of the 30 most common words 30
pMCW Probability of the Most Common Word (except , and the) 1
adMCW Avg distance between consecutive appearances of MCW 1
mdMCW Minimum distance between consecutive appearances of MCW 1
MdMCW Maximum distance between consecutive appearances of MCW 1
pThe Probability of the word the/el 1
adThe Avg distance between consecutive appearances of the/el 1
mdThe Minimum distance between consecutive appearances of the/el 1
MdThe Maximum distance between consecutive appearances of the/el 1
pMCWx Probability of the MCW (except articles, prepositions and ,) 1
adMCWx Avg. dist between appearances of MCW (except articles, prepositions and ”,”) 1
mdMCWx Min. dist. between appearances of MCW (except articles, prepositions and ”,”) 1
MdMCWx Max. dist. between appearances of MCW (except articles, prepositions and ”,”) 1
PkMCWx Probability distribution of the 30 MCWs (except articles, prepositions and ”,”) 30
pComma Probability of the comma 1
adComma Average distance between consecutive appearances of the comma 1
mdComma Minimum distance between consecutive appearances of the comma 1
MdComma Maximum distance between consecutive appearances of the comma 1
MIFS MIF for time series S (40 displacements) 40
MIFPL MIF for time series paragraph length (40 displacements) 40
MIFSL MIF for time series sentence length(40 displacements) 40
MIFMCW MIF for time series distance between MCW(40 displacements) 40
MIFMCWx MIF for time series distance between MCWx(40 displacements) 40
MIFComma MIF for time series distance between comma(40 displacements) 40
MIFThe MIF for time series distance between the/el(40 displacements) 40
MIFBin MIF for time series B (40 displacements)(40 displacements) 40
PWSS Power spectrum of time series S (5 highest frequencies) 40
PWSPL Power spectrum of time series paragraph length (5 highest frequencies) 5
PWSSL Power spectrum of time series sentence length (5 highest frequencies) 5
PWSMCW Power spectrum of time series distance between MCW (5 highest frequencies) 5
PWSMCWx Power spectrum of time series distance between MCWx (5 highest frequencies) 5
PWSCWy Power spectrum of time series distance between comma (5 highest frequencies) 5
PWSThe Power spectrum of time series distance between the (5 highest frequencies) 5
PWSB Power spectrum of time series B (5 highest frequencies) 5
Time series extracted from texts are the basis of the concept of stylistics we
follow. However, time series per se only give limited details, and more process-
ing on them is necessary. Texts may present different lengths so a normalizing
methodology is needed to compare time series that may come from texts of
different size. Time series are not analyzed directly. Several tools from the time
series and signal processing communities can be applied in order to extract subtle
and relevant patterns [9]. Among the attributes that can be extracted from time
series the most common ones are the power spectrum, the Lyapunov, and the
mutual information function [10]. In this contribution, we extracted the mutual
information function (MIF) and power spectrum (PWS) from the time series
coming from texts.
SOM for Visualization of Style 269
MIF is a measure of non-linear correlation between random variables or sys-
tems [11]. It gives an answer to the following question: Once we know the state
a system is in, how much information does knowledge give about the state a
second system is in? MIF is based in Shannon’s information theory [12]. When
MIF is applied to a time series, the second system (or random variable) is con-
structed by shifting the time series up t k positions. The length of that shift is
represented the x axis when plotted.
In summary, the high-dimensional stylistics space S is a high-dimensional
space formed by several MIF (40 displacements each), several power spectrum
(the five highest frequencies), and several statistics. All these attributes are de-
scribed in table 1. As the length of texts is distributed along one range of mag-
nitude, finite size correction was applied for normalizing data. Once the S space
is defined, we can visualize the distribution texts follow in that space by apply-
ing a non-linear mapping to a low-dimensional space. The self-organizing map
(SOM) is an accurate and powerful tool to accomplish that mapping. Also, we
are interested in identifying a small subset of attributes in S able to distinguish
between texts from different authors and thus propose that subset as a very
small candidate stylistics space.
SOM is frequently applied as a visualization tool. SOM is able to preserve in
a low-dimensional space the approximate distribution shown by vectors in the
high-dimensional input space [13]. It outperforms common visualization tools
such as principal component analysis as SOM takes into account high-order
statistics, instead of at most second-order statistics[14].
We are interested in studying stylistics from a pure statistical and signal
processing perspective. That is, we think of texts as signals and we systematically
study how far we can reach by leading aside grammatical and lexical issues. We
are not interested in the already well established concepts of bag of words and
other related aspects. In the next section, we present some maps for several texts
from a dozen of writers.
3 Results
Each text is transformed to a point in the high-dimensional stylistics S space.
The coordinates of each text are given by the attributes described in the previous
section. We now want to know what attributes of this space are relevant to
identify the author of a text.
The analyzed authors and their texts are shown in fig. 1. Texts were analyzed
in accordance to the stylistics attributes described in the previous section. Only
these authors are show in this contribution in order to simplify the visualization
and the analysis (the full list of texts and analysis is available from authors).
In order to discover the distribution texts present in the stylistics space S,
a visualization tool is needed. As there are ∼ 1500 dimensions in that space
(see table 1), a projection over all possible two-dimensional spaces is out of
the question. Also, not all of the variables are necessarily relevant to define
the stylistics. We have then two issues to solve: the visualization task and the
270 A. Neme et al.
Fig. 1. Authors and their works studied in this contribution
identification of a subset of variables (dimensions) that indeed are enough as to
identify the stylistics.
In fig. 2-a it is shown the SOM formed for all variables in space S. It is
observed that, although some texts from the same author tend to be mapped in
clusters, this is not a general fact for all authors. In fig. 2-b, it is shown a SOM
for the analyzed texts, but now embedded in the attribute space defined only by
the eight MIF shown in table 1.
The stylistics space S includes several features, including relative frequencies,
MIF and power spectrum. We are interested now in the following question: Is
there a subset of A ∈ S such that authors may be recognized based on their texts
position on that space A? In order to give an answer to that question, we applied
a recently introduced method for variables selection [18] based in information
theory. We are interested in finding at most K variables (K < dim(S)) from S
such that such that the mutual information (MI) from A to the class Z (author’s
name) is maximal. Let Φ(A,Z) be the mutual information between systems A
and Z. We seek to find A such that Φ(A,Z) is maximum.
This task differs from what information-based algorithms as C4.5 follows.
We are not interested in classifying objects based on MI. We are trying to find
a subspace such that the coordinates in that space give as much information
about the label or class as possible. Then, a machine learning algorithm can be
fed with vectors in that space A, instead of being fed with vectors from space S
whose dimension is higher. The task we have declared is somehow similar to that
followed in algorithms such as testors [16], in which a matrix of differences is
systematically explored to identify those features that correctly classify patterns.
We intend to find an attribute space such that the MI between points, rep-
resenting texts in that space and authors, is as maximum as possible. To do
this, the MI of a compound system is needed. That is, if there is only one
SOM for Visualization of Style 271
Fig. 2. a) SOM formed on a 30x30 lattice for all texts from stylistics space S. When
texts of different authors are mapped to the same unit, the square is divided in equal
slices for each text and colored accordingly to the author code. b) Map formed for the
input space of all MIF (see table 1). The number in the cell indicates the text index
shown in fig. 1.
attribute then the MI is calculated straightforward. In the case of two continu-
ous attributes X
′
and Y
′
and ns is the number of states in which each attribute
is to be discretized (X and Y ), a compound system Z is constructed as follows.
Z ′i = Xi × ns + Yi and Z = discretize(Z ′, ns). For more than two attributes,
the procedure is applied recursively.
The náive scheme to construct the space A from S will be to select the K most
informative variables. Such strategy is followed, for example, by C4.5 [15] but
that greedy strategy leads to local optima. The space generated by K attributes
from space S is called A. The number of possible spaces A is the number of
combinations of K positions available to D different attributes C(D,K). The
exhaustive search for the case here presented is prohibitively time- consuming for
K > 3. Thus, a search scheme is needed in order to select the relevant features
[17]. We applied an heuristic search method, a genetic algorithm, in order to
find at most K attributes from T that generate a space such that Φ(A;Class)
is maximum.
A genetic algorithm was implemented in Python with an elitist scheme and
probabilities of mutation of 0.05 and crossover of 0.9. Population size was settled
to 200 and the algorithm was allowed to run for 1000 epochs. Note that the
algorithm identifies a space A of dimension D ≤ K. That space is not easily
observed once D > 3. In order to visualize the distribution of the analyzed texts
in that space, we decanted our options towards the SOM.
Fig. 3 shows the SOM achieved by different K values. The image on the left
corresponds to a SOM for a space A of 27 dimensions, which include MIFThe,
MIFMCWy, among others. The image on the right is a SOM for a space A of
272 A. Neme et al.
5 dimensions that corresponds to MIFSL and MIFMCWy It can be observed
that, indeed, there are detectable general distribution patterns that may allow
to discriminate the author. Texts do not necessarily form clusters: once again,
we are interested in an attribute space such that mutual information between
the distribution and the author of a text is maximized. Clusters are only one
way in which that mutual information can be maximized, but there are many
others. Our methodology finds a family of those distributions.
Fig. 3. SOM formed on a 30x30 lattice for all texts from stylistics space A ∈ S. a)
A of dimension 27 b) A of dimension 5. Both spaces A were obtained by the genetic
algorithm mentioned in the text.
The B time series mentioned in the previous section is interesting because
it summarizes the rate at which writers include new words in the text. If now
we define space A as specifically the MIF for B, the distribution of that space
is approximated in the SOM in fig. 4-a. In general, texts from the same author
are similar in that space, that is, they are located in similar areas (see 4-b), but
there are some exceptions: Iris Murdoch presents a clear evolution in the style
if defined as MIF of B (fig. 4-c). This is consistently with the fact that her last
novel (Jacksons Dilemma) was written at the time she was suffering from a brain
disorder, so a change in her style was expected.
In a different experiment, the label associated to each text was not the author
but the language in which it was written. We applied the described genetic
algorithm to find the attributes that maximize the MI about the language (class)
and we show two SOM for two different conditions in fig. 5. In both cases there are
variables that once again include attributes related to MIF, but now, regarding
the use of the most common word which is not an article/preposition. Also, a
variable selected by the algorithm was the maximum distance between the most
common word (including article/preposition).
SOM for Visualization of Style 273
Fig. 4. SOM for input space A defined as MIF for B (a). In b) it is show the MIF for
one of the authors (MCS). c) Shows MIF for three texts of author IM.
Fig. 5. SOM for two input spaces A ∈ S. MI between A and the language of the text
was maximized. Red: English, blue: Spanish. Left: dim(A) = 8, Right: dim(A) = 11.
4 Conclusions
In the tasks of authorship attribution and computational stylistics, it is of major
interest to identify a set of attributes that can offer as much information as
possible about the author of the text. Here, we have applied a self-organizing
map to visualize the distribution followed by several texts from different authors.
A genetic algorithm that constructs a space of at most K attributes such that it
maximized the information about the class or author of the text was implemented
and the distribution of texts in that space was visualized with the SOM
The analysis of texts as time series is also powerful to distinguish between
authors. The stylistics is at least partially, well described by the particular pat-
tern authors follows when using certain words. From those patterns it is possible
also to analyze the evolution of the style. The methodology here described can
be applied to any kinds of texts and it consistently shows that the properties of
274 A. Neme et al.
the extracted time series are relevant to distinguish the stylistics and thus are
valuable in the authorship attribution task.
Acknowledgement. A. Neme thanks SNI CONACYT and ICyTDF.
References
1. Juola, P.: Authorship attribution. NOW Press (2008)
2. Stamatatos, E.: A survey of modern authorship attribution methods. J. of the
American Soc. for Information Science and Technology 60(3), 538–556 (2010)
3. Canter, D.: An evaluation of Cusum stylistics analysis of confessions. Expert Evi-
dence 1(2), 93–99 (1992)
4. Garrard, P., Maloney, L.M., Hodges, J.R., Patterson, K.: The effects of very
early Alzheimer’s disease on the characteristics of writing by a renowned author.
Brain 128, 250–260 (2005)
5. Mayer, R., Rauber, A.: On Wires and Cables: Content Analysis of WikiLeaks Using
Self-Organising Maps, pp. 238–246 (2011)
6. Neme, A., Cervera, A., Lugo, T.: Authorship attribution as a case of anomaly
detection: A neural network model. Int. J. of Hybrid Intell. Syst. 8, 225–235 (2011)
7. Manning, C., Schutze, H.: Foundations of statistical natural language processig.
MIT Press (2003)
8. Lagus, K., Kaski, S., Kohonen, T.: Mining massive document collections by the
WEBSOM method. Information Sciences 163(1-3), 135–156 (2004)
9. Abarbanel, H.: Analysis of observed chaotic data. Springer (1996)
10. Kantz, H., Schreiber, T.: Nonlinear time series analysis, 2nd edn. Cambridge Press
11. Cellucci, C.J., Albano, A.M., College, B., Rapp, P.E.: Statistical Validation of Mu-
tual Information Calculations: Comparison of Alternative Numerical Algorithms.
Physical Review E 71(6) (2005), doi:10.1103/PhysRevE.71.066208
12. Shannon, C.E.: A Mathematical Theory of Communication. Bell System Technical
Journal 27, 379–423, 623–656 (1948)
13. Kohonen, T.: Self-organizing maps, 2nd edn. Springer (2000)
14. Hujun, Y.: The Self-Organizing Maps: Background, Theories, Extensions and Ap-
plications. Studies in Computational Intelligence (SCI) 115, 715–762 (2008)
15. Quinlan, R.: Programs for Machine Learning. Morgan Kaufmann Publishers (1993)
16. Cortes, M.L., Ruiz-Shulcloper, J., Alba-Cabrera, E.: An overview of the evolution
of the concept of testor. Pattern Recognition 34, 753–762 (2001)
17. Guyon, I., Elisseeff, A.: An Introduction to Variable and Feature Selection. J. of
Machine Learning Res. 3, 1157–1182 (2003)
18. Hernández, S., Neme, A.: Identification of the minimal set of attributes that max-
imizes the authorship information (to appear in LNCS, 2012)
