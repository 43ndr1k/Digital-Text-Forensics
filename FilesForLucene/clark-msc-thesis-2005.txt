 
MSc Project Report 
Classifying XML Documents by Genre 
Volume 1  
Malcolm Clark 
2005 
 
 
 
 
A report submitted as part of the requirements for the degree of MSc in Computing: Software 
Technology at The Robert Gordon University, Aberdeen, Scotland 
 
 
Malcolm Clark Page 2 
ACKNOWLEDGEMENTS 
 
Huge thanks go to my wife Sam, Mum Annie and sons Owen, Callum and Nathan for their 
love, support and help through some tricky moments. Additional thanks go to the supervisor 
Dr Watt for his motivation, enthusiasm and also the opportunity to investigate a truly exciting 
subject area.  
 
 
Malcolm Clark Page 3 
ABSTRACT 
 
The difficulties inherent with Information Retrieval are many fold. The main problem is how 
to find and display the users’ needs. This volume briefly explores IR background, typical 
components and how it has traditionally been performed in the past on a multitude of works. 
Retrieval is being utilised on collections by using genre, which identifies the type of 
document by conceptual features instead of using traditional topical information; this volume 
investigates research in this field. Some authors have claimed that a document can be 
identified by form alone. 
Subsequently, a proposal is made with regard to investigating the genre of a document by 
using ten structural features. This would be carried out  by conducting retrieval on the INEX 
XML collection which is to be indexed and searched using the Lucene library and classified 
by using two data mining algorithms.  
 
Malcolm Clark Page 4 
TABLE OF CONTENTS 
ACKNOWLEDGEMENTS .....................................................................................................2 
ABSTRACT ..............................................................................................................................3 
TABLE OF FIGURES .............................................................................................................5 
CHAPTER ONE .......................................................................................................................6 
1. INTRODUCTION......................................................................................................................... 6 
1.1 Project...................................................................................................................................................... 6 
1.2 Information Retrieval Background....................................................................................................... 6 
1.3 Brief History............................................................................................................................................ 6 
1.4 Information Retrieval Organisations .................................................................................................... 6 
1.5 Information Retrieval –The Problem Identified .................................................................................. 6 
1.6 What is Information Retrieval?............................................................................................................. 7 
1.7 Information Retrieval Models ............................................................................................................... 8 
1.9 XML-Background................................................................................................................................. 11 
1.10 XML Information Retrieval Needs ................................................................................................... 11 
1.11 Report Overview ................................................................................................................................. 12 
1.13 Motivations.......................................................................................................................................... 12 
1.12 Project Objectives ............................................................................................................................... 12 
CHAPTER TWO ....................................................................................................................13 
2. LITERATURE  REVIEW.......................................................................................................... 13 
2.1 Genre Introduction ............................................................................................................................... 13 
2.2 XML – Basic evolution ......................................................................................................................... 13 
2.3 Areas of research .................................................................................................................................. 14 
2.4 Genre Research ..................................................................................................................................... 20 
2.5 Conclusion ............................................................................................................................................. 34 
CHAPTER THREE................................................................................................................35 
3. TOOLS, REQUIREMENTS, METHODOLOGY AND DESIGN OUTLINE...................... 35 
3.1 Aims of Implementation ....................................................................................................................... 35 
3.2 Development Tools................................................................................................................................ 35 
3.3 Indexing ................................................................................................................................................. 39 
3.4 Searching Tools..................................................................................................................................... 46 
3.5 Indexing and Searching Conclusion.................................................................................................... 49 
3.6 Outline Design....................................................................................................................................... 50 
3.7 Basic Functionality of the GUI ............................................................................................................ 50 
3.8 Identified Problems .............................................................................................................................. 51 
3.9 Methodology.......................................................................................................................................... 52 
REFERENCES .......................................................................................................................60 
APPENDICES ONE – INITIAL SPECIFICATION ..........................................................64 
APPENDICES TWO - PROJECT PLAN ............................................................................65 
STAGE 1-INVESTIGATION AND PROJECT PLAN ............................................................... 65 
STAGE 2-IMPLEMENTATION AND EVALUATION ............................................................. 65 
RESOURCES .................................................................................................................................. 66 
GANT DIAGRAM .......................................................................................................................... 66 
Stage one...................................................................................................................................................... 66 
Stage two...................................................................................................................................................... 67 
 
 
 
Malcolm Clark Page 5 
TABLE OF FIGURES 
 
Figure 1 Typical Search Model ...............................................................................................9 
Figure 2 Topic from INEX 2004............................................................................................10 
Figure 3 Simple search and query ........................................................................................14 
Figure 4 Relevance formula for ADHOC processing..........................................................20 
Figure 5 Concept examples....................................................................................................25 
Figure 6 Number one, touch your tongue (Newcome 2002) ...............................................26 
Figure 7 Generic cues .............................................................................................................30 
Figure 8 Format example.......................................................................................................32 
Figure 9 Project Development ...............................................................................................35 
Figure 10 Partial screenshot of the Eclipse IDE(The Eclipse Foundation 2004)..............37 
Figure 11 Using Maven from Eclipse (The Eclipse Foundation 2004) ..............................38 
Figure 12 Indexing process identified by Gospodnetic (2003)............................................40 
Figure 13 Stack Diagram .......................................................................................................41 
Figure 14 XML file and Digester EMP’s..............................................................................41 
Figure 15 Luke........................................................................................................................43 
Figure 16 Indexing..................................................................................................................46 
Figure 17 Scoring Formulae ..................................................................................................47 
Figure 18 Proposed model ....................................................................................................50 
Figure 19 INEX 1.4 corpus ....................................................................................................52 
Figure 20 Features to be analysed.........................................................................................53 
Figure 21 WEKA splash screen/main menu and example classifier choices ....................56 
Figure 22 WEKA explorer.....................................................................................................56 
Figure 23 Trimmed down version of ARFF file format (Witten et al 1999). ....................57 
Figure 24 Explorer view (Clark 2004) and Witten et al (1999) ..........................................58 
Figure 25 example output shows four algorithms tested on three datasets. (Clark 2004) 
and Witten et al (1999) ...........................................................................................................58 
Figure 26 Rankings example (Clark 2004) and Witten et al(1999)....................................59 
 
Malcolm Clark Page 6 
 
CHAPTER ONE  
 
1. INTRODUCTION 
1.1 Project 
This project has been initiated to investigate XML retrieval by genre and to design and 
implement a system which will index and conduct retrieval on the INEX 1.4. 
1.2 Information Retrieval Background 
Information Retrieval encapsulates the scientific methods involved in searching for a 
document, partial document information, metadata describing documents within databases or 
hypertext based databases which contain images, text, sound or data (Wikipedia 2005) 
1.3 Brief History  
Information Retrieval has been a major topic of research since the 1960s, at the time, when 
Gerard Salton – a pre-eminent figure in the field of IR at Cornell University – began to use 
the SMART (Salton’s Magical Automatic Retriever of Text) as a research tool. His work led 
to fundamental changes in full-text processing, setting the cornerstones for this research field 
(Wikipedia 2005). The research in the early days mainly involved relatively small (compared 
with today’s standards) collections of documents using Vector Space and Boolean Logic 
models for retrieval. As technology has advanced and different types of collections, for 
example, imagery and video, have evolved, IR has also had to try to advance at the same pace. 
1.4 Information Retrieval Organisations 
Information Retrieval is a global research field, The ACM Special Interest Group on 
Information Retrieval (SIGIR) deals with academic, governmental and industrial issues 
involving all aspects of the storage, retrieval and dissemination of information including 
research strategies, output schemes and system evaluations. This organisation is involved in 
three conferences; The Workshops International ACM/SIGIR Conference on Research & 
Development, the Joint Conference on Digital Libraries (JCDL) and the Conference on 
Information & Knowledge Management (CIKM) (Lalmas 2005).  
1.5 Information Retrieval –The Problem Identified 
“…digital libraries need to be evaluated to determine how useful, usable, and economical 
they are and whether they achieve reasonable cost-benefit ratios. Results of evaluation 
studies can provide strategic guidance for the design and deployment of future systems, can 
assist in determining whether digital libraries address the social, cultural, and economic 
problems, and whether they are as maintainable as possible” 
(Lalmas 2004) 
Malcolm Clark Page 7 
The main goals of effective IR are the identification of users’ specific information needs and 
the evaluation of the results by creating Information Retrieval applications that can discern 
better matches between users’ information needs and the available documents. The overlying 
problem is that when a user inputs a query keyword into a search engine too many documents 
are returned (for example, inputting ‘Information Retrieval’ into Google resulted in sixty 
million, three hundred thousand hits being returned) but only a tiny proportion of these will be 
‘relevant’ or useful to the user. Special techniques are required to enable the specifics of user 
queries to be assessed so that the search can be narrowed down to the particular documents 
needed. Deciding what is really relevant is a subjective task. It could be argued, perhaps, that 
the focus should be on the user learning to input better queries but given the diverse range of 
users with all their various skills, in particular those using search engines on the internet, this 
is not really an option – for example, internet users are unlikely to respond enthusiastically to 
advice that they should consult a thesaurus to narrow down the search. In theory, all 
documents could be structurally standardised but, in reality, this is really a no go area because 
it would lead to confusion amongst developers. Salminen et al (2001) have tried to analyse the 
problems involved here and seek to provide an evaluation of all present and future answers to 
the database management problem, emphasising the importance of encouraging the 
development of systems and models for XML database management.  At the present time, 
however, the only real option is to match the user’s needs to the documents retrieved by 
means of, for example, topical and genre analysis. 
Narrowing a search down to a particular topic or genre of document is also a common 
problem. A user may require the minutes of a specific meeting or the paper published to 
announce the results of INEX or TREC for 2004. Particular file types could also be required. 
Currently, there are a multitude of file types which can be used for extraction in Information 
Retrieval, for example, PDF (Adobe Acrobat), Rich Text Format and, lastly, Microsoft 
application file types, such as Word Excel and PowerPoint.  
1.6 What is Information Retrieval? 
So what is typical Information Retrieval in an educational sense? Summing up the topic of IR 
into small bite-size pieces is no easy feat, since it has many related and overlapping areas, 
such as Artificial Learning, Data Mining, Natural Language Processing and Human Computer 
Interaction, amongst others. 
 
 
 
Malcolm Clark Page 8 
1.7 Information Retrieval Models 
“Retrieval models form the theoretical basis of computing the answer to the theory” 
Fuhr (2001) 
The Information Retrieval models are profoundly theoretical; this report will only mention 
them briefly.  
1. Set-theoretic / Boolean models 
2. Algebraic / vector space models 
3. Probabilistic models 
1.7.1 Vector Space Model 
The vector space model, explains Fuhr (2001), consists of documents and queries symbolised 
as vectors in a vector space which are spanned by the terms in the index. Wikipedia (2005) 
states that there are several sub-types of the Vector Space models such as the Generalized 
Vector Space Model, Topic-Based Space Model, Enhanced Topic-Based Vector Space Model 
and Latent Semantic Indexing.  
1.7.2 Boolean Model 
The Boolean model (Fuhr 2001) is based on set theory and algebraic Boolean. The 
Documents in the model are represented as sets of terms and the Queries are Boolean 
expressions on terms. Wikipedia (2005) states that there are sub-types of the Boolean model, 
for example, the Standard and Extended Boolean models and Fuzzy retrieval.  
1.7.3 Probabilistic Model 
This model works (Fuhr 2001) by making assumptions about the distribution of terms in 
relevant and non-relevant documents which in turn approximates the probability of relevance 
of a document for a query. The language model calculates the probability that the query is 
produced from a given document. Wikipedia (2005) states that there are sub-types of the 
Probabilistic model, namely the Binary Independence Retrieval, Uncertain Interference, 
Language Models and the Divergence from Randomness Models. 
1.8.1 Typical Components 
In order to arrive at a satisfactory description of Information Retrieval, it is first of all 
important to outline some typical components which could make up an IR system:  
1. User Interface – the user interface is the front end for the user to interact with the 
whole IR system, for example, Input Query, view the document and score results 
from the search. Google is a well-known instance of a UI for query operations. 
2. Text Operations – stopwords, stemming (for example, Porter) or Lexical Analysis 
operations.  
Malcolm Clark Page 9 
3. Indexing – for example, process which creates an inverted index of words. 
4. Searching - retrieves document(s) for the user which comprise a given query token 
from the indexing referred to above in number 3. 
5. Query – this component is mainly concerned with techniques for improving the 
query, such as reference books, dictionaries and Thesauruses.  
6. Ranking – this component scores all the documents returned from the search in 
number 4. 
A good example of an IR system is provided by the following logical diagram of a Search 
Engine which performs a typical Information Retrieval on a document collection: 
 
Figure 1 Typical Search Model 
 
1.8.2 Topics 
Once the system has been designed and implemented the ‘Information Retrieval’ experiments 
have to be decided. The retrieval experiments normally take the form of ‘topics’ which have 
to be retrieved from a collection. For example, a topic from the INEX 2004 collection is 
displayed below:  
topic_id="127" query_type="CAS" ct_no="13">  
<title>//sec//(p| fgc)[about( ., Godel Lukasiewicz and other fuzzy 
implication definitions)]</title> 
<description>Find paragraphs or figure-captions containing the 
definition of Godel, Lukasiewicz or other fuzzy-logic 
implications</description>  
<narrative>Any relevant element of a section must contain the 
definition of a fuzzy-logic implication operator or a pointer to the 
element of the same article where the definition can be 
found. Elements containing criteria for identifying or comparing fuzzy 
implications are also of interest. Elements which discuss or introduce 
non-implication fuzzy operators are not relevant. </narrative>  
<keywords>Godel implication, Lukasiewicz implication, fuzzy 
Malcolm Clark Page 10 
implications, fuzzy-logic implication </keywords> 
Evaluation Discussion 
 
Figure 2 Topic from INEX 2004 
The topic text is displayed in XML format as, of course, the INEX is based on this format. 
The participants now try to retrieve the specific topic from the collection using the search 
engine. Once the retrieval has been completed, evaluation of the performance follows. 
1.8.3 Evaluation 
Evaluation is essential because the user needs to determine whether a system is suitable and 
effective and, for this purpose, has to compare different systems. The evaluation processes 
also assist in re-assessing all relevant terms and functionality such as weighting, selection and 
ranking. 
The effective evaluation of IR experiments involves many different dimensions and types of 
performance measurement, such as Precision, Recall which are calculated as follows 
(simplistic definitions by Wikipedia 2005): 
Precision: Number of relevant documents retrieved / Total Number of documents retrieved 
Recall: Number of relevant documents retrieved / Total Number of relevant documents 
Additionally there is Mean Average precision, which finds the mean of all the documents 
retrieved, and also the F-measure which is the harmonic mean of Precision and Recall, for 
example, F=  2 x precision x /(precision + recall). 
1.8.4 Evaluation Workshops 
Many types of Information Retrieval organizations, conferences or workshops exist for the 
pooling of IR techniques and provide a solid platform for IR researchers to evaluate their 
results and report the data of their computer science experiments. One of the most important 
conferences, along with INEX, is the TREC (Text REtrieval Conference) which was held for 
the first time in 19921 and has continued since then on an annual basis. Each year, tracks 
(tasks) are laid out for participants by the TREC program committee. Tracks are like a 
specification of new and existing research areas and define the questions regarding the 
problem, evaluation methods and collections to be used. The Tracks focus on topics which are 
currently of interest to the computer science communities and provide tasks which suit the 
research interests of most groups. Finally, they also “try and demonstrate the robustness of 
                                                     
1 TREC- co-sponsored by the National Institute of Standards and Technology (NIST) and U.S. Department of 
Defense. In 1992, the tracks were ADHOC retrieval and Routing. 
 
Malcolm Clark Page 11 
core retrieval technology in that the same techniques are frequently appropriate for a variety 
of tasks.”(TREC 2004) 
1.9 XML-Background 
XML is an acronym for EXtensible Mark-Up Language and is a standard for document mark 
up which is fully endorsed by the W3C. 
The EXtensible Mark-Up Language (XML) is rapidly becoming the leading method of storing 
many types of digital media such as text and imagery. It is also commonly employed as a 
means of displaying data through the World Wide Web. 
XML is one of the most important developments in document syntax in the history of 
computing (Harold et al 2002). 
The use of the technology has been extremely diverse since its conception: it is derived from 
SGML2, (Standard Generalised Mark-Up Language), which was developed in the 1970s by a 
team of employees at IBM and is still used today. The first version of XML was finally 
launched in 1998.  
XML provides many features, such as:   
1. Storage   
2. Schemas such as Document Type Definitions (DTD), XML Schemas, RELAX NG 
and others. 
3. Query languages – XQuery (similar to SQL), XPath, XQL, XML-QL, QUILT and 
others 
4. Programming interfaces - SAX, DOM and JDOM 
1.10 XML Information Retrieval Needs 
The increase in storage of digital documents in XML format has brought about the explosion 
in the development of systems to store, access and exploit the logical structure of such 
corpuses (Lalmas et al 2002). 
There is a need for research methods which can extract and classify information from XML 
sources, that is, not only whole documents but also individual sections in contrast with the 
usual document collections or ‘bags of words’ (Watt  2004) where the retrieval depends solely 
on structural items, such as abstracts, footnotes and titles. 
At present, the Information Retrieval community of computer scientists and other scholars is 
using genre to categorise documents in digitally structured media. However, only a few exist 
which use a XML structured corpus. 
                                                     
2 SGML is a method of specifying rules for tagging elements rather than formatting. HTML is a derivation of 
SGML and was standardized in 1986. 
Malcolm Clark Page 12 
1.11 Report Overview 
Many fields of study, algorithms and systems for IR have been created which have been used 
and adopted for Information Retrieval. For example, the Stemmer Algorithm written in 1980 
is widely used to stem words to original form, and the Conceptual IR System, FERRET, 
provides a great precision and recall performance for full text searches. (Mauldin 1991). 
This study mainly involves genre theory and Information Retrieval genre classification, but 
will begin by looking at important techniques, experiments and evaluations using this area of 
research. In addition, it will look at XML and related retrieval, the INEX organisation and 
also touch on TREC, where Wilkinson completed a significant experiment regarding whether 
to retrieve partial or full documents. 
This project will look at categorising in all formats but mainly XML retrieval. Studies 
currently exist to categorise documents as fictional/non-fictional, subjective/ objective (Finn 
et al 2003) which can be considered facets of genre. Genre theory and classification is the 
focus of a wide-ranging review of literature on these topics. Chapter Two also elaborates on 
XML, and the INEX workshop. Chapter Three focuses on the requirements, design outline, 
methodology and tools which will incorporate the proposed topics and evaluation of the 
retrieval system.  
1.13 Motivations 
The crucial importance and potential of this topic as a field of research very quickly becomes 
obvious. As data collections grow, the techniques for retrieving the information have to adapt 
and improve. Computer scientists around the world are trying to find methods to extract and 
retrieve multimedia types of images, audio, video, web documents and structured documents 
(XML) and evaluate their efforts. The aim is to improve at each evaluation and thus advance 
Information Retrieval techniques. 
1.12 Project Objectives 
The objectives of the project are: 
• To investigate current methods of classifying documents using Genre. 
• To examine current categorisation systems and tools primarily using Java™. 
• To create an application to create, search an index and assist in classifying documents 
by genre from the INEX 1.4 XML collection. 
• To evaluate software and extracted information from the XML collection using genre. 
 
 
Malcolm Clark Page 13 
CHAPTER TWO  
 
2. LITERATURE  REVIEW 
 
2.1 Genre Introduction 
In this study, genre will be looked at in two contexts: firstly, in terms of human behavioural 
theory where, for example, Watt (2004) refers to the opportunities offered by the “socially 
constructed communicative behaviours called genres to improve the efficiency of communal 
activities”.  Additionally, Yates et al (1992), in their pioneering work on the concept of genre, 
suggest that “Genres (e.g., the memo, the proposal, and the meeting) are typified 
communicative actions characterised by similar substance and form and taken in response to 
recurrent situations”, which can be used to identify types of organizational communication. 
Secondly, genre is examined in the context of IR where genres can be used categorise the 
purpose for which text has been written (Lee et al 2004). 
To begin this chapter, before going into genre in a greater depth, it is pertinent to explore the 
relevant studies to gain an understanding of how XML and traditional text IR has arrived 
where it is today. 
2.2 XML – Basic evolution 
The first step must be to trace the evolution of XML since this is the corpus of this project. 
Bosak3 (2005) attempted to convince other computer scientists that technologies of the current 
web infrastructure would not scale up to future needs. He realised that HTML (an offshoot of 
SGML) had only basic qualities which could be utilised but, in reality, SGML was required 
for computer industry needs in particular. Bosak headed a working group for the W3C. XML 
was originally named ‘Web SGML Activity’ but this was later changed after a colleague 
made a suggestion which could have been just to shorten the name. The XML effort, Bosak 
suggests, was totally “organized, led and underwritten” by Sun Microsystems over a two year 
period and eventually Microsoft noticed the benefits of XML and agreed to adopt it into their 
technologies, as did many other organisations soon afterwards. 
As the amount and size of XML databases expand, for example, web and digital libraries, the 
need for IR systems based around partial and full text XML, as opposed to traditional IR 
systems, increases. The first priority here is to identify the requirements for searching and 
querying collections. 
 
                                                     
3 Bosak is widely renowned as one of the creators of XML. 
Malcolm Clark Page 14 
2.3 Areas of research 
As can be expected, many types of research have been carried out for many different reasons, 
for example, Pehcevski et al looked at the requirements for searching and querying and 
Hatano explored keyword retrieval. Shaorong et al wrote a paper regarding indexing and 
ranking. All of these fields and others, namely Evaluation and Experiments, are explored in 
the next section. 
2.3.1 Requirements for searching and querying 
Pehcevski et al (2003) helped to identify the overall requirements for an XML retrieval 
application:  
 
 
 
 
Figure 3 Simple search and query 
Firstly (see Figure 3), the system should enable users to express their queries, for example, 
allow the user to input a set of words identified as queries. Secondly, the output results should 
be ranked according to their similarity and relatedness. Thirdly, the system should return 
fragmentations of documents and know the context of the fragments in respect of the 
document hierarchy. Notice, however, that Pehcevski et al (2003) refer to document 
fragments.  
Hatano et al (2002) state the unsuitability of keyword query retrieval for XML fragments or 
whole documents since the results returned generally do not bear any relationship to the 
query. They suggest that only fragments such as sections, subsections or chapters of 
documents should be retrieved because the most important part of XML retrieval is 
establishing the entity for the retrieval answers. However, there is some debate as to whether 
Full or Partial documents should be retrieved.  
2.3.2 What to retrieve from XML: fragments or whole documents? 
Wilkinson (1994) bases his now out-dated arguments on retrieval using the TREC database. 
None the less, the experiments and results he describes regarding the retrieval of structured 
information provide some useful insights. 
He considers the problem of how much information should be retrieved: for example, whole 
or partial documents. The documents may be so large that the retrieval system will be 
deceived into believing that the document is actually relevant when in fact it is completely 
   
 
Express Query 
   
Output 
Ranked 
Results 
   
Return 
Fragments of 
Documents 
Malcolm Clark Page 15 
irrelevant to the query. Wilkinson (1994) suggests that the IR world, in some circumstances, 
should concentrate on retrieving partial documents from structured corpora.  
Wilkinson performed tests to examine the documents which specified the frequency of terms 
in section parts, content, type and finally section-document inclusions. 
He considered that:  
1. The content, type and the structure of the parts should be considered useful, as well as 
the document as a whole. 
2. The retrieval of whole documents can be achieved if the users have some knowledge 
of the document parts but limited basic knowledge of the document as a whole will 
lead to less successful results. If users of large document collections combine their 
knowledge and understanding of the whole and the parts of the documents, they will 
return better retrieval results. 
Through the results of his set of experiments, Wilkinson proved that knowledge of the 
structure will enhance retrieval performance, but the documents should not be treated as if 
they are standardised. Obviously the Information Retrieval world took Wilkinson’s arguments 
on board as Kamps et al (2003) also address the question of what should be retrieved from the 
extensive XML corpus and focus on the Content Only (CO) units of retrieval.  
Firstly, it is important to explain what Content Only queries are: for example, during the 
ADHOC processing in the INEX track the queries are structured from Content Only (CO) and 
Content And Structure (CAS); the latter, as the definition suggests, retrieves the Content and 
Structure of the requested query whilst CO retrieves the most specific XML elements, 
answering the query in the most appropriate way it can. It allows the retrieval of only a partial 
section instead of the whole document (Lalmas et al (2004).  
Kamps et al (2003) discuss the difficulties involved in retrieving XML content, in comparison 
with traditional text retrieval.  The unit to be retrieved and also the size of the unit should be 
neither too large nor too small. Two approaches were employed and compared to substantiate 
their argument: 
the Full Document Retrieval System (FDRS) and the XML Element Retrieval System (XML 
ERS) and two units of retrieval, one being the usual Relevance and the other called Coverage 
which measures how much of the retrieved element is Relevant.  
The Content Only (CO) procedures which were followed to obtain the results were: retrieve 
each element and measure Relevance and Coverage from the ‘Raw scores’ using the ‘Strict 
measure’. According to this Strict measuring system, an element is only accepted if it has 
exact coverage and is highly relevant. CAS is of most interest to this study, with a particular 
Malcolm Clark Page 16 
focus on structure, with regard to the methods employed by researchers to distinguish 
between Content and Structure since these frequently overlap and are both highly subjective. 
2.3.3 Indexing and Ranking 
Two of the most important issues in the whole process of Information Retrieval are Indexing 
and Ranking which assist in finding the users’ needs.  
Firstly, the question of how to index information has long been a problem for the IR 
community but, in earlier days, only textual formats had to be dealt with. Now, with the 
establishment of Web Pages and XML amongst others, a new problem has emerged: how to 
index multi types of numeric, times, dates, URLs, tags and so on. As Shaorong et al (2004) 
point out, not all tags for XML content are semantically meaningful and the poor indexing of 
content will lead to “false negatives”. 
Secondly, the normal static methods of ranking documents in traditional IR, in an attempt to 
mark the relevance of the document to the question, may not be helpful to the user initiating 
the query because in XML content the query may be a deeply embedded element in the XML 
database and not the whole document. 
In their paper, Shaorong et al (2004) offer a possible solution and emphasise the importance 
of configurable indexing and ranking for XML information retrieval and identify these as two 
key areas for the purposes of “efficiency and success”. They offer the IR community a new 
system which allows the user to control tags and text via flexible configuration of the 
indexing system. One feature of the index configurations is that the system converts the XML 
into ‘compact tree representations’, named “CTree” by the authors. The implementation of the 
XML ranking is achieved by ‘weighted term frequency’ and ‘inverted element frequency’ 
which analyse the weighting of a term depending on the location and frequency of the term 
within the XML element and other criteria.  
The steps followed were: 
1. Model the tree by transforming the XML document tree to compact indexing tree 
2. Implement the configurable XML IR system – scan document to retrieve structure and 
content statistical information and then store information in a spreadsheet for availability 
purposes for the user. Users then, according to their requirements, choose the relevant 
information of the similar elements based on the statistics. 
3. Use an extension of the Vector Space Model in traditional IR to the XML model and the 
implements “weighted term frequency” and “inverted element frequency” which depend 
on the frequency, popularity and location of an XML document. 
Malcolm Clark Page 17 
4. Measure effectiveness by applying and evaluating vigorous experimentation exercises on 
the INEX 2003 document corpus and 30 CAS topics.  
 
The authors claim that they achieved significant results, for example, high precision in low 
recall regions and high average precision amounting to 0.3309, compared to 38 official INEX 
2003 submissions and also point out that setting tag weights correctly can improve the 
precision. 
For the purposes of this project, the Lucene open source tool will be used for the indexing of 
the INEX 1.4 corpus, further details of which will be given in Chapter Three. 
2.3.4 Experiments  
Experiments vary for a multitude of reasons depending on the specific hypothesis the 
participants are attempting to prove. A brief summary of some of the experiments performed 
by the authors of the reviewed articles will be shown. It is important to understand the types 
of tests so that this project can follow the same types of experimental format. 
The first experiment retrieved involved Mauldin and uses a machine-readable dictionary to 
supplement the FERRET’s lexical knowledge and a variant of its genetic learning to extend 
its script catalogue. The retrieval is implemented by using 22 sample user queries with a 
Boolean keyword query system.  
While participating in INEX, Kamps et al (2003) employed the FDRS and XML ERS 
approaches by using the inex_eval program version 0.006, which was disseminated among the 
participants with set metrical values, in order to investigate the type of information required to 
retrieve partial or full information. All runs contained up to 1000 results and none of them 
contained Stemming4 or Feedback. 
Whilst trying to prove the unsuitability of keyword retrieval, Hatano et al (2002) described the 
experiments they performed on the XML collection made up from the INEX corpus: 
1. Parse using Xerces obtained from Apache open source environment. The parser 
assembles Document Object Model (DOM), as opposed to SAX, tree constructions of 
the XML documents.  
2. As extensively as possible, the system divides the XML documents into partial XML 
documents. Stemming and Stopword analysis is implemented (does not specify a 
stemmer such as Porter). Partial elements add up to circa 7 million and 181 partial 
documents. 
                                                     
4 Refers to the root origins of a word such as Search which is the root of Search-es and Search-ing. 
Malcolm Clark Page 18 
3. Determine “Coherent Partial Documents” (CPDs) quantities of words and tokens and 
also proportion of tokens. 
4. Use the quantity of document parts to appraise the performance of the IR system. 
5. Study the adequate size of the fragment of XML document taking into consideration 
the CPDs. 
While experimenting on the TREC database, Wilkinson (1994) considered a large set of 
questions.  
The experiments were structured as follows: 
1. Rank full documents against the queries using standard cosine measures. 
2. Split documents into sections, measure similarity of each section against the queries 
using cosine measure and order on highest ranking first. 
3. Repeat previous experiment (2) but add weights of sections. 
4. Split documents into sections. Measure alikeness of each segment against the queries. 
5. Combine Experiments 3 and 4. 
Wikinson concluded from these experiments that it is possible to achieve satisfactory retrieval 
when whole documents are requested by using section information only. 
The next set of experiments, following on from the above, were set up to test the “issue of 
enhancing document retrieval using global and local information.” by combining ranks and 
similarities. The following procedures were carried out: 
6. Combine rankings. 
7. Add normalised weights of experiments 1 and 3. 
8. Add weighted normalised weights of experiments 1 and 3. 
9. Add normalised weights of experiments 1 and 5. 
These results of these experiments displayed very limited benefits which led Wilkinson to 
point out that since the method of comparison of both levels(global and local) is not cheap, 
the cost may outweigh the benefits gained. 
In the next stage, Wilkinson utilised a threshold so that low ranking sections were not viewed 
even though they contained details of high ranking documents. His strategy was to:   
10. Rank each section 
11. Rank each section on content and type. 
12. Rank each section based completely on containing document (experiment 1). 
13. Rank each section by document first, and then by section using experiment 11. 
14. Use document ranking and finally section ranking but remove the documents below 
the threshold. 
Malcolm Clark Page 19 
15-18. Try to reveal if combining evidence for section retrieval is useful and  
       worthwhile.  
These experiments showed, according to Wilkinson, that the high effectiveness of document 
retrieval is achieved when sections are required and indicated that experiment 12 is a poor 
strategy. Experiment 16 demonstrated the advantages of combining evidence compared with 
the results of experiment 11.  
As can be seen, Wilkinson based his work on a cumbersome set of experiments and this was 
considered appropriate for testing his hypothesis to the fullest degree. This project is subject 
to time constraints so the proposed experimental model will have to be short but not, of 
course, less effective. 
2.3.5 Evaluation 
Evaluation is arguably the most important section of information retrieval, because it is 
important to measure the effectiveness of the retrieval systems. An outline of the evaluation 
strategy at INEX is essential for the project because it may form the basis for evaluating the 
application developed in the Implementation and Evaluation stage. The annual workshop, 
INEX (INitiative for the Evaluation of XML Retrieval), in which RGU participated for the 
first time in 2004, assesses evaluation methods for retrieval on a collection of thoroughly 
marked-up XML documents. These documents consist of past IEEE Computer Society 
journals which have been completely compiled in XML format. INEX uses many types of 
tracks to test XML documents, for example, Relevance Feedback, Natural Query language, 
Heterogeneous (Het), Interactive and the main one, ADHOC, which could include several 
different methods of analysing and extracting document information, such as Shallow 
Parsing, Latent Semantic Analysis and ‘Genre’. The Interactive track studies “the behaviour 
of users when interacting with components of XML documents” and “investigates and 
develops approaches for XML retrieval which are effective in user-based environments” 
(Lalmas et al 2004). Het is too cumbersome to be explained briefly and will therefore not be 
included in this report. An examination of past ADHOC retrieval processes on the INEX 
collection is appropriate for this report as it helps explain Evaluation. 
Lalmas et al (2004) described the evaluation of ADHOC at the last INEX in 2004 which 
measured the effectiveness on the test collection, the selection of the appropriate document 
collection, the creation of user requests and, finally, the generation of relevance assessments.  
The relevance of the queries is based upon two logical measurements: Exhaustivity and 
Specificity. The former is exploited to judge the extent to which the retrieved elements 
Malcolm Clark Page 20 
discuss the query topic and Specificity is used to measure the focus of the retrieved element of 
the query topic. Each logical element is judged by grading the two measurements from 0-3.  
The formula which INEX specified for judging the relevance consisted of: 
 
  
 
 
 
Figure 4 Relevance formula for ADHOC processing 
 
The in depth analysis by Lalmas et al (2004) describes the employment of the quantization5 
function(Figure 4) applied metric by mapping two relevance areas to the one relevance scale 
and different quantization to map both dimensions to a single scalar value. According to the 
article, the strict quantization function is used to evaluate retrieval methods with respect to 
their capability of relevance metric, “highly exhaustive”, divided by specific document 
components. The measurement was obtained by calculating the average precision values with 
all the quantization functions. In the future, INEX will also look at user behaviour/intentions 
which are based on the gain measurements and tolerance to irrelevance, respectively, and how 
much irrelevance a user will put up with, for example, redundant information. 
2.4 Genre Research 
2.4.1 Introduction 
This section of the review is based on genre literature and will be divided into two sections. 
Genre theory will focus, in particular, on basic theory and genre classification will examine 
tools and classification techniques which have been implemented using genre.  
2.4.2 Genre Theory 
“In structurational terms, genres are social institutions that are produced, reproduced, or 
modified when human agents draw on genre rules to engage in organizational 
communication” 
(Yates et al 1992) 
Research on genre, genre theory and diverse genre-related topics is being carried out in many 
overlapping areas and is being implemented in many different ways.  
                                                     
5 quantization is the state of being constrained to a set of discrete values, rather than varying 
continuously.(Wikipedia 2005) 
 
Malcolm Clark Page 21 
It is important to understand genre and how it has been studied since the late nineteenth 
century. A clear picture of the way in which genre theory has evolved can be obtained by 
considering some of the work on genre theory, which has been written and published to date: 
Yates et al (1992), who arguably introduced the concept of genre to the IR field, seek to 
explain human behaviour in the context of genres of organisational communication, social 
rules and ‘structuration’ theory. They suggest that this is “embedded in social process” and is 
not an effect of “isolated rational actions”. Genres are typified open actions which are 
characterised by similar substance and structure and taken in response to recurring situations. 
The genres develop in time and in shared communication between standardised practices and 
individual human actions. However, genres are not to be confused with communications 
media although they concede that the media, and in particular the introduction of new types of 
media, may have a role in the evolution of genre. The authors point to the results of genre 
studies carried out in the past decade, for example, the studies of six major accounting 
companies, where letters and memos were used as a basis for identifying genres familiar to 
this particular field. Many types of each communication media were discovered such as 
research and administrative memos.  
Interestingly, the same authors also portray the cycle of genre rules for the memo as it has 
evolved since the mid-nineteenth century: from the 1870s to the 1920s, from the1920s to 
the1970s and finally from the1970s to the1990s, deriving their information from business 
correspondence records which are stored in an historical documentation database in the 
United States. There is, in addition, a description of the ways in which the memo genre has 
influenced the structure and development of the E-mail, which is, of course, an important 
modern communication tool. Yates et al also discuss organisational communications, for 
example, time-related studies evaluating the ongoing evolution of genres in an organisation 
beginning before and after the introduction of a new genre medium. 
Orlikowski et al (1994) examine the norms and forms for work and interaction regarding 
Genre repertoire by studying the electronic communication of knowledge workers who were 
all co-operating on an extended project over a time span of many years. They discovered that 
four genres typified the work practices and relationships: memo, proposal, dialogue and 
finally ballot. The authors explain how the “Genre Repertoire” acts as an authoritative social 
model which shows how, why and with what result members of a group communicate to 
accomplish their work. They point out that the so called Genre Repertoires evolve over the 
course of time as responses to project events and task demands, amongst other factors. The 
authors state that the analysis of work practices is useful for investigating and defining the 
Malcolm Clark Page 22 
ways in which electronic media may be connected with changes in work routines and 
communication norms. The methodology employed by the authors to arrive at their 
conclusions was to observe usage of e-mail by a group of specialist workers who were 
working on an inter-establishment multi-year venture. The authors pointed out that email was 
the main means of communication used by workers and that this constituted the largest 
proportion of their project work. By analysing the emails, Orlikowski et al segmented the 
content into Genre Repertoires which described how and why it changed over the time period 
being analysed, which in turn led to theories on why and how a group instigates, employs and 
transforms its genre repertoires, work modes and communication. 
The authors conclude that “the Genres through which data is shaped and shared for particular 
purposes (reports, spreadsheets, meetings, teleconferences etc) are no longer merely an aspect 
part of organizational work; they are the organizational work.” Changes in genres and genre 
repertoires therefore disclose changes in operation, communication and establishment. The 
authors also argue that they have developed a template for the future which could assist 
organisations in designing models for work and interaction at assemblies or in establishments. 
According to genre theorists (Spinuzzi 2004), genres do work together well in assemblages 
(large collections brought together). The author describes the structural sections of genres, 
namely sets, systems, repertoires and ecologies. He suggests that although the genres within 
these structural sections are supposed to be identical, many differences exist among them. 
Spinuzzi suggests scenarios in which the sections can each be utilised individually. He 
describes the genre sets by breaking them down into five axes in which the genres deviate. 
These axes (Spinuzzi 2004) are briefly listed below: 
Model of action – How are the users affected by the genres in the framework? How are the 
genres used and how do the activities change through usage?  
Agency – Who acts within a given framework? 
Foregrounded genres – Which genres in particular are subjected to examination in a 
framework and which are subjected to less examination? 
Perspective: For whom does the viewpoint framework afford analysis? 
Relationship between genres: Are genres related sequentially or do they overlap? 
The author places the sets, systems, repertoires and ecologies into framework placements and 
sums up by saying that he has “highlighted the frameworks analytical focuses and different 
agendas” and that this will “help researchers make stronger choices”.  
 
 
Malcolm Clark Page 23 
2.4.3 Genre Detection 
“Genre provides a new dimension for text retrieval and classification, 
 in addition to topicality, and help users become selective in their  
information seeking process and obtain high quality information” 
Lee et al (2004) 
 
Past genre research is diverse, for example, Rauber et al (2002), in the first of their two papers 
in this review, explain how they have used genre to retrieve files from a music database. This 
is a significant achievement. They describe how they have isolated music by audio signal 
“processed by psychoacoustic models to obtain a time-invariant representation of its 
characteristics”. The result of this experiment was the clustering into groups where each 
group represented genre groups. This project obviously does not look at audio categorisation 
but does show the range of current genre studies. 
Of course, this project does consider genre text categorisation and, in particular, form (format) 
interpretation of document genres but will also take a brief look at content and style features. 
2.4.4 The Problem 
Imagine the difficulties involved in trying to find a solution to a problem on the internet with 
a faulty mp3 player. The manufacturer ‘Apple’ is listed on the internet and so a solution could 
be found to a defect if a user were able to find the contact information and submit a 
complaint. The user submits ‘Apple’ to the internet search engine Google. The results of the 
search are going to be contained within a certain class of topic (Apple) with different 
purposes, but the range of genre classes will be diverse. The results may reflect Apple 
homepages, advertisements, product specifications, critical reviews and more. Methods of 
narrowing the result by genre have to be explored as all the above results will be relevant to 
the search but not altogether appropriate to what the user wants. 
Most research into classification of digital media is based around the topical aspect of a 
document and therefore research into genre needs to diversify; this is certainly happening at 
present, but arguably not fast enough. Many authors, such as Rauber et al (2001), have called 
for more research into genre. They comment on the fact that with the increase in different 
documentary types in digital libraries, a need has arisen for improvements in management, 
organisation and the types of presentation of the content. They point out that most types of 
retrieval consist of structural and topical representation and that hardly any focus on the genre 
types that already exist in everyday life. genre, they argue, “forms one of the most 
distinguishing features in conventional libraries and in information searches”. The following 
approaches were fully recommended by the authors: automatically analyse the structural 
make-up of the documents and automatically create content-based organisation by integrating 
Malcolm Clark Page 24 
the structural analysis information. Then create a visualisation of the documents which belong 
to different genres but are similar in topicality, with the documents visualised in different 
colours to assist users in locating the relevant documents. 
However, researchers do recognise the difficulties in genre classification tasks, for example, 
Rauber (2001) believes that ” many documents belong to multiple genres” with overlaps 
occurring throughout whilst Finn(2003) states that “identifying a genre taxonomy is a 
subjective process and people may disagree about what constitutes a genre, or the criteria for 
membership of a particular genre”. Collins (2000) believes that that there is insufficient 
research into genre based classification and that although many information-sharing 
communities exist, they make little use, if any at all, of the information in developing the 
tools to classify and retrieve by genre. He states “The communities at present simply do not 
use the archives to their true/full potential.” He also recognises that, as of five years ago, only 
“statistical and text analysis techniques to automatically derive semantics” were in existence. 
Collins has a point, not perhaps with regard to traditional text archives, but in the context of 
XML archives. The XML archives are growing and are simply not used to their maximum 
potential as regards genre classification. To illustrate this, all the papers by Stamatatos, Lee 
and Finn were written after experiments had been performed on traditional text collections.  
Stamatatos et al (2000) used common word and punctuation frequencies in which the most 
frequent types were measured. 
Lee et al (2004) used discrimination analysis on several features while Finn et al (2002) 
applied machine learning techniques to identify genre by linguistic attributes.   
Numerous experiments exist for XML retrieval but not for XML genre research.  
Many papers have, however, been written on web genre research techniques which are 
applicable for most digital collections. Many of these papers are now explored below. 
2.4.5 Concepts 
In current research, there are several concepts in which documents can be judged in genre. 
Boese (2005) commented on the three underlying concepts that were persistent in ‘Genre’ 
definitions: style, form, and content of a document. She also clearly defined web genre as “a 
taxonomy that incorporates the style, form, and content of the document which is orthogonal 
to topic, allowing fuzzy classification to multiple genres and mapping of multiple genres to a 
single document.” She also goes on to say that “this definition is more encompassing than 
those found currently in the Web IR community, acknowledging the three main feature-
aspects of a document and explicitly recognizing the multiplicity of genres within a document 
Malcolm Clark Page 25 
and multi-classification of a document to multiple genres.” Boese stated that these are 
common in “web genres”.  
Of course, these conceptual features of style, format and content can be utilised with other 
digital documents formats, especially XML, which is the main corpus of this project.  
Campbell et al (1999) suggested that the conceptual features consisted of “a set of distinct 
facets or layers”, function, form and interface. function is “the semantic content of the 
document as represented by the meaning of the words in the text”, form is “the visual 
appearance of the document, its structure, as manifested by its specific formatting and layout” 
and finally interface is “the means by which the document is accessed and used, and the portal 
through which it is examined.” 
By taking Boese’s (2005) and Kennedy’s (2005) ideas and looking at these conceptual 
features, many pieces of genre classification works being reviewed fall into the concepts they 
describe.  
Boese et al (2005) in a different paper, namely Effects of Web Document Evolution on Genre 
Classification, use the same categories of form, content and style with the following features 
measured:  
Concept Feature Examples Reference (Boese 2005) 
unless stated 
Style Readability and Part 
Of Speech statistics 
(POS) 
 
Finn et al (2002) 
Form Text statistics and 
HTML format 
analysis. 
 
 
Content Bag-of-words, 
Words in HTML 
title tag and URL, 
Number types, 
Closed-world sets, 
Punctuation 
 
Figure 5 Concept examples 
 
Content can be  analysed by looking at Punctuation such as ; or ?, Closed World Sets; such as 
Dr, Mr, Mrs or  emoticons ; or  B-O-W in which a document is encoded as a feature vector, 
with each element in the vector indicating the presence or absence of a word in the document. 
 
Malcolm Clark Page 26 
Style context systems include categorising document genre by punctuation frequencies or 
readability. For example, the document might use colons and semi-colons for elongated 
sentences, use long and/or conjunctive adverbs such as ‘nevertheless’ and ‘otherwise’ or 
‘indeed’, and be written in complete sentences.” Additionally, Parts-of –Speech (P-O-S) 
statistics could be utilised, for example, Finn et al (2002) used P-O-S statistics which would 
reflect the style of the language sufficiently to distinguish between different genre classes. 
Each document was represented as a vector of 36 P-O-S features, one for each P-O-S tag, 
expressed as a percentage of the total number of words for the document. 
Form looks at features in which could include Text statistics and XML analysis of the tag 
structure. The text statistics within the document could measure the number of words in a 
section and number of paragraphs.   
There are of course a multitude of additional features which could be included in Figure 5 and 
these, it could be argued, belong to content, style and form; such decisions are subjective. 
Two examples follow: 
1. An Iambic Pentameter may be analysed as a style of writing or indeed content because 
it consistently contains an unstressed syllable followed by a stressed syllable.  
2. A document may consistently contain a high frequency of punctuation, possibly 
indicating a poem which could be judged form or content (Figure 6). 
Look at this nursery rhyme: 
Number one, touch your tongue.   
Number two, touch your shoe.  
Number three, touch your knee.  
Number four, touch the floor.  
Number five, learn to jive.  
Number six, pick up sticks.  
Number seven, go to heaven.  
Number eight, over the gate  
Number nine, touch your spine.  
Number ten - do it again. 
Figure 6 Number one, touch your tongue (Newcome 2002) 
 
The reason for the overlap is to enable the classification to be tested against each feature set, 
for example, Style versus Form (Boese 2005). 
content or form? 
punctuation could be 
indicative of either. 
Malcolm Clark Page 27 
Documents do provide “visual cues that enable users to conceptualize the form: in particular, 
the layout of a document contains distinctive features which alert the users to the type of 
content the document will contain.” Watt (2004), for example, has written an, as yet, 
unpublished paper studying form which starts from the hypothesis that “formatting, white 
space, and other non-linguistic cues play an essential role in effective text categorisation”. 
The research consisted of distributing electronic mails with linguistic data from which all 
formatting had been removed. The trial tested the swiftness and precision of the resulting 
categorisation of text.  
Watt’s strategy was to recruit eight academics, who knew the formats of calls for papers, and 
produce derived images of the message text: 
1. Prepare 24 messages and pair with 24 other messages with similar sizes and dates. 
2. Produce images of the message text according to unchanged message text and format, 
all letters and digits replaced with ‘X’ with all formatting and punctuation left in. 
3. Remove all formatting, punctuation and other characters and alter letters to lower case. 
4. Apply Substitutions 2 and 3, producing messages with both formatting removed and 
letters altered to “X”. 
All messages were distributed to the academic staff members and the experiment consisted of 
“a timed-response decision task: participants were asked to press a key corresponding to 
whether each message was a call for papers or not.” After the trials, the participants were 
asked to describe any strategies that they used in categorising the messages. 
A 2 by 2 ANOVA was used to test whether there was interaction between the effects of 
formatting and text. The test results showed they play an important role in text categorisation 
Mann-Whitney tests were conducted on formatting and text and this showed that neither 
“removing formatting nor changing letters into X’s seemed to have any clear effect on 
response time.” In comparison, where formatting is kept in place an effect was observed. A t-
test was implemented to show if the effect of changing letters to X’s when format is  
preserved did significantly increase response time and this was in fact the case. Other 
discoveries were also made: 
1. Formatting did affect accuracy of categorisation with significantly more errors made 
on unformatted messages in comparison to formatted ones. 
2. Changing letters into X’s had a very significant effect on accuracy 
3. Even with all formatting erased and letters altered to X’s, participants were performing 
well. 
4. Calls for papers were categorised faster than other messages. 
Malcolm Clark Page 28 
The participants noted that in terms of core strategies used during the experiments, they  
1. Utilised the shapes of the messages and skimmed them 
2. Used centred blocks of text at the beginning of the text 
3. Viewed the first few lines looking for keywords, if formatting was removed, and then 
looked for dates as indicative of a call for papers 
The author shows that the stripping of the formatting had a clear causal effect on the 
relationship between text and formatting cues in classification and revealed the significance of 
formatting in human text categorisation.  
2.4.6 Other Studies of Concepts; Style, Form and Content Features 
Taking style, form and content into consideration there are simply hundreds of features which 
could be measured and the normal convention is to group them, or as Boese says, put them in 
feature sets. 
Other authors have written of Information Retrieval experiences using a diverse range of 
attributes of documents. Finn et al (2002) use three feature approaches, which are also 
examined for classifying documents by genre: 
1. Part-Of-Speech statistics(P-O-S) 
2. Hand Crafted Shallow Linguistic Features 
3. Traditional Bag-of-Words 
They draw attention to the difficulties inherent in identifying useful documents by applying 
machine learning techniques to the huge repositories of information which have resulted from 
the evolution of the World Wide Web. The authors identify genre as a significant feature and, 
in particular, the facets concerned with subjectivity, positivity or negativity.  
The writers are keen to explore the topic of Domain Transfer 6 which, in this context, 
measures how skilled classifiers generalise from a training corpus to a new document corpus.  
The evaluation is performed by computing the precision of the classifier in a solitary topic 
domain and when taught on one subject domain but tested on another. 
The authors show that an ‘ensemble learner’ based on different feature sets improves 
performance  for genre classification and that combining predictions from different 
approaches to sample discriminatively which documents to append to the training set; this 
tactic improves the learning pace of the genre classifier. 
They show that P-O-S is better than Bag-of-Words techniques in the context of domain 
transfer. 
                                                     
6 Domain Transfer indicates the ability of a genre classifier to classify documents that are related to topics rather 
than relying on trained documents. 
Malcolm Clark Page 29 
In another paper, Finn et al (2003) investigate which of three approaches performs best: B-O-
W(Bag-Of-Words), Parts-Of- Speech(P-O-S) or hand crafted shallow linguistic features. 
The authors explain the difficulties of genre classification and mention other techniques 
which currently exist, such as achieving High Recall precision and reports on two genre 
classification tasks which were performed with machine learning techniques. The tasks were 
to investigate whether news articles were subjective or objective or whether a review was 
positive or negative. The authors question current methodologies for genre classification and 
suggest Domain Transfer for generating classes. The accuracy for single domain experiments 
was evaluated by implementing ten-fold cross validation. The domain transfer is applied by 
training the classifier in one subject domain and testing with another. The evaluation consists 
of single domain experiments and evaluation of domain transfer.  
The results show that in the single domain, hand-crafted shallow linguistic features performs 
best with an average score of 88%. P-O-S is worst at an average of 85%. 
In the domain transfer experiments, the P-O-S features the best results and B-O-W performs 
worst which shows that keywords can be used to identify subjective documents but a model 
built using these features is more closely tied to the document collection used for training. 
The authors also suggest using filters for information retrieved by, for example, “educational 
background”, since the quality and type of information required depends on the user – for 
example, a secondary school and a PhD student would require different information. 
It is shown that the features based on Parts-Of-Speech statistics are able to be used to identify 
the genre of documents, particularly during the important transfer scenario in which the 
classifier is trained and tested on different corpora. Finally, Finn et al explain the extension 
they would like to include for the future such as whether a document is brief or detailed, the 
“level of topic expertise assumed by the author”, and whether the review is negative or 
positive. All these would be integrated into a “personal news retrieval and recommendation 
system”.  
Lee et al  explain in Part One how genre typifies text significantly different to the typical 
subject or prepositional subject matter that has been the focal point of Information Retrieval 
and classification research. Their two hypotheses are: 
“Genre classifcation information for training documents helps subject-based classification 
when it is used with the deviation formula proposed in this formula with this research” and 
“training a classifier with a set of documents belonging to a particular genre class improves 
subject-based classification” 
Malcolm Clark Page 30 
The authors claim that they have created a new method , which like that previously devised by 
Stamatatos et al, uses discrimination frequency analysis for the automation of genre 
classification based on statistically selected features of the form feature set ,which are 
”retrieved from subject and genre classified training data. “The genre classification method 
(algorithm) calculates the weight of a feature for a genre class by using its frequency statistics 
for subject classifications” (Lee et al 2004).  
After creating the function of the discrimination and deviation formula, implementing 
document frequency ratios works as required, the authors went on to study the roles of various 
types of features such as : 
        content-bearing words 
        function words 
        morphemes7 
        punctuation marks 
The experiments were performed on a set of documents which were retrieved from the World 
Wide Web(WWW) and split into genres: Critical review, Editorial, Personal homepage, 
Product specification, Q&A and Technical paper. 
These were then placed in subject categories by exploiting the hierarchy which was initially 
allocated to them. Kessler et al explain that as an augmentation to topical and structural 
principles of classification, genre is increasingly becoming an important part of computational 
linguistics due to the variety and increasing sizes of textual databases. The problem, they 
believe, is that it is a “…difficult notion to get a conceptual handle on”. The three authors of 
the paper suggest a “…theory of genres as bundles of facets”(Kessler et al 1997).The facets 
compare with various surface indications(or generic cues) which also argue that genre 
recognition is just as important as recognition based on the structural properties of text files.  
The generic cues identified by Kessler et al were: 
Cues Examples 
Structural 
 
Passives, Nominalisations, Topicalised sentences, Parts-Of-Speech tags 
Lexical Mr, Mrs, Dr etc 
Character-Level Punctuation such as , and : 
Derivative 
 
Cues and variations measurements which emerge from lexical and character-
level features. 
Figure 7 Generic cues 
                                                     
7 a morpheme is the smallest language unit that carries a semantic interpretation (Wikipedia 2005) 
Malcolm Clark Page 31 
The experiments consisted of analysing the Brown corpus texts in terms of three facets which 
were Brow, Narrative and genre. Each one had several levels assigned to it. genre, for 
example had Reportage, Editorial, Scitech, etc. The basic numerical method used for the 
experiments was Logical Regression which predicts a Boolean variable Y from logical 
relationships among a collection of Boolean predictor variables using a logit function. 
The experimental results are thus: 
1. Categorisation decisions can be made with reasonable accuracy using surface cues. 
Nevertheless, a close look at the results reveals that only some sub-sections of the 
facets performed well, such as Reportage and Fiction but that others did not perform 
particularly well.  
2. The experiments suggest that there is only a minor discrepancy between surface and 
structural cues. 
Stamatatos et al (2000), in a different paper, present a particular methodology for perceiving 
the text genre speedily and effortlessly. In their analysis of the Wall Street Journal collection 
they use style markers for the frequencies of occurrence of the most common words in a 
training corpus and as a comparison, they look at the most repetitive prose in an entire written 
dialect (British National Corpus). As a supplement to frequency analysis, the frequency of 
punctuation marks was tested as these sometimes play a vital function in detection of text 
genres. Stamatatos et al offer an example: an interview is generally typified by an unusually 
copious number of question marks. The most frequent types were measured, such as full-
stops, commas, colons, semicolons, quotes, parentheses, question marks and hyphens. The 
frequencies of the punctuation and, additionally, word frequency were tested on the corpus 
and, as before, cross-validated with the training corpus.  
2.4.7 Form 
The studies above are of course very important and as shown previously, the conceptual 
features mostly overlap but this study will only focus on the feature set Form. This project 
will be used to show that form on its own can distinguish the genre. Watt (2004) suggests that 
opportunities exist to advance text-centred IR methods, for example, text categorisation 
systems might consider merging formatting and text evidence. In his proposal, Watt (2005) 
states that the “layout and structure of documents reflects their purpose” and has 
experimentally proved this in Watt (2004). Campbell et al (1999), by also experimenting with 
form, found that the structure helps communicate the purpose of the document faster than the 
actual content. They showed how readers rely on layout of a document by either deleting 
Malcolm Clark Page 32 
format or, similarly to Watt (2004), by leaving the formatting untouched and totally replacing 
any content with X’s but leaving in punctuation.  
 
 
 
 
 
 
Figure 8 Format example 
 
Another example could be as follows: a reader picks up a broadsheet and visually scans it 
with his/her eyes, the columns and headlines alert the reader to the type of document. Again, 
if the content were removed or replaced with X’s the user would recognise the type of 
document. Here, user recognition of socially familiar discourses is triggered. A remarkable 
discovery was made by Collins et al (2000): they wanted to analyse genre theory and genre 
for tools development within one paper. The authors’ declared objective was to “investigate 
genre in terms of identification, analysis and classification of communal artefacts” and this 
work was structured into five tasks.  
Task one was performed first and the remainder in correlation: 
1. Extract the perspective and use scenario of the shared artefacts 
2. Represent core, stable, hard to obtain knowledge in an ontology. 
3. Investigate possible genres 
4. Perform genre investigation in context of layout, structure, and community 
vocabulary. 
5. Apply and test within the aimed community 
The work was implemented using an electronic newsletter called KMi Planet in the form of a 
webpage. The holistic aim of the initial examination was to gain verification as to whether 
community genres can be successfully recognised and used to support the sharing and 
retrieval of documents or messages within a community and,  in this case in particular as to 
whether writers of  the stories had developed a type of genre that could be exploited to allow 
the correct stories to be recovered with a high measure of precision. 
Once stages 1-3 were completed and the genre was distinguished, the genre analysis began 
(number 4).The messages were reviewed by structure and format. These were completed 
together in correlation. The authors next proceeded to use an inverted pyramid developed by 
X X X X X X X 
     X X 
X X X X X X X 
X X X X X X X 
X X X X X X X 
X X X X X X X 
X       
M T W T F S S 
      1 2 
3 4 5 6 7 8 9 
10 11 12 13 14 15 16 
17 18 19 20 21 22 23 
24 25 26 27 28 29 30 
31       
Malcolm Clark Page 33 
Keeble in 1998: the layers of the pyramid number seven - who, what, where, when, why, and 
how. The procedure was to layout the most important information at the top of the inverted 
pyramid and the least important information at the bottom. Collins et al discovered that a 
pattern existed which was markedly different from the “naïve ‘distance from the beginning’ 
heuristic used by some search engines.” One of the reasons for this was that the headline was 
placed first, but this was deemed not to be useful in some instances with regard to the story 
content. The layout of the genre does reveal the ideal placement of the story content and is 
represented so “community-independent heuristics like these are bound to be limited”. The 
analysis of the different structures of the stories began to look for differences in vocabulary 
and mark the text item as evidence of the genre in the terms. The authors applied “1 by 2 chi-
tests8” to look for more important words that were more likely to show in the first sentence 
than in the rest of the document. 
Collins et al then went on to create a “browsing tool” to test for the community genre which 
focused on word patterns occurring in the first sentence and then parsed the html stories into a 
structured database which is queried using the identified story structure. By utilising the terms 
identified in the vocabulary analysis the stories are categorised according to the topics of 
interest to the community. The classification was shown to have high precision even for new 
stories which were not considered for genre analysis.  
In conclusion, Collins et al claim to have discovered a style which imitates a journalistic 
practice genre. The revealed journal can be used to support the automatic analysis of the 
stories and IR. As regards tools, they specify that developed tools must implement 
“community genre” to identify what a commune deems important. It would be interesting to 
discover in the future whether the same features and methods could be utilised on highly 
structured documentation such as XML. Seki (2005), in a report which has just become 
available in ACM, claims to have used document genre and structure of documents to apply 
methods for topic and genre retrieval by merging them, and has shown significant 
improvements in returning a user’s needs. Two of his stated aims were “Single-Document 
Summarization Using Text Structure: Summarization for a Specific Document genre, 
Newspaper Editorial” and “Multi-Document Summarization Using Document Genre and Text 
Structure: Summarization of Multiple Genre Documents Based on the User's Information 
Needs”. The first aim showed, according to the author, the high value of summarization to 
retrieval. 
                                                     
8 Simplistic rule in statistics that states it  is always essential to discover whether the products of any tests are 
sensible 
Malcolm Clark Page 34 
With regard to his second aim, Seki stated “Document genre was determined by a 
combination of values according to four dimensions of genre: situation dependency, 
argumentation, impersonal styles, and factual reporting”. Six sentence types were analysed to 
differentiate the text structure. He showed that his proposed methods produced summaries 
consistent and relevant to the user's information needs. 
2.5 Conclusion 
At present, it seems that much research is being carried out on conventional IR document 
collections, for example, using the TREC collection. In particular, there are numerous papers 
detailing genre research experiments published by ACM, SIGIR to name but a few. 
Further work is essential, however, in the field of genre information retrieval research, using 
all collections and not just XML. All the facets of creating a system, implementing such 
techniques and performing evaluation need to be subjected to long-term, detailed analysis, 
but, given the time constraints placed on this project, this is not possible here. In addition, 
there is insufficient time to carry out a deep and thorough evaluation of the retrieval results so 
that a simplified model will have to be devised parallel with implementing the hardware. 
It has been proved comprehensively by many authors that genre can be retrieved using 
features of form, content and style, sometimes utilising a mix of the three in comparison. 
There are few studies, however, which focus solely on the form concept, although Watt 
(2004), Campbell et al (1999) Collins et al (2000) and Rosso(2005)  have proved that genre 
can be categorised using just form features from analysing human behaviour, whereas Seki 
(2005) used summarisation and genre. The limited number of studies concentrating on this 
one concept with XML and unfruitful searches for such literature make it clear that this 
project is entering almost un-chartered waters. Retrieval using a subset of form features is 
now going to be tested during the Implementation stage of the project, which is laid out in 
Chapter Three. 
 
Malcolm Clark Page 35 
CHAPTER THREE 
 
3. TOOLS, REQUIREMENTS, METHODOLOGY AND DESIGN OUTLINE 
3.1 Aims of Implementation 
1. Create initial detailed design 
2. Finalise detailed design of index and search tool 
3. Create indexer using Java™ 
4. Perform indexing 
5. Write the software for the search engine 
6. Conduct testing   
7. Compile, write-up results and convert to ARFF format 
8. Perform classification on results and evaluate 
3.2 Development Tools 
One large problem identified during this project was the administration, portability, 
consistency and security factor, which by security this is meant as version back-ups, to aid 
with the implementation of this project the supervisor Dr Watt recommended using:  
1. Maven/Mevenide 
2. Eclipse/Subclipse  
3. Subversion server 
Figure 9 Project Development 
  
 
 
Subversion 
Server  
Home PC Flat 
Laptop 
Send/Retrieve file updates 
Send/Retrieve file updates Send/Retrieve file updates 
Malcolm Clark Page 36 
The development model is setup so that work can be performed in a location determined by 
the developer. There is a considerable amount of installing and configuration to perform on 
each workstation and the single laptop. All of the software listed Maven, Eclipse, Subversion, 
Lucene, and Digester is open source which means that it is licensed for the user to operate 
quite freely with the source code as long as a few guidelines are followed, such as distributing 
copyright notices with Eclipse software. 
As there is only one developer for this project, concurrency is not an issue although this will 
be mentioned briefly later. 
For the sake of clarity, it is necessary to describe each tool component in this development 
3.2.1 Maven 
The Apache Maven Team (2005) state “Maven is a software project management and 
comprehension tool. Based on the concept of a project object model (POM), Maven can 
manage a project's build, reporting and documentation from a central piece of information.” 
The software exists to make life for Java™ developers easier.  
The Apache Maven Team (2005) set out all their objectives: 
1. Making the build process easy 
2. To offer a uniform build system  
3. To offer quality project information  
4. To offer guidelines for best practices development  
5. To allow transparent migration to new features  
The Apache Maven Team (2005) describe the following features: 
1. Model based builds using predetermined output formats such as WAR and JAR, 
mostly removing the need for scripting. 
2. Coherent site of project information uses the project metadata to generate a website 
and standardised reports focused on during the project 
3. Release management and distribution publication allows integration with a source 
control system for a distribution location for other projects. 
4. Maven uses a dependency system. For example, if a user’s project needs Xerces.jar 
and Lucene.jar, it will read this from the POM and automatically download them to 
the users Central Repository. 
3.2.2 Eclipse 
The Eclipse platform/IDE is a small sub-set of the open source community called Eclipse, 
which provides much for its users. The consortium was started up by IBM when they released 
the Eclipse platform as open source but now it is now a large and continuously growing 
Malcolm Clark Page 37 
collection of well known, and some little known, organisations, for example, Hewlett 
Packard, IBM and the OMG (Object  Management Group who specialise in Distributed 
Systems. There is only one condition for joining the foundation: is the potential member 
organisation has to offer a plug-in within one year of joining. One of the foundations’ goals is 
being established “to engage with commercial developers and consumers, academic and 
research institutions, standards bodies, tool interoperability groups and individual developers, 
plus coordinate Open Source projects.” (The Eclipse Foundation 2004).  
There are many projects in the Eclipse Foundation namely The Eclipse Tools Project, The 
Eclipse Technology Project, The Eclipse Web Tools Platform Project, The Eclipse Test and 
Performance Tools Platform Project, Business Intelligence and Reporting Tools (BIRT) 
Project, Data Tools Platform Project (DTP) and Device Software Development Platform 
(DSDP).The many projects listed are beyond the scope and need of this project so this project 
will only use the so called Eclipse Project. The Eclipse Project provides “a robust, full 
featured, commercial-quality, industry platform for the development of highly integrated tools 
and rich client applications.” (The Eclipse Foundation 2002). The Eclipse project provides 
JDT (Java™  Development Tools), PDE (Plug-in Development Environment) and the Eclipse 
Platform. Even though Eclipse does provide all the Java™ functionality a Java™  Runtime 
Environment is still required. 
Figure 10 Partial screenshot of the Eclipse IDE(The Eclipse Foundation 2004) 
 
3.2.3 Mevenide 
To begin with, it was more suitable to learn Maven with the command line interface/console 
but there is a facility or plug-in to connect Maven to an IDE, namely Eclipse via Mevenide. 
Malcolm Clark Page 38 
Mevenide can also provide integration for Netbeans, IntelliJ and JBuilder. 
 
Figure 11 Using Maven from Eclipse (The Eclipse Foundation 2004) 
Mevenide, which has the full name Integrating Maven into IDE’s - Mevenide Eclipse, allows 
a user to execute Maven ‘goals’ via the Eclipse IDE. Mevenide allows a user to update Project 
files, Synchronization of IDE with POM, to launch Maven from the IDE (Figure 9 ).To setup 
the Maven/Eclipse link the user simply imports the project files from Maven to Eclipse. For 
this project it enabled the execution of the JUnit tests (sample programs in this context) and 
main project files. A useful feature utilised in this project is the ability to store and Execute 
the JUnit tests stored in the Maven directory and the importation of the many Jar files; 
Commons Digester, Lucene, Commons Logging and Commons Beanutils. 
3.2.4 Subclipse  
The second plug-in installed into Eclipse is the Subversion Server plug-in namely Subclipse. 
Again, this allows integration of Subversion servers into the development environment. An 
explanation of a Subversion server is given in the next section, but in short, Subclipse enables 
Eclipse to connect to the server which allows exchanges (Commit or Update) of files for a 
project. There are, of course, other simple facilities which are too many to be detailed here 
such as synchronization. 
 
 
Malcolm Clark Page 39 
3.2.5 Subversion Server 
Collabnet (Collins-Sussman et al 2004) commissioned a team of developers to find a 
replacement for CVS, which is version control for source code and other project documents. 
They tried to create something which would retain the features of CVS but remove the bugs 
and other little annoying aspects which users had pointed out. The team of developers created 
a system which would be a replacement but would also allow users to transfer very quickly 
from CVS. This new system is Subversion which was released in 2001 and is managed by a 
few developers who are paid by CollabNet. It is, however, completely open source and is 
“governed by a loose, transparent set of rules that encourage meritocracy” (Collins-Sussman 
et al 2004)   
Subversion is an open source licensed control system, which manages files and directories 
from a tree of files located in a central repository. It allows users to manage version control of 
their project files and is critical for programmers and other types of people or organisations 
who need to manage information. 
Subversion servers are useful as they remember every version of files and allow for them to 
be recovered if there is a problem discovered in the current version of the files. As shown in 
Figure 9, the server allows for file and directory access from any setup location which halts 
the necessity of transferring files. Collins-Sussman et al maintain that the real worth of such a 
facility comes from a multi person/site development as the ability to modify and manage 
information fosters collaboration. They point out that some systems hold trees of software 
files and other features for software development whereas Subversion allows the tree based 
storage of any file type the user wishes. 
3.3 Indexing  
3.3.1 What is indexing?  
It is a process of translating a document collection to a form so it can be speedily searched. 
Most documentary objects can be indexed except text in imagery such as photographs. 
Hatcher et al(2004) described the concept behind indexing. Would a reader pick up a book 
and try to find the relevant segment of text by scanning each page sequentially? No that 
would be far too time consuming so the reader consults the index to find the relevant passage 
of text.  
In the context of this project one of the most important aims was to parse and index the 
document collection of INEX files, and, for this reason, a capable and powerful indexing tool 
needed to be identified. To achieve this aim, a tool for translating and constructing the XML 
into Java™ objects was required. Gospodnetic (2003), in a web article, explained the 
Malcolm Clark Page 40 
suitability of marrying Digester and Lucene together. The implementation of the three 
components “cut down your development time for projects in which you manipulate XML.” 
and remove the need for building complex interfaces using SAX. He identified three 
components:       
3.3.2 Logical Indexer model 
 
 
 
 
 
 
Figure 12 Indexing process identified by Gospodnetic (2003) 
 
Already being only slightly familiar with Lucene, being part of the Apache project, this open 
source environment provided all the required solutions of Indexing and Searching. Lucene is a 
great indexer for plain text documents but could it be used for XML? Gospodnetic (2003)  
asserted that this was possible and that it was necessary to find software,which is extendable, 
powerful, adaptable, speedy and capable of performing all the required tasks parallel with 
each other. 
3.3.3 Digester 
It is essential to give brief coverage to DOM and SAX (Data Centric XML) before moving on 
to Digester because while investigating the available API’s (Application Program Interface) 
for processing, accessing and manipulation of XML with Java™, two names often emerged: 
DOM (Document-Object-Model) and SAX (Simple API for XML). DOM, it was discovered, 
is only used for tree based representations of XML structures and is highly memory intensive. 
It is used in conjunction with XML, HTML and CSS stylesheets and is mainly used for 
structural processing of the XML files, but will have a small but vital role in the indexing 
process. SAX, according to Harold (2002), is an event-based API for reading XML input 
streamed documents. It includes many types of Parser, which are covered next, namely 
Xerces, Crimson, MSXML, Oracle XML Parser for Java™ and is faster and less memory 
intensive than DOM. SAX is also used with many different object-orientated programming 
languages namely Python, PERL and C++.  
Digester is part of the Apache Commons group and is an interface which is used for 
converting XML to Java™ objects. It provides a high level method of XML processing to 
trigger a SAX event which in reality is not that simple for a developer to use. Digester allows 
 
Component 2: 
Parser 
 
Component 1: 
Translate to 
Java™ objects 
using Digester  
 
Component 3: 
Index objects with 
Lucene 
 
XML file 
Malcolm Clark Page 41 
a XML file to be read and each time an element is found, a method is triggered creating a 
Java™ object in an event-driven manner. Anyone familiar with a stack in programming will 
understand the methodology involved with this particular type of data structure. 
The stack works on a First-In-First-Out (F-I-F-O) basis and has many operation such as push 
which pushes an object into the stack, pop which removes it, top which returns the top item 
and finally isempty and isfull which respectively check the level of content in the stack. 
 
 
 
 
Figure 13 Stack Diagram 
Digester has the following steps for its operations: 
1. Create a new instance of Digester (For example Document). 
2. Setup the configuration properties. For example, rules (covered later) or name space 
awareness. 
3. Push objects onto the stack as already discussed. 
4. Register Element Matching Patterns to identify the processing rules which are 
executed when each pattern is matched. 
5. Call the parse method by pointing digester to the XML file and identify the exceptions 
which need to be caught. 
Each Element Matching Pattern becomes a text field which in turn are added to the document. 
To nominate Element Matching Patterns some knowledge of the XML files structure is 
needed. For example:    
XML segment: 
<book>  
<chapters> 
<chapterone></chapterone> 
<chaptertwo></chaptertwo> 
</chapters> 
 
Figure 14 XML file and Digester EMP’s 
Once a pattern is matched whilst the XML file is being read, an event is fired to create the text 
field which in turn is added to the document Java™ object. The document object is then ready 
to be indexed. Interestingly, Digester allows for flexibility in pattern defining. A wild card 
push 
pop 
Equivalent EMP segment in Digester: 
book 
book/chapters  
book/chapters/chapterone 
book/chapters/chaptertwo 
 </book> 
 
Malcolm Clark Page 42 
symbol can be used such as * and, for example, book/chapters could be replaced by book/? so 
any pattern matched after the book element will fire off an event. 
Digester, of course, contains many other classes, methods and plug-ins involved with Digester 
such as:  
1. Plug-ins - dynamic adding of rules during the Digester processing. 
2. Substitution – enables manipulation of XML before rules are processed. 
3. xmlrules – enables XML based definition of rules. 
Unfortunately, there are a few issues with Digester which cause concern, such as: 
1. The digester API (The Apache Software Foundation 2005) states that Digester is not 
normally ideal for parsing multiple XML documents but there are some methods, 
which can be implemented to overcome this difficulty. For example, creating a new 
instance of Digester for every XML document. Fortunately, this was already taken 
into account for the beginning of the implementation phase.  
2. DTD issues are important as there are many entities, which the parser may have 
trouble validating. 
3. The XML files ‘article’ do not display a DTD declaration at the top, unlike the 
‘volume’ files, which the Digester/Xerces parser may not agree with. A method of 
declaring the DTD location will have to be implemented such as a entity resolver. 
3.3.4 Parsing XML document with Digester 
Wikipedia (2005) provides excellent definitions for parsing and parser.   
Parsing:  “process of analyzing a continuous stream of input in order to determine its 
grammatical structure with respect to a given formal grammar.” 
A parser: “a parser is a computer program that carries out this task”. After consulting the 
Digester API, it was discovered that only two parsers are configured for it at present: Xerces 
(named after the blue butterfly) part of Apache and JAXP (Java™ API for XML Processing) 
associated with Sun Microsystems. They both provide the capability of validating and parsing 
XML documents using two basic parsing interfaces which are, of course, DOM and SAX. 
Xerces also incorporates SAX2 whilst DOM includes stylesheets capability XSLT . If the 
parser is not defined in the code then Digester will default to the Xerces collection probably 
because it is part of Apache foundation. Wikipedia (2005) states “Xerces is a family of 
software packages for parsing and manipulating XML. Xerces provides world-class XML 
parsing and generation”. In Commons Digester, the Xerces parser requires a minimum of 
version 1.3.1 whilst JAXP is 1.1. 
 
Malcolm Clark Page 43 
3.3.5 Lucene Overview 
Lucene is a high performance and scalable Information Retrieval library (not a ready to use 
application) which allows Indexing and Searching capability to application. One of the 
benefits of Lucene is that like Digester, Eclipse and Maven, it is an open source community 
library in which withdrawals are made but never returned although this is not completely true 
as the community does exchange their creations. For example, Luke (Figure 15 below) is an 
application which is made from Lucene. 
As Hatcher et al (2004) point out, the success of an application is normally judged by how 
many programming languages have portability. So far PERL, C++, Python Microsoft .NET, 
Ruby C and Delphi have Lucene capability. Many groups have implemented Lucene into their 
applications: for example, Wikipedia, which has provided some encyclopedic computing 
knowledge throughout this report, is powered by Lucene.  In addition to Lucene, there are 
other types of index and searching libraries available on the internet (Hatcher et al 2004): 
Egothor is similar to Lucene in core components and operates using the Boolean model which 
has already been discussed. It does not, unfortunately, index XML but does work on many 
other popular formats such as Microsoft Word documents and XLS. Xapian is another 
example: this based on C++ but is not at present porting to Java. It is based on the 
probabilistic model but indexes only a very limited sub-set of Rich Text Format documents.   
 
Figure 15 Luke 
Lucene has other features which are useful but these not pertinent to this project and will 
therefore not be used. Optimization allows the mixing of many large indexes to save space on 
the hard disk which is not applicable to this project. Concurrency issues are dealt with by 
applying locks which will only allow one user to write to the index at one time, though many 
Malcolm Clark Page 44 
can read it at one time. As there is only one user at present for this index, it is not essential. 
Another feature which may be implemented is RAMDirectory which is detailed later in the 
Searching section. 
3.3.6. Lucene Indexer 
This is without doubt the trickiest part of the project implementation as has been discovered 
by running small code samples during the investigation. 
Several different types of indexers are available in many programming languages, such as 
Zebra, which provides structured text indexing and a powerful retrieval engine. It reads 
records in a variety of formats and provides access to them through Boolean search and 
relevance ranked queries. Zebra only supports four filetypes: GRS-1, XML, MARC and 
SUTRS, which is not good for extendibility, and it does not have a Java™ capability. Other 
types of multi-language, meaning programming language, IR applications are available on my 
operating systems. Xapian is a Probabilistic based search engine, Zetir for HTML and TREC 
corpus retrieval and Terrier which is an application for the speedy creation of Web, intranet 
and desktop search engines. 
According to The Apache Software Team(2005) the index will be reduced by a maximum of 
30%, has small Random Access Memory requirements and processes 20Mb a minute on quite 
a low spec processor. These claims will be evaluated when the indexing is performed in the 
Implementation stage. 
Lucene provides two components: Indexing and Searching, but for this section only the 
Indexing segment of Lucene will be discussed. A fuller introduction to the Lucene Searching 
capabilities is written in section 3.4. Hatcher et al (2004) clarified the requirements for the 
indexing aim. The core components of Indexing are IndexWriter, Directory, Analyzer, 
Document and Field. 
3.3.7 IndexWriter 
This class is used to create an index and add documents objects to it. This gives a user the 
ability to write only to an index of choice. 
3.3.8 Directory 
The directory class symbolizes the index location and its methods are associated with a vital 
link to the file system directory. It has many useful facilities for representation of the index as 
not only a disk mounted but the ability to store and define Random Access Memory instances 
of the index. RAM directories allow much speedier processing of the index. 
 
 
Malcolm Clark Page 45 
3.3.9 Analyzer 
To process the information to the index it is run through an analyzer which depending on the 
type can weed out the unwanted content. Hatcher et al (2004) state that all information post-
analyser becomes tokens and the rest is discarded. As this project uses XML and not plain 
text the data to be indexed is translated as already described. 
3.3.10 Document 
This is a virtual Document which contains many fields (which are formatted and created in 
this instance by Digester). The format of the document, according to Hatcher et al, could be 
Word, Rich Text Format and XML. 
3.3.11 Fields 
The final item in the list above is Field. The document as mentioned contains many fields 
which are retrieved by search query or from the index. 
Four types exist according to Hatcher et al Keyword, UnIndexed, UnStored and Text. All of 
these fields can co-exist with each other in one document. 
3.3.12 Keyword 
This is indexed and stored in exactly the same form as processed which means it is not 
analysed. If there is a requirement to preserve the original format of the data then place it in a 
keyword field, for example, Uniform Resource Locator (URL), dates and file paths.  
3.3.13 UnIndexed 
These field types are not indexed or analyzed so is useful for field types which equate to 
primary keys or URL and is unsuitable for large values. 
3.3.14 UnStored 
This field has the reciprocal action to UnIndexed as it is stored and indexed but not stored in 
the index. It is useful for large bodies of text or, for example, paragraphs <p> from XML 
documents. 
3.3.15 Text 
This is analyzed and indexed so that it can be searched but caution is advised when using it. If 
a piece of text is indexed as type String such as “Malcolm” then it will be suitable for 
searching. However, if the text is read using a Lucene ‘Reader’ then storage will not be 
possible 
 
 
 
 
Malcolm Clark Page 46 
3.3.16 How does Indexing work? 
 
 
 
 
 
Figure 16 Indexing 
 
3.3.17 Converting the Text 
As mentioned already, with Lucene, the text has to be extracted and converted into a stream 
of tokens and forced to populate the fields. This works well for plain text but is a completely 
different matter for indexing XML. The methodology of preparing XML data for indexing has 
already been demonstrated in the Digester section. 
3.3.18 Analysis 
As soon as the data is prepped in the form of a document it is then analysed by Lucene. An 
Analyzer builds TokenStreams, which analyze text. There are many types such as Standard, 
Stop and WhitespaceAnalyzer. For example, the StopAnalyser removes Stop words which are 
considered as un-useful such as A, the and is. Additionally, there are different types of 
language analysers such as German and Russian. 
3.3.19 Writing the Index 
Post analysis by Lucene is swiftly followed by writing all the data to the index. The whole 
structure is stored in an inverted index. Hatcher et al claim that this data structure enables 
efficient usage of disk space whilst enabling quick searching. The authors also maintain that 
the index is inverted because the tokens are used as primary searching keys instead of the 
documents themselves. Most search engines on the World Wide Web are constructed as such 
but the look-up parameters are closely guarded secrets. 
It is worth noting that Lucene also allows users to update, delete, undo deletions index 
contents as required. This is beyond the scope of this project which only requires the reading 
of the index. 
3.4 Searching Tools 
In direct contrast with Indexing and the components needed for that task, searching is not 
simple but more straightforward. Only one API is required: Lucene. 
So why Lucene? XPath is a useful non-XML syntaxical facility for navigating the nodes of an 
XML structure whilst XQuery is semantically more like SQL (Structured Query Language) 
 
Stage1 
 
Converting the Text 
 
Stage2 
 
Analysis 
 
 
Stage3 
 
Writing the Index 
 
Malcolm Clark Page 47 
and much praised by the W3C. It is arguably preferable to query an index of a whole 
collection, such as INEX 1.4, and provide useful results for a user much like a search engine 
on the World Wide Web without having to have knowledge of the XML structure. Putting 
aside the difficulties inherent in indexing, Lucene provides an API of much power and 
extendibility to perform user searches of a simplistic nature and clarity. 
3.4.1 Lucene Searching 
Hatcher et al (2004) clarified what was needed for the Searching aim. The core components of 
searching are: IndexSearcher, Term, Query, TermQuery and Hits.  
3.4.2  IndexSearcher 
The searcher is the connection to the index (read-only) and offers many methods which the 
user can exploit for building a search apparatus to explore the index. It has an abstract class 
Searcher which, in its simplest form as Hatcher et al point out, takes the Query as a parameter 
and Hits is returned to tell the user how many hits were returned. The IndexSearcher is 
generally pointed towards a file path or directory and plugs-in to the index. It is recommended 
that a user should utilise the directory structure since “it’s better to decouple the searching 
from where the index resides” (Hatcher et al 2004). 
Taking speed into account, it is sometimes appropriate to consider loading an index in RAM 
if, for instance, your hardware resources are low performance and it would be 
computationally feasible to do so. An index can be kept persistently in the computer’s 
memory allowing for lightning fast demand searches. The decision regarding the use of 
RAMDirectory should also depend on whether the memory available is higher than the size of 
the index. 
3.4.3 Term 
The term component is the basic requirement for searching. It is formed to match a search 
term with the document term and searches the index looking for a match. The term is used in 
conjunction with TermQuery. 
3.4.4 Hits  
This is a range of facilities to display ranks and scores for the searches. For example, it can 
return a score, normalised between 0-1 against the highest document, for each Hit in the 
search. The scoring function class named ‘Similarity’ in the Lucene API uses a formula based 
on tf*idf which produces a raw score. (The Apache Software Foundation 2005): 
∑ tf (t in d) .idf (t).boost (t.field in d).lengthNorm (t.field in d)  * coord(q,d)      
Figure 17 Scoring Formulae 
 
t in q 
* queryNorm(q) 
Malcolm Clark Page 48 
The breakdown of the formula fields is thus (Hatcher et al 2004): 
1. tf (t in d) -    Term frequency factor for the term. 
2. idf(t) – inverse document frequency of the term. 
3. boost (t.field in d) – Field boost, as set during indexing. Allows user to effect query by 
setting influence of field on the raw score 
4. lengthNorm(t.field in d) – Normalisation value of the element after appropriating the 
amount of terms. Computed during the indexing process and stored. 
5. coord(q,d) – Coordination factor, based on the amount of query terms the document holds. 
6. queryNorm(q) Normalisation value for a query, given the sum of the squared weights of 
each of the query terms. 
The Similarity class has many score settings which can be altered to suit the user such as the 
frequency square root but any deep explanation of the computational theory is beyond the 
scope of this volume. 
There are a couple of Hits implementation issues which need to be carefully considered but 
these are in a web context and do not need to be discussed at present. 
3.4.5 Query 
There are many types of Query: 
BooleanQuery                           SpanQuery 
PhraseQuery                             TermQuery 
PrefixQuery                              FuzzyQuery 
RangeQuery                              FilteredQuery 
PhrasePrefixQuery 
3.4.6 TermQuery 
Hatcher et al(2004) point out that this is the most basic type of query for Lucene API. A basic 
description of using TermQuery is written above in 3.4.3 Term. 
3.4.7 Searching Query Types 
BooleanQuery – This query allows the settings of flags to query an index using conditions 
OR, NOT or AND. The settings allow the setting of attributes as to whether a term should 
optionally, must or must not contain a term. 
PhraseQuery – This query allows searches of whether a term appears near to the actually 
retrieved term and it would be a useful query in the context of computational linguistics to 
study Word Sense Disambiguation (WSD) in order to examine in which sense a word, which 
has many distinct senses, is written. For example, Bank has many distinct meanings, for 
example, it is a place to manage your money or where people sit beside the river. By 
Malcolm Clark Page 49 
searching the surrounding words it is sometimes possible to deduce the context in which the 
word appears. 
It is worth noting that PhraseQuery also allows multiple terms to be specified for a search and 
wildcard queries which allows the searcher to submit partial terms such as Dog could become 
?og. 
PrefixQuery – This matches documents containing terms which start with the specified term. 
It is possible to search a hierarchical structure recursively using a simple keyword. 
PhrasePrefixQuery – This is a mix, of course, of the Phrase and Prefix types of queries.  
RangeQuery – This query type allows for searching in a range between two values. A 
common example would be searching for all information between two dates. 
FilteredQuery – This query filters the results of another query. 
FuzzyQuery – This allows terms similar to the indexed data. So if the search were for Cat, 
then Mat would also be returned.  
3.5 Indexing and Searching Conclusion 
To conclude this section: Lucene Indexing has much potential for this project and with the 
correct implementation and use of the library it should be a speedy and accurate solution to 
the indexing problem although there are some problems which are discussed later. How 
Digester, Xerces parser and the Lucene indexer operates with the whole INEX 1.4 collection 
is not quantifiable until actually performed so an estimate of the duration of indexing is 
difficult. It does perform well in small test programs but these are not as memory intensive as 
the proposed indexer application. A previous indexing program written entirely in PERL by 
Dr Watt took around twenty-four hours to index the full INEX collection so any duration 
under that total could be considered a minor success. 
As Hatcher et al show, a simple query is relatively easy to construct so 
that the querying of the index should be comparatively straight forward. Unfortunately, the 
many problems with indexing have limited any detailed tests of queries at this point but some 
types such as TermQuery should be very useful for the extraction of the features. By 
investigating the Lucene API and reading Hatcher et al (2004) samples it should be possible 
to extract the features identified using specially constructed queries. The scoring and ranking 
methods are truly remarkable and return the most relevant documents to the query which is 
very useful. The indexing and searching sections in this volume really only touch on the full 
capability and methods available but the main aspects of these two important tasks have been 
identified. 
 
Malcolm Clark Page 50 
3.6 Outline Design 
 
The figure 18 displays the components of the indexing and searching model necessary for 
implementation of the application. 
 
 
 
Figure 18 Proposed model   
 
 
 
 
 
 
 
 
 
 
 
3.7 Basic Functionality of the GUI 
The functionality specified below is only a loose interpretation of what’s required and any 
decisions made to change any aspects of the model will be fully documented during detailed 
design and the implementation phase.  
The application GUI will be formed by two tabbed panels. Items 1-4 will form the indexing 
panel and 5-8 will be on the panel concerned with searching/retrieving. 
1. Open index (open index) location by Filefilter 
2. Create an index 
3. Delete an index 
4. Indexing Admin Add document to index 
5. Remove document from index 
6. Search by keyword and view result 
7. View document  
7.1. By document variable feature types (Figure 20) collective 
7.2. By document variable feature types (Figure 20) singular 
8. Overview 
8.1. Number of fields 
8.2. Number of documents 
8.3. Number of terms 
8.4. By document number 
9. Settings 
             
       SearchEngine 
       IndexWriter 
 
             
         Digester  
         
           Analyzer       
     
             
       IndexSearcher 
             
TermQuery/Query 
Text input- 
add fields 
Text to index 
Text  index 
writer.addDocument  
             
            Index 
 
Output query results/hits 
get text 
query (parse) index by term 
return 
length,score, 
get title 
/content 
parse by doc, 
content/title 
write to index  
            Hits 
Malcolm Clark Page 51 
10. Colours 
11. Font 
12. Help and About 
3.8 Identified Problems 
One problem was identified while setting up the tools for development. In particular, the 
Subversion server is only available from home and C11. The laptop is having trouble 
connecting via proxy settings from Woolmanhill. A solution will hopefully be found during  
consultations with Dr Watt. 
Two repetitive and as yet unsolved problems were identified regarding the Indexing during 
phase one: 
1. The method of handling DTD’s has to be looked at closely during implementation. The 
parser had many problems parsing undeclared entities such as &copy which symbolises the © 
symbol. A possible solution is to employ a Entity Resolving method which is mentioned in 
the Digester API.  
Originally using a line in Digester:  
<!DOCTYPE books PUBLIC "-//LBIN//DTD IEEE Mag//EN" "xmlarticle.dtd" 
The above line was used to point the parser to the DTD and relevant files but did not work as 
expected: in an attempt to clarify the situation regarding the DTD handling it was necessary to 
try to contact the author of the article Gospodnetic (2003) in which he explained the 
“marrying” of Lucene to Digester. Thankfully the author replied and explained that the line 
above was not specified to do what it was being used for in this project example (entity 
resolving) but just to tell the parser where the DTD is located. 
2. During the parsing of the XML files all named Volume.xml the parser would only index 
the last XML element in any repetitive list. For example:  
<book> 
</chapters> 
<title></title> 
<title></title> Only this title element is indexed 
</chapters> 
</book> 
Gospodentic suggested that Digester/Lucene should be able to store multiple pieces of text in 
each Digester field so he is at a loss to explain why the project example is behaving as it does.       
 
 
Malcolm Clark Page 52 
3.9 Methodology 
3.9.1 Corpus 
The INEX XML collection consists of 12 magazines: the IEEE Computer Society’s 
publications from between 1995-2002. The content of each folder consists of a volume file 
and many individual article file types.  
For example: Figure 19 INEX 1.4 corpus 
 
1995                
1996 
1997 
1998 
1999 
2000 
2001 
 
Lalmas et al (2004) point out that there are 12,107 articles which each contain an average of 
1,532 nodes with the average depth of a node being 6.9. There are over eight million elements 
to index which amount to 494 Megabytes of information. 
The INEX corpus is very different to some of the typical plain text corpus, for example, 
Stamatos et al (2000) explain the system they developed by categorizing a homemade corpus 
of Greek text created from free text available on the World Wide Web. Boese et al (2005) 
used the WebKb (Web Knowledge Base), Meyer zu Eissen and FAQ for their comparative 
study on Effects of Web Document Evolution on Genre Classification. 
3.9.2 Features to be analysed 
For the sake of clarity and as a result of time constraints, this study will focus on ten specially 
selected features. A few of the mechanisms for the pre-processing of data are: Document 
Frequency (DF), Mutual Information (MI), Information Gain (IG). As the list of features is so 
short, it will not be necessary to implement feature selection (to choose which are the priority 
to study) and is subsequently beyond the scope of this project. 
 
 
 
 
 
each year folder contains a volume.xml explaining the 
structure of the volume file and between forty-three and 
fifty xml files with a naming convention such as  
a1003.xml or t312.xml 
am 
Malcolm Clark Page 53 
The following form features to be analysed are:  
Feature Type Examples Reference  
(if applicable) 
Proposed method of 
extraction 
Verbs Passive bitten, presented (Boese 2005) Lucene Query 
 Active bit, present   
Word average Average 
words in 
paragraph 
 (Boese 2005) Lucene Query 
Paragraph Average 
paragraph 
length 
 (Boese 2005) Lucene Query 
Pronouns Subjective I you he she they 
we it  
(Boese 2005) Lucene Query 
 Objective me you her him it 
us you  them 
 Lucene Query 
XML tags Amount of 
tags in 
article 
<title>,<p>,<it>, 
<yr> <date> 
<img> 
<tbl><item> 
<label> 
(Boese’s 2005) 
‘though used 
HTML’ 
DOM printTree 
program 
Tenses Present Take  Lucene Query 
 Past Took  Lucene Query 
 Future Will Take  Lucene Query 
Punctuation Formatting Q & A with many 
? 
(Statamatos 2000) Lucene Query 
URL links Articles with 
many links may 
indicate regular 
feature 
(Boese’s 2005) 
 
Lucene Query or 
DOM printTree 
Nominalizations Excessive 
use of 
nouns over 
verbs 
…caused the 
introduction of 
Fin et al(2002) Lucene Query 
References Amount of 
INEX 
Feature 
articles 
INEX 
2004\inex-
1.4\xml\cg\
1996\ 
G3032 G3042 
G3052 G3058 
G3064 
 Lucene Query 
Figure 20 Features to be analysed 
 
The features selected have been found by the referenced authors in their experiments to aid 
the identification of documents by genre and have been found to be within the INEX 
Malcolm Clark Page 54 
documents. The features will be retrieved by a carefully constructed range of queries using the 
Lucene library. The design of the queries will feature in Volume Two during the detailed 
design. 
3.9.3 Genre Types 
It is important to find documents which form a sub-set of the current documents which the 
INEX contains. Time constraints render attempts to distinguish all Genres in the corpus an 
impossible task as there are hundreds of types of articles and these have also sometimes 
changed over time. It is important to choose a subset. For the purposes of this project, only ten 
features will be chosen. These articles are not completely distinct from each other because 
they overlap, for example, many of them contain image or reference links. However, it is 
hoped that analysis of the form features will enable the genres to be categorised. The article 
document types to be classified have to have many instances in the index, at least five 
throughout the collection, so the initial estimated sub-set is made larger. Five-hundred and 
seventy one articles and seven volumes will be in the test set9 for the experiment because of 
the time parameter with many other types acting as noise documents. 
The nine article types proposed, which will be identified by genre, all appear consistently  
throughout the subset collection in path \INEX 2004\inex-1.4\xml\cs: 
1. From The Editor-in-Chief 
2. Conferences & Workshops 
3. Feature-Article   
4. Interfaces Theme Article  
5. Technology News & Reviews   
6. Computer Simulations  
7. Computing Prescriptions   \INEX 2004\inex-1.4\xml\cs\1999\c6092.xml 
It is worth noting, however, that these article names sometimes alter, even if only in a minor 
way, throughout the collection. For example in 1999, Feature-Article becomes Feature-
Articles presumably because the publishers decided to have more than one feature article for 
later publications. 
3.9.4 Classification 
Once the features are extracted using Lucene, the task of classifying the documents into a 
specific genre begins. The questions which now need to be dealt with are: is it possible to 
                                                     
9 Indexed separately from the main collection 
Malcolm Clark Page 55 
classify the documents by genre using WEKA’s classification algorithms and what is the best 
classifier for the task? 
Machine learning/Data Mining is a somewhat overlapping and related field of IR which can 
be used for the purpose of identifying document genre. A multitude of algorithms is available 
but as time is short only three will be used for the implementation; it is however necessary to 
briefly outline some of the types of algorithms: 
Decision trees, aka Regression and Classification trees (Wikipedia 2005), are predictive 
models used in this context for taking calculations of features for each document genre and 
transforming them into if-then categorization rules. One advantage of Decision Trees is that 
the output representation is normally easy for a reader to understand. 
For example:  
If document contains many URL’s  
then classify as Feature-Article 
kNN (k-nearest neighbour) is a clustering methodology that groups documents within a 
vector-space. The Euclidean distance is sometimes used to measure the distance between two 
items. In its simplest definition, as the name suggests, the nearest document to the class is 
then classified as being a genre match. 
TF*IDF,  Lucene scoring formula, parses a documents contents and counts the number of 
times the terms appear within each one. 
Lastly, the probability algorithm Naïve Bayes, in this context, calculates the probability of a 
document being a genre class.  
Many authors have utilised classification techniques after extracting the required conceptual 
features from their document selection. For example, Lee et al(2002) used Naïve Bayes and 
Finn et al(2003) used decision trees which is the Divide and Conquer strategy (Witten et al 
1999). Boese (2005) used LogitBoost for webpage genre classification which is contained 
within WEKA’s metadata algorithms.  
Most authors seem to use only one algorithm but for this project three, kNN, Naïve Bayes and 
C4.5 (Decision Trees) will be employed and the results compared. 
3.9.5 Data Mining Tool 
Witten et al (1999) developed an open source tool which uses Java™ implementation of the 
vast array of algorithms for Data Mining named WEKA(Waikato Environment  for 
Knowledge Analysis).The tool allows a user to format data into a few different formats, for 
example, ARFF(WEKA filetype) and CSV (Comma Separated Values) and also load data 
from a URL. The tool allows the user to explore the data and run classification experiments. 
Malcolm Clark Page 56 
 
Figure 21 WEKA splash screen/main menu and example classifier choices 
 
The only two menu items of concern in this report are the Experimenter and Explorer. It is 
worth noting that WEKA does enable a user to XML for simple tasks such as command line 
and serialization but they are beyond the scope of this report. 
 
Figure 22 WEKA explorer 
3.9.6 Experiments 
The object of the experiments is to extract the features (figure 18) and apply the algorithms.  
First it is necessary to transform the features data into ARFF format which is the main filetype 
for WEKA. 
 
Malcolm Clark Page 57 
 For example: 
@relation weather 
@attribute outlook {sunny, overcast, rainy} 
@attribute temperature real 
@data 
sunny,85,85 
sunny,80,90 
overcast,83,86 
rainy,70,96 
rainy,68,80 
Figure 23 Trimmed down version of ARFF file format (Witten et al 1999). 
 
The file of feature data is loaded into WEKA and the algorithms are chosen. 
For example, IBk is the nearest neighbour classifier (clustering), which comes under the title 
of Instance Based Learner. Weka has to be setup to enable it to choose the best setting for k, 
i.e. (between 1 & 10). Bayes Net (Bayesian Belief Network) according to Wikipedia (2005) 
contend that the algorithm is a “directed acyclic graph of nodes representing variables and 
arcs representing dependence relations among the variables. If there is an arc from node A to 
another node B, then we say that A is a parent of B.”  
The first item on the menu is the Explorer in WEKA which is mainly used to “apply a 
learning algorithm to a data set and analyse its output and apply several learning algorithms to 
a data set and compare their performance in order to choose one of them as a 
classifier.”(Witten et al 1999). The explorer is utilised to: 
1. Pre-process: to select and modify datasets. 
2. Classify: to train and test learning algorithms for classification (or for regression). 
3. Cluster: to learn clusters from the dataset. 
4. Associate: to learn association rules from the dataset. 
5. Select attributes: to choose appropriate attributes which describe the dataset. 
6. Visualise: to plot the data i.e. interactive or 2D.(Witten et al 1999) 
Importantly, WEKA allows the user to filter the information so allowing the Discretisation 
and Normalisation 10of data. This, of course, is an essential part of the project as it allows a 
                                                     
10 The filter Discretize discretises a range of numeric values into nominal values which is important for this 
project. The filter Normalize normalises all numeric values in a dataset. 
 
Malcolm Clark Page 58 
clear view of classifying results for the document genres. The figure below displays examples 
of an attributes list and a breakdown of each. 
 
Figure 24 Explorer view (Clark 2004) and Witten et al (1999) 
The second item, the Experimenter, as an alternative to the Explorer, allows the user to cross-
validate the many algorithms against many datasets and compare the performance. The 
following figures are sample outputs. 
Once the algorithms are applied over a chosen number of runs (or folds) and with alternate 
baselines, evaluation of the results is necessary. WEKA provides output of high quality: 
 
Figure 25 example output shows four algorithms tested on three datasets. (Clark 2004) 
and Witten et al (1999) 
 
Datasets        algorithms (1-4)  
 
 
 
 
 
 
 
 
Malcolm Clark Page 59 
 
 
 
Figure 26 Rankings example (Clark 2004) and Witten et al(1999)  
 
The figure 26 shows J48 as the best performing algorithm versus ZeroR (one level decision 
tree) which performs the worst. 
The figures shown are only small examples of WEKA’s classification power and will be 
demonstrated fully during the implementation phase. 
3.9.7 Evaluation 
The evaluation will be performed on three areas; evaluation of the performance of the 
indexing, extraction of features and the classification experiments. A full report on the 
proposed features that have been successfully extracted, indexing and the application of the 
Bayes Net, IBk algorithms and C4.5 will be written in Volume Two. 
The testing of the indexing will be part of the documentation for the Implementation phase.    
3.9.8 Conclusion 
The simple objective of the methodology is to create, search an index and assist in classifying 
documents by genre from the INEX 1.4 XML collection, evaluate software and extracted 
information. It is believed that the implementation of the Lucene indexer/search library and 
experimental setup using WEKA will show that XML documents can be distinguished by 
genre solely by using ten form features. 
 
 
 
Difference between wins and losses 
Total wins Total losses 
Malcolm Clark Page 60 
 
REFERENCES 
 
Boese, E.S. 2005, Stereotyping the Web: Genre Classification of Web Documents (M.S. 
Thesis), Computer Science Department, Colorado State University.  
Boese, E.S. & Howe, A. Effects of Web Document Evolution on Genre Classification, .  
Bosak, J. 2005, 09/02/2005-last update, The Birth of XML [Homepage of Sun Microsystems], 
[Online]. Available: http://java.sun.com/xml/birth_of_xml.html [2005, 06/2005] .  
Campbell, D.G. 1999, "Genre as Interface Metaphor: Exploiting Form and Function in Digital 
Environments", HICSS '99: Proceedings of the Thirty-Second Annual Hawaii 
International Conference on System Sciences-Volume 2IEEE Computer Society, , pp. 
2008.  
Clark, M. 2004, CMM510 Data Mining Coursework, Coursework report edn, Robert Gordon 
University, Aberdeen.  
Collins, T.D., Mulholland, P. & Watt, S.N.K. 2000, Using genre to support active 
participation in learning communities, Knowledge Media Institute, The Open University.  
Collins-Sussman, B.F.,Brian W. & Pilato, C.M. 2004, Version control with Subversion, 1st 
edn, O'Reilly Media, United States.  
Croft, W.B. 1995, 01/11/1995-last update, What Do People Want from Information Retrieval? 
(The Top 10 Research Issues for Companies that Use and Sell IR Systems) [Homepage of 
D-Lib Magazine], [Online]. Available: 
http://www.dlib.org/dlib/november95/11croft.html [2005, 06/2005] .  
Eclipse Foundation Webmaster 2002, 19/11/2002-last update, eclipse project FAQ; 
[Homepage of Eclipse Foundation Webmaster], [Online]. Available: 
http://www.eclipse.org/eclipse/faq/eclipse-faq.html [2005, 10/10] .  
Finn, A., Kushmerick, N. & Smyth, B. 2002, "Genre classification and domain transfer for 
information filtering", Advances in Information Retrieval. 24th BCS-IRSG European 
Colloquium on IR Research. Proceedings, 25-27 March 2002Springer-Verlag, Glasgow, 
UK, pp. 353.  
Finn, A. & Kushmeric, N. 2003, 2003-last update, Learning to classify documents according 
to genre [Homepage of University College Dublin], [Online]. Available: 
www.cs.ucd.ie/staff/nick/home/ research/download/finn-ijcai03-style.pdf [2005, 06/03] .  
Fuhr, N. 2001, "Models in information retrieval", , pp. 21-50.  
Gospodnetic , O. 2003, 03/06/2003-last update, Parsing, indexing, and searching XML with 
Digester and Lucene [Homepage of IBM], [Online]. Available: http://www-
106.ibm.com/developerworks/java/library/j-lucene/ [2005, 06/04] .  
Malcolm Clark Page 61 
Gray, N. 2003, Web Server Programming, Paperback edn, Wiley, Chichester,West 
sussex,England.  
Harold, E.R. & Scott Means, W. 2002, XML in a Nutshell, 2nd edn, O'Reilly, 
Sebastapol,California.  
Hatano, K., Kinutani, H., Watanabe, M., Yoshikawa, M. & Uemura, S. 2002, "Determining 
the Unit of Retrieval Results for XML Documents.", INEX Workshop, pp. 57.  
Hatcher, E. & Gospodnetić, O. 2004, Lucene in Action, 1st edn, Manning Publications Co., 
Greenwich,U.S.  
Jovan Pehcevski, J.A.T. & Anne-Marie Vercoustre 2003, "XML-Search Query Language: 
Needs and Requirements", Proceedings of AUSWeb 2003, The Ninth Australian World 
Wide Web Conference, pp. 487.  
Kamps, J., Marx, M., Rijke}, M.{. & Sigurbj\"ornsson, B. 2003, "XML retrieval: What to 
retrieve?", Proceedings of the 26th Annual International ACM SIGIR Conference on 
Research and Development in Information Retrieval (SIGIR 2003), pp. 409.  
Kennedy, A. & Shepherd, M. 2005, "Automatic Identification of Home Pages on the Web", 
HICSS '05: Proceedings of the Proceedings of the 38th Annual Hawaii International 
Conference on System Sciences (HICSS'05) - Track 4IEEE Computer Society, , pp. 99.3.  
Kessler, B., Nunberg, G. & Schfitze, H. 1997, "Automatic Detection of Text Genre", 
Proceedings of the 35th annual meeting on Association for Computational Linguistics , 
ed. ACL Anthology, Association for Computational Linguistics, Morristown, NJ, USA, 
pp. 32.  
Lalmas Mounia 2005, 10/10/05-last update, ACM SIG Fact Sheet ACM/SIGIR [Homepage of 
SIGIR], [Online]. Available: http://www.acm.org/sigir/sigir_fact_sheet.html [2005, 
10/09/05] .  
Lalmas, M., Rolleke, T., Szl, Z.a. & Tombros, T. 2004, 2/11/2004-last update, Accessing 
XML documents: the INEX initiative [Homepage of Queen Mary University of London], 
[Online]. Available: http://www.dcs.qmul.ac.uk/~mounia/CV/Papers/inextracks.pdf 
[2005, May/2005] .  
Lee, Y. & Myaeng, S.H. 2004, "Automatic identification of text genres and their roles in 
subject-based categorization", Proceedings of the Hawaii International Conference on 
System Sciences, Jan 5-8 2004Institute of Electrical and Electronics Engineers Computer 
Society, Piscataway, NJ 08855-1331, United States, Big Island, HI., United States, pp. 
1603.  
Lee, Y. & Myaeng, S.H. 2002, "Text genre classification with genre-revealing and subject-
revealing features", Proceedings of the Twenty-Fifth Annual International ACM SIGIR 
Conference on Research and Development in Information Retrieval, Aug 11-15 
2002Association for Computing Machinery, Tampere, Finland, pp. 145.  
Malcolm Clark Page 62 
Liu, S., Zou, Q. & Chu, W.W. 2004, "Configurable indexing and ranking for XML 
information retrieval", SIGIR '04: Proceedings of the 27th annual international ACM 
SIGIR conference on Research and development in information retrievalACM Press, , 
pp. 88.  
Massol, V. & O'Brien, T.M. 2005, Maven a Developer's Notebook , 1st edn, O'Reilly, United 
States.  
Mauldin, M.L. 1991, "Retrieval performance in Ferret a conceptual information retrieval 
system", SIGIR '91: Proceedings of the 14th annual international ACM SIGIR 
conference on Research and development in information retrievalACM Press, , pp. 347.  
Newcome, Z. 2002, "Number one, touch your tongue" in Five Little Monkeys Over 50 Action 
And Counting Rhymes, ed. Walker Books Ltd, 1st edn, Walker Books Ltd, 
London,United Kingdom, pp. 8-9.  
Orlikowski, W.J. & Yates, J. 1994, "GENRE REPERTOIRE: 
Norms and Forms for Work and Interaction", 3671-94, vol. 39, no. 1, pp. 541-574.  
Rauber, A., M\&\#252, ller-K\&\#246 & gler, A. 2001, "Integrating automatic genre analysis 
into digital libraries", JCDL '01: Proceedings of the 1st ACM/IEEE-CS joint conference 
on Digital librariesACM Press, , pp. 1.  
Rauber, A., Pampalk, E. & Merkl, D. 2002, "Content-based music indexing and 
organization", SIGIR '02: Proceedings of the 25th annual international ACM SIGIR 
conference on Research and development in information retrievalACM Press, , pp. 409.  
Rosso, M.A. 2005, "What type of page is this?: genre as web descriptor", JCDL '05: 
Proceedings of the 5th ACM/IEEE-CS joint conference on Digital librariesACM Press, , 
pp. 398.  
Salminen, A. & Tompa, F.W. 2001, "Requirements for XML document database systems", 
DocEng '01: Proceedings of the 2001 ACM Symposium on Document engineeringACM 
Press, , pp. 85.  
Seki, Y. 2005, "Automatic summarization focusing on document genre and text structure", 
SIGIR Forum, vol. 39, no. 1, pp. 65-67.  
Spinuzzi, C. 2004, "Four ways to investigate assemblages of texts: Genre sets, systems, 
repertoires, and ecologies", Proceedings of the 22nd Annual International Conference on 
Design of Communication - the Engineering of Quality Documentation, Oct 10-13 
2004Association for Computing Machinery, New York, NY 10036-5701, United States, 
Memphis, TN, United States, pp. 110.  
Stamatatos, E., Fakotakis, N. & Kokkinakis, G. 2000, "Text genre detection using common 
word frequencies", Proceedings of the 17th conference on Computational 
linguisticsAssociation for Computational Linguistics, , pp. 808.  
Stamatatos, E., Kokkinakis, G. & Fakotakis, N. 2000, "Automatic text categorization in terms 
of genre and author", Comput.Linguist., vol. 26, no. 4, pp. 471-495.  
Malcolm Clark Page 63 
The Apache Maven Team 2005, 05/10/05-last update, Apache Maven Project [Homepage of 
Apache Maven Project], [Online]. Available: http://maven.apache.org/ [2005, 30/09] .  
The Apache Software Foundation 2005, 14/05/05-last update, The Apache Software 
Foundation - Lucene [Homepage of The Apache Software Foundation], [Online]. 
Available: http://lucene.apache.org/java/docs/features.html [2005, 09/10] .  
The Apache Software Foundation 2005, 10/07/05-last update, Digester API [Homepage of 
The Apache Software Foundation], [Online]. Available: 
http://jakarta.apache.org/commons/digester/ [2005, 08/10] .  
The Eclipse Foundation 2004, Eclipse IDE, 3.1st edn, ECLIPSECON, Anaheim,California.  
TREC 2004, 30/01/04-last update, Overview TREC [Homepage of NIST], [Online]. 
Available: http://trec.nist.gov/overview.html [2005, 30/08/05] .  
Watt, S. 2005, Structured text retrieval - international benchmarking group.  
Watt, S. 2004, Text Categorization Without Words: Can it Possibly Work?.  
Wikipedia 2005, , Information retrieval. Available: 
http://en.wikipedia.org/wiki/Information_retrieval [10/09/05, 10/09/05] .  
Wilkinson, R. 1994, "Effective retrieval of structured documents", Proceedings of 17th 
International Conference on Research and Development in Information Retrieval. SIGIR 
94, 3-6 July 1994Springer-Verlag, Dublin, Ireland, pp. 311.  
Witten, I.,H & Frank, E. 1999, Data Mining: Practical Machine Learning Tools and 
Techniques with Java Implementations (The Morgan Kaufmann Series in Data 
Management Systems) (Paperback), 1st edn, Morgan Kaufmann, New Zealand.  
Yates, J. & Orlikowski, W.J. 1992, "Genres of Organizational Communication: A 
Structurational Approach to studying communication and media", The Academy of 
Management Review, vol. 17, no. 2, pp. 299-326.  
 
 
  
Malcolm Clark Page 64 
 
APPENDICES ONE – INITIAL SPECIFICATION 
 
Title Classifying XML Documents using Genre 
Project Code N/A 
Proposed By Dr Stuart Watt 
 
Techniques 
Classification using Genre; XML Information Retrieval; evaluation and statistics. 
 
Requirements 
Java™ 
 
Background 
The EXtensible Mark-Up Language (XML) is rapidly becoming the leading method of storing many types of 
digital media such as text and imagery. It is also a common way of displaying data through the World Wide 
Web. 
There is a need for research methods which can extract and classify information from XML sources.  In contrast 
with the usual document collections or ‘bags of words’, the retrieval depends solely on structural items, such as 
abstracts, footnotes and titles. 
The annual workshop INEX, in which RGU participates, uses retrieval on a collection of thoroughly ordered 
XML documents. These documents consists of past British Computer Society publications which have been 
completely re-arranged in XML format. INEX uses many types of processes to test XML documents, such as 
Relevance Feedback, Natural Query language and ADHOC. This project will focus on ADHOC processing. 
There are several ways of analysing and extracting document information such as Shallow Parsing, Latent 
Semantic Analysis and ‘Genre’. 
This project will use the unit of analysis ‘Genre’, which (Watt 2005) states that the “layout and structure of 
documents reflects their purpose”. 
 
Objectives  
 
• To investigate current methods of classifying documents using Genre. 
• To examine current categorisation systems and tools primarily using Java™. 
• To create software to index and extract information from the XML collection (1.4) using Genre. 
• To evaluate software and extracted information from the XML collection using Genre. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Malcolm Clark Page 65 
APPENDICES TWO - PROJECT PLAN 
 
STAGE 1-INVESTIGATION AND PROJECT PLAN 
 
Initial Plan/Preparation/Interview 
Investigate Literary Resources/ Conduct Literary Review 
This sub-task involved conducting searches on the World Wide Web, ACM Digital library, Robert Gordon 
Universities and other Catalogues available under the RGU catalogue. Once the literary sources are identified a 
review of the literature was written for the first volume. 
Requirements Specification 
Ask Dr Watt for his main requirements and note them. 
Confirm Requirements 
Confirm main requirements with Dr Watt. 
Outline Design 
Outline design of application model and methodology all for Volume 1 chapter 3. 
Investigation/Research Tools 
Investigation of software development tools and main API’s. 
Deliver Spec+ Ethics form 
Submit the specification and the Ethics form for the project which enables the Robert Gordon University panel 
(School Ethics Review Panel) to conduct Ethical reviews of projects. 
Final Project Plan 
Decide the project plan final version. 
Volume One Report – activities 
Write-up Volume One  
Volume one is written from the beginning of the project. It consists of the compilation of all 
information for Chapter one – Introduction, Chapter two – Literary Review and Chapter three – tools, 
requirements, methodology and design outline. 
Volume One Submission (Advisory Only) 
Volume One Submission (Final  Deadline) 
 
STAGE 2-IMPLEMENTATION AND EVALUATION 
 
Software Solution 
Create initial prototype/outline code 
Designed GUI, class diagrams, detailed functionality and possibly UML diagrams. Implement 
prototype of application. 
Create indexer using Java  
Implement Digester and Lucene. Index INEX 1.4 using identified software tools and techniques. 
Test Index 
Test results using INEX topics and measure using command line queries and  P/R to check that  the 
basic model actually performs as it is supposed to. 
Create search code and implement 
Implement search query code for the feature extraction 
Extraction and Evaluation 
At this stage, the extractions will take place. 
Evaluate extraction results 
Identify the documents structural features and perform classification experiments using WEKA tool 
Compile/Write-up results 
 Write up a report detailing the results 
Volume Two Report 
Volume Two Writeup 
Write up all proceedings of phase 2 with results of experiments. 
Hand-in Volume 2 
 
Handin CD + Project Slides + Project Demonstration 
Poster Creation 
Design and Create 
Hand In 
Project Demonstration 
Project Demo to Supervisor 
Malcolm Clark Page 66 
RESOURCES 
 
RGU  Libraries/Catalogues  
ACM Digital library, Science Direct and Library. 
Adobe Document Server Developer Center 
Only used to create user/testing documents. 
Lucene 1.4.3 
API for the Indexing/Searching 
INEX Document Collection 1.4 
Index whole INEX corpus but tests only performed on a small subset 
Microsoft Office 2003 
Word, Project, Outlook Express etc 
Digester 1.7 
Digester used for formatting of XML to Java TM objects 
Compact Disc 
Disk for submitting at project conclusion. 
WEKA 3.4 Library/Tool 
Data mining tool for classification etc 
Luke 
Open source Lucene index searcher tool 
 
GANT DIAGRAM 
Stage one 
 
 
 
 
 
 
 
 
 
 
 
Malcolm Clark Page 67 
 
Stage two 
 
 
 
 
