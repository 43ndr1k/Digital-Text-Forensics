Applying Biometric Principles to Avatar Recognition 
 
Marina L. Gavrilova 
Department of Computer Science 
University of Calgary, CANADA 
marina@cpsc.ucalgary.ca 
 
Roman V. Yampolskiy 
Computer Engineering and Computer Science 
University of Louisville, USA 
roman.yampolskiy@louisville.edu 
Abstract—Domestic and industrial robots, intelligent 
software agents, virtual world avatars and other artificial 
entities are quickly becoming a part of our everyday life. Just 
like it is necessary to accurately authenticate identity of human 
beings, it is becoming essential to be able to determine identities 
of non-biological agents. In this paper, we present the current 
state of the art in virtual reality security, focusing specifically 
on emerging methodologies for avatar authentication. We also 
outline future directions and potential applications for this high 
impact research field.  
 
Keywords-biometric; avatar; recognition; robot; artimetrics 
I. INTRODUCTION  
Domestic and industrial robots, intelligent software 
agents, virtual world avatars and other artificial entities are 
quickly becoming a part of our everyday life. Just like it is 
necessary to be able to accurately authenticate identity of 
human beings, it is becoming essential to be able to 
determine identity of the non-biological entities rapidly 
infiltrating all aspects of modern society. Military soldier-
robots [27], robots museum guides [6], software office 
assistants [7], human-like biped robots [35], office robots 
[2], bots [44], robots with human-like faces [31], virtual 
world avatars [57] and thousands of other man-made entities 
all have something in common: a pressing need for a 
decentralized, affordable, automatic, fast, secure, reliable, 
and accurate means of identity authentication. To address 
these concerns, we proposed [62, 65, 64] the concept of 
Artimetrics – a field of study that will allow identifying, 
classifying and authenticating robots, software and virtual 
reality agents. In this paper, unless otherwise identified, the 
word robot (or agent) refers to the above mentioned non-
biological entities. 
While the area of robot and agent authentication may 
seem a bit futuristic at first, careful analysis of recent news 
stories shows that the proposed research is years behind 
where it needs to be. 
 
 
Figure 1: Facial images of a humanoid robot-model, robot celebrity and 
a 3D-virtual avatar [41] [22]. 
To give just some examples: Al-Qaeda terrorists have 
been reported recruiting and communicating in virtual 
communities such as Second Life [8]. Cybercrime, including 
identity theft, is rampant in virtual worlds populated by 
millions of avatars and operating multibillion dollar 
economies [40].  Security experts have testified to the US 
Senate that defenses are lacking when it comes to emerging 
threats to the nation's Cyberinfrastructure. International 
teams of hackers assisted by semiautomatic hacking software 
agents have perpetrated numerous attacks against the 
Pentagon and other government agencies’ computers and 
networks [59].  
A novel paradigm, unique to virtual communities, has 
appeared in recent years and was labeled “interreality’’. In 
the Second Life visitors are allowed to populate, build and 
exploit initially empty spaces. As a result “the new reality 
that is thus created is, remarkably enough not entirely 
‘virtual’, but is becoming gradually more linked to our 
physical reality” [40]. Relationships between social, 
economical, and psychological status of game players and 
their respected avatars in the virtual environment are a 
subject of current research. Early results show that avatars 
for the most parts resemble their “owners” rather than being 
completely virtual creations. As the physical and the virtual 
worlds seem to come really close to each other, the 
distinction between the two begins to fade and the need 
arises for security systems capable of working in the contexts 
of interreality and augmented reality [37]. In his dissertation 
‘Architecture of a Cyber Culture’ (2003), Van Kokswijk 
describes this phenomenon as “the hybrid and absolute 
experience of physical and virtual reality”. Interreality is the 
creation of a hybrid total image of and in both the physical 
and virtual worlds. Unfortunately, currently available 
biometric systems are not designed to handle visual and 
behavioral variations observed in non-human agents and 
consequently perform extremely poorly if applied outside of 
their native domain.  
The question of security and identification of avatars in 
this “interreality” consistently arises. Based on research and 
polls performed on Internet forums, people often complain 
about the insufficient security in Second Life, with almost 
40% of the respondents asking for additional security [40]. 
More than half of the respondents admit they have been 
harassed (this includes imprisoning, stalking, gossiping and 
using inappropriate language) and 40% indicate that certain 
actions should not be permitted in Second Life. Thus, the 
definite need in increasing and enforcing security is 
2010 International Conference on Cyberworlds
978-0-7695-4215-7/10 $26.00 © 2010 IEEE
DOI 10.1109/CW.2010.36
179
apparent, which motivates emerging research on security in 
the increasingly complex and interrelated virtual worlds.  
It is interesting to note that some biometric methods came 
very close to avatar development and intelligent 
robots/software authentication on a number of different 
instances. For example, in 1998 M.J. Lyons et.al. published a 
report: ”Avatar Creation using Automatic Face 
Recognition”, where they discuss specific steps and 
techniques that need to be taken in order for avatar to be 
created almost automatically from the human face [36]. In 
fact, the process described is essentially the process of 
biometric synthesis, conceptualized and generalized in the 
book devoted specifically to this subject [69]. Users of 
virtual words have also noted that avatars very often 
resemble the characteristics of its creator, and not only facial 
characteristics, but also body shape, accessories and clothes.  
But what about other less obvious resemblances such as 
manner of communication, various situation response, nature 
of work, style of house, leisure/recreational activities, time of 
appearing in virtual world etc.? All of the above 
encompasses behavioral characteristics that can be exploited 
by the fusion of biometric-based techniques, with 
methodology tailored to specifics of virtual world.  Such 
behavioral characteristics, as authors of this article would 
postulate, are even less likely to change than the avatar’s 
facial appearance and clothes during the virtual world 
sessions, as users typically invest a lot of time and money 
into creation of a consistent virtual image but would not so 
easily change their patterns of behavior.  
The rest of this paper is organized as follows: a literature 
review is presented in Section 2, a comprehensive survey of 
non-biological entities (avatars) is given in Section 3, an 
overview of methodology under development, focusing on 
dataset creation, visual, behavioral and multi-modal 
artimetrics constitutes Section 4, applications and 
implications of this emerging area are outlines in Section 5 
and finally concluding summary is provided in Section 6.  
 
II. LITERATURE REVIEW 
To the best of our knowledge, no paper surveying 
automatic visual or behavioral authentication of software 
agents, virtual reality entities or hardware robots have been 
published to date. While no research has been reported in 
automatic robot authentication or behavior analysis some 
relevant research has been published on robot emotion 
recognition [13]. In addition to experiments on 
understanding of emotional states of robots, some work has 
been started on general analysis of avatar behavior. One of 
the projects under the heading of Intelligence Advanced 
Research Projects Activity is to develop systems to observe 
avatars to study how they behave and communicate with one 
another for insights into how real-life people in hostile 
cultures think and act. The hope is to obtain useful insights 
into the nationalities, genders, approximate ages, 
occupations, educational levels, even the ideologies of 
avatars’ owners in the real world. One of the goals of this 
project is to understand how terror groups might use such 
virtual worlds to communicate [5].  
Another novel research direction is known as Avatar 
DNA™ a patent pending technology from Raytheon. It 
focuses on providing authentication, confidentiality, and 
integrity within a virtual world by entangling real world 
biometrics of the user and his avatar profile. Avatar DNA is 
a multi-attribute entity with each element forming a segment 
of the Avatar DNA. Together the segments define the 
makeup of an avatar. The genes of the avatar are unique and 
include user biometric data, public key information, personal 
information, authentication information, creation data, etc. 
Verification modules in the virtual world collect information 
directly from the avatar to establish the roles and rights that 
should be granted to this user [58].     
In another experiment linking real world and the world of 
avatars William Steptoe asked 11 volunteers personal 
questions. During the interviews the volunteers wore eye-
tracking devices. A second group of volunteers watched 
videos of avatars as they delivered first group’s answers. 
Some avatars had eye movements that mirrored those of the 
original volunteers, while others did not. The volunteers had 
to determine if the avatar was lying to them. Eye-movement 
allowed increasing accurate detection of truthful statements 
from 70% to 88% and detection of lies from 39% to 48% 
clearly demonstrating importance of even subtle body 
language in virtual world communication and avatar 
behavioral analysis [12].  
Multiplayer online computer games are quickly growing 
in popularity, with millions of players logging in every day. 
While most play in accordance with the rules set up by the 
game designers, some choose to utilize artificially intelligent 
assistant programs, a.k.a. bots, to gain an unfair advantage 
over other players. A recently published paper by one of the 
authors of this work demonstrated feasibility of applying 
strategy-based purely behavioral biometrics developed for 
recognition of human beings to the recognition of intelligent 
software agents [65]. The paper lays the theoretical 
groundwork for the research in authentication of non-
biological entities. The possibility that behavior-based 
biometric systems can be spoofed in particular by artificially 
intelligent software agents [63] was also addressed, which 
lead to research on automatically telling bots and humans 
apart [66]. Authors of the paper demonstrate how an 
embedded non-interactive test can be used to prevent 
automatic artificially intelligent players from illegally 
participating in online game-play. Specifically, they 
demonstrated that behavioral biometrics is a great approach 
to intelligent software authentication.  
III. SURVEY OF NON-BIOLOGICAL ENTITIES 
There are three main types of non-biological entities, that 
can be broadly classified as Virtual Beings (avatars),  
Intelligent Software Agents (bots), and Hardware Robots 
[21].  Virtual Being are at the focus of the following survey, 
180
while bots and robots, while equally interesting, are beyond 
the scope of the current paper.  
According to a dictionary, the word “Avatar” means: 
“embodiment: a new personification of a familiar idea”; or 
the manifestation of a Hindu deity (especially Vishnu) in 
human or superhuman or animal form. In an on-line 
community, Avatar is a virtual representation of a player in 
an on-line world, a software creation that exists in virtual 
environment but is controlled by a human player from the 
physical world. A comprehensive summary of avatar types is 
given in an on-line book by John Suler, Department of 
Psychology Professor at Rider University [55].  The book 
itself is not your ordinary collection of printed articles – it 
exists only in the on-line form and evolves with time to 
reflect constant changes in virtual gaming communities. 
According to [55], the following types of avatars exist based 
on preferences and behavior of its human creator: 
Odd/shocking avatars are unusual, strange, or bizarre; 
Abstract avatars may be represented by abstract art; 
Billboard avatars are announcements of some kind; Lifestyle 
avatars depict a significant aspect of a person's life; 
Matching avatars are designed to accompany each other; 
Clan avatars are worn by members of the same social group; 
Animated avatars contain motion; Animal avatars are 
typically associated with person’s pets or self association 
with nature; Cartoon avatars are based on famous drawn 
characters; Celebrity avatars tend to follow trends in popular 
culture; Evil avatars are scary looking; Real Face avatars are 
uploaded pictures of the actual users; Idiosyncratic avatars 
are strongly associated with a specific user; Positional 
avatars are designed by the member to be placed into 
specific locations; Power avatars are symbols of 
omnipotence; Seductive avatars partially naked or scantily 
clothed figures.  
Identification of such avatars can be carried out through 
analysis of their appearance, attributes, behavioral patterns, 
frequency and type of changes, using a combination of 
traditional image pattern recognition techniques and 
biometric behavioral identifiers. Classifying further the types 
of behaviors that avatars might exhibit can assist 
significantly in the task of avatar authentication. According 
to [55], such behavior can be expressed in Mischievous 
Pranks (such as smearing someone else’s room, spoofing 
someone with “msay” command, or popping text balloon 
over someone’s head), Flooding of the server by users who 
make rapid multiple changes of their avatars, Blocking 
(placing one’s avatar on top or too close to another person's 
prop),  Sleeping (by users who have walked away from their 
computer and their avatar fails to react), Eavesdropping (by 
reducing avatar to a single pixel and usernames to only one 
character, someone may become "invisible" and secretly 
listen in on conversations), Prop Dropping (placing an 
inappropriate or obscene prop in an empty room), Identity 
Disruption - people suffering from disturbances in their 
identity may act it out through frequently changing props 
they wear. Imposters - stealing someone's avatar, wearing it 
and also using that person's name (or a variation of it) – one 
of very serious crimes in cyberworld as it is essentially 
“stealing someone else’s entire identity”. Those behaviors 
resemble typical criminal behaviors of humans and so 
require high degree of attention from those in charge of 
security of the virtual communities.  
Author of [55] describes one such act “Sometimes, it's 
hard even for sympathetic people to resist the antics and 
game-playing. One night, although trying to remain a neutral 
observer, I eventually found myself as an accomplice to 
another member in a prank where we set up an unmanned 
female prop in the spa pool. We used "msay" to talk 
THROUGH the prop while also talking to it as if it were 
another user. Essentially, it was a virtual ventriloquist act. 
Honey " (the prop) was rather seductive towards the guests, 
and the guests all thought it was a "real" person. It was quite 
funny, although perhaps a bit mean to the poor naive guests 
who were unaware of the msay command.” The paragraph 
above is highly interesting as it describes the process of 
another virtual entity creation, or a “fake avatar”,  separate 
from legitimate avatars,  that does not corresponds to a real 
person, but “appears” to be just like them and can sometimes 
fool even experienced users. Utilizing methods from 
biometric research as well as developing new approaches 
targeting specifically avatar authentication and behavior 
recognition can assist in identifying those “fake avatars” as 
well as classifying real ones. 
 
IV. AVATAR  AUTHENTICATION  
In this section, we first take a look at techniques for 
collecting and classifying databases of avatars and bots, 
moving on to propose a new way to synthesis the new 
images through application of biometric synthesis methods 
based on geometric processing and multiresolution 
techniques. We then study the two main types of 
authentication in virtual world: visual and behavioral, and 
introduce the multi-resolution system for enhanced 
performance.  
A.  Datasets Generation  
In the well-established fields such as biometrics, 
numerous standardized and publicly available datasets exist 
[49] making it possible to compare experimental results 
achieved by different algorithms and to test developed 
systems. Labeled public datasets of avatar faces, robot faces, 
or attributed conversations from artificially intelligent agents 
are currently unavailable. Techniques for creation of 
standardized and consistent with real world datasets can be 
learned from examining approaches to generation and 
evaluation of facial datasets [29, 15] utilized by biometric 
security systems or from chat mining research applied to 
gender attribution [9] and human versus bot classification 
[18].    
 
181
Figure 2: Left: Sample images for a robot-face dataset, currently limited to manual collection; 
Right: Automatically generated random avatar-faces [43]. 
 
The authors of this paper have begun work on generation 
of a publicly available avatar face dataset [43], and collection 
of speech corpora from intelligent agents. One is a set of 
high resolution facial images of avatars collected from the 
most popular virtual worlds: SecondLife.com and 
EntropiaUniverse.com, the other one is a text corpus from 
intelligent agents who have performed extremely well in the 
recent Lobner.net prize in Artificial Intelligence 
competitions. We have developed automated tools utilizing 
the power of AutoItScript.com and Linden Scripting 
Language (LindenLab.com) for creation of customized 
datasets of both kinds. With the assistants of the developed 
tools any researcher in the field can effortlessly generate 
virtually unlimited amount of data for visual and stylometric 
robot authentication experiments.  
Currently, it is only possible to specify the desired amount 
of data and the gender of the avatars’ faces and overall area 
of knowledge about which intelligent agents communicate. It 
is however already possible to generate multiple samples for 
each non-biological entity making it easy to perform training 
and testing on disjoint datasets. Additional work is still 
necessary to make it possible to generate data with specific 
characteristics, in which we propose to utilize some of the 
recently developed biometric synthesis processes as outlined 
below. 
A link between two areas - avatar generation and 
synthetic biometric generation, is very weak at the moment. 
One of the first examples can be accredited to 1998 report 
”Avatar Creation using Automatic Face Recognition”, where 
authors discuss specific steps and processing techniques that 
need to be taken in order for avatar to be created almost 
automatically from a human face [36]. However, authors of 
this article postulate that the process of avatar creation and 
authentication can be further augmented by applying 
techniques from both biometric synthesis and biometric 
authentication.  
Synthetic biometric is defined as “reverse problem of 
biometric” [70] and is intended to create artificial 
phenomenon that does not exist in physical reality, but 
resembles it. In that respect, synthetic creations (fingerprints, 
irises, faces, ears, hands, and even behavioral patterns and 
virtual bodies) are similar to avatars. However, there are 
some substantial differences that make synthetic biometric 
be recognized in their own category. Synthetic biometric, at 
least up to day, is completely non-personalized, i.e. it does 
not corresponds to a single human or function, but possesses 
characteristics of multiple biometrics that were used in the 
process of new biometric entity synthesis. However, exactly 
this property might prove most beneficial for new virtual 
dataset creation.  
In general, data synthesis refers to the creation of new 
data to meet some intended purposes, and includes areas 
such as texture synthesis, domain specific rendering and 
biometric synthesis. Due to logistical and privacy issues with 
collecting and organizing large amounts of biometric data, a 
new direction of biometric research concentrates on the 
synthesis of biometric information. One of the primary goals 
of the synthesis of biometric data is to provide databases for 
testing newly developed biometric algorithms [17]. For 
instance, author of this paper proposed an approach for facial 
synthesis and expression modeling based on the underlying 
mesh modification for both 2D and 3D face models. 
Selection of control points in this method is guided by the 
three-dimensional Voronoi diagram which represents the 
[72]. A general overview of related work on utilizing 
geometric algorithms in facial expression modeling can be 
found in [16].  
B. Visual Recognition  
From a problem of database generation, we now move to 
visual recognition of avatars problem. Face Recognition is 
the task naturally performed by humans, and it remains in the 
182
center of biometric research over the last few decades. 
Hundreds of  papers have been published on the topic, with 
comprehensive surveys of facial biometric research found in  
[68, 73, 56] as well as in a recent book presenting state-of-
the-art in the area [23]. Dozens of different approaches 
ranging in accuracy of face recognition from low 60% to 
99% have been proposed [68]. Knowledge based methods, 
such as the multi-resolution  based approach [67], capture 
the relationship between facial features. Feature invariant 
approaches look for structures consistency under a variety of 
poses and lighting conditions, examples include grouping of 
edges [71], space gray-level dependence matrix [11], and 
mixture of Gausians [38]. Template matching extracts 
standard patterns of the face which are later compared to 
regions being tested to determine the degree of correlation, 
classical examples include shape template [10] and Active 
Shape Model [34]. Finally, appearance-based methods such 
as Eigenvector decomposition [60], Support Vector 
Machines (SVM) [42], Hidden Markov Model [45], Naïve 
Bayes Classifier [50] and Neural Networks [48] learn facial 
templates from a set of training image. 
It is interesting to note that the performance of such 
adapted technique on avatar face recognition would be 
superior to method performance among humans. Consider an 
actual scene in the natural world. The effects of air quality, 
lightning, reflections, person’s posture, clothing, and 
possible movement, as well as the type of the physical 
medium used to capture the image (film, camera, cell phone) 
and the distance/positioning of this capturing device from the 
person make the problem of face recognition extremely 
difficult and not resolved up to date. However, in the virtual 
world, while some variability still exists, the nature of the 
avatar being a computer generated entity makes it much 
easier to extract the “ground truth” - the way avatar face was 
initially created, and thus to develop a standardized approach 
to avatar face recognition. An example of application of 
feature-based (geometry-based) method to avatar recognition 
is given in Figure below.  
 
 
Figure 3: Feature-based facial recognition applied to an avatar’s face. 
 
Another important fact to consider is that, as mentioned in 
the introduction, some research confirms a strong 
resemblance of avatar to its human creator, which makes it 
possible to use the results of successful avatar recognition for 
human recognition, and vice versa. This will, in turn, open a 
new area of virtual biometric, or augmenting the actual 
biometric with results of recognition in virtual world.  
C. Behavioral Authentication  
As mentioned above, facial recognition, alone with 
expression analysis and face synthesis, are highly prominent 
and actively researched areas of biometric [17, 23]. Facial 
expression analysis has been an active research topic for 
behavioural scientists since the work of Darwin in 1872. 
Emotion recognition was studied in paralinguistic 
communication, clinical psychology, psychiatry, neurology, 
pain assessment, lie detection, intelligent environments, and 
multimodal human-computer interface (HCI). From 
comprehensive book chapters devoted to state of the art 
research on facial expression and modeling, to tutorials in 
Biometric conferences and Biometric conference themes 
devoted exclusively to face animation, morphing, expression 
analysis and 3D models  - the area is receiving a spur of 
attention from biometric communities, consortiums and 
industries worldwide. One of the emerging recent trends is 
capturing subtle details such as wrinkles, creases and minor 
imperfections that are highly important for biometric 
modeling as well as matching.    
A  novel approach to the problem recently introduced to 
the scientific community takes into an account subtle 
expression changes and performs morphing expression 
images in 2D and 3D based on the powerful computational 
geometry methods [72]. This work makes a number of 
important contributions to the field of expression modeling 
and morphing: it is one of the first applications of the sketch-
based approach to facial image generation and the first one 
that preserves and utilizes subtle expression lines. It provides 
a simple fully automated algorithm based on the distance 
transform that computed the mapping between pixels in a 
monochrome image through a clever process of sweeping the 
image and reusing the information obtained on the previous 
step. It also provides a combination of Sibson coordinates 
and Delaunay triangulation mesh to generate and morph 3D 
facial models. Because all the generated facial models have 
the same underlying structure, animation created by 
developed tools can be easily retargeted to various models. 
Thus, it allows generating facial models with different 
expressions suitable for further utilization in biometric 
testing and behavioral research.  
Forensics and more specifically authorship recognition, 
sometimes called stylometry, is another area related to 
behavior-based authentication of identity. In particular, a lot 
of research has been done in vocabulary analysis and 
profiling of plain text [25, 32, 33], emails [54, 61] and source 
code [51, 19, 14]. Written text or spoken word, once 
transcribed, can be analyzed in terms of vocabulary and style 
183
to determine its authorship. In order to do so a linguistic 
profile needs to be established. Many linguistic features can 
be profiled such as: lexical patterns, syntax, semantics, 
pragmatics, information content or item distribution through 
a text [20]. Commonly utilized text descriptors include: word 
count, punctuation mark count, noun phrase count, word 
included in noun phrase count, prepositional phrase count, 
word included in prepositional phrase count and keyword 
count [52]. Once linguistic features have been established 
Support Vector Machines [24], Bayesian classifiers [28], 
multiple regression and discriminant analysis [53] algorithms 
(among others) have been applied to determine the 
authorship of the text.  Applying the techniques above to 
pattern recognition and behavior authentication of avatars 
based on the way they present themselves, perform their 
tasks, and communicate in the virtual world is another 
emerging area of research.  
D. Multi-modal system for avatar recognition 
Biometric system based solely on a single biometric may 
not always identify the entity (human or avatar) in the most 
optimal or precise way. Thus, multibiometric system 
research is   emerging as a trend which helps to overcome 
limitations of a single biometric solution [47]. This is 
especially useful in the presence of complex patterns, 
conflicting or misleading behavior, abnormal data samples, 
intended or accidental mischief etc. A reliable and successful 
multibiometric system normally utilizes an effective fusion 
scheme to combine the information presented by multiple 
matchers. Over the last decade, researchers tried different 
biometric traits with sensor, feature, decision, and match 
score level fusion approaches to enhance the security of a 
biometric system [47], thus enhancing security and 
performance of authentication system. 
Multimodal biometric approaches improve overall system 
accuracy and address issues of non-universality, spoofing, 
noise, and fault tolerance. Multimodal biometrics or 
Multibiometrics can referrer to a number of different 
approaches such as [46]: 
• Multi-Sensor – employ multiple sensors to capture a 
single biometric trait. 
• Multi-Algorithm – utilize a number of feature 
extraction or matching algorithms on the same data. 
• Multi-Instance – utilize data from multiple instances 
of the same trait such as multiple fingerprints Multi-
Sample – collect multiple instances of the same trait 
via a single sensor. 
• Multi-Modal – utilize multiple biometric traits (ex. 
face and fingerprint and voice).  
In a similar manner, together behavioral and physical 
artimetrics in the virtual worlds can be utilized as a part of a 
Physoemotional Artimetric system which is a multimodal 
system. In addition, another concept of Multi-Dimensional 
system, crossing over between virtual and real world, is 
introduced. The concept is illustrated on example of visual 
authentication of avatar through its creator authentication, 
and vice versa. 
 
V. APPLICATIONS 
There are numerous applications for the methodology, 
some of which are listed below.  
A. Preventing malicious intelligent software from 
obtaining access to information or system resources and 
granting it to authorized agents and by doing so, 
improving security of virtual communities, social 
networks, and country’s cyber-infrastructure especially 
vulnerable in the post 9/11 world. With exponential growth 
in abilities of artificially intelligent agents (bots, software 
weapons, viruses, etc.) comes the pressing need to secure 
information and resources from access by the unauthorized 
agents, while at the same time allowing seamless access for 
the “goodware”. Behavior based profiling of software agents 
provides an unobtrusive way of separating helpful bots from 
malware. Additional research in artimetrics is likely to 
produce novel behavior-profiling approaches specifically 
designed to take advantage of the unique “psychology” of 
artificially intelligent programs. Current explosive research 
on CAPTCHAs [66, 1, 3, 4, 39] demonstrates one promising 
direction of future research.  
B. Finding out which agent has performed a given task 
in case a number of possible alternatives exist, either for 
demanding responsibility or assigning reward. Behavioral 
profiling can be used to uniquely identify a specific type of 
avatar and potentially the avatar owner. Examples of such 
work can be found in Click Fraud and virus detection 
research. In both domains unique behavioral signatures can 
be obtained (sometimes indirectly) from the software agent 
and matched up with known behavioral signatures leading to 
attribution of the attack to a particular hacker or a 
mischievous group.  
C. Securing interaction between different pieces of 
intelligent software or between a human being and an 
instance of intelligent software in a virual world. 
Botnents, groups of intelligent cooperating agent and mixed 
robot/human teams are quickly emerging in numerous 
domains [30,26]. Being able to secure their communications 
is important for further progress in e-commerce, 
crowdsourcing, virtual community development, 
construction, military and any other industry with heavy 
reliance on team based efforts. In order to communicate 
securely identity of all parties wishing to exchange 
information needs to be determined with high degree of 
accuracy. Consequently it is important to develop automatic 
algorithm which would give robots ability to recognize other 
robots and human beings they are working with. While 
numerous algorithms exist to authenticate identity of specific 
robots/computers based on digital signatures and 
cryptographic networking protocols in human dominated 
environments robots have a better chance of “fitting-in” if 
184
they utilize humanlike biometric approach to identity 
management advocated in this paper.    
Other applications include detecting cheating in games 
based on assistance from AI software, for example in chess, 
provide visual and behavioral search capabilities for the 
virtual worlds, such as Second Life, based on descriptions of 
individuals, and targeting merchandise marketing in virtual 
worlds only to agents matching a certain profile.  
 
VI. CONCLUSIONS AND FUTURE DIRECTIONS  
This review paper describes a new subfield of security 
research which transforms and expands the domain of 
biometrics beyond biological entities to include virtual 
reality entities, such as avatars, which are rapidly becoming a 
part of society. Artimetrics research builds on and expands 
such diverse fields of science as forensics, robotics, 
stylometry, computer graphics, biometrics and security. The 
paper describes how verification and recognition of avatars 
can be carried out via visual properties and behavioral 
profiling. It also introduces a multimodal system, 
simultaneously profiling multiple independent physical and 
behavioral characteristic of en entity, and postulates the 
feasibility of creating a multimodal system capable of 
authenticating both biological (human being) and non-
biological (avatars) entities.  
Potential directions for future Artimetrics research include 
the investigation of other visual and behavioral approaches 
to avatar/robot security based on appearance of new 
characteristics and abilities in the avatars/robots of 
tomorrow. Even today it is possible to expand robotic 
biometrics beyond faces and vocabulary to intelligent 
software agents which mimic higher order human 
intelligence (such as composing inspiring music, drawing 
beautiful paintings, and writing poetry). As AI and virtual 
reality research progresses, it will in turn stimulate creation 
of new security solutions to identity management across both 
human and artificial entity worlds.   
REFERENCES 
[1] L. v. Ahn, M. Blum, N. Hopper and J. Langford, CAPTCHA: Using 
Hard AI Problems for Security, Eurocrypt, 2003. 
[2] H. Asoh, S. Hayamizu, I. Hara, Y. Motomura, S. Akaho and T. 
Matsui, Socially embedded learning of the office-conversant mobile 
robot jijo-2, 15th International Joint Conference on Artificial 
Intelligence (IJCAI), 1997. 
[3] H. S. Baird and J. L. Bentley, Implicit CAPTCHAs, In Proceedings of 
the SPIE/IS&T Conference on Document Recognition and Retrieval 
XII (DR&R2005), San Jose, CA, January, 2005. 
[4] J. Bentley and C. L. Mallows, CAPTCHA challenge strings: problems 
and improvements, Document Recognition & Retrieval 18-19 January 
2006. 
[5] R. S. Boyd, Feds thinking outside the box to plug intelligence gaps, 
Available at: http://www.mcclatchydc.com/2010/03/29/91280/feds-
thinking-outside-the-box.html, Retrieved April 10, 2010. 
[6] J. S. Charles, C. Rosenberg and S. Thrun, Spontaneous, Short-term 
Interaction with Mobile Robots, IEEE International Conference on 
Robotics and Automation, 1999, pp. 658-663. 
[7] K.-J. Chen and J.-P. Barthes, Giving an office assistant agent a 
memory mechanism, 7th IEEE International Conference on Cognitive 
Informatics (ICCI), Compiegne, 2008, pp. 402 - 410  
[8] J. Cole, Osama bin Laden's "Second Life", Salon, Available at: 
http://www.salon.com/opinion/feature/2008/02/25/avatars/, Retrieved 
June 7, 2009, 2008. 
[9] M. Corney, O. d. Vel, A. Anderson and G. Mohay, Gender-
preferential text mining of e-mail discourse, 18th Annual Computer 
Security Applications Conference, Brisbane, Australia, 2002, pp. 282-
289. 
[10] I. Craw, D. Tock and A. Bennett, Finding Face Features, Second 
European Conference on Computer Vision, Santa Margherita Ligure, 
Italy, 1992, pp. 92-96. 
[11] Y. Dai and Y. Nakano, Face-Texture Model Based on SGLD and Its 
Application in Face Detection in a Color Scene, Pattern Recognition, 
29(6) (1996), pp. 1007-1017. 
[12] R. Fisher, Avatars can't hide your lying eyes, New Scientist. Issue 
2755. , Available at: www.newscientist.com/article/mg20627555.600-
avatars-cant-hide-your-lying-eyes.html, April 8, 2010. 
[13] T. W. Fong, I. Nourbakhsh and K. Dautenhahn, A survey of socially 
interactive robots, Robotics and Autonomous Systems, 42 (2003), pp. 
143-166. 
[14] G. Frantzeskou, S. Gritzalis and S. MacDonell, Source Code 
Authorship Analysis for Supporting the Cybercrime Investigation 
Process, 1st International Conference on eBusiness and 
Telecommunication Networks - Security and Reliability in Information 
Systems and Networks Track, Kluwer Academic Publishers, Setubal 
Portugal, August 2004, pp. 85-92. 
[15] W. Gao, B. Cao, S. Shan, X. Chen, D. Zhou, X. Zhang and D. Zhao, 
The CAS-PEAL Large-Scale Chinese Face Database and Baseline 
Evaluations, IEEE Transactions on Systems, Man and Cybernetics, 
Part A, 38(1) (2008), pp. 149-161. 
[16] M. L. Gavrilova, Algorithms in 3d real-time rendering and facial 
expression modeling, 3IA'2006 Plenary Lecture, Eurographics, May 
2006, pp. 5-8. 
[17] M. L. Gavrilova, Computational geometry and image processing 
techniques in biometrics: on the path to convergence in Image Pattern 
Recognition: Synthesis and Analysis in Biometrics, World Scientic 
Publishers, 2007. 
[18] S. Gianvecchio, M. Xie, Z. Wu and H. Wang, Measurement and 
classification of humans and bots in internet chat, 17th conference on 
security symposium San Jose, CA, 2008, pp. 155-169. 
[19] A. Gray, P. Sallis and S. MacDonell, Software Forensics: Extending 
Authorship Analysis Techniques to Computer Programs, In Proc. 3rd 
Biannual Conf. Int. Assoc. of Forensic Linguists (IAFL'97), 1997. 
[20] H. v. Halteren, Linguistic profiling for author recognition and 
verification, In Proceedings of ACL-2004, 2004. 
[21] T. Holz, M. Dragone and G. M. P. O’Hare, Where Robots and Virtual 
Agents Meet. A Survey of Social Interaction Research across 
Milgram’s Reality-Virtuality Continuum International Journal of 
Social Robotics 1(1) (January, 2009). 
[22] J. Ito, Fashion robot to hit Japan catwalk, PHYSorg, Available at: 
www.physorg.com/pdf156406932.pdf, Retrieved June 2009. 
[23] A. Jain and S. Z. Li, Handbook on Face Recognition, Springer-Verlag, 
New York, July 2004. 
[24] D. Joachim, K. Jorg, L. Edda and G. Paass, Authorship Attribution 
with Support Vector Machines, Applied Intelligence (2003), pp. 109-
123. 
[25] P. Juola and J. Sofko, Proving and Improving Authorship Attribution, 
Proceedings of CaSTA-04 The Face of Text, 2004. 
[26] T. Kanda, H. Ishiguro, T. Ono, M. Imai and K. Mase, Multi-robot 
cooperation for human-robot communication, 11th IEEE International 
Workshop on Robot and Human Interactive Communication, 2002, pp. 
271- 276. 
[27] J. Khurshid and H. Bing-rong, Military robots - a glimpse from today 
and tomorrow, 8th Control, Automation, Robotics and Vision 
Conference (ICARCV), China, 2004, pp. 771 - 777. 
[28] B. Kjell, Authorship attribution of text samples using neural networks 
and Bayesian classifiers, IEEE International Conference on Systems, 
185
Man, and Cybernetics. 'Humans, Information and Technology', San 
Antonio, TX, USA, 1994, pp. 1660-1664. 
[29] B. Klimpak, M. Grgic and K. Delac, Acquisition of a Face Database 
for Video Surveillance Research, 48th International Symposium 
focused on Multimedia Signal Processing and Communications, 
Zadar, 2006, pp. 111-114. 
[30] V. Klingspor, J. Demiris and M. Kaiser, Human-Robot-
Communication and Machine Learning, Applied Artificial 
Intelligence, 11 (1997), pp. 719-746. 
[31] H. Kobayashi and F. Hara, Study on face robot for active human 
interface-mechanisms of facerobot and expression of 6 basic facial 
expressions, 2nd IEEE International Workshop on Robot and Human 
Communication, Tokyo, Japan, 3-5 Nov 1993, pp. 276-281. 
[32] M. Koppel and J. Schler, Authorship Verification as a One-Class 
Classification Problem, 21st International Conference on Machine 
Learning, Banff, Canada, July 2004, pp. 489-495. 
[33] M. Koppel, J. Schler and D. Mughaz, Text Categorization for 
Authorship Verification, Eighth International Symposium on Artificial 
Intelligence and Mathematics, Fort Lauderdale, Florida, Januray 2004. 
[34] A. Lanitis, C. J. Taylor and T. F. Cootes, An Automatic Face 
Identification System Using Flexible Appearance Models, Image and 
Vision Computing, 13(5) (1995), pp. 393-401. 
[35] H.-O. Lim and A. Takanishi, Waseda biped humanoid robots realizing 
human-like motion, 6th International Workshop on Advanced Motion 
Control, Nagoya, Japan, 2000, pp. 525-530. 
[36] M. Lyons, A. Plante, S. Jehan, S. Inoue and S. Akamatsu, Avatar 
Creation using Automatic Face Recognition, ACM Multimedia 98, 
Bristol, England, Sept. 1998, pp. 427-434. 
[37] M. R. Lyu, I. King, T. T. Wong, E. Yau and P. W. Chan, ARCADE: 
Augmented Reality Computing Arena for Digital Entertainment, IEEE 
Aerospace Conference, Big Sky, MT 5-12 March 2005, pp. 1-9. 
[38] S. McKenna, S. Gong and Y. Raja, Modelling Facial Colour and 
Identity with Gaussian Mixtures, Pattern Recognition, 31 (1998), pp. 
1883-1892. 
[39] D. Misra and K. Gaj, Face Recognition CAPTCHAs, International 
Conference on Telecommunications, Internet and Web Applications 
and Services (AICT-ICIW '06), 19-25 Feb. 2006, pp. 122. 
[40] D. d. Nood and J. Attema, The Second Life of Virtual Reality, 
Available at: http://www.epn.net/interrealiteit/EPN-REPORT-
The_Second_Life_of_VR.pdf, retrieved June 2009. 
[41] J.-H. Oh, D. Hanson, W.-S. Kim, I. Y. Han, Y. Han and I.-W. Park, 
International Conference on Intelligent Robots and Systems, Daejeon, 
2006, pp. 1428 - 1433. 
[42] E. Osuna, R. Freund and F. Girosi, Training Support Vector Machines: 
An Application to Face Detection, IEEE Conference on Computer 
Vision and Pattern Recognition, 1997, pp. 130-136. 
[43] J. N. Oursler, M. Price and R. V. Yampolskiy, Parameterized 
Generation of Avatar Face Dataset, 14th International Conference on 
Computer Games: AI, Animation, Mobile, Interactive Multimedia, 
Educational & Serious Games, Louisville, KY, 2009. 
[44] P. Patel and H. Hexmoor, Designing BOTs with BDI agents, 
International Symposium on Collaborative Technologies and Systems 
(CTS) Carbondale, USA, 2009, pp. 180-186. 
[45] A. Rajagopalan, K. Kumar, J. Karlekar, R. Manivasakan, M. Patil, U. 
Desai, P. Poonacha and S. Chaudhuri, Finding Faces in Photographs, 
6th IEEE Intern. Conference on Computer Vision, 1998, pp. 640-645. 
[46] A. Ross, An Introduction to Multibiometrics, 15th European Signal 
Processing Conference (EUSIPCO) Poznan, Poland, September 2007. 
[47] A. Ross and A. Jain, Information fusion in biometrics, Pattern 
Recognition Letters, 24 (2003), pp. 2115-2125. 
[48] H. Rowley, S. Baluja and T. Kanade, Neural Network-Based Face 
Detection, IEEE Transactions on Pattern Analysis and Machine 
Intelligence, 20(1) (1998), pp. 23-38. 
[49] S.Li and A.Jain, eds., Handbook of Face Recognition-Face Databases, 
Springer, New York, 2005. 
[50] H. Schneiderman and T. Kanade, Probabilistic Modeling of Local 
Appearance and Spatial Relationships for Object Recognition, IEEE 
Conference on Computer Vision and Pattern Recognition, 1998, pp. 
45-51. 
[51] E. H. Spafford and S. A. Weeber., Software Forensics: Can We Track 
Code to its Authors?, 15th National Computer Security Conference, 
Oct 1992, pp. 641-650. 
[52] E. Stamatatos, N. Fakotakis and G. Kokkinakis, Automatic authorship 
attribution, in Proc. nineth Conf. European Chap. Assoc. 
Computational Linguistics, Bergen, Norway, Jun. 1999, pp. 158--164. 
[53] E. Stamatatos, N. Fakotakis and G. Kokkinakis, Computer-Based 
Authorship Attribution Without Lexical Measures Computers and the 
Humanities, 35(2) (2001), pp. 193-214. 
[54] S. J. Stolfo, S. Hershkop, K. Wang, O. Nimeskern and C.-W. Hu, A 
Behavior-based Approach to Securing Email Systems, Mathematical 
Methods, Models and Architectures for Computer Networks Security, 
2776 (2003), pp. 57-81. 
[55] J. Suler, The Psychology of Cyberspace, On-line book, Available at: 
http://psycyber.blogspot.com, 2009. 
[56] X. Tan, S. Chen, Z.-H. Zhou and F. Zhang, Face recognition from a 
single image per person: A survey, Pattern Recognition, 39(9) (2006), 
pp. 1725-1745. 
[57] H. Tang, Y. Fu, J. Tu, M. Hasegawa-Johnson and T. S. Huang, 
Humanoid Audio–Visual Avatar With Emotive Text-to-Speech 
Synthesis, IEEE Transactions on Multimedia 10 (2008), pp. 969-981. 
[58] D. Teijido, Information assurance in a virtual world, Australasian 
Telecommunications Networks and Applications Conference 
(ATNAC09), Canberra, Australia, November 10-12, 2009. 
[59] B. G. Thompson, The State of Homeland Security, House.gov, 
Available at: http://hsc-democrats.house.gov/SiteDocuments/ 
20060814122421-06109.pdf, Retrieved June 10, 2009, 2006. 
[60] M. Turk and A. Pentland, Eigenfaces for Recognition, Journal of 
Cognitive Neuroscience, 3(1) (1991), pp. 71-86. 
[61] O. D. Vel, A. Anderson, M. Corney and G. Mohay, Mining Email 
Content for Author Identification Forensics, ACM SIGMOD Record: 
Special Section on Data Mining for Intrusion Detection and Threat 
Analysis, 30(4) (2001), pp. 55-64. 
[62] R. V. Yampolskiy, Behavioral Biometrics for Verification and 
Recognition of AI Programs, 20th Annual Computer Science and 
Engineering Graduate Conference (GradConf2007), Buffalo, NY, 
2007. 
[63] R. V. Yampolskiy, Mimicry Attack on Strategy-Based Behavioral 
Biometric, 5th International Conference on Information Technology: 
New Generations (ITNG2008). Las Vegas, Nevada, April 7-9, 2008, 
pp. 916-921. 
[64] R. V. Yampolskiy and V. Govindaraju, Behavioral Biometrics for 
Recognition and Verification of Game Bots, The 8th annual European 
Game-On Conference on simulation and AI in Computer Games 
(GAMEON'2007), Bologna, Italy, November 20 - 22, 2007. 
[65] R. V. Yampolskiy and V. Govindaraju, Behavioral Biometrics for 
Verification and Recognition of Malicious Software Agents, SPIE 
Defense and Security Symposium, Orlando, March 16-20, 2008. 
[66] R. V. Yampolskiy and V. Govindaraju, Embedded Non-Interactive 
Continuous Bot Detection, ACM Computers in Entertainment, 5(4) 
(2007), pp. 1-11. 
[67] G. Yang and T. S. Huang, Human Face Detection in Complex 
Background, Pattern Recognition, 27(1) (1994), pp. 53-63. 
[68] M.-H. Yang, D. J. Kriegman and N. Ahuja, Detecting Faces in 
Images: A Survey, IEEE Transactions On Pattern Analysis and 
Machine Intelligence, 24(1) (2002). 
[69] S. Yanushkevich, M. Gavrilova, P. Wang and S. Srihari, Image 
Pattern Recognition: Synthesis and Analysis in Biometrics, World 
Scientific Publishers, 2007. 
[70] S. Yanushkevich, A. Stoica, V. Shmerko and D. Popel, Inverse 
Problem of Biometric, CRC Press/Taylor&Francis, 2005. 
[71] K. C. Yow and R. Cipolla, Feature-Based Human Face Detection, 
Image and Vision Computing, 15(9) (1997), pp. 713-735. 
[72] L. Yuan, M. Gavrilova and P. Wang, Facial metamorphosis using 
geometrical methods for biometric applications, IJPRAI, 22(3) (May 
2008), pp. 555 - 584. 
[73] W. Zhao, R. Chellappa, P. J. Phillips and A. Rosenfeld, Face 
recognition: A literature survey, ACM Computing Surveys 35(4) 
(2003), pp. 399 - 458. 
 
186
