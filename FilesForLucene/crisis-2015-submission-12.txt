Short Text Sentiment Analysis for Mobile
Device Forensic Examinations
Oluwapelumi Aboluwarin1, Panagiotis Andriotis1, Atsuhiro Takasu2 and Theo
Tryfonas1
1 University of Bristol, Bristol, BS8 1TH, United Kingdom
2 National Institute of Informatics, 2-1-2 Hitotsubashi,
Chiyoda-ku, Tokyo 101-8430, Japan
Abstract. In recent times, mobile devices have served as a dominant
medium for communication across individuals. While communicating,
humans express different emotions which can be aggregated to analyse
their emotional inclination across diverse subjects of interest. Natural
Language Processing (NLP) techniques have been used to analyse sen-
timent in text by researchers. However, research work involving senti-
ment analysis in the short message domain (Short Message Service texts:
SMS and Twitter feeds: Tweets) do not account for the presence of non-
dictionary words. In this paper, we investigate the problem of Sentiment
Analysis in short messages in a bid to analyse the emotional swing of
an individual over time. This provides an additional layer of information
for forensic analysts while probing suspects. We compared four Machine
Learning (ML) algorithms and identified the optimal one for our task.
Non-dictionary words were normalised and the impact of normalisation
on the classification task was investigated. The Sentiment polarity Clas-
sification task F-Score was improved by 6.96% when compared to related
work. An intuitive user interface (defined as a Forensic Tool) was devel-
oped to ease extraction of sentiment information from SMS of individu-
als.
Keywords: Sentiment Analysis, SMS, Twitter, Normalisation, Text Min-
ing, Micro-blogging
1 Introduction
The ubiquity of mobile devices has extensively redefined the communication
landscape across the world. This has led to the creation of valuable individual
data through conversational services like SMS and micro blogging platforms like
Twitter. Mining the content of such interactions can provide valuable insight on
the people an individual communicates with. Information such as the time the
interaction takes place and the content of the conversation might be useful to
the forensic analysis because it reveals patterns hidden in the text.
Using Machine Learning techniques, additional information on the disposi-
tion of conversations can be extracted. Sentiment Analysis is the field concerned
2
with retrieving opinion or emotion expressed in text. In literature, applications
of Sentiment Analysis have been proposed in different fields with a special in-
terest in the social media and micro blogging services. Sentiment information
can also be useful for forensic investigations in smartphones as proposed by [2].
To the best of our knowledge, at the time of this writing there is no particular
study in the literature that discusses the use of Sentiment Analysis with Machine
Learning methods in short texts (SMS) to enhance digital forensic analysis in
mobile devices.
This paper therefore investigates the use of sentiment analysis to model the
emotional swing of an individual as opposed to the emotional swing of a group
of people towards a brand, which is more common in literature. We used Ma-
chine Learning algorithms for the sentiment polarity classification task. We also
accounted for lexically incorrect terms that are prevalent in conversational texts
by normalizing them. Such invalid terms are known to negatively impact the
efficiency of NLP tasks as proposed by [20]. The emotional timeline generated
by the tool we developed provides an additional layer of information about a
person under investigation, because it helps the forensic analyst identify periods
of time that such an individual exhibits volatile emotional state.
Our main contributions are outlined below:
– We show the effect of normalising non dictionary words alongside other sen-
tence level features to improve the Sentiment Polarity classification task. A
POS-Tagger aware of the peculiarities on short messages was also shown to
improve the classifier performance.
– We study how individual features affect the performance of the most efficient
classifier for emotional classification in short text.
– We present a conceptual design of a forensic tool that provides details about
sentiment polarity expressed in an individual’s SMS messages in a concise
and intuitive manner to facilitate rapid extraction of information by forensic
analysts.
The remaining part of this paper is organised as follows. Section 2 briefly
describes related work in the field of Natural Language Processing and Digital
Forensics with a focus on Text Mining and Sentiment Analysis. Section 3 provides
information on the classifiers implemented and the datasets we used. In Section 4
we discuss the results obtained from our experiments testing variations of feature
sets. The forensic tool used for sentiment visualisation is described in Section 5.
Finally, Section 6 presents our conclusions and provides directions for future
work.
2 Related Work
The need to know the opinion of others on subjects of interest always proves
valuable when trying to make decisions in an unfamiliar terrain [5,18,21,27]. The
ubiquity of review and recommendation data provided online, makes the web a
go-to place for seekers of such information. People rely on the opinion of others
3
on the web to guide decision-making by viewing reviews of products, movies,
employers, schools and so on. Increased interest in this sort of information has
been the major driver of research into the field of Sentiment Analysis. Since the
work of [22] and [27] in 2002, Sentiment Analysis has been studied extensively in
a bid to make sense of the extensive text containing opinion information available
online.
Sentiment Analysis started getting increasing attention in the research land-
scape after the work of both [22] and [27] in 2002 and since then it has been
studied extensively leading to its use in many interesting applications like con-
tent advertising in [14], election monitoring in [28] and customer feedback data
classification in [10].
Sentiment Analysis problems often take the form; given an instance of text,
determine its polarity as either positive or negative, or identify its position within
the extremes of both polarities [21]. Since some text instances are neither posi-
tive nor negative, sentiment analysis also involves identifying texts that do not
convey any form of emotion which are referred to as ‘neutral’. Hence, sentiment
analysis problems are handled as classification or regression tasks. As an exam-
ple, deducing if a movie review is positive or negative is a binary classification
task, while deducing how positive the review is on a scale of 1-10 is a regres-
sion task. In addition, such problems can be treated as multi-class classification
tasks in scenarios where the instances to be classified fall under categories such
as positive, negative and neutral.
Sentiment Analysis techniques include: a) Lexicon based methods, b) Ma-
chine Learning methods and c) Hybrid approaches combining both methods [9].
When treating Sentiment Analysis as a classification task, Machine learning al-
gorithms known to perform well in text classification are often used. Some of the
supervised learning algorithms commonly used in literature are; Support Vector
Machines (SVM), Multinomial Naive Bayes and Maximum Entropy (Logistic
Regression)[22,11,26].
In Digital Forensics, text mining methods have been used in tasks like au-
thorship attribution in emails [15], gender detection in short messages [7] and
text string searching [3]. SVM algorithms were used to determine the authors
of emails [8] and identify the gender of the author of an SMS [7]. Authorship
attribution experiments were also conducted using ML in [13] and [24].
The work of [19] is closely related to our research as it focuses on extracting
sentiment polarity information from ‘tweets’. The paper details the techniques
used by the winning team of the 2013 SemEval competition for Sentiment Polar-
ity classification. In [2] the authors initiated a research that involves the use of
sentiment analysis to augment forensic investigation by retrieving opinion infor-
mation from SMS found on a mobile device. A lexicon-based technique was used
for the Sentiment Polarity Classification task. The research presented a proof of
concept to visualize the emotional content within SMS.
Since ML techniques are known to outperform lexicon-based methods [11],
we decided to use ML methods for Sentiment Classification as a part of devel-
oping a forensic tool. Our work takes cues from some sentence level features
4
presented in [19]. We further improved the classification task by integrating nor-
malisation of non-dictionary words. We also used conclusions presented at [25],
which is a survey that describes commonly used techniques in handling noisy
text and serves as a good introduction to the problem we investigate. Finally,
the work of [12] which used a Statistical Machine Translation (SMT) technique
for normalisation served as the basis of our normalisation task in this research
work.
3 Dataset and Classification
We trained four classifiers using four ML algorithms namely; Multinomial Naive
Bayes (MNB), Support Vector Machine (SVM), Maximum Entropy (MaxEnt)
and K-Nearest Neighbours (KNN) Classifier. The algorithms were implemented
in Python using the scikit-learn library [23]. The MaxEnt classifier outperformed
other classifiers in terms of the F-Score and execution speed when evaluated
using ten-fold cross validation and an unseen SMS dataset. Subsequent parts of
this section describe an overview of the dataset, features used and preprocessing
techniques. Figure 1 shows the classifier architecture and the interaction of its
components.
Fig. 1. A representation of the Classifier architecture
3.1 Dataset Overview
The dataset used during the 2013 Semantic Evaluation (SemEval) competition
workshop was used for training our models. More information about it can be
found at the SemEval Task description webpage: http://www.cs.york.ac.uk/
semeval-2013/task2. Our dataset contained a total of 8120 tweets . The polar-
ity distribution of each class label (positive, negative and neutral) is shown in
Table 1. Table 2 gives an overview of the SMS test dataset used. It is the same
as the test set in the work of [2] making it possible to compare results directly.
5
Label Count (%)
Positive 3019 (37.18%)
Negative 1193 (14.69%)
Neutral 3908 (48.13%)
Total 8120 (100%)
Table 1. Training Dataset [19].
Label Count (%)
Positive 1866 (67.03%)
Negative 918 (32.97%)
Neutral 0 (0%)
Total 2784 (100%)
Table 2. Test Dataset [2].
3.2 Preprocessing
Preprocessing involves the cleansing of raw datasets before applying ML algo-
rithms. It is a standard procedure in most ML tasks and the techniques used
varies across domains. Proper preprocessing ensures noisy data is in proper shape
for ML algorithms. In text mining, preprocessing often consists of normalisation,
spelling correction, managing text encoding etc. Some of the techniques used here
are briefly described subsequently.
Normalisation In this context, normalisation involves resolving lexically in-
correct monosyllabic terms to their correct form. This may be in form of spelling
mistakes or adhoc social media short forms as defined by [17]. Normalisation is
known to improve the quality of some Natural Language tasks like language
translation as seen in [16] and [17].
Raw text: Hi ranger hw r u
Normalised text: Hi ranger how are you
Normalisation was handled as a Statistical Machine Translation (SMT) task and
some of the techniques used are described in [17]. The output of the Normali-
sation task is a dictionary mapping of lexically incorrect terms to the lexically
correct variants. An example of such mapping can be identified by mapping each
word in the ‘Raw text’ to the corresponding word in the ‘Normalised text’ in
the representation above.
The SMT technique requires the use of a parallel corpus. A parallel corpus
is a list of messages containing lexically incorrect terms mapped to the lexi-
cally correct form. In our dataset the total number of ‘incorrect terms’ that
were mapped as ‘corrected terms’ using the aforementioned method was 156.
Thus, the generated normalisation dictionary was quite small due to the limited
corpora size. To supplement this disadvantage, we used as an addition the nor-
malisation dictionary generated from the work of [12] which contains over 41,181
normalisation candidates in the short message domain.
To apply the normalisation dictionary to the corpus, each tweet was tokenized
and lexically correct tokens were filtered off, leaving only lexically invalid tokens.
Lexically correct terms were identified based on their presence in an English
dictionary using the Python ‘Enchant’ library3. We identified the remaining
3 Enchant is a python spell checking library. It can be used to identify words that are
not in the dictionary of a defined language. More details at: http://bit.ly/pyench
6
lexically correct terms by checking for their presence in online slang dictionaries
(Urban Dictionary). Normalising the data instances before the sentiment polarity
classification task is one of the novel contributions of this work.
Data Cleaning: Some terms (specific to Twitter and SMS) were cleaned to
reduce the noise in the data. All occurrences of a user mention (e.g. @jack) and
all web addresses within tweets were replaced with an empty string. In addition,
occurrences of the term ‘RT’, which means retweet on Twitter, were removed.
These terms were removed to avoid overfitting the model on the Twitter dataset
knowing fully well that mentions, retweets and URLs are not as common in SMS
as they are in tweets. Positive emoticons were with words known to have a pos-
itive connotation while negative emoticons were replaced with negative polarity
words. This ensures that the information emoticons add to the model is not
lost during the process of tokenisation since emoticons are prone to ambiguous
tokenization.
Data Cleaning also involved the unification of elongated expressions. Elon-
gated expressions here are terms with a sequence of three or more characters
(e.g. ‘whyyyy’). Such expressions are usually used to convey emphasis on social
media and the number of elongated characters often varies across users. All such
elongated characters were trimmed to a maximum of two, making it easier to
identify words that are emphasising the same emotion. This implies that a term
like ‘killll’ was trimmed to ‘kill’.
Stemming: This is the process of reducing a word to its root form. For in-
stance, the words ‘simpler’ and ‘simplest’ are reduced to ‘simple’ when stemmed.
The aim of stemming is to ensure that words carrying the same meaning (but
written in different forms) are transformed to the same format so as to unify
frequency counts. We used the Snowball Stemmer because it resulted in a better
performance when compared to the Porter Stemmer.
Stop word removal: In NLP tasks, stop words are words that are known to
occur more frequently in a language than other words. In many NLP tasks, stop
words are usually filtered out since their presence biases the model. In this work,
we deduced a corpus specific list of stop words which is based on the frequency
of words in the dataset. This implies that words frequently occurring in the
corpus were filtered out making our model more robust in handling datasets
from different sources.
3.3 Description of Classifier Features
To generate the feature vectors, different feature extraction techniques were used.
Features were determined from emoticons, lexicons, tweet content, POS tags
present etc. Details of the features can be found below.
Lexicon based Features: Five distinct opinion lexicons were used similar to
the work of [19]. Two of them were manually generated while the remaining
three were created using Distant Supervision. The features extracted from each
lexicon for the tweets are; number of positive tokens, score of the maximum
7
scoring token, score of last token and net score of tweet using the sum of the
score of its tokens.The lexicons are outlined subsequently:
1. Bing Liu’s Opinion Lexicon: This is a manually created lexicon with
2006 positive words and 4783 negative words. It includes common wrongly
spelt terms, slangs and social media lingo making it more valuable than a
pure English lexicon. The lexicon was compiled from 2004 to 2012 by [9].
2. Multi Perspective Question Answering (MPQA4) Subjectivity Lex-
icon: It contains 8221 manually labeled unigrams. It indicates the prior po-
larity of a word alongside its part of speech information.
3. NRC Word-Emotion Association Lexicon: A unigram lexicon with
14,200 unique words manually labeled as positive or negative.
4. Sentiment140 Lexicon: It was automatically generated from Twitter data
(1.6million tweets) using distant supervision. The lexicon contains 62,468
unigrams and 677,698 bigrams.
5. NRC Hashtag Sentiment Lexicon: It was generated using a similar tech-
nique to the Sentiment140 lexicon. It contains 54,129 unigrams and 316,531
bigrams.
Emoticon Features: Three distinct features were generated based on emoti-
cons. Two of the features are binary features that indicate the presence or ab-
sence of positive or negative emoticon in the tweets. The presence of the desired
property sets the feature to 1 while it’s absence sets it to 0. The third emoticon-
based feature sets a binary feature based on if the tweet ends with a positive or
negative emoticon. The last token of a tweet is significant because it provides
valuable insight on the concluding message of a tweet.
POS Tagging: POS tagging involves the assignment of Part of Speech informa-
tion to a word in text. It is know in NLP circles that part of speech information
provides important insight into sentiment information in text. POS tagging of
tweets using traditional taggers tend to lead to unusual results because of the
noise and abundance of out-of-vocabulary (OOV) terms present in tweets. To
augment the NLTK Tagger [4], a POS tagger aware of the nature of Twitter lingo
is used. The authors of [20] implemented a Twitter aware POS tagger trained
with manually labeled POS tagged tweets. After successfully retrieving the POS
tags for each tweet, for each tag name in the tag set, the number of times each
POS tag occurs is identified and accounted for by an integer value.
Sentence Level Features Sentence level features accounted for are upper case
word count, elongated word count and presence of punctuations.
– In each tweet, the number of words that appear in uppercase was counted.
4 The MPQA Subjectivity lexicon can be retrieved here: http://mpqa.cs.pitt.edu/
lexicons/subj_lexicon/
8
– Counting the number of words containing a character sequence greater than
two identified elongated word count.
– A binary feature was used to represent if the last token in a tweet is an
exclamation or question mark.
– The number of continuous sequence of exclamation or question mark.
– Negation was handled using the method proposed by [22] which is defined
as the region of a tweet that starts with a negation term and ends with any
of the punctuations full stop, comma, question mark, colon, semi colon or
exclamation mark.
4 Evaluation and Discussion
At the early stage of our experimentation, we implemented a cascade of two
classifiers for each of the algorithms. The first classifier was used to separate
neutral tweets from positive and negative ones while the second one was used to
separate positive and negative tweets. We compared different properties (time,
precision, recall, F-score) of the classifiers in order to identify the most effective
one. Table 3 shows the training time of each of the classifiers.
Classifier Algorithm SVM KNN MNB MaxEnt
Time (seconds) 373 9.31 47.53 10.71
Table 3. Neutral vs Positive & Negative classifier training time.
Figure 2 shows a barchart comparing the precision, recall and F-Score ob-
tained in classifier 1 (Neutral vs Positive & Negative classifier) using different
ML algorithms.
Fig. 2. Comparison of Classifier 1 metrics across 4 algorithms.
From the bar chart, it can be seen that the best performing classifiers had
comparable results (Figure 2). Recall was the highest of the metrics measured
9
across all the classifiers (Naive Bayes recall being 99.97%). The best F-Score
was from the MaxEnt Classifier, closely followed by Multinomial Naive Bayes
and SVM. Although recall was higher in the MNB classifier, the F-Score of the
MaxEnt classifier was better. After integrating improvements into the classifiers,
MaxEnt had the best performance in time and F-Score. Hence, it was used to
power the forensic tool.
Following the baseline results, we performed further experiments using dif-
ferent feature extraction techniques so as to identify the optimal combination of
features resulting in the best performance. Table 4 shows the effect of each of
the features on the overall F-Score of the classifier.
Experimentation F-Score (% difference)
Optimal features combination 73.59
Part of Speech (POS) Tagging 71.59 (2.00)
Stemming 72.13 (1.46)
Stop word removal 72.27 (1.32)
Negation Handling 72.52 (1.07)
All Lexicons 72.82 (0.77)
Sentence level features (Capitalization, term
elongation, punctuation, emoticons)
73.18 (0.41)
Bigrams 73.27 (0.32)
Normalization 73.28 (0.31)
Table 4. Effect of individual features on F-Score for MaxEnt.
From the results, it can be observed that the features based on the Twitter
aware POS tagger [20] had the highest positive impact on the F-Score followed
by stemming, both increasing the F-Score by a cummulative 3.46%. We experi-
mented with a traditional POS tagger and it skewed the results by reducing the
F-Score. This further reinforces the impact of using tools suitable for the short
message domain. The use of normalisation and removal of stop words during the
preprocessing phase boosted the F-Score by a total of 1.62%. The introduction
of some of these features resulted in the better performance of our classifier when
compared to related work [19], [2] where the features were not used. Stop word
removal involved identifying domain-specific stop-words based on word frequen-
cies in the data set. Although the lexicon based features improved the F-Score
by a total of 0.77% it was not as effective as it was in the work of [19] where
it resulted in approximately 8% increase. This can be explained by the use of a
different ML algorithm in our research and the introduction of novel preprocess-
ing techniques. The test set used was the same as the one used in the work of
[2] where an F-Score of 68.8% was obtained compared to the 73.59% obtained
in this work which is a percentage increase of 6.96%.
10
Fig. 3. Architecture of Forensic (Sentiment Visualization) Tool.
5 Forensic Tool (Sentiment Visualization Tool)
A web visualization tool was implemented as a proof of concept creating an
easy to use interface to extract relevant sentiment information from SMS. The
implementation was done using the Python ‘Flask’ library and the ‘Bootstrap’
framework for the frontend. The classifier was trained with the set of features
resulting in the best F-Score and it is used to predict the sentiment of unknown
SMS instances of individuals. Figure 3 shows the architecture of the forensic
tool.
Note that despite the classifier was trained with tweets and not SMS mes-
sages, the visualisation tool uses SMS as a test case. This is because tweets
and SMS share a striking similarity in terms of structure. Both formats set re-
strictions to their lenght using character limits and they also include words and
symbols with common characteristics (e.g. emoticons). More details on the sim-
ilarity between SMS and tweets can be found in the work of [2]. Furthermore,
the classifier test result on an unseen SMS dataset presented in Table 4 shows
that the classifier performs well on an SMS dataset.
The messages used to showcase the forensic tool are a part of the NUS
dataset [6] which contains a total of 45,062 messages sent by over 100 people
spanning over 3 years (from 2010 to 2014). The messages are in XML format and
each message tag contains meta-data about the SMS5. The available information
about each message in the dataset we used is outlined below:
– Sender phone number.
– Recipient phone number.
– Time message was sent.
– Age of sender.
5 However, the new version of the dataset contains anonymous information.
11
– Country and city where message is sent.
After parsing the XML message data, the sender, recipient and time fields
are retrieved for each SMS message. The age, country and city fields are not used
in this research work. Each SMS is preprocessed using the same preprocessing
techniques utilised when training the classifier. Features are extracted and fed
into the classifier as test input data for sentiment polarity classification. The
classifier outputs the polarity of each SMS message and the classified messages
are pushed into Apache Solr6 for storage and indexing.
Apache Solr is a fast, open source enterprise search software built on Apache
Lucene. Solr allows facetted search, which entails dynamic clustering of search
results to help users easily drill down to answers they want. An example of a
facetted search in the context of this project is to find messages that have a
negative polarity, and are sent by a particular user S after a given time T. The
ability to have such strong grip on the data retrieval process is the rationale
behind pushing the data into Solr. Additional interesting features can be built
into the forensic tool in future because of the features provided by Solr.
Once the visualization software interface is launched, it accesses the relevant
Solr core7 and gets all the unique suspects. These suspects are pre-loaded into
a dropdown list. The suspect of interest can thus be selected and information
about the polarity of messages sent by the individual can be visualized. The
preloaded data creates an avenue to showcase the features of the forensic tool.
In a real life use case we would expect to follow a certain procedure during a
forensic analysis: 1) Obtain physical image from the device, 2) fetch SMS from
the SQLite database (mmssms.db if the mobile device runs under the Android
operating system), c) classify them with the trained classifier and d) push the
result into Solr, where the visualization tool can access it. This research work
does not cover techniques for extracting messages from a mobile device. Infor-
mation on extracting physical digital images and SMS messages from Android
devices is detailed in [1].
The visualization tool consists of: a) A pie chart, b) tag cloud, c) sentiment
timeline view and d) search interface. Each of the components are outlined sub-
sequently.
5.1 Search Tool
A search tool was implemented allowing a user to search for an occurrence of
any desired term within the messages. As a use case scenario, we assume that
there is an interest to find out which are the messages where the user mentions
the word ‘feel’. The search box seen in Figure 4 can be used to enter a search
query. Also Figure 4 shows the output with relevant results.
6 Solr project homepage: http://lucene.apache.org/solr/
7 The Solr core is the running instance of Lucene with the solr configuration. Details
on Solr can be found here: https://wiki.apache.org/solr/SolrTerminology
12
Fig. 4. Screenshot of Forensic Tool Search component.
5.2 Polarity Distribution View
The visualisation component is a pie chart and it is used to show the percentage
polarity distribution of messages sent. Figure 5 illustrates a screenshot that
shows the polarity distribution of sent messages for a given user as seen on the
dashboard of the sentiment visualisation tool.
Fig. 5. Screenshot of Polarity Distribution of suspect SMS messages repre-
sented in a pie chart.
5.3 Tag Cloud
A tag cloud is used to render the most common words in messages with negative
polarity. This gives an observer a feel of terms that are often associated with a
negative emotion by the individual. The tag cloud we implemented is interactive
as it responds to mouse click events. When a word is clicked in the tag cloud,
messages containing the word are returned. Figure 6 shows a screenshot of the
tag cloud generated for a sample user.
13
Fig. 6. Screenshot of Tag Cloud Generated for user SMS in Visualization
Tool.
5.4 Sentiment Timeline View
A sentiment timeline view was implemented to ease analysis of the mood swing
of an individual over time. Figure 7 shows a screenshot of the timeline view
with the horizontal axis representing the day and the vertical axis representing
number of messages sent.
When the mouse cursor hovers on a node, a tooltip is used to display the
number of SMS messages the node represents. The node can then be clicked
to view the content of the messages sent as well. As seen in the screenshot,
on Friday 12th March, it can be observed that the user experienced a sudden
spike in emotional swing. This is because the user sent 8 negative messages that
day but did not send any negative message the previous day. The forensic tool
extracts patterns of this nature and it can help the forensic analyst identify
emotional fingerprints that will have been otherwise hidden.
Fig. 7. Screenshot of Sentiment Timeline component of Forensic tool.
14
6 Conclusion and Future Work
This research work has succeeded in bringing the problems plaguing sentiment
analysis in the short message domain to the fore and presents useful tools to
solve each of those problems. A sentiment aware tokenizer was used, a POS-
Tagger suitable for the short message domain was utilized, normalisation was
implemented and negation was handled. Amidst all the features used, the POS
tagging feature proved to be most effective followed by stemming. The use of
normalisation, domain specific stop words (based on term frequency) and bigram
features absent in related work further improved the results. We also showed that
the classifier performed well on an SMS test set, validating the similarity between
SMS and tweets and affirming that the model does not overfit.
An intuitive visualization tool was implemented to aid extraction of intel-
ligence information regarding an individual. It helps visualize the mood swing
of an individual overtime and such information can prove useful for a forensic
analyst. Experimentation was done with several sentence level features and the
effect of normalisation in Sentiment Polarity Classification was demonstrated.
The sentiment visualization tool implemented presents a unique view into
understanding the sentiment expressed by humans over time. The tool allows
intuitive visualization of the mood swing of an individual providing valuable
patterns of low times and high times. This tool does not in any way aim to
replace a forensic analyst; it simply serves as an additional source of information
for further investigation.
This research shows potential for developing a forensic tool based on SMS
information retrieved from a user’s mobile device. In a bid to improve the forensic
tool, the visualization tool can be improved to provide an overview of the subjects
discussed in the messages. A keyword based preliminary version of this is already
achieved by the tag cloud. This will entail providing an overview of the summary
of a group of messages. The forensic tool developed already shows how the
emotional state of an individual evolves over time based on messages sent.
Some further research can be done to identify if there is a pattern asso-
ciated with the mood swing. This will provide additional useful information
for the forensic analyst. To improve the classification F-Score and efficiency,
well-established Feature reduction techniques like Principal Component Analy-
sis (PCA) can be used to reduce the feature space. This will improve the runtime
of some of the classifiers like the SVM and it may improve classification results.
The MNB classifier powering the forensic tool uses the default decision threshold
for classification. ROC analysis can be done to identify the optimal threshold
for each of the classifiers so as to improve the classification accuracy.
Acknowledgments
This work has been supported by the EU DG Home Affairs - ISEC (Preven-
tion of and Fight against Crime) / INT (Illegal Use of Internet) programme
(HOME/2012/ISEC/AG/INT/4000003892) and the National Institute of Infor-
matics, Tokyo, Japan.
15
References
1. Andriotis, P., Oikonomou, G.C., Tryfonas, T.: Forensic analysis of wireless net-
working evidence of android smartphones. In: WIFS. pp. 109–114 (2012)
2. Andriotis, P., Takasu, A., Tryfonas, T.: Smartphone message sentiment analysis.
In: Peterson, G., Shenoi, S. (eds.) Advances in Digital Forensics X, IFIP Advances
in Information and Communication Technology, vol. 433, pp. 253–265. Springer
Berlin Heidelberg (2014), http://dx.doi.org/10.1007/978-3-662-44952-3_17
3. Beebe, N.L., Clark, J.G.: Digital forensic text string searching: Improving infor-
mation retrieval effectiveness by thematically clustering search results. Digital in-
vestigation 4, 49–54 (2007)
4. Bird, S.: Nltk: the natural language toolkit. In: Proceedings of the COLING/ACL
on Interactive presentation sessions. pp. 69–72. Association for Computational Lin-
guistics (2006)
5. Cambria, E., Schuller, B., Xia, Y., Havasi, C.: New avenues in opinion mining and
sentiment analysis. Intelligent Systems, IEEE 28(2), 15–21 (2013)
6. Chen, T., Kan, M.Y.: Creating a live, public short message service corpus: The
nus sms corpus. Language Resources and Evaluation 47(2), 299–335 (2013)
7. Cheng, N., Chandramouli, R., Subbalakshmi, K.: Author gender identification from
text. Digital Investigation 8(1), 78–88 (2011)
8. De Vel, O., Anderson, A., Corney, M., Mohay, G.: Mining e-mail content for author
identification forensics. ACM Sigmod Record 30(4), 55–64 (2001)
9. Ding, X., Liu, B., Yu, P.S.: A holistic lexicon-based approach to opinion mining.
In: Proceedings of the 2008 International Conference on Web Search and Data
Mining. pp. 231–240. ACM (2008)
10. Gamon, M.: Sentiment classification on customer feedback data: noisy data, large
feature vectors, and the role of linguistic analysis. In: Proceedings of the 20th in-
ternational conference on Computational Linguistics. p. 841. Association for Com-
putational Linguistics (2004)
11. Go, A., Bhayani, R., Huang, L.: Twitter sentiment classification using distant
supervision. CS224N Project Report, Stanford pp. 1–12 (2009)
12. Han, B., Cook, P., Baldwin, T.: Lexical normalization for social media text. ACM
Transactions on Intelligent Systems and Technology (TIST) 4(1), 5 (2013)
13. Iqbal, F., Binsalleeh, H., Fung, B., Debbabi, M.: Mining writeprints from anony-
mous e-mails for forensic investigation. digital investigation 7(1), 56–64 (2010)
14. Jin, X., Li, Y., Mah, T., Tong, J.: Sensitive webpage classification for content
advertising. In: Proceedings of the 1st international workshop on Data mining and
audience intelligence for advertising. pp. 28–33. ACM (2007)
15. Juola, P.: Authorship attribution. Foundations and Trends in information Retrieval
1(3), 233–334 (2006)
16. Kobus, C., Yvon, F., Damnati, G.: Normalizing sms: are two metaphors better
than one? In: Proceedings of the 22nd International Conference on Computa-
tional Linguistics-Volume 1. pp. 441–448. Association for Computational Linguis-
tics (2008)
17. Ling, W., Dyer, C., Black, A.W., Trancoso, I.: Paraphrasing 4 microblog normal-
ization. In: EMNLP. pp. 73–84 (2013)
18. Mart́ınez-Cámara, E., Mart́ın-Valdivia, M.T., Ureñalópez, L.A., Montejoráez,
A.R.: Sentiment analysis in twitter. Natural Language Engineering pp. 1–28 (2012)
19. Mohammad, S.M., Kiritchenko, S., Zhu, X.: Nrc-canada: Building the state-of-the-
art in sentiment analysis of tweets. arXiv preprint arXiv:1308.6242 (2013)
16
20. Owoputi, O., O’Connor, B., Dyer, C., Gimpel, K., Schneider, N., Smith, N.A.:
Improved part-of-speech tagging for online conversational text with word clusters.
In: HLT-NAACL. pp. 380–390 (2013)
21. Pang, B., Lee, L.: Opinion mining and sentiment analysis. Foundations and trends
in information retrieval 2(1-2), 1–135 (2008)
22. Pang, B., Lee, L., Vaithyanathan, S.: Thumbs up?: sentiment classification using
machine learning techniques. In: Proceedings of the ACL-02 conference on Empir-
ical methods in natural language processing-Volume 10. pp. 79–86. Association for
Computational Linguistics (2002)
23. Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O.,
Blondel, M., Prettenhofer, P., Weiss, R., Dubourg, V., et al.: Scikit-learn: Ma-
chine learning in python. The Journal of Machine Learning Research 12, 2825–2830
(2011)
24. Stolerman, A., Overdorf, R., Afroz, S., Greenstadt, R.: Breaking the closed-world
assumption in stylometric authorship attribution. In: Advances in Digital Forensics
X, pp. 185–205. Springer (2014)
25. Subramaniam, L.V., Roy, S., Faruquie, T.A., Negi, S.: A survey of types of text
noise and techniques to handle noisy text. In: Proceedings of The Third Workshop
on Analytics for Noisy Unstructured Text Data. pp. 115–122. ACM (2009)
26. Suttles, J., Ide, N.: Distant supervision for emotion classification with discrete
binary values. In: Computational Linguistics and Intelligent Text Processing, pp.
121–136. Springer (2013)
27. Turney, P.D.: Thumbs up or thumbs down?: semantic orientation applied to un-
supervised classification of reviews. In: Proceedings of the 40th annual meeting on
association for computational linguistics. pp. 417–424. Association for Computa-
tional Linguistics (2002)
28. Wang, H., Can, D., Kazemzadeh, A., Bar, F., Narayanan, S.: A system for real-time
twitter sentiment analysis of 2012 us presidential election cycle. In: Proceedings of
the ACL 2012 System Demonstrations. pp. 115–120. Association for Computational
Linguistics (2012)
