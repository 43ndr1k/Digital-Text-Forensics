Cuisine: Classification Using Stylistic Feature
Sets and/or Name-Based Feature Sets
Yaakov HaCohen-Kerner, Hananya Beck, Elchai Yehudai, and Mordechay Rosenstein
Department of Computer Science, Jerusalem College of Technology (Machon Lev),
21 Havaad Haleumi Street, P.O.B. 16031, 91160 Jerusalem, Israel.
E-mail: {kerner, hananya, yehuday, timur}@jct.ac.il
Dror Mughaz
Department of Computer Science, Bar-Ilan University, 52900 Ramat-Gan, Israel and
Department of Computer Science, Jerusalem College of Technology (Machon Lev).
E-mail: myghaz@cs.biu.ac.il
Document classification presents challenges due to
the large number of features, their dependencies, and the
large number of training documents. In this research, we
investigated the use of six stylistic feature sets (including
42 features) and/or six name-based feature sets (includ-
ing 234 features) for various combinations of the fol-
lowing classification tasks: ethnic groups of the authors
and/or periods of time when the documents were writ-
ten and/or places where the documents were written.The
investigated corpus contains Jewish Law articles written
in Hebrew–Aramaic, which present interesting problems
for classification. Our system CUISINE (Classification
UsIng Stylistic feature sets and/or NamE-based feature
sets) achieves accuracy results between 90.71 to 98.99%
for the seven classification experiments (ethnicity,
time, place, ethnicity&time, ethnicity&place, time&place,
ethnicity&time&place). For the first six tasks, the stylistic
feature sets in general and the quantitative feature set in
particular are enough for excellent classification results.
In contrast, the name-based feature sets are rather poor
for these tasks. However, for the most complex task
(ethnicity&time&place), a hill-climbing model using all
feature sets succeeds in significantly improving the clas-
sification results. Most of the stylistic features (34 of
42) are language-independent and domain-independent.
These features might be useful to the community at large,
at least for rather simple tasks.
Introduction
Text classification (TC) is an important component in
many research domains such as text clustering, text filtering,
text indexing, information extraction, information retrieval,
Received October 15, 2009; revised March 7, 2010; accepted March 8,
2010
© 2010 ASIS&T • Published online 22 April 2010 in Wiley InterScience
(www.interscience.wiley.com). DOI: 10.1002/asi.21350
text mining, and word sense disambiguation (Knight, 1999;
Pazienza, 1997).
TC means labeling text with one or more predefined cate-
gories. Classification according to categories is usually based
on content words and collocations (Collocation is the rela-
tionship between two words or groups of words that often go
together and form a common expression.) For instance, doc-
uments about sports are differentiated from documents about
politics by their content words and collocations. In contrast,
stylistic classification is usually based on various linguistic
features (e.g., Argamon et al., 2007; Koppel, Argamon, &
Shimony, 2002).
Current-day TC presents challenges due to the large num-
ber of features present in the text set, their dependencies, and
the large number of training documents. This article tackles
classification problems over a unique document collection:
Jewish legal responsa (answers written by rabbinic scholars
in response to Jewish legal questions). The unique character-
istics of this collection arise from the complex orthographical
and morphological nature of the Hebrew–Aramaic language
in which they are written, and from their narrow domain
and long history, having been written over a period of many
hundreds of years.
The research’s goal is to investigate the following clas-
sification tasks: (a) historical period when the responsa
were written (in the 20th century or in the 16th–19th cen-
turies), (b) Jewish ethnic groups of the authors—Sephardim
(Mediterranean) or Ashkenazim (Eastern or Central Europe),
and (c) place when the responsa were written (Israel or
elsewhere).
These classification tasks are important from the Orthodox
Jewish viewpoint since (a) according to Jewish ruling, there is
a greater importance and impact to older responsa; and (b) the
customs of each ethnic group or place are mainly dependent
JOURNAL OF THE AMERICAN SOCIETY FOR INFORMATION SCIENCE AND TECHNOLOGY, 61(8):1644–1657, 2010
on responsa that were written by authors who belong to the
same ethnic group or place.
Conclusions drawn from these tasks can help (a) to find
which feature set (or combinations of feature sets) are most
suitable for such tasks; (b) to generate results useful to
scholars in the humanities (i.e., identifying the differences
in writing style, culture, and customs between writers who
belong to different ethnic origin and/or historical period when
the responsa were written and/or place where the documents
were written; (c) to help identify undated documents or
unknown ethnic origin or place of writing; and (d) the stylis-
tic feature sets (especially the quantitative and topographic
feature sets, the vocabulary’s richness feature, and one func-
tion feature, which are language-independent and domain-
independent) can be applied to similar classification tasks for
other languages and can therefore be useful to the community
at large.
The various stylistic feature sets and name-based feature
sets that are used in this research extend that of previous
authors working in computational stylistics and authorship
attribution.
Research on classification of such documents also is
important because the (a) Semitic language processing in
general is of great interest today; (b) Hebrew and Aramaic
have been studied relatively little; (c) they are richer than
many languages in their morphological forms (Choueka,
Conley, & Dagan, 2000); and (d) Hebrew documents in gen-
eral and Jewish Law articles written in Hebrew–Aramaic in
particular include a relatively high incidence of abbreviations
(HaCohen-Kerner, Kass, & Peretz, 2004).
This article is organized as follows: First, we describe
Hebrew–Aramaic texts and their classification. Next, we
present stylistic feature sets used in related works and
feature-selection methods. The model is then described,
including the stylistic and the name-based feature sets
defined by us. Then, the results of the experiments are pre-
sented and discussed. We conclude with our proposed future
directions.
Hebrew–Aramaic Texts and Their Classification
Hebrew–Aramaic documents in general and Hebrew–
Aramaic responsa in particular are challenging for research.
First, Hebrew is richer in its morphology forms than is
English. Hebrew has 70,000,000 valid (inflected) forms
while English has only 1,000,000 (Choueka et al., 2000).
In Hebrew, there are up to 7,000 declensions for a single stem
while there are only a few declensions in English. Second,
these kinds of documents include a high rate of abbreviations
(∼20% of all the words in the documents) while more than
one third of them (∼8%) are ambiguous. There has been some
research on disambiguation of ambiguous Hebrew abbre-
viations (HaCohen-Kerner et al., 2004; HaCohen-Kerner,
Kass, & Peretz, 2008a; HaCohen-Kerner, Kass, & Peretz,
2008b). A comprehensive survey of Hebrew computational
linguistics can be found in Wintner (2004).
CHAT, a system for stylistic classification of Hebrew–
Aramaic texts (Koppel, Beck, Yehudai, & Mughaz, 2004,
Koppel, M., Mughaz, D., & Akiva, N. (2006).
Koppel, Mughaz, and Schler (2004), Koppel, Nughaz, and
Akiva (2006), and Mughaz (2003), present applications of
several TC tasks to Hebrew–Aramaic texts: (a) Which of a
set of known authors is the most likely author of a given
document of unknown provenance? (b) Were two given cor-
pora written/edited by the same author? (c) Which of a set of
documents preceded which, and did some influence others?
(d) From which version (i.e., manuscript) of a document is a
given fragment taken?
CHAT uses as features only single words, prefixes, and
suffixes. It uses simple Machine Learning (ML) methods such
as Winnow and Perceptron. Its datasets contain only a few
hundred documents. CHAT does not investigate the various
tasks proposed at the end of the Introduction.
Classification of Biblical documents without using any
ML method has been performed by Radai (1978, 1979, 1982).
In an earlier conference paper (HaCohen-Kerner, Beck,
Yehudai, & Mughaz, 2006), we addressed the identification
of historical period and/or ethnic origin of documents based
on stylistic feature sets using the Support Vector Machines
(SVM) ML method. The classification accuracy results of the
three examined classification tasks (ethnic origin, historical
period, ethnic origin and historical period) were 98.67, 98.95,
and 92.81%, respectively.
Identification of the ethnic group of the authors based on
word stems using the Artificial Neural Network (ANN) ML
method was carried out by HaCohen-Kerner, Boger, Beck,
and Yehudai (2007). The best ANN model led to an accuracy
classification result of 89.7%.
Stylistic Text Features Used in Related Works
Stylistic text features have been applied in various kinds
of applications, such as authorship attribution (Argamon-
Engelson, Koppel, & Avneri, 1998; Baayen, Van Halteren, &
Tweedie, 1996; de Vel, Anderson, Corney, & Mohay,
2001; Diederich, Kindermann, Leopold, & Paass, 2003;
Fung & Mangasarian, 2003; McEnery & Oakes, 2000;
Mosteller & Wallace, 1964; Novak, Raghavan, & Tomkins,
2004; Stamatatos, 2006, 2008; Stamatatos, Fakotakis, &
Kokkinakis, 2001), genre-based TC and retrieval (Finn,
Kushmerick, & Smyth, 2002; Hota, Argamon, & Chung,
2006; Karlgren & Cutting, 1994; Kessler, Nunberg, &
Schutze, 1997; Lim, Lee, & Kim, 2005; Schler, Koppel,
Argamon, & Pennebaker, 2006), sentiment analysis (Pang &
Lee, 2005; Pang, Lee, & Vaithyanathan, 2002; Snyder &
Barzilay, 2007; Turneys & Littman, 2002), and spam filter-
ing (Androutsopoulos, Koutsias, Chandrinos, Paliouras, &
Spyropoulos, 2000; Kushmerick, 1999; Patrick, 2004; Zhu &
Yao, 2004).
Stylistic Feature Sets
In this subsection, we present different feature sets that
have been used for stylistic research. Their strengths and
JOURNAL OF THE AMERICAN SOCIETY FOR INFORMATION SCIENCE AND TECHNOLOGY—August 2010 1645
DOI: 10.1002/asi
weaknesses regarding the discussed research will be eval-
uated. Relevant feature sets were selected to be applied for
the research at hand.
Quantitative features. These features present various sta-
tistical measures concerning a document, such as average
number of characters in a word/sentence/document and aver-
age number of word tokens in a sentence/document. Such
features were probably first proposed by Yule (1938). Quan-
titative features are relatively easy to compute and have the
advantage that they are general, domain-independent, and
language-independent. We therefore decided to use these in
our study.
Orthographic features. The orthography of a language
specifies the correct way of using a certain writing system
to write the language. Orthography consists of spelling, cap-
italization, word breaks, and punctuation marks. Friedman
(1996) used abbreviations, acronyms, and various spellings
of the same words as orthographic features. Some of these
features also are relatively easy to compute and have the
advantage that they are general, domain-independent, and
language-independent. Thus, they will be applied in our
research.
Parts of speech (POS) (or syntactic) features. POS are the
basic types of words that a language has. Most grammar
books state that there are eight parts of speech for English:
nouns, verbs, adjectives, adverbs, pronouns, conjunctions,
prepositions, and interjections. Various features deal with
POS information. Among them, we can find frequencies and
distribution of POS tags such as noun, verb, adjective, and
adverb; basic syntactic sequences such as noun–adjective
and subject–verb relations; and active and passive sentences.
POS counts (e.g., noun and adverb) were used by Karlgren
and Cutting (1994). Hota et al. (2006) used POS features for
determining the gender of Shakespeare’s literary characters.
Frequencies and distribution of POS tags also were proposed
by Baayen et al. (1996) and Stamatatos et al. (2001).
Unfortunately, no friendly POS tagger for Hebrew–
Aramaic was available to us. There are two online available
Hebrew taggers; however, these taggers are suitable for deal-
ing with Modern Hebrew texts, which are quite different from
responsa (rabbinic answers written in Hebrew–Aramaic),
which are our concern in this study. Therefore, theses features
will not be applied in the discussed research.
Web-oriented features. These features are related to Web
documents. They include URL tags (e.g., depth of URL, doc-
ument type, and domain area) and HTML tags (frequencies
of various types of links). These types of features were used
by Lim et al. (2005) for automatic genre classification of
Web documents. These features are not relevant to the doc-
uments at hand since they are not Web-oriented. Therefore,
the Web-oriented features will not be applied in our research.
Function (stop) words. These are words that have little lex-
ical meaning or have ambiguous meaning, but instead serve
to express grammatical relationships with other words within
a sentence or specify the attitude or mood of the speaker.
Function words contain, among other groups, articles (e.g.,
the, a), pronouns (e.g., he, him, she, her), particles (e.g., if,
then, well, however, thus), and conjunctions (e.g., for, and,
or, nor, but, yet, so), auxiliary verbs (be, have, shall, will,
may, and can). Function words were probably first proposed
by Mosteller and Wallace (1964). These features are usually
language-dependent. Furthermore, in Hebrew, many kinds of
function words are hard to identify since they are included
as prefixes and terminal letters in other words. Thus, these
features will be applied only partially in our research. In our
research, we decided to test two types of function features:
(a) various kinds of stop word features and (b) several specific
functions (e.g., pronouns).
Lexical (content) features. Words that are not function
words are called lexical (i.e., content) words. These words
include nouns, verbs, adjectives, and most adverbs. These
features are usually regarded as word unigrams, which are
included in the next feature set.
Lemma features. These are character n-grams and word
n-grams. Usually, Lemma features consist of features such
as unigrams, bigrams, and trigrams. Hota et al. (2006)
used word unigrams to cluster words that identify “typical”
female and male concerns in Shakespeare’s works. Peng,
Schuurmans, and Wang (2003) presented a method based
on character-level n-gram language models for language-
independent and task-independent text-classification learn-
ing. They presented results of experiments performed on
several languages—Greek, English, Chinese, and Japanese—
in several text-classification problems—language identifi-
cation, authorship attribution, text genre classification, and
topic detection. These features are domain-independent
and language-independent. However, the number of possible
features of this type is relatively high, so we decided to restrict
our investigation to types with a relatively small number of
features. Therefore, these features are left for future research.
Vocabulary richness features. These types of features try to
capture the richness or the diversity of the vocabulary of a
text. These features have been applied mainly to authorship
attribution research. The most popular feature of this cate-
gory is the type-token ratio V /N, where V is the size of the
vocabulary of the document, and N is the number of tokens
of the document. These features are highly text-length-
dependent and quite unstable for texts shorter than 1,000
words (Twedie & Baayen, 1998). The aforementioned feature
is easy to compute and has the advantage that it is gen-
eral, domain-independent, and language-independent. Thus,
it will be applied in our research.
1646 JOURNAL OF THE AMERICAN SOCIETY FOR INFORMATION SCIENCE AND TECHNOLOGY—August 2010
DOI: 10.1002/asi
Feature-Selection Methods
Unfortunately, the combinatorial nature of many subset
feature-selection problems prohibits solving them optimally
in most cases. Therefore, various feature-selection methods
have been formalized and applied for many classification
domains. Classical methods include greedily adding (forward
selection), removing features (backward selection), and var-
ious variants of hill climbing (e.g., stochastic hill climbing)
(Baluja, 1995; Mitchell, Holland, & Forrest, 1994).
More complex feature-selection methods have been pro-
posed by Weston et al. (2000) and Hamo and Markovitch
(2005). Weston et al. introduced various feature-selection
methods for SVMs. Their methods are based on minimiz-
ing generalization bounds via gradient descent. Hamo and
Markovitch introduced COMPSET, a general algorithm for
subset selection that invokes an existing local search algo-
rithm from a random subset and its complementary set,
exchanging information between the two runs to help identify
wrong moves.
The Model
The research described in this article is clearly developed
and expanded beyond the conference paper presented by us
in HaCohen-Kerner et al. (2006), as follows: (a) The back-
ground and the related researches in various subdomains
were enlarged significantly; (b) new feature sets (name-based
feature sets) have been defined and applied; (c) additional
classification experiments were applied to also identify places
where the responsa were written; (d) instead of applying
the five-fold cross-validation, we apply the 10-fold cross-
validation. The 10-fold cross-validation tends to give a less
biased estimate of true generalization error. It contains 10
experiments instead of five, and learning in each subexper-
iment is done for 90% of the documents instead of 80%;
(e) measures such as Precision, Recall, and F measure were
added; and (f) terms, analyses and conclusions were added,
explained, and detailed.
Methods already used in TC require adaptation to handle
Hebrew-Aramaic documents. Therefore, first, the definition
of suitable feature sets is required. Second, the proper combi-
nation of feature sets is needed to be investigated for a variety
of classification experiments.
Stylistic Feature Sets
We have defined six stylistic sets containing 42 base-
line stylistic features appropriate for Hebrew–Aramaic texts.
Many features are normalized by the number of words in a
document. Features regarding sentences have two versions
(relating or not relating to a comma as an end of a sentence).
The six stylistic sets are presented next:
1. Stopword features. This set includes four stop word fea-
tures: frequency of 958 religious stop words (e.g., bible,
responsa, rabbi); that is, the number of religious stop
words divided by the number of words in the document;
frequency of 533 general stop words (e.g., of, at, on,
no); frequency of both religious stop words and general
stop words; and frequency of 307 summarization words;
that is, words that are used when conclusions or sum-
maries appear (e.g., conclusion, to conclude, summary,
to sum up).
2. Orthographic features. This set includes two features: the
normalized number of acronyms in a sentence and the nor-
malized number of abbreviations in a sentence. In the cur-
rent research, the investigated documents are considered
as modern responsa, and the acronyms and abbreviations
were mostly written by the authors themselves.1
3. Topographic features. This set includes 17 features;
normalized frequency of each word from the follow-
ing groups: the first n (10, 20) word tokens, the last
n word tokens, the first n/2 word tokens and the last n/2
word tokens, the word tokens in the first n (2, 4) sentences,
the word tokens in the last n sentences, the word tokens
in the first n/2 sentences and the word tokens in the last
n/2 sentences, the word tokens in the first n (1, 2) para-
graphs, the word tokens in the last n paragraphs, and the
word tokens in the first n/2 paragraphs and the word tokens
in the last n/2 paragraphs.
4. Quantitative features. This set includes 15 features: aver-
age number of characters in a word/sentence/paragraph/
document; average number of word tokens in a sentence/
paragraph/document, average number of sentences in a
paragraph/document, average number of paragraphs in
a document; and average number of punctuation signs
(e.g., !. ?, :, ;) in a document. Note that punctuation signs
make sense only for such texts that have modern punctua-
tion. Premodern texts only had few punctuation signs, and
these were used sparsely. Such texts were possibly edited
by the original printers, and later by printers or editors
with the addition of punctuation. However, the texts inves-
tigated in this research are considered modern, and the
punctuation signs were written by the authors themselves.
5. Function features. This set includes three features: nor-
malized frequencies of sentences appeared in brackets
with/without relating to a comma as an end of a sentence
(divided by the number of sentences in the document)
and normalized frequency of 11 nonambiguous Hebrew
pronouns (divided by the number of word tokens in the
document).
6. Vocabulary’s richness. This set includes one feature: size
of author’s vocabulary in word tokens.
The quantitative, topographic, and vocabulary’s rich-
ness features and one function feature are domain-
independent and language-independent. The stop word and
the orthographic features and one function feature are
domain-dependent and language-dependent. All features
have been especially fitted to the Hebrew and Aramaic
languages. Dictionaries containing religious stop words,
general stop words, summarization words, abbreviations,
and acronyms have been built. Moreover, they have been
1Note that historically, acronyms and abbreviations depended on the type-
setters. If they agreed to publish a book for a given sum, and it was not high
enough to fully satisfy them, they would abbreviate wherever they could,
even mangling readability, to reduce the number of pages.
JOURNAL OF THE AMERICAN SOCIETY FOR INFORMATION SCIENCE AND TECHNOLOGY—August 2010 1647
DOI: 10.1002/asi
combined with various kinds of prepositions, belonging,
terminal letters, and so on.
Name-Based Feature Sets
Additional relevant feature sets for Hebrew–Aramaic
responsa are name-based feature sets. These sets contain var-
ious combinations of the names of rabbinic scholars, their
books, and their abbreviations integrated with topographic
features (e.g., first and last paragraphs in the document).
Such features are regarded as good content-based features
since they are used by human classifiers to distinguish
between different categories of responsa.
The history of Jewish responsa covers a period of the last
1,700 years. This period is divided into two main groups:
Rishonim and Acharonim. Rishonim ( ), literally “the
first” or “the former,” is a term referring to the leading Rabbis
and Poskim (Jewish legal decisors) who lived approximately
between the 13th and the 16th centuries.
Acharonim ( ), literally “the later ones,” is a term
referring to the leading rabbis living from roughly the
16th century to the present. The responsa investigated in
this research (detailed later) were authored by Acharonim:
Sephardi rabbis (Mediterranean) andAshkenazi rabbis (East-
ern or Central Europe) in the last 500 years (16th–20th
centuries).
The publication of the Shulchan Aruch (“Arranged Table”)
by a Sephardi Rabbi called RabbiYosef Caro (Maran) and the
HaMapa (“The Tablecloth”) by an Ashkenazi Rabbi called
Rabbi Moshe Isserlis (the Rama) in the 16th century mark
the beginning of the era of the Acharonim. The Rama’s
HaMapa was published together with the Shulchan Aruch,
and together they became the universally recognized Code of
Jewish Law.
Based on Brauner (1983), we have collected 1,127
names and abbreviations of all relevant Rishonim and Acha-
ronim and their responsa books. A total of 234 baseline
name-based features contained in six feature sets have been
defined (39 features for each set). These features belong to the
six sets presented in Table 1. Each set includes the full names
of the rabbis, their names’ abbreviations, and the titles of
famous books written by them and their abbreviations. Each
name-based feature depending on its specific topographic
nature computes a normalized frequency of its names.
TABLE 1. Name-based feature sets.
Titles of
Full names Abbreviations of books written Abbreviations of No. of items
Set Feature set (family) of rabbis rabbis’ names by rabbis rabbis’ books in set
1 Sephardi Rishonim (SR) 50 23 69 6 148
2 Ashkenazi Rishonim (AR) 67 36 73 16 192
3 Maran 1 1 5 3 10
4 Rama 1 2 6 3 12
5 Sephardi Achronim (SA) 50 16 77 100 243
6 Ashkenazi Achronim (AA) 140 51 285 46 522
No. of items for each category of names 309 129 515 174 1,127
Machine Learning Applied to TC
ML applied to TC is the ability of a computer to improve its
document-classification performance based on learning from
previous results of document classification. In many existent
systems, supervised learning is the type of learning that is
applied. Supervised learning means that all the documents in
a training set are assigned a class before the training process.
Then, the model has to assign the given documents to one or
more predefined categories (Meretakis & Wuthrich, 1999).
The availability of such powerful ML methods enables
researchers to deal with many features. For instance, Madigan
et al. (2005) used all the words that appear at least twice in
the corpus, Stamatatos (2006) uses the 1,000 most frequent
words, and Koppel, Mughaz, and Akiva (2006) used the 500
and 200 most frequent words.
A comprehensive summary of various ML methods used
for TC can be found in Sebastiani (2002). The SVM method
(Cortes & Vapnik, 1995; Vapnik, 1995) was chosen as the
machine learning method to be applied in this model since
it has been very successful in various TC applications (Díaz,
Ranilla, Montañés, Fernández, & Combarro, 2004; Dumais,
Platt, Heckerman, & Sahami, 1998; Joachims, 1998, 2002;
Yang & Liu, 1999). There are various variants of SVMs. One
simple and fast method is Sequential Minimal Optimization
(SMO), developed by Platt (1999). In this setting, multiclass
problems are solved using pairwise classification.
Hill-Climbing Applied to TC Using Feature Sets
The measure of accuracy in all experiments is the frac-
tion of the number of documents correctly classified to the
total number of possible documents to be classified. To find
the best combination of sets for any particular classification
task, one should try all possible combinations of sets. One of
the known properties of the binomial coefficients is that the
total number of distinct k-subsets on a set of n elements (i.e.,
the number of possible subsets) is
∑n
k=0
(
n
k
)
= 2n, where a
k-subset is a subset of a set of n elements containing exactly
k elements.
To overcome this combinatorial explosion for non-small
values of n, the following hill-climbing model is proposed, as
follows: There is an attempt to improve a certain classification
by a series of additions of feature sets, using a hill-climbing
1648 JOURNAL OF THE AMERICAN SOCIETY FOR INFORMATION SCIENCE AND TECHNOLOGY—August 2010
DOI: 10.1002/asi
For each experiment (a certain classification)
     For each one of the following three groups of feature sets (stylistic, name -based, both)
          Combination of feature sets = { } 
  Iterate a hill-climbing classification process until no further improvement occurs
Select the feature set that when added to the combination of feature sets 
contributes the most to the discussed classification by using
a 10-fold cross-validation while training a SVM classifier
  Output the best combination of feature sets  so far and its classification rate 
FIG. 1. General algorithm of the proposed model.
search, while improving the classification accuracy at each
step; that is, on the first stage, each feature set is tested,
independently. The best feature set, in terms of accuracy clas-
sification rate, is selected among n possible feature sets. On
the second stage, all possible combinations of two feature sets
(where one of them is the set chosen on the previous stage)
are tested. That is, (n − 1) possible feature sets are checked
in the second step. If the best combination of two feature sets
is better than the best single feature set, then the process will
be continued. This process proceeds step-by-step, until no
further improvement is achieved.
Such a hill-climbing model tests a maximal number
of n + (n − 1) + . . .+1 = ∑1k=n k = n(n+1)2 combinations of
feature sets; that is, the complexity of this heuristic model
is O(n2) instead of O(2n). In this research, there are six
stylistic feature sets and six name-based feature sets (i.e.,
n = 12). Therefore, it is sufficient to check at most 78 combi-
nations instead of 4,096 combinations (including the empty
set). In addition, it takes many hours to build SVM models
for so many combinations and to run various classification
experiments for each combination.
Investigating whether the accuracy can be improved if
the feature-selection process will be applied to every single
feature is left for future research.
The Model
The general algorithm of the model is described in
Figure 1. This algorithm is based on the experimental
procedure proposed by Forman (2003).
Results
The examined dataset is a collection of 10,504 responsa
authored by 60 Jewish rabbinic scholars, with about 175 doc-
uments for each scholar. The documents were taken from a
widespread variety of domains relevant to Jewish life (e.g.,
laws, holidays, customs, kosher food, economics, and army).
The documents were downloaded from The Global Jewish
Database (The Responsa Project2) at Bar-Ilan University.
These documents were written in the 16th to 20th centuries.
The total number of word tokens in the dataset is about 18.5
2http://www.biu.ac.il/ICJI/Responsa
million word tokens while a document contains on average
about 1,763 word tokens.
These responsa can be classified into seven different
classifications: (a) ethnic Jewish groups (Sephardim or
Ashkenazim) of their authors, (b (periods of time when
they were written (in the 20th century or in the 16th–
19th centuries), (c) places where they were written (Israel
or elsewhere), (d) ethnicity&time, (e) ethnicity&place,
(f) time&place, and (g) ethnicity&time&place.
The responsa were collected in such a way that for each
classification, the dataset can be divided into equal-sized suit-
able sets. In other words, for each experiment, the number of
documents in the positive and in the negative sets is the same.
The measure of accuracy used in all experiments is the ratio
of the number of documents correctly classified. To test the
accuracy of the model, the 10-fold cross-validation was used.
The SVM applied version was the SMO implementation of
Weka (Witten & Frank, 2009) using a linear kernel and default
values. Model tuning is left for future research.
Experiments With Stylistic Feature Sets
All seven experiments have been applied, one for each
possible classification. Table 2 presents the main results (in
percents) of these seven experiments using the stylistic fea-
ture sets only. Figure 2 shows the rate of improvement (from
the best set alone to the best combination of sets) as a function
of the seven experiments for the stylistic feature sets.
Several general conclusions can be drawn from Table 2
and Figure 2:
• The quantitative set (Set 4) was superior to all others. Several
possible explanations of this finding are that this set includes
the largest number of features (n = 14), and moreover, these
features include widespread information about the whole doc-
ument. However, the accuracy classification results improved
significantly in the more complex experiments (i.e., the last
two) by using additional feature sets.
• The stopword (Set 1) and function (Set 5) sets achieve reason-
able results, which are better than those of the rest of the sets
(except the quantitative set). Moreover, these sets are always
part of the best combination of sets.
• The orthographic (Set 2), topographic (Set 3), and the vocabu-
lary richness (Set 6) sets yielded rather poor results, especially
the last one.
JOURNAL OF THE AMERICAN SOCIETY FOR INFORMATION SCIENCE AND TECHNOLOGY—August 2010 1649
DOI: 10.1002/asi
TABLE 2. Classification results using stylistic feature sets.
Classification by each stylistic set alone
Classification by
No. of Kind of 1 2 3 4 5 6 the best combination SD/Precision/Recall/
experiment classification Stop Ort Top Qua Fun Voc of sets F -measure
1 ethnicity 81.79 57.69 58.18 97.97 74.28 49.76 {1,2,3,4,5,6} 0.3/0.998/ 0.975/0.987
98.67
2 time 83.60 58.61 62.25 96.94 80.05 53.97 {1,2,3,4,5,6} 0.15/0.997/ 0.982/0.989
98.95
3 place 76.85 56.28 54.33 92.90 77.85 56.10 {1,2,4,5} 0.64/0.992/ 0.97/0.98
97.92
4 ethnicity&time 62.83 41.92 38.13 86.33 57.04 28.8 {1,2,3,4,5} 0.43/1/ 0.99/0.99
92.81
5 ethnicity&place 56.20 34.07 31.05 84.33 49.83 32.27 {1,2,3,4,5,6} 0.43/0.99/ 0.99/0.99
90.43
6 time&place 57.86 32.57 36.20 81.76 53.35 30.45 {1,2,3,4,5} 0.82/0.99/ 0.99/0.99
90.65
7 ethnicity&time&place 39.74 25.89 23.67 66.99 43.88 18.28 {1,2,3,4,5} 0.45/1/ 0.997/1
80.93
Stop = stopword set; Ort = orthographic set; Top = topographic set; Qua = quantitative set; Fun = function set; Voc = vocabulary richness set.
0.00
2.00
4.00
6.00
8.00
10.00
12.00
14.00
16.00
et ti pl et&ti et&pl pl&ti et&ti&pl
kind of classification
ra
te
 o
f 
im
p
ro
ve
m
en
t
FIG. 2. Rate of improvement as a function of the seven experiments for the stylistic feature sets.
• In three of seven experiments, the best results were achieved
by a combination of all feature sets. In three other experi-
ments, the best results were achieved by a combination of
five feature sets.
• The improvement rate (from the best set alone to the best
combination of sets) varies from 1% (Experiment 1) to 14%
(Experiment 7).
• The more complex the task, the lower classification results
achieved.
• The more complex the classification task, the higher rate of
improvement in the hill-climbing process achieved.
• The low values of the standard deviations indicate that the
classification results are stable.
• The Precision, Recall, and F-measure results were almost
optimal and also indicate that all seven classification tasks
were highly successful.
• Relatively small error rates have been found in these experi-
ments, although the following facts—(a) Some Sephardi and
Ashkenazi rabbis were active in modern Israel, and their
articles were influenced by the prevalent nonethnic Hebrew
writing; and (b) some rabbis were active both in the 19th and
20th centuries.
Experiments With Name-Based Feature Sets
Table 3 presents the main results of the seven experiments
using the name-based feature sets only. Figure 3 shows the
rate of improvement (from the best set alone to the best com-
bination of sets) as a function of the seven experiments for
the name-based feature sets.
The general conclusions that can be drawn from Table 3
and Figure 3 are:
• All seven classification tasks using name-based feature sets
achieved rather poor results compared to the results achieved
by the stylistic feature sets.
• The Acharonim Ashkenazim set (Set AA) was superior to all
other sets. This set includes 522 items (the largest name-
based feature set in Table 1). The second-best set was Set SA
1650 JOURNAL OF THE AMERICAN SOCIETY FOR INFORMATION SCIENCE AND TECHNOLOGY—August 2010
DOI: 10.1002/asi
TABLE 3. Classification results using name-based feature sets.
Classification by each name-based set alone Classification
by the best
No. of Kind of 1 2 3 4 5 6 combination SD/Precision/
experiment classification SR AR Maran Rama SA AA of sets Recall/F -measure
1 ethnicity 57.66 52.23 50.96 51.25 59.73 67.03 {1,2,3,5,6} 72.71 0.86/0.86/0.54/0.66
2 time 53.86 52.71 51.32 51.50 57.18 60.58 {1,2,3,4,5,6} 68.66 0.68/0.62/0.96/0.75
3 place 53.32 51.90 51.90 52.79 56.54 63.66 {1,2,3,4,5,6} 68.58 1.19/0.64/0.86/0.73
4 ethnicity&time 32.98 28.97 27.12 26.98 36.38 44.52 {1,2,3,4,5,6} 53.71 0.87/0.56/0.45/0.5
5 ethnicity&place 32.60 28.45 27.23 27.90 35.58 46.53 {1,2,3,4,5,6} 56.11 1.16/0.81/0.68/0.74
6 time&place 30.52 28.26 27.82 27.56 34.46 41.93 {1,2,3,4,5,6} 53.16 0.42/0.57/0.49/0.53
7 ethnicity&time&paace 20.45 16.04 15.51 15.50 23.38 34.00 {1,2,3,4,5,6} 46.24 1.56/0.34/0.3/0.32
SR = Sephardi Rishonim; AR = Ashkenazi Rishonim; SA = Sephardi Achronim; AA = Ashkenazi Achronim.
0.00
2.00
4.00
6.00
8.00
10.00
12.00
14.00
et ti pl et&ti et&pl pl&ti et&ti&pl
kind of classification
ra
te
 o
f 
im
p
ro
ve
m
en
t
FIG. 3. Rate of improvement as a function of the seven experiments for the name-based feature sets.
(Sephardi Achronim), which contains 243 items (the second-
largest name-based feature set in Table 1). These findings can
be explained by the rule that “more relevant knowledge” leads
to better results, in terms of accuracy classification rate.
• The two worst sets, in terms of accuracy classification rate,
were the Maran and Rama groups. A possible explanation
for this finding is that these groups are based on less knowl-
edge (i.e., fewer names, books, and abbreviations) than the
knowledge included in the other sets.
• In six of seven experiments, the best results were achieved by
a combination of all feature sets.
• The improvement rate (from the best set alone to the best
combination of sets) varies from 5% (Experiment 3) to 12%
(Experiment 7).
• The more complex the task, the lower classification results
achieved.
• The more complex the classification task, the higher rate of
improvement in the hill-climbing process achieved.
• The low values of the standard deviations indicate that the
classification results are stable.
• The Precision, Recall, and F-measure results were almost
optimal and also indicate that all seven classification tasks
were highly successful.
Experiments With Both Stylistic and Name-Based
Feature Sets
Tables 4 to 10 present all the results of the hill-climbing
processes using all 12 feature sets (six stylistic feature
sets and six name-based feature sets) when applied for
all seven classifications. As explained earlier, using this
hill-climbing method in each experiment, we checked only
78 combinations of different feature sets instead of 4,096
combinations.
The first row in Table 4 presents the results of the classifi-
cation according to ethnic group using only one feature set.
The best result was achieved by the quantitative set (Set 4).
The second row presents all results of the second step of the
hill-climbing process (i.e., the results of all possible combi-
nations of two sets where one of them is Set 4 are presented).
The best combination (Sets 4 and 5) is chosen as a basis
for the next step, and so on. This hill-climbing process ends
when no improvement occurred. Nonrelevant cells for the
hill-climbing process are in gray.
The general conclusions that can be drawn from
Table 4 are:
1. This classification task was highly successful.
2. The quantitative set (Set 4) was superior to all other sets,
and it was enough for a very successful classification. In
other words, except for the quantitative set, in general
all stylistic feature sets and in particular all name-based
feature sets are almost useless for the classification task.
3. The best combination {1,2,3,4,5,11,12} is composed of 7
sets of 12 total.
4. The first three chosen sets belong to the stylistic feature
sets.
JOURNAL OF THE AMERICAN SOCIETY FOR INFORMATION SCIENCE AND TECHNOLOGY—August 2010 1651
DOI: 10.1002/asi
TABLE 4. Classification according to ethnicity using all feature sets.
Stylistic feature sets Name-based feature sets
1 2 3 4 5 6 7 8 9 10 11 12
Best combination of sets Stop Ort Top Qua Fun Voc SR AR Maran Rama SA AA
{4} 81.79 57.69 58.18 97.97 74.28 49.76 57.66 52.23 50.96 51.25 59.73 67.03
{4,5} 98.07 97.94 98.01 98.28 97.96 97.93 97.94 97.93 97.91 98.12 97.67
{1,4,5} 98.51 98.38 98.34 98.30 98.39 98.26 98.28 98.28 98.42 98.31
{1,4,5,11} 98.53 98.54 98.50 98.58 98.49 98.48 98.45 98.63 98.59
{1,4,5,11,12} 98.67 98.69 98.57 98.76 98.66 98.63 98.61 98.87
{1,2,4,5,11,12} 98.90 98.86 98.87 98.84 98.82 98.85 98.82
{1,2,3,4,5,11,12} 98.99 98.89 98.90 98.81 98.91 98.88
{1,2,3,4,5,11,12} 98.93 98.90 98.90 98.98 98.97
Best result 98.99
SD/Precision/Recall/F-measure 0.23/0.99/0.98/0.99
Stop = stopword set; Ort = orthographic set; Top = topographic set; Qua = quantitative set; Fun = function set; Voc = vocabulary richness set.
SR = Sephardi Rishonim; AR = Ashkenazi Rishonim; SA = Sephardi Achronim; AA = Ashkenazi Achronim.
TABLE 5. Classification according to time using all feature sets.
Stylistic feature sets Name-based feature sets
1 2 3 4 5 6 7 8 9 10 11 12
Best combination of sets Stop Ort Top Qua Fun Voc SR AR Maran Rama SA AA
{4} 83.60 58.60 62.25 96.94 80.05 53.97 53.86 52.71 51.32 51.5 57.18 60.58
{1,4} 98.11 97.16 97.49 98.09 97.18 97.07 96.93 97.00 97.05 97.05 97.18
{1,4,5} 98.11 98.23 98.79 98.17 98.15 98.07 98.10 98.13 98.19 98.28
{1,3,4,5} 98.86 98.90 98.82 98.80 98.82 98.81 98.8 98.81 98.73
{1,2,3,4,5} 98.94 98.91 98.91 98.92 98.87 98.90 98.87 98.78
{1,2,3,4,5,6} 98.95 98.95 98.94 98.90 98.91 98.90 98.91
{1,2,3,4,5,6,7} 98.96 98.94 98.90 98.92 98.89 98.89
{1,2,3,4,5,6,7} 98.88 98.90 98.90 98.90 98.87
Best result 98.96
SD/Precision/Recall/F-measure 0.34/0.99/0.98/0.99
Stop = stopword set; Ort = orthographic set; Top = topographic set; Qua = quantitative set; Fun = function set; Voc = vocabulary richness set.
SR = Sephardi Rishonim; AR = Ashkenazi Rishonim; SA = Sephardi Achronim; AA = Ashkenazi Achronim.
TABLE 6. Classification according to place using all feature sets.
Stylistic feature sets Name-based feature sets
1 2 3 4 5 6 7 8 9 10 11 12
Best combination of sets Stop Ort Top Qua Fun Voc SR AR Maran Rama SA AA
{4} 76.85 56.28 54.33 92.90 77.85 56.10 53.52 53.88 51.90 52.79 56.54 63.66
{4,5} 94.87 96.25 92.96 97.37 92.92 93.24 92.84 92.92 93.24 93.08 95.06
{4,5,12} 97.58 97.63 97.40 97.38 97.61 97.41 97.38 97.38 97.28 97.76
{2,4,5,12} 97.83 97.92 97.78 97.78 97.78 97.74 97.74 97.72 97.68
{2,4,5,10,12} 98.16 97.93 97.90 97.98 97.87 97.95 97.98 97.85
{1,2,4,5,10,12} 98.22 97.96 97.99 97.97 97.93 98.01 97.92
{1,2,4,5,6,10,12} 98.24 98.27 98.19 98.19 98.20 98.21
{1,2,4,5,6,10,12} 98.23 98.23 98.26 98.27 98.19
Best result 98.27
SD/Precision/Recall/F-measure 0.26/0.99/0.97/0.98
Stop = stopword set; Ort = orthographic set; Top = topographic set; Qua = quantitative set; Fun = function set; Voc = vocabulary richness set.
SR = Sephardi Rishonim; AR = Ashkenazi Rishonim; SA = Sephardi Achronim; AA = Ashkenazi Achronim.
1652 JOURNAL OF THE AMERICAN SOCIETY FOR INFORMATION SCIENCE AND TECHNOLOGY—August 2010
DOI: 10.1002/asi
TABLE 7. Classification according to ethnicity&time using all feature sets.
Stylistic feature sets Name-based feature sets
1 2 3 4 5 6 7 8 9 10 11 12
Best combination of sets Stop Ort Top Qua Fun Voc SR AR Maran Rama SA AA
{4} 62.83 41.92 38.13 86.33 57.04 28.80 32.98 28.97 27.12 26.98 36.38 44.52
{4,5} 89.25 87.93 87.74 89.47 86.70 87.86 86.39 86.61 87.07 87.01 87.74
{1,4,5} 91.99 90.54 90.70 89.41 90.07 89.27 89.66 89.65 89.90 90.33
{1,3,4,5} 92.14 92.69 91.95 92.22 91.99 92.09 92.00 91.94 92.52
{1,3,4,5,12} 92.81 92.56 92.92 92.67 92.74 92.68 92.38 93.09
{1,2,3,4,5,12} 93.47 93.35 93.31 93.07 93.23 93.32 93.37
{1,2,3,4,5,11,12} 93.59 93.61 93.50 93.55 93.62 93.81
{1,2,3,4,5,9,11,12} 93.87 93.81 93.63 93.94 93.75
{1,2,3,4,5,6,9,11,12} 94.08 93.95 93.72 93.89
{1,2,3,4,5,6,9,11,12} 94.01 93.93 93.97
Best result 94.08
SD/Precision/Recall/F-measure 0.49/1/0.99/0.99
Stop = stopword set; Ort = orthographic set; Top = topographic set; Qua = quantitative set; Fun = function set; Voc = vocabulary richness set.
SR = Sephardi Rishonim; AR = Ashkenazi Rishonim; SA = Sephardi Achronim; AA = Ashkenazi Achronim.
TABLE 8. Classification according to ethnicity&place using all feature sets.
Stylistic feature sets Name-based feature sets
1 2 3 4 5 6 7 8 9 10 11 12
Best combination of sets Stop Ort Top Qua Fun Voc SR AR Maran Rama SA AA
{4} 56.20 34.07 31.05 84.33 49.83 32.27 32.60 28.45 27.23 27.90 35.58 46.53
{1,4} 86.39 85.72 85.27 86.12 85.08 84.82 84.20 84.52 84.48 84.68 84.94
{1,4,5} 87.73 87.61 88.04 87.34 86.33 86.48 86.46 86.39 87.21 86.96
{1,2,4,5} 89.45 89.01 89.05 88.22 87.99 88.24 88.04 88.72 88.49
{1,2,3,4,5} 90.21 89.93 89.32 89.49 89.52 89.20 89.96 89.59
{1,2,3,4,5,11} 90.43 90.32 90.24 90.18 89.98 90.86 90.28
{1,2,3,4,5,8,11} 91.09 91.07 91.17 90.99 90.97 91.16
{1,2,3,4,5,7,8,11} 91.29 91.38 91.17 91.07 91.16
{1,2,3,4,5,6,7,8,11} 91.46 91.19 91.17 91.24
{1,2,3,4,5,6,7,8,11,12} 91.29 91.38 91.58
{1,2,3,4,5,6,7,8,11,12} 91.49 91.38
Best result 91.58
SD/Precision/Recall/F-measure 0.4/0.99/0.99/0.99
Stop = stopword set; Ort = orthographic set; Top = topographic set; Qua = quantitative set; Fun = function set; Voc = vocabulary richness set.
SR = Sephardi Rishonim; AR = Ashkenazi Rishonim; SA = Sephardi Achronim; AA = Ashkenazi Achronim.
TABLE 9. Classification according to time&place using all feature sets.
Stylistic feature sets Name-based feature sets
1 2 3 4 5 6 7 8 9 10 11 12
Best combination of sets Stop Ort Top Qua Fun Voc SR AR Maran Rama SA AA
{4} 57.86 32.57 36.20 81.76 53.35 30.45 30.52 28.26 27.82 27.56 34.46 41.93
{4,12} 86.79 82.52 84.56 84.22 82.30 84.12 82.07 82.03 82.43 85.33 89.78
{1,4,12} 91.21 90.18 90.63 90.59 89.78 90.23 89.59 89.89 89.83 90.62
{1,3,4,12} 91.41 92.08 91.68 91.13 91.44 91.16 91.31 91.17 91.96
{1,3,4,5,12} 92.36 92.63 92.10 92.36 91.96 92.11 92.03 92.54
{1,3,4,5,11,12} 92.90 92.71 92.98 92.66 92.80 92.65 93.31
{1,3,4,5,7,11,12} 93.45 93.29 93.89 93.15 93.34 93.58
{1,3,4,5,7,10,11,12} 93.90 93.77 93.81 93.81 93.95
{1,2,3,4,5,7,10,11,12} 94.00 93.98 93.94 93.95
{1,2,3,4,5,7,8,10,11,12} 93.99 94.08 94.05
{1,2,3,4,5,7,8,10,11,12} 93.95 93.99
Best result 94.08
SD/Precision/Recall/F-measure 0.24/0.99/0.99/0.99
Stop = stopword set; Ort = orthographic set; Top = topographic set; Qua = quantitative set; Fun = function set; Voc = vocabulary richness set.
SR = Sephardi Rishonim; AR = Ashkenazi Rishonim; SA = Sephardi Achronim; AA = Ashkenazi Achronim.
JOURNAL OF THE AMERICAN SOCIETY FOR INFORMATION SCIENCE AND TECHNOLOGY—August 2010 1653
DOI: 10.1002/asi
TABLE 10. Classification according to ethnicity&time&place using all feature sets.
Stylistic feature sets Name-based feature sets
1 2 3 4 5 6 7 8 9 10 11 12
Best combination of sets Stop Ort Top Qua Fun Voc SR AR Maran Rama SA AA
{4} 39.74 25.89 23.67 66.99 43.38 18.28 20.45 16.04 15.51 15.50 23.38 34.00
{4,12} 71.35 69.74 70.39 73.60 68.20 70.95 67.42 67.40 68.22 70.24 78.46
{4,5,12} 80.95 79.61 80.88 83.43 79.25 80.26 78.64 78.76 79.05 80.90
{1,4,5,12} 85.98 84.55 85.22 83.96 85.42 83.42 83.55 83.71 85.05
{1,4,5,7,12} 87.03 87.13 86.25 87.82 86.09 86.21 86.24 87.27
{1,4,5,7,11,12} 88.62 88.21 87.88 87.63 87.87 87.73 88.96
{1,2,4,5,7,11,12} 89.73 89.41 89.14 88.78 89.13 89.19
{1,2,3,4,5,7,11,12} 90.25 89.91 89.72 89.79 89.95
{1,2,3,4,5,7,10,11,12} 90.31 90.19 90.27 90.54
{1,2,3,4,5,6,7,10,11,12} 90.71 90.43 90.51
{1,2,3,4,5,6,7,10,11,12} 90.63 90.69
Best result 90.71
SD/Precision/Recall/F-measure 0.42/1/1/1
Stop = stopword set; Ort = orthographic set; Top = topographic set; Qua = quantitative set; Fun = function set; Voc = vocabulary richness set.
SR = Sephardi Rishonim; AR = Ashkenazi Rishonim; SA = Sephardi Achronim; AA = Ashkenazi Achronim.
0.00
5.00
10.00
15.00
20.00
25.00
et ti pl et&ti et&pl pl&ti et&ti&pl
kind of classification
ra
te
 o
f 
im
p
ro
ve
m
en
t
FIG. 4. Rate of improvement as a function of the seven experiments for the stylistic and name-based feature sets.
5. Five stylistic feature sets and only two name-based fea-
ture sets are included in the best combination. That is, the
stylistic feature sets have been found to be better than were
the name-based feature sets for the task under discussion.
6. Only the last two name-based feature sets are selected.
This is not surprising since these are the largest name-
based feature sets (Table 1) and achieve the best results in
Table 3.
7. The improvement rate (from the best set alone to the best
combination of sets) is 1% since Set 4 achieves an excel-
lent result by itself for a task that is considered to be rather
simple.
8. The low values of the standard deviations indicate that the
classification results are stable. The Precision, Recall, and
F-measure results were almost optimal and also indicate
that all three classification tasks were highly successful.
Tables 5 to 10 present the results of rest six classifications
using all feature sets. Conclusions that can be drawn from
Tables 4 to 10 will be presented after Table 10.
Figure 4 shows the rate of improvement (from the best
set alone to the best combination of sets) as a function of
the seven experiments for the stylistic and the name-based
feature sets.
Figure 5 presents a histogram describing the number of
the chosen sets and their type (stylistic or name-based) that
are included in the best combination of sets as a function of the
seven experiments for both the stylistic and the name-based
sets.
General conclusions that can be drawn from Tables 4 to
10 and Figures 4 to 5 are:
• All classifications were highly successful.
• The quantitative set (Set 4) was always superior to all other
11 sets.
• The more complex the classification task, the less successful
the classification results we achieved.
• The more complex the classification task, the higher the rate
of improvement in the hill-climbing process achieved. That
1654 JOURNAL OF THE AMERICAN SOCIETY FOR INFORMATION SCIENCE AND TECHNOLOGY—August 2010
DOI: 10.1002/asi
0
1
2
3
4
5
6
# of stylistic sets 5 6 5 6 6 5 6
# of name-based sets 2 1 2 3 4 5 4
et ti pl et&ti et&pl pl&ti et&ti&pl
FIG. 5. Number of the chosen sets and their type included in the best combination of sets as a function of the seven experiments for both the stylistic and
name-based feature sets.
is, the improvement rate (from the best set alone to the best
combination of sets) varies from 1, 2, and 5% (Experiments
1, 2, 3, respectively), via 8, 8, and 12% (Experiments 4, 5, 6,
respectively), to 24% (Experiment 7).
• The number of sets in the best combination varies from seven
(Experiments 1, 2, and 3) to 10 (Experiments 5, 6, and 7) of
12 possible sets.
• In all experiments, the best combination includes at least five
stylistic feature sets and between one to five (usually between
two to four) name-based feature sets.
• The contribution of the name-based feature sets becomes
meaningful in the last experiment (ethnicity&time&place).
The accuracy classification rate improved from 66.99%
achieved by the quantitative feature set, via 80.93% achieved
by a hill-climbing process using only stylistic feature sets,
(Table 2) to 90.71% achieved by a hill-climbing process using
all feature sets. That is, the name-based feature sets present a
significant contribution (10%).
• Also note that the second chosen feature set in the last exper-
iment was a name-based feature set (Set 12), the Ashkenazi
Acharonim set (AA). This set was superior to all other name-
based feature sets as shown in Table 3. Although there are two
stylistic feature sets (Sets 1 and 5) that yielded better results
than this set on the first step of the algorithm, Set 12 was
found to contribute more to the quantitative set. This finding
can be explained by the fact that Set 12 belongs to another
kind of feature set. It might be that there is a larger interaction
between Set 4 and Sets 1 and 5 than the interaction between
Sets 4 and 12.
• The low values of the standard deviations indicate that the
classification results are stable.
• The Precision, Recall, and F-measure results were almost
optimal and also indicate that all seven classification tasks
were highly successful.
Conclusions 2 and 6 support the finding that the six
stylistic feature sets (containing only 42 features) are bet-
ter than the six name-based feature sets (containing 234
features) for the investigated classification tasks. Possible
explanations for this finding might be that (a) the stylistic
feature sets are based on much more knowledge included in
the text while the name-based feature sets are based on only a
relatively small dataset containing a few hundreds names; and
(b) the name-based feature sets might be improved by tak-
ing into account the kinds of sentences (e.g., summarization,
examples, beginning of the document, end of the document)
in which they are included.
Conclusions and Future Work
In this research, we presented CUISINE, which extends
and improves the system presented in HaCohen-Kerner et al.
(2006) by: (a) new feature sets (name-based feature sets);
(b) new applications such as places where the responsa
were written and a total of seven different experiments
instead of three, and (c) better results: CUISINE achieved
accuracy results of 98.99, 94.08, and 90.71% for the fol-
lowing classification experiments: ethnicity, ethnicity&time,
and ethnicity&time&place, respectively, compared to those
achieved by the previous system: 98.67 and 92.81% for
ethnicity and ethnicity&time, respectively.
We presented a hill-climbing model that uses stylistic fea-
ture sets and name-based feature sets for classification of
Jewish responsa written in Hebrew–Aramaic. The experi-
ments showed that this model improves the results obtained
in various classification tasks. Although there are many more
name-based features than the stylistic features (234 vs. 42),
the stylistic feature sets have been found to be better for the
investigated classification tasks. The name-based feature sets
present a significant contribution (10%) only in a relatively
complex classification task (Experiment 7).
In contrast to the name-based feature sets that are
language-dependent and domain-dependent, most of the
stylistic features (34 of 42) proposed in this research (15
quantitative features, 17 topographic features, 1 vocabulary’s
richness features, and 1 function feature) are language-
independent and domain-independent. In all classification
tasks, the quantitative feature set was superior to all other sets.
Moreover, in most experiments, this set sufficed for excellent
classification results.
JOURNAL OF THE AMERICAN SOCIETY FOR INFORMATION SCIENCE AND TECHNOLOGY—August 2010 1655
DOI: 10.1002/asi
It will be interesting to apply all stylistic feature sets,
only the language-independent and domain-independent fea-
tures, and the quantitative features to similar classification
tasks in other domains and/or other languages. The language-
independent and domain-independent features might be use-
ful to the community at large, at least for rather simple
tasks.
Future research also should include application of a variety
of additional language-independent and domain-independent
features, such as lemma features (e.g., character n-grams,
word n-grams including the most frequent words, etc.) and
additional specific-function features (e.g., particles, conjunc-
tions, and auxiliary verbs), and to test their effectiveness in
the tasks at hand and in additional tasks in other domains and
languages.
Some of the language-dependent and domain-dependent
features that have been applied in this research can be
developed with reasonable efforts for other domains and
languages. Such features are stop word features (e.g., stop
words and summarization words) and the function feature
“normalized frequency of pronouns.”
There are many additional potential research directions
concerning feature sets: (a) Which feature sets are good for
which classification tasks? (b) What are the specific reasons
for sets to perform better or worse on different classifica-
tion tasks? (c) What are the guidelines for selection of the
correct sets for a certain classification task? (d) The name-
based feature sets can be improved by taking into account
the kinds of sentences (e.g., summarization, examples, begin-
ning of the document, end of the document) in which they are
included?
Other general research proposals are investigating whether
the accuracy can be improved if the feature-selection process
is applied to every single feature, investigating other features
and other ML methods that might improve classification, and
tuning the model’s parameters.
References
Androutsopoulos, I., Koutsias, J., Chandrinos, K., Paliouras, G., &
Spyropoulos, C. (2000). An evaluation of naive bayesian anti-spam fil-
tering. In Proceedings of the 11th European Conference on Machine
Learning in the New Information Age (ECML 2000) (pp. 9–17). Berlin,
Germany: Springer.
Argamon, S., Whitelaw, C., Chase, P., Hota, S.R., Garg, N., & Levitan, S.
(2007). Stylistic text classification using functional lexical features:
Research articles. Journal of the American Society for Information
Science and Technology, 58(6), 802–822.
Argamon-Engelson, S., Koppel, M., & Avneri, G. (1998). Style-based text
categorization:What newspaper am I reading? In Proceedings of theAAAI
Workshop on Learning for Text Categorization (pp. 1–4). Menlo Park, CA:
AAAI Press.
Baayen, R.H., Van Halteren, H., & Tweedie, F. (1996). Outside the cave of
shadows: Using syntactic annotation to enhance authorship attribution.
Literary and Linguistic Computing, 11(3), 121–131.
Baluja, S. (1995). An empirical comparison of seven iterative and evolution-
ary function optimization heuristics (Tech. Rep. No. CMU-CS-95–193).
Carnegie Mellon University, School of Computer Science, Pittsburgh, PA.
Brauner, A. (1983). Practical guide for the history of Geonim, Rishonim
and Acharonim (2nd ed.) [in Hebrew]. Jerusalem: No information about
publishers.
Choueka, Y., Conley, E.S., & Dagan, I. (2000). A comprehensive bilingual
word alignment system: Application to disparate languages—Hebrew,
English. In J. Veronis (Ed.), Parallel text processing (pp. 69–96). London:
Kluwer.
Cortes, C., & Vapnik, V. (1995). Support-vector networks. Machine Learn-
ing, 20, 273–297.
de Vel, O., Anderson, A., Corney, M., & Mohay, G.M. (2001). Mining
e-mail content for author identification forensics. SIGMOD Record, 30(4),
55–64.
Díaz, I., Ranilla, J., Montañés, E., Fernández, J., & Combarro, E.F. (2004).
Improving performance of text categorization by combining filtering, sup-
port vector machines. Journal of the American Society for Information
Science and Technology, 55(7), 579–592.
Diederich, J., Kindermann, J., Leopold, E., & Paass, G. (2003). Authorship
attribution with support vector machines. Applied Intelligence, 19(1–2),
109–123.
Dumais, S., Platt, J., Heckerman, D., & Sahami, M. (1998). Inductive learn-
ing algorithms, representations for text categorization. In Proceedings of
the Seventh ACM International Conference on Information, Knowledge
Management (pp. 148–155). New York: ACM Press.
Finn, A., Kushmerick, N., & Smyth, B. (2002). Genre classification and
domain transfer for information filtering. In F. Crestani, M. Girolami, &
C.J. van Rijsbergen (Eds.), Proceedings of the 24th European Colloquium
on Information Retrieval Research. Lecture Notes in Computer Science,
2291, 349–352.
Forman, G. (2003). An extensive empirical study of feature selection metrics
for text classification. Journal of Machine Learning Research, 3, 1289–
1305.
Friedman, S. (1996). The manuscripts of the Babylonian Talmud: A typol-
ogy based upon orthographic and linguistic features. In M. Bar-Asher
(Ed.), Studies in Hebrew and Jewish languages presented to Shelomo
Morag [in Hebrew] (pp. 163–190). Jerusalem: The Center for Jewish Lan-
guages and Literatures, the Hebrew University of Jerusalem/The Bialik
Institute.
Fung, G., & Mangasarian, O. (2003). The disputed Federalist Papers: SVM
feature selection via concave minimization. Proceedings of the 2003
Conference on Diversity in Computing (pp. 42–46).
HaCohen-Kerner,Y., Beck, H.,Yehudai, E., & Mughaz, D. (2006). Identify-
ing historical period and ethnic origin of documents using stylistic feature
sets. In Proceedings of the Ninth International Conference on Discovery
Science. Lecture Notes in Artificial Intelligence (Vol. 4625, pp. 90–101).
Berlin, Germany: Springer-Verlag.
HaCohen-Kerner, Y., Boger, Z., Beck, H., & Yehudai, E. (2007). Identifi-
cation of the ethnic group of the writers using stems. Proceedings of the
20th International Conference on Computer Applications in Industry and
Engineering (pp. 5–11).
HaCohen-Kerner, Y., Kass, A., & Peretz, A. (2004). Baseline methods for
automatic disambiguation of abbreviations in Jewish law documents.
Proceedings of the Fourth International Conference on Advances in Nat-
ural Language Processing, LNAI 3230 (pp. 58–69). Berlin, Germany:
Springer-Verlag.
HaCohen-Kerner, Y., Kass, A., & Peretz, A. (2008a). Combined one sense
disambiguation of abbreviations. Proceedings of the Annual meeting
of the Association for Computational Linguistics: Human Language
Technologies, Short Papers (Companion Vol.) (pp. 61–64). Stroudsburg,
PA: ACL.
HaCohen-Kerner, Y., Kass, A., & Peretz, A. (2008b). Abbreviation dis-
ambiguation: Experiments with various variants of the one sense per
discourse hypothesis documents. In E. Kapetanios, V. Sugumaran, &
M. Spiliopoulou (Eds.), Proceedings of the 13th International Conference
onApplications of Natural Language to Information Systems, LNCS 5039
(pp. 27–39). London: Springer-Verlag.
Hamo, Y., & Markovitch, S. (2005). The compset algorithm for sub-
set selection. In Proceedings of the 19th International Joint Confer-
ence for Artificial Intelligence (pp. 728–733). San Francisco: Morgan
Kaufmann.
Hota, S., Argamon, S., & Chung, R. (2006, November). Gender in Shake-
speare: Automatic stylistics gender classification using syntactic, lexical,
1656 JOURNAL OF THE AMERICAN SOCIETY FOR INFORMATION SCIENCE AND TECHNOLOGY—August 2010
DOI: 10.1002/asi
and lemma features. Paper presented at the Chicago Colloquium on Dig-
ital Humanities and Computer Science, Chicago, IL. Retrieved April 8,
2010, from http://dhcs2006.uchicago.edu/abstracts/hota.pdf
Joachims, T. (1998). Text categorization with support vector machines:
Learning with many relevant features. Proceedings of the Tenth European
Conference on Machine Learning (pp. 137–142). London: Springer-
Verlag.
Joachims, T. (2002). Learning to classify text using Support Vector
Machines. London: Kluwer.
Karlgren, J., & Cutting, D. (1994). Recognizing text genres with simple
metrics using discriminant analysis. Proceedings of the 15th Interna-
tional Conference on Computational Linguistics, (Vol. 2, pp. 1071–1075).
Morristown, NJ: ACL.
Kessler, B., Nunberg, G., & Schutze, H. (1997). Automatic detection of text
genre. In P.R. Cohen &W.Wahlster (Eds.), Proceedings of the 35thAnnual
Meeting of the Association for Computational Linguistics and Eighth
Conference of the European Chapter of theAssociation for Computational
Linguistics (pp. 32–38). Somerset, NJ: Association for Computational
Linguistics.
Knight, K. (1999). Mining online text. Communications of theACM, 42(11),
58–61.
Koppel, M.,Argamon, S., & Shimony,A.R. (2002).Automatically categoriz-
ing written texts by author gender, Literary. Linguistic Computing, 17(4),
401–412.
Koppel, M., Mughaz, D., & Akiva, N. (2006). New methods for attribution
of rabbinic literature. Hebrew Linguistics: A Journal for Hebrew Descrip-
tive, Computational, Applied Linguistics, 57, v–xviii, Bar-Ilan University
Press.
Koppel, M., Mughaz, D., & Schler, J. (2004, January). Text categorization
for authorship verification. Paper presented at the Eighth Symposium on
Artificial Intelligence and Mathematics, Fort Lauderdale, FL.
Kushmerick, N. (1999). Learning to remove internet advertisement. In
O. Etzioni, J.P. Muller, & J.M. Bradshaw (Eds.), Proceedings of the Third
International Conference on Autonomous Agents (pp. 175–181). New
York: ACM Press.
Lim, C.S., Lee, K.J., & Kim, G.-C. (2005). Multiple sets of features for auto-
matic genre classification of web documents. Information Processing &
Management, 41(5), 1263–1276.
Madigan, D., Genkin, A., Lewis, D., Argamon, S., Fradkin, D., &
Ye, L. (2005, June). Author identification on the large scale. Paper
presented at the Classification Society of North America Annual
Meeting, (CSNA-05), St. Louis, MO. Retrieved April 8, 2010, from
http://www.stat.rutgers.edu/∼madigan/PAPERS/authorid-csna05.pdf
Matthews, R.A.J., & Merriam, T.V.N. (1997). Distinguishing literary styles
using neural networks. In E. Fiesler & R. Beale (Eds.), Handbook of neural
computation (pp. G8.1.1-6). Oxford, United Kingdom: IOP Publishing
and Oxford University Press.
McEnery, A., & Oakes, M. (2000). Authorship studies/textual statistics. In
R. Dale, H. Moisl, & H. Somers (Eds.), Handbook of natural language
processing. New York: Marcel Dekker.
Meretakis, D., & Wuthrich, B. (1999). Extending naive bayes classi-
fiers using long item sets. Proceedings of the Fifth ACM-SIGKDD
International Conference on Knowledge Discovery and Data Mining
(pp. 165–174). New York: ACM Press.
Mitchell, M., Holland, J.H., & Forrest, S. (1994). When will a genetic
algorithm outperform hill climbing? Advances in NIPS, 6, 51–58.
Mosteller, F., & Wallace, D.L. (1964). Inference and disputed authorship:
The Federalist. Reading, MA: Addison-Wesley.
Mughaz, D. (2003). Classification of Hebrew texts according to style.
Unpublished master’s thesis [in Hebrew], Bar-Ilan University, Ramat-
Gan, Israel.
Novak, J., Raghavan, P., & Tomkins, A. (2004). Anti-aliasing on the web.
Proceedings of the 13th International Conference on World Wide Web
(pp. 30–39). New York: ACM Press.
Pang, B., & Lee, L. (2005). Seeing stars: Exploiting class relationships for
sentiment categorization with respect to rating scales. Proceedings of
the 43rd annual meeting on Association for Computational Linguistics
(pp. 115–124). Stroudsburg, PA: ACL.
Pang, B., Lee, L., & Vaithyanathan, S. (2002). Thumbs up? Sentiment
classification using machine learning techniques. Proceedings of the
2002 Conference on Empirical Methods in Natural Language Processing.
Stroudsburg, PA: ACL.
Patrick, J. (2004). The scamseek project: Text mining for financial scams on
the Internet. In S. Simoff & G. Williams (Eds.), Proceedings of the Third
Australasian Data Mining Conference (AusDM04) (pp. 33–38). Sydney,
Australia: University of Technology.
Pazienza, M.T. (Ed.). (1997). Information extraction. Lecture Notes in
Computer Science, 1299. Heidelberg, Germany: Springer.
Peng, F., Schuurmans, D., & Wang, S. (2003). Language and task inde-
pendent text categorization with simple language models. Proceedings
of the Human Language Technology Conference of the North American
Chapter of the Association for Computational Linguistics (HLT-NAACL)
(pp. 110–117). Stroudsburg, PA: ACL.
Platt, J.C. (1999). Fast training of support vector machines using sequential
minimal optimization. In B. Scholkopf, C. Burges, & A.J. Smola (Eds.),
Advances in kernel methods—support vector learning (pp. 185–208).
Cambridge, MA: MIT Press.
Radai, Y. (1978). Hamikra haMemuchshav: hesegim bikoret umishalot [in
Hebrew]. Balshanut Ivrit, 13, 92–99.
Radai, Y. (1979). Od al hamikra haMemuchshav [in Hebrew]. Balshanut
Ivrit, 15, 58–59.
Radai, Y. (1982). Mikra uMachshev: divrei idkun [in Hebrew]. Balshanut
Ivrit, Vol. 19, 47–52.
Schler, J., Koppel, M., Argamon, S., & Pennebaker, J. (2006, March).
Effects of age and gender on blogging. Paper presented at the
2006 AAAI Spring Symposium on Computational Approaches for
Analyzing Weblogs, Palo Alto, CA. Retreived April 8, 2010, from
http://lingcog.iit.edu/doc/springsymp-blogs-final.pdf
Sebastiani, F. (2002). Machine learning in automated text categorization.
ACM Computing Surveys, 34(1), 1–47.
Snyder, B., & Barzilay, R. (2007). Multiple aspect ranking using the good
grief algorithm. In Proceedings of the Joint Human Language Technology/
North American Chapter of the ACL Conference (pp. 300–307).
Stamatatos, E. (2006).Authorship attribution based on feature set subspacing
ensembles. International Journal on Artificial Intelligence Tools, 15(5),
823–838.
Stamatatos, E. (2008). Author identification: Using text sampling to handle
the class imbalance problem. Information Processing & Management,
44(2), 790–799.
Stamatatos, E., Fakotakis, N., & Kokkinakis, G. (2001). Computer-based
authorship attribution without lexical measures. Computers and the
Humanities, 35, 193–214.
Turney, P., & Littman, M. (2002). Unsupervised learning of semantic
orientation from a hundred-billion-word corpus (Tech. Rep. No. ERB-
1094; NRC No. 44929). Philadelphia: National Research 41 Council
Canada.
Vapnik, V.N. (1995). The nature of statistical learning theory. New York:
Springer-Verlag.
Weston, J., Mukherjee, S., Chapell, O., Pontil, M., Poggio, T., & Vapnik, V.
(2000). Feature selection for SVMs. In Proceedings ofAdvances in Neural
Processing Systems (NIPS) (pp. 668–674). Cambridge, MA: MIT Press.
Wintner, S. (2004). Hebrew computational linguistics: Past and future.
Artificial International Review, 21(2), 113–138.
Witten, I.H., & Frank, E. (2009). Weka 3.6: Machine learning soft-
ware in Java. Retrieved April 8, 2010, from http://www.cs.waikato.
ac.nz/∼ml/weka
Yang, Y., & Liu, X. (1999). A re-examination of text categorization
methods. Proceedings of the 22nd ACM International Conference on
Research Development in Information Retrieval (pp. 42–49). New York:
ACM Press.
Yule, U. (1938). On sentence length as a statistical characteristic of style in
prose with application to two cases of disputed authorship. Biometrika,
30, 363–390.
Zhu, J., & Yao, T. (2004). An evaluation of statistical spam filtering tech-
niques. ACM Transactions on Asian Language Information Processing,
3(4), 243–269.
JOURNAL OF THE AMERICAN SOCIETY FOR INFORMATION SCIENCE AND TECHNOLOGY—August 2010 1657
DOI: 10.1002/asi
