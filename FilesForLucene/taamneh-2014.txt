Compression-Based Arabic Text Classification
Haneen Ta’amneh, Ehsan Abu Keshek, Manar Bani Issa, Mahmoud Al-Ayyoub, Yaser Jararweh
Jordan University of Science and Technology
Irbid, Jordan
Emails: {hjalitamnah10, eaabukeshek11, mbbanyissa10}@cit.just.edu.jo, {maalshbool, yijararweh}@just.edu.jo
Abstract—Text classification (TC) is one of the fundamental
problems in text mining. Plenty of works exist on TC with
interesting approaches and excellent results; however, most of
these works follow a word-based approach for feature extraction.
In this work, we are interested in an alternative (byte-based
or character-based) approach known as compression-based TC
(CTC). CTC has been used for some languages such as En-
glish and Portuguese and it is shown to have certain advan-
tages/disadvantages compared with word-based approaches. This
work applies CTC on the Arabic language with the purpose of
investigating whether these advantages/disadvantages exists for
the Arabic language as well. The results are encouraging as they
show the viability of using CTC for Arabic TC.
I. INTRODUCTION
The text classification (TC) problem is concerned with
automatically placing text documents in categories/classes
based on their contents. It is one of the fundamental problems
in many fields such as text mining, machine learning, natural
language processing, information retrieval, etc., with a vast
range of applications such as spam filtering [1], sentiment
analysis [2], [3], [4], [5], determining author’s characteristics
such as identity [6], [7], [8], gender [9], [10], dialect [11],
[12], native language [13], political orientation [14], [15], etc.
The TC problem gained more importance due to the explosion
in the size of text data available on the Web over the past two
decades. Not only this expansion forced people to consider
scalability issues (giving rise to important fields such as Big
Data), it has also produced special challenges for the TC
problem.
In general TC, we are given a large-enough dataset of
manually labeled training documents and the objective is to
build a classification model based on this dataset capable
of accurately predicting the class of an unlabeled document.
While this description applies to all supervised learning prob-
lems, TC has some special characteristics requiring special
attention. For example, most works on TC start by applying
some text preprocessing tasks followed by employing a word-
based approach for feature extraction. For example, they may
tokenize the article and apply stemming followed by step
words removal. Then they may use word occurrences in each
article to build a feature vector for it in what is known as
the bag-of-words (BOW) approach [16]. Such an approach
relies heavily on word-based features (which are language-
dependent) such as tokenization, stemming, etc., and tend to
ignore word order, contextual information and other non-word
features such as punctuation marks and features spanning more
than one word. Moreover, it tends to generate feature vectors
consisting of thousands of features even for relatively small
and restricted datasets. Thus, a feature selection algorithm
has to be applied to determine which features to keep due
to their “discriminating” power. Finally, according to Frank
et al. [17], it has to deal with issues like how to define a
“word,” what to do with numbers and other non-alphabetic
strings, and whether to apply stemming. These issues give rise
to alternative approaches to TC such as compression-based TC
(CTC).
According to Marton et al. [18], CTC has been heavily
studied to explore its advantages/disadvantages compared with
traditional word-based TC approaches. Examples of the advan-
tages include the ease of application, the lack of dependence
on the often heavy text preprocessing steps, the ability to cap-
ture non-word features, etc. On the other hand, the disadvan-
tages include the poor performance by some CTC approaches
in terms of accuracy and computational complexity. Most of
the such works are for the English language. The objective of
this work is to explore these advantages/disadvantages for the
Arabic language. To the best of our knowledge, there has been
no previous works on CTC of Arabic document despite the fact
that CTC has been heavily studies for English documents over
the past three or four decades [17]. This work is especially
important to draw attention to CTC as an alternative option to
perform various TC tasks such as spam filtering, authorship
authentication, language/dilect identification, etc. Taking into
consideration the significance of TC and the reliance of the
traditional TC algorithms on language-dependent tools which
do not perform on Arabic text as well as they perform on
English text, one would see the need to explore language
independent options.
The languages of choice in this work is Arabic. Most
existing works on NLP in general consider English text from
text processing tools to optimized classifiers. Arabic, on the
other hand, is largely understudied despite being one of the six
official languages of the UN and the native language of 420
million people living in the Arab world, which spans regions of
the Middle East and North Africa (MENA) in addition to parts
of East Africa (Horn of Africa) [19]. Moreover, the amount
of Arabic content on the Web and the number of Arabic
speaking users are growing rapidly [5], [20]. Finally, Arabic is
a rich morphological language with many challenging aspects.
The importance of the Arabic language and the interesting
challenges associated with studying it make it one of the most
appealing languages to study.
The rest of this paper is organized as follows. In Section II,
978-1-4799-7100-8/14/$31.00 ©2014 IEEE 
594
we present an up-to-date coverage of the addressed problem
while, in Sections III and III-C, we present our research
methodology and experimental results. Finally, we conclude
the paper and discuss future work guidelines in Section IV.
II. LITERATURE REVIEW
Since TC is a fundamental problem based on which many
problems are formulated in many fields such as machine learn-
ing, data mining, information retrieval and natural language
processing, there are numerous papers addressing different
aspects of it. Since the English language is the most studied
language in the literature making it the focal point of the
textbooks on NLP and TC, we will simply refer the interested
readers to surveys with thorough coverage of TC for the
English language such as [21], [16], [1], [22], [23]. Below, we
mention some of the interesting works on Arabic TC before
discussing the most relevant works in terms of CTC.
A. Previous Works on Arabic TC
In the discussion below, we focus on the works addressing
Arabic TC.
Since the number and quality of features used to ex-press
documents have a direct effect on categorization algorithms,
the following discusses the main ideas and techniques of
feature reduction and selection and their impact on TC.
Duwairi et al. [24] compared between three reduction tech-
niques (stemming, light stemming, and word cluster). KNN
was selected for training and testing and the results showed
that light stemming yielded the highest accuracy and lowest
time of model construction. Another study [25] compared 17
Feature Subset Selection (FSS) metrics. They carried out a
comparative study to examine the effect of the feature selection
metrics in terms of precision, recall, F1-measure, and model
building time. The results in general revealed that Odd Ratio
(OR) worked better than the others.
Some studies focused on other techniques like N-gram
and different distance measures and proved their effects on
Arabic TC. For instance, [26] used a statistical method called
Maximum Entropy (ME) for the classification of Arab News
articles. The author showed that the Dice measures using
N-gram outperforms using the Manhattan distance. Similar
classifier was used in [27], but different selection and reduc-
tion techniques were applied. The author used normalization,
stemming and stop words removal to increase the ultimate
accuracy.
However, many studies focused on the exploited classifiers,
and the evolvement of the classifiers used in each study keeps
growing alongside pre-processing tasks such as stemming,
weighting techniques, N-gram, and so forth. In [28], the
authors classified a dataset collected from different Arabic web
sites utilizing the Naive Bayes (NB) algorithm and achieved
69% accuracy. In [29], the author used three classification
algorithms: K-Nearest Neighbor (KNN), SVM and NB, for
classifying each document into one of nine classes (Computer,
Economics, Education, Engineering, Law, Medicine, Politics,
Religion and Sports). Whilst, in [30], the NB and KNN
classifiers were only used to classify Arabic text collected
from online Arabic newspapers such as Aljazeera, Al-Ahram,
Al-Dostor, etc. Then in [31] proposed a hybrid algorithm for
Arabic stemming and compared it to other proposed stemmer,
for example, Khoja stemmer. The outcomes were promising
and acceptable.
Moreover, [32] studied four different term-frequency
weighting schemes such as: raw Term Frequency (TF), which
improves recall, Inverse Document Frequency (IDF), which
improves precision, Term Frequency-Inverse Document fre-
quency (TF-IDF), which improves both recall and precision,
and Weighted Inverse Document Frequency (WIDF). Finally,
experiments showed that, in general, NB was the best followed
by KNN and Rocchio.
Researchers have not stopped investigating the impact of
several factors on the classification accuracy. These factors
include corpora size and diversity, features selection and
reduction, targeted language/dialect, classification approach,
etc. Hence, studies like [33], [34], [35], [36], [37], [38], [39],
[40], [41] are comprehensive references for that matter. Most
of them illustrate the importance of choosing certain criteria
during the training and testing phases and some of them
suggested new ideas which handle the classification process
quite differently. For instance, [42] proposed a distance based
classifier in which each category is represented by a vector
containing the words of the training documents after applying
pre-processing and stemming operations.
B. Previous Works on CTC
It is difficult to determine who suggested using compression
for classification first [18]. Also, compression-based tech-
niques have been used for TC problems where the classes are
not the topics/domains of the documents. Instead, some papers
worked on the authorship authentication problem (where the
classes are the authors) Here we review previous experimental
work on the approach. Working on the authorship authentica-
tion problem of large dataset of Russian literary, Kukushkina
et al. [43] conducted extensive experiments using a many
compression techniques. Another work on authorship authen-
tication is by Thaper [44] who applied LZ78,1 character-based
PPM,2 and word-based PPM on a dataset of English literary.
As for traditional (topic-based) TC, Frank et al. [17] exper-
imented with PPM and concluded that compression methods
do not fare well compared to the state of the art word-based
approaches such as BOW-based machine learning approaches.
According to Frank et al., this is mainly due CTC techniques’
inability to exploit keywords. On the contrary to Frank et
al.’s conclusion, Teahan and Harper [45] experimented with
variants of PPM to prove the effectiveness of CTC techniques
to topic-based TC.
As can be seen in the previous paragraph, there is some
controversy associated with CTC techniques and their effec-
tiveness in addressing different TC problems. Perhaps the
1A lossless data compression algorithm proposed by Lempel and Ziv.
2PPM stands for prediction by partial matching, a commonly used CTC
technique.
 
595
most controversial work is that of Benedetto et al. [46] who
addressed the authorship authentication problem using gzip
coupled with BCN (discussed in Section III-B1). To get more
information about what happened, the interested reader is
referred to following sources [47], [48], [49], [50], [51].
Several TC techniques were investigated and compared on
Reuters’ dataset of news articles in Khmelev and Teahan’s
work [52]. The set of considered classifiers included SVM
(as one of the best machine learning technique for TC) and
a CTC using gzip and RAR and the experiments outcome
showed that CTC with RAR produced the best results even
when compared with SVM. Commenting on these results,
the authors pointed out to the suboptimality of the way they
used SVM for multiclass classification. Also, they justified the
results by word-based approaches’ inability to capture non-
word features such as features spanning more than one word.
Several character-based TC techniques have been proposed
in the literature [53], [54], [55], [56], [57]. One of the most
interesting one is that of Peng et al. [56], [57] which is
basically based on Teahan’s work on CTC approaches using
PPM [58], [45]. In [56], [57], the authors showed that using
character-based language modeling techniques employing N-
gram Markov models for TC can produce great results. They
use cross-entropy to calculate the similarity between the
learned model and the test documents.
III. METHODOLOGY
This section presents the methodology followed in this work
starting with the discussion of the datasets followed a detailed
description of the CTC approaches considered here.
A. The Datasets
In our experiments we used two publicly available datasets
of Arabic news articles. The first one (called the DAA dataset)
was collected by Diab Abuaiadh3 and it consists of 2,700
documents evenly spread across nine categories (Art, Econ-
omy, Health, Law, Literature, Politics, Religion, Sport and
Technology). The dataset is available in five versions:
• Version#1: The original dataset.
• Version#2: The dataset after removing stop words, punc-
tuation and diacritic marks.
• Version#3: Version#2 after applying the light10 stemmer.
• Version#4: Version#2 after applying Chen stemmer.
• Version#5: Version#2 after applying Khoja algorithm for
extracting the roots.
We used the first version of this dataset. To avoid performance
bottleneck and allow some of the considered CTC techniques
to finish, we cut the size of this dataset to the third for some
experiments. Specifically, we use only the first 100 documents
in each class. We call this the DAA-Reduced dataset. For
testing purposes, we use the holdout method by randomly
dividing the 100 documents of each class into a training set
of 67 files and a testing set of 33 files. Document size ranges
from 2.1KB to 6KB. The total size of the training data per
3http://diab.edublogs.org/dataset-for-arabic-document-classification/
class varies from 270.1KB to 479.3KB. We also did another
experiment using all the 2,700 documents (which we call the
DAA-All dataset), and randomly divided the documents of each
class into 200 training files and 100 testing files. For this
setting, the total size of the training data per class varies from
544.4KB to 756.8KB.
Note that the first dataset is rather small with perfect balance
across the nine categories it contains. To test the considered
CTC approaches under more realistic settings, we use the BBC
Arabic dataset4, which includes 4,763 text documents spread
across seven categories as follows:
1) Middle East News: 2,356 documents (11.1MB).
2) World News: 1,489 documents (6.5MB).
3) Business & Economy 296 documents (1.2MB).
4) Sports 219 documents (979.3KB).
5) International Press 49 documents (556.2KB).
6) Science & Technology 232 documents (985.3KB).
7) Art & Culture 122 documents (671.5KB).
The sizes of the documents range from 779Bytes to 50KB.
We create four versions of this dataset as follows. In the
first one, we use the entire dataset. We call this the BBC-
Unbalanced dataset. In the second one, we balance the dataset
by reducing the number of documents in each class to match
the number of documents in the minority class. However,
since the International Press class contains only 49 documents,
we decide to exclude it from this version (and subsequent
versions) of the dataset and set the number of documents to
122. We call this the BBC-Balanced dataset. In the third one,
we choose the longest 100 document from each class. We
call this the BBC-Long dataset. Finally, tn the fourth one, we
choose the shortest 100 document from each class. We call
this the BBC-Short dataset.
B. Compression-Based Text Classification (CTC)
As their name suggest, CTC approaches make use of some
compression software (such as RAR, gzip and LZW) to create
a model or dictionary of each file they process. The training
phase is to simply compress the labeled articles in the training
set creating training models. When fed a new document, CTC
approaches simply compresses it using the different training
models or dictionary and assigns it to the class whose model’s
compression rate is the highest. Marton et al. [18] gave
an information-theoretic argument of why such an approach
works by noting that it minimizes the cross-entropy between
the training set and the new document measured by comression
rate.
According to [17], [18], CTC approaches are appealing
because they are simple enough to be applied by average end-
users (e.g., see [47]), they do not lose information by dis-
carding some of the computed features, they are not hindered
by language-dependent issues like word boundaries and word
morphology, they are able to capture non-word features such
as character-based features and features spanning more than
one word, etc. Moreover, CTC can be useful for objectives
4http://sourceforge.net/projects/ar-text-mining/files/Arabic-Corpora
 
596
other than categorization such as improving the compression
performance.
The previous paragraphs discuss CTC in general. Below, we
give the details of the CTC approaches under consideration
here.
1) CTC Techniques: We discuss the following three dif-
ferent CTC techniques: the Standard Minimum Descrip-
tion Length(SMDL), the Approximate Minimum Description
Length (AMDL) and the Best-Compression Neighbor (BCN)
procedures. Here is a description of each technique [18]:
• SMDL: Given training documents for categories from
C1 to Cn. SMDL forms for each Ci a single file Ai
consisting of all documents in that category. It then runs
the compression algorithm on each Ai to obtain a model
(or dictionary) Mi. For each Mi, it runs the compression
algorithm “statically” on a test file T . At the end, it
assigns test document T to the class i whose model
Mi has achieved the best compression of T . SMDL is
discussed here for the sake of completeness. we do not
actually use it in our experiments.
• AMDL: Similar to SMDL, AMDL forms for each Ci a
single training file Ai consisting of all training documents
in Ci. It then runs the compression algorithm on each
Ai to produce a compressed file Ai of size |Ai| and
appends T to each Ai, producing AiT . It then runs
the compression algorithm on each AiT to produce a
compressed file of size |Ai|. At the end, it assigns T to the
class Ci that minimizes the compressed size difference
vi = |AiT ||Ai|. The value vi represents an estimate of
the cross-entropy of text T with respect to text Ai.
• BCN: Unlike SMDL and AMDL, BCN keeps each
training document D in a separate file. It concatenates
test document T to each D forming DT and calculate
vDT = |DT ||D|. It then assigns T to the class containing
the document D that minimizes vDT .
SMDL is expected to be faster than both AMDL and BCN
in classifying a new file, because it uses saved models or
dictionaries for each class. In AMDL and BCN, the new file
is concatenated to the training files, which causes the models
or dictionaries for the training files to be recomputed.
2) Compression Techniques: We consider three compres-
sion techniques: gzip, LZW and RAR. Here is a description
of each technique [18]:
• Gzip is a software application used for file compression
and decompression. It is available on most UNIX sys-
tems. It uses Lempel-Ziv (LZ77) compression algorithm.
Its efficacy in classification is limited by its use of a
sliding window; the typical size of a gzip sliding window
is 32KB. We use the command line option “-9fc” for best
compression and notice that the accuracy improves by just
using the “-c” option.
• LZW is a well-known, dictionary-based compression
method. It is simple to implement, and has the potential
for very high throughput in hardware implementations.
A large text file can be compressed using LZW to about
half its original size. The compression command we
used was ”compress” with the “-c” option. The compress
utility uses a modified Lempel-Ziv algorithm. Common
substrings in the file are first replaced by 9-bit codes 257
and up. When code 512 is reached, the algorithm switches
to 10-bit codes and continues to use more bits until the
limit specified by the “-b” option or its default is reached
which is 16bit. LZW dictionary size is limited.
• RAR is a proprietary archive file format that supports data
compression, error recovery and file spanning. Current
versions of RAR can use either LZ (Lempel-Ziv) based
or PPM based compression, and chooses between them
based on the input data. For text, it usually uses PPM
based compression. PPM (prediction by partial matching)
is a data compression technique based on context model-
ing and prediction. Its models a set of previous symbols
in the uncompressed symbol stream to predict the next
symbol in the stream.
C. Experiments and Results
In this section, we present the details of the experiments
conducted on the two considered CTC techniques (AMDL
and BCN) using the three considered compression techniques
(gzip, LZW and RAR) running on the two datasets (DAA and
BBC). We conduct four different experiments and dedicate
each of the following subsections to a single experiment. The
first two experiments are conducted on the DAA datasets to
determine which compression technique is better (the first
experiment) and which CTC technique is better (the second
experiment). The last two experiments are conducted on the
BBC datasets to determine the effect of certain aspects such
as dataset balance (the third experiment) and lengths of the
documents (the fourth experiment) on CTC techniques in
general. As mentioned previously, the testing technique is the
hold out method with two thirds of the dataset being reserved
for training and the remaining third being reserved for testing.
The only measure we report here is the accuracy, which is
defined as the percentage of correctly classified documents.
D. Comparison of RAR, gzip, and LZW
The objective of the first experiment is to determine
which of the three compression techniques under consideration
(RAR, gzip and LZW) is better. For this purpose, we test each
one of them on the same datasets (the DAA datasets) using
the same CTC technique (AMDL). The results are presented
in Table I. As the table shows, for the smaller dataset (DAA-
Reduced) RAR performs the best while gzip’s performance is
very close. This is probably due to the training documents’
small sizes. To prove this, we repeat our experiments on the
larger dataset (DAA-All) and the performance gap between
RAR and gzip became larger. One justification of this is related
to gzip’s 32KB sliding window technique and how it is affect
by AMDL’s policy of concatenating the training files, which
means that gzip’s sliding window will only have information
from the last 32KB of the concatenated file. Another ob-
servation from this table is LZW’s poor performance. This
 
597
TABLE I
RESULTS OF USING THE DIFFERENT COMPRESSION TECHNIQUES WITH
AMDL ON THE TWO VERSIONS OF THE DAA DATASET.
DAA-Reduced DAA-All
RAR 0.88 0.96
LZW 0.76 0.69
gzip 0.85 0.87
TABLE II
ACCURACY RESULTS OF APPLYING BOTH CTC TECHNIQUES UNDER
CONSIDERATION WITH DIFFERENT COMPRESSION TECHNIQUES ON THE
DAA-REDUCED DATASET.
AMDL BCN
RAR 0.88 0.89
LZW 0.76 0.68
gzip 0.86 0.87
is probably related to its limited dictionary size, which gets
full quickly (after reading only part of the input text) and no
changes can be made on it afterwards. So, LZW’s performance
is bound to degrade with larger datasets. Both gzip and LZW
make use of parts of the training set, which allows RAR to
insignificantly outperform them due to its ability to make use
of the entire training set.
E. Comparison of AMDL and BCN
The objective of the second experiment is to determine
which of the two CTC techniques under consideration (AMDL
and BCN) is better. For this purpose, we test each one of
them on the same dataset (the DAA dataset) using different
compression techniques. The accuracy results are presented in
Table II whereas the running times are presented in Table III.
The tables show that BCN runs very slowly compared to
AMDL, which is expected since BCN performs concatenate
and compress operations multiple times more than AMDL.
To avoid prohibitively long experiments, we took several
measures such as creating the DAA-Reduced dataset. More-
over, we modified the BCN code to reduce the number of
concatenate and compress operations from m (which is the
number of documents in each class) to 3. From the table, it
can be seen that the effect gzip’s 32KB sliding window is
minimal as it performs closely to RAR, which is expected for
BCN since the concatenated files are not very large giving
gzip the chance to use most of the training set.
TABLE III
RUNNING TIMES OF APPLYING BOTH CTC TECHNIQUES UNDER
CONSIDERATION WITH DIFFERENT COMPRESSION TECHNIQUES ON THE
DAA-REDUCED DATASET.
AMDL BCN
RAR 3.38 24.05
LZW 3.59 21.23
gzip 3.76 23.94
TABLE IV
ACCURACY RESULTS OF APPLYING BOTH CTC TECHNIQUES UNDER
CONSIDERATION WITH DIFFERENT COMPRESSION TECHNIQUES ON THE
BBC-UNBALANCED AND BBC-BALANCED DATASETS.
BBC-Unbalanced BBC-Balanced
AMDL BCN AMDL BCN
RAR 0.81 N/A 0.91 0.92
LZW 0.74 N/A 0.72 0.80
gzip 0.34 N/A 0.76 0.84
F. Studying the effect of Balancing the Dataset
Since the DAA dataset is a balanced one (in terms of the
number of documents in each class) with documents that do
not vary greatly in length, we are forced to use a different
dataset for the third and fourth experiments. The dataset we
choose is the BBC dataset and, as mentioned in Section III-A,
we create four versions of this dataset: BBC-Unbalanced,
BBC-Balanced, BBC-Long and BBC-Short.
The objective of this experiment is to study the effect of
balancing the dataset on the different combinations of com-
pression/CTC techniques under consideration. The accuracy
results are presented in Table IV whereas the running times are
presented in Table V. The first thing to note about these tables
is the missing values for the BCN experiments on the BBC-
Unbalanced dataset. This is mainly due to the slow running
time of BCN, which prevents it from producing any results
within reasonable time when run on a dataset of thousands of
documents. Another obvious observation from these tables is
the superiority of RAR over the other compression techniques
under consideration, which conforms with what is shown in
the previous two subsections. This might be due to the fact the
balanced dataset is smaller which gives RAR the potential to
benefit from all training documents in each class. Moreover,
gzip performs better with the balanced data due to its 32KB
sliding window and how it interacts with AMDL. Finally, it
seems that the only combination of compression/CTC tech-
niques that got hurt from balancing the dataset is the AMDL
with LZW. However, the drop in accuracy for LZW/AMDL is
small.
As for the running times, Table V shows that AMDL is
much faster than BCN even if we ran it on the entire dataset
while running BCN on the balacned dataset which is much
smaller. As for the compression techniques, LZW is the fastest
followed by RAR. Finally, the table shows an interesting ob-
servation related to AMDL’s scalability: increasing the dataset
size by about 6.5 times causes an increase in AMDL’s running
time by more than 8 times.
 
598
TABLE V
RUNNING TIMES OF APPLYING BOTH CTC TECHNIQUES UNDER
CONSIDERATION WITH DIFFERENT COMPRESSION TECHNIQUES ON THE
BBC-UNBALANCED AND BBC-BALANCED DATASETS.
BBC-Unbalanced BBC-Balanced
AMDL BCN AMDL BCN
RAR 18.81 N/A 2.14 29.69
LZW 16.58 N/A 2.04 29.52
gzip 19.94 N/A 2.46 30.23
TABLE VI
ACCURACY RESULTS OF APPLYING BOTH CTC TECHNIQUES UNDER
CONSIDERATION WITH DIFFERENT COMPRESSION TECHNIQUES ON THE
BBC-LONG AND BBC-SHORT DATASETS.
BBC-Long BBC-Short
AMDL BCN AMDL BCN
RAR 0.84 0.83 0.88 0.89
LZW 0.76 0.59 0.79 0.77
gzip 0.62 0.72 0.79 0.86
G. Studying the effect of Lengths of the Documents on CTC
Techniques
Considering the way compression techniques work, the
length of a text document to be compressed does have an
effect on the compression outcome. This is not specific to
compression-based techniques as word-based techniques are
also affect by it [38]. To address this issue, we create the
datasets BBC-Long (containing the 100 longest documents
in each class) and BBC-Short (containing the 100 shortest
documents in each class). We compare the performance of
the different combinations of compression/CTC techniques
under consideration on each dataset. The accuracy results
are presented in Table VI whereas the running times are
presented in Table VII. Table VI shows that the accuracy
improves with shorter documents. While the improvement is
small for most combinations of compression/CTC techniques
under consideration, there are cases of significant improvement
such as BCN with LZW.
As for the running times, Table V shows that AMDL’s
average running time is about 8.4% of BCN’s average run-
ning time. As with previous experiments, LZW is the fastest
compression technique. Finally, a counter-intuitive observation
from this table is that working with shorter documents does
not necessarily mean smaller running times.
TABLE VII
RUNNING TIMES OF APPLYING BOTH CTC TECHNIQUES UNDER
CONSIDERATION WITH DIFFERENT COMPRESSION TECHNIQUES ON THE
BBC-LONG AND BBC-SHORT DATASETS.
BBC-Long BBC-Short
AMDL BCN AMDL BCN
RAR 1.86 21.69 1.7 20.72
LZW 1.62 20.34 1.66 21.29
gzip 1.85 20.4 1.84 20.94
IV. CONCLUSIONS AND FUTURE WORK
This work was intended to explore the potentials of using
CTC on Arabic articles. Since this is a pilot study, we only
focused on the combination of three compression techniques
(RAR, gzip and LZW) with two compression-based classifi-
cation techniques (AMDL and BCN). Regarding the question
of which compression technique is better, the results showed
that RAR almost always produced more accurate classification
than LZW and gzip. LZW often performed poorly due to its
limited size dictionary. Gzip’s problem was with its sliding
window. As for the CTC techniques, we found AMDL to
be better than BCN for RAR, both in runtime and accuracy,
whereas, BCN was found to be better than AMDL for gzip’s
accuracy, although it runs even more slowly than AMDL.
Overall, combining RAR with AMDL seems to give the best
results.
REFERENCES
[1] C. C. Aggarwal and C. Zhai, “A survey of text classification algorithms,”
in Mining text data. Springer, 2012, pp. 163–222.
[2] A. Abbasi, H. Chen, and A. Salem, “Sentiment analysis in multiple
languages: Feature selection for opinion classification in web forums,”
ACM Transactions on Information Systems (TOIS), vol. 26, no. 3, p. 12,
2008.
[3] N. Abdulla, N. Mahyoub, M. Shehab, and M. Al-Ayyoub, “Arabic
sentiment analysis: Corpus-based and lexicon-based,” in Proceedings of
The IEEE conference on Applied Electrical Engineering and Computing
Technologies (AEECT), 2013.
[4] M. N. Al-Kabi, N. A. Abdulla, and M. Al-Ayyoub, “An analytical study
of arabic sentiments: Maktoob case study,” in The 8th International
Conference for Internet Technology and Secured Transactions (ICITST).
IEEE, 2013, pp. 89–94.
[5] N. A. Abdulla, M. Al-Ayyoub, and M. N. Al-Kabi, “An extended
analytical study of arabic sentiments,” International Journal of Big Data
Intelligence, vol. 1, no. 1, pp. 103–113, 2014.
[6] P. Juola, “Authorship attribution,” Foundations and Trends in information
Retrieval, vol. 1, no. 3, pp. 233–334, 2006.
[7] E. Stamatatos, “A survey of modern authorship attribution methods,”
Journal of the American Society for information Science and Technology,
vol. 60, no. 3, pp. 538–556, 2009.
[8] A. Alwajeeh, M. Al-Ayyoub, and I. Hmeidi, “On authorship authen-
tication of arabic articles,” in The fifth International Conference on
Information and Communication Systems (ICICS 2014), 2014.
[9] N. Cheng, R. Chandramouli, and K. Subbalakshmi, “Author gender
identification from text,” Digital Investigation, vol. 8, no. 1, pp. 78–
88, 2011.
[10] K. Alsmearat, M. Al-Ayyoub, and R. Al-Shalabi, “An extensive study
of the bag-of-words approach to gender identification of arabic articles,”
in The ACS/IEEE International Conference on Computer Systems and
Applications (AICCSA), 2014.
[11] O. F. Zaidan and C. Callison-Burch, “The arabic online commentary
dataset: an annotated dataset of informal arabic with high dialectal
content,” in Proceedings of the 49th Annual Meeting of the Association
for Computational Linguistics: Human Language Technologies: short
papers-Volume 2. Association for Computational Linguistics, 2011,
pp. 37–41.
[12] ——, “Arabic dialect identification,” Computational Linguistics, vol. 40,
no. 1, pp. 171–202, 2013.
[13] J. Tetreault, J. Burstein, and C. Leacock, Eds., Proceedings
of the Eighth Workshop on Innovative Use of NLP for
Building Educational Applications. Atlanta, Georgia: Association
for Computational Linguistics, June 2013. [Online]. Available:
http://www.aclweb.org/anthology/W13-17
 
599
[14] M. Koppel, N. Akiva, E. Alshech, and K. Bar, “Automatically classifying
documents by ideological and organizational affiliation,” in Intelligence
and Security Informatics, 2009. ISI’09. IEEE International Conference
on. IEEE, 2009, pp. 176–178.
[15] R. Abooraig, A. Alwajeeh, M. Al-Ayyoub, and I. Hmeidi, “On the
automatic categorization of arabic articles based on their political orien-
tation,” in Third International Conference on Informatics Engineering
and Information Science (ICIEIS2014), 2014.
[16] T. Joachims, Learning to classify text using support vector machines:
Methods, theory and algorithms. Kluwer Academic Publishers, 2002.
[17] E. Frank, C. Chui, and I. H. Witten, “Text categorization using compres-
sion models,” University of Waikato, Department of Computer Science,
Tech. Rep., 2000.
[18] Y. Marton, N. Wu, and L. Hellerstein, “On compression-based text
classification,” in Advances in Information Retrieval. Springer, 2005,
pp. 300–314.
[19] N. Abdulla, R. Majdalawi, S. Mohammed, M. Al-Ayyoub, and M. N.
Al-Kabi, “Automatic lexicon construction for arabic sentiment analysis,”
in The 2nd International Conference on Future Internet of Things and
Cloud (FiCloud), 2014.
[20] M. Al-Ayyoub, S. Bani Essa, and I. Alsmadi, “Lexicon-based sentiment
analysis of arabic tweets,” International Journal of Social Network
Mining (IJSNM), to appear.
[21] F. Sebastiani, “Machine learning in automated text categorization,” ACM
computing surveys (CSUR), vol. 34, no. 1, pp. 1–47, 2002.
[22] V. Korde and C. N. Mahender, “Text classification and classifiers: A
survey,” International Journal of Artificial Intelligence & Applications,
vol. 3, no. 2, 2012.
[23] K. Aas and L. Eikvil, “Text categorisation: A survey,” Raport NR, vol.
941, 1999.
[24] R. Duwairi, M. N. Al-Refai, and N. Khasawneh, “Feature reduction
techniques for arabic text categorization,” Journal of the American
society for information science and technology, vol. 60, no. 11, pp.
2347–2352, 2009.
[25] A. Mesleh, “Feature sub-set selection metrics for arabic text classifi-
cation,” Pattern Recognition Letters, vol. 32, no. 14, pp. 1922–1929,
2011.
[26] L. Khreisat, “Arabic text classification using n-gram frequency statistics
a comparative study,” in Conference on Data Mining— DMIN’06, 2006,
p. 79.
[27] A. El-Halees, “Arabic text classification using maximum entropy,” The
Islamic University Journal (Series of Natural Studies and Engineering),
vol. 15, pp. 157–167, 2007.
[28] M. El Kourdi, A. Bensaid, and T.-e. Rachidi, “Automatic arabic docu-
ment categorization based on the naı̈ve bayes algorithm,” in Proceedings
of the Workshop on Computational Approaches to Arabic Script-based
Languages. Association for Computational Linguistics, 2004, pp. 51–
58.
[29] A. M. Mesleh, “Chi square feature extraction based svms arabic lan-
guage text categorization system,” Journal of Computer Science, vol. 3,
no. 6, p. 430, 2007.
[30] W. Hadi, F. Thabtah, S. ALHawari, and J. Ababneh, “Naive bayesian
and k-nearest neighbour to categorize arabic text data,” in European
Simulation and Modeling Conference, 2008, pp. 196–200.
[31] M. Hadni, A. Lachkar, and S. A. Ouatik, “A new and efficient stemming
technique for arabic text categorization,” in Multimedia Computing and
Systems (ICMCS), 2012 International Conference on. IEEE, 2012, pp.
791–796.
[32] G. Kanaan, R. Al-Shalabi, S. Ghwanmeh, and H. Al-Ma’adeed, “A
comparison of text-classification techniques applied to arabic text,”
Journal of the American society for information science and technology,
vol. 60, no. 9, pp. 1836–1844, 2009.
[33] S. Alsaleem, “Automated arabic text categorization using svm and nb,”
Int. Arab J. e-Technol., vol. 2, no. 2, pp. 124–128, 2011.
[34] F. Harrag, E. El-Qawasmeh, and P. Pichappan, “Improving arabic text
categorization using decision trees,” in Networked Digital Technologies,
2009. NDT’09. First International Conference on. IEEE, 2009, pp.
110–115.
[35] F. Harrag, E. El-Qawasmah, and A. M. S. Al-Salman, “Stemming
as a feature reduction technique for arabic text categorization,” in
Programming and Systems (ISPS), 2011 10th International Symposium
on. IEEE, 2011, pp. 128–133.
[36] M. F. Umer and M. Khiyal, “Classification of textual documents using
learning vector quantization,” Information Technology Journal, vol. 6,
no. 1, 2007.
[37] I. Hmeidi, B. Hawashin, and E. El-Qawasmeh, “Performance of knn
and svm classifiers on full word arabic articles,” Advanced Engineering
Informatics, vol. 22, no. 1, pp. 106–111, 2008.
[38] M. Faqeeh, N. Abdulla, M. Al-Ayyoub, Y. Jararweh, and M. Quwaider,
“Cross-lingual short-text document classification for facebook com-
ments,” in The 2nd International Conference on Future Internet of
Things and Cloud (FiCloud), 2014.
[39] M. K. Saad, “The impact of text preprocessing and term weighting on
arabic text classification,” Master’s thesis, Computer Engineering, The
Islamic University-Gaza, 2010.
[40] D. Said, N. M. Wanas, N. M. Darwish, and N. Hegazy, “A study of
text preprocessing tools for arabic text categorization,” in The Second
International Conference on Arabic Language, 2009, pp. 230–236.
[41] M. S. Khorsheed and A. O. Al-Thubaity, “Comparative evaluation of text
classification techniques using a large diverse arabic dataset,” Language
resources and evaluation, vol. 47, no. 2, pp. 513–538, 2013.
[42] R. M. Duwairi, “Machine learning for arabic text categorization,” Jour-
nal of the American Society for Information Science and Technology,
vol. 57, no. 8, pp. 1005–1010, 2006.
[43] O. Kukushkina, A. Polikarpov, and D. V. Khmelev, “Using literal and
grammatical statistics for authorship attribution,” Problems of Informa-
tion Transmission, vol. 37, no. 2, pp. 172–184, 2001.
[44] N. Thaper, “Using compression for source based classification of text,”
Master’s thesis, MIT, 2001.
[45] W. J. Teahan and D. J. Harper, “Using compression-based language
models for text categorization,” in Language Modeling for Information
Retrieval. Springer, 2003, pp. 141–165.
[46] D. Benedetto, E. Caglioti, and V. Loreto, “Language trees and zipping,”
Physical Review Letters, vol. 88, no. 4, p. 048702, 2002.
[47] B. Schechter, “Fun with your zip program: Sort through texts, and more,”
The New York Times, April 2002.
[48] D. V. Khmelev and W. J. Teahan, “Comment on “language trees and
zipping”,” Physical Review Letters, vol. 90, no. 8, p. 089803, 2003.
[49] D. Benedetto, “Benedetto, caglioti, and loreto reply,” Phys. Rev. Lett
Phys Rev Lett, vol. 90, p. 089804, 2003.
[50] J. Goodman, “Extended comment on language trees and zipping,” arXiv
preprint cond-mat/0202383, 2002.
[51] D. Benedetto, E. Caglioti, and V. Loreto, “On j. goodman’s comment to
“language trees and zipping”,” arXiv preprint cond-mat/0203275, 2002.
[52] D. V. Khmelev and W. J. Teahan, “A repetition based measure for ver-
ification of text collections and for text categorization,” in Proceedings
of the 26th annual international ACM SIGIR conference on Research
and development in informaion retrieval. ACM, 2003, pp. 104–110.
[53] M. Damashek et al., “Gauging similarity with n-grams: Language-
independent categorization of text,” Science, vol. 267, no. 5199, pp.
843–848, 1995.
[54] W. B. Cavnar, J. M. Trenkle et al., “N-gram-based text categorization,”
Ann Arbor MI, vol. 48113, no. 2, pp. 161–175, 1994.
[55] D. V. Khmelev and F. J. Tweedie, “Using markov chains for identifi-
cation of writer,” Literary and linguistic computing, vol. 16, no. 3, pp.
299–307, 2001.
[56] F. Peng, D. Schuurmans, and S. Wang, “Language and task independent
text categorization with simple language models,” in Proceedings of the
2003 Conference of the North American Chapter of the Association for
Computational Linguistics on Human Language Technology-Volume 1.
Association for Computational Linguistics, 2003, pp. 110–117.
[57] ——, “Augmenting naive bayes classifiers with statistical language
models,” Information Retrieval, vol. 7, no. 3-4, pp. 317–345, 2004.
[58] W. J. Teahan, “Text classification and segmentation using minimum
cross-entropy.” in RIAO, 2000, pp. 943–961.
 
600
