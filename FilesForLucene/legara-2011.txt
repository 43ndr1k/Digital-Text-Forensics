Physica A 390 (2011) 110–119
Contents lists available at ScienceDirect
Physica A
journal homepage: www.elsevier.com/locate/physa
Ranking of predictor variables based on effect size criterion provides an
accurate means of automatically classifying opinion column articles
Erika Fille Legara, Christopher Monterola ∗, Cheryl Abundo
National Institute of Physics, University of the Philippines, Diliman, Quezon City, 1101, Philippines
a r t i c l e i n f o
Article history:
Received 15 August 2009
Received in revised form 8 March 2010
Available online 17 March 2010
Keywords:
Author identification analysis
Effect size criterion
Linear discriminant analysis
a b s t r a c t
We demonstrate an accurate procedure based on linear discriminant analysis that allows
automatic authorship classification of opinion column articles. First, we extract the
following stylometric features of 157 column articles from four authors: statistics on high
frequency words, number of words per sentence, and number of sentences per paragraph.
Then, by systematically ranking these features based on an effect size criterion, we show
thatwe can achieve an average classification accuracy of 93% for the test set. In comparison,
frequency size based ranking has an average accuracy of 80%. The highest possible average
classification accuracy of our data merely relying on chance is ∼31%. By carrying out
sensitivity analysis, we show that the effect size criterion is superior than frequency ranking
because there exist low frequency words that significantly contribute to successful author
discrimination. Consistent results are seen when the procedure is applied in classifying
the undisputed Federalist papers of Alexander Hamilton and James Madison. To the best of
our knowledge, the work is the first attempt in classifying opinion column articles, that
by virtue of being shorter in length (as compared to novels or short stories), are more
prone to over-fitting issues. The near perfect classification for the longer papers supports
this claim. Our results provide an important insight on authorship attribution that has
been overlooked in previous studies: that ranking discriminant variables based on word
frequency counts is not necessarily an optimal procedure.
© 2010 Elsevier B.V. All rights reserved.
1. Introduction
With the advent of the digital age, publishing electronic articles online through news websites and the blogosphere is
literally at everyone’s fingertips. As of January 2006, Technorati, an internet search engine for blogs, reported that over
75,000 new weblogs are created everyday. Moreover, the group said that these electronic articles (e-articles) continue to
double about every 5.5 months [1].
This rapid e-article percolation could pose serious problems to society including, but not limited to, authorship-related
cybercrime issues. Authorship analysis is one of the tools used to address such matters. It has been proven to be especially
functional in resolving controversial literary disputes among authors including the tendentious Federalist Papers case, which
involved 12 disputed works and two authors [2]. In the work of Binongo in 2003, he resolved the authorship dispute on the
15th book of Oz by doing principal component analysis on the most frequently used words, finally attributing authorship
to Thompson rather than Baum [3]. Recent works on authorship analysis deal with more practical implementations like
plagiarism detection, verification of the authors of electronic artifacts, and forensic cases, to name a few [4–7].
∗ Corresponding author. Tel.: +63 9209530251; fax: +63 29205474.
E-mail address: cmonterola@gmail.com (C. Monterola).
URL: http://www.nip.upd.edu.ph/ipl/mem/homepages/chris/ (C. Monterola).
0378-4371/$ – see front matter© 2010 Elsevier B.V. All rights reserved.
doi:10.1016/j.physa.2010.03.016
E.F. Legara et al. / Physica A 390 (2011) 110–119 111
Author attribution or identification is one of the principal aspects of author analysis. As the name implies, it determines
the author of a particular piece of writing through comparisons with his or her existing works using quantitative tools and
established techniques in stylometry. In author identification, research shows that classification becomes more arduous
when (1) the number of words in the texts is decreased (i.e. online news articles, newspaper columns and blogs are more
difficult to categorize as opposed to novels and essays) [8] and (2) when the number of authors is increased [8,9]. Moreover,
as in many classification studies, the real challenge is in identifying the optimal set of features (threshold features) that
results in a successful classification performance, since toomanyuseless featuresweaken categorization, a commonproblem
in classification referred to as the ‘‘curse of dimensionality’’ [10–12]. This is because redundant and/or irrelevant predictors
force over-fitting of the input–output mapping, leading eventually to a poorer generalization performance.
In this paper, we extract the stylometric features of 157 opinion column articles from four different column authors. We
demonstrate an automatic author identification procedure that compares and contrasts the accuracy obtained by ranking
discriminant parameters based on an effect size criterion as opposed to frequency of word counts. The effect size criterion
provides a quantitative measure of both the correlation and variance similarity of two statistical sets of data, and has been
extensively used in the biosciences to determine the degree to which a given variable predicts another parameter [13].
Our results reveal that the proper choice of the optimal set of writing-style features is critical in improving the predictive
accuracy of the classifier based on linear discriminant analysis (LDA). Finally, we do sensitivity analysis on the predictor
variables to understand the structure of the parameter space that yields the best classification protocol.
2. Feature selection and analysis
In this section we discuss briefly the different stylometric features we have extracted for authorship identification. We
also compare and contrast the methods we have implemented with existing literature whenever applicable. Classification
of column articles, to our knowledge, has not been done. Moreover, it provides a unique challenge for author identification
since its word statistics are inherently sparse, in contrast with novels and/or short stories. In particular, it is known that as
the number of words is decreased, accrediting a specific work to a particular author becomes less accurate [8].
2.1. Article and author sampling
We obtained from the online archives the articles (total = 157) of four well-read Filipino columnists namely: Ambeth
Ocampo (36 articles, designated as Author 1), Conrado de Quiros (46 articles, Author 2), Randy David (31 articles, Author 3),
and Solita Monsod (44 articles, Author 4). The articles appeared from 2005 to 2009 in the Philippine Daily Inquirer (PDI)—
the most subscribed daily newspaper in the country that uses English as the medium language. In the July 2009 survey
conducted by Nielsen Media Research, one of the leading providers of advertising information services worldwide, about
964,000 or 49% of daily Filipino readers subscribed to PDI (population of the Philippines is ∼89 million in 2008). More than
half of the articles are opinions in politics and governance issues concerning the incumbent administration of President
Gloria Macapagal-Arroyo.
2.2. Extracting author-style features
Extracting stylometric features in authorship analysis is a well-researched field. The different writing-style features,
which are quantitative representations of the different writing-styles of writers, can be divided into four types, namely:
syntactic, structural, lexical and content-specific features [14].
Looking at the sentence-level, an author’s ‘‘writeprint’’ may be revealed through an article’s syntactic features. These
include the function words (words that are ‘‘content-free’’) and punctuation. Binongo, in 2003, used these syntactic features
in his study on the 15th book of Oz, where he focused on the frequency of function words in the literary piece [3]. Structural
features, on the other hand, involve statistics such as the number of words per sentence and the number of sentences
in a paragraph, including the use of indentation. Using these features, de Vel et al. obtained a successful classification
performance for author identification of emails [5]. Finally, lexical features involve character-based andword-based features,
while content-specific features involve keywords in a specific topic.
For the purposes of our research, we limit the discriminating variables to lexical, syntactic and structural features
only. Specifically, we have extracted the following: (1) frequency of the words being used, (2) sentence length statistics
(SLS, mean and standard deviation) and (3) sentences per paragraph statistics (SPS, mean and standard deviation). With
about 1000 feature vectors reportedly used in awide-range of authorship analysis studies [15], limiting the variable features
to lexicon, syntax and structure does not substantially reduce the possible number of features that can be considered.
2.3. Linear discriminant analysis
Linear discriminant analysis is the most common classifier and is the standard gauge of most classifier methods. The
discriminant function is given by the expression
Zi = λi0 + λi1x1 + λi2x2 + · · · + λinxn, (1)
112 E.F. Legara et al. / Physica A 390 (2011) 110–119
Table 1
Addition of writing-style features. Two general methods were used in this study. The first one is the frequency ranking method (FRM), where features were
added systematically to the analyses according to their frequency, starting with the word that has the highest frequency (set A). The second method is the
effect size ranking method (ESRM), where features were added according to their effect size ratio with the dependent variable, starting with the word that
has the highest effect size ratio (set A). These two methods were again implemented by adding the four syntactic and structural features SLS and SPS prior
to the systematic addition (set B).
Set A Set B
Frequency ranking method *high frequency words →
(1) Sentence length mean
(2) Sentence length standard deviation
(3) Number of sentences per paragraph mean
(4) Number of sentences per paragraph standard deviation
*high frequency words →
Effect size ranking method *high effect size ratio →
(1) Sentence length mean
(2) Sentence length standard deviation
(3) Number of sentences per paragraph mean
(4) Number of sentences per paragraph standard deviation
*high effect size ratio →
where {λin} are weights that intend to maximize the inter-group variances compared to the within-group variances. In the
LDAmethod, an n-dimensional set of predictors {x1, x2, . . . , xn} is reduced to an inumber of variables called the discriminant
scores Zi. The maximum number of discriminant functions that can define a classification problem is given by the number
of classes minus one, or the number of predictors, whichever is smaller [11]. For author identification, three discriminant
functions are necessary to discriminate among all four authors. A threshold value determines the class to which a specific
case will be classified.
2.4. Proportional chance criterion
A common yardstick in ascertaining the success of a classifier in comparison with random chance prediction is the
proportional chance criterion ΦPCC. The value of ΦPCC is the highest average success rate due to random guess, and is given
by the expression:
ΦPCC = p2author1 + p
2
author2 + p
2
author3 + p
2
author4, (2)
where pi is the proportion of articleswritten by author i over the population. As a suggested rule of estimating the acceptable
level of classification accuracy, a procedure S is considered as a successful classifier if ΦS > 1.25 ∗ ΦPCC [11]. For the data at
hand, ΦPCC ∼ 31%, and 1.25 ∗ ΦPCC ∼ 39%.
3. Systematic addition of features: frequency ranking method (FRM) vs effect size ranking method (ESRM)
Bearing in mind that both insufficient or too many predictor variables could hamper classification accuracy, there is
a need for a technique that can optimally find the most appropriate variable combinations. Scanning all the possible
combinations from a set of N-predictor variables to find the feature set that yields the highest prediction entails testing N!
variable combinations. However, suchmethodology is not acceptable for practical reasons (case in point: for∼100 variables
as used here, the total possible combinations will be in the order of 10157).
Here, we performed systematic addition of features in two ways that we refer from hereon as set A and set B. For
set A, we started with one writing-style feature and then routinely increased the number of features by incrementing it
with another feature. For set B, the process in Set A is repeated except that four auxiliary syntactic and structural features
(SLS and SPS) were included a priori in all the sets. By implementing such procedures, we are able to show that there exists
an optimal set of writing-style features that optimizes the trade-off between over-fitting (‘‘curse of dimensionality’’ issues)
and under-fitting (insufficient predictor parameters).
We then ranked the features methodically based on either frequency of words or effect size criterion. The frequency
ranking method (FRM) proceeds with the addition of features starting with the word that has the highest frequency
(FRM set A). Another set is implemented (FRM set B) with the inclusion of SLS and SPS in the FRM variables. The next
procedure, which is referred to as the effect size ranking method (ESRM), makes incremental addition of feature variables
by first considering the predictor parameters with a high effect size ratio with the dependent variable (ESRM set A). In
exact analogy with FRM, another ESRM set B is implemented by adding SLS and SPS. Table 1 illustrates the four procedures
implemented in this paper (FRM set A, FRM set B, ESRM set A, ESRM set B).
To solve for the different effect size ratios, we used Cohen’s distance d [13] given by:
d = (⟨xi⟩ − ⟨xj⟩)/s, (3)
E.F. Legara et al. / Physica A 390 (2011) 110–119 113
Table 2
Frequency vs effect size ranking. The table lists the top 40 words ranked according to two different criteria: frequency and effect size values. It is apparent
that high-frequency words do not necessarily correspond to high effect size values.
Rank Freq Effect size Rank Freq Effect size
1 the you 21 have government
2 of to 22 but first
3 to political 23 this is
4 and not 24 or no
5 in of 25 from do
6 a was 26 his Philippines
7 is and 27 they just
8 that which 28 has some
9 it that 29 one if
10 for well 30 who at
11 not I 31 at national
12 was being 32 we world
13 as it 33 their because
14 on these 34 an my
15 he has 35 what only
16 I or 36 all a
17 with this 37 there against
18 be their 38 more than
19 by like 39 can about
20 are country 40 will him
where ⟨xi⟩ and ⟨xj⟩ are the average values of a discriminating variable for cases of two classes (i.e. two authors), and s is the
pooled standard deviation given by:
s =

(ni − 1)s21 + (nj − 1)s
2
2
ni + nj
. (4)
Here, n1 and n2 are the numbers of cases belonging to author i and author j respectively, and si and sj are the standard
deviations of each of the classes. Since our analyses involve four different classes, s is subsequently solved for d using all pairs
of classes (i.e. 1–2, 1–3, etc.), and the effective d is taken by averaging d over the ensemble of pairs. This criterion allows us
to find the appropriate predictors that best discriminate the cases into the four different classes.
The method employed also minimizes the variability of each of the predictors within cases belonging to the same class,
ensuring the repeatability of the classification prediction [13]. In Table 2, we list the top 40 words according to FRM and
ESRM values. It is evident in the list that high-frequency words do not necessarily correspond to high effect size values.
4. Results and discussion
4.1. Frequency Ranking Method (FRM)
Most literature on author identification analysis implemented the technique of extracting high-frequency words and/or
frequency of function words. In particular, it was applied by Burrows [16], Mosteller [2], and Binongo [3] for author
identification (<3 authors) of short stories and novels. Below, we investigate the performance of a similar technique when
tasked to attribute column articles into four different authors.
Fig. 1 shows the accuracy in author identification as a function of the number of discriminating variables ranked based
on FRM. The success accuracy (ΦFRM or ΦESRM ) is given as the ratio of the correctly classified states over the total states to be
classified.We divided our data into two sets: the training set or the data thatwe used to fix theweights of the LDA algorithm,
and the test set where we made the predictions and hence served as our validation set. We fixed the training:test ratio at
80%:20% following the validation requirement imposed in previous studies [11,12,17].
Results suggest that for the training set (empty and filled circles), the identification performance of FRM for both set A
and set B reaches 100% as the number of discriminators or feature variables is increased (i.e., for training set:ΦFRM → 100%).
The addition of the auxiliary features SLS and SPS (set B) improves the prediction rate (test set ΦFRM ) on the average
by 2.3%. The most successful identification performance is observed when 46 writing-style features are utilized, with
ΦFRM = 80.3% ± 2.9% for the test set. The general trend of decreasing test set ΦFRM for variables > 90 verifies the presence
of the ‘‘curse of dimensionality’’ for the problem at hand.
4.2. Effect size ranking method
We now exploit the potential of effect size values in systematically choosing the variable combination that is optimal for
classification. To our knowledge, the use of effect size criterion in authorship analysis has never been explored, although it
has been a very common procedure in identifying the most effective predictor variables in biosciences-related studies [13].
The effect size values determine the magnitude to which a variable affects the experimental group more than the control
114 E.F. Legara et al. / Physica A 390 (2011) 110–119
Fig. 1. Color online. Success rate of the LDA-based classification using frequency ranking method (FRM) for the first 100 predictor variables. Error bars are
standard deviations of five-trial averages. Circles are from the training sets and squares are the from the test set. The dashed line highlights the combination
of 46 variables (42 frequencywords+ 4 SLS and SPS) that gives the highest averageΦFRM for the test set. Starting at the∼43rd rank frequencyword variable,
the average ΦFRM for the training set is ∼100%.
group [18]. Psychological research also contain reports of using effect sizemeasures in determining the strength of a certain
variable’s effect to a phenomenon being studied [19].
Most works on author attribution are not concernedwith the ranking of the discriminant variables [20–25]. For instance,
in Burrows’ works, where he introduced the concept of Delta measure, statistical correlation such as t-test was done not to
select the discriminant variables but to determine the closeness of Delta values computed from the target and the sample
text [20,22]. Delta as defined by Burrows compares the average of ‘‘the absolute difference between the z-scores for a set
of word variables in a given text-group and the z-scores for the same set of word-variables in a target text’’ [20]. The t-test
statistics ascertain whether the difference in themean is due to random sampling error alone or is representative of the true
difference [11].
Here, we systematically rank our variables in terms of their strength in identifying the authors of each article in our
sample. Since we are concerned with the magnitude to which a particular variable separates our data into different author
groups, a measure of actual effect (like the effect size) and not merely of statistical significance is more helpful.
We initially calculated the effect size ratios of all discriminating variables to each of the pairs of output variables and
ranked them based on their ensemble averages (see Section 3). By systematically increasing the features selected based
on this criterion, the training set ΦESRM → 100%, closely resembles the trend behaviour of FRM. However for the test set,
the best average performance of our classifier has significantly improved to ΦESRM = 93.0 ± 3.9%, which is 12.7% more
accurate than the highest test ΦFRM , and about three-fold that of ΦPCC ∼ 31%. Note that the increase happens when, (1) the
auxiliary features are added (set B), and (2) the ranking is based on effect size. Moreover, the optimal set of writing-style
features has been reduced to 36 variables (from46 in FRM), implying that a lesser number of variables is required for optimal
classification via ESRM. As in FRM, the ‘‘curse of dimensionality’’ resulting in a fluctuating but decreasing trend in test ΦESRM
is observed as the number of features is increased continuously (Fig. 2).
The confusion matrix of the LDA classifier (Table 3) shows that the main source of error is the misclassification of author
4 as either author 2 or author 1. Togetherwith the near perfect classification of articles that belongs to author 2, this suggests
that the LDA weights are relatively biased towards author 2. We conjecture that this can be partly attributed to the unequal
group proportions in the study with author 2 having the most articles in the sample population. Fig. 3 shows the four
distinct regions on a territorial map for the four authors, and the existence of some data from author 4 residing in the
regions of authors 1 and 2. Note that author 3 is perfectly classified with no false negatives or false positives, implying that
the discriminant Zi-region spanned by author 3 is highly distinct from the other authors. Again, the map of Fig. 3 visually
confirms the distinct confinement in the discriminant Z space of articles belonging to author 3.
In summary, we illustrate in this section that for the opinion column articles at hand, it is more effective to implement
ESRM than the commonly adapted procedure of FRM. While it is an open question whether there are other ranking
procedures that can beat ESRM, our study clearly indicates that previous literature for authorship identification might
benefit from doing systematic ranking different from FRM.We expect that this result can be extended to nonlinear methods
such as neural networks [26,27] since ‘‘curse of dimensionality’’ issues plague all fundamental classification algorithms. We
elaborate on this result by performing sensitivity analysis on the predictor variables during the LDA classification [11].
4.3. Sensitivity analysis of predictor variables
Linear discriminant analysis for this particular authorship classification study requires three discriminant functions to
separate the data set into four different author regions. Using the three discriminant functions,we let the normalized average
E.F. Legara et al. / Physica A 390 (2011) 110–119 115
Fig. 2. Color online. Success rate of the LDA based classification using the effect size ranking method (ESRM) for the first 100 predictor variables. Error bars are
standard deviations of five-trial averages. Circles are from the training sets and squares are the from the test set. The dashed line highlights the combination
of 36 variables (32 frequency words + 4 SLS and SPS) that gives the highest average ΦESRM for the test set. Starting at the ∼33rd rank frequency word
variable, the average ΦESRM for the training set is ∼100%.
Fig. 3. Color online. Territorial map. A representative trial for author attribution showing visually the prediction accuracy of our proposed effect size ranking
method in feature selection and using LDA.
value of the coefficients or weights {λin} in Eq. (1), be the quantitative measure of xn’s contribution to the classification
accuracy (test set ΦFRM or test set ΦESRM ) [11,12].
In Figs. 4 and 5, the top five frequency variables in terms of normalized importance are shown for two particular cases
of LDA authorship classification analysis, when (1) the prediction accuracy (ΦFRM or ΦESRM ) is highest and when (2) 100
frequency words are used.
For the set Bmethods (FRMset B and ESRMset B), the structural variables SLS and SPS are shown togetherwith the top five
frequency variables. Cases (1) and (2) of the set Bmethods show that the SPS variables (sentence per paragraphmean and the
sentence per paragraph standard deviation) consistently have the highest normalized importance except in some instances
where dips are observed. In contrast, the SLS variables (words per sentence mean and standard deviation) do not contribute
significantly to the discriminant function. The increase in prediction accuracies observed in the addition of the four structural
variablesmay then be attributed to the inclusion of the SPS variables (sentence per paragraphmean and standard deviation).
The length limitation of column articles could have caused the significant variation in the sentence per paragraph statistics
used by the authors, since increasing or decreasing the number of sentences per paragraph can subsequently lengthen or
shorten the space that an article needs to occupy. Furthermore, the dips seen in the normalized importance of the SPS
116 E.F. Legara et al. / Physica A 390 (2011) 110–119
Fig. 4. Color online. Normalized importance of discriminating variables for FRM. The five frequency variables with the highest normalized importance are
shown for two specific cases of interest, namely when (1) ΦFRM is the highest (set A: 62 frequency words, set B: 42 frequency words + SPS and SLS) are
used, and when (2) 100 frequency words are used. These variables of FRM (set A) cases (1) and (2) are presented in (a) and (b) respectively. Similarly, these
variables of FRM (set B) cases (1) and (2) are shown in (c) and (d) together with the SLS and SPS.
Table 3
Confusion matrix for author identification. The averages are taken over five different random training (80%) and test (20%) set samplings.
Author 1 Author 2 Author 3 Author 4
Training set
Author 1 100 0 0 0
Author 2 0.58 ± 1.30 99.42 ± 1.30 0 0
Author 3 0 0 100 0
Author 4 2.14 ± 1.20 0 0 97.86±1.20
Test set
Author 1 88.34 ± 16.23 3.34 ± 7.47 0 8.34± 11.79
Author 2 0.58 ± 1.30 99.42 ± 1.30 0 0
Author 3 0 0 100 0
Author 4 4.44 ± 6.08 14.44 ± 5.10 0 79.12±1.20
variables for certain combinations of discriminating variables show that in the presence of some variables, the predictive
power of a generally good discriminant variable decreases. Hence, finding the optimal set of variables is important for a
successful classification.
Looking at the top five variables in case (1) of FRM and ESRM, we see that three of the top five variables of ESRM set
A as shown in Fig. 5a have significant contributions (FRM set A: 0.60, 0.15, 0.16, 0.16, 0.30; ESRM set A: 1.00, 0.02, 0.43,
0.11, 0.60) even when all the frequency words have been added. In contrast, the normalized importances of the top five
variables in FRM set A are shown in Fig. 4a to decrease as more variables are added and only one of its top five variables
E.F. Legara et al. / Physica A 390 (2011) 110–119 117
Fig. 5. Color online. Normalized importance of discriminating variables for ESRM. The five frequency variables with the highest normalized importance are
shown for two specific cases of interest, namely when (1) ΦESRM is the highest (set A: 16 frequency words, set B: 32 frequency words + SPS and SLS) and
when (2) 100 frequencywords are used. These variables of ESRM (set A) cases (1) and (2) are presented in (a) and (b) respectively. Similarly, these variables
of ESRM (set B) cases (1) and (2) are shown in (c) and (d) together with the SLS and SPS.
remains significant. Similarly, comparing case (1) of FRM set B shown in Fig. 5c with case (1) of ESRM set B shown in Fig. 5c,
the top five variables of ESRM has a relatively greater contribution (FRM set B: up to 0.21; ESRM set B: up to 0.43) to the
classification result when all the frequency words have been added. This suggests that the effect size criterion is a better
basis in ranking the variables in terms of predictive ability than the frequency criterion.
We now look at the five variables with the highest normalized importance in case (2) of FRM and ESRM. Note that
here, since we are using all the 100 frequency words, the five highest variables in FRM set A and ESRM set A are the
same, as well as in set B of FRM and ESRM (FRM and ESRM set A: {being, even, last, against, these}; FRM and ESRM set
B: {these, being, against, only, over}). It is seen from Figs. 4b,d and 5b,d, that the rank of the top five variables for both sets
A and B are higher in ESRM than in FRM (set A: FRM—66, 67, 84, 98, 7; ESRM—11, 52, 67, 36, 13; set B: FRM—71, 67, 99, 49,
94; ESRM—14, 12, 37, 35, 68). This additionally demonstrates that the set of variables used in ESRM are better predictors
than that used in FRM and hence the higher prediction accuracy attained in ESRM.
The top five variables in cases yielding the highest prediction accuracywere not necessarily the top five variables in cases
when 100 frequency words were used. This further supports our finding that the presence of too many classifiers dampens
the predictive capability of a potentially significant variable and that the classification system potentially suffers from the
‘‘curse of dimensionality’’. It is also interesting to note that the only exception is the word being which is the top one in case
(2) of both ESRM and FRM, and is also always included in the top five variables of the ESRMmethod. The highest prediction
accuracy of authorship classification attained using the ESRM method may thus have also been due to the inclusion of the
word being in the variable set.
By analyzing the trend of the variables with the highest contribution to the discriminant functions in terms of their
average normalized weights, we find that (1) the inclusion of SPS variables is significant in achieving a high prediction
118 E.F. Legara et al. / Physica A 390 (2011) 110–119
Fig. 6. Color online. Success rates (test sets) of the LDA based classification using effect size ranking method (ESRM, circles) and (FRM, squares) for the first 30
predictor variables. Error bars are standard errors of five-trial averages. The accuracy of classifier predictions and their corresponding standard errors are
seen to be constant from the 20th to the 30th ranked variables. We note that this asymptotic behavior extends until the 100th ranked variable.
accuracy, (2) there exists an optimal set of discriminating variables, and correctly identifying them is essential to the
classification performance and (3) ESRM performs better than FRM in identifying the variables that must be included in
the feature set, since there exist low frequency words that are important in attaining high prediction accuracy.
4.4. Method tested in Federalist papers
To test the robustness of our proposed method, we have applied both the systematic addition through ESRM and the
FRM on the undisputed Federalist papers of Alexander Hamilton and James Madison [28]. For the training set, we utilized
80% of the 28 randomly selected articles written by Hamilton (10 articles) and Madison (10 articles). We used the remaining
essays as the test set (four for Hamilton and four for Madison). In contrast with the opinion column articles, which contain
an average of 951± 54 words, these short essays consist of 2211± 738 words on the average, with a maximumword count
of 5705 in one of the articles. Moreover, compared to the initial analyses on the opinion column articles, where we have
included four different authors, only two authors are involved here.
Fig. 6 shows that for these essays, the test set classification accuracy as compared to the column articles is higher and
requires a lesser number of discriminators. Mainly, we can attribute this improvement to the longer length of the Federalist
papers and to the lesser number of authors we have classified. Consistent with our results for opinion column articles,
ranking based on ESRM proves to be superior as compared to FRM for both the training and test sets. For the training sets
(figure not shown), perfect classification using FRM ranking requires six discriminators for set A and five (plus four auxiliary:
2 SLS+ 2 SPS) variables for set B. In comparison, ESRM ranking is achieved after only three discriminators for set A and three
(plus four auxiliary) variables for set B.
For the test sets (Fig. 6), we find that FRM ranking requires nine discriminating variables for set A to yield a perfect
classification. For the FRM Set B, the highest average prediction accuracy over five trials was only 92.5% ± 5.0% requiring
five (5) discriminators (plus the four auxiliary ones). On the other hand, ESRM ranking needs only four discriminators for set
A and another four (plus four auxiliary ones) for set B to reach a perfect prediction accuracy. Again, these results demonstrate
that frequency word counts are not necessarily optimal in identifying which discriminating variables to use in authorship
analysis. The decreasing trend from variables 10 to 15 in Fig. 6 also shows that similar to column articles, the accuracy of
Federalist papers classification is affected by over-fitting or ‘‘curse of dimensionality’’.
5. Conclusion
We have introduced the idea of using an effect size ratio measure in systematically ranking the discriminant variables
prior to linear discriminant analysis classification. We have shown that this ranking procedure, at least for opinion column
articles, is superior to the standard frequencyword countmethod that has been employed inprevious literature [2,3,8,16,25].
In particular, we have achieved an average test accuracy of 93% for column articles using an ESRM in LDA classifier, which
is three-fold higher than chance and ∼12% better than FRM-based LDA. Consistent results have been observed when the
procedure is applied to the Federalist papers where ESRM produced a perfect test classification while FRM only achieved
92.5% test accuracy. Moreover, a lesser number of discriminant variables are needed for ESRM, as compared to FRM, to
reach the optimal success rate.
The study is the first attempt in classifying opinion column articles that are more prone to the ‘‘curse of dimensionality’’
dilemma by virtue of being shorter in length as compared to essays, short stories or novels. While it is an open question
E.F. Legara et al. / Physica A 390 (2011) 110–119 119
Fig. 7. Zipf’s Law. The distribution of words when all articles per author are combined result in a power-law distribution more commonly known in
linguistics as Zipf’s Law (f (x) = ax−γ ; above: γ = 0.93 ± 0.04 with R2 = 0.96).
whether there are other ranking procedures that can beat the use of effect sizemeasures discussed here, our results indicate
that previous literature for authorship identification can benefit by doing selection of variables other than word count
frequency ranking.
Finally, we note that, although each column article is relatively short in nature in terms of word count, when more than
30 articles of a given author are combined, the histogram distribution of words follow Zipf’s law—a power law statistical
distribution ofword frequencies observed inmostwritten text (see Fig. 7) [29,30]. The presence of Zipf’s law in the collection
of column articles is indicative of our work’s general similarity to the previously studied short novels and/or short stories.
This implies that the procedure developed here can possibly be extended in ascertaining the originality and syntactic
consistency of a segment or short portions of a long article.
References
[1] Dave Sifry, State of the blogosphere, February 2006 part 1: on blogosphere growth, Technocrati blog. Report posted: February 6, 2006. Retrieved date:
July 15, 2009. http://technorati.com/weblog/.
[2] F. Mosteller, D.L. Wallace, Inference and Disputed Authorship: The Federalist, Addison-Wesley, Reading, MA, 1964.
[3] J.N. Binongo, Chance 16 (2) (2003) 9–17.
[4] O. de Vel, Proc. workshop on text mining, in: ACM International Conference on Knowledge Discovery and Data Mining, KDD2000, 2000.
[5] O. de Vel, et al., SIGMOD Record 30 (4) (2001) 55–64.
[6] R. Zheng, J. Li, H. Chen, Z. Huang, Journal of the American Society for Information Science and Technology 57 (3) (2006) 378–393.
[7] V. Guillen-Nieto, et al., International Journal of English Studies 8 (1) (2008) 1–28.
[8] G.R. Ledger, T.V.N. Merriam, Literary and Linguistic Computing 9 (1994) 235–248.
[9] J.N. Binongo, D.P. Mays, Communications in Statistics: Simulation and Computation 34 (2005) 293–308.
[10] J. Jin, Proceedings of the National Academy of Science 106 (22) (2009) 8859–8864.
[11] J.F. Hair, R. Anderson, R. Tatham, W. Black, Multivariate Data Analysis, 5th ed., Prentice-Hall, Inc., New Jersey, 1998, pp. 268–270.
[12] C. Monterola, C. Abundo, J. Tugaff, L.E. Venturina, International Journal of Modern Physics C 11 (2009) 1697–1718.
[13] A. Fielding, Cluster and Classification Techniques for the Biosciences, 1st ed., Cambridge University Press, New York, 2007.
[14] H. Liu, H. Motoda, Feature Selection for Knowledge Discovery and Data Mining, Kluwer Academic Publishers, Norway, MA, 1998.
[15] J. Rudman, Computers and the Humanities 31 (1998) 351–365.
[16] J.F. Burrows, Literary and Linguistic Computing 2 (1987) 61–67.
[17] C. Monterola, M. Lim, J. Garcia, C. Saloma, Journal of Forecasting 21, 435–449.
[18] S. Nakagawa, I. Cuthill, Biological Reviews Cambridge Philosophical Society 82 (2007) 591–605.
[19] A. Brand, M.T. Bradley, L.A. Best, G. Stoica, Perceptual and Motor Skills 106 (2008) 645–649.
[20] J. Burrows, Style 36 (2002) 677–699.
[21] J. Burrows, Literary and Linguistic Computing 17 (2002) 267–287.
[22] J. Burrows, Computers and the Humanities 37 (2003) 5–32.
[23] D. Hoover, Literary and Linguistic Computing (2004) 453–475.
[24] E. Stamatatos, Journal of the American Society for Information Science and Technology (2009) 538–556.
[25] M. Koppel, J. Schler, S. Argamon, Journal of the American Society for Information Science and Technology (2008) 9–26.
[26] C. Monterola, C. Saloma, Phys. Rev. Lett. 89 (2002) 188102.
[27] C. Monterola, M. Zapotocky, Phys. Rev. E 71 (2005) 036134.
[28] D.I. Holmes, R.S. Forsyth, LIterary and LInguistic Computing 10 (1995) 111–127.
[29] W. Dahuia, L. Menghuib, D. Zengrub, Physica A 358 (2005) 545–550.
[30] M. Montemurro, Physica A 300 (2001) 567–578.
