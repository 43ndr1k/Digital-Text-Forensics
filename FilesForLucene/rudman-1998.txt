Computers and the Humanities 31: 351–365, 1998.
© 1998 Kluwer Academic Publishers. Printed in the Netherlands.
351
The State of Authorship Attribution Studies: Some
Problems and Solutions
JOSEPH RUDMAN
Carnegie Mellon, Pittsburgh, Pennsylvania 15213, U.S.A. (e-mail: rudman@cmphys.phys.cmu.edu)
Key words: authorship attribution, statistics, stylistics
Abstract. The statement, “Results of most non-traditional authorship attribution studies are not
universally accepted as definitive,” is explicated. A variety of problems in these studies are listed
and discussed: studies governed by expediency; a lack of competent research; flawed statistical tech-
niques; corrupted primary data; lack of expertise in allied fields; a dilettantish approach; inadequate
treatment of errors. Various solutions are suggested: construct a correct and complete experimental
design; educate the practitioners; study style in its totality; identify and educate the gatekeepers;
develop a complete theoretical framework; form an association of practitioners.
1. Introduction
Non-traditional authorship attribution studies – those employing the computer,
statistics, and stylistics – have had enough time to pass through any “shake-down”
phase and enter one marked by solid, scientific, and steadily progressing studies.
But, after over 30 years and 300 publications, they have not.
These studies (experiments) must not only form and force a consensus on
methodology among their practitioners but they also must demand an intellectual
and a scientific respect for and belief in their results. This is lacking. There is more
wrong with authorship attribution studies than there is right.
In this paper I attempt to:
1. Show that serious problems exist in non-traditional attribution studies;
2. Detail a few of the more common or crucial problems;
3. Highlight some solutions.
But most of all I would like to fuel a concerted effort to look at this field in a
scientific way – to treat each study as a unique, hard scientific experiment with the
concomitant controls, rigor, reproducibility, open availability of all data, programs
and tests performed, and with a well articulated theoretical framework.
There are many more problems and solutions than those treated below. There
also is a real need to list and discuss what is “right” with non-traditional authorship
attribution studies. Many practitioners have done credible work and have advanced
352 JOSEPH RUDMAN
the field. However, this paper concentrates on the majority of studies – studies that
evidence major problems.
Nor can the question whether all of the building blocks of non-traditional
authorship studies are set on a solid foundation or on quicksand be treated in this
paper. An in-depth book length treatment of every facet of the field is forthcoming.
2. Problems Exist
The Bibliographies of stylistics contain thousands of titles, there is no lack
of observed facts; however, the polysemy of concepts, the imprecision of
methods, the uncertainty about the very goal of this research hardly make for a
prosperous discipline.
Todorov1
The results of most non-traditional authorship attribution studies are not universally
accepted as definitive. One major indication that there are problems in any field
is when there is no consensus on results, no consensus as to accepted or correct
methodology, and no consensus as to accepted or correct techniques. An even
stronger indication of problems is disagreement over many of the underlying
assumptions – in our case in the “core” fields of statistics and stylistics – assump-
tions such as the consciousness or unconsciousness of style or the randomness of
word selection.
I am not the first to point out this lack of consensus. Others, Ledger,2 Brunet,3
and Burrows,4 to name just a few, describe aspects of this debilitating fact. But
so far with little effect. It seems that for every paper announcing an authorship
attribution method that “works” or a variation of one of these methods, there is a
counter paper that points out real or imagined crucial shortcomings:
• Even as early as 1903, Robert Moritz pointed out major flaws in the
1888 “Sherman principle” of sentence length as an indicator of style and
authorship;5
• Mealand called Neumann’s heavy reliance on discriminant analysis
“problematic”;6
• Donald McNeil pointed out that scientists strongly disagree as to Zipf’s Law;7
• Christian Delcourt raised objections against some uses of co-occurrence
analysis;8
• Portnoy and Peterson pointed out what they considered errors in Radday and
Wickmann’s use of the correlation coefficient, chi-squared test, and t-test;9
• Hilton and Holmes showed problems in Morton’s QSUM (cusum)
technique;10
• Smith raised many objections against Morton’s early methods;11
• In fact, Morton’s methods have been assailed since 1965 when Ellisone said
that Morton’s methods were, “. . . an abuse of both computers and scholar-
THE STATE OF AUTHORSHIP ATTRIBUTION STUDIES 353
ship.” “When put to the same tests . . . [Morton’s] own writings seemed to
bear the stamp of multiple authorship”;12
• There are the lengthy and well documented Merriam versus Smith con-
troversies;13
• Foster’s attribution of “A Funeral Elegy” to Shakespeare is under fire;14
• And there is the current Foster versus Elliott and Valenza brouhaha unfolding
on the pages of Computers and the Humanities.15
This widespread disagreement not only threatens to undermine the legitimate
studies in the court of public and professional opinion but it also has kept author-
ship attribution studies out of most United States court proceedings. For example,
the judge in the Patty Hearst trial ruled that Dr. Singer’s testimony on stylistic
comparisons should not be admitted into evidence.16 Great Britain’s judicial
system, which accepts authorship attribution as a legitimate science, is faced with a
serious quandary since one of its star expert witnesses in these cases, Morton, had
his method seemingly debunked on live television.17
The cause of so much disagreement and misunderstanding is not always on the
part of the reader. The onus of competency, clarity, and completeness is on the
practitioner. The researcher must document and make clear every step of the way.
No smoke and mirrors, no hocus-pocus, no “trust me on this.”
There is also a lack of continuity. Many, if not most of the attribution studies
are done by a “one problem” practitioner with no long range commitment to the
field. This might always be a problem, but understandably so. Once a scholar’s
specific attribution study is completed (with or without valid results), why should
that scholar continue with other attribution studies in alien fields.
Non-traditional authorship attribution studies bring a unique problem to inter-
disciplinary studies: who is the authority? who is the experimental spokesman?
the group leader? Is it the linguist? the statistician? the computer scientist? the
rhetorician? Is it the expert in the field of the questioned work: literature? classics?
law? philosophy? religion? economics?
What journal or journals do we turn to for an imprimatur or even a nihil obstat.
A quick scan of my working bibliography shows that non-traditional authorship
attribution studies have been published in well over 76 journals representing 11
major fields – not to mention the 50 or so books, 11 dissertations, and numerous
conference proceedings.
3. Problems
As the problems are discussed, I am not going to list all of the specific references
to the flawed research. Rather, I will list generic problems and give some specific
examples. I would like as much as possible to avoid even the appearance of ad
hominem attacks and mere polemics.
354 JOSEPH RUDMAN
PROBLEM (1)
Most authorship attribution studies have been governed by expediency, e.g.:
1. The copy text is not the one that should be used but it was available in electronic
form and isn’t too bad.18
Neither time constraints nor funding constraints should preclude the correct
copy text.
2. This is not how the data should have been treated but the packaged program
that I used didn’t do exactly what I wanted.
Never let the computer program dictate the design of the experiment. Practi-
tioners should at least understand enough about programming to know what
the computer can and cannot do.
3. The control data aren’t complete but it would have been too complicated to
input the complete set.
4. The control data are not from the correct time period (authors, genre) but they
were available in machine readable form.
5. I only had one year to do the research and the study, so some corners had to be
cut.
It is important that both readers and practitioners realize that there is nothing,
nothing in an authorship attribution study that is beyond the responsibility of the
practitioner. If you are planning a study and cannot get the correct electronic texts,
or you realize that control texts do not exist, do not do the study. If packaged
programs cannot do the needed analysis, either write the program, hire it out, or do
not do the study.
PROBLEM (2)
There is a lack of competent and complete bibliographical research and there
is little experimental memory. Researchers working in the same subject area of
authorship attribution often fail to cite and make use of pertinent previous efforts.
Willard McCarty’s recent posting on Humanist, although in a more general context,
points this out:
. . . scholarship in the field is significantly inhibited, I would argue, by the low
degree to which previous work in humanities computing and current work in
related fields is known and recognized.19
How many authorship attribution practitioners are aware of William Benjamin
Smith who, under the pen name of Conrad Mascol, published two articles, one in
1887 and the other in 1888 describing his “curve of style.”20 This is the same year
– 1887 – that Mendenhall published his “Characteristic Curves of Composition.”21
But Smith is just not mentioned. In 1888, Sherman’s “principle of sentence length
as an indicator of style and attribution” was published, but Sherman is very rarely
mentioned. Mendenhall is usually cited as if in a vacuum.
THE STATE OF AUTHORSHIP ATTRIBUTION STUDIES 355
Kenneth Neumann’s impressive 1990 dissertation, The Authenticity of the
Pauline Epistles in the Light of Stylostatistical Analysis, didn’t reference Mascol’s
two 1888 articles on the “Curves of Pauline and Pseudo-Pauline Style.”22
Most of us are aware of David Holmes’ “The Analysis of Literary Style –
A Review.”23 It is one of the most referenced works on authorship attribution
studies. But, how often has Gerald McMenamin’s excellent 1993 book, Forensic
Stylistics,24 been referenced?
How many studies and articles written in English reference the untranslated
works from the French, the German, the Russian, and other languages.
PROBLEM (3)
Professor G.E.P. Box and Dr. F. Yates expressed reservations about the
encouragement of unthinking manipulation of numbers. We share their view
that statistical methods should not be applied to numbers but rather to the
situations giving rise to the data.
Andrews & Hertzberg25
Many researchers are led into this swampy quagmire of authorship attribution
studies by the ignis fatuus of a more sophisticated statistical technique. Too many
researchers have a great new technique and go looking for a quick and easy problem
– one with available data. Simply using statistics does not give validity to attribu-
tion studies. Too many papers place too much emphasis on statistical technique –
they try to create an aura of scientific invincibility without scientific rigor.
The earlier examples of non-consensus mentioned in Section 2 are all examples
of a disagreement over statistics.
Blind borrowing of statistical techniques from other disciplines must stop:
• The Efron-Thisted tests (expanded from Fisher) are from butterfly collecting;
• Simpson’s index is based on the distribution of different species co-existing
in a given ecosystem;
• The modal analysis used by Elliott’s group is derived from signal processing;
• Morton’s QSUM is based on industrial process and quality control monitor-
ing.
The Effron-Thisted tests are based on the assumption that things (words) are
well mixed in time. The assumption is that you will not capture all the members of
one species early on and all of the members of another species later.26
McNeil, in his work on estimating an author’s vocabulary, assumes that vocab-
ulary is fixed and finite and that the author writes by successively drawing words
from this collection, independently of the previous collection.27
We must be leery of assumptions. We must be able to prove any assumptions.
Statistics should not be the tail that wags the dog of attribution studies.
356 JOSEPH RUDMAN
Where is compliance or even reference to the 1978 “Proposed Criteria for
Publishing Statistical Results,” that appeared in the Bulletin of the Association for
Literary and Linguistic Computing28 or the 1980 “Statement on Statistics,” that
was printed in Computers and the Humanities?29 Are they still adaquate? Should
they be updated?
But, statistics should not become the bugaboo of attribution studies. Statistics is
a sine qua non.
PROBLEM (4)
As incorrect and inappropriate as some statistics are, it is the primary data that is
at the root of many if not most of the problems in authorship attribution studies. It
is a given that the primary data or texts being used in attribution studies should be
as close to the original holograph as possible – each stage of removal introduces
systematic and other errors that may be fatal.
Many studies fail to comprehend that the concept of “author” changes through-
out the ages and plays a significant part in setting up each authorship study.
• Oral Tradition
– Homer. How long after the initial composition were the Iliad and the
Odyssey first put in written form? How much of the text is formulaic
phrases used as memorization aids?30 How do you account for this in an
attribution study?
• Scribal Tradition
– The scribe in ancient Hebrew literature not only re-wrote but interpreted.
– Plato. How much of his work comes to us by way of amanuenses? How
soon after Plato spoke did they write? What do you do with this text?
• Dramatic Tradition
What do we have when we look at the text of a Shakespeare drama? How
many actual words and phrases were copied over from his source material
such as Holinshed’s Chronicles or North’s Plutarch? How many entire
passages were paraphrased? How many years elapsed from the date the play
was first written until the text we now have was printed? How many direc-
tors, actors, copy scribes, pirate publishers, textual scholars, and editors made
additions or other changes, intentional or inadvertant? Drama is by its very
nature a collaborative genre.31 And then we are doing authorship studies on
these plays using hapax legomena and rare word tests!
Corrupted texts are another major data problem.
THE STATE OF AUTHORSHIP ATTRIBUTION STUDIES 357
• Authorial Corruption
– Plagiarism
– Imitation
– Lifting from the author’s earlier work
– Translation
– Substantial quotations
• Editorial Corruption
– Typesetting mistakes
– Changing word forms to comply with a style sheet
– Supplying missing words to fill damaged text
• Experimental Corruption
– Re-Pointing
– Modernizing the spelling
– Lemmatizing
– Allomorphs
If you do not have a viable text, why do the study? Garbage in, garbage out.
The most important lesson here is that many attribution experiments cannot be
successfully completed and should be aborted after a preliminary analysis.
Problem (5)
Too often researchers brush aside the needed expertise in allied fields:
I am not an expert in linguistics, but . . .
I am not an expert in statistics, but . . .
I am not an expert in text authentication, but . . .
I am not an expert in 18th century literature, but . . .
Anthony Kenny, in his well respected Aristotelian Ethics, stated:
To be fully qualified to undertake such a task a man must be a professional
philosopher, classicist, and statistician. I can claim to be professionally quali-
fied only as a philosopher: I am a very amateur classicist and a complete novice
in statistics. My excuse for being undeterred by this is the fact that most of
those working in the field of literary statistics are also, in one or other respect,
novices, or, as they would no doubt prefer to put it, pioneers.32
Leon Gleser stated that statistics, “. . . allows me to enter almost any field, and
without a need to get really deep information about the subject matter of that field
. . . ”33
358 JOSEPH RUDMAN
Problem (6)
A little Learning is a dang’rous Thing;
Drink deep, or taste not the Pierian Spring:
There shallow Draughts intoxicate the Brain,
And drinking largely sobers us again.
Pope34
The problem of ignorance is rampant – not knowing the pitfalls, not understand-
ing the assumptions, implicit and/or explicit. You must be able to prove any
assumptions that you make.
A major commitment to fully research, study, and understand all of the aspects
of authorship attribution (traditional and non-traditional) is demanded. The above
quote from Pope says it well.
We should understand that style is a complex package consisting of a theoreti-
cally unique combination of thousands of individual traits – a very large but finite
number. Working with a given attribution problem means that style is a closed
system with a finite number of style markers.
Problem (7)
Where is the treatment of errors? How many studies even bother to report on errors?
How many studies have corrected an answer for systematic errors? How many
studies cite a reference such as Yardly Beers’ Introduction to the Theory of Error?35
• Systematic (Experimental) Errors
– Mistyping homonyms
– Input errors – mechanical and human
– Editorial intervention
– Program bugs
• Random (Numerical) Errors
– Standard deviations
– Statistical fluctuations
• Illegitimate (Avoidable) Errors
Some errors of this type are not serious enough to invalidate the results, but
many are.
– Cherry Picking
1. Not holding out a randomly selected sub-set of the
author’s known writing to be used later as one type of control.
THE STATE OF AUTHORSHIP ATTRIBUTION STUDIES 359
2. Using only tests that prove a pre-conceived theory while
discarding those that cause problems with that theory.
– Blunders
4. Solutions
The following solutions do not mirror or answer the above problems number for
number. Many of the problems are dissipated by simply articulating them – the
solutions being self evident. And remember, a traditional authorship study looking
at all of the external and traditional internal evidence must be completed before
a non-traditional study is undertaken. Non-traditional attribution studies provide
only a few of the tools for the attribution scholar. And these tools are by no means
the most important.
SOLUTION (1)
Have a complete and correct experimental design. Do the study right. This seems
simple enough – a truism. But you must know what right is. How many of the
researchers who publish have read or are even aware of a significant percentage of
the body of literature? My working bibliography contains well over 600 relevant
entries.
Every practitioner should be familiar with and follow the research design prin-
ciples put forth in books like Hatch and Lazaraton’s The Research Manual36 or
Milliken and Johnson’s Analysis of Messy Data.37
Each study must have a well defined experimental set up – all of the constituent
parts are needed for a valid study.
Every concept must be uniquely defined – e.g. what is a word, what is a
sentence?
Everyone should read and adhere to the tenets promulgated in the National
Academy of Sciences’ monograph On Being A Scientist: Responsible Conduct in
Research.38
SOLUTION (2)
Educate the practitioners. Produce explanatory histories, “how to” handbooks, and
complete annotated bibliographies.
More courses and workshops such as The University of Glasgow’s “Work-
shop in Computationally Intensive Methods in Quantitative Linguistics” should
be offered. But more comprehensive authorship attribution workshops also should
be mounted.
Make sure that the totality of the field is known:
• The various types of authorship attribution studies and what is necessary to
competently complete each;
360 JOSEPH RUDMAN
– Anonymous work – no idea of potential author.
– Anonymous work – two, three, or some other small workable number of
potential authors. This is the least complicated one. The one that has the
most legitimate studies. You eliminate all but a few potential authors and
then say which of the candidates most likely is the author of the questioned
work. However, the practitioner should be aware of the potential for error.
The possibility of deception should be thoroughly investigated. Mosteller
and Wallace’s Federalist Paper study falls here.39 Foster’s Primary Colors
study falls here.40 Holmes’ Cassandra study falls here.41
– Anonymous work – a collaboration.
– Anonymous work – did Author “A” write it. To call this a simple test of
homogeneity as Mosteller and Wallace42 did is to seriously understate the
problem.
• There are variations of the above. There also are other considerations such as
translations and editors – from a commercial editor to a more intimate type.
An example of this is the Frankenstein work of Mary and Percy Shelley.43
One of the most important facts to keep in mind is that each authorship study
is different. Not only are there the various types but each author, each genre, each
language, each time period force variations on the experimental design and require
a unique expertise. And those 600 references I mentioned earlier do not include
references to this kind of expertise – e.g. the working bibliography on my 20 year
(but seemingly endless) Defoe attribution studies is well over 1,000 entries.
SOLUTION (3)
Study style in its totality. Approximately 1,000 style markers have already been
isolated. We must strive to identify all of the markers that make up “style” – to
map style the way biologists are mapping the gene.
Function words, type/tokens, word lengths, hapax legomena, and other specific
style markers may not in themselves be an indicator of a unique style, but when
used in conjunction with all of the other quantifiable indicators that make up style,
they become important.
Many studies have compared a single style marker (or some small number of
style markers) to a fingerprint – an authentication method considered infallible.
However, one whorl or one loop is not sufficient for a positive identification. Also,
there have been no practitioners who have claimed infallibility for their study –
although the QSUM proponents come close.
A better analogy would be to DNA matching. The autoradiogram with its
multiple markers does not claim infallibility but does claim probabilities approach-
ing certainty.44 The same idea behind the DNA scientist’s concern with population
genetics (correcting for demographics) applies to attribution studies. However, the
THE STATE OF AUTHORSHIP ATTRIBUTION STUDIES 361
attribution scientist must correct for genre, date of publication, language, country,
and other like concerns.
It is important to look at as many of the myriad style markers as possible –
some markers will overlap with those of the controls and of the other suspects, but
a matching pattern should emerge.
Because a style marker or a group of style markers is shown to be effective in
one study does not mean that the same marker(s) will be as effective, or even of any
value, in another study. Authorship studies must not fall into the trap of discarding
style markers from their stylistic autoradiogram because they didn’t work in some
other study. Until the study is done, it is not known which style markers will be the
discriminators.
SOLUTION (4)
Identify and educate the gatekeepers: journal reviewers, conference reviewers,
and funding agencies. If you have the expertise, become a gatekeeper. The same
education talked about for practitioners should be put in place for the gatekeepers.
We, as a discipline, want to avoid even the appearance of a Sokal syndrome –
although the author might not be parodying a legitimate study.
SOLUTION (5)
Develop a complete and necessarily multi-faceted theoretical framework on which
to hang all non-traditional authorship attribution studies.
Publish the theories, discuss the theories, and put the theories to experimental
tests.
SOLUTION (6)
The field of authorship attribution is large and unwieldy as a discipline. It is time
that those working in the field from all the various disciplines come together to
discuss and decide how to proceed. Should there be an annual meeting in conjunc-
tion with the ACH/ALLC conference? – a listserver? – a web page? Ideally, this
would be an ongoing group that would then become the authority.
I would like to invite any and all interested parties to contact me with ideas and
suggestions on getting such a group started.
5. Conclusion
I hope that this overview presented enough of what I consider important problem-
atic facets of non-traditional authorship attribution studies to encourage every
practitioner to re-think the field and to invest the time and effort to conduct valid
362 JOSEPH RUDMAN
experiments. Because of past problems and the current lack of a unified methodol-
ogy, future non-traditional attribution studies must be held to a higher standard of
competency and completeness.
The worst case scenario is that nothing changes. The practitioners agree that
there are problems – but not with their own studies. And then nothing but another
spate of flawed articles.
Notes
1 Todorov. “The Place of Style in the Structure of the Text,” p. 29.
2 Ledger. Re-counting Plato, p. 1.
3 Brunet, “What do Statistics Tell Us?” p. 72.
4 Burrows, “Numbering the Streaks of the Tulips?” See especially paragraphs 1 and 2.
5 Moritz. “On the Variation and Functional Relation of Certain Sentence Constants in Standard
Literature,” e.g. page 242.
6 Mealand. “The Extent of the Pauline Corpus: A Multivariate Approach,” p. 64.
7 McNeil. “Estimating an Author’s Vocabulary,” p. 92.
8 Delcourt. “About the Statistical Analysis of Co-occurrence.”
9 Portnoy and Peterson. “Biblical Texts and Statistical Analysis: Zechariah and Beyond,” p. 13.
10 Hilton and Holmes. “An Assessment of Cumulative Sum Charts for Authorship Attribution.”
11 Smith. “An Investigation of Morton’s Method to Distinguish Elizabethan Playwrights.”
12 Phillips. NYT, 23 Jun 65, p. 17.
13 Merriam. “Smith on Morton.” (See also Dr. Smith’s “An Analysis of the Arguments,” appended
to the Merriam article.)
14 See “Attributing A Funeral Elegy.”
15 Elliott and Valenza. “And Then There Were None: Winnowing the Shakespeare Claimants.”
Foster. “Response to Elliot [sic] and Valenza, ‘And Then there Were None’.”
16 “United States v. Hearst,” p. 895.
17 Matthews. “Harsh Words for Verbal Fingerprints.”
18 E.g. see Lana. “Xenophon’s Athenaion Politeia,” p. 18.
19 McCarty. “Communication and Memory in Humanities Computing.”
20 Browne. Titan vs Taboo, p. 47.
Mascol. “Curves of Pauline and of Pseudo-Pauline Style I.”
Mascol. “Curves of Pauline and of Pseudo-Pauline Style II.”
21 Mendenhall. “The Characteristic Curves of Composition.”
22 Neumann. The Authenticity of the Pauline Epistles in the Light of Stylostatistical Analysis.
23 Holmes. “The Analysis of Literary Style – A Review.”
24 McMenamin. Forensic Stylistics.
25 Andrews and Hertzberg. DATA.
26 Valenza. “Are the Thisted-Efron Authorship Tests Valid?”
27 McNeil. “Estimating an Author’s Vocabulary.”
28 Ross and Brainerd. “Proposed Criteria for Publishing Statistical Results.”
29 “Statement on Statistics.”
30 See Foley. Oral Tradition in Literature, esp. p. 3.
31 For a detailed discussion of this see McDonald’s The Bedford Campanion to Shakespeare, espe-
cially pages 24 through 28 and chapter 3.
32 Kenny. The Aristotelian Ethics. Oxford: Clarendon Press, 1978, p. v.
33 Clark, “A Passion for Statistics,” p. 20.
34 Pope. An Essay on Criticism, p. 14.
35 Beers. Introduction to the Theory of Error.
THE STATE OF AUTHORSHIP ATTRIBUTION STUDIES 363
36 Hatch and Lazaraton. The Research Manual: Design and Statistics for Applied Linguistics. See
also Hatch and Farhady. Research Design and Statistics for Applied Linguists.
37 Miliken and Johnson. Analysis of Messy Data (Vol. 1: Designed Experiments).
38 National Academy of Sciences. On Being a Scientist: Responsible Conduct in Research.
39 Mosteller and Wallace. Applied Bayesian and Classical Inference.
40 Foster. “ Primary Culprit.”
41 Matthews. “Unmasking Anonymous.”
42 Mosteller and Wallace. Applied Bayesian and Classical Inference, p. 275.
43 Robinson. The Frankenstein Notebooks. See “MWS and PBS’s Collaboration in The Frankenstein
Notebooks,” pp. lxvi–lxxi.
44 Kirby. DNA Fingerprinting, p. 164.
References
“A Statement on Statistics: An Occasional Piece.” Computers and the Humanities, 14 (1980), 117.
Andrews, D. F. and A. M. Hertzberg. DATA: A Collection of Problems from Many Fields for the
Student and Research Worker. New York: Springer-Verlag, 1985.
“Attributing A Funeral Elegy.” Publications of the Modern Language Association of America, 112(3)
(1997), 429–434.
Beers, Yardly. Introduction to the Theory of Error. Reading, Massachusetts: Addison Wesley, 1958.
Browne, Warren. Titan vs Taboo: The Life of William Benjamin Smith. Tucson: The Diogenes Press,
1961.
Brunet, Etienne. “What do Statistics Tell Us?” In Research in Humanities Computing I: Selected
Papers from the ALLC/ACH Conference, Toronto, June 1989. Ed. Susan Hockey and Nancy Ide.
Guest Editor Ian Lancashire. Oxford: Clarendon Press, 1991, pp. 70–92.
Burrows, J. F. “Numbering the Streaks of the Tulip? Reflections on a Challenge to the Use of
Statistical Methods in Computational Stylistics.” Computing in the Humanities Working Papers
(http://www.chass.utoronto.ca/epc/chwp/) (ISSN 1205-5743), 1996.
Clark, Tom. “A Passion for Statistics.” Ventures (University of Pittsburgh), 6(2) (1996), 19–21.
Clayman, D. L. “Trends and Issues in Quantitative Stylistics.” Transactions of the American
Philological Association, 122 (1992), 385–390.
Delcourt, Christian. “About the Statistical Analysis of Co-Occurrence.” Computers and the Human-
ities, 26(1) (1992), 21–29.
Elliott, Ward E. Y. and Robert J. Valenza. “And Then There Were None: Winnowing the Shakespeare
Claimants.” Computers and the Humanities, 30(3) (1996), 191–245.
Foley, John Miles. “Introduction.” In Oral Tradition in Literature. Columbia: University of Missouri
Press, 1986, pp. 1–18.
Foster, Donald W. “Response to Elliot [sic] and Valenza, ‘And Then There Were None’.” Computers
and the Humanities, 30(3) (1996), 247–255.
Foster, Donald W. “Primary Culprit: An Analysis of a Novel of Politics.” New York (26 February
1996), 50–57.
Hatch, Evelyn and Hossein Farhady. Research Design and Statistics for Applied Linguists. New York:
Newbury House, 1982.
Hatch, Evelyn and Anne Lazaraton. The Research Manual: Design and Statistics for Applied
Linguistics. Boston: Heinle & Heinly, 1991.
Hilton, M. L. and D. I. Holmes. “An Assessment of Cumulative Sum Charts for Authorship
Attribution.” Literary and Linguistic Computing, 8 (1993), 73–80.
Holmes, David I. “The Analysis of Literary Style – A Review.” The Journal of the Royal Statistical
Society (Series A [General]), 148(4) (1985), 328–341.
Holmes, David I. “Unmasking Anonymous.” The Daily Telegraph (London) (3 December 1996), 7.
364 JOSEPH RUDMAN
Kirby, Lorne T. DNA Fingerprinting: An Introduction. New York: W.H. Freeman, 1992.
Lana, Maurizio. “Xenophon’s Athenaion Politeia: A Study by Correspondence Analysis.” Literary
and Linguistic Computing, 7(1) (1992) 16–26.
Ledger, Gerard R. Re-Counting Plato: A Computer Analysis of Plato’s Style. Oxford: Clarendon
Press, 1989.
Mascol, Conrad. “Curves of Pauline and Pseudo-Pauline Style I.” Unitarian Review, 30 (November
1888), 452–460.
Mascol, Conrad. “Curves of Pauline and Pseudo-Pauline Style II.” Unitarian Review, 30 (December
1888), 539–546.
Matthews, Robert. “Harsh Words for Verbal Fingerprints.” Sunday Telegraph (London) (4 July 1993).
Matthews, Robert. “Unmasking Anonymous.” The Daily Telegraph (London) (3 December 1996).
McCarty, Willard. “Communication and Memory in Humanities Computing.” Humanist Discussion
Group, 10(137) (27 June 1996). Online http://www.princeton.edu/∼mccarty/humanist.
McDonald, Russ. The Bedford Companion to Shakespeare: An Introduction with Documents. Boston:
Bedford Books of St. Martin’s Press, 1996.
McMenamin, Gerald R. Forensic Stylistics. Amsterdam: Elsevier, 1993. (Reprinted from Forensic
Science International, 58 (1993).)
McNeil, Donald R. “Estimating an Author’s Vocabulary.” Journal of the American Statistical
Association, 68(341) (1973), 92–96.
Mealand, D. L. “The Extent of the Pauline Corpus: A Multivariate Approach.” Journal for the Study
of the New Testament, 59 (1995), 61–92.
Mendenhall, T. C. “The Characteristic Curves of Composition.” Science, 214 (March 1887), 237–
249.
Merriam, Thomas. “Smith on Morton.” Literary and Linguistic Computing, 1(2) (1987), 104–106.
(See also Dr. Smith’s “An Analysis of the Arguments,” appended to the Merriam article.)
Milliken, George A., and Dallas E. Johnson. Analysis of Messy Data (Vol. 1: Designed Experiments).
New York: Van Nostrand Reinhold, 1984.
Moritz, Robert E. “On the Variation and Functional Relation of Certain Sentence-Constants in
Standard Literature.” University Bulletin, 8(11) (1903), 229–253.
Mosteller, Fredrick and David L. Wallace. Applied Bayesian and Classical Inference: The Case of
the “Federalist Papers” (2nd Edition). New York: Springer-Verlag, 1984.
National Academy of Sciences (Committee on Science, Engineering and Public Policy). On Being a
Scientist: Responsible Conduct in Research. Washington, D.C.: National Academy Press, 1995.
Neumann, Kenneth J. The Authenticity of the Pauline Epistles in the Light of Stylostatistical Analysis.
Atlanta, Georgia: Scholars Press (Society of Biblical Literature Dissertation Series Number 120),
1990.
Philips, McCandlish. “Computer Flouts Test by Another: Study on St. Paul’s Epistles Questioned at
Yale Parley.” New York Times (23 Jan. 1965), 17.
Pope, Alexander. An Essay on Criticism. London: Printed for W. Lewis in Russel-Street, p. 1711.
Portnoy, Stephen L. and David L. Peterson. “Biblical Texts and Statistical Analysis: Zechariah and
Beyond.” Journal of Biblical Literature, 103(1) (1984), 11–21.
Robinson, Charles E. Mary Wollstonecraft Shelley: The Frankenstein Notebooks (A Facsimile
Edition of Mary Shelley’s Manuscript Novel, 1816–17 (With Alterations in the Hand of Percy
Bysshe Shelley) As it Survives in Draft and Fair Copy Deposited by Lord Abinger in the Bodleian
Library, Oxford (Dep. c. 477/1 and Dep. c. 534/1–2)). Part One: Draft Notebook A. New York:
Garland, 1996.
Ross, D. and B. Brainerd. “Proposed Criteria for Publishing Statistical Results.” ALLC Bulletin, 6
(1978), 233–234.
Smith, M. W. A. “An Investigation of Morton’s Method to Distinguish Elizabethan Playwrights.”
Computers and the Humanities, 19(1) (1985), 3–21.
THE STATE OF AUTHORSHIP ATTRIBUTION STUDIES 365
Todorov, Tzvetan. “The Place of Style in the Structure of the Text.” In Literary Style: A Sympo-
sium. Ed. (and translated in part by) Seymour Chatman. London: Oxford University Press, 1971,
pp. 29–39.
United States v. Hearst. Federal Supplement (412). St. Paul: West Publishing, 1976.
Valenza, Robert J. “Are the Thisted-Efron Authorship Tests Valid?” Computers and the Humanities,
25(1) (1991), 27–46.
