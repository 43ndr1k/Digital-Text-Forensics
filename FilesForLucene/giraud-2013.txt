Bagging de caractÃ©ristiques pour
lâ€™authentification dâ€™auteur
FranÃ§ois-Marie Giraud â€” Thierry ArtiÃ¨res
Laboratoire dâ€™Informatique de Paris 6 (LIP6)
UniversitÃ© Pierre et Marie Curie, Paris 6 - 4 place Jussieu F-75252 PARIS cedex 05
{francois.giraud, thierry.artieres}@lip6.fr
RÃ‰SUMÃ‰. Les travaux en authentification dâ€™auteur ont montrÃ© la difficultÃ© de dÃ©passer une stra-
tÃ©gie simple telle quâ€™un classifieur linÃ©aire opÃ©rant sur des reprÃ©sentations de type sac de
caractÃ©ristiques des documents. Nous proposons pour surmonter cette difficultÃ© dâ€™utiliser les
techniques de bagging de caractÃ©ristiques qui reposent sur lâ€™apprentissage dâ€™un ensemble de
classifieurs appris sur des sous-ensembles alÃ©atoires de caractÃ©ristiques, puis sur le vote de ces
classifieurs en test.
ABSTRACT. The authorship attribution literature demonstrates the difficulty to design classifiers
that outperform simple strategies such as linear classifiers operating on bag of features rep-
resentation of documents. To overcome this difficulty we propose to use Bagging techniques
that rely on learning classifiers on different random subsets of features, then to combine their
decision by making them vote.
MOTS-CLÃ‰S : Authentification dâ€™auteur, Bagging de caractÃ©ristiques
KEYWORDS: Author identification, feature bagging
1. Introduction
Une question clÃ© dans le domaine de lâ€™attribution et de la vÃ©rification dâ€™auteur rÃ©-
side dans le choix de caractÃ©ristiques pertinentes, cela a motivÃ© de nombreuses Ã©tudes
(Stamatatos, 2009), (Koppel et al., 2009), (Savoy, 2012). MalgrÃ© de nombreux ef-
forts pour construire des caractÃ©ristiques pertinentes du style dâ€™un auteur (e.g. (Kim
et al., 2011)) un choix trÃ¨s populaire reste de considÃ©rer un ensemble important de
caractÃ©ristiques simples issues du monde de la recherche dâ€™information (Comptages
ou TFIDF de mots et/ou de n-grammes de caractÃ¨res), dont on sÃ©lectionne une partie
a priori pour limiter la complexitÃ© de lâ€™apprentissage. Au delÃ  du critÃ¨re de frÃ©quence
(trÃ¨s utilisÃ©) on peut rÃ©aliser la sÃ©lection de caractÃ©ristiques via dâ€™autres critÃ¨res (gain
dâ€™information, information mutuelle, corrÃ©lation Ï‡2, ...) (Savoy, 2012).
Les classifieurs les plus souvent rencontrÃ©s pour lâ€™authentification dâ€™auteurs sont
des modÃ¨les linÃ©aires tels que des machines Ã  vecteurs support (SVM). Ces classifi-
cateurs opÃ©rant sur des reprÃ©sentations de type sac de caractÃ©ristiques des documents
apparaissent en rÃ©alitÃ© assez difficiles Ã  battre (Koppel et al., 2009).
Notre travail est une tentative de dÃ©passer cette approche simple mais efficace. Il
est inspirÃ© de deux constats. Tout dâ€™abord, il a Ã©tÃ© observÃ© dans (Sutton et al., 2005)
que lâ€™apprentissage de modÃ¨les linÃ©aires ou log-linÃ©aires (dans lesquels il y a un pa-
ramÃ¨tre par caractÃ©ristique) pouvait conduire Ã  une forme de sous apprentissage, oÃ¹
certaines caractÃ©ristiques pertinentes pour la tÃ¢che de classification ne sont en fait pas
prises en compte par le modÃ¨le aprÃ¨s apprentissage (e.g. les poids correspondants sont
proches de zÃ©ro). Cela peut se produire quand un petit nombre de caractÃ©ristiques est
suffisant, Ã  lui seul, Ã  la discrimination parfaite des Ã©chantillons dâ€™apprentissage. Dans
ce cas, lâ€™apprentissage dâ€™un modÃ¨le linÃ©aire peut se concentrer sur lâ€™apprentissage des
paramÃ¨tres correspondant Ã  ces caractÃ©ristiques et nÃ©gliger dâ€™autres caractÃ©ristiques
Ã©ventuellement pertinentes sur les donnÃ©es dâ€™apprentissage. Cela peut conduire Ã  des
erreurs en test qui pourraient Ãªtre Ã©vitÃ©es si toutes les caractÃ©ristiques discriminantes
Ã©taient exploitÃ©es par le modÃ¨le aprÃ¨s apprentissage. DeuxiÃ¨mement, le travail par
(Koppel et al., 2007) suggÃ¨re que le style dâ€™un auteur peut Ãªtre caractÃ©risÃ© par la faÃ§on
dont se comporte le classifieur lorsque les caractÃ©ristiques les plus importantes (de
poids fort) sont progressivement ignorÃ©es.
Nous proposons ici dâ€™Ã©tudier comment exploiter ces deux rÃ©sultats pour concevoir
des classifieurs performants pour lâ€™attribution dâ€™auteur. Notre approche repose sur le
bagging de caractÃ©ristiques oÃ¹ lâ€™on combine les rÃ©sultats dâ€™un certain nombre de clas-
sifieurs qui sont appris chacun sur des sous-ensembles alÃ©atoires (de taille limitÃ©e) de
caractÃ©ristiques. Nous prÃ©sentons tout dâ€™abord un aperÃ§u des travaux connexes dans la
section 2 puis nous prÃ©sentons les jeux de donnÃ©es dans la section 3, et en particulier
les jeux de donnÃ©es du challenge PAN 2012 auquel nous avons participÃ©. Ensuite, nous
motivons et prÃ©sentons lâ€™idÃ©e gÃ©nÃ©rale du bagging de caractÃ©ristiques et en Ã©tudions
lâ€™intÃ©rÃªt dans des expÃ©riences en section 4. Enfin nous prÃ©sentons une extension de
lâ€™approche par Bagging exploitant le rÃ©sultat de (Koppel et al., 2007) en section 4.2.
2. Etat de lâ€™art
Les mÃ©thodes de classification les plus utilisÃ©es sont des mÃ©thodes linÃ©aires, trÃ¨s
souvent des machines Ã  vecteurs supports ou SVMs. La littÃ©rature montre en effet que
les SVM linÃ©aires sont particuliÃ¨rement efficaces dans le domaine de lâ€™identification
de lâ€™auteur (comme ils le sont pour des tÃ¢ches de catÃ©gorisation de textes) (Koppel et
al., 2009), et cela pour de nombreux types de caractÃ©ristiques. Seuls quelques travaux
ont conclu a la supÃ©rioritÃ© de SVM non linÃ©aires pour cette tÃ¢che (e.g. (Teytaud et al.,
2000)). En fait peu de travaux portent sur le dÃ©veloppement de nouvelles mÃ©thodes
de classification. La plupart des Ã©tudes publiÃ©es visent Ã  construire de nouvelles ca-
ractÃ©ristiques pertinentes pour lâ€™attribution dâ€™auteur (e.g. (Kim et al., 2011)), ou bien
comparer des jeux de caractÃ©ristiques (Koppel et al., 2009), (Stamatatos, 2009), ou
enfin Ã  proposer des mÃ©thodes de sÃ©lection des caractÃ©ristiques les plus pertinentes
(Savoy, 2012).
La conception de bonnes caractÃ©ristiques semble Ãªtre la vraie question clÃ© pour
lâ€™identification dâ€™auteur. Parmi les caractÃ©ristiques couramment employÃ©es on dis-
tingue des caractÃ©ristiques lexicales, syntaxiques, structurelles et contextuelles. Les
caractÃ©ristiques lexicales incluent les tfidf, la longueur des mots, des phrases, la ri-
chesse du vocabulaire (Koppel et al., 2009), les n-grammes de mots ou de caractÃ¨res
(Hoover, 2002). Ces caractÃ©ristiques Ã©tant souvent trÃ¨s nombreuses on en sÃ©lectionne
un sous ensemble par des critÃ¨res du type gain dâ€™information (Savoy, 2012). Les carac-
tÃ©ristiques syntaxiques sont des comptages ou des tfidf sur des mots particuliers (mots
de liaison, conjonction, prÃ©position, pronom, verbes modaux) ou sur des Ã©tiquettes
POS. On peut Ã©galement utiliser des n-grammes de POS tags (Argamon-Engelson et
al., 1998). Les caractÃ©ristiques structurelles concernent la taille de la police, la couleur,
le nombre dâ€™hyperliens etc (Abbasi et al., 2005). Enfin les caractÃ©ristiques contex-
tuelles concernent les sujets abordÃ©s par le document, lâ€™Ã©longation ou lâ€™inflexion dans
la langue arabe etc (Abbasi et al., 2005). Parmi les nombreux travaux comparant la
pertinence des divers jeux de caractÃ©ristiques, les conclusions sont souvent contra-
dictoires. Par exemple les caractÃ©ristiques les plus discriminantes sont des caractÃ©-
ristiques lexicales dans (Koppel et al., 2009) alors que ce sont des caractÃ©ristiques
contextuelles dans lâ€™Ã©tude de (Abbasi et al., 2005).
Il semble dâ€™aprÃ¨s lâ€™ensemble de la littÃ©rature sur le sujet que la complexitÃ© de lâ€™au-
thentification dâ€™auteur vient dâ€™une part du fait que la signature de lâ€™auteur est mÃªlÃ©e Ã 
dâ€™autres informations, plus prÃ©gnantes, qui concernent la nature du document, le su-
jet du texte, lâ€™opinion de lâ€™auteur, etc. Si bien que les caractÃ©ristiques lexicales sont
souvent efficaces et quâ€™il est dÃ©licat de sÃ©lectionner manuellement des caractÃ©ristiques
intuitivement liÃ©es au style. En outre, il est probable que les caractÃ©ristiques les plus
discriminantes pour un auteur soient trÃ¨s dÃ©pendantes de lâ€™auteur, la sÃ©lection de ca-
ractÃ©ristiques ne pourrait alors Ãªtre rÃ©alisÃ©e efficacement a priori pour lâ€™ensemble des
auteurs.
3. Contexte expÃ©rimental
3.1. Jeux de donnÃ©es
Nous prÃ©sentons des rÃ©sultats expÃ©rimentaux obtenus sur les jeux de donnÃ©es de la
compÃ©tition internationale PAN 2012 et sur deux ensembles de donnÃ©es additionnels
sur lesquels nous avons cherchÃ© Ã  caractÃ©riser le comportement de nos propositions.
â€“ Corpus de littÃ©rature anglaise. Ce corpus a Ã©tÃ© utilisÃ© dans certaines publications
antÃ©rieures (Koppel et al., 2009), (Koppel et al., 2007). Il comprend 2 livres complets
pour 9 auteurs. Chaque livre a Ã©tÃ© divisÃ© manuellement en une centaine de documents,
en gardant lâ€™intÃ©gritÃ© des chapitres et des sections de texte. Les documents obtenus
sont longs dâ€™environ 500 Ã  3000 mots.
â€“ Corpus de blogs. Ce corpus compte originellement environ 18 000 auteurs (Kop-
pel et al., 2006), nous nâ€™avons considÃ©rÃ© que les 60 principaux auteurs, ceux qui ont
postÃ© au moins 20 messages de plus de 100 mots.
â€“ Corpus de la compÃ©tition PAN 2012. La compÃ©tition PAN 2012 a proposÃ© plu-
sieurs tÃ¢ches dâ€™attribution dâ€™auteur, nous nous sommes focalisÃ©s sur la tache tradition-
nelle dâ€™attribution dâ€™auteur de textes littÃ©raires. Il y a avait trois corpus dâ€™apprentissage
(deux de nouvelles littÃ©raires, le dernier de romans). Pour chacun des corpus il existait
deux sous-tÃ¢ches, lâ€™une dite fermÃ©e ou un texte de test Ã©tait Ã©crit par lâ€™un des auteurs
du corpus dâ€™apprentissage quâ€™il fallait reconnaÃ®tre, lâ€™autre ouverte dans laquelle cette
condition nâ€™Ã©tait pas remplie (le classifieur devait donc Ãªtre capable de rejeter un docu-
ment). Nous avons essentiellement participÃ© aux tÃ¢ches fermÃ©es. Les jeux de donnÃ©es
Ã©taient les suivants :
- Corpus 1 : 3 auteurs, 2 documents par auteurs, entre 1700 et 6000 mots par
documents.
- Corpus 2 : 8 auteurs, 2 documents par auteurs, entre 1900 et 13000 mots par
documents.
- Corpus 3 : 14 auteurs, 2 documents par auteur, entre 30 000 et 170 000 mots
par documents.
3.2. Conditions expÃ©rimentales
Dans toutes les expÃ©riences rapportÃ©es, nous avons utilisÃ© des classifieurs SVMs
linÃ©aires. Nous avons utilisÃ© la bibliothÃ¨que libsvm (Chang et al., 2011) oÃ¹ un classi-
ficateur multiclasse pour un problÃ¨me de classification Ã  N classes est mis en oeuvre
par lâ€™apprentissage de N Ã—(N âˆ’ 1)/2 SVM binaires. Tous les classifieurs sont ap-
pris avec un terme de rÃ©gularisation L2 standard dont le poids est fixÃ© sur la base de
validation.
4. Bagging de caractÃ©ristiques
Nous considÃ©rons un problÃ¨me de classification Ã  N auteurs (classes), les docu-
ments sont reprÃ©sentÃ©s par des vecteurs Ã  p dimensions.
4.1. Motivation
Il est connu que lâ€™apprentissage de modÃ¨les de classification de forte capacitÃ©
(par exemple des modÃ¨les linÃ©aires sur des donnÃ©es en trÃ¨s grande dimension) peut
conduire Ã  une forme de sur-apprentissage, oÃ¹ le classifieur peut parfaitement discri-
miner les donnÃ©es dâ€™apprentissage et avoir un comportement dÃ©gradÃ© en gÃ©nÃ©ralisation
(sur des donnÃ©es non vues en apprentissage). Dans certaines situations ce phÃ©nomÃ¨ne
a Ã©galement Ã©tÃ© qualifiÃ© de sous-apprentissage (Sutton et al., 2005). Ce dernier sug-
gÃ¨re que certaines caractÃ©ristiques pertinentes peuvent ne pas Ãªtre pleinement prises
en compte par le modÃ¨le aprÃ¨s apprentissage. Cela peut se produire quand plusieurs
caractÃ©ristiques (ou plusieurs sous-ensembles de caractÃ©ristiques) sont suffisantes Ã 
elles seules pour une discrimination parfaite des Ã©chantillons dâ€™apprentissage. Dans
ce cas, lâ€™apprentissage peut se concentrer sur lâ€™exploitation de certaines de ces carac-
tÃ©ristiques pertinentes tout en en nÃ©gligeant dâ€™autres. Du point de vue de lâ€™apprentis-
sage automatique un apprentissage de ce type, que lâ€™on pourrait qualifier de partiel,
correspondrait effectivement Ã  une maximisation du critÃ¨re (de marge, de probabilitÃ©
a posteriori) et constituerait une solution valide. Malheureusement, si les caractÃ©ris-
tiques discriminantes qui ont Ã©tÃ© nÃ©gligÃ©es durant lâ€™apprentissage apparaissent dans un
Ã©chantillon de test, et pas les caractÃ©ristiques discriminantes sur lesquelles le classi-
fieur a appris Ã  construire sa prÃ©diction, alors cet exemple de test sera mal classÃ©. Alors
quâ€™il inclut des caractÃ©ristiques pertinentes qui pourraient avoir Ã©tÃ© utilisÃ©es pour bien
le classer. Câ€™est en cela que cette forme de sur-apprentissage peut Ãªtre interprÃ©tÃ©e
comme du sous-apprentissage.
Ce type de phÃ©nomÃ¨ne a Ã©tÃ© observÃ© en particulier dans le contexte du traitement
de donnÃ©es textuelles avec des modÃ¨les log-linÃ©aires (type CRFs ou Conditional Ran-
dom Fields) qui sont traditionnellement appris avec un trÃ¨s grand nombre de caractÃ©-
ristiques pour des tÃ¢ches oÃ¹ les donnÃ©es sont parfois linÃ©airement sÃ©parables avec un
petit sous-ensemble des caractÃ©ristiques.
En rÃ©alitÃ© nous avons effectivement observÃ© sur une petite dizaine de corpus dâ€™au-
thentification dâ€™auteurs que des SVMs travaillant sur des reprÃ©sentations des docu-
ments en grande dimension (e.g. de caractÃ©ristiques lexicales) atteignent trÃ¨s souvent
une prÃ©cision de 100% sur lâ€™ensemble dâ€™apprentissage tandis que les performances
sur lâ€™ensemble de test peuvent Ãªtre nettement infÃ©rieures, ce qui est symptomatique
dâ€™un surapprentissage mais peut Ãªtre mieux apprÃ©hendÃ© comme du sousapprentissage.
Les figures 1 et 2 montrent la prÃ©cision obtenue par un SVM linÃ©aire en fonction
du nombre (limitÃ©) de caractÃ©ristiques, X , utilisÃ©es pour reprÃ©senter les documents. La
valeur de X varie de 10 Ã  350. Les caractÃ©ristiques sont choisies parmi un ensemble de
Figure 1. Corpus de LittÃ©rature Anglaise (Koppel et al., 2009). Taux de classification
correcte sur les donnÃ©es dâ€™apprentissage de SVMs linÃ©aires en fonction du nombre
X de caractÃ©ristiques utilisÃ©es, choisies au hasard ou les plus frÃ©quentes (parmi un
ensemble de 2 500 caractÃ©ristiques). La performance dâ€™un SVM utilisant toutes les
(2 500) caractÃ©ristiques ainsi que celle dâ€™un SVM utilisant toutes les caractÃ©ristiques
exceptÃ©es les X les plus frÃ©quentes sont donnÃ©es Ã©galement.
Figure 2. MÃªmes courbes que dans la figure 1 mais sur les donnÃ©es de test.
2 500 caractÃ©ristiques qui sont les 2 500 trigrammes de caractÃ¨res les plus frÃ©quents.
Les courbes sont tracÃ©es pour lâ€™ensemble de donnÃ©es dâ€™apprentissage (figure 1) et de
test (figure 2) pour le cas oÃ¹ les X caractÃ©ristiques sont choisies alÃ©atoirement parmi
les 2 500 caractÃ©ristiques initiales ou bien par sÃ©lection des X caractÃ©ristiques les
plus frÃ©quentes. Deux courbes additionnelles sont donnÃ©es pour comparaison. Lâ€™une
correspond Ã  la performance dâ€™un SVM exploitant les 2 500 caractÃ©ristiques lâ€™autre
Ã  la performance dâ€™un SVM exploitant les 2 500 caractÃ©ristiques moins les X plus
frÃ©quentes. Ces rÃ©sultats ont Ã©tÃ© obtenus sur le corpus de LittÃ©rature Anglaise.
On voit tout dâ€™abord que les SVMs opÃ©rant sur lâ€™ensemble des caractÃ©ristiques
obtiennent une prÃ©cision de 100% sur la base dâ€™apprentissage aors que la performance
plafonne Ã  80% en test.
Ensuite, la performance des classifieurs qui exploitent seulement quelques caractÃ©-
ristiques est trÃ¨s Ã©levÃ©e sur lâ€™ensemble dâ€™apprentissage si lâ€™on sÃ©lectionne les caractÃ©-
ristiques les plus frÃ©quentes. Et si on augmente le nombre de caractÃ©ristiques utilisÃ©es
la performance atteint rapidement une classification parfaite en apprentissage, (ce qui
est Ã©galement vrai lorsque lâ€™on utilise toutes les caractÃ©ristiques), tandis quâ€™elle atteint
le mÃªme plateau en test Ã  environ 80% de prÃ©cision. Il y a donc un Ã©cart clair entre la
performance sur lâ€™ensemble dâ€™apprentissage et sur lâ€™ensemble de test. On note Ã©gale-
ment que la prÃ©cision dâ€™un SVM exploitant lâ€™ensemble des 2 500 caractÃ©ristiques ex-
ceptÃ©es les X plus frÃ©quentes est trÃ¨s Ã©levÃ©e, tant sur lâ€™ensemble dâ€™apprentissage que
sur lâ€™ensemble de test, ce qui montre que ces caractÃ©ristiques contiennent Ã©galement
des informations discriminantes. Ainsi non seulement les X premiÃ¨res caractÃ©ristiques
permettent une discrimination parfaite en apprentissage mais les caractÃ©ristiques de X
Ã  2 500 le permettent aussi.
Par ailleurs si lâ€™on observe la performance des classifieurs utilisant X caractÃ©ris-
tiques prises au hasard dans lâ€™ensemble des 2 500 caractÃ©ristiques, on voit que lâ€™utili-
sation dâ€™un nombre limitÃ© de caractÃ©ristiques alÃ©atoires permet Ã©galement de faire la
distinction entre les auteurs jusquâ€™Ã  un certain point, ce qui tend Ã  montrer Ã©galement
que toutes les caractÃ©ristiques (y compris les moins frÃ©quentes) contiennent des infor-
mations discriminantes. Potentiellement les courbes de ces figures laissent penser que
de nombreuses caractÃ©ristiques vÃ©hiculent une information discriminante.
Or, il est probable que lâ€™apprentissage dâ€™un SVM mettra lâ€™accent sur lâ€™exploitation
des caractÃ©ristiques les plus frÃ©quentes de sorte quâ€™Ã  la fin, on peut sâ€™attendre Ã  ce que
les SVMs ne soient pas nÃ©cessairement en mesure dâ€™exploiter pleinement toutes les
caractÃ©ristiques discriminantes. En dâ€™autres termes, il doit exister un certain nombre de
caractÃ©ristiques discriminantes qui sont nÃ©gligÃ©es par le processus dâ€™apprentissage et
qui pourraient amÃ©liorer les performances en gÃ©nÃ©ralisation si elles Ã©taient rÃ©ellement
exploitÃ©es.
4.2. Bagging de caractÃ©ristiques pour lâ€™authentification dâ€™auteur
Sur la base de lâ€™analyse prÃ©cÃ©dente nous avons cherchÃ© Ã  concevoir des approches
capables dâ€™exploiter pleinement le potentiel de toutes les caractÃ©ristiques disponibles.
Nous nous sommes naturellement tournÃ©s vers des mÃ©thodes dâ€™ensemble avec lâ€™idÃ©e
de combiner de multiples classifieurs appris sur des ensembles de caractÃ©ristiques
diffÃ©rents.
De nombreuses mÃ©thodes ont Ã©tÃ© proposÃ©es pour combiner des classifieurs, le co-
training, le boosting, le bagging, dont un certain nombre ont Ã©tÃ© conÃ§ues ou adaptÃ©es
pour combiner des classificateurs opÃ©rant sur diffÃ©rents sous-ensembles de caractÃ©ris-
tiques (Viola et al., 2001), (Sutton et al., 2005). En particulier, lâ€™apprentissage de clas-
sifieurs appris sur des ensembles de caractÃ©ristiques divers a Ã©tÃ© Ã©tudiÃ© par quelques
chercheurs dans le passÃ© (Oâ€™Sullivan et al., 2000), avec le cas particulier de (Viola et
al., 2001) qui ont utilisÃ© des classifieurs faibles appris chacun sur une caractÃ©ristique.
Nous avons explorÃ© une approche de Bagging de caractÃ©ristiques oÃ¹ lâ€™on apprend
un nombre important de classifieurs de base, chacun appris sur un sous-ensemble alÃ©a-
toires de caractÃ©ristiques, que lâ€™on fait voter en infÃ©rence pour produire une dÃ©cision.
Plus concrÃ¨tement, pour obtenir des rÃ©sultats performants sur nos corpus de classifi-
cation dâ€™auteurs nous avons utilisÃ© plusieurs centaines Ã  plusieurs milliers de modÃ¨les
SVMs appris chacun sur un sous-ensemble alÃ©atoire de quelques dizaines Ã  quelques
centaines de caractÃ©ristiques. Dans nos expÃ©riences tous les SVM sont appris avec la
boÃ®te Ã  outils libsvm.
5. RÃ©sultats expÃ©rimentaux
5.1. RÃ©sultats prÃ©liminaires
Nous montrons tout dâ€™abord quelques rÃ©sultats prÃ©liminaires obtenus sur le corpus
de blogs. Tous les rÃ©sultats prÃ©sentÃ©s dans cette section, exceptÃ©s ceux de la table 2,
ont Ã©tÃ© obtenus pour un dÃ©coupage unique apprentissage / validation / test pour limiter
la complexitÃ© des expÃ©riences. La base de validation est utilisÃ©e pour dÃ©terminer la
valeur optimale du paramÃ¨tre de rÃ©gularisation des classifieurs SVM.
Nous Ã©tudions tout dâ€™abord lâ€™influence du nombre de caractÃ©ristiques alÃ©atoires X
exploitÃ©es par chacun des classificateurs de base et du nombre de classifieurs de base,
M . La figure 3 montre lâ€™Ã©volution et la prÃ©cision du systÃ¨me en fonction du nombre
de modÃ¨les de base M . Chaque courbe correspond Ã  une valeur de X . Les caractÃ©-
ristiques utilisÃ©es sont choisies parmi lâ€™ensemble des 3 000 trigrammes de caractÃ¨res
les plus frÃ©quents dans le corpus. Comme on le voit la valeur de X une influence clai-
rement sur la performance de lâ€™approche globale et il semble prÃ©fÃ©rable dâ€™utiliser ici
une valeur plutÃ´t petite, qui permet probablement dâ€™induire une plus grande variabilitÃ©
entre les classificateurs de base. Par ailleurs, il semble que la performance du systÃ¨me
final augmente avec le nombre de classifieurs de base, en particulier dans le cas de
classifieurs de base opÃ©rant sur un petit nombre de caractÃ©ristiques.
La table 1 fournit les performances minimales, moyennes et maximales parmi un
ensemble de 1 300 classifieurs exploitant 100 caractÃ©ristiques choisies alÃ©atoirement,
sur les bases dâ€™apprentissage, de validation et de test. On y voit que les performances
en apprentissage sont trÃ¨s Ã©levÃ©es en moyenne et que le gap entre performance en
apprentissage et en test est effectivement important dans tous les cas.
Figure 3. Performance (prÃ©cision) de lâ€™approche par Bagging en fonction du nombre
M de modÃ¨les utilisÃ©s (de 1 Ã  700) pour trois tailles de sous ensembles de caractÃ©ris-
tiques (X = 100, 200, 600).
La table 2 montre les rÃ©sultats de lâ€™approche par bagging de caractÃ©ristiques sur le
mÃªme jeu de donnÃ©es, avec 1 300 classifieurs exploitant chacun 100 caractÃ©ristiques
alÃ©atoires, mais cette fois les rÃ©sultats ont Ã©tÃ© obtenus avec une procÃ©dure de validation
croisÃ©e Ã  6 folds, ce qui permet dâ€™obtenir des indices de significativitÃ©. On voit que
lâ€™approche Baggging apporte des gains significatifs par rapport Ã  lâ€™approche de rÃ©fÃ©-
rence, un SVM linÃ©aire opÃ©rant sur lâ€™ensemble des caractÃ©ristiques. La derniÃ¨re ligne
montre la valeur de la statistique obtenue par un t-test pour valider que la performance
de lâ€™approche Bagging est significativement supÃ©rieure Ã  celle du SVM. Ces valeurs
montrent que lâ€™approche par Bagging est supÃ©rieure avec un degrÃ© de confiance de
lâ€™ordre de 95%.
Tableau 1. Statistiques sur les M = 1 300 classifieurs exploitant 100 caractÃ©ris-
tiques.
Minimum Mean Maximum
Train Valid Test Train Valid Test Train Valid Test
67,3 17,8 16,1 99,5 28,5 26,9 100 42,2 41,7
Enfin, pour explorer la capacitÃ© de rejeter efficacement des documents (par
exemple pour rejeter un document non Ã©crit par un des auteurs connus du systÃ¨me)
nous avons construit une courbe de prÃ©cision rappel en ordonnant les documents par
leur score calculÃ© comme le nombre de votes de la classe reconnue. Nous avons consi-
dÃ©rÃ© les exemples bien classÃ©s comme des exemples positifs et les exemples mal clas-
sÃ©s comme des exemples nÃ©gatifs. On obtient des courbes de prÃ©cision rappel du type
Tableau 2. Comparaison de la performance de lâ€™approche Bagging et dâ€™un SVM. La
derniÃ¨re ligne est la valeur de la statistique obtenue par un test t-test pairÃ© sur la
supÃ©rioritÃ© de lâ€™approche par Bagging (e.g. une valeur infÃ©rieure Ã  0,05 indique que
lâ€™approche Bagging est supÃ©rieure avec une certitude de 95%).
Model Train Valid Test
Bagging (1 300 modÃ¨les - 100 features) 100 83,6 82,1
Single SVM with all 3 000 features 100 80,3 79,8
Valeur de la statistique - 0,0015 0,0535
Figure 4. Courbe de prÃ©cision en fonction du rappel pour lâ€™approche de Baggging.
Les exemples sont rangÃ©s suivant le nombre de votes quâ€™ils ont reÃ§us. Les exemples
positifs sont les exemples bien reconnus et les exemples nÃ©gatifs sont les exemples non
reconnus.
de la figure 4. On voit que le nombre de votes est un critÃ¨re qui semble assez efficace
pour rejeter.
5.1.1. RÃ©sultats sur la compÃ©tition PAN
Pour le dÃ©fi PAN, il nous Ã©tait donnÃ© un ensemble de donnÃ©es dâ€™entrainement.
Nous avons choisi dâ€™apprendre des modÃ¨les de classification sur un certain nombre,
S (de lâ€™ordre de 10), de partitions du corpus dâ€™entrainement en ensemble dâ€™apprentis-
sage et ensemble de validation. Pour chacune de ces partitions, nous avons appris M
modÃ¨les exploitant chacun X caractÃ©ristiques choisies alÃ©atoirement parmi les carac-
tÃ©ristiques initiales, soit des comptages mots soit des comptages de ngrams de carac-
tÃ¨res. Nous avons ensuite gÃ©nÃ©rÃ© des prÃ©dictions en faisant voter les S Ã—M modÃ¨les
obtenus. Pour les problÃ¨mes fermÃ©s, nous avons simplement utilisÃ© un vote majori-
taire.
Lors de cette compÃ©tition, 3 mÃ©thodes ont obtenu les meilleurs rÃ©sultats. La pre-
miÃ¨re est le rÃ©sultat de la collaboration entre lâ€™universitÃ© de Bucarest et lâ€™institut
Fraunhofer FOKUS (Popescu et al., 2012). Leur mÃ©thode utilise des SVM Ã  noyaux et
plus particuliÃ¨rement des "string kernels". La seconde mÃ©thode provient de lâ€™univer-
sitÃ© de Bar-Ilan (Akiva, 2012) et utilisent des SVMs sur une reprÃ©sentation qui capture
la prÃ©sence et absence de mots courants. Enfin, lâ€™universitÃ© de Duquesne (Ryan et al.,
2012) a proposÃ© une approche faisant voter 3 techniques sur des reprÃ©sentations en sac
de mot : le plus proche voisin en distance L1, un SVM, une technique de vote sur un
dÃ©coupage en micro-documents de 3000 caractÃ¨res. Sur les tÃ¢ches fermÃ©es de la com-
pÃ©tition nous avons fini en 3Ã¨me position derriÃ¨re (Popescu et al., 2012) et (Akiva,
2012).
6. Approche par similitude de profils
Nous avons voulu Ã©galement exploiter les rÃ©sultats de (Koppel et al., 2007) qui a
suggÃ©rÃ© que le style dâ€™un auteur se caractÃ©rise par la faÃ§on dont se comporte la perfor-
mance dâ€™un classifieur au fur et Ã  mesure que lâ€™on ignore en test les caractÃ©ristiques
les plus importantes identifiÃ©es en apprentissage (i.e. celles dont les poids sont les plus
importants dans un modÃ¨le linÃ©aire). Peu importe de quelle caractÃ©ristique il sâ€™agit la
vitesse Ã  laquelle la performance dÃ©croit est rÃ©vÃ©latrice de lâ€™auteur.
Nous avons voulu exploiter ce rÃ©sultat dans le cadre de notre approche par Bag-
ging. Le systÃ¨me que nous proposons est un systÃ¨me en deux Ã©tapes. Dans un premier
temps, nous apprenons comme dans notre approche par Bagging M SVMs linÃ©aires
multiclasses exploitant des sous-ensembles alÃ©atoires de X caractÃ©ristiques. Nous no-
tons Si âŠ‚ [1, p] lâ€™ensemble des indices des caractÃ©ristiques utilisÃ©es par le ieme clas-
sifieur SVM, que nous notons SVMi. Tous ces classifieurs sont appris Ã  affecter un
document Ã  lâ€™un des N auteurs.
Ensuite, nous utilisons les M SVMs appris pour construire de nouveaux vecteurs
que nous appelons des profils. Il y a un profil par couple (auteur, document). Pour
tout auteur a âˆˆ [1, N ] et pour tout document d, on construit un nouveau vecteur Ã  p
dimensions (un profil), notÃ© u(d, a), dont la jeme composante est dÃ©finie suivant :
âˆ€j âˆˆ [1, p] , uj(d, a) = 1
Z(j)
âˆ‘
i=1:M
Î´(j âˆˆ Si)Ã— Î´(SVMi(d) == a) [1]
oÃ¹ SVMi(d) correspond Ã  la sortie (un numÃ©ro de classe dans [1 .. N]) de SVMi pour
le document d, oÃ¹ Î´(P ) est Ã©gal Ã  1 si le prÃ©dicat P est vrai et Ã  0 sinon, et oÃ¹ Z(j)
est un facteur de normalisation Z =
âˆ‘
i=1:M Î´(j âˆˆ Si). Ainsi uj(d, a) reprÃ©sente le
pourcentage des classifieurs, parmi ceux qui exploitent la jeme caractÃ©ristique, qui
Figure 5. Profils moyens positifs (triÃ©s) sur le corpus de blogs, oÃ¹ lâ€™on voit une courbe
par auteur. Lâ€™ordonnÃ©e est la valeur dâ€™une composante dâ€™un profil et lâ€™abscisse est le
numÃ©ro de la composante.
prÃ©disent lâ€™auteur a. A chaque document correspondent N profils, un pour chaque au-
teur, dont un est un profil dit positif (celui qui correspond Ã  lâ€™auteur rÃ©el du document)
et les autres sont des profils nÃ©gatifs (ceux calculÃ©s pour les autres auteurs).
Ces profils peuvent Ãªtre triÃ©s (de la valeur la plus Ã©levÃ©e Ã  la plus basse) de sorte
que la numÃ©rotation des composantes est perdue. La figure 5 montre les profils positifs
triÃ©s (et normalisÃ©s pour que la valeur de la premiÃ¨re composante soit Ã©gale 1) pour
les 60 auteurs du corpus blog. Dâ€™une certaine faÃ§on le rÃ©sultat de (Koppel et al., 2007)
conduit Ã  penser que la forme de cette courbe et sa pente est caractÃ©ristique dâ€™un profil
positif ou nÃ©gatif.
A ce stade, nous pouvons apprendre un nouveau classifieur pour discriminer entre
les profils positifs et les profils nÃ©gatifs et construire un classifieur en N classes opÃ©-
rant sur les profils. Nous avons ici utilisÃ© une mÃ©thode trÃ¨s simple dans laquelle chaque
auteur est reprÃ©sentÃ© par le profil positif moyen sur les documents de validation Ã©crits
par cet auteur, notÃ© uvala . Pour classifier un document de test on calcule la sortie des
M SVMs puis on construit N profils du document (un par auteur) {u(d, a)|a = 1..N}
puis on dÃ©termine lâ€™auteur pour lequel le profil positif moyen est le plus corrÃ©lÃ© au pro-
fil correspondant du document :
aÌ‚ = argmaxa
[
correl(uvala , u(d, a))
]
[2]
oÃ¹ correl(x, y) est la corrÃ©lation entre les deux vecteurs x et y.
Le tableau 3 montre que cette seconde approche donne des rÃ©sultats Ã©quivalents Ã 
lâ€™approche SVM simple quâ€™elle ne parvient pas Ã  dÃ©passer. Si lâ€™on utilise des profils
non triÃ©s la performance est mÃªme trÃ¨s dÃ©gradÃ©e. Mais si cette approche ne permet
pas de dÃ©passer la mÃ©thode de Bagging, elle opÃ¨re sur une reprÃ©sentation tout Ã  fait
diffÃ©rente et lâ€™on peut chercher Ã  les combiner, ce que nous avons rÃ©alisÃ© en calculant
une combinaison linÃ©aire des scores :
scoreComb(u, a) = Î±Ã— scoreProfile(d, a) + (1âˆ’ Î±)Ã— scoreBagg(d, a) [3]
oÃ¹ scoreprofile(d, a) est la mesure de corrÃ©lation prÃ©cÃ©dente et scoreBagg(d, a) est
un score produit par lâ€™approche par Bagging (un nombre de votes). La figure 6 montre
lâ€™Ã©volution de la performance de la mÃ©thode de combinaison en fonction du paramÃ¨tre
de mÃ©lange Î±.
Tableau 3. Comparaison de lâ€™approche par profils et de lâ€™approche combinÃ©e avec
lâ€™approche SVM simple. A noter Ã©galement les rÃ©sultats de lâ€™approche par profils sur
des profils non triÃ©s. La valeut T stat calculÃ©e dans la derniÃ¨re ligne correspond Ã  la
valeut de la statistique dâ€™un t-test pairÃ© sur la supÃ©rioritÃ© de la mÃ©thode combinÃ©e
(avec un paramÃ¨tre de mÃ©lange optimale) par rapport Ã  la mÃ©thode de Bagging, elle
montre la significativitÃ© Ã  95% de ce rÃ©sultat.
MÃ©thode PrÃ©cision en test
SVM unique 79,8
Bagging 82,1
Profils (Non triÃ©s) 48,9
Profils (TriÃ©s) 78,9
MÃ©thode combinÃ©e 83,5 (T stat=0,0415)
7. Conclusion
Nous avons proposÃ© dâ€™utiliser une approche de bagging de caractÃ©ristiques pour
lâ€™authentification dâ€™auteurs et montrÃ© que cette approche dÃ©passe une stratÃ©gie trÃ¨s
populaire et efficace pour cette tÃ¢che. Cette mÃ©thode a obtenu des rÃ©sultats intÃ©res-
sants dans la compÃ©tition internationale PAN 2012 et sâ€™est placÃ© Ã  la troisiÃ¨me place
parmi onze participants sur les tÃ¢ches dâ€™identification fermÃ©es. Nous avons Ã©galement
proposÃ© une seconde mÃ©thode qui si elle sâ€™est avÃ©rÃ©e moins efficace que la premiÃ¨re
peut lui Ãªtre avantageusement combinÃ©e.
8. Remerciements
Merci Ã  Moshe Koppel de Bar-Ilan Univeristy (Israel) pour nous avoir fourni ses
corpus. Ce travail a Ã©tÃ© rÃ©alisÃ© dans le cadre du projet SAIMSI financÃ© par lâ€™ANR
(ANR-09-CSOSG-SAIMSI).
Figure 6. Performance de la mÃ©thode combinant les approches Bagging et Profil en
fonction du coefficient de mÃ©lange Î±. Î± = 0 est Ã©quivalent Ã  la mÃ©thode de Bagging
et Î± = 1 est Ã©quivalent Ã  la mÃ©thode par Profils.
9. Bibliographie
Abbasi A., Chen H., Â« Applying Authorship Analysis to Extremist-Group Web Forum
Messages Â», IEEE Intelligent Systems, vol. 20, nËš 5, p. 67-75, September, 2005.
Akiva N., Â« Authorship and Plagiarism Detection Using Binary BOW Features Â», In Notebook
for Uncovering Plagiarism, Authorship, and Social Software Misuse (PAN) at CLEF, 2012.
Argamon-Engelson S., Koppel M., Avneri G., Â« Style-based text categorization : What
Newspaper Am I Reading ? Â», Proceedings of the AAAI Workshop on Text Categorization,
p. 1-4, 1998.
Chang C.-C., Lin C.-J., Â« LIBSVM : A library for support vector machines Â», ACM
Transactions on Intelligent Systems and Technology, vol. 2, p. 27 :1-27 :27, 2011.
Software available at  	


	.
Hoover D. L., Â« Frequent Word Sequences and Statistical Stylistics Â», Literary and Linguistic
Computing, vol. 17, p. 157-180, 2002.
Kim S., Kim H., Weninger T., Han J., Kim H. D., Â« Authorship classification : a discriminative
syntactic tree mining approach Â», SIGIR, 2011.
Koppel M., Schler J., Argamon S., Â« Computational methods in authorship attribution Â»,
Journal of the American Society for Information Science and Technology, 2009.
Koppel M., Schler J., Argamon S., Messeri E., Â« Authorship attribution with thousands of
candidate authors Â», Proceedings of the 29th annual international ACM SIGIR conference
on Research and development in information retrieval, SIGIR â€™06, ACM, New York, NY,
USA, p. 659-660, 2006.
Koppel M., Schler J., Bonchek-Dokow E., Â« Measuring differentiability : unmasking
pseudonymous authors Â», Journal of Machine Learning Research, 2007.
Oâ€™Sullivan J., Langford J., Caruana R., Blum A., Â« FeatureBoost : A Meta Learning Algorithm
that Improves Model Robustness Â», In Proceedings of the Seventeenth International
Conference on Machine Learning, p. 703-710, 2000.
Popescu M., Grozea C., Â« Kernel Methods and String Kernels for Authorshiip Analysis Â», In
Notebook for Uncovering Plagiarism, Authorship, and Social Software Misuse (PAN) at
CLEF, 2012.
Ryan M., Jr J. N., Â« Mixture of Experts Authorship Attribution Â», In Notebook for Uncovering
Plagiarism, Authorship, and Social Software Misuse (PAN) at CLEF, 2012.
Savoy J., Â« Authorship Attribution Based on Specific Vocabulary Â», ACM Trans. Inf. Syst., vol.
30, nËš 2, p. 12 :1-12 :30, May, 2012.
Stamatatos E., Â« A survey of modern authorship attribution methods Â», Journal of the
American Society for Information Science and Technology, vol. 60, nËš 3, p. 538-556, 2009.
Sutton C., Sindelar M., Mccallum A., Feature bagging : Preventing weight undertraining in
structured discriminative learning, Technical report, CIIR, 2005.
Teytaud O., Jalam R., Â« Kernel-Based Text-Categorization Â», In International Joint Conference
on Neural Networks (IJCNN), 2000.
Viola P., Jones M., Â« Rapid object detection using a boosted cascade of simple features Â»,
Computer Vision and Pattern Recognition, 2001, 2001.

