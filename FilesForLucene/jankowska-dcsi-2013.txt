Proximity based one-class classification with Common
N-Gram dissimilarity for authorship verification task
MAGDALENA JANKOWSKA, VLADO KEŠELJ and EVANGELOS MILIOS, Dalhousie University
Authorship verification is a problem of answering the question whether or not a given document was written by the same
person as some other documents known to be authored by a single person. We propose a proximity based method for one-
class classification (based on an idea similar to the k-centers boundary method) that applies the Common N-Gram (CNG)
dissimilarity measure. The CNG dissimilarity is based on the differences in the frequencies of the character n-grams that are
most common in the considered documents. Our method compares the dissimilarity between the sample document and each
document from the target set of documents of known authorship to the maximum dissimilarity between this target document
and all other documents from the set; thresholding is applied to arrive at the classification of the sample document. PAN 2013
competition, Author Identification task, provides an evaluation environment for the solutions for the authorship verification
problem. In this competition, our method yielded the rank 5th (shared) of 18.
Key Words and Phrases: authorship verification, one-class classification, character n-grams
ACM Reference Format:
Magdalena Jankowska, Vlado Kešelj, and Evangelos Milios. 2013. Proximity based one-class classification with Common N-
Gram dissimilarity for authorship verification task. DCSI 2013, (September 2013), 3 pages.
1. INTRODUCTION
The task of computational detection of who wrote a given text, is a widely studied linguistic and ma-
chine learning problem with applications in domains such as forensics, criminal and civil law, or lit-
erary research. Authorship verification problem is a type of such a computational authorship analysis
task, in which, given a set of documents written by one author, and a sample document, one is to an-
swer the question whether the sample document was written by the same author as the remaining
documents. The Authorship Identification competition task of PAN 2013 (evaluation lab on uncovering
plagiarism, authorship, and social software misuse) [PAN 2013], constitutes a testbed for solutions for
this problem. We describe our method that constituted our submission for the competition.
2. METHODOLOGY
We approach the task with an algorithm based on the idea of proximity based methods for one-class
classification, resembling the idea of the k-centers algorithm for one-class classification [Ypma et al.
1998], [Tax 2001], with k being equal to the number of all training documents in the target set (i.e.,
written by the given author). The k-centers algorithm uses equal radius sphere boundaries around the
target documents and compares the sample document to the closest target document; we propose a
different classification condition, described below.
This work has been previously accepted at PAN at CLEF 2013 conference (a non-refereed notebook paper for PAN at CLEF
2013).
This research was funded by a contract from the Boeing Company and a Collaborative Research and Development grant from
the Natural Sciences and Engineering Research Council of Canada.
Author’s emails: {jankowsk, vlado, eem}@cs.dal.ca
Dalhousie Computer Science In-House Conference (DCSI) 2013, Publication date: September 2013.
2 • M. Jankowska, V. Kešelj, E. Milios
Let A = {d1, ..., dk}, k ≥ 2, be the input set of documents written by a given author, which we will
call target documents. If only one target document is provided, we split it in half and treat these two
chunks as two target documents. Let u be the input sample document, which authorship we are to
verify.
Our algorithm calculates for each target document di, i = 1, 2, ..., k, the maximum dissimilarity be-
tween this document and all other target documents: Dmax(di, A), as well as the dissimilarity between
this document and the sample document u: D(di, u), and finally the dissimilarity ratio r(di, u, A) =
D(di,u)
Dmax(di,A)
(and thus r(di, u, A) < 1 means that there exists in the target set a document more dissim-
ilar to di than u, while r(di, u, A) > 1 means that all the target documents are more similar to di than
u). The average of the dissimilarity ratios, over all target documents d1, d2, ..., dk, is the subject of the
thresholding: if this measure is less than or equal to the selected threshold θ, the sample document is
classified as belonging to the target class (i.e., written by the same author as target documents).
Notice that the used dissimilarity between the documents does not need to be a metric distance (i.e.,
does not need to fulfil the triangle inequality), as in fact is the case for the dissimilarity measure we
have chosen.
For the dissimilarity measure between documents we use the Common N-Gram (CNG) dissimilarity,
proposed by Kešelj et al. [Kešelj et al. 2003]. We chose it because this dissimilarity (or its variants)
used in the k-Nearest Neighbour classification scheme with k = 1 (Common N-gram classifier) was
successfully applied to authorship classification tasks [Kešelj et al. 2003], [Juola 2006], [Stamatatos
2007].
CNG dissimilarity is based on the differences in the usage frequencies of the most common charac-
ter n-grams (strings of characters of the given length n) of the considered documents. The important
parameters of the dissimilarity is the length of the character n-grams n and the number L of the most
common character n-grams used as the representation of each document (such a list of Lmost common
n-grams from a document is called the profile of the document).
To select the three parameters: n (length of the character n-grams), L (length of the profiles) and
θ (threshold for the average dissimilarity ratio), we performed experiments on training datasets for
authorship verification in English and Greek, with the objective to maximize the accuracy. We used the
(small) training dataset provided for the PAN 2013 Authorship Identification task [PAN 2013] as well
as two other datasets, which we compiled using existing datasets for other authorship identification
tasks, namely the corpus for the Traditional Authorship Attribution subtask of the PAN 2012 [PAN
2012] (in English) and the Greek dataset created by Stamatos et al. [Stamatatos et al. 2000]. The
algorithm parameters we selected are presented in Table I (for Spanish we used the same parameters
as for English).
Table I. The parameters of our method used in the competition.
English and Spanish Greek
n (n-gram length) 6 7
L (profile length) 2000 2000
θ (threshold) if at least two target documents are given 1.02 1.008
θ (threshold) if a single target document is given 1.06 1.04
An additional condition was applied for ensuring that the documents for a given instance are all
represented by profiles of the same length (for cases when there is not enough character n-grams
in some documents to build a profile of the prescribed length). We also found out that cutting all
documents in a given problem instance to the length of the shortest document tend to increase the
accuracy of the method, so we applied this prepossessing.
Dalhousie Computer Science In-House Conference (DCSI) 2013, Publication date: September 2013.
Proximity based one-class classification with Common N-Gram dissimilarity for authorship verification task • 3
3. EVALUATION AT THE PAN 2013 COMPETITION
The dataset of PAN 2013 competition task of Author Identification consists of English, Greek and
Spanish instances. In each instance, the number of documents of the known authorship was not greater
than 10 (possibly only one). The results yielded by our method in the competition are presented in
Table II. The metric used for the evaluation was the F1 measure: the harmonic mean of precision and
recall. Precision and recall are defined as follows, based on the fact that it is allowed to withdraw an
answer to a problem: recall = #correct answers#problems , precision =
#correct answers
#answers .
Table II. The results in the PAN 2013 competition task Author Identification (as of June 12, 2013).
PAN 2013 Auhtor Identification test dataset
Entire set English subset Greek subset Spanish subset
F1 of our method 0.659 0.733 0.600 0.640
competition rank of our method 5th (shared) of 18 5th (shared) of 18 7th (shared) of 16 9th of 16
highest F1 of other participants 0.753 0.800 0.833 0.840
random baseline 0.5 0.5 0.5 0.5
Our method proved to be reasonably competitive, yielding the 5th (shared) rank out of 18 in the
competition; the method that achieved the best result on the entire test outperformed our method by
0.094 in F1. The performance of our method on the English subset was better than on the Greek one
and the Spanish one.
4. FUTURE WORK
We plan to perform further evaluation of our method on other datasets as well as more detailed anal-
ysis of the algorithm parameter selection and the parameter sensitivity. Investigation of other dissim-
ilarity functions between documents is a possible further direction that may potentially improve the
performance of our method.
REFERENCES
Patrick Juola. 2006. Authorship attribution. Found. Trends Inf. Retr. 1, 3 (Dec. 2006), 233–334.
Vlado Kešelj, Fuchun Peng, Nick Cercone, and Calvin Thomas. 2003. N-gram-based Author Profiles for Authorship Attribu-
tion. In Proceedings of the Conference Pacific Association for Computational Linguistics, PACLING’03. Dalhousie University,
Halifax, Nova Scotia, Canada, 255–264.
PAN. 2012. Dataset of PAN 2012, Author Identification task. (2012). Retrieved Apr 2, 2013 from http://www.uni-weimar.de/
medien/webis/research/events/pan-12/pan12-web/authorship.html
PAN. 2013. PAN competition, Author Identification. (2013). http://www.uni-weimar.de/medien/webis/research/events/pan-13/
pan13-web/author-identification.html
Efstathios Stamatatos. 2007. Author Identification Using Imbalanced and Limited Training Texts. In Proceeding of the 18th
International Workshop on Database and Expert Systems Applications, DEXA’07. 237–241.
Efstathios Stamatatos, George Kokkinakis, and Nikos Fakotakis. 2000. Automatic text categorization in terms of genre and
author. Comput. Linguist. 26, 4 (Dec. 2000), 471–495.
David Tax. 2001. One Class Classification. Ph.D. Dissertation. Delft University of Technology.
Alexander Ypma, Er Ypma, and Robert P.W. Duin. 1998. Support Objects for Domain Approximation. In Proceedings of Int.
Conf. on Artificial Neural Networks. 2–4.
Dalhousie Computer Science In-House Conference (DCSI) 2013, Publication date: September 2013.
