A Comparison of Rabin Karp and Semantic-Based 
Plagiarism Detection 
Catur Supriyanto
 
Department of Computer Science 
Dian Nuswantoro University 
Semarang, Indonesia  
caturs@research.dinus.ac.id 
 
Sindhu Rakasiwi  
Department of Computer Science 
Dian Nuswantoro University 
Semarang, Indonesia
 
 ochin_sindhu@yahoo.com 
 
Abdul Syukur  
Department of Computer Science 
Dian Nuswantoro University 
Semarang, Indonesia  
abdul.syukur@research.dinus.a
c.id
   
ABSTRACT 
Document plagiarism is a challenging task for scholars. 
Similarity computation of two documents is the main step of 
document plagiarism. The accuracy of Rabin Karp and 
semantic-based document plagiarism is measured for 
comparison. This paper employed Latent Semantic Analysis 
(LSA) approach via Singular Value Decomposition (SVD) as 
the semantic-based document plagiarism. The result showed 
Rabin Karp has better performance than LSA Plagiarism. 
Keywords 
Plagiarism Detection, Rabin Karp, Latent Semantic Analysis. 
1. INTRODUCTION 
Plagiarism is the use of ideas or writing without enclosing the 
source of text. Students or lecturers who do research are very 
easy to do plagiarism [1]. It can be prevented by using a 
plagiarism detector to detect a plagiarism in a digital document. 
According to [1], plagiarism detection method can be classified 
into several types. Based on complexity of the use method, 
plagiarism can be classified into superficial and structural. There 
is no linguistic rule in superficial type, different from structural 
type which used linguistic rule. Based on the number of 
document, plagiarism is classified into four categories, singular, 
paired, multidimensional and corpal. Singular plagiarism used 
single-document to compute the metric. Paired plagiarism used 
two document to be processed together to compute the metric. 
Multidimensional plagiarism used multi-documents to be 
processed together to compute the metric. Corpal plagiarism 
used all documents in the dataset to be processed together to 
compute the metric. 
Based on the existing of reference (original) document, 
plagiarism can be split into two categories: external and internal 
plagiarism [2]. The difference is external plagiarism use 
reference document to detect plagiarism in suspicious document, 
meanwhile internal plagiarism identify the plagiarism in 
suspicious document without the existing of reference 
document. 
Another type of plagiarisms is semantic-based and string 
matching-based plagiarism. Semantic-based plagiarism used 
transformation matrix to find the semantic relationship between 
terms in the corpus. The popular matrix transformation is 
Singular Value Decomposition (SVD). Meanwhile, string 
matching-based is string searching algorithm that can be used to 
plagiarism detection [3]. Detailed classification of document 
plagiarism is presented in [4]. 
The outline of this paper is as follows: section 2 describes the 
summary of algorithms. Section 3 describes data corpus. Section 
4 shows the performance analysis of two algorithms. Section 5 
presents the conclusion and future work. 
2. SUMMARY OF ALGORITHM 
Two different plagiarism document approaches used in this 
paper are described in this section.   
2.1 Rabin Karp Algorithm 
Rabin Karp Algorithm is a searching method by using hash 
function. The purpose of hash function is to speed up the search. 
Rabin Karp has been implemented for plagiarism purpose, since 
it is impractical method to detect a plagiarized document. Rabin 
Karp algorithm can be seen as follow: 
RabinKarpMatcher (String P, String T, integer d, integer q ) 
    n : length[T], m: length[P] 
    h : dm-1 mod q 
    p : 0; tn : 0 
    for  i=1 to m do 
          p=d p+P[i] mod q 
          tn = d tn +T[i] mod q 
    for s=0 to n-1 do 
         if p= tn then 
             if p[1…m]=T[s+1 …. S+m]  then 
                     print s 
          if s<n-1 then 
              tn = (d {tn – T[s+1]  h}+ T[s+m+1]mod q 
Figure 1. Pseudo code of Rabin Karp Algorithm [5] 
2.2 Latent Semantic Analysis 
Latent Semantic Analysis (LSA) via Singular Value 
Decomposition (SVD) is a popular transformation technique in 
information retrieval area, such as document clustering, 
document summarization and document plagiarism [6][7][8]. 
SVD can reduce large dimensional space into lower dimensional 
space [9]. Moreover, SVD can enable capture semantic 
relationship between terms and the context. Therefore, the 
performance of information retrieval technique can be increased 
by using lower dimensional space or small number of terms. 
The process of SVD starts with the creation of matrix a term by 
document matrix A . Matrix A has m n× dimensional space, 
3rd International Conferences on Soft Computing, Intelligent System and Information Technology 2012
29
which m is the number of terms and n is the number of 
documents. The SVD of matrix A is defined as: 
 
T
m n m k k k k nA U V× × × ×= ∑                         (1) 
 
Where U is called left singular vector matrix, ∑  is called 
singular value matrix and 
T
V  is called right singular vector 
matrix. 
Based on the above discussion, this paper used matrix 
T
V to 
compute the similarity of document, since 
T
V contains the 
vector of document. 
 
3. DATA CORPUS 
This paper used data corpus of plagiarized short answer 
developed by [10]. Data corpus1 consists of 100 documents (19 
examples of each of the heavy revision, light revision and near 
copy levels and 38 non-plagiarized examples written 
independently from the Wikipedia source). For performances 
measure, we differentiated the corpus only into 2 categories, 
plagiarized and non-plagiarized document. Tokenization, 
stopword removal and stemming algorithm (porter stemming 
algorithm) as the preprocessing of document were implemented 
to the corpus in both algorithms.  
Since, Rabin Karp and LSA-based plagiarism have difference 
approach to detect plagiarism in suspicious document, this paper 
implemented different similarity measure for both. We 
implemented dice similarity and cosines similarity for Rabin 
Karp and LSA-based document plagiarism respectively. The 
calculation of dice and cosines similarity is given bellow. 
                    
2 ( ) ( )
( , )
( ) ( )
A B
A B
A B
w d w d
Dice d d
w d w d
∩
=
+
                      (2) 
 
              
2 2
os ( , )
( ) ( )
A B
A B
A B
w w
C ines d d
w w
×
=
∑ × ∑
∑
              (3) 
 
Where ( )Aw d and ( )Bw d is word in document A  and 
document B , Aw  and Bw  is the tfidf value of each term in 
document A  and document B . 
4. EXPERIMENT RESULT 
Performance analysis of the algorithms is evaluated on the 
corpus collected for this paper. For the performance analysis, we 
choose an intrinsic evaluation method and used precision (P), 
recall (R), and F-measure (F). Similarity of two documents has a 
value in range from 0 to 1. 1 means that the documents are 
exactly the same and 0 means that documents are exactly 
different. A document is decided as plagiarized document if 
similarity of suspicious and original document is more than a 
                                                                
1 http://ir.shef.ac.uk/cloughie/resources/plagiarism_corpus.html 
threshold τ . This paper used the threshold τ  between 0 % and 
100%. The performance of both algorithms is performed in 
different n-grams (n=2, 3, 4). According to [11], the using of n-
gram can identify the writer’s style and n-gram gives some 
flexibility to detection task for the external plagiarism detection. 
Table 1. A confusion matrix for two class imbalanced 
problem 
Actual System 
Predicted Plagiarized Non-Plagiarized 
Plagiarized True Positive (TP) False Positive (FP) 
Non-
Plagiarized 
False Negative (FN) True Negative (TN) 
 
By using a confusion matrix above, recall (R), precision (P) and 
F-measure (F) can be computed as follow: 
                             / ( )R TP TP FN= +                                 (4) 
              / ( )P TP TP FP= +                                  (5) 
                               
2 P R
F
P R
× ×
=
+
                                      (6) 
 
Figure 2. F-Measure of Rabin Karp Plagiarism Detection 
 
Table 2 shows the performance evaluation result of Rabin Karp 
detection on the data corpus. The best F-measure 0.97 is 
obtained when the plagiarism does not use n-gram. For obtain 
the best result for each n-gram, threshold τ for 4-gram, 3-gram, 
2-gram have been set into 35%, 47%, 71%, respectively. The 
smaller the number of n-gram, the higher the number of 
threshold τ  is required. 
 
Figure 3. F-Measure of SVD Plagiarism Detection 
3rd International Conferences on Soft Computing, Intelligent System and Information Technology 2012
30
 
Table 3 shows the performance evaluation result of LSA based 
detection on the data corpus. The best F-measure 0.86 is 
obtained when the plagiarism also does not use n-gram. In LSA 
based plagiarism detection, the threshold τ has to be set more 
than 50% to obtain the best performance for non n-gram and 
each n-gram. 
In comparison, from Figure 2 and Figure 3, experimental result 
shows that Rabin Karp performed better than LSA based 
plagiarism. Since, Rabin Karp use string matching approach 
which found the similar text directly. Different from LSA based 
plagiarism that needs to consider the noise in document 
collection (term-document matrix). 
5. CONCLUSION AND FUTURE WORK 
This paper compared two different plagiarism approaches 
between Rabin Karp and LSA based plagiarism. Although Rabin 
Karp plagiarism detection is simpler than LSA based plagiarism 
detection in detecting plagiarism in a document, the 
performance of Rabin Karp outperformed LSA based in 
plagiarism detection.  
As a future research, we plan to evaluate other similarity 
measure to these approaches and try larger dataset to evaluate 
the performances. Also, machine learning can be used to 
plagiarism detection. The objective of machine learning in 
plagiarism detection is its ability to differentiate between 
original document and suspicious document automatically. 
6. ACKNOWLEDGMENTS 
The authors would like to thank Dian Nuswantoro University 
(UDINUS) for supporting this research. 
7. REFERENCES 
[1] Kashkur, M. and Parshutin, S. 2010. Research into 
Plagiarism Cases and Plagiarism Detection Methods. 
Scientific Journal of Riga Technical University. pp. 138-
143. 
[2] Zechner, M., Muhr, M., Kern, R., and Graz, K. 2009. 
External and Intrinsic Plagiarism Detection Using Vector 
Space Models. In SEPLN 2009. 
[3] Singla, N. and Garg, D. 2012. String Matching Algorithms 
and their Applicability in various Applications. 
International Journal of Soft Computing and Engineering 
(IJSCE). pp. 218-222. 
[4] S. L, Thomas, B.B., and Idicula, S.M. 2011. A Study of 
Plagiarism Detection Tools and Technologies. International 
Journal of Advanced Research in Technology. vol. 1. pp. 
64-70. 
[5] Gupta, P., Agarwal, V. and Varshney, M. 2008. Design and 
Analysis of Algorithm, Asoke K. Ghosh, PHI Learning 
Private Limited. 
[6] Abdulla, H.D., Polovincak, M. and Snasel, V. 2009. Using 
a Matrix Decomposition for Clustering Data.  International 
Conference on Computational Aspects of Social Network. 
[7] Gupta, V., Science, C. and Lehal, G.S. 2010. A Survey of 
Text Summarization Extractive Techniques. Journal of 
Emerging Technologies in Web Intelligence. vol. 2. pp. 
258-268. 
[8] Mudhasir, Y.S. 2011. Near-Duplicates Detection and 
Elimination Based on Web Provenance for Effective Web 
Search. In Proceedings of the IJIDCS International Journal 
on Internet and Distributed Computing Systems. pp. 22-32. 
[9] Abidin, T.F. Yusuf, B. and Umran, M. 2010. Singular 
Value Decomposition for Dimensionality Reduction in 
Unsupervised Text Learning Problems. In Proceedings of 
the ICETC International Conference on Education 
Technology and Computer. pp. 422-426. 
[10] Clough, P. and Stevenson, M. 2009. Developing A Corpus 
of Plagiarised Short Answers, Language Resources and 
Evaluation: Special Issue on Plagiarism and Authorship 
Analysis, In Press. Journal Language Resources and 
Evaluation. 
[11] Stamatatos, E. 2009. Intrinsic Plagiarism Detection Using 
Character n-gram Profiles. In: Stein, B., Rosso, P., 
Stamatatos, E., Koppel, M., Agirre, E. (eds.) SEPLN 2009 
Workshop on Uncovering Plagiarism, Authorship, and 
Social Software Misuse (PAN 09). pp. 38-46.  
 
 
3rd International Conferences on Soft Computing, Intelligent System and Information Technology 2012
31
