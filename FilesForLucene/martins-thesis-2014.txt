JEFFERSON GUSTAVO MARTINS
IDENTIFICAÇÃO DE ESPÉCIES FLORESTAIS
UTILIZANDO SELEÇÃO DINÂMICA DE
CLASSIFICADORES NO ESPAÇO DE DISSIMILARIDADE
Tese apresentada ao Programa de Pós-
Graduação em Informática do Setor de Ciências
Exatas da Universidade Federal do Paraná,
como requisito parcial à obtenção do t́ıtulo de
Doutor em Ciência da Computação.
Orientador: Luiz Eduardo S. Oliveira, Dr.
Co-orientador: Robert R. Sabourin, Dr.
CURITIBA - PR
2014
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
M386i 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Martins, Jefferson Gustavo 
      Identificação de espécies florestais utilizando seleção dinâmica de 
classificadores no espaço de dissimilaridade [manuscrito] / Jefferson Gustavo 
Martins. –  Curitiba, 2014. 
      160f. : il. [algumas color.] ; 30 cm. 
        
      Tese (doutorado) - Universidade Federal do Paraná, Setor de Ciências Exatas, 
Programa de Pós-graduação em Informática, 2014. 
 
      Orientador: Luiz Eduardo  Soares de Oliveira -- Co-orientador: Robert R. 
Sabourin. 
      Bibliografia: p. 143-155.  
 
     1.Madeira - Identificação. 2. Processamento de imagens. 3. Sistemas de 
classificação (Computação). I. Universidade Federal do Paraná. II. Oliveira. Luiz 
Eduardo Soares de. III. Sabourin, Robert R. IV. Título. 
 
                                                                                                 CDD: 526.982 
 
 

RESUMO
A progressiva escassez dos recursos naturais tem conduzido a um uso cada vez mais ra-
cional destes materiais, independente de sua origem e aplicação. Dentre tais recursos, a
madeira e sua exploração têm despertado grande interesse, principalmente por ser, muitas
vezes, extráıda de florestas nativas e da influência que estas têm sobre o planeta. Além
disso, as transações comerciais de madeira envolvem grandes montantes e são suscet́ıveis
a fraudes. Estes logros decorrem da entrega de madeira extráıda de espécies com menor
valor comercial do que o acordado entre as partes e tentativas de exploração de espécies
em iminente extinção. Garantir a autenticidade de madeiras constitui uma necessidade
tanto de seus compradores quanto das agências fiscalizadoras. Fatores como o elevado
número de espécies, a falta de profissionais capacitados, o exaustivo processo de reco-
nhecimento e a perda de caracteŕısticas naturais (folhas, casca e cor) tornam ainda mais
dif́ıcil garantir a autenticidade das madeiras. Inserido neste contexto, este trabalho focou
a construção de um sistema robusto para a classificação de espécies florestais utilizando as
caracteŕısticas texturais presentes nas imagens microscópicas de madeira, a representação
no espaço de dissimilaridade e os sistemas compostos por múltiplos classificadores. Para
isso, explorou-se diferentes alternativas para representar as caracteŕısticas texturais. Para
permitir a aplicação dos modelos de classificação a espécies não consideradas durante seu
treinamento, buscou-se definir os melhores valores para os parâmetros inerentes ao pro-
cesso de construção dos classificadores no espaço de dissimilaridade. Buscando ainda
melhorar o desempenho do sistema, também foram propostos e avaliados métodos para
seleção e/ou combinação de classificadores, além da avaliação das taxas de reconhecimento
em diferentes ńıveis da Botânica, visto que nem sempre é preciso chegar à classificação em
ńıvel de espécie. Testados em uma base de imagens constrúıda para o desenvolvimento
deste trabalho, as estratégias e os métodos de seleção dinâmica de classificadores propos-
tos demonstraram sua efetividade e superioridade com relação tanto aos classificadores
individualmente quanto aos demais métodos testados.
Palavras-Chave: reconhecimento de padrões, seleção dinâmica de classificadores, dissi-
milaridade, imagem microscópica, espécie florestal, madeira.
ABSTRACT
The exploitation of natural resources and their scarcity have led to a rational use of these
materials, regardless of their origin and application. Among these resources, wood has
attracted great interest, mainly because it is often extracted from native forests and the
influence of these forests on the planet. Commercial transactions involve large amounts
of wood and are susceptible to fraud where a wood trader might mix a noble species with
cheaper ones, or even try to export wood whose species is endangered. Buyers must certify
they are buying the correct material while supervising agencies have to certify that wood
has been not extracted irregularly from forests. Identifying a log or a piece of timber
outside its natural environment (the forest) is not an easy task. The high number of
species, the lack of well-trained specialists, the exhaustive process of recognition and loss
of natural features such as leaves, bark and color make it even more difficult to ensure the
authenticity of the woods. In this context, this work is focused on building a robust system
for classification of forest species using the textural features present in wood microscopic
images, a representation in the dissimilarity space and multiple classifier systems. To
do that, different representations for the textural characteristics were tried out. We also
attempted to define the best values for the parameters used to build the classifiers in the
dissimilarity space, which would allow the use of the classification models for species not
considered during their training. Intending to increase recognition rates, we proposed and
evaluated different methods to select and/or combine classifiers. In this context, we also
evaluate all obtained results at different levels defined by botany, as sometimes it is not
necessary to do it at the species classification level. We tested the proposed strategies and
all methods on a database of images built for the development of this work. Finally, the
proposed strategies and methods for dynamic classifier selection have demonstrated theirs
effectiveness and superiority over individual classifiers and the other tested methods.
Keywords: pattern recognition, dynamic classifier selection, dissimilarity, microscopic
image, forest specie, wood.
LISTA DE FIGURAS
1.1 Semelhanças entre plantas de espécies diferentes: (a) Cedrus libani, (b)
Melia azedarach, (c) Pseudotsuga macrolepsis e (d) Simaruba amara. . . . 21
1.2 Amostras da Madeira de Taxodium distichum: (a) Brasil e (b) EUA. . . . . 22
2.1 Sistema para o reconhecimento de padrões (Baseado em Duda et al. [25]). . 26
2.2 Texturas decorrentes da Anatomia da Madeira: (a) Cephalotaxus drupacea,
(b) Chamaecyparis pisifera, (c) Larix sp, (d) Keteleeria fortunei, (e) Tsuga
sp, (f) Eschweilera matamata, (g) Copaifera trapezifolia, (h) Lonchocar-
pus subglaucencens, (i) Parapiptadenia rigida, (j) Tabebuia rosea alba, (k)
Myrcia racemulosa, (l) Rhamnus frangula, (m) Prunus sellowii, (n) Melia
azedarach e (o) Swietenia macrophylla. . . . . . . . . . . . . . . . . . . . . 27
2.3 Pontos de observação: (a) planos de corte; (b) estruturas macroscópicas no
plano de corte X. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28
2.4 Gimnosperma: Pinus elliottii. . . . . . . . . . . . . . . . . . . . . . . . . . 30
2.5 Angiosperma: Porcelia macrocarpa. . . . . . . . . . . . . . . . . . . . . . . 31
2.6 Exemplos de textura da base Brodatz [11]: (a) ráfia; (b) areia; (c) cerca de
madeira; (d) tijolos; (e) casca de árvore. . . . . . . . . . . . . . . . . . . . 32
2.7 Cálculo do padrão LBP para a região sobreposta por uma máscara 3×3
([90], p. 2). . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34
2.8 Operador LBPP,R extendido para P vizinhos e raio R ([90], p. 2). . . . . . 35
2.9 Diferentes primitivas detectadas pelo operador LBP ([79], p. 4). . . . . . . 35
2.10 LBPriP,R: a rotação das imagens em α graus é refletida nas vizinhanças
circulares de seus pontos (x,y) ([1], p. 65). . . . . . . . . . . . . . . . . . . 36
2.11 Descritor SIFT: (a) aplicação da máscara na imagem e obtenção dos gradi-
entes para cada direção na região sobreposta; (b) acúmulo dos gradientes
para cada subregião para as oito direções. . . . . . . . . . . . . . . . . . . 40
2.12 Imagem integral: ilustração do cálculo da soma dos pixels contidos em uma
subregião DBCA da imagem com apenas três operações de adição. . . . . . . . 42
2.13 Janela deslizante de orientação que com ângulo π/3. . . . . . . . . . . . . . . . 42
2.14 Descritor SURF: (a) aplicação da máscara 8×8 alinhada com a orientação iden-
tificada e obtenção dos gradientes para cada direção na região sobreposta da
imagem; (b) acúmulo dos gradientes para cada subregião. . . . . . . . . . . . . 43
2.15 Processo de definição das regiões extremas. Considere a imagem original
em (a) Porcelia macrocarpa. Após esta ser convertida para ńıveis de cinza,
diferentes limiares são aplicados e diferentes imagens binarizadas são gera-
das para a identificação das regiões extremas. As imagens (b) a (h) ilustram
os resultados para os limiares 31, 62, 93, 124, 155 e 186 . . . . . . . . . . . 44
2.16 Geração de GLCMs: (a) fragmento considerado da imagem com apenas
cinco ńıveis de cinza; (b) GLCM para 00; e (c) GLCM para 450. . . . . . . 47
2.17 Bancos de Filtros de Gabor: imagens das partes reais considerando cinco
escalas (ν = [0, 4]) e oito orientações (µ = [0, 7]), σ = 2π, kmax = π/2 e
f =
√
2. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49
2.18 Cálculo dos vetores de dissimilaridade Zi,j: (a) amostras positivas; (b)
amostras negativas (Baseado em Hanusiak et al. [43]). . . . . . . . . . . . . 51
2.19 Transformação de um problema n-dimensional (a) e (c) para bidimensional
(b) e (d) [124, 125]. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 52
2.20 Invariância à distribuição das amostras entre as classes: (a) curvas ROC
idênticas para ‘taxa de erro igual’ (Equal Error Rate - EER, Equação 2.45);
(b) curvas para a relação precisão e taxa tp (Baseado em [31], p. 865). . . . 54
2.21 Matriz de confusão bidimensional representando os acertos (diagonal prin-
cipal) e os erros (diagonal secundária) de cada classificador ([31], p. 862). . 54
2.22 Posśıveis fases para MCSs. . . . . . . . . . . . . . . . . . . . . . . . . . . . 56
2.23 Borda count. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59
2.24 Alternativas para a seleção de classificadores [64]: (a) seleção estática de
agrupamento; (b) seleção dinâmica de classificador; e (c) seleção dinâmica
de agrupamento. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 62
2.25 KNORA [64, 65]: (a) ELIMINATE; e (b) UNION. . . . . . . . . . . . . . . 68
4.1 Modelo proposto com base na seleção dinâmica de classificadores no espaço
de dissimilaridade: (a) treinamento e (b) classificação. . . . . . . . . . . . . 81
4.2 Situação hipotética para a seleção dinâmica de classificadores baseada na
minimização da distância entre a instância questionada Zq,j e a origem do
respectivo espaço de representação sintético com dimensões x1 e x2 quaisquer. 90
4.3 Seleção dinâmica de classificadores baseada na minimização da distância
entre a instância questionada Zq,j e os centróides (C+ e C−) das classes
positiva e negativa dos conjuntos de validação. . . . . . . . . . . . . . . . . 92
4.4 Seleção dinâmica de classificadores baseada na maximização da distância
entre a instância questionada Zq,j e as fronteiras f dos modelos. . . . . . . 94
4.5 Seleção dinâmica de classificadores baseada na minimização da dispersão
das instâncias positivas Zu,v obtidas para cada classe candidata. . . . . . . 96
4.6 Métodos baseados em local accuracy : (a) vizinhança da amostra questio-
nada sq; (b) ordenação da vizinhança segundo o critério da distância Eu-
clidiana entre os vizinhos rj e sq. . . . . . . . . . . . . . . . . . . . . . . . 97
4.7 Identificação dos agrupamentos (espaços em branco) realizados nas matri-
zes de confusão durante o deslocamento entre os ńıveis (a) espécie (112×112),
(b) gênero (85×85), (c) famı́lia (30×30) e (d) filo (2×2). . . . . . . . . . . 103
5.1 Avaliação da influência dos cantos escuros: (a) microscópio Olympus modelo
CX40, (b) imagem original e (c) imagem em escala de cinza com a identificação
dos recortes utilizados. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 107
5.2 Avaliação da influência do número de amostras por espécie florestal e re-
ferências por amostra nas taxas de reconhecimento. . . . . . . . . . . . . . 111
5.3 Avaliação da influência do número de espécies florestais do conjunto de
treinamento nas taxas de reconhecimento. . . . . . . . . . . . . . . . . . . 111
5.4 Avaliação da influência do número de espécies florestais candidatas do con-
junto de teste nas taxas de reconhecimento. . . . . . . . . . . . . . . . . . 112
5.5 Distância média e desvio padrão entre as instâncias questionadas Zq,j e os
centróides (C+ ou C−) das classes selecionadas nos diferentes espaços de
representação. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 114
5.6 Distância média e desvio padrão entre as instâncias questionadas e os
centróides das classes selecionadas, considerando todos os espaços de re-
presentação. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 115
5.7 Distância média e desvio padrão entre as instâncias questionadas Zq,j e as
fronteiras dos modelos f nos diferentes espaços de representação. . . . . . . 117
5.8 Distância média e desvio padrão entre as instâncias questionadas Zq,j e as
fronteiras dos modelos f , considerando todos os espaços de representação. . 118
5.9 Dispersão média das referências Zu,v e desvio padrão nos diferentes espaços
de representação. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 119
5.10 Dispersão média e desvio padrão das referências considerando todos os
espaços de representação. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 120
5.11 Taxas de reconhecimento alcançadas pelos métodos OLA e LCA para a
regra de fusão máximo e as vizinhanças entre um e 75 elementos. . . . . . 122
5.12 Gráfico ROC para as vizinhanças com os melhores resultados para os
métodos OLA e LCA e regra de fusão máximo. . . . . . . . . . . . . . . . 123
5.13 Taxas de reconhecimento alcançadas pelos métodos a priori e a posteriori
para a regra de fusão máximo e as vizinhanças entre um e 75 elementos. . . 123
5.14 Gráfico ROC para as vizinhanças com os melhores resultados para os
métodos a priori e a posteriori e regra de fusão máximo. . . . . . . . . . . 124
5.15 Taxas de reconhecimento alcançadas pelos métodos MCB OLA e MCB
LCA para a regra de fusão máximo e as vizinhanças entre um e 75 elementos.125
5.16 Gráfico ROC para as vizinhanças com os melhores resultados para os
métodos MCB OLA e MCB LCA e regra de fusão máximo. . . . . . . . . . 125
5.17 Taxas de reconhecimento alcançadas pelos métodos MCB a priori e MCB
a posteriori para a regra de fusão máximo e as vizinhanças entre um e 75
elementos. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 126
5.18 Gráfico ROC para as vizinhanças com os melhores resultados para os
métodos MCB a priori e MCB a posteriori e regra de fusão máximo. . . . 126
5.19 Taxas de reconhecimento alcançadas pelos métodos KNORA-E e KNORA-
U para as regras de fusão máximo e média e as vizinhanças entre um e 75
elementos. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 128
5.20 Gráfico ROC para as vizinhanças com os melhores resultados para os
métodos KNORA-E e KNORA-U e as regras de fusão máximo e média,
respectivamente. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 128
5.21 Taxas de reconhecimento alcançadas pelo métodos baseados no critério
LCA para a delimitação da vizinhança da instância questionada, a regra
de fusão máximo e as vizinhanças entre um e 75 elementos. . . . . . . . . . 130
5.22 Gráfico ROC para as vizinhanças com os melhores resultados para os
métodos baseados no critério LCA para a delimitação da vizinhança da
instância questionada e a regra de fusão máximo. . . . . . . . . . . . . . . 131
5.23 Taxas de reconhecimento alcançadas pelos métodos a posteriori e MCB a
posteriori para a regra de fusão máximo, com diferentes subconjuntos com
10, 7 e 5 classificadores e as vizinhanças entre um e 75 elementos. . . . . . 132
5.24 Taxas de reconhecimento alcançadas com as regras de fusão máximo e
média para as vizinhanças entre um e 75 elementos: (a) OLA e LCA, (b)
a priori e a posteriori, (c) MCB OLA e MCB LCA, e (d) MCB a priori e
MCB a posteriori. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 134
5.25 Exemplos de erros de classificação ocorridos por espécies florestais: (a)
Pinus caribaea; (b) Tibouchiana sellowiana; (c) Erisma uncinatum. . . . . 137
A.1 Amostras da Base de Imagens: (a) Gimnosperma; (b) Angiosperma. . . . . 157
A.2 Amostras de ‘Araucaria angustifolia’: (a) Microscópica; (b) Macroscópica. . 157
LISTA DE TABELAS
3.1 Śıntese dos resultados apresentados para classificação de madeira. . . . . . 79
4.1 Descritores utilizados, dimensões de seus vetores de caracteŕısticas, tempo
médio de extração e complexidade algoŕıtmica. . . . . . . . . . . . . . . . . 86
5.1 Resultados individuais dos classificadores e oráculo acumulado. . . . . . . . 105
5.2 Dimensões das faixas exclúıdas das imagens originais e dimensões das ima-
gens finais (em pixels) ilustradas na Figura 5.1(c). . . . . . . . . . . . . . . 107
5.3 Taxas de reconhecimento obtidas para os diferentes recortes das imagens
originais com o descritor LPQ. . . . . . . . . . . . . . . . . . . . . . . . . . 108
5.4 Resultados obtidos para o conjunto de 15.000 pontos fixos igualmente dis-
tribúıdos pelas imagens com o descritor SURF-128. . . . . . . . . . . . . . 109
5.5 Resultados da combinação das abordagens avaliadas para SURF cujos re-
sultados foram apresentadas nas Tabelas 5.1 e 5.4. . . . . . . . . . . . . . . 109
5.6 Estat́ısticas referentes ao número de pontos detectados pela implementação
do algoritmo SURF disponibilizada pela ferramenta MatLab [89]. . . . . . 109
5.7 Melhores taxas de reconhecimento obtidas para as variações dos experi-
mentos desta seção. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 110
5.8 Resultados da combinação de agrupamentos com k (k = 1..10) classifica-
dores, sendo todos alcançados pela regra de combinação máximo. . . . . . 113
5.9 Taxa de seleção dos classificadores para os diferentes subconjuntos consi-
derados nos experimentos com seleção dinâmica de classificadores baseada
nas distâncias d(Zq,j, C). . . . . . . . . . . . . . . . . . . . . . . . . . . . . 115
5.10 Estat́ısticas das distâncias entre as instâncias questionadas Zq,j correta-
mente classificadas e os centróides (C+ ou C−) das classes selecionadas
nos diferentes espaços de representação. . . . . . . . . . . . . . . . . . . . . 116
5.11 Estat́ısticas das distâncias entre as instâncias questionadas Zq,j incorreta-
mente classificadas e os centróides (C+ ou C−) das classes selecionadas
nos diferentes espaços de representação. . . . . . . . . . . . . . . . . . . . . 116
5.12 Taxa de seleção de cada classificador para os diferentes subconjuntos consi-
derados nos experimentos com seleção dinâmica de classificadores baseada
nas distâncias d(Zq,j, f). . . . . . . . . . . . . . . . . . . . . . . . . . . . . 117
5.13 Estat́ısticas das distâncias entre as instâncias questionadas Zq,j correta-
mente classificadas e as fronteiras f nos diferentes espaços de representação.118
5.14 Estat́ısticas das distâncias entre as instâncias questionadas Zq,j incorreta-
mente classificadas e as fronteiras f nos diferentes espaços de representação.119
5.15 Taxa de seleção de cada classificador para os diferentes subconjuntos consi-
derados nos experimentos com seleção dinâmica de classificadores baseada
na dispersão das referências Zu,v. . . . . . . . . . . . . . . . . . . . . . . . 120
5.16 Estat́ısticas das dispersões das referências Zu,v nos diferentes espaços de
representação para os classificadores corretamente selecionados. . . . . . . 121
5.17 Estat́ısticas das dispersões das referências Zu,v nos diferentes espaços de
representação para os classificadores incorretamente selecionados. . . . . . 121
5.18 Taxas de seleção dos classificadores para o método KNORA-E, conside-
rando os 30 e os 90 vizinhos dos conjuntos de validação mais próximos às
instâncias questionadas. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 129
5.19 Caracterização dos métodos segundo os critérios: (a) definição da vizi-
nhança, (b) delimitação da vizinhança e (c) seleção do classificador. . . . . 129
5.20 Taxas de seleção dos classificadores para cada um dos métodos baseados
no critério LCA para a delimitação da vizinhança de sq. . . . . . . . . . . . 131
5.21 Taxas de seleção dos classificadores para os métodos a posteriori e MCB
a posteriori, considerando os oito vizinhos dos conjuntos de validação mais
próximos às instâncias questionadas, além de subconjuntos com os 10, 7 e
5 melhores classificadores. . . . . . . . . . . . . . . . . . . . . . . . . . . . 133
5.22 Taxas de reconhecimento para os ńıveis definidos pela Botânica espécie,
gênero, famı́lia e filo com, respectivamente, 112, 85, 30 e 2 classes ‘reais’. . 135
5.23 Comparação dos resultados obtidos pelos modelos de classificação cons-
trúıdos para distinguir as 112 espécies florestais e do processo de classi-
ficação hierárquica seguindo os ńıveis definidos pela Botânica. . . . . . . . 136
5.24 Śıntese dos erros de classificação ocorridos para as espécies florestais da
Figura 5.25. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 137
A.1 Gimnospermas: classificação Botânica das espécies. . . . . . . . . . . . . . 158
A.2 Angiospermas: classificação Botânica das espécies. . . . . . . . . . . . . . . 159
LISTA DE ABREVIATURAS
AUC Area Under a ROC Curve
CAIRO Centre for Artificial Intelligence and Robotics
DBI Davies-Bouldin Index
DFT Discrete Fourier Transform
DRIFT Diffuse Reflectance Infrared Fourier Transform
DWT Discrete Wavelet Transform
EER Equal Error Rate
ER Extremal Region
EUA United States of America
FN False Negative
FP False Positive
FRIM Forest Research Institute of Malaysia
GLCM Gray Level Co-occurrence Matrix
HSV Hue, Saturation and Value
IAWA International Association of Wood Anatomists
kNN k-Nearest Neighbors
KNORA K-Nearest-ORAcle
K-NPFDA functional Nadaraya-Watson kernel nonparametric method
LBP Local Binary Pattern
LBP-HF LBP Histogram Fourier Features
LBPri LBP with rotation invariant
LBPriu2 LBP with rotation invariant uniform 2 pattern code
LBP-TOP LBP from Three Orthogonal Planes
LBPu2 LBP with uniform 2 pattern code
LCA Local Class Accuracy
LDC Linear Discriminant Classifier
LPQ Local Phase Quantization
LPQ-TOP LPQ from Three Orthogonal Planes
MC Confusion Matrix
MCB Multiple Classifier Behaviour
MCS Multiple Classifier Systems
MLP Multilayer Perceptron
MSER Maximally Stable Extremal Regions
NIR Near-Infrared
OLA Overall Local Accuracy
OpenCV Open Source Computer Vision Library
PCA Principal Component Analysis
PLS Partial Least Squares
PO Ponto de Operação
QDC Quadratic Discriminant Classifier
RGB Red, Green, Blue
RNA Artificial Neural Network
Continua na próxima página
continuação da página anterior
ROC Receiver Operator Characteristics
SIFT Scale Invariant Feature Transform
SOM Self-Organizing Maps
STFT Short-Term Fourier Transform
SVM Support Vector Machine
SURF Speed-Up Robust Feature
TEXTEL TEXture ELement
TN True Negative
TP True Positive
UFPR Federal University of Parana
VLBP Volume Local Binary Pattern
SUMÁRIO
RESUMO iv
ABSTRACT v
LISTA DE FIGURAS ix
LISTA DE TABELAS xi
LISTA DE ABREVIATURAS xii
1 INTRODUÇÃO 17
1.1 Motivação . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17
1.2 Desafios . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20
1.3 Objetivos . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22
1.4 Contribuições . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23
1.5 Estrutura do Trabalho . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24
2 FUNDAMENTAÇÃO TEÓRICA 26
2.1 Anatomia da Madeira . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27
2.1.1 Principais Estruturas definidas pela Anatomia da Madeira . . . . . 28
2.1.2 Grupos Vegetais produtores de Madeira . . . . . . . . . . . . . . . . 29
2.2 Extração e representação de caracteŕısticas texturais . . . . . . . . . . . . 32
2.2.1 Métodos Estruturais . . . . . . . . . . . . . . . . . . . . . . . . . . 33
2.2.2 Métodos Estat́ısticos . . . . . . . . . . . . . . . . . . . . . . . . . . 45
2.2.3 Métodos Espectrais . . . . . . . . . . . . . . . . . . . . . . . . . . . 48
2.3 Representação das relações entre objetos por meio do conceito de dissimi-
laridade . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 50
2.3.1 Vetores de dissimilaridade e a mudança na representação dos pro-
blemas de espaços n-dimensionais para o espaço bidimensional . . . 51
2.3.2 Caracteŕısticas de Receptor-Operador . . . . . . . . . . . . . . . . . 53
2.4 Sistemas compostos por Múltiplos Classificadores . . . . . . . . . . . . . . 56
2.4.1 Combinação de Classificadores . . . . . . . . . . . . . . . . . . . . . 57
2.4.2 Seleção de Classificadores . . . . . . . . . . . . . . . . . . . . . . . 61
2.5 Considerações Finais . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 69
3 ESTADO DA ARTE EM RECONHECIMENTO DE MADEIRA 70
3.1 Revisão da Literatura . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 70
3.2 Considerações Finais . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 78
4 METODOLOGIA 80
4.1 Visão geral da arquitetura proposta . . . . . . . . . . . . . . . . . . . . . . 80
4.2 Extração de caracteŕısticas e avaliação dos descritores . . . . . . . . . . . . 82
4.2.1 Famı́lia de descritores LBP . . . . . . . . . . . . . . . . . . . . . . . 83
4.2.2 Famı́lia de descritores LPQ . . . . . . . . . . . . . . . . . . . . . . 83
4.2.3 SIFT . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 83
4.2.4 SURF . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 84
4.2.5 MSER-SURF . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 84
4.2.6 GLCM . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 85
4.2.7 Filtros de Gabor . . . . . . . . . . . . . . . . . . . . . . . . . . . . 85
4.2.8 Resumo dos descritores utilizados . . . . . . . . . . . . . . . . . . . 85
4.3 Classificação: avaliação dos parâmetros inerentes à representação baseada
em vetores de dissimilaridade . . . . . . . . . . . . . . . . . . . . . . . . . 86
4.4 Seleção de Classificadores . . . . . . . . . . . . . . . . . . . . . . . . . . . 89
4.4.1 Métodos de seleção dinâmica de classificadores baseados na distri-
buição das instâncias no espaço de dissimilaridade . . . . . . . . . . 91
4.4.2 Métodos de seleção dinâmica de classificadores baseados nas de-
cisões para as vizinhanças das instâncias questionadas . . . . . . . . 95
4.5 Combinação de Classificadores . . . . . . . . . . . . . . . . . . . . . . . . . 99
4.6 Avaliação de Resultados . . . . . . . . . . . . . . . . . . . . . . . . . . . . 101
4.6.1 Avaliação das taxas de reconhecimento nos diferentes ńıveis defini-
dos pela Botânica . . . . . . . . . . . . . . . . . . . . . . . . . . . . 102
4.6.2 Uso de meta-classes para a abordagem de classificação hierárquica . 102
4.7 Considerações Finais . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 104
5 RESULTADOS 105
5.1 Avaliações dos descritores: melhores resultados individuais . . . . . . . . . 105
5.1.1 Avaliação da influência dos cantos escuros das imagens nas taxas
de reconhecimento . . . . . . . . . . . . . . . . . . . . . . . . . . . 107
5.1.2 Avaliação quanto ao uso de pontos fixos para os descritores baseados
em pontos de atenção . . . . . . . . . . . . . . . . . . . . . . . . . . 108
5.2 Classificação: avaliação dos parâmetros inerentes à representação baseada
em vetores de dissimilaridade . . . . . . . . . . . . . . . . . . . . . . . . . 110
5.3 Seleção e Combinação de Classificadores . . . . . . . . . . . . . . . . . . . 112
5.3.1 Combinação de agrupamentos de classificadores . . . . . . . . . . . 112
5.3.2 Métodos de seleção dinâmica de classificadores baseados na distri-
buição das instâncias no espaço de dissimilaridade . . . . . . . . . . 113
5.3.3 Métodos de seleção dinâmica de classificadores baseados nas de-
cisões para as vizinhanças das instâncias questionadas . . . . . . . . 121
5.3.4 Combinação dos classificadores selecionados . . . . . . . . . . . . . 133
5.4 Perspectivas empregadas durante a avaliação dos resultados . . . . . . . . . 134
5.4.1 Avaliação dos resultados nos diferentes ńıveis definidos pela Botânica134
5.4.2 Uso de meta-classes para a abordagem de classificação hierárquica . 135
5.5 Análise dos Erros de Classificação . . . . . . . . . . . . . . . . . . . . . . . 136
5.6 Considerações Finais . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 138
6 CONSIDERAÇÕES FINAIS 139
6.1 Discussão . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 139
6.2 Trabalhos Futuros . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 142
REFERÊNCIAS 143
A BASE DE IMAGENS 156
CAPÍTULO 1
INTRODUÇÃO
A progressiva escassez dos recursos naturais tem conduzido a um uso cada vez mais
racional destes materiais, independente de sua origem e aplicação. Dentre tais recursos,
a madeira e sua exploração têm despertado grande interesse, principalmente por ser,
muitas vezes, extráıda de florestas nativas e da influência que estas florestas têm sobre
o planeta. Diante da importância deste tema, o presente trabalho foca a construção de
um sistema robusto para a identificação de espécies florestais por meio do reconhecimento
de imagens microscópicas de sua madeira, da representação no espaço de dissimilaridade
e da seleção dinâmica de classificadores. O presente caṕıtulo apresenta a motivação do
trabalho, focando diversos aspectos e perspectivas quanto ao tema. Destaca-se também
os desafios a serem transpostos, os objetivos que delimitam o escopo do trabalho, seus
resultados e contribuições, além da estrutura geral deste relatório.
1.1 Motivação
A madeira é um dos materiais mais amplamente utilizados pelo ser humano, tanto em
termos de volume quanto de finalidades. Neste sentido, Ioannou et al. [55] destacam
a diversidade dos tipos de madeira existentes, a grande variação de sua aparência em
decorrência de suas cores e texturas, além de propriedades qúımicas, f́ısicas e mecânicas
que as tornam próprias ou impróprias para certas aplicações [49, 50, 55, 95, 140].
Como resultado de tais influências, algumas espécies produzem madeiras mais resis-
tentes a diversos agentes externos e ao tempo, possuem valores comerciais superiores e são
empregadas na fabricação de produtos que demandam maior vida útil. De outra forma,
há espécies cujas madeiras são empregadas para auxiliar a execução de tarefas, tal como
palanques e tábuas para caixarias e suporte, possuem vida útil curta e são bem mais
baratas.
A exploração de matas nativas distantes dos grandes centros urbanos industrializa-
dos justifica a necessidade de reconhecer os tipos de madeira e, consequentemente, sua
origem no decorrer do processo de extração e transformação [55]. A atual visão quanto
à conservação e ao aproveitamento racional dos recursos naturais também se apresenta
como fator importante no apoio à identificação das espécies florestais. A otimização deste
recurso também se deve por esta matéria-prima constituir cerca de 40% dos custos de
produção de muitos produtos industrializados, bem como pela elevação de seus preços
devido à crescente escassez [93].
Tomando o fato das negociações alcançarem grandes volumes financeiros e extrapola-
rem fronteiras em todo o globo, fraudes podem decorrer de misturas de diferentes tipos de
18
madeira, das mais nobres às menos valorizadas, e da tentativa de extração e exportação
de madeira proveniente de espécies sujeitas à extinção. Estas fraudes, relacionadas à en-
trega de materiais diferentes daqueles acordados previamente, podem implicar em grandes
prejúızos para os envolvidos e comprometer a qualidade do produto final devido às dife-
rentes caracteŕısticas apresentadas por cada espécie.
A correta identificação de espécies florestais para garantir a autenticidade de peças de
madeira é de grande importância para vários segmentos da sociedade, desde os produtores,
passando por indústrias, governo e culminando no consumidor final. Compradores devem
se certificar de que estão recebendo o material correto, enquanto agências supervisoras
precisam garantir que não haja madeira extráıda irregularmente das florestas.
Ao se considerar as divisões da Botânica sob um contexto mais amplo, Angiospermas
e Gimnospermas constituem basicamente os dois principais grupos em que se encontram
as espécies produtoras de madeira. Estas espécies podem ser classificadas de acordo
com suas caracteŕısticas anatômicas, estruturais e botânicas (vide seção 2.1). Porém,
além destas caracteŕısticas, o número de variáveis envolvidas na formação da planta e de
sua estrutura é bastante vasto. Pode-se encontrar, inclusive, diferenças muito sutis em
estruturas apresentadas em amostras de diferentes espécies e também diferenças maiores
em estruturas apresentadas em amostras de uma mesma espécie [14].
Embora exista uma série de caracteŕısticas (folhas, frutos, sementes, cores, odor, dentre
outras), ao se retirar os troncos das florestas e processá-los por meio de cortes perde-se
a maioria delas. Assim, o reconhecimento torna-se mais dif́ıcil, senão inviável a olho
nu, sendo necessário especialistas com conhecimento quanto a caracteŕısticas não tão
aparentes, tais como as estruturas celulares presentes em cada espécie.
Também tem-se claro que o número de especialistas não é suficiente para atender
o mercado e que o treinamento de novos profissionais consome tempo, pois estes preci-
sam alcançar um ńıvel mı́nimo de maturidade. Para agravar ainda mais esta situação,
a inserção de etapas executadas manualmente pode influenciar nos resultados finais do
processo de classificação, mesmo com especialistas que dominem os conhecimentos da área
e que tal processo esteja padronizado. Além da subjetividade, tais influências decorrem
de vários fatores inerentes ao processo, o qual é caracterizado como repetitivo, monótono
e demorado, além de requerer alto grau de concentração [22, 115, 119].
De forma geral, os aspectos identificados têm despertado a atenção de muitos estudio-
sos das áreas de Ciência da Computação, Ciências Biológicas e Engenharia Florestal, bem
como das indústrias que empregam madeira em seu processo de produção. Independente
dos aspectos focados pelos interessados, a dificuldade do ser humano em alcançar e/ou
manter elevadas taxas de reconhecimento de madeira durante longos peŕıodos de trabalho
justifica a necessidade de sistemas que automatizem ao menos algumas partes do processo.
Sistemas dotados de visão computacional certamente já beneficiam este amplo público
e são uma opção interessante para identificação de defeitos decorrentes de irregularidades
externas aos troncos, mas ainda ocultas pela casca [15, 16, 72, 123, 134]; detecção e
19
classificação de defeitos em placas de madeira [13, 22, 30, 41, 74, 119]; otimização de
cortes de peças de madeira [19, 93, 115]; e inspeção de produtos finais [58, 92]. No
entanto, estas aplicações ainda sofrem restrições devido à deficiência de pesquisas na área
e à falta de bases de dados com imagens de madeiras [4, 55, 59].
Além dos focos anteriormente identificados, pesquisas também têm sido desenvolvidas
com o intuito de identificar espécies florestais (vide caṕıtulo 3). No entanto, tais pesquisas
geralmente empregam classificadores tradicionais baseados em múltiplas classes e bases de
imagens com um número muito reduzido de espécies florestais, visto a grande diversidade
existente [12, 55, 59, 67, 71, 73, 95, 97, 98, 99, 102, 107, 110, 111, 116, 133, 135, 137,
138, 139, 147]. Tais soluções geralmente não são adequadas a problemas como o abordado
neste trabalho devido a seu elevado número de classes, o qual chega a milhares de espécies
florestais [128].
Os fatores citados no parágrafo anterior limitam a aplicação dos modelos de classi-
ficação às espécies utilizadas durante o treinamento dos classificadores. Assim, diante da
necessidade de incluir uma única espécie àquelas previamente utilizadas, deve-se descartar
os modelos constrúıdos e reconstrúı-los, justamente a fase de classificação que demanda
maior custo [128]. A partir das considerações anteriores e da inviabilidade de se construir
modelos que contemplem todas as espécies florestais existentes, o presente trabalho inves-
tiga a robustez propiciada por sistemas baseados em seleção dinâmica de classificadores
constrúıdos no espaço de dissimilaridade.
A representação no espaço de dissimilaridade (vide Seção 2.3) transforma problemas
com n classes em problemas com apenas duas classes e reduz suas complexidades originais.
Também se tem a independência que esta representação propicia ao modelo com relação
às classes empregadas nas fases de treinamento e classificação, além dos resultados obtidos
por diversos estudos em variados domı́nios de aplicação [27, 26, 38, 57, 113, 114, 129],
dentre os quais se destacam o reconhecimento de assinaturas [7, 28, 29, 70], manuscritos
[43, 132], faces [117] e bio-criptografia [28].
Assim como a representação no espaço de dissimilaridade, sistemas compostos por
múltiplos classificadores (Multi-Classifier Systems - MCSs) têm sido utilizados para al-
cançar maior robustez e melhorar as taxas individuais de reconhecimento dos classifi-
cadores. MCSs são apresentados em maiores detalhes na Seção 2.4. Estes exploram a
ideia de conjuntos formados por diferentes classificadores, os quais podem oferecer in-
formações complementares para aumentar a efetividade geral do processo de reconheci-
mento [66, 128]. Tal contexto tem levado à crença de que, com a aplicação em conjunto e
simultânea de caracteŕısticas e classificadores de diferentes tipos, as taxas de classificação
poderiam ser melhoradas [35, 146, 37, 36].
Basicamente, combinação de classificadores e seleção dinâmica de classificadores são
as duas principais abordagens para MCSs. Na primeira, as amostras questionadas são
submetidas aos classificadores, de forma individual e em paralelo. A partir disso, as de-
cisões individuais são combinadas seguindo alguma regra para alcançar uma decisão global
20
[25, 56, 60, 61]. Dentre suas desvantagens, destaca-se o fato da maioria de seus métodos
assumirem que os classificadores do conjunto cometem erros de classificação independen-
tes entre si. Embora esta premissa seja necessária para garantir o aumento da acurácia
da classificação com relação às acurácias individuais dos classificadores, ao se conside-
rar aplicações reais, geralmente é dif́ıcil projetar e treinar um conjunto de classificadores
independentes [35, 62, 65, 63, 64].
A seleção dinâmica de classificadores, por sua vez, tenta identificar o classificador com
maior probabilidade de classificar corretamente uma amostra questionada qualquer. Dado
que apenas um classificador é selecionado, automaticamente sua predição será assumida
como a decisão final para a amostra em questão [33, 35, 65, 63, 64, 146]. Como principal
vantagem, os métodos baseados na seleção dinâmica de classificadores não precisam assu-
mir a premissa quanto à independência dos erros dos classificadores. Contudo, precisam
que sejam estabelecidos os critérios utilizados para a seleção dos classificadores [33].
Mesmo diante da inviabilidade de se construir um modelo totalmente genérico para
a identificação das milhares de espécies florestais existentes, o presente trabalho busca
responder a seguinte questão: É posśıvel construir um sistema robusto para a
classificação de espécies florestais utilizando as caracteŕısticas texturais pre-
sentes nas imagens microscópicas de madeira, a representação no espaço de
dissimilaridade e MCSs? Diante desta questão também surgem as seguintes questões
secundárias: Quais são as melhores representações para as caracteŕısticas texturais utili-
zadas na construção de tal modelo de classificação? Para os classificadores constrúıdos no
espaço de dissimilaridade, qual a influência da quantidade de classes, amostras por classe
e referências por amostra no processo de classificação? Quais as vantagens e desvantagens
quanto ao uso de MCSs no processo de classificação? Ao se considerar o elevado número
de espécies florestais existentes, qual a influência de se avaliar as taxas de reconhecimento
do sistema nos diferentes ńıveis filo, famı́lia, gênero e espécie, definidos pela Botânica?
1.2 Desafios
O principal desafio deste trabalho compreende a construção de um sistema robusto para
a identificação de espécies florestais utilizando as caracteŕısticas texturais presentes nas
imagens microscópicas de madeira, a representação no espaço de dissimilaridade e MCSs.
Tal problema é caracterizado pela existência de um elevado número de classes, cada qual
com um reduzido número de amostras. Embora tal situação ocorra com frequência para
problemas reais, não foram encontradas referências a bases de imagens com tais carac-
teŕısticas para madeira e/ou espécies florestais. Neste sentido, destaca-se ainda que não foi
encontrada qualquer referência a bases de imagens microscópicas de madeira. Diante da
falta de recursos dispońıveis para o desenvolvimento do trabalho, a construção da base de
imagens utilizada já caracterizou um desafio, principalmente quando se compara a quan-
tidade e variedade de espécies nela compreendida (vide Tabelas A.1 e A.2, no Apêndice
21
A) com as demais bases encontradas na literatura (vide Tabela 3.1, no Caṕıtulo 3).
A base empregada compreende 112 espécies florestais diferentes, cada uma com 20
imagens, num total de 2.240 imagens. Algumas destas espécies tiveram sua origem no
decorrer do processo de evolução das plantas, situam-se nos limites entre os grupos de
Gimnospermas e Angiospermas e apresentam caracteŕısticas comuns a ambos. Adici-
onando maior grau de complexidade a este cenário, a combinação dos diferentes tipos
de células em diferentes proporções (vide Seção 2.1) com fatores internos e externos às
plantas (geralmente não pasśıveis de serem controlados) influenciam profundamente a
formação das estruturas celulares da madeira. Tais influências estão representadas na
base de imagens constrúıda e algumas delas podem ser percebidas nas ilustrações deste
trabalho.
Dentre os fatores internos, tem-se a localização da amostra no tronco, os defeitos, a
composição qúımica e o volume da matéria lenhosa. Para os fatores externos, destacam-
se as condições ecológicas e climáticas do ambiente em que a planta cresce, as pragas e
doenças, bem como a concorrência por espaço e demais recursos para o desenvolvimento
das plantas. Assim, podem haver pequenas variações entre amostras de diferentes espécies
e também variações maiores entre amostras pertencentes a uma mesma espécie. Tal
influência pode até mesmo conduzir a situações em que diferentes partes de uma mesma
amostra (planta e/ou espécie) não sejam idênticas e, consequentemente, não possuam as
mesmas possibilidades de aplicação [14].
Comparando as quatro imagens da Figura 1.1, identifica-se semelhanças entre as Fi-
guras 1.1(a) e 1.1(b) e entre as Figuras 1.1(c) e 1.1(d), como se tais pares pertencessem às
mesmas espécies. Porém, 1.1(a) e 1.1(c) são classificadas como Gimnospermas, enquanto
1.1(b) e 1.1(d) são classificadas como Angiospermas. No outro extremo, as Figuras 1.2(a)
e 1.2(b) ilustram a presença de diferenças nas estruturas celulares de plantas pertencentes
a uma mesma espécie. A primeira foi obtida de uma planta que cresceu no Brasil e a se-
gunda de uma planta que cresceu nos Estados Unidos da América (EUA) e, possivelmente,
tais diferenças são decorrentes de fatores geográficos e climáticos.
(a) (b) (c) (d)
Figura 1.1: Semelhanças entre plantas de espécies diferentes: (a) Cedrus libani, (b)
Melia azedarach, (c) Pseudotsuga macrolepsis e (d) Simaruba amara.
Além dos fatores identificados anteriormente, frequentemente há um número muito
reduzido de exemplares por espécie florestal dispońıvel para serem tomados como re-
22
(a) (b)
Figura 1.2: Amostras da Madeira de Taxodium distichum: (a) Brasil e (b) EUA.
ferências. Tal restrição limita a capacidade de generalização dos modelos elaborados e
suas aplicações a diferentes configurações. Neste sentido, tem-se claro que o corte de
plantas pertencentes a espécies em iminente extinção apenas para a coleta de tais amos-
tras não é plauśıvel. Ao mesmo tempo, mesmo que se sacrificasse uma única planta para
coletar algumas amostras, diante do conjunto de fatores que influenciam na composição da
madeira e em seu padrão textural, provavelmente não se alcançaria o grau de generalização
necessário.
Outro desafio durante a construção do sistema compreende a definição dos parâmetros
utilizados para gerar os vetores de dissimilaridade durante a mudança da representação
do espaço de caracteŕısticas para o espaço de dissimilaridade (vide Seção 2.3.1). Mesmo
diante do limitado número de exemplares, o processo de avaliação dos parâmetros consu-
miu grande esforço para identificar as melhores alternativas para a quantidade de classes,
amostras por classe e referências por amostra a serem utilizadas nas fases de treinamento
e classificação. As Seções 4.3 e 5.2 apresentam a metodologia empregada e os resultados
obtidos.
Por fim, destaca-se ainda a definição dos critérios para a seleção dinâmica de classi-
ficadores. De forma geral, a maioria dos métodos de seleção dinâmica de classificadores
utiliza critérios de vizinhança e medidas de distância. No entanto, alguns testes foram
realizados tomando medidas de distância entre a instância questionada e seus vizinhos do
conjunto de validação como critério de seleção do espaço de representação a ser utilizado
para a classificação. Todas as estratégias avaliadas mostraram-se inviáveis, visto que os
classificadores aqui considerados foram constrúıdos em espaços n-dimensionais diferentes.
Ou seja, os testes realizados demonstram a impossibilidade quanto à realização de com-
parações que envolvam as medidas de distância direta ou indiretamente entre os diferentes
espaços de representação, até mesmo quando normalizadas.
1.3 Objetivos
O objetivo geral deste trabalho consiste na construção de um sistema robusto para
classificação de espécies florestais a partir de caracteŕısticas texturais extráıdas
de imagens microscópicas de sua madeira. Para isso, tal sistema teve como base as
23
técnicas de seleção dinâmica de classificadores, os quais foram constrúıdos no espaço de
dissimilaridade.
Para o cumprimento do objetivo geral previamente definido, identificou-se os seguintes
objetivos espećıficos:
• Confeccionar uma base com imagens microscópicas de madeira para o desenvolvi-
mento de pesquisas em classificação de espécies florestais;
• Analisar e testar descritores para o uso em reconhecimento de espécies florestais,
considerando as taxas de reconhecimento alcançadas por cada um;
• Analisar a influência dos parâmetros utilizados durante a mudança da representação
do espaço de caracteŕısticas para o espaço de dissimilaridade, isto é, número de
classes, amostras por classe e referências por amostra;
• Propor, analisar e testar métodos de seleção dinâmica de classificadores, conside-
rando os critérios empregados e as taxas de reconhecimento alcançadas para cada
uma;
• Analisar as taxas de reconhecimento nos ńıveis definidos pela Botânica espécies,
gênero, famı́lia e filo, tendo em vista sua maior representatividade em termos de
diferenciação do conjunto de classes existentes na base de imagens constrúıda.
1.4 Contribuições
As contribuições deste trabalho podem ser relacionadas aos contextos cient́ıfico, social e
tecnológico.
Sob o contexto cient́ıfico, a principal contribuição deste trabalho constitui uma nova
abordagem para a identificação de espécies florestais por meio de imagens microscópicas
de sua madeira. Tal identificação está baseada em descritores texturais e na seleção
dinâmica de classificadores constrúıdos no espaço de dissimilaridade. Tal combinação
garantiu um modelo de classificação mais robusto que aqueles constrúıdos com a aborda-
gem de classificadores tradicionais e que pode ser utilizado para classificar amostras de
espécies inexistentes na base de imagens durante o treinamento dos classificadores. Esta
flexibilidade é interessante principalmente por permitir, pelo menos teoricamente, que a
base de imagens cresça constantemente sem a necessidade de reconstrução do modelo de
classificação.
É importante destacar que não foram encontradas referências quanto à seleção dinâmica
de classificadores no espaço de dissimilaridade na literatura, o que faz desta abordagem
um importante diferencial para o presente trabalho. Enquanto a seleção no espaço de
caracteŕısticas ocorreria uma única vez para cada amostra questionada, no espaço de
24
dissimilaridade esta ocorre para cada vetor de dissimilaridade criado para esta amostra
questionada e suas referências.
Além do modelo de classificação, foram apresentados e validados três novos métodos
para seleção dinâmica de classificadores. Tais métodos apresentaram taxas de reconhe-
cimento equivalentes ou superiores àqueles previamente apresentados por Woods et al.
[146] e Giacinto e Roli [33]. Embora os três métodos propostos tenham sido aplicados e
validados no espaço de dissimilaridade, eles também podem ser aplicados para a seleção
dinâmica de classificadores no espaço de caracteŕısticas, sem quaisquer alterações.
Diante da dificuldade de acesso às bases de imagens existentes, também foi necessário
construir uma base de imagens para o desenvolvimento de pesquisas em classificação de
espécies florestais. Esta possui número e variedade de espécies muito superior a qualquer
outra encontrada na literatura da área, sendo a única com imagens microscópicas que
se tem conhecimento. Publicada em [85], a base de imagens pode ser requisitada para
o desenvolvimento de pesquisas no endereço eletrônico http://web.inf.ufpr.br/ vri/forest-
species-database.
Ainda no contexto cient́ıfico, destaca-se a proposta quanto à avaliação das taxas de
reconhecimento do modelo para diferentes ńıveis definidos pela Botânica. Esta possibili-
dade se mostrou interessante ao se considerar que nem todas as situações de identificação
obrigam que se chegue ao ńıvel de espécie. Como previamente suposto, confirmou-se a
tendência de se obter taxas de reconhecimento melhores nos ńıveis superiores, devido à
redução gradativa do número de espécies e à reunião de agrupamentos menores dos ńıveis
inferiores que apresentam caracteŕısticas comuns. Ao mesmo tempo, mostrou-se que o
uso destes ńıveis num processo hierárquico de classificação não contribui para a melhoria
das taxas, embora agregue maior complexidade ao processo.
Sob o contexto social, garantiu-se a identificação da espécie florestal, independente
de fatores que se perdem com o decorrer do tempo, tais como folhas, frutos, casca, cor e
odor, dentre outros. Este foco, considerando caracteŕısticas texturais da madeira, permite
a identificação da espécie florestal a qualquer momento após a derrubada da árvore. Tal
facilidade provê melhores condições de fiscalização para os órgãos governamentais e de
certificação dos produtos negociados por particulares, pois estes dependem do aux́ılio de
especialistas que, muitas vezes, não estão presentes ou dispońıveis.
Por fim, sob o contexto tecnológico, a principal contribuição é a criação de um sistema
robusto para a classificação de espécies florestais. Tal sistema contempla os elementos
previamente descritos nesta seção, o que lhe provê importantes diferenciais com relação
àqueles propostos por Woods et al. [146], Giacinto e Roli [35, 36] e Ko et al. [64, 65].
1.5 Estrutura do Trabalho
A presente tese está organizado em seis caṕıtulos. O primeiro compreende sua motivação,
os desafios enfrentados, os objetivos gerais e espećıficos, bem como as contribuições desta
25
pesquisa. O Caṕıtulo 2 contempla a fundamentação teórica, os conceitos e os ferramen-
tais empregados. Neste sentido, tem-se uma explanação quanto às espécies florestais e sua
classificação pela Botânica. Neste caṕıtulo também são apresentados os descritores utili-
zados, a representação no espaço de dissimilaridade e dos sistemas baseados em múltiplos
classificadores, com seus métodos para seleção e combinação de classificadores.
O Caṕıtulo 3 apresenta uma breve contextualização do atual estado da arte em reco-
nhecimento de madeira. O Caṕıtulo 4 compreende a descrição da metodologia utilizada
durante o desenvolvimento do trabalho, dos métodos de seleção dinâmica de classificadores
propostos, bem como dos testes realizados e das configurações que geraram as melhores
taxas de reconhecimento. O Caṕıtulo 5 contém os resultados alcançados e sua discussão.
As considerações finais e os trabalhos futuros são apresentados no Caṕıtulo 6.
CAPÍTULO 2
FUNDAMENTAÇÃO TEÓRICA
Um sistema para reconhecimento de padrões (Figura 2.1) contempla as seguintes etapas:
aquisição; pré-processamento; segmentação; extração de caracteŕısticas; e classificação.
Por si só, cada etapa constitui um diferente contexto, possui diferentes ńıveis de comple-
xidade e envolve conhecimentos espećıficos próprios, além daqueles inerentes ao domı́nio
de aplicação abordado [21, 39, 112].
Figura 2.1: Sistema para o reconhecimento de padrões (Baseado em Duda et al. [25]).
Considerando os objetivos delimitados no Caṕıtulo 1, o presente trabalho compreende
cada uma das etapas identificadas na definição anterior. Neste sentido, este caṕıtulo
apresenta brevemente os conteúdos necessários para uma melhor compreensão do escopo
envolvido. Inicialmente apresenta-se uma visão quanto à Anatomia da Madeira (Seção
2.1), destacando-se os ńıveis de classificação definidos pela Botânica, os principais tipos
celulares e suas ocorrências. Tais ocorrências e suas frequências produzem padrões visuais
distintos (Figura 2.2) e conduzem ao emprego do conceito de textura, bem como das
técnicas para extração, representação e descrição das caracteŕısticas texturais (Seção 2.2).
A representação de relações entre objetos baseada no conceito de dissimilaridade e
Receiver Operator Characteristics (ROC) são apresentados na Seção 2.3, sendo impor-
tantes diferenciais para o presente trabalho. Por fim, a Seção 2.4 define os sistemas
compostos por múltiplos classificadores e destaca as abordagens empregadas para seleção
27
e combinação de classificadores.
(a) (b) (c) (d) (e)
(f) (g) (h) (i) (j)
(k) (l) (m) (n) (o)
Figura 2.2: Texturas decorrentes da Anatomia da Madeira: (a) Cephalotaxus drupa-
cea, (b) Chamaecyparis pisifera, (c) Larix sp, (d) Keteleeria fortunei, (e) Tsuga sp, (f)
Eschweilera matamata, (g) Copaifera trapezifolia, (h) Lonchocarpus subglaucencens, (i)
Parapiptadenia rigida, (j) Tabebuia rosea alba, (k) Myrcia racemulosa, (l) Rhamnus fran-
gula, (m) Prunus sellowii, (n) Melia azedarach e (o) Swietenia macrophylla.
2.1 Anatomia da Madeira
A International Association of Wood Anatomists (IAWA) coordena os trabalhos para
a descrição da anatomia da madeira. Tais trabalhos incluem a padronização quanto à
descrição e aos testes f́ısicos e mecânicos aplicados na identificação da madeira, além
da proposição de normas que englobam observações qualitativas e medições macro e mi-
croscópicas. Estas definições auxiliam a identificação das espécies florestais por meio dos
padrões texturais da madeira, os quais são decorrentes das estruturas anatômicas distin-
tas, com células de tipos, funções e caracteŕısticas f́ısicas diferentes [14].
Apesar da contribuição dos padrões texturais para a identificação das espécies flo-
restais, alguns aspectos tornam esse processo mais complexo. As espécies florestais são
classificadas de acordo com as definições da Botânica (vide Seção 2.1.2) e não da Anatomia
da Madeira. Como consequência, espécies relativamente próximas na estrutura definida
pela Botânica podem apresentar anatomias mais distintas entre si que outras mais distan-
tes. Além disso, as caracteŕısticas climáticas, concorrência por recursos e agentes nocivos
à planta possuem grande influência na caracterização textural da madeira.
28
2.1.1 Principais Estruturas definidas pela Anatomia da Madeira
Devido às diferentes formas, disposições e organizações das células, o aspecto e o com-
portamento f́ısico-mecânico da madeira variam à medida que se altera o ponto de ob-
servação. Neste sentido, os estudos anatômicos consideram (Figura 2.3(a)) três planos de
corte [4, 14, 68, 144]:
• Transversal (X): perpendicular ao eixo longo do tronco da árvore, expondo os anéis
de crescimento e demais componentes definidos à diante;
• Longitudinal Radial (R): divide o tronco ao meio, sendo paralelo aos raios ou per-
pendicular aos anéis de crescimento; e
• Longitudinal Tangencial (T): tangencia os anéis de crescimento e é perpendicular
aos raios.
Barker destaca que os textos referentes à identificação de madeira sempre consideram
superf́ıcies paralelas a estes planos de corte e que a adoção de diferentes planos produz
resultados confusos [4]. Ao se fazer um corte transversal em um tronco, basicamente
tem-se a visão apresentada na Figura 2.3(b). A Casca é o componente mais externo,
com a função de revestir o tronco e proteger a planta contra ações externas. O Câmbio
localiza-se entre o xilema (lenho ou madeira) e o floema, sendo o segundo responsável por
gerar novos elementos celulares que formarão o xilema e a casca [4, 14, 68, 144].
(a) (b)
Figura 2.3: Pontos de observação: (a) planos de corte; (b) estruturas macroscópicas no
plano de corte X.
O Cerne e o Alburno compõem o lenho. O primeiro situa-se na região mais interna
do tronco e geralmente apresenta uma coloração mais escura, por ser formado por células
fisiologicamente inativas. Já o alburno compreende a parte mais periférica (externa) do
tronco e é formado por células ativas [4, 14, 68, 144].
A Medula encontra-se normalmente no centro do tronco, armazena nutrientes e re-
aliza o transporte ascendente de ĺıquidos. Os anéis de crescimento caracterizam a
transição entre os lenhos inicial e tardio, respectivamente, formados nos peŕıodos anuais
29
em que as atividades fisiológicas das plantas atingem os pontos máximo e mı́nimo. As
células do lenho inicial apresentam paredes mais finas, lumes maiores e coloração mais
clara, enquanto aquelas do lenho tardio têm paredes mais espessas, lumens menores e um
aspecto mais escuro (vide Figura 2.4) [4, 14, 68, 144].
2.1.2 Grupos Vegetais produtores de Madeira
Diferentes alternativas foram propostas para melhor organizar os conhecimentos nas mais
diversas áreas das ciências. Estas geralmente definem divisões e subdivisões sucessivas,
sob uma estrutura de árvore, para se permitir a representação e a diferenciação das espe-
cializações dos subgrupos. A proposta de Carl Von Linné foi selecionada para o presente
trabalho por ser a mais clássica, sendo constitúıda por sete ńıveis: Reino, Filo (ou Di-
visão), Classe, Ordem, Famı́lia, Gênero e Espécie [145].
O mais alto ńıvel do sistema de classificação é o Reino, no qual os organismos são di-
ferenciados considerando sua organização celular (uni ou pluri-celulares) e os métodos de
nutrição (absorção, ingestão ou produção de alimentos). Logo abaixo tem-se o Filo, cujos
agrupamentos estão baseados nas similaridades quanto à organização e forma básicas dos
corpos. Na sequência, o ńıvel Classe considera principalmente o sistema de sustentação
(esqueleto, por exemplo), a capacidade geral de adaptação ambiental e o sistema repro-
dutivo. A Ordem agrupa famı́lias constitúıdas por espécies que apresentam um elevado
grau de semelhança genômica e morfo-funcional entre si, geralmente devido a uma ances-
tralidade comum [2]
No ńıvel Famı́lia tem-se conjuntos de gêneros afins, isto é, muito próximos ou pareci-
dos, embora possuam diferenças mais significativas do que a divisão em gêneros. Gênero
determina o nome genérico da espécie e agrupa espécies que compartilham um conjunto
muito amplo de caracteŕısticas morfológicas e funcionais, geralmente pela existência de
ancestrais comuns muito próximos. Espécie determina o nome espećıfico da espécie e
designa a unidade básica do sistema taxonômico utilizado na classificação cient́ıfica dos
seres vivos. Sob este ńıvel, os indiv́ıduos de cada agrupamento possuem profundas se-
melhanças estruturais e funcionais, podendo ser vistos como cópias imperfeitas uns dos
outros [2].
Considerando as definições apresentadas, sob o Reino das Plantas (Plantae), tem-se
as definições para o filo Angiospermae, classe Magnoliopsida, ordem Myrtales, famı́lia
Myrtaceae, gênero Eucalyptus e espécie globulus ; tem-se ainda para o Reino das Plan-
tas (Plantae), as definições para o filo Gymnospermae, classe Pinopsida, ordem Pinales,
famı́lia Araucareaceae, gênero Agathis e espécie becarii. Além destes, outros exemplos
podem ser encontrados no Apêndice A, sendo que basicamente as espécies produtoras de
madeira estão compreendidas nos filos Gimnospermas (Gymnospermae) e Angiospermas
(Angiospermae).
30
2.1.2.1 Gimnospermas
De origem grega, gimnosperma provém da união das palavras gymnos (nua) e sperma
(semente) e explicita o fato de suas sementes serem viśıveis externamente à planta. Suas
plantas são vulgarmente denominadas softwoods ou cońıferas, com aproximadamente 675
espécies, organizadas em 63 gêneros, e que se concentram nas regiões temperadas e frias
do globo terrestre. Na flora nativa brasileira são encontrados apenas os gêneros Arau-
caria, Podocarpus, Zamia, Gnetum e Ephedra. Embora somente Araucaria e Podocarpus
sejam formados por espécies produtoras de madeira, Gimnospermas possui grande im-
portância econômica devido à exploração das espécies exóticas introduzidas no páıs para
fins ornamentais e madeireiros, tais como as do gênero Pinus [14, 81].
A anatomia primitiva e o reduzido número de caracteŕısticas apresentadas implicam
numa maior dificuldade para diferenciação entre as espécies do grupo. Dentre as princi-
pais alternativas para sua caracterização no processo de classificação, tem-se os seguintes
componentes (Figura 2.4): traqueóides axiais, raios, células epiteliais e canais resińıferos
[14, 81].
Figura 2.4: Gimnosperma: Pinus elliottii.
Os traqueóides, com destaque para os axiais na Figura 2.4, podem compreender até
95% do volume da madeira, mas também estar ausentes em algumas espécies do grupo
Gimnospermas. Os raios armazenam nutrientes e os transportam no sentido horizontal.
Estes podem ser distingúıveis a olho nu e são importantes elementos da anatomia para a
identificação das espécies [4, 14, 68, 144].
Os canais resińıferos constituem uma das principais caracteŕısticas das espécies per-
tencentes ao grupo Gimnospermas, sendo importantes para a diferenciação destas espécies
com relação às do grupo Angiospermas. Viśıveis a olho nu em algumas espécies, estes
canais constituem espaços intercelulares delimitados por células epiteliais e, conforme
denominação, vertem resina. As células epiteliais, por sua vez, delimitam os canais
resińıferos e são especializadas na produção de resina [4, 14, 68, 144].
Apresentados na seção anterior, os anéis de crescimento são facilmente identificados nos
Gimnospermas, com lenho inicial menos denso devido à função de condução de substâncias
31
e lenho tardio mais denso devido à função de sustentação. Na Figura 2.4 destaca-se tal
formação para uma planta do grupo Gimnospermas, na qual as células menores e com
coloração em vermelho mais forte compõem o lenho tardio.
2.1.2.2 Angiospermas
Também de origem grega, angiosperma tem sua origem na união das palavras angios
(urna ou recipiente) e sperma (semente), por suas sementes estarem envolvidas por algum
invólucro. Embora mais de 250 mil espécies componham este grupo, apenas o subgrupo
Dicotiledôneas (vulgarmente denominadas hardwoods ou folhosas) agrega as espécies que
produzem madeira. De forma geral, este grupo é mais diversificado que o anterior, possui
um conjunto mais amplo de caracteŕısticas que permitem sua identificação, uma com-
posição anatômica mais especializada e complexa, além de maior capacidade evolutiva
e de adaptação às variadas condições ambientais do globo. Basicamente, vasos, fibras,
parênquimas e raios são os principais tipos celulares que caracterizam estas plantas (Fi-
gura 2.5) [4, 14, 68, 81, 82, 144].
Figura 2.5: Angiosperma: Porcelia macrocarpa.
Os vasos constituem a principal caracteŕıstica para diferenciar Gimnospermas e An-
giospermas, pois estão presentes em praticamente todas as espécies do segundo grupo.
Estes componentes realizam o transporte de água das ráızes para as folhas e são facil-
mente viśıveis com o aux́ılio de lentes ou mesmo a olho nu [4, 14, 68, 144].
As fibras constituem entre 20% e 80% do lenho dos Angiospermas, tendo a função
de sustentação nas plantas deste grupo e determinando o grau de resistência de sua
madeira. Importantes recursos para a distinção das espécies, os parênquimas (axiais
ou radiais - raios) armazenam, transformam e transportam nutrientes no Cerne e no
Alburno, constituindo as únicas células vivas no segundo componente. Geralmente mais
abundantes nos Angiospermas que nos Gimnospermas, parênquimas axiais raramente
estão ausentes em algumas espécies. Sua abundância implica em madeiras muito leves,
com baixa resistência e pouca durabilidade [4, 14, 68, 144].
32
2.2 Extração e representação de caracteŕısticas texturais
A escolha das caracteŕısticas a serem extráıdas das imagens e empregadas no processo
de classificação é altamente dependente do problema [21, 112]. Neste sentido, Pedrini e
Schwartz [112] afirmam que “um dos problemas básicos no desenvolvimento de um sis-
tema para análise de imagens é a seleção de um conjunto de caracteŕısticas extráıdas do
objeto de interesse para o propósito de classificação” (p. 248). Ampliando o ńıvel de com-
plexidade para a definição das caracteŕısticas a serem empregadas, tem-se as influências
de fatores como iluminação, sobreposição de objetos, se os objetos estão parados ou em
movimento, se há algum tipo de deformação, translação, rotação ou escala aplicado aos
objetos de interesse [21, 112].
Como alternativa, ao se voltarem para o sistema visual humano, Pedrini e Schwartz
[112] destacam a textura, com suas informações sobre a distribuição espacial, a variação
de luminosidade, o arranjo estrutural das superf́ıcies e as relações entre regiões vizinhas
[112, 150]. Contudo, embora o sistema visual humano seja capaz de reconhecer texturas
com os devidos graus de invariância quanto a escala, rotação e translação, para os sistemas
computacionais esta garantia ainda é muito dif́ıcil e principalmente custosa [150].
Para Pedrini e Schwartz [112], as soluções computacionais esbarram ainda no fato
de que “é extremamente dif́ıcil formalizar [a] definição [de textura] ou desenvolver um
conjunto de descritores ou medidas que possa ser utilizado para análise de imagens em di-
ferentes domı́nios de aplicações” (p. 287). Apesar da diversidade de definições existentes,
de forma geral, o conceito de Textura se refere às propriedades empregadas na repre-
sentação da superf́ıcie ou da estrutura de um objeto (Figura 2.6). Neste sentido, Conci
et al. [21] afirmam que os padrões apresentados pelas texturas podem representar carac-
teŕısticas f́ısicas, tais como rugosidade e reflexão da luz. Já Haralick [44] define textura
como um fenômeno espacial que pode ser decomposto em duas dimensões. A primeira
descreve as primitivas básicas que compõem a imagem e a segunda descreve a organização,
a interação ou mesmo a dependência espacial entre estas primitivas [21, 39, 44, 150].
(a) (b) (c) (d) (e)
Figura 2.6: Exemplos de textura da base Brodatz [11]: (a) ráfia; (b) areia; (c) cerca de
madeira; (d) tijolos; (e) casca de árvore.
A primitiva é definida como um conjunto conexo de células (pixels) com propriedades
locais semelhantes, muitas vezes denominadas Elementos de Textura (TEXture ELement
- TEXTEL ou Texton). Dentre tais propriedades pode-se elencar ńıveis de cinza, direção,
33
forma, comprimento e homogeneidade. Já os TEXTELs podem constituir elementos mais
simples (pixels, arestas e poĺıgonos) ou mesmos combinações destes, formando elementos
mais complexos (componentes conexos sob qualquer forma) [44, 94, 150].
Nasirzadeh et al. [95] afirmam que medidas baseadas em textura podem lidar melhor
com variação das condições de iluminação e sua influência nos ńıveis de cinza, principal-
mente para ambientes externos. Porém, a diversidade quanto às variações das primitivas
dificulta o reconhecimento por parte dos sistemas computacionais, os quais são ainda mais
prejudicados com variações de escala, rotação e translação [21, 39, 44, 45, 112]. Consi-
derando tais variações, Pedrini e Schwartz [112] classificam texturas como “ásperas” e
“finas”. Segundo os autores, “texturas ásperas” (Figura 2.6(c-e)) apresentam interações
espaciais melhor definidas e regiões mais homogêneas. Já as “texturas finas” (Figura 2.6(a-
b)) apresentam interações espaciais aleatórias e grandes variações nos ńıveis de cinza das
primitivas, sendo geralmente tratadas por abordagens estat́ısticas [44, 45].
As diferentes perspectivas quanto às definições das primitivas e seus relacionamentos
conduzem a abordagens distintas para a descrição das imagens. Diante da ampla gama de
alternativas, as seções seguintes restringem-se à apresentação daquelas empregadas neste
trabalho.
2.2.1 Métodos Estruturais
Na abordagem Estrutural a textura é definida como um conjunto de TEXELs arranjados
entre si de acordo com algum conjunto de regras. Seus métodos têm foco primário nas
formas definidas pelas fronteiras dos elementos, bem como na frequência e na organização
destes elementos na imagem. Seus descritores consideram o contorno ou os aspectos
inerentes à área, peŕımetro, excentricidade, orientação, centro de gravidade, retângulos
englobantes e contornos [21, 39, 44, 94, 112, 150].
2.2.1.1 LBP
O método Padrão Binário Local (Local Binary Pattern - LBP) foi introduzido, em 1996,
como uma medida complementar para contraste local de uma imagem em ńıveis de cinza,
sendo definido como invariante a mudanças monotônicas dos ńıveis de cinza. Em sua
versão original, LBP considera uma vizinhança-8 e distância um para o pixel central
(xc, yc) de uma máscara com dimensões 3×3 (Figura 2.7 (a)) [79].
Cada ponto da imagem é tomado como sendo o ponto central (xc, yc), cujo valor
é utilizado como limiar na comparação com o conteúdo de cada um de seus vizinhos
(xi, yi). Desta comparação gera-se uma cadeia de zeros e uns (Figura 2.7 (b)), pois cada
vizinho assume o valor um se seu conteúdo for maior que o do ponto central (xc, yc)
e zero caso contrário (Equação 2.2). A organização desta cadeia considera a posição
relativa j de cada um dos vizinhos, iniciando do canto superior-esquerdo com valor zero
34
Figura 2.7: Cálculo do padrão LBP para a região sobreposta por uma máscara 3×3
([90], p. 2).
e circundando o ponto central no sentido anti-horário (Figura 2.7 (c)). Ao ser tomada
como uma representação em base dois e convertida para a base dez (Equação 2.1), tem-se
o padrão que representa a região sobreposta pela máscara (Figura 2.7 (d-e)) [79].
Após gerar os padrões para todos os pontos da imagem, as frequências destes padrões
são contabilizadas por meio de um histograma com um total de 2P padrões para P vizi-
nhos. A consideração de P = 8 (Figura 2.8(a)) gera um total de 256 padrões de transição
de bits (Figura 2.7 (b)). Dentre estes padrões, apenas 58 atendem a definição de uni-
formidade, isto é, a ocorrência de, no máximo, duas transições do valor zero para um
e vice-versa. Todos os demais padrões são contabilizados juntos, levando a um total de
59 valores para o descritor denominado LBP uniforme (LBP u2P,R). Os autores afirmam
que a frequência dos padrões uniformes compreende cerca de 90% dos padrões para a
vizinhança (8,1) (Figura 2.8 (a)) e 70% dos padrões para a vizinhança (16,2) (Figura 2.8
(c)) [79, 103, 104].
LBPP,R(xc, yc) =
P−1∑
j=0
(xi, yi)2
j (2.1)
(xi, yi) =
{
1, se (xi, yi)>(xc, yc)
0, caso contrário
(2.2)
Posteriormente, esta proposta sofreu adequações para suportar invariância à rotação,
diferentes quantidades de vizinhos (P) e diferentes distâncias (R - raio) destes vizinhos
com relação ao ponto central, sendo genericamente denominados LBPPR. A variação de
P vizinhos (xi, yi) igualmente espaçados a um raio R do ponto central (xc, yc) é ilustrada
na Figura 2.8. A coordenada do vizinho (xi, yi), quando esta não coincide exatamente
com um ponto qualquer da imagem (Figura 2.8(b-c)), é dada pela Equação 2.3 e seu valor
é calculado pela interpolação bilinear de seus respectivos vizinhos [1, 151].
(xi, yi) =
(
xc +R cos
(
2πj
P
)
, yc +R sen
(
2πj
P
))
(2.3)
35
Figura 2.8: Operador LBPP,R extendido para P vizinhos e raio R ([90], p. 2).
LBP combina as abordagens estrutural e estat́ıstica, pois ao mesmo tempo explica a
textura por meio da formação do pixel e de sua vizinhança local. Ou seja, cada pixel é
representado por um código de primitiva de textura que melhor se adapta a sua vizinhança,
o que permite detectar pontos, áreas planas, arestas, fins de linha, cantos, entre outras
(Figura 2.9) [79].
Figura 2.9: Diferentes primitivas detectadas pelo operador LBP ([79], p. 4).
As versões invariantes à rotação LBPriP,R (LBP Rotation Invariant) e LBP
riu2
P,R (LBP
Rotation Invariant and Uniform) foram apresentadas por Ojala et al. [103], em 2002.
Estas mantêm a mesma definição básica de LBP e se beneficiam com a representação
circular da vizinhança e a invariância dos padrões binários (Figura 2.10). Tal invariância
é obtida por P rotações dos bits que compõem a representação binária dos padrões e a
identificação do menor valor decimal gerado. LBPriP,R acumula, em um mesmo elemento do
descritor, todos os padrões binários que mantêm o mesmo valor decimal mı́nimo LBPriP,R
(Equação 2.4) quando seus P bits são rotacionados (operação ROR). LBPriu2P,R combina as
definições LBPu2P,R e LBP
ri
P,R. Assim, usa apenas os padrões binários uniformes e acumula,
em um mesmo elemento do descritor, todos os padrões binários que mantêm o mesmo
valor decimal mı́nimo LBPriu2P,R (Equação 2.5) quando seus P bits são rotacionados. Tais
agrupamentos de padrões fazem com que LBPriP,R e LBP
riu2
P,R apresentem apenas 36 e 10
elementos em seus descritores, respectivamente. [1].
LBP riP,R =min{ROR(LBPP,R, i) | i = [ 0, P − 1 ] }. (2.4)
LBP riu2P,R =min{ROR(LBP u2P,R, i) | i = [ 0, P − 1 ] }. (2.5)
36
Figura 2.10: LBPriP,R: a rotação das imagens em α graus é refletida nas vizinhanças
circulares de seus pontos (x,y) ([1], p. 65).
2.2.1.2 LPQ
Proposto por Ojansivu e Heikkilä [105], em 2008, Quantização de Fase Local (Local Phase
Quantization - LPQ) se baseia na fase quantizada da transformada discreta de Fourier
(Discrete Fourier Transform - DFT). A informação da fase local de uma imagem (N×N)
é obtida por uma 2D-DFT (Transformada de Fourier de Curto Termo, do inglês Short-
Term Fourier Transform - STFT) computada para uma vizinhança retangular Vx (m×m)
para cada pixel x da imagem. A STFT f̂ui(x) para a imagem f(x) é dada pela Equação
2.6 e o filtro φui (m×m) pela Equação 2.7 [46, 122].
f̂ui(x) = (f ∗ φui)(x) (2.6)
φui = e
−j2πuTi y | y ∈ Vx (2.7)
com ∗ denotando a convolução de φui em f , j =
√
−1, r = (m− 1)/2 e o vetor base da
2D-DFT ui na frequência i.
LPQ considera apenas quatro coeficientes complexos que correspondem às frequências
bidimensionais u1 = [a, 0]
T , u2 = [0, a]
T , u3 = [a, a]
T e u4 = [a,−a]T , nas quais a
frequência a = 1/m. Tomando a notação vetorial, a STFT pode ser representada pela
Equação 2.8, na qual f(x) constitui o vetor com os m2 pixels da vizinhança Vx e Φui
representa o vetor base da 2D-DFT na frequência i (φui) [105].
f̂ui(x) = Φ
T
ui
f(x) (2.8)
Seja F = [f(x1), f(x2), ..., f(xN2)] e a matriz m
2×N2 para representar os m2 vi-
zinhos dos N2 pixels da imagem. Seja Φ = [ΦR,ΦI ]
T , com suas partes real ΦR =
Re{[Φu1 ,Φu2 ,Φu3 ,Φu4 ]} e imaginária ΦI = Im{[Φu1 ,Φu2 ,Φu3 ,Φu4 ]}. A STFT para to-
dos os pixels da imagem f(x) é dada por F̂ = ΦF , na qual F̂ é uma matriz de valores
reais e dimensões 8×N2 [46, 105, 122].
37
Ojansivu e Heikkilä [105] assumem que a função de uma imagem f(x) resulta do
processo de 1a ordem de Markov, na qual o coeficiente de correlação ρs entre os pixels
adjacentes xi e xj está relacionado exponencialmente com sua distância d
s
ij, além de uma
variação unitária para os pixels. Com os pixels de f(x) organizados em um vetor ~f , gera-
se a matriz de covariância C (m2×m2) com os elementos Ci,j dados pela Equação 2.9,
com dsij sendo a distância Euclidiana dada pela Equação 2.10.
Ci,j = ρ
dsij
s (2.9)
dsij =
√∑2
k=1
| xi(k)− xj(k) | 2 (2.10)
A matriz de covariância dos coeficientes de Fourier é, então, dada por D = ΦCΦT .
Tais coeficientes podem deixar de ser correlacionados pela transformação E = V T F̂ , sendo
V uma matriz 8×8 cuja transformação D′ = V TDV resulte em uma matriz D′ diagonal.
Tal matriz V pode ser obtida pelo cálculo dos eigenvectors de D que, por sua vez, podem
ser obtidos com a multiplicação dos valores singulares de decomposição (Singular Value
Decomposition - SVD) pelos eigenvalues de D [46, 105, 122].
Os coeficientes são quantizados usando a Equação 2.12, na qual ei,j ∈ E, e codificados
em valores decimais (8 bits, [0,255]) pela Equação 2.11. As frequências destes valores
decimais são, por fim, contabilizadas por meio de um histograma sob a forma de um vetor
com 256 posições [46, 105].
bj =
7∑
i=0
qi,j2
i (2.11)
qi,j =
{
1, se ei,j > 0
0, se ei,j < 0
(2.12)
Os autores afirmam que os códigos produzidos pelo LPQ são invariantes a borramentos
simétricos considerando um ponto central como referência, o que inclui movimentação
e falta de foco [3]. Embora tal invariância não seja completamente alcançada devido
ao tamanho finito da janela do filtro usado, o método ainda é altamente insenśıvel a
borramentos. Além disso, devido ao emprego de informações considerando fase, o método
também apresenta invariância a mudanças uniformes de iluminação [46, 105].
Inspirados nas variantes Local Binary Pattern from Three Orthogonal Planes (LBP-
TOP) e Volume Local Binary Pattern (VLBP) propostas por Zhao e Pietikäinen [151] para
LBP, em 2011 Päivärinta et al. [106] propuseram variantes similares para LPQ: Local
Phase Quantization from Three Orthogonal Planes (LPQ-TOP) e Volume Local Phase
Quantization (VLPQ). A variante LPQ-TOP foi também empregada neste trabalho e,
basicamente, é caracterizada pela aplicação da versão original LPQ nas três dimensões
38
das imagens dinâmicas e na concatenação dos vetores com os descritores, num total de
768 elementos. Para LPQ-TOP, os elementos da matriz C utilizada no cálculo da matriz
de covariância é obtido pela Equação 2.13, com dsij e d
t
ij dados pelas Equações 2.10 e
2.14, respectivamente. ρt representa o coeficiente de correlação entre os pixels adjacentes
xi e xj e está relacionado exponencialmente com sua distância d
t
ij no domı́nio temporal.
Por abordar imagens estáticas, o presente trabalho utilizou apenas os primeiros 256 do
total de 768 elementos, sendo que a diferença na aplicação das variantes LPQ e LPQ-
TOP está no fato de que elas utilizam valores diferentes para ρs, tendo sido identificado
complementaridade em seus resultados.
Ci,j = ρ
dsij
s ρ
dtij
t (2.13)
dtij = | xi(3)− xj(3) | (2.14)
2.2.1.3 SIFT
Transformação de Caracteŕısticas Invariantes à Escala (Scale Invariant Feature Transform
- SIFT) foi proposto por Lowe [75], em 1999, com o objetivo de identificar regiões de inte-
resse e extrair caracteŕısticas que permitam a comparação de imagens de objetos ou cenas
capturadas de diferentes perspectivas. As regiões identificadas são caracterizadas por pon-
tos que apresentam diferenças máximas e mı́nimas da função Gaussiana aplicada no que
o autor denomina espaço escala. Estas altas variações das regiões e escalas constituem
as principais garantias para a estabilidade do descritor e para a invariância a translação,
escala e rotação, além de invariância parcial a mudanças de iluminação e projeções 3D.
O autor afirma que, embora exista e provavelmente seja identificado um número elevado
destas regiões, a correlação entre duas imagens contendo um mesmo objeto pode ser es-
tabelecida com o uso de apenas três delas, o que provê certo grau de tolerância inclusive
a oclusões parciais [75, 76, 143].
A detecção das regiões de interesse é realizada por um processo de filtragem em cascata
tomando uma mesma imagem sob diferentes escalas. A cada iteração são tomadas novas
amostras dos pixels da imagem, as quais são geradas pela interpolação bilinear dos pontos
contidos numa vizinhança de raio 1.5 da escala imediatamente anterior. Este processo
garante a estabilidade do descritor, pois tenta correlacionar uma região detectada em
uma iteração com aquelas identificadas nas demais iterações. Este espaço escala de uma
imagem (Equação 2.15) é definido como uma função L(x, y, σ) produzida pela convolução
de uma variável escala Gaussiana G(x, y, σ) na imagem de entrada I(x, y), na qual ∗
representa a operação de convolução no ponto (x, y), G(x, y, σ) é dada pela Equação 2.16
[75, 76] e σ é a escala.
39
L(x, y, σ) = G(x, y, σ) ∗ I(x, y) (2.15)
G(x, y, σ) =
1
2πσ2
e−(x
2+y2)/2σ2 (2.16)
Para garantir a precisão das localizações das regiões de interesse, Lowe emprega a
função diferença da Gaussiana convolúıda na imagem (Equação 2.17), a qual pode ser
computada pela diferença de duas escalas próximas e separadas pelo fator multiplicador
constante k (k =
√
2). Para detectar os máximos e mı́nimos locais de D(x, y, σ), cada
ponto (x, y) é comparado com seus oito vizinhos na escala corrente e nove vizinhos nas
escalas imediatamente acima e abaixo. Os pontos selecionados nesta fase obrigatoriamente
são maiores (máximo) ou menores (mı́nimo) que todos seus vizinhos, mas ainda podem
ser eliminados caso apresentem baixo contraste (sensibilidade a rúıdos) ou componham
arestas [75, 76].
A escala de um ponto selecionado é utilizada na escolha da imagem L suavizada pela
Gaussiana, a partir da qual todas as computações são realizadas de forma invariante à
escala. Para cada ponto L(x, y) desta imagem (Figura 2.11(a)), considerando a escala
já predefinida, são computadas a magnitude m(x, y) e a orientação θ(x, y) do gradiente
por meio de diferenças entre pixels (Equações 2.18 e 2.19). A orientação do gradiente
da região de interesse é obtida pela composição de um histograma de orientações dos
pixels vizinhos a D(x, y, σ), sendo que cada pixel adicionado ao histograma é previamente
ponderado pela magnitude de seu gradiente local e uma Gaussiana circular também pon-
derada representada por um ćırculo na Figura 2.11(a). A orientação final do gradiente é
dada pelo maior valor do histograma [75, 76].
D(x, y, σ) = (G(x, y, kσ)−G(x, y, σ)) ∗ I(x, Y ) = L(x, y, kσ)− L(x, y, σ) (2.17)
m(x, y) =
√
(L(x+ 1, y)− L(x− 1, y))2 + (L(x, y + 1)− L(x, y − 1))2 (2.18)
θ(x, y) = tan−1((L(x, y + 1)− L(x, y − 1))/(L(x+ 1, y)− L(x− 1, y))) (2.19)
Embora o processo considere um conjunto de 4×4 descritores computados em uma
vizinhança 16×16, a Figura 2.11(b) mostra apenas 2×2 descritores computados em uma
vizinhança 8×8 (Figura 2.11(a)), o que não prejudica o entendimento. O processo de
cálculo dos descritores é semelhante ao descrito para a definição da orientação do gradiente
da região de interesse. Os pontos L(x, y) são ponderados pela Gaussiana identificada pelo
ćırculo na Figura 2.11(a). Estes são então acumulados em um histograma de orientação
40
que sumariza os conteúdos em 4×4 subregiões (Figura 2.11(b)), com o comprimento de
cada aresta correspondendo à soma das magnitudes dos gradientes que pertencem àquela
subregião e que possuem a mesma direção [75, 76, 143].
Figura 2.11: Descritor SIFT: (a) aplicação da máscara na imagem e obtenção dos gra-
dientes para cada direção na região sobreposta; (b) acúmulo dos gradientes para cada
subregião para as oito direções.
Considerando os histogramas das 4×4 regiões e que cada um acumula a avaliação
dos gradientes nas oito direções posśıveis, cada ponto é representado por um vetor de
caracteŕısticas com 128 elementos. Além disso, geralmente são detectados centenas ou
até milhares de pontos para cada imagem I, todos potencialmente candidatos a compor
o conjunto de caracteŕısticas que descreve I [75, 76, 143].
2.2.1.4 SURF
Proposto por Bay et al. [6], em 2006, Caracteŕısticas Robustas Aceleradas (Speed-Up
Robust Feature - SURF) apresenta semelhanças com relação a SIFT e também permite
detecção e descrição de regiões de interesse. Os autores afirmam que SIFT apresentou
o melhor desempenho dentre os descritores por eles analisados e que, dentre suas vanta-
gens, está a capacidade de capturar substanciais quantidades de informação dos padrões
espaciais e ainda ser robusto a pequenas deformações e erros de localização das regiões
detectadas. Porém, SIFT apresenta uma alta dimensionalidade em seu descritor e um
custo computacional que dificulta seu uso para aplicações on-line [5].
Seguindo esta linha de racioćınio, os autores propuseram um descritor com a metade
do número de elementos do SIFT e baseado em matrizes Hessianas, as quais garantem
maior estabilidade que detectores de cantos de Harris, além de apresentar boa performance
em termos de tempo computacional e acurácia. A proposta ainda inclui o uso de deter-
minantes da matriz Hessiana, devido a sua robustez quanto a estruturas mal localizadas
e alongadas, e o conceito de imagens integrais [5, 6].
41
As estruturas detectadas pelo SURF estão situadas em regiões que maximizam o de-
terminante da matriz Hessiana. Por definição, dado o ponto (x, y) na imagem I sob uma
escala σ, a matriz Hessiana H(x, y, σ) é dada pela Equação 2.20, na qual Lxx(x, y, σ)
representa a convolução da derivada parcial de segunda ordem da Gaussiana
∂2
∂x2
g(σ)
na imagem I no ponto (x, y). A mesma descrição é aplicada a Lxy(x, y, σ) e Lyy(x, y, σ)
[5, 6].
H(x, y, σ) =
[
Lxx(x, y, σ) Lxy(x, y, σ)
Lxy(x, y, σ) Lyy(x, y, σ)
]
(2.20)
O cálculo do determinante da matriz Hessiana H é apresentado na Equação 2.21, na
qual w representa um peso usado para preservar a energia entre os núcleos da Gaussiana
e os núcleos da aproximação da Gaussiana; e D representa as aproximações das derivadas
parciais de segunda ordem da Gaussiana nas respectivas direções x, y e xy [5, 6].
det(Happrox) = DxxDyy − (wDxy)2 (2.21)
O uso do conceito de imagens integrais reduz drasticamente o tempo de computação
devido aos filtros de convolução baseados em caixas (Figura 2.12). Por definição, cada
elemento de uma imagem integral I∑(x, y) representa a soma de todos os pixels da ima-
gem original I contidos na região retangular situada entre a origem e (x, y) (Equação
2.22). Diante disto, o cálculo da soma dos pixels contidos em uma região qualquer requer
apenas três operações de adição (Figura 2.12), o tempo necessário para aplicar qualquer
filtro à imagem permanece constante (independente de suas dimensões), todos os filtros
são aplicados na imagem integral sem a necessidade da criação de novas imagens por
meio de interpolações, os componentes de alta frequência são preservados e poderão ser
recuperados independentemente da escala corrente [5, 6].
I∑(x, y) =
i≤x∑
i=0
j≤y∑
j=0
I(i, j) (2.22)
Semelhante à informação do gradiente extráıda pelo SIFT, o descritor SURF repre-
senta a distribuição dos ńıveis de cinza na vizinhança do ponto de interesse (x, y). Para
isso, SURF considera a derivada de primeira ordem da wavelet de Haar. Uma vez detec-
tada uma região de interesse, sua orientação é determinada pelas respostas da wavelet de
Haar nas direções x e y para cada ponto contido na vizinhança do ponto de interesse. Tais
respostas, após serem multiplicadas por pesos definidos pela função Gaussiana centrada
no ponto de interesse, são representadas como pontos no espaço (Figura 2.13) e acumu-
ladas considerando as direções horizontal e vertical e uma janela deslizante de orientação
42
Figura 2.12: Imagem integral: ilustração do cálculo da soma dos pixels contidos em uma
subregião DBCA da imagem com apenas três operações de adição.
que abrange um ângulo de π/3. Por fim, o maior valor (vetor), considerando todas as pos-
sibilidades geradas durante o deslocamento da janela deslizante de orientação, determina
a orientação do ponto de interesse [5, 6].
Figura 2.13: Janela deslizante de orientação que com ângulo π/3.
Após identificar a região de interesse e sua orientação, o próximo passo consiste em
calcular os valores do descritor. Para isso, define-se uma região quadrada (8×8) centrada
no ponto de interesse e alinhada com a orientação previamente identificada (Figura 2.14).
Para cada um dos 64 elementos, obtém-se a resposta da wavelet de Haar nas direções
x e y, denominadas respectivamente dx e dy. Para cada subregião 2×2, dx, dy, |dx| e
|dy| são acumuladas separadamente, gerando 16 conjuntos com as quatro caracteŕısticas
({
∑
dx,
∑
dy,
∑
|dx|,
∑
|dy|}), num total de 64 elementos. Ao final, como SIFT, geral-
mente são detectados centenas ou até milhares de pontos para cada imagem I. Todos
estes pontos são invariantes à translação, escala e rotação, além de ser parcialmente inva-
riante a mudanças de iluminação e projeções 3D e potencialmente candidatos a compor
o conjunto de caracteŕısticas que descreve I [5, 6].
Os autores também apresentaram a variante SURF-128, a qual duplica o número de
caracteŕısticas que compõem o vetor final. Esta variante acumula dx e |dx| separadamente
para dy < 0 e dy≥0, sendo o mesmo considerado para dy e |dy| de acordo com o sinal de dx.
Embora esta variação garanta descritores mais discriminantes, a maior dimensionalidade
do vetor de caracteŕısticas exige maiores recursos computacionais [5, 6].
43
Figura 2.14: Descritor SURF: (a) aplicação da máscara 8×8 alinhada com a orientação
identificada e obtenção dos gradientes para cada direção na região sobreposta da imagem; (b)
acúmulo dos gradientes para cada subregião.
2.2.1.5 MSER
Em 2002, Matas et al. [88] conceituaram regiões extremas (Extremal Regions - ER)
e propuseram o algoritmo Regiões Extremas Maximamente Estáveis (Maximally Stable
Extremal Regions - MSER) para detectá-las. ERs são caracterizadas como componentes
conexos invariantes a transformações das coordenadas das imagens e a transformações das
intensidades de seus pixels. De forma simplificada, as regiões extremas são identificadas
por meio de uma sequência de limiarizações da imagem original (em ńıveis de cinza) e das
imagens binárias geradas (Figura 2.15). Tal sequência de imagens inicia com um quadro
totalmente branco e termina com um outro totalmente negro, passando por diversas
imagens intermediárias nas quais as regiões de interesse são identificadas. Tais regiões
se tornam cada vez maiores e se fundem à medida que o valor utilizado como limiar é
incrementado [77, 88].
Formalmente, Matas et al. [88] apresentam definições para imagem, região, borda da
região, regiões extremas e regiões extremas maximamente estáveis. Dada a Imagem I, a
qual representa um mapeamento I : D ⊂ Z2 → S, ERs são bem definidas em I se:
1. S é totalmente ordenado, isto é, há uma relação binária ≤ reflexiva, antisimétrica
e transitiva1.
2. Uma relação de adjacência (vizinhança) A ⊂ D × D é definida2.
Região Q é um subconjunto cont́ıguo de D, isto é, para cada p, q ∈ Q há uma
sequência p, a1, a2, ..., an, q e pAa1, aiAai+1, anAq.
Borda externa da regiao ∂Q = {q ∈ D \ Q : ∃ p ∈ Q : qAp}, isto é, a borda ∂Q
de Q é o conjunto de pixels adjacentes a, pelo menos, um pixel de Q, mas não pertence
1No trabalho original os autores assumem S = [0, 255], mas deixam claro que valores reais (S = R)
poderiam ser considerados.
2Os autores utilizam vizinhança-4, isto é, p, q ∈ D são adjacentes (pAq) se
∑d
i=1|pi − qi| ≤ 1.
44
(a) (b) (c) (d)
(e) (f) (g) (h)
Figura 2.15: Processo de definição das regiões extremas. Considere a imagem original
em (a) Porcelia macrocarpa. Após esta ser convertida para ńıveis de cinza, diferentes
limiares são aplicados e diferentes imagens binarizadas são geradas para a identificação
das regiões extremas. As imagens (b) a (h) ilustram os resultados para os limiares 31, 62,
93, 124, 155 e 186
.
a Q.
Região Extrema Q ⊂ D é a região tal que para todo p ∈ Q, q ∈ ∂Q : I(p) > I(q)
(região de intensidade máxima) ou I(p) < I(q) (região de intensidade mı́nima).
Região extrema maximamente estável. Considere Q1, ..., Qi−1, Qi,... como
uma sequência de regiões extremas aninhadas, isto é, Qi ⊂ Qi+1. Qi∗ é maximamente
estável se qi = |Qi+∆ \ Qi−∆| / Qi possui um mı́nimo local em i∗. Nesta notação, |.|
define a cardinalidade de um conjunto, isto é, o número de elementos presentes neste
conjunto; A \ B define o conjunto de todos os elementos de A que não estão em B; e ∆
e S são parâmetros do métodos.
Pelas definições anteriores, as ERs são identificadas apenas em função dos ńıveis de
cinza dos pixels que as compõem e daqueles externos a elas. Ou seja, tais regiões são
ou mais escuras ou mais claras que sua vizinhança, o que as tornam estáveis diante da
aplicação de diferentes limiares num processo de binarização. Os autores afirmam que tais
regiões devem ser estáveis e invariantes a escalas, a transformações das coordenadas das
imagens e a transformações das intensidades de seus pixels. A enumeração destas regiões
inicia com a ordenação dos pixels da imagem. Em seguida, tal sequência (crescrente ou
decrescente) é percorrida e as posições dos pixels na imagem permitem que os componentes
conexos e suas áreas sejam identidicados e mantidos por meio do algoritmo union-find.
Ao se encontrarem, duas ou mais regiões deixam de existir e dão origem a uma única
região maior, formada por todos os pixels previamente existentes nas antecessoras. Por
fim, ńıveis de cinza caracterizados como mı́nimos locais da taxa de mudança da área são
selecionados como limiares produzindo regiões extremas maximamente estáveis [32, 88].
A sáıda do algoritmo consiste do ńıvel de cinza mı́nimo (ou máximo) local e do limiar.
No entanto, não há uma busca por um limiar ótimo ou global, pois todos os limiares
45
são testados e a estabilidade dos componentes conexos avaliadas. Para os casos em que
existam múltiplos limiares estáveis, um sistema de subconjuntos aninhados é retornado
[88].
2.2.2 Métodos Estat́ısticos
Primeira abordagem utilizada na representação de textura, os métodos estat́ısticos cons-
tituem o maior conjunto de técnicas computacionais para este fim. Suas técnicas repre-
sentam textura como uma coleção de valores estat́ısticos obtidos para as caracteŕısticas
selecionadas para representar uma superf́ıcie [39, 112, 150].
Geralmente estes métodos caracterizam medidas de frequência espacial, direta ou indi-
retamente. Neste contexto, texturas finas apresentam altas frequências espaciais enquanto
texturas irregulares apresentam baixas frequências espaciais [44]. Isto permite a caracte-
rização de ńıveis de suavidade, aspereza e granularidade, bem como sua graduação diante
dos altos ńıveis de aleatoriedade caracteŕısticos [39, 112, 150]. Diante disto, as principais
aplicações dos métodos estat́ısticos focam texturas finas e sem a presença de primiti-
vas mais complexas, basicamente formadas por pontos com distribuição aparentemente
aleatória.
2.2.2.1 Medidas Estat́ısticas de Primeira Ordem
As propriedades texturais de uma imagem I podem ser representadas pelos momentos
estat́ısticos de primeira ordem. Estes momentos consideram a distribuição dos ńıveis
tonais e podem ser obtidos a partir de histogramas dos canais de I, considerando a
imagem total ou parcialmente.
Formalmente, considere a imagem I com dimensões M×N e L ńıveis de cinza. Seja z
uma variável aleatória que demonstra a intensidade discreta de I; ni o número de pixels
em I com o ńıvel tonal zi (i = [1, L]); p(zi) o histograma representando a probabilidade
de ocorrência do ńıvel tonal zi em I (Equação 2.23); e a intensidade média m (Equação
2.24). A partir destas definições, o n-ésimo momento angular de z (µn(z)) pode ser obtido
pela Equação 2.25, a partir do qual pode-se obter estat́ısticas e utilizá-las como descritores
para I [21].
p(zi) =
ni
MN
(2.23)
m =
L∑
i=1
zip(zi) (2.24)
µn(z) =
L∑
i=1
(zi −m)np(zi) (2.25)
46
O primeiro momento central (µ1) corresponde à própria média dos ńıveis tonais m
da Equação 2.24. O segundo momento central (µ2) é a variância (var) e representa
a distribuição dos ńıveis com relação aos valores médios e a homogeneidade da imagem
(Equação 2.26). A partir da variância obtém-se o desvio padrão σ (Equação 2.27), uti-
lizado nas estat́ısticas subsequentes. A obliquidade v (Equação 2.28) é derivada do
terceiro momento angular (µ3) e indica a assimetria da distribuição dos ńıveis em torno
da média. A curtose k (Equação 2.29) decorre do quarto momento angular e representa
o achatamento da curva de distribuição [21, 112].
var =
L∑
i=1
(zi −m)2p(zi) (2.26)
σ =
√
var (2.27)
v =
µ3
σ3(z)
(2.28)
k =
µ4
σ4(z)
− 3 (2.29)
Além destes, há outros momentos estat́ısticos da distribuição dos ńıveis tonais. Porém,
Gonzalez e Woods [39] afirmam que os demais não agregam informação quantitativa ao
conteúdo da textura. Além disso, os autores declaram que, de forma geral, os momentos
não possuem informações quanto à posição relativa dos pixels na imagem.
2.2.2.2 GLCM
Matriz de Co-ocorrência de Nı́veis de Cinza (Gray Level Co-occurrence Matrix - GLCM)
foi proposta por Haralick et al. [45], em 1973, e caracteriza-se como um dos mais co-
nhecidos métodos que exploram repetições de ocorrências de padrões. Tais padrões são
caracterizados pela dependência entre os ńıveis de cinza dos pixels das imagens e por sua
distribuição espacial. As repetições dos padrões provêem medidas quanto a propriedades
como rugosidade, suavidade e regularidade sob diferentes perspectivas com a variação dos
parâmetros direção e distância [141].
Formalmente, Haralick fundamenta GLCM pela seguinte definição: dada uma imagem
I com dimensões Nr×Nc, tal que Lr = [1, Nr] e Lc = [1, Nc] representam os posśıveis
valores para linhas e colunas, respectivamente; e L = [1, Ng] o conjunto de Ng ńıveis
de cinza quantizados de I. A imagem I pode ser representada como uma função que
associa algum ńıvel de cinza de G a uma célula ou par de coordenadas de Lr×Lc. Ou
seja, I : Lr×Lc→G [44, 45, 112].
A partir disto, Haralick define o uso de uma matrizNg×Ng para representar a frequência
Pij, tal que um pixel pi possua ńıvel de cinza ni e um pixel vizinho a pi (pj - a uma
distância d e um ângulo α) possua ńıvel de cinza nj. Embora Haralick tenha estabe-
47
lecido ângulos com intervalos de 45 graus, os cálculos podem assumir outros ângulos
[44, 45, 112, 135, 136].
Seguindo as definições anteriores, as GLCM da Figura 2.16(b-c) foram geradas para
a imagem da Figura 2.16(a) com Ng = 5, distância d = 1 e direções 0 e 45 graus,
respectivamente.
(a)
(b)
(c)
Figura 2.16: Geração de GLCMs: (a) fragmento considerado da imagem com apenas
cinco ńıveis de cinza; (b) GLCM para 00; e (c) GLCM para 450.
Dentre as posśıveis medidas extráıdas de GLCM, tem-se as 14 caracteŕısticas apre-
sentadas por Haralick et al. (em 1973) e Haralick (em 1979): Segundo Momento An-
gular, Contraste (Soma do Quadrado da Variância), Correlação, Variância (Soma dos
Quadrados), Momento de Diferença Inverso (Homogeneidade), Soma da Média, Soma
da Variância, Soma da Entropia, Entropia, Diferença da Variância, Diferença da Entro-
pia, Informação de Medidas de Correlação 1, Informação de Medidas de Correlação 2 e
Coeficiente de Correlação Máxima [44, 45].
Embora a proposta inicial tenha definido 14 elementos, a maioria dos trabalhos en-
contrados na literatura consideram diferentes subconjuntos destes e afirmam haver cor-
relações e/ou redundâncias entre as informações provenientes de alguns deles. Assim,
aqui empregou-se apenas seis das caracteŕısticas propostas por Haralick [44, 45]: energia,
contraste, entropia, homogeneidade, probabilidade máxima e momento de terceira ordem
(Equações 2.30 a 2.35). Ng é o número de diferentes ńıveis de cinza da imagem; i e j
são os ńıveis de cinza e servem como ı́ndices da GLCM; e P (i, j) é a probabilidade de
48
co-ocorrência do par (i, j) de ńıveis de cinza.
Energia =
√√√√Ng−1∑
i=0
Ng−1∑
i=0
{P (i, j)}2 (2.30)
Contraste =
Ng−1∑
i=0
Ng−1∑
i=0
|i− j|2P (i, j) (2.31)
Entropia = −
Ng−1∑
i=0
Ng−1∑
j=0
P (i, j)log(P (i, j)) (2.32)
Homogeneidade =
Ng−1∑
i=0
Ng−1∑
j=0
P (i, j)
1 + |i− j|2
(2.33)
Probabilidade Máxima =
Ng−1
max
i=0
P (i, j) (2.34)
Momento Terceira Ordem =
Ng−1∑
i=0
Ng−1∑
i=0
|i− j|3P (i, j) (2.35)
2.2.3 Métodos Espectrais
Os métodos compreendidos neste grupo transformam a representação da imagem do
domı́nio espacial para o domı́nio de frequência. Assim, permitem que as imagens sejam
analisadas considerando as frequências e as variações nas intensidades dos pixels, pro-
vendo invariância à escala em que a imagem esteja representada, uma vez que diferentes
resoluções podem caracterizar diferentes estruturas f́ısicas [21, 80, 112].
Dentre os métodos mais conhecidos deste grupo têm-se transformada de Fourier, filtros
de Gabor e Wavelets. A primeira alternativa não permite representar informações ine-
rentes a localização ou regiões espećıficas nas imagens. Já os filtros de Gabor apresentam
maior custo computacional quando comparados com Wavelets, embora seus resultados
geralmente superem aqueles obtidos com Wavelets [39, 101, 112]. Diante destas consi-
derações, optou-se pelo emprego dos filtros de Gabor, descritos na subseção seguinte.
2.2.3.1 Filtros de Gabor
Proposto em 1946 por Dennis Gabor, os filtros de Gabor são bastante utilizados para
segmentação de imagens, reconhecimento de faces e assinaturas, melhoria e identificação
de impressões digitais, criação de imagens sintéticas, além de outras aplicações de proces-
samento de imagens. Os filtros de Gabor caracterizam-se como um conjunto de funções
senoidais complexas, bidimensionais e moduladas por funções Gaussianas também bi-
dimensionais. Estes são invariantes a deslocamento e geram imagens caracteŕısticas de
Gabor r(x, y), as quais são resultantes da convolução do filtro g(x, y) centrado no ponto
49
(ξ, η) sobre a imagem original I(x, y) de dimensões M×N , tal como ilustrado na Equação
2.36 [21, 39, 40, 91, 149].
r(x, y) =
∫ M−1
x=0
∫ N−1
y=0
I(x, y)g(x− ξ, y − η)dxdy (2.36)
Dependendo dos parâmetros empregados por meio de g(x, y), isto é, ângulo θ e largura
da Gaussiana σ3, o filtro de Gabor permite a caracterização de orientação e frequência.
Porém, uma das principais dificuldades quanto a sua utilização consiste na definição des-
tes parâmetros. Uma posśıvel solução consiste no emprego de recursos como imagem
direcional4 para identificar os melhores valores quanto à orientação do filtro e à largura
da Gaussiana [21, 40].
A variação de g(x, y) implica também na alteração de seus parâmetros θ e σ e per-
mite a criação de diferentes conjuntos de filtros, geralmente referenciados como bancos de
filtros (Figura 2.17). Além disso, diferentemente da transformada de Fourier, os filtros
de Gabor permitem a captura de informações tanto em termos de frequência quanto em
termos temporais. Esta é uma de suas principais vantagens, sendo importante para o
reconhecimento de padrões por agregar maior riqueza de informações [39, 40].
Figura 2.17: Bancos de Filtros de Gabor: imagens das partes reais considerando cinco
escalas (ν = [0, 4]) e oito orientações (µ = [0, 7]), σ = 2π, kmax = π/2 e f =
√
2.
Neste trabalho empregou-se a implementação disponibilizada por Zhu et al. [153], a
qual se baseia na pesquisa desenvolvida por Lades et al. [69]. Zhu et al. simplificam a
3σ corresponde ao desvio padrão da distribuição normal e relaciona-se à largura da Gaussiana que
modula o filtro de Gabor e controla o tamanho da banda passante deste filtro.
4A imagem direcional é obtida com a aplicação de filtros especiais e determina o ângulo médio dos
elementos presentes na imagem filtrada.
50
Equação 2.36 com a expressão da Equação 2.37, com z sendo as coordenadas (x, y) na
imagem em ńıveis de cinza I. ∗ representa a convolução da famı́lia de filtros ψk centrados
na origem sobre I e Ok(z) é o resultado desta convolução. Os autores também definem a
famı́lia de filtros dada pela Equação 2.38, na qual k identifica o filtro ψk(z), criado com
a orientação µ e a escala ν. ψk(z) é definido como k(µ, ν) = kνe
iφµ para kν = kmax/f
ν ,
φµ = πµ/µmax e σ = 2π. kmax (kmax = π/2) define a frequência máxima, µmax identifica
o número máximo de orientações e f (f =
√
2) representa o fator de espaçamento entre
os filtros no domı́nio de frequência.
Ok(z) =I(z) ∗ ψk(z) (2.37)
ψk(z) =
‖k‖2
σ2
e‖k‖
2‖z‖2/2σ2 [eikz − e−σ2/2] (2.38)
2.3 Representação das relações entre objetos por meio do con-
ceito de dissimilaridade
Os conceitos de similaridade, dissimilaridade e proximidade têm sido discutidos sob di-
ferentes perspectivas [38, 114, 129]. Pekalska e Duin em [27, 113, 114] introduziram a
ideia de representar relações entre objetos por meio de suas diferenças e a denominaram
representação por dissimilaridade. Na proposta, os autores consideram um conjunto de
referências R (rj ∈ R; j = [1, n]), a amostra a ser classificada sq e seus respectivos vetores
de caracteŕısticas Vj e Vq. As referências em R são assumidas como protótipos das dife-
rentes classes Cll (l = [1,m]) existentes no problema em questão. Assim, dada a distância
d(Vq, R) entre sq e as referências em R, pela regra do vizinho mais próximo, sq é atribúıda
à classe Clj, tal que rj ∈ Clj e d(sq, rj) = min d(Vq, R). Ou seja, dentre as posśıveis
classes Cll, Clj é definida como a classe predita Clp.
Bertolini et al. [7] empregaram a ideia de vetores de dissimilaridade, combinando a
descrição baseada em caracteŕısticas com o conceito de dissimilaridade. Esta aborda-
gem foi escolhida para o presente trabalho por reduzir a complexidade de um problema
qualquer de m para 2 classes e pela independência dos modelos com relação às classes
empregadas nas fases de treinamento e classificação. A mesma é detalhada na próxima
seção, seguida de ROC que se caracteriza como alternativa para a avaliação de problemas
com duas classes.
51
2.3.1 Vetores de dissimilaridade e a mudança na representação
dos problemas de espaços n-dimensionais para o espaço
bidimensional
Bertolini et al. [7] consideram um conjunto S composto por p amostras (si∈S, i = [1, p])
e um conjunto R composto por n referências (rj∈R, j = [1, n]), bem como seus vetores
de caracteŕısticas V S e V R. A partir de S e R, as amostras si e as referências rj são
selecionadas e seus vetores de caracteŕısticas Vi (Vi ∈ V S) e Vj (Vj ∈ V R) são extráıdos.
Computa-se os vetores de dissimilaridade Zi,j, conforme Equação 2.39, na qual t representa
o número de caracteŕısticas utilizadas para descrever si e rj e define a dimensionalidade
de Vi, Vj e Zi,j.
Zi,j = d(Vi, Vj) = [|Vi,1 − Vj,1|, |Vi,2 − Vj,2|, ..., |Vi,t − Vj,t|] (2.39)
O emprego dos vetores de dissimilaridade Zi,j foca um momento posterior à extração
de Vi e Vj e é independente dos descritores utilizados. Dado o conjunto das amostras si
pertencentes à classe Cli, o conjunto R deve compreender referências rj pertencentes às
classes Clj positivas e negativas. As referências rj positivas (Figura 2.18(a)) pertencem à
mesma classe Cli que si, isto é, Cli = Clj. Assim, é esperado que os valores que compõem
Zi,j fiquem próximos de zero. Já as referências rj negativas (Figura 2.18(b)) pertencem a
classes Clj diferentes de Cli e os valores que compõem Zi,j devem divergir de zero [7, 43],
tal como ilustrado nas Figuras 2.19 (b) e (d).
(a) (b)
Figura 2.18: Cálculo dos vetores de dissimilaridade Zi,j: (a) amostras positivas; (b)
amostras negativas (Baseado em Hanusiak et al. [43]).
A partir da descrição anterior, identifica-se a redução da complexidade do problema
de m para 2 classes (Figura 2.19). Partindo da representação no espaço de caracteŕısticas
(Figuras 2.19 (a) e (c)), com m = 3 e as classes Cl1, Cl2 e Cl3, o cálculo de Zi,j muda a
representação do problema para o espaço de dissimilaridade (Figuras 2.19 (b) e (d)), no
qual haverá apenas as classes positiva (Cl+) e negativa (Cl−) [7, 27, 114].
A base de dados utilizada na criação do modelo de classificação no espaço de dissimi-
laridade é composta por Zi,j e não por Vi, como ocorre na classificação tradicional. Após
definir o subconjunto de vetores Zi,j utilizados para o treinamento, este é fornecido ao
classificador e o modelo é criado. Tal modelo define os limites para que cada vetor de
52
(a) (b)
(c) (d)
Figura 2.19: Transformação de um problema n-dimensional (a) e (c) para bidimensional
(b) e (d) [124, 125].
dissimilaridade Zq,j possa ser atribúıdo a uma das posśıveis classes, Cl+ ou Cl−.
Para classificar sq, esta deve ser fornecida ao sistema juntamente com as referências
rj∈R, positivas e negativas. Extrai-se seus vetores de caracteŕısticas Vq e Vj e calcula-se
Zq,j. Os vetores Zq,j resultantes são submetidos ao classificador e as decisões individuais
para cada Zq,j são combinadas (vide seção 2.4.1) para alcançar a decisão final para sq
[7, 43]. Após combinar as decisões individuais, a classe candidata Cll (no espaço de
caracteŕısticas) que maximizar as probabilidades para a classe positiva Cl+ será definida
como a classe predita Clp.
Outra vantagem desta representação consiste na independência do modelo quanto às
classes empregadas nas fases de treinamento e classificação. Tal independência possibi-
lita que o modelo seja utilizado para classificar amostras cujas classes não tenham sido
utilizadas em sua criação [7, 26, 27]. Porém, deve-se garantir que existam referências
pertencentes à classe real à que sq pertence. Caso contrário, sq será atribúıda à qualquer
classe Cll (negativa, no espaço de caracteŕısticas) que maximizar as probabilidades para
a classe Cl+ (no espaço de dissimilaridade).
Uma vez criado, um mesmo modelo poderá ser empregado para a classificação nos
contextos de identificação, verificação e monitoramento [7, 26, 27, 113, 114]. A Identi-
ficação exige que sq seja comparada com referências de todas as classes da base (1 : m)
e a classe candidata Cll (no espaço de caracteŕısticas) que maximizar as probabilidades
53
para a classe Cl+ será definida como a classe predita Clp para sq. A Verificação implica
em apenas uma comparação (1 : 1) com a suposta classe Cls. Se Cls (no espaço de carac-
teŕısticas) maximizar as probabilidades para a classe Cl+, confirma-se a suposição para
Cls. Caso contrário, não se pode determinar à que classe sq pertence. O Monitoramento
implica em uma comparação 1 : k, em que k representa um subconjunto de m (k≤m).
Tal subconjunto é definido por Jain et al. [57] como uma lista mantida pelo sistema e que
contém as identidades (ou classes) dos objetos desejados (monitorados). A cada objeto
detectado, o sistema compara com as referências de sua lista, o que situa o monitoramento
entre verificação e identificação.
Diante do elevado número de espécies florestais existentes (vide Seção 2.1), do reduzido
número de amostras por espécie (vide Apêndice A) e, consequentemente, da dificuldade
quanto à construção de modelos tradicionais para sua identificação, escolheu-se os modelos
constrúıdos a partir de vetores de dissimilaridade e o contexto de identificação. Tal escolha
caracteriza a tentativa de garantir robustez ao modelo, mesmo quando aplicado a espécies
não utilizadas durante o treinamento dos classificadores. Também procura-se otimizar os
modelos constrúıdos por meio da avaliação da influência de fatores como as quantidades
de classes, de amostras por classe e de referências utilizadas para cada amostra durante
a geração de seus vetores Zi,j. Tais fatores são mencionados por Bertolini et al. [7] e
Hanusiak et al. [43] e foram avaliados tanto no processo de construção do modelo quanto
no processo de classificação, diante de sua relevância para problemas com poucas amostras
por classe.
2.3.2 Caracteŕısticas de Receptor-Operador
Fawcett [31] afirma que considerar apenas a precisão de um classificador não é suficiente
para avaliar sua performance, principalmente se houver diferenças ou alterações das dis-
tribuições entre as classes e dos custos quanto aos erros de classificação. Neste sentido,
a Figura 2.20 ilustra a robustez de Caracteŕısticas de Receptor-Operador (Receiver Ope-
rator Characteristics - ROC) para ambientes imprecisos. Nela, verifica-se que alterações
inerentes às distribuições entre as classes não alteram os gráficos ROC enquanto o mesmo
não ocorre com a relação entre precisão e taxa tp (recall) [60, 61, 120, 121].
Como ilustrado na Figura 2.20, ROC provêem gráficos que permitem visualizar as
performances dos classificadores, bem como organizá-los e selecionar aqueles cujas perfor-
mances, individual ou em conjunto, forem melhor avaliadas. Tais ferramentas são úteis
para avaliar classificadores aplicados a problemas com apenas duas classes, uma positiva
(P) e outra negativa (N) [31, 61]. Este contexto é inerente aos problemas representados no
espaço de dissimilaridade e que geralmente apresentam um número maior de exemplares
para a segunda classe, tal como o deste trabalho.
A avaliação dos classificadores por meio de ROC pode empregar diferentes indicadores.
Para obtê-los, ao final do processo de classificação, gera-se uma Matriz de Confusão (MC)
54
(a) (b)
Figura 2.20: Invariância à distribuição das amostras entre as classes: (a) curvas ROC
idênticas para ‘taxa de erro igual’ (Equal Error Rate - EER, Equação 2.45); (b) curvas
para a relação precisão e taxa tp (Baseado em [31], p. 865).
bidimensional em que a diagonal principal representa os acertos e a diagonal secundária
representa os erros do classificador (Figura 2.21). Dentre os indicadores obtidos a partir
desta MC sob um contexto de avaliação mais geral, destaca-se a totalização de acertos e
erros dados por verdadeiros positivos (True Positive - TP), falsos negativos (False Negative
- FN), verdadeiros negativos (True Negative - TN) e falsos positivos (False Positive - FP).
TP compreende as amostras positivas classificadas como positivas. FN compreende as
amostras positivas classificadas como negativas. TN compreende as amostras negativas
classificadas como negativas. FP compreende as amostras negativas classificadas como
positivas. TP, FN, TN e FP são expressos em valores absolutos e permitem a derivação
de taxas em termos percentuais (Equações 2.40 a 2.45), o que facilita a avaliação da
performance dos classificadores [31, 42, 60, 61].
Figura 2.21: Matriz de confusão bidimensional representando os acertos (diagonal prin-
cipal) e os erros (diagonal secundária) de cada classificador ([31], p. 862).
55
A partir da combinação dos pares ordenados (taxa fp, taxa tp), denominados Pontos
de Operação (POs), gera-se as curvas ROC (Figura 2.20(a)). Plotadas em um gráfico
bidimensional, estas curvas permitem analisar as relações entre os custos (taxa fp) e
os benef́ıcios (taxa tp) dos classificadores [31, 83]. Com isso, tem-se diferentes limiares
para a decisão, o que não é posśıvel para as taxas derivadas da MC, por exemplo. Esta
flexibilidade quanto aos POs permite realizar ajustes diante de situações em que diferentes
tipos de erro tenham diferentes custos associados [31, 83].
Neste sentido, pode-se definir o PO ideal de acordo com a necessidade ou criticidade
quanto à tolerância a falhas de cada problema [31, 60, 61, 83]. Um exemplo quanto à
necessidade de definição de um PO poderia considerar um limite máximo para a classi-
ficação de Angiospermas como Gimnospermas, devido ao valor mais elevado da madeira
pertencente às espécies do primeiro grupo. Ou, num ângulo oposto, o ajuste poderia
contemplar a aceitação de Angiospermas classificados como Gimnospermas, mas não o
contrário, ao se selecionar materiais para edificações que devam ter maior vida últil ou
garantias quanto a resistência do material e segurança. Para o presente trabalho, não
houve qualquer especificação prévia dos POs. Assim, todas as classificações consideraram
a definição da Equação 2.45 (Figura 2.20) para a ‘taxa de erro igual’ (Equal Error Rate -
EER).
A representação gráfica das curvas ROC também permite a quantificação numérica
quanto à performance do classificador pelo cálculo da Área sob a Curva ROC (Area
Under a ROC Curve - AUC). Este valor numérico está compreendido no intervalo [0, 1]
e equivale à probabilidade de que um determinado classificador organize as amostras tal
que uma amostra positiva escolhida aleatoriamente possua maior score que uma amostra
negativa também escolhida aleatoriamente [31, 61, 83]. Ou, como afirmado por Khreich
et al [60], AUC representa a fração de pares positivos-negativos ordenados corretamente.
taxa tp =
TP
P
(2.40)
taxa fp =
FP
N
(2.41)
precisão =
TP
TP + FP
(2.42)
especificidade =
TN
N
ou 1− taxa fp (2.43)
acurácia =
TP + TN
P +N
(2.44)
taxa de erro igual =
FP
N
=
FN
P
(2.45)
Uma outra vantagem de ROC com relação à MC consiste no fato de que, ao se tomar
o processo de classificação, pode-se considerar que a organização caracteriza um processo
mais básico. Esta organização pode ocorrer previamente à classificação propriamente dita
56
ou prover uma sáıda final com uma ordenação das posśıveis classes de acordo com as
probabilidades da amostra pertencer a cada uma delas. Ou ainda, em contextos em que
não é necessário atribuir uma amostra questionada a alguma classe espećıfica, pode-se
apenas fornecer ind́ıcios (probabilidades) quanto a sua caracterização e deixar a decisão
para um especialista humano ou algum outro processo computacional [31, 42, 60, 61, 83].
2.4 Sistemas compostos por Múltiplos Classificadores
A grande variedade de problemas, representações de dados e algoritmos de classificação
geraram também diferentes alternativas de classificadores. Cada uma apresenta vantagens
e desvantagens em diferentes situações. Mesmo diante do emprego de um conjunto de
diferentes classificadores a um único problema, cada um poderá apresentar performance
superior aos demais em diferentes momentos. Estes fatos impossibilitam a escolha e o
emprego de um único classificador e conduzem aos Sistemas com Múltiplos Classificadores
(Multiple Classifier Systems - MCSs) [25, 31, 56, 60, 61].
Basicamente, as propostas para MCSs podem ser posicionadas em uma dentre três
posśıveis fases (Figura 2.22): geração, seleção e integração. Na primeira fase tem-se a
construção dos classificadores. A seleção não é caracterizada como obrigatória e consiste
na escolha de um subconjunto dos classificadores gerados na primeira fase. A fase de
integração compreende a combinação (interpolação) dos classificadores selecionados, caso
o subconjunto não contenha um único classificador [25, 31, 56, 60, 61].
Figura 2.22: Posśıveis fases para MCSs.
MCSs ainda podem ser classificados sob diferentes parâmetros. Sob a perspectiva dos
tipos das sáıdas dos classificadores, distingue-se três ńıveis: abstrato, ranking e probabi-
lidade (scores). Se o classificador provê apenas o rótulo da classe predita em suas sáıdas,
este é denominado abstrato. Se o classificador provê uma lista ordenada que indica a
sequência das posśıveis classes para uma amostra questionada, da mais provável à menos
provável, ele será denominado ranking. No último ńıvel, tem-se os classificadores cujas
sáıdas associam valores de probabilidade a posteriori (scores) quanto à predição para to-
das as classes definidas no problema [56]. Neste trabalho, considerando as estratégias de
combinação de classificadores apresentadas na Seção 2.4.1, cada um destes três tipos foi
utilizado em algum momento.
Outra posśıvel distinção quanto aos classificadores pode considerar os conjuntos resul-
tantes de sua combinação. Os conjuntos homogêneos contêm classificadores que imple-
mentam as mesmas técnicas e que alcançam diversidade por meio de variações em seus
57
parâmetros de configuração, tais como valores iniciais utilizados na construção dos mode-
los, diferentes subconjuntos dos dados de treinamento (Bagging [10] e Boosting [131]) e
diferentes subespaços de caracteŕısticas (Random Subspace Selection [47]). Já os conjun-
tos heterogêneos empregam diferentes tipos de classificadores, diferentes arquiteturas de
classificadores ou diferentes inicializações dos parâmetros de aprendizagem, embora man-
tenham os mesmos conjuntos de treinamento ou dados de entrada [130]. Sob esta perspec-
tiva, os classificadores empregados no desenvolvimento deste trabalho são heterogêneos,
gerados com diferentes descritores, mas mantendo exatamente as mesmas amostras em
seus conjuntos de treinamento, teste e validação.
O emprego de MCSs geralmente é vantajoso por aumentar a precisão, mas determinar
quais classificadores devem ser utilizados (constrúıdos, selecionados e/ou combinados)
não é uma tarefa tão trivial [25, 42, 51, 52, 60, 61, 62]. Primeiramente, a combinação de
classificadores depende do pressuposto de que todos os membros do agrupamento cometem
erros de classificação independentes. Se esta independência não for garantida, não será
posśıvel assegurar que a combinação de suas decisões implicará na melhoria das taxas
finais de classificação do agrupamento. Estas taxas finais podem, inclusive, piorar em
alguns casos [24, 51, 52, 56, 62, 130].
Assumindo a independência dos erros dos classificadores, sua combinação permite o
uso de modelos mais simples sob a perspectiva individual e eleva a precisão do conjunto
de classificadores [25, 51, 52, 62, 118]. Para isso, a combinação deve garantir o em-
prego de classificadores complementares [7, 47, 56, 78]. A complementaridade garante
que haja uma distribuição dos riscos entre os classificadores e que estes cometam erros
não-correlacionados diante de novos padrões [24, 51, 52, 62, 65, 63, 64]. No entanto, nas
aplicações reais de reconhecimento de padrões, é dif́ıcil projetar um conjunto de clas-
sificadores que satisfaça tal critério de independência mútua quanto a suas predições
[33, 37, 51, 52, 146].
As seções seguintes apresentam algumas alternativas quanto a combinação e/ou seleção
de classificadores.
2.4.1 Combinação de Classificadores
De acordo com Jain et al. [56], MCSs podem ser agrupados em três diferentes topolo-
gias (série, paralela e hierárquica), havendo ainda derivações e combinações destas. Neste
trabalho, a topologia em Paralelo foi a única utilizada na combinação das sáıdas dos
classificadores (vide Seção 4.5). Esta define o emprego dos classificadores de forma in-
dependente e, posteriormente, a combinação de seus resultados. Todos os classificadores
trabalham com um mesmo escopo do problema e os erros individuais de cada classificador
não interferem nos resultados individuais dos demais. Porém, o desempenho obtido por
implementações desta topologia sofre grande influência da estratégia de combinação de
classificadores adotada [56].
58
Dentre as regras de combinação das sáıdas dos classificadores, as mais conhecidas são:
voto majoritário, borda count, soma, média, produto, máximo e mı́nimo. Em cada caso,
a aplicação dessas regras poderá gerar resultados completamente diferentes de outra e
influenciará nas taxas resultantes. Além disso, exceto para a duas primeiras regras, os
classificadores devem fornecer sáıdas com probabilidades [56, 62].
As Equações 2.47 a 2.53 apresentam as fórmulas para as regras anteriormente menci-
onadas. Nelas, sq é a amostra questionada, Vq é o vetor de caracteŕısticas extráıdas para
sq e empregado por cada um dos K classificadores Ck (k = [1, K]), Cll representa cada
uma das m classes (l = [1,m]) consideradas no domı́nio de aplicação, p(Vq|Cll) é a função
de densidade probabilidade, P (Cll) é a probabilidade de ocorrência a priori de p(Vq|Cll),
P (Cll|Vq) é a probabilidade a posteriori. Todas as regras consideram a teoria Bayesiana,
associando sq à classe predita Clp com o maior valor para a probabilidade a posteriori
dentre todas as classes Cll (Equação 2.46) [56, 62].
sq→Clp se
P (Clp|Vq) =
m
max
l=1
P (Cll|Vq) (2.46)
O voto majoritário constitui a regra mais simples e conhecida para combinar classi-
ficadores, sendo que cada classificador representa um voto (Equação 2.47). Para cada
amostra sq, os votos são totalizados para cada classe Cll e a que obtiver o maior número
de votos se torna a classe predita Clp para sq. De acordo com a Equação 2.48, o voto
do classificador Ck é atribúıdo à classe Cll com a maior probabilidade a posteriori. Sua
principal vantagem está em sua simplicidade e facilidade em ser empregada, além de po-
der ser utilizada quando as sáıdas dos classificadores provêem apenas o rótulo das classes
preditas por cada um [56, 62].
sq→Clp se
K∑
k=1
∆pk =
m
max
l=1
K∑
k=1
∆lk, com (2.47)
∆lk =
 1, se P (Cllk|Vq) =
m
max
j=1
P (Cljk|Vq)
0, caso contrário.
(2.48)
A regra Borda count foi proposta por Black [8] e necessita que as sáıdas dos clas-
sificadores forneçam uma lista ordenada com as posśıveis classes e, possivelmente, as
probabilidades (ranking) para cada uma destas classes. Para cada posição da lista é de-
terminado um valor ou pontuação, o qual será atribúıdo à classe que ficar posicionada
naquele ponto da lista por um determinado classificador. Ao final do processo, a com-
59
binação se dá pela soma destes pontos e a classe que acumular mais pontos determinará
a classe predita Clp. No caso de haver a determinação de um ranking com probabilidades
pelos classificadores, estas probabilidades deverão ser totalizadas e a classe que obtiver
maior valor será a classe predita Clp [8, 48].
Nesta regra de combinação a classe correta não necessariamente precisa aparecer como
a primeira do ranking, mas apenas ocupar posições próximas à primeira na maioria das
sáıdas dos classificadores. A Figura 2.23 apresenta um exemplo quanto à aplicação desta
regra para cinco classes e três classificadores (sem probabilidades). Uma pontuação entre
um e cinco, identificada pelas colunas ‘Rank ’, é atribúıda para cada classe de acordo com
a posição determinada pelo classificador. Ao totalizar a pontuação destes classificadores
nas Figuras 2.23 (a-c)), o maior número de pontos foi acumulado pela classe dois (Figuras
2.23 (d)). Esta é definida como “vencedora”, mesmo com apenas um dos classificadores
a identificando como tal [8, 48].
Figura 2.23: Borda count.
A regra Produto combina as probabilidades finais para cada classe Cll por meio de
um produtório entre as probabilidades associadas às sáıdas dos classificadores para esta
classe (Equação 2.49) [56, 62].
sq→Clp se
K∏
k=1
P (Clpk|Vq) =
m
max
l=1
K∏
k=1
P (Cllk|Vq) (2.49)
A Soma combina as probabilidades finais para cada classe Cll pelo somatório das
probabilidades associadas às sáıdas dos classificadores Ck (Equação 2.50). De forma
semelhante, a Média (Equação 2.51) calcula a média entre as probabilidades associadas
às sáıdas dos classificadores para cada classe Cll. Estas regras geralmente apresentam
bons resultados e semelhanças entre os mesmos [56, 62].
60
sq→Clp se
K∑
k=1
P (Clpk|Vq) =
m
max
l=1
K∑
k=1
P (Cllk|Vq) (2.50)
sq→Clp se
1
K
K∑
k=1
P (Clpk|Vq) =
m
max
l=1
1
K
K∑
k=1
P (Cllk|Vq) (2.51)
Máximo (Equação 2.52) é uma regra que define como vencedora a classe que apresentar
a maior probabilidade dentre todos os classificadores. Uma classe poderá ser declarada
vencedora mesmo que apresente bom desempenho apenas para um dos classificadores. Já a
regra de combinação Mı́nimo (Equação 2.53), inicialmente obtém o menor valor atribúıdo
por cada classificador para cada uma das classes. A partir destes valores, define-se a
classe vencedora selecionando-se a que apresentar a maior probabilidade dentre todos os
classificadores [56, 62].
sq→Clp se
K
max
k=1
P (Clpk|Vq) =
m
max
l=1
(
K
max
k=1
P (Cllk|Vq)) (2.52)
sq→Clp se
K
min
k=1
P (Clpk|Vq) =
m
max
l=1
(
K
min
k=1
P (Cllk|Vq)) (2.53)
Considerando as regras que exigem o emprego de probabilidades (produto, soma,
média, máximo e mı́nimo) e que estes valores sejam expressos no intervalo [0,1], estas po-
dem ser categorizadas de acordo com sua severidade (Equação 2.54). Produto caracteriza-
se como a mais severa, pois a ocorrência de pelo menos uma probabilidade com valor baixo
para uma classe Cll em um dos classificadores Ck incorrerá em um valor resultante final
baixo a ser associado a Cll. Esta regra é indicada para situações de extrema criticidade,
nas quais erros não são tolerados ou a tolerância permite taxas de erros muito pequenas.
Mı́nimo é considerada severa e Máximo é uma regra de baixa severidade [56, 62].
61
K∏
k=1
P (Cllk|Vq) ≤
K
min
k=1
P (Cllk|Vq) ≤ ...
≤ 1
K
K∑
k=1
P (Cllk|Vq) ≤
K
max
k=1
P (Cllk|Vq)
(2.54)
2.4.2 Seleção de Classificadores
Dado um conjunto com K classificadores, a melhor alternativa para sua combinação não
necessariamente implicará na utilização de todos eles, mas na escolha daqueles que se
demonstrarem complementares. O emprego de classificadores com sobreposição pode
implicar no aumento do custo computacional, bem como na redução das taxas de re-
conhecimento individuais [56, 78, 130]. Assim, a seleção de classificadores provê maior
flexibilidade aos sistemas e estabelece diferentes alternativas para a escolha de um sub-
conjunto dos classificadores dispońıveis, para sua posterior combinação na classificação
de um conjunto de amostras [7, 24, 47].
Tomando como parâmetro o momento em que o conjunto de classificadores é determi-
nado, a seleção pode ser definida como estática ou dinâmica. Na seleção estática, todas as
amostras questionadas sq são classificadas por um subconjunto fixo de classificadores, o
qual é definido na fase de treinamento. Por outro lado, na seleção dinâmica, o subconjunto
de classificadores é definido durante a fase de classificação, considerando as caracteŕısticas
das diferentes sq [56, 65, 63, 64, 127, 130].
As principais alternativas quanto à seleção de classificadores são apresentadas na Fi-
gura 2.24. Na Seleção Estática de Agrupamento (Figura 2.24(a)), um subconjunto dos
classificadores dispońıveis é pré-selecionado durante o treinamento. O mesmo subconjunto
é então empregado para a classificação, independentemente de variações na caracterização
do problema ou das amostras. Na Seleção Dinâmica de Classificador (Figura 2.24(b))
um único classificador é escolhido com base nas caracteŕısticas da amostra. A Seleção
Dinâmica de Agrupamento (Figura 2.24(c)) considera as caracteŕısticas de cada sq para
selecionar um subconjunto de classificadores. Tanto no primeiro quanto no terceiro caso,
as sáıdas dos classificadores selecionados são combinadas seguindo critérios que podem va-
riar em função dos classificadores escolhidos. De modo diferente, a decisão do classificador
selecionado no segundo caso é assumida como a decisão final do sistema [65, 63, 64].
Por necessitar que apenas um classificador realize a predição corretamente para cada
amostra, a criação de MCSs baseados em seleção de um único classificador torna-se bem
mais simples que a criação de MCSs baseados em seleção e/ou combinação de múltiplos
classificadores. Entretanto, a seleção de agrupamentos tende a apresentar melhores resul-
tados [33, 35, 146]. Considerando as limitações e o foco deste trabalho, a próxima subseção
descreve alguns métodos para seleção dinâmica de um único classificador e também para
62
(a) (b) (c)
Figura 2.24: Alternativas para a seleção de classificadores [64]: (a) seleção estática de
agrupamento; (b) seleção dinâmica de classificador; e (c) seleção dinâmica de agrupa-
mento.
a seleção dinâmica de agrupamentos de classificadores.
2.4.2.1 Seleção Dinâmica de Classificadores
Algumas alternativas têm sido propostas para minimizar ou eliminar a imposição quanto
aos classificadores independentes. Dentre estas, têm-se conjuntos de classificadores não-
correlacionados [108, 126], funções de combinação que não impõem tal independência
[51, 52] e seleção dinâmica de classificadores [33, 34, 35, 146].
As estratégias empregadas na seleção dinâmica de classificadores podem considerar
diferentes critérios de competência durante a escolha do subconjunto dos classificadores.
Alguns critérios concentram-se na interação entre os elementos do conjunto por meio
de sua diversidade e ambiguidade enquanto outros baseiam-se nas taxas individuais dos
classificadores na vizinhança da amostra questionada sq (Local Accuracy) [7, 24, 47, 56,
63, 64, 65, 78, 130].
Este trabalho concentra-se no segundo grupo e em suas posśıveis alternativas para a
seleção dinâmica de um único classificador ou de agrupamentos de classificadores. Algu-
mas destas alternativas são brevemente apresentadas nesta seção e utilizam as definições
da Seção 2.4.1. Além disso, conforme apresentado no Caṕıtulo 1 e detalhado na Seção 4.4,
devido à representação baseada em vetores de dissimilaridade, a seleção e/ou combinação
dos classificadores ocorre neste espaço de representação. Ou seja, enquanto a seleção
no espaço de caracteŕısticas ocorreria uma única vez para a amostra questionada sq, no
espaço de dissimilaridade esta ocorre para cada vetor de dissimilaridade Zq,j criado para sq
63
e as referências utilizadas rj. Destaca-se também que não foi necessário realizar quaisquer
alterações nos métodos de seleção dinâmica de classificadores originais para empregá-los
neste estudo. Ao mesmo tempo, os métodos propostos na Seção 4.4.2, embora tenham
sido empregados apenas no espaço de dissimilaridade, também podem ser utilizados no
espaço de caracteŕısticas.
Para definir a relação de proximidade entre sq e os vizinhos mais próximos (referências
rj) do conjunto de validação, Woods et al. [146] utilizaram a distância Euclidiana d(sq, rj).
Os autores estimam a acurácia de cada classificador na vizinhança de sq e selecionam o
classificador mais preciso nesta vizinhança, assumindo esta decisão individual como a
decisão global do MCS para sq.
Implicitamente, os mesmos autores também definem critérios Acurácia Local Geral
(Overall Local Accuracy - OLA) e Acurácia de Classe Local (Local Class Accuracy -
LCA) para a delimitação da vizinhança, os quais são utilizados por outras técnicas. Pelo
critério OLA, todas as h referências do conjunto de validação compõem a vizinhança de
sq. Já o critério LCA limita a vizinhança de sq para cada classificador Ck. Ou seja, pelo
critério LCA, dado que Ck classifique sq como pertencente à classe Cll, a vizinhança de
sq será composta apenas pelas hl (hl≤h) referências do conjunto de validação também
pertencentes à Cll.
Proposto por Woods et al. [146], o método OLA (Pseudo-código 2.1) emprega o
critério OLA ao delimitar a vizinhança de sq. Este considera que o classificador mais
preciso C∗ é definido pela maximização da taxa de vizinhos corretamente classificados em
todo o conjunto de Validação (Equação 2.55), com hk sendo a quantidade de vizinhos
corretamente classificados pelo classificador Ck [63, 64, 65, 146].
C∗ =
K
max
k=1
hk
h
(2.55)
O método LCA (Pseudo-código 2.2) emprega o critério LCA para delimitar a vizi-
nhança de sq. Conforme a Equação 2.56, o classificador selecionado C
∗ será aquele que
maximizar a relação entre os vizinhos por ele corretamente classificados e pertencentes à
classe Cll (hlk) e todos os vizinhos pertencentes à classe Cll (hl) [63, 64, 65, 146].
C∗ =
K
max
k=1
hlk
hl
(2.56)
Giacinto e Roli [35] demonstraram que um classificador Bayseano ótimo pode ser
obtido por meio da seleção de um classificador Ck considerando as probabilidades de
suas predições corretas. A partir disto, os autores assumem classificadores probabiĺısticos
(scores), ao invés dos abstratos (rótulos) considerados por Woods et al. [146], e propõem
variantes dos métodos anteriores. Por considerar apenas as probabilidades das predições
corretas, a vizinhança é limitada a hk nas Equações 2.57 e 2.58, bem como a hlk nas
Equações 2.59 e 2.60.
O método a priori (Pseudo-código 2.3) baseia-se no método OLA e no critério OLA
64
Pseudo-código 2.1. Método OLA.
Detalhes: classificadores abstratos, critério OLA para delimitação da vizinhança.
Entradas: conjunto de validação, rótulos associados por cada classificador Ck
para todo o conjunto de validação, tamanho h da vizinhança.
Sáıda: classificador Ck que maximiza a taxa de vizinhos corretamente classificados.
1: ordene os elementos do conjunto de validação considerando suas distâncias
Euclidianas para sq, em ordem crescente
2: para cada classificador Ck faça
3: conte os hk vizinhos mais próximos corretamente classificados por Ck
4: calcule a taxa de vizinhos corretamente classificados por Ck (Eq. 2.55)
5: fim-para
6: selecione Ck que maximiza a taxa de vizinhos corretamente classificados
calculada nos passos 2-5.
Pseudo-código 2.2. Método LCA.
Detalhes: classificadores abstratos, critério LCA para delimitação da vizinhança.
Entradas: conjunto de validação, rótulos associados por cada classificador Ck
para todo o conjunto de validação, tamanho hl da vizinhança, rótulo da classe
Cll associada por Ck à sq.
Sáıda: classificador Ck que maximiza a taxa de vizinhos corretamente classificados.
1: ordene os elementos do conjunto de validação considerando suas distâncias
Euclidianas para sq, em ordem crescente
2: para cada classificador Ck faça
3: selecione os hl vizinhos mais próximos no conjunto de validação
4: conte os hlk vizinhos mais próximos corretamente classificados por Ck
5: calcule a taxa de vizinhos corretamente classificados por Ck (Eq. 2.56)
6: fim-para
7: selecione Ck que maximiza a taxa de vizinhos corretamente classificados
calculada nos passos 2-6.
para delimitar a vizinhança de sq, com a Equação 2.57 substituindo Equação 2.55. Com o
intuito de minimizar a incerteza inerente ao tamanho da vizinhança, os autores também
propõem a aplicação dos pesos Wi = 1/d(sq, rj) correspondentes às distâncias Euclidianas
entre sq e seus vizinhos rj por meio da Equação 2.58 [35].
C∗ =
K
max
k=1
hk∑
i=1
P̂ (Cllk | Vi ∈ Cll)
hk
(2.57)
C∗ =
K
max
k=1
hk∑
i=1
P̂ (Cllk | Vi ∈ Cll)Wi
hk∑
i=1
Wi
(2.58)
O método a posteriori (Pseudo-código 2.4), por sua vez, é baseado no método LCA
e no critério LCA para delimitar a vizinhança de sq, com a Equação 2.59 substituindo a
Equação 2.56. Com o intuito de minimizar a incerteza inerente ao tamanho da vizinhança,
os autores também propõem a aplicação dos pesos Wi = 1/d(sq, rj) (Equação 2.60) [35].
Em outro trabalho, Giacinto e Roli [36] propõem a seleção dinâmica de classificadores
65
baseada no comportamento de múltiplos classificadores (Multiple Classifier Behaviour -
MCB). Nesta proposta, cria-se uma assinatura MCB(si), tal como expresso na Equação
2.61, com as predições Ck(si) do classificador Ck (k = [1, K]) para cada amostra si dos
conjuntos de Teste (sq) e Validação (rj). Para cada amostra questionada sq, calcula-se o
ı́ndice de similaridade S(sq, rj) entre sq e seus vizinhos rj, o qual é dado pela Equação
2.62, com Tk(sq, rj) dado pela Equação 2.63.
C∗ =
K
max
k=1
P̂ (Ck(Vi) = Cll | Vi ∈ Cll) =
K
max
k=1
hlk∑
i=1
P̂ (Cllk | Vi)
hl∑
i=1
P̂ (Cll | Vi)
(2.59)
C∗ =
K
max
k=1
P̂ (Ck(Vi) = Cll | Vi ∈ Cll) =
K
max
k=1
hlk∑
i=1
P̂ (Cllk | Vi)Wi
hl∑
i=1
P̂ (Cll | Vi)Wi
(2.60)
Pseudo-código 2.3. Método a priori.
Detalhes: classificadores probabiĺısticos, critério OLA para delimitação da vizinhança
e restritos somente aos hk corretamente classificados por cada Ck.
Entradas: conjunto de validação, probabilidades a posteriori associadas por cada Ck
para todo o conjunto de validação, tamanho hk da vizinhança.
Sáıda: classificador Ck que maximiza as probabilidades a posteriori dos hk
vizinhos mais próximos rj ponderadas pela distância Euclidiana dj entre sq e rj .
1: ordene os elementos do conjunto de validação considerando suas distâncias
Euclidianas para sq, em ordem crescente
2: para cada classificador Ck faça
3: selecione os hk vizinhos vizinhos mais próximos corretamente classificados
no conjunto de validação
4: calcule a média ponderada das probabilidades a posteriori (Eq. 2.58)
5: fim-para
6: Selecione Ck que maximiza a média ponderada calculada nos passos 2-5.
O ı́ndice S define a relação de vizinhança e proximidade entre sq e seus vizinhos rj,
havendo maior semelhança entre eles à medida que o valor de S aumenta. Assim, para
cada sq, seus vizinhos rj são ordenados com base em S, sendo utilizados todos os que
tiverem ı́ndice de similaridade superior a um limiar pré-definido. Na sequência, tomando-
se as assinaturas MCB(rj), para cada classificador Ck, contabiliza-se a taxa de acertos
(Equação 2.55) para os h vizinhos (referências) mais próximos à sq selecionados. Por fim,
seleciona-se o classificador Ck que apresentar a maior taxa de acertos.
66
Pseudo-código 2.4. Método a posteriori.
Detalhes: classificadores probabiĺısticos, critério LCA para delimitação da vizinhança
e restritos somente aos hlk corretamente classificados por cada Ck.
Entradas: conjunto de validação, probabilidades a posteriori associadas por cada Ck
para todo o conjunto de validação, tamanho hlk da vizinhança, rótulo da classe
Cll associada por Ck à sq.
Sáıda: classificador Ck que maximiza as probabilidades a posteriori dos hlk
vizinhos mais próximos rj ponderadas pela distância Euclidiana dj entre sq e rj .
1: ordene os elementos do conjunto de validação considerando suas distâncias
Euclidianas para sq, em ordem crescente
2: para cada classificador Ck faça
3: selecionar os hlk vizinhos vizinhos mais próximos corretamente classificados
no conjunto de validação
4: calcule a média ponderada das probabilidades a posteriori (Eq. 2.60)
5: fim-para
6: selecione Ck que maximiza a média ponderada calculada nos passos 2-5.
MCB(si) = {C1(si), C2(si), ..., Ck(si), ..., CK(si)} (2.61)
S(sq, rj) =
1
n
n∑
k=1
Tk(sq, rj) (2.62)
Tk(sq, rj) =
{
1, se Ck(sq) = Ck(rj)
0, se Ck(sq) 6= Ck(rj)
(2.63)
Como se pode perceber, Giacinto e Roli [36] definem a taxa de acertos de forma glo-
bal, sendo que os próprios autores mencionam a semelhança com o método OLA na fase
de definição do classificador selecionado. Por aplicar o critério OLA para a delimitação
da vizinhança de sq, com sua independência com relação à classe predita, esta estratégia
será aqui denominada MCB OLA (Pseudo-código 2.5). Além disto, os autores propõem
o uso de um limiar pré-definido e que implica em diferentes quantidades de vizinhos para
cada sq. Em seu trabalho, os autores não utilizam um limiar fixo, mas sim determinam
a quantidade de vizinhos a serem considerados. Neste sentido, devido à alta probabili-
dade de haver ı́ndices de proximidade muito semelhantes entre o h-ésimo vizinho e seus
sucessores, os autores definem que todos os sucessores com o mesmo ı́ndice que o h-ésimo
vizinho sejam selecionados.
Outro método para seleção dinâmica de classificadores (ensembles) bastante referen-
ciado na literatura foi proposto por Ko et al. [65, 63, 64]. Denominado KNORA (K-
Nearest-ORAcles - k oráculos mais próximos), este se diferencia dos demais por esco-
lher o subconjunto de classificadores C∗ que corretamente classificam os k vizinhos mais
próximos de uma instância questionada sq, no conjunto de validação. Na Figura 2.25,
em ambas ilustrações, os pequenos ćırculos da esquerda representam os vizinhos de sq no
conjunto de validação, sendo que apenas os cinco mais próximos são considerados neste
exemplo.
A Figura 2.25(a) representa a versão KNORA-ELIMINATE (KNORA-E), dada pela
67
Pseudo-código 2.5. Método MCB OLA.
Detalhes: classificadores abstratos, critério OLA para delimitação da vizinhança.
Entradas: conjunto de validação, rótulos associados por cada classificador Ck
para todo o conjunto de validação, tamanho h da vizinhança.
Sáıda: classificador Ck que maximiza a taxa de vizinhos corretamente classificados.
1: crie vetor MCB(si), conforme Eq. 2.61, para cada amostra si dos conjuntos
de teste e validação
2: ordene os elementos do conjunto de validação considerando sua similaridade
com sq (Eq. 2.62), em ordem decrescente
3: selecione os elementos do conjunto de validação com o ı́ndice de similaridade
maior ou igual ao do h-ésimo elemento
4: para cada classificador Ck faça
5: conte os hk vizinhos corretamente classificados por Ck na vizinhança
selecionada no passo 3
6: calcule a taxa de vizinhos corretamente classificados por Ck (Eq. 2.55)
7: fim-para
8: selecione Ck que maximiza a taxa de vizinhos corretamente classificados
calculada nos passos 4-7.
interseção dos classificadores que classificam os elementos de uma dada vizinhança correta-
mente. Nesta versão (Pseudo-código 2.6), dados os k vizinhos mais próximos rj (j = [1, k])
a sq e o subconjunto de classificadores C
∗ que corretamente classificam todos os k vizi-
nhos, cada classificador Ci ∈C∗ terá direito a um voto na classificação de sq. No entanto,
se nenhum classificador puder classificar corretamente todos os k vizinhos mais próximos
a sq, dever-se-á selecionar o(s) classificador(es) com o maior número de acertos dentre
os k vizinhos. Já para KNORA-UNION (KNORA-U) tem-se a união dos classificadores
que corretamente classificam pelo menos um dos elementos pertencentes a uma determi-
nada vizinhança (Figura 2.25(b)). Nesta versão (Pseudo-código 2.7), cada classificador
Ci terá direito a um voto para cada vizinho rj por ele corretamente classificado dentre os
k vizinhos mais próximos a sq.
Similar a Giacinto e Roli [36], Ko et al. [64, 65] também propõem versões do KNORA
em que as distâncias entre sq e rj são utilizadas como pesos para os votos dos classificadores
selecionados. Com exceção dos pesos, as demais definições anteriores são mantidas e tais
versões são denominadas KNORA-E-W e KNORA-U-W.
A Seção 4.4 apresenta três novas propostas para os métodos de seleção dinâmica de
classificadores, as quais são baseadas nas estratégias propostas por Woods et al. [146] e
Giacinto e Roli [36]. Como se pode perceber, os métodos de seleção dinâmica de clas-
sificadores aqui apresentados (e também os propostos) utilizam critérios de vizinhança e
medidas de distância.
Durante o desenvolvimento deste trabalho, alguns testes foram realizados tomando
medidas de distância entre a instância questionada e seus vizinhos do conjunto de va-
lidação como critério de seleção do espaço de representação a ser utilizado para a classi-
ficação. Todas as estratégias avaliadas mostraram-se inviáveis, visto que os classificadores
aqui considerados foram constrúıdos em diferentes espaços n-dimensionais. Ou seja, os
testes realizados demonstram a impossibilidade quanto à realização de comparações que
68
(a)
(b)
Figura 2.25: KNORA [64, 65]: (a) ELIMINATE; e (b) UNION.
Pseudo-código 2.6. Método KNORA-E.
Detalhes: classificadores probabiĺısticos.
Entradas: conjunto de validação, rótulos associados por cada classificador Ck
para todo o conjunto de validação, tamanho h da vizinhança.
Sáıda: classe predita.
1: ordene os elementos do conjunto de validação considerando suas distâncias
Euclidianas para sq, em ordem crescente
2: para cada classificador Ck faça
3: contar os hk vizinhos corretamente classificados por Ck
4: fim-para
5: enquanto h > 0 e não houver um subconjunto de classificadores C∗ que
classifica corretamente todos os h elementos faça
6: decremente h
7: fim-enquanto
8: se h > 0
9: selecione C∗
10: senão
11: enquanto pelo menos um classificador não classificar um vizinho
corretamente faça
12: incremente h
13: fim-enquanto
14: selecione C∗
15: fim-se
16: use o regra de fusão ‘voto majoritário’ para para identificar a classe eleita
dentre aquelas preditas pelos classificadores C∗.
envolvam as medidas de distância direta ou indiretamente entre os diferentes espaços
69
Pseudo-código 2.7. Método KNORA-U.
Detalhes: classificadores probabiĺısticos.
Entradas: conjunto de validação, rótulos associados por cada classificador Ck
para todo o conjunto de validação, tamanho h da vizinhança.
Sáıda: classe predita.
1: ordene os h elementos do conjunto de validação considerando suas distâncias
Euclidianas para sq, em ordem crescente
2: para cada classificador Ck faça
3: conte os hk vizinhos corretamente classificados por Ck
4: fim-para
5: use o regra de fusão ‘voto majoritário’ para para identificar a classe eleita
dentre aquelas preditas pelos classificadores C∗, sendo que cada voto de Ck
é multiplicado pelo número de vizinhos por ele corretamente classificados.
de representação, até mesmo quando normalizadas. Assim, as versões KNORA-E-W e
KNORA-U-W propostas por Ko et al. [64, 65] e as propostas originais de Giacinto e Roli
[36] não foram utilizadas. Nestas versões, as distâncias são utilizadas como pesos em uma
combinação ponderada dos votos dos classificadores e das probabilidades dos vizinhos,
respectivamente. Maiores detalhes são apresentados nas Seções 4.4.1 e 5.3.2.
2.5 Considerações Finais
O presente caṕıtulo apresentou os conceitos e ferramentas necessários para o desenvol-
vimento e a compreensão deste trabalho. Foram abordados conceitos da Anatomia da
Madeira e da Botânica que embasam a representação textural considerada. Seguiu-se
com os métodos utilizados para a extração e a representação dos padrões texturais, a
representação no espaço de dissimilaridade e ROC.
Destacou-se os MCSs, a combinação de classificadores por meio das regras de fusão
e a seleção dinâmica de classificadores como alternativa para elevar as taxas de reconhe-
cimento. A partir deste conjunto de elementos, os próximos caṕıtulos apresentam uma
revisão da literatura com o estado da arte em reconhecimento de espécies florestais e a
metodologia empregada no decorrer deste trabalho.
CAPÍTULO 3
ESTADO DA ARTE EM RECONHECIMENTO DE
MADEIRA
Henry Huber realizou um dos primeiros trabalhos com foco na automação da produção
de artefatos de madeira. Este trabalho foi relatado em sua dissertação intitulada “Econo-
mics of Cutting Hardwood Lumber by Two Different Methods” em 1969 [53], com posterior
publicação em 1971 sob o t́ıtulo “A Computerized Economic Comparison of a Conven-
tional Furniture Rough Mill with a New System of Processing” [54]. Desde então, os
crescentes avanços tecnológicos têm permitido ampliar o foco dos estudos. Tais estu-
dos têm inclúıdo o reconhecimento da espécie florestal à qual uma amostra de madeira
pertence e a avaliação da qualidade desta amostra de madeira. Este caṕıtulo apresenta
uma revisão dos principais e mais recentes estudos desenvolvidos no campo de reconhe-
cimento de espécies florestais e seus agrupamentos nos filos Angiospermas (Hardwoods) e
Gimnospermas (Softwoods)1, destacando as técnicas empregadas e os resultados obtidos.
3.1 Revisão da Literatura
Nault e Manville [97] desenvolveram um estudo para a identificação de oito espécies do
filo Gimnospermas. O método limitou-se a medir o espectro do infravermelho refletido
pelas amostras de madeira no intervalo entre 4.000nm e 25.000nm, sendo cada espectro
representado por um vetor de 2.116 elementos. A partir da análise de correlação e da
aplicação de Análise de Componente Principal (Principal Component Analysis - PCA)
às medidas anteriores, selecionou-se os diferentes conjuntos de comprimentos de onda, e
suas respectivas medidas, utilizados na diferenciação das espécies. As amostras foram
organizadas em três grupos com diferentes espécies e a mesma abordagem de classificação
foi utilizada em dois momentos para cada um deles, considerando as amostras verdes e após
estas serem desidratadas por congelamento. No primeiro agrupamento havia um total de
308 amostras das espécies Picea glauca (99), Pinus contorta (147) e Abies lasiocarpa (62).
Destas, 60 compuseram o conjunto de treinamento e 248 o de teste, tendo-se alcançado
taxas de reconhecimento de 83% das amostras verdes e 76% das amostras desidratadas,
com 10 e 30 diferentes comprimentos de onda, respectivamente. O segundo agrupamento
continha 192 imagens das espécies Larix occidentalis (158) e Pseudotsuga menziesii (34).
Destas, 20 compuseram o conjunto de treinamento e 172 o de teste, tendo-se alcançado
taxas de reconhecimento de 91% das amostras verdes e 98% das amostras desidratadas,
com 12 e 18 diferentes comprimentos de onda, respectivamente. O último agrupamento
1As subdivisões definidas pela Botânica são apresentadas na Seção 2.1.2.
71
continha 166 imagens das espécies Tsuga heterophylla (92), Picea sitchensis (58) e Abies
amabilis (16). Destas, 30 compuseram o conjunto de treinamento e 136 o de teste, tendo-
se alcançado taxas de reconhecimento de 67% das amostras verdes e 83% das amostras
desidratadas, com 15 e 19 diferentes comprimentos de onda, respectivamente [96, 97].
Os mesmos autores em [98] utilizaram espectroscopia por Reflectância Difusa no Infra-
vermelho com Transformada de Fourier (Diffuse Reflectance Infrared Fourier Transform
- DRIFT) para diferenciar espécies do filo Gimnospermas. Neste trabalho, os experimen-
tos consideraram apenas amostras verdes, o terceiro agrupamento do trabalho anterior
permaneceu o mesmo e a espécie Picea engelmannii foi adicionada ao primeiro conjunto.
Para tais conjuntos alcançou-se taxas de reconhecimento de 99% e 94%, respectivamente.
Inserido no mesmo contexto, Brunner et al. [12] avaliaram o espectro do infravermelho
refletido pelas amostras de madeira no intervalo entre 400nm e 1.100nm. Os autores utili-
zaram entre cinco e dez leituras de regiões aleatórias das amostras, bem como Classificador
Discriminante Quadrático (Quadratic Discriminant Classifier - QDC) para identificar as
espécies Pseudotsuga menziesii, Pinus contorta e Picea sp para 75 amostras de madeira,
sendo 25 amostras por espécie. Os resultados indicaram que algumas vezes QDC realizou
confusões entre Picea sp e Pinus contorta, mas alcançou resultados entre 98% e 99% ao
separar Pseudotsuga menziesii das outras duas (Picea sp e Pinus contorta).
Lewis et al. [73] realizaram um estudo para a diferenciação entre hardwoods e softwoods
provenientes de regiões com clima temperado. Foram empregadas caracteŕısticas espec-
trais baseadas em espectroscopia Raman, a qual segundo os autores provê bandas mais
bem definidas por reduzir a degradação fototérmica da amostra provocada por aqueci-
mento e radiação de fluorescência decorrente do uso de infravermelho. Também se reali-
zou um pré-processamento para minimizar o efeito da fluorescência. Foram utilizados 56
espectros, sendo 28 de hardwoods e 28 de softwoods. Foi utilizada validação cruzada com
a divisão dos espectros em quatro folds, sendo três deles empregados para treinamento e
um para teste.
Os resultados foram avaliados considerando as resoluções utilizadas para os espectros,
as quais foram avaliadas como muito boa, boa, média, ruim ou muito ruim. Para esta
variável, não foram encontradas diferenças entre os espectros gerados para imagens com
resoluções consideradas boas ou ruins, sendo que em ambos os casos alcançou-se taxas de
reconhecimento de 98,21%. Os autores identificaram a influência quanto aos diferentes
ńıveis da radiação de fluorescência testados e do aquecimento das amostras, bem como
bandas em que hardwoods e softwoods podem ser melhor diferenciados. Durante os ex-
perimentos, também identificou-se que o uso de duas camadas ocultas nas Redes Neurais
(RNA) feed-forward propiciaram melhores resultados enquanto que RNAs sem camadas
ocultas foram incapazes de diferenciar hardwoods e softwoods. De forma geral, os autores
afirmam que há um alto grau de dificuldade na diferenciação entre hardwoods e softwoods
por meio da combinação de espectroscopia Raman e RNAs feed-forward.
Yang et al. [147] replicaram o estudo anterior, substituindo as RNAs feed-forward
72
por RNAs Kohonen Self-Organizing Maps (SOMs) e utilizando 59 espécies de regiões
com clima temperado, com 31 hardwoods e 28 softwoods. Foram empregadas SOMs uni
e bidimensionais, sendo que apenas duas amostras foram classificadas incorretamente
pela primeira. Houve um erro para hardwood e outro para softwood, cujas amostras
ficaram próximas à fronteira definida pela SOM bidimensional. Os resultados alcançados
(96.6%) foram semelhantes àqueles obtidos por Lewis et al. [73], mas sem a exigência de
conhecimento prévio quanto ao tipo de madeira dos espectros.
Num segundo conjunto de testes, os autores incorporaram 24 novas espécies de hardwo-
ods provenientes de regiões com clima tropical. Os resultados para a SOM unidimensi-
onal ficaram em 63,86% de acerto e, mesmo com a variação entre três e 81 neurônios,
a RNA não alcançou uma completa separação dos três grupos. Os autores empregaram
uma adaptação da proposta de Chen e Gasteiger [20], na qual a matriz de pesos da
Kohonen SOM (representada pela distância entre cada neurônio e seus vizinhos) auxi-
lia na exploração e agrupamento de dados desconhecidos. As taxas de reconhecimento
alcançaram 89,8% e ficaram próximas daquelas obtidas com RNAs multi-camadas feed-
forward para diferenciar os grupos hardwoods e softwoods provenientes de regiões tem-
peradas. As análises dos autores identificaram um ńıvel muito alto de semelhança entre
os espectros obtidos de amostras dos três diferentes grupos. Além disso, as amostras de
hardwoods provenientes de regiões tropicais apresentaram espectros intermediários àquelas
pertencentes aos outros dois grupos.
Lavine et al. [71] também realizaram um estudo para a diferenciação entre hardwoods
e softwoods provenientes de regiões com clima temperado e hardwoods provenientes de
regiões com clima tropical. Dentre as 98 amostras de madeira, 59 eram de região com
clima temperado (América do Norte, 31 hardwoods e 28 softwoods) e 39 de regiões com
clima tropical (Brasil, 15; e Honduras, 24). O conjunto de treinamento era composto por
88 amostras e o de teste por apenas 10 amostras.
Cada espectro foi produzido tomando-se a média de 500 varreduras e representado
por um conjunto de 670 caracteŕısticas. Após a aplicação de PCA e tomando apenas
os 2 maiores componentes principais, foi posśıvel classificar corretamente as amostras de
hardwoods e softwoods provenientes de regiões temperadas. Porém, houve erros no que se
refere às amostras pertencentes a hardwoods provenientes de regiões tropicais. Com o uso
de Algoritmos Genéticos para selecionar um subconjunto dentre as 670 caracteŕısticas, o
vetor foi reduzido a apenas 8 elementos. Os autores conclúıram que as 3 classes puderam
ser completamente separadas e identificaram grandes diferenças entre os grupos e pequenas
diferenças internamente a eles.
Palm [107] propôs uma extensão de GLCM considerando múltiplos canais de cor. O
autor também aplicou sua proposta para a classificação de espécies florestais por meio
de imagens da casca das plantas. A base de imagens era formada por seis espécies, cada
qual com 68 imagens com dimensões 384×256. Para a realização dos experimentos, as
408 imagens foram recortadas para eliminar os planos de fundo das bordas, e as imagens
73
finais ficaram com dimensões de 300×200. O autor empregou diferentes conjuntos de
treinamento e teste, os quais sempre continham 67 e uma imagens, respectivamente.
O classificador utilizado foi 5-NN e distância Euclidiana entre os vetores. As taxas de
reconhecimento ficaram em 72,1% para caracteŕısticas de textura extráıdas do canal ‘L’
do sistema LUV, 65,4% para caracteŕısticas de textura propostas por Haralick e extráıdas
de imagens em escalas de cinza e 98,6% quando se combina as caracteŕısticas inerentes à
cor e as caracteŕısticas inerentes à intensidade.
Nilsson [99] aplicou duas abordagens para a classificação de amostras da madeira
das espécies Picea Abies e Pinus Sylvestris. Na primeira abordagem foram coletadas
medidas por meio de espectroscopia com infravermelho próximo (near-infrared - NIR) de
53 discos de madeira, 28 pertencentes à espécie Picea Abies e 25 à Pinus Sylvestris. Para
a segunda abordagem foram coletadas imagens RGB (Red, Green, Blue) de 146 discos, 79
pertencentes a Picea Abies e 67 pertencentes a Pinus Sylvestris, e que compreendiam a
casca, a madeira e a combinação casca e madeira. Nesta abordagem, inicialmente aplicou-
se Transformada Discreta Wavelet (Discrete Wavelet Transform - DWT) bidimensional
(2D DWT) seguida por DFT bidimensional (2D DFT) às imagens RGB, sendo que cada
canal foi tratado como uma imagem distinta e era representado por 5.000 coeficientes
das 2D DFT. Numa segunda estratégia, gerou-se uma GLCM para 00 para cada imagem,
seguida pela aplicação de 2D DWT, com um vetor de caracteŕısticas com 5.000 coeficientes
das 2D DWT [99, 100].
Mı́nimos Quadrados Parciais (Partial Least Squares - PLS) foi utilizado para encontrar
modelos de regressão entre os espectros coletados e as espécies reais às quais os discos
utilizados pertenciam. As duas abordagens alcançaram resultados semelhantes, sendo que
na primeira todas as amostras do conjunto de teste foram classificadas corretamente. Para
a segunda abordagem, a combinação entre DWT e DFT alcançou 89,6%, 81,3% e 66,7% de
precisão, respectivamente, para imagens com somente casca, casca e madeira e somente
madeira. Já a combinação entre GLCM e DWT alcançou taxas de reconhecimento de
97,9%, 85,4% e 72,9%, respectivamente, para imagens com somente casca, casca e madeira
e somente madeira [99, 100].
Nuopponen et al. [102] também tentaram distinguir hardwoods e softwoods por meio
de medidas de densidade, lignina, α-celulose e resina obtidas por meio de espectroscopia.
A base era composta por um total de 535 amostras. Do grupo de softwoods haviam
491 amostras da espécie Picea sitchensis e 20 amostras da espécie Pinus sylvestris. As
amostras pertencentes ao grupo de hardwoods foram extráıdas de 24 diferentes espécies
provenientes de regiões de clima tropical. O conjunto de teste foi composto por 243
amostras da espécie Picea sitchensis e as demais amostras compuseram o conjunto de
treinamento.
Foram avaliados diferentes comprimentos de ondas e as combinações de seus resultados,
concluindo-se que o uso de um número reduzido de diferentes comprimentos de onda
manteve as taxas de reconhecimento obtidas com todo o conjunto. De forma geral, os
74
resultados apresentados foram similares àqueles obtidos por outros estudos. Os modelos
baseados nas medidas de resina e densidade diferenciaram as espécies de cada grupo.
Embora o mesmo tenha ocorrido com α-celulose, seus resultados foram inferiores aos
anteriores, enquanto que os modelos baseados em lignina apresentaram baixa precisão.
Tou et al. [135] propuseram a aplicação de GLCM e Multilayer Perceptron (MLP) em
um sistema completo. Os experimentos avaliaram a influência de diferentes distâncias na
geração da GLCM e na representatividade das caracteŕısticas empregadas na diferenciação
das espécies. Para isso, foram utilizadas 50 imagens macroscópicas pertencentes a cinco
diferentes espécies da base do Centre for Artificial Intelligence and Robotics (CAIRO).
Cada imagem foi representada por um vetor com as caracteŕısticas de contraste, cor-
relação, energia, entropia e homogeneidade nas quatro direções (ângulos de 00, 450, 900 e
1350), totalizando 20 caracteŕısticas. As imagens foram divididas na proporção 50%-50%
para treino e teste. Os resultados ficaram entre 60% e 72%, sendo que distâncias meno-
res geraram valores mais próximos para todas as espécies. Os autores destacam que, de
forma geral, a MLP gerou scores baixos para todas as espécies vencedoras em todos os
experimentos.
Khalid et al. [59] apresentaram um sistema de baixo custo e integrado para automati-
zar todo o processo de reconhecimento. Este compreende a aquisição das imagens, o pré-
processamento, a extração de caracteŕısticas, a classificação e apresentação dos resultados.
Foram utilizadas 1.949 imagens de 20 diferentes espécies florestais malaias pertencentes à
base Forest Research Institute of Malaysia (FRIM). As imagens são macroscópicas e foram
melhoradas com aplicação de filtro passa-alta, operações de equalização de histograma,
remoção de irregularidades, binarização e melhoria do contraste. As caracteŕısticas ex-
tráıdas para cada imagem a partir das GLCM foram segundo momento angular, contraste,
correlação, entropia e momento da diferença inversa para as quatro direções, num total de
20 atributos. A classificação empregou MLP, utilizou 90% das imagens para treinamento
e 10% para teste, apresentando resultados superiores a 95% de acerto.
Em outro trabalho Tou et al. [137] empregaram uma representação unidimensional
de GLCM e a compararam com o tradicional formato bidimensional. A proposta unidi-
mensional implica em um menor custo computacional e representa apenas a frequência
da diferença (ou da soma) de dois ńıveis de cinza. Por ser diferente da forma tradicional,
que representa a frequência de co-ocorrência entre dois ńıveis de cinza, esta implica na
realização de alguns ajustes nas fórmulas propostas por Haralick. Os autores utilizaram
as bases de imagens Brodatz e CAIRO, bem como os classificadores k-Nearest Neighbors
(kNN, k = [1, 10]) e MLP. Os experimentos consideraram ainda diferentes combinações
das caracteŕısticas contraste, energia, entropia, homogeneidade e correlação, calculados
para as quatro direções e concatenados. Também variou-se a distância (d = [1, 5]), os
ńıveis de cinza (8, 16, 32, 64, 128 e 256).
Para a base Brodatz, as GLCM bi e unidimensional obtiveram taxas de reconheci-
mento de 81,35% (k=1) e 83,01% (k=4), respectivamente. Na base CAIRO todos os
75
experimentos empregaram cinco espécies com 100 imagens cada uma, considerando di-
visões com proporções 50%-50% e 90%-10% para treinamento e teste. As melhores taxas
de reconhecimento (80%) foram obtidas com kNN (k=3) para a primeira divisão e GLCM
unidimensional contra 77% para MLP com 32 ńıveis de cinza para a segunda divisão. De
forma geral, os resultados indicaram que o número de ńıveis de cinza e a distância empre-
gada na obtenção da GLCM afetaram os resultados finais; GLCM unidimensional obteve
resultados melhores que a bidimensional mesmo com menos descritores que a GLCM
convencional; de forma geral, kNN apresentou desempenho pior que MLP.
Os mesmos autores em [138] realizaram testes para reconhecimento de textura con-
siderando as técnicas Matriz de Covariância, GLCM, filtros de Gabor e a combinação
das duas últimas. Foram utilizadas imagens macroscópicas de seis espécies florestais da
base CAIRO, num total de 600 imagens (100 para cada espécie). Foram empregadas 90%
destas para treinamento e 10% para teste do classificador kNN. Cada imagem foi dividida
em 16 amostras (partes) com dimensões de 64×64 pixels. Foram aplicadas três variações
(rotação, escala e rotação e escala em conjunto) a cada uma destas amostras. Posteri-
ormente, foram combinadas a imagem normal e estas três variações para representar as
amostras finais. Deste conjunto de imagens com 16 combinações, foram escolhidas alea-
toriamente oito para treinamento e as oito restantes para teste (como em [136]). Após
dez execuções, as taxas médias de reconhecimento foram 85% para matriz de covariância
aplicadas às imagens geradas pelos filtros de Gabor; 78,33% para raw GLCM ; 76,67%
para GLCM; 73,33% para filtros de Gabor; e 76,67% para GLCM combinada com filtros
de Gabor.
Os autores ainda apresentaram em [139] um algoritmo invariante a rotação focando
o reconhecimento de espécies florestais por meio de imagens macroscópicas. Durante o
processo de classificação, era verificado se a espécie da amostra questionada correspondia
a alguma das espécies com exemplares na base de treinamento. O algoritmo empregou
GLCM e considerou os valores de energia para definir o grau de similaridade entre os
pares amostra de teste e amostra (template) de treinamento. Também foi considerado um
limiar para determinar a compatibilidade (ou não) entre ambas as amostras. Nos testes
foram empregadas distância de um pixel para GLCM e 510 imagens macroscópicas de seis
espécies florestais da base CAIRO. No ińıcio do processo, tais imagens foram convertidas
para oito ńıveis de cinza. Além disso, as imagens originais que possúıam dimensões de
576×768 pixels foram recortadas em fragmentos com dimensões 512×512 pixels e 256×256
pixels. Em cada teste, foi utilizado 90% das imagens para treinamento e 10% para teste,
sendo que a determinação da classe vencedora ocorreu por meio de votação. As taxas
obtidas foram 80% para imagens inteiras; 78,33% para as dimensões 512×512; e 73,33%
para 256×256 pixels.
Ioannou et al. [55] apresentaram um sistema especialista baseado em regras para a
identificação de espécies florestais existentes na Grécia. O sistema foi implementado por
meio de árvores de decisão constrúıdas a partir das chaves de identificação das espécies.
76
As informações das chaves de identificação das espécies eram fornecidas de forma iterativa.
Como consequência, podia-se comparar a amostra a ser classificada com outras perten-
centes às espécies candidatas a cada nova informação fornecida. Os autores afirmam que
esta abordagem facilita o processo de identificação das espécies florestais para qualquer
público interessado no assunto. Enfatizam ainda que esta abordagem não obriga o público
a ter contato com especialistas da área e que a repetição do processo de identificação pode
garantir a precisão de seus resultados e evitar eqúıvocos quanto aos mesmos. No entanto,
os autores não apresentaram os resultados obtidos com a utilização do sistema proposto.
Paula Filho et al. [110] apresentaram uma base composta por 347 imagens de 11
diferentes espécies florestais brasileiras. A aquisição das imagens ocorreu com distância e
iluminação padronizadas, com uma câmera fotográfica digital e aproximação ótica de dez
vezes. Os experimentos consideraram as imagens inteiras e sua divisão, com a melhor al-
ternativa para 25 fragmentos. Foram empregadas 18 caracteŕısticas de cor e 24 extráıdas
de GLCM, num total de 42. As caracteŕısticas de cor combinaram canais dos mode-
los RGB, HSV (Hue, Saturation and Value) e CIELUV2. Já para GLCM, considerou-se
energia, contraste, entropia, homogeneidade, probabilidade máxima e momento de ter-
ceira ordem para as quatro direções e distância de um pixel. As imagens foram divididas
na proporção 30%-50%-20% para os conjuntos de treinamento, teste e validação. Para
tais configurações, as taxas de reconhecimento do classificador MLP foram 65% para as
imagens inteiras e 82% quando estas eram divididas e se realizava votação.
A base proposta em [110] foi ampliada pelos autores em [111] com 11 novas espécies.
A segunda versão da base contém 1.270 imagens pertencentes a 22 diferentes espécies.
Os procedimentos e ferramentas foram os mesmos descritos no trabalho anterior e os
resultados finais foram 66,3% para as imagens inteiras e 80,8% quando estas eram divididas
e se realizava votação. Ou seja, embora se tenha dobrado o número de espécies e triplicado
o número de imagens, os resultados se mantiveram semelhantes.
Labati et al. [67] realizaram uma série de experimentos considerando a distinção entre
hardwoods e softwoods, bem como entre as 21 diferentes espécies florestais presentes no
conjunto de amostras utilizadas. Os experimentos consideraram 20 espectros para cada
espécie, obtidos em regiões diferentes das amostras e avaliados com diferentes quantidades
e comprimentos de ondas. As diferentes configurações para as RNAs feed-forward com-
preenderam o uso de 3, 10 ou 30 neurônios na camada oculta, sendo que todas elas tinham
duas camadas e utilizavam as funções de ativação log-sigmoidal na camada intermediária
e linear na camada de sáıda.
Com validação cruzada com 12 folds e 12 execuções, os resultados alcançados indicaram
a possibilidade de se aplicar a proposta a sistemas de tempo real. A classificação entre
hardwoods e softwoods alcançou taxas de reconhecimento de 97,9% (σ=3,0), para a qual
se utilizou uma configuração mais simples com 11 filtros óticos com amplitude de 100nm
2Proposta pela International Commission on Illumination, com L referenciando a luminosidade (light-
ness), U a graduação de vermelho e V a predominância do verde sobre o azul.
77
e centros regularmente distribúıdos entre 500nm e 750nm. Já a diferença entre as 21
espécies alcançou taxas de reconhecimento de 82,4% (σ=9,8) e exigiu o emprego de 30
filtros óticos com amplitude de 100nm e centros regularmente distribúıdos entre 500nm e
750nm.
Piuri e Scotti [116] propuseram um sistema para a classificação da madeira de 21
espécies florestais. O sistema utilizou espectros de fluorescência para a extração de carac-
teŕısticas e permitia a classificação das amostras de madeira em tempo real. Os autores
empregaram um intervalo fixo de comprimentos de ondas e os espectros de fluorescência
foram normalizados para minimizar os efeitos inerentes à absorção de luz por parte das
amostras. Os dados foram divididos em 10 folds, houveram 10 rodadas e, em cada uma,
os conjuntos de treinamento e teste eram formados por nove e um fold, respectivamente.
Foram empregados os Classificadores Discriminantes Lineares (Linear Discriminant
Classifier - LDC), quadráticos (QDC), kNN e Máquina de Vetor de Suporte (Support
Vector Machine - SVM). Para tais classificadores foram empregadas versões com e sem
a utilização prévia de normalização e PCA, sendo que o segundo foi empregado com o
objetivo de reduzir a dimensionalidade dos vetores de caracteŕısticas originais. O primeiro
conjunto de testes focou a diferenciação entre hardwoods e softwoods, alcançando taxas
de reconhecimento de 98,93% (σ=0,2%) com SVM. Para estes testes, a aplicação prévia
de PCA não influenciou os resultados. Considerando a diferenciação entre os 21 tipos de
madeira houve taxas de reconhecimento de 93,6% (σ=0,9%) utilizando QDC.
Nasirzadeh et al. [95] realizaram um estudo focando reconhecimento de espécies flo-
restais tropicais. Os autores apresentaram uma nova variante para LBP denominada
Local Binary Pattern Histogram Fourier Features (LBP-HF), a qual garante invariância
à rotação por meio da aplicação da DFT. Para avaliar seu desempenho, os autores reali-
zaram testes com descritores gerados por LBPriu2 (LBP with rotation invariant uniform
2 pattern code), LBPu2 (LBP with uniform 2 pattern code) e LBP-HF, bem como o clas-
sificador kNN.
Foram utilizadas imagens da base CAIRO, sendo que todas as imagens de treinamento
estavam com um mesmo ângulo de rotação enquanto as imagens de teste possúıam outros
ângulos de rotação. O primeiro conjunto de experimentos empregou 1.000 imagens, sendo
10 diferentes espécies com 100 imagens cada uma, e considerou a proporção 70%-30% para
os conjuntos de treinamento e teste, respectivamente. Os melhores resultados foram ob-
tidos para LBP-HF para diferentes combinações (P:d) quanto a vizinhos (P) e distâncias
(d), sendo 90% para (8:1), 93,33% para (16:2) e 100% para (24:3). Os experimentos an-
teriores foram replicados, mas considerando as 37.000 imagens e a divisão com proporção
80%-20%. Novamente, LBP-HF obteve os melhores resultados, com 83% para (8:1), 87%
para (16:2) e 96,6% para (24:3), embora LBPriu2 tenha obtido taxas de reconhecimento
de 84% para (8:1).
Tarŕıo-Saavedra et al. [133] analisaram o potencial de identificação de espécies flores-
tais, ou agrupamentos destas (softwoods e hardwoods - de climas temperado e tropical),
78
considerando os ńıveis de degradação das amostras quando submetidas a diferentes tem-
peraturas. Assim, a partir da variação da temperatura, foram obtidas medidas de massa
(termogravimetria) e de calorimetria diferencial3 e analisou-se a influência da primeira
com relação às outras duas medidas.
Os experimentos empregaram sete classes, cada uma com sete amostras. Aplicou-se va-
lidação cruzada com 48 elementos no conjunto de treinamento e apenas um no conjunto
de teste (a cada rodada) e quatro algoritmos de classificação: B, B-PCA, K-NPFDA
(functional Nadaraya-Watson kernel nonparametric method) e KNN-NPFDA. Segundo
os autores, os intervalos de temperatura que apresentaram as melhores taxas para cada
espécie e/ou grupo de espécies coincidiram com aqueles relatados na literatura. Também
os resultados alcançados são compat́ıveis com os apresentados na literatura por trabalhos
que utilizaram sistemas baseados em processamento de imagens ou espectro. As carac-
teŕısticas baseadas em medidas de massa tiveram melhor desempenho que as baseadas em
calorimetria diferencial. Combinadas com o algoritmo B, as primeiras obtiveram taxas de
reconhecimento de 90% na diferenciação das sete espécies e, com os algoritmos K-NPFDA
e KNN-NPFDA, alcançaram 94% para a separação dos três agrupamentos.
Além dos trabalhos anteriormente destacados, há diversos outros contextos de aplicação
de visão computacional envolvendo madeira. Em sua grande maioria, os estudos focam a
avaliação da qualidade da madeira ainda num estado bruto ou de peças já confeccionadas.
Caron-Decloquement [16], Rinnhofer et al. [123], Butler et al. [15], Lebow et al. [72] e
Thomas et al. [134] focaram a identificação de defeitos decorrentes de irregularidades
externas aos troncos, mas ainda ocultas pela casca. Conners et al. [22] avaliaram a quali-
dade de placas de madeira considerando caracteŕısticas de suas superf́ıcies (tais como nós,
buracos, fissuras e manchas), caracteŕısticas geométricas (forma e irregularidades quanto
ao corte) e caracteŕısticas internas (vazios, nós e regiões deterioradas). Em sua maioria,
os trabalhos concentram-se na detecção e classificação de defeitos em placas de madeira
[13, 30, 41, 74, 119] e otimização de cortes de peças de madeira considerando a eliminação
de defeitos [19, 93, 115]. Num contexto mais espećıfico, mas não menos importante, há
processos de inspeção de produtos finais [92], tal como a avaliação da qualidade de peças
de piso de madeira realizado por Kauppinen [58], a qual se baseou em caracteŕısticas de
cor.
3.2 Considerações Finais
Este caṕıtulo apresentou um levantamento dos principais e mais recentes estudos desen-
volvidos no campo de reconhecimento de espécies florestais, os quais estão resumidos na
Tabela 3.1. Relativamente recente, esta linha de pesquisa tem sido impulsionada pela
necessidade de compradores e órgãos de fiscalização certificarem a matéria-prima, pela
3Differential scanning calorimetry é uma técnica termo-anaĺıtica que relaciona a diferença entre a
quantidade de calor utilizada e a temperatura do objeto.
79
evolução tecnológica e pela crescente escassez de algumas espécies florestais.
Na Tabela 3.1, a coluna ‘Amostras’ apresenta a relação entre as quantidades de imagens
(TL) e classes (CL), bem como o ńıvel da Botânica (N) em que a classificação ocorreu em
cada trabalho. Já a coluna ‘Distribuição’ apresenta a relação quanto às imagens utilizadas
para treinamento (TR), teste (TS) e validação (VL), embora nem todos os experimentos
tenham considerado a validação.
Tabela 3.1: Śıntese dos resultados apresentados para classificação de madeira.
Autor Ano Caracteŕısticas Classificador Amostras Distribuição(%) Taxas
TL CL N TR TS VL (%)
[97] 1992 Espectro infravermelho An. Correlação 192 2 E 10 90 - 98,0
[98] 1997 DRIFT An. Correlação 166 3 E 18 82 - 99,0
[12] 1996 DRIFT QDC 75 3 E - - - 99,0
[107] 2004 Matriz de Co-
ocorrência para Cor
5-NN 408 6 E 98 2 - 98,6
[99] 2005 Espectro infravermelho PLS 53 2 E - - - 100,0
[135] 2007 GLCM MLP 50 5 E 50 50 - 72,0
[59] 2008 GLCM MLP 1.949 20 E 90 10 - 95,0
[137] 2008 GLCM kNN 500 5 E 50 50 - 80,0
[138] 2009 Filtros Gabor e Matriz
de Covariância
kNN 600 6 E 90 10 - 85,0
[139] 2009 GLCM e raw GLCM kNN 510 6 E 90 10 - 80,0
[55] 2009 Chaves dicotômicas Árvores de Decisão - - E - - - -
[110] 2009 cor e GLCM MLP 347 11 E 30 50 20 82,0
[111] 2010 cor e GLCM MLP 1.270 22 E 30 50 20 80,8
[95] 2010 LBP-HF kNN 1.000 10 E 70 30 - 96,6
[67] 2009 Espectro de Fluo-
rescência
RNA feed-forward 420 21 E - - - 82,4
420 2 F - - - 97,9
[116] 2010 Espectro SVM 420 21 E 90 10 - 93,6
QDC 420 2 F 90 10 - 98,9
[133] 2011 Medida de massa B 49 7 E 98 2 - 90,0
K-NPFDA/ 49 3 G 98 2 - 94,0
KNN-NPFDA
[73] 1994 Espectro de Raman RNA feed-forward 56 2 F 75 25 - 98,2
[147] 1999 Espectro de Raman RNA SOM 1D 59 2 F - - - 96,6
[71] 2001 Espectro de Raman PCA 98 2 F 90 10 - 100,0
[102] 2006 Espectro PLS 535 2 F 55 45 - 100,0
( - ) não se aplica ou não apresentado.
(EF) Espectro de Fluorescência.
(E) Classificação em ńıvel de Espécies.
(F) Classificação em ńıvel de Filo (Angiospermas e Gimnospermas).
(G) Classificação em ńıvel de Grupos de Espécies.
Ao se considerar o número de aproximações, tem-se claro que esta variável pode in-
fluenciar as taxas de reconhecimento. No entanto, todos os trabalhos referenciados na
literatura da área e apresentados neste caṕıtulo consideraram imagens macroscópicas.
Embora seja viável tanto técnica quanto financeiramente, não foram encontrados traba-
lhos relacionados a imagens microscópicas, tal como aquelas empregadas neste trabalho.
Tal fato exclui a possibilidade de se explorar a maior riqueza de detalhes de cada um dos
componentes anatômicos da madeira apresentados na Seção 2.1.
CAPÍTULO 4
METODOLOGIA
A metodologia empregada durante o desenvolvimento deste trabalho está inserida no con-
texto da Figura 2.1, assim como a visão geral de um sistema para o reconhecimento de
padrões. Para o sistema de classificação proposto neste trabalho, destaca-se o processo
de extração de caracteŕısticas e as estratégias de classificação, principalmente a seleção
dinâmica e/ou a combinação de classificadores. Etapas como pré-processamento e seg-
mentação não são discutidas por basicamente terem envolvido operações como conversões
entre os sistemas de cores e fragmentações das imagens em pedaços menores.
O presente caṕıtulo inicia com uma visão geral do modelo proposto. Segue-se com o de-
talhamento das configurações utilizadas para a extração dos descritores de caracteŕısticas.
Para a classificação, avaliou-se os parâmetros envolvidos na geração dos vetores de dis-
similaridade empregados nas fases de treinamento e teste. A seleção de classificadores
apresenta as abordagens analisadas e contextualiza os métodos propostos diante daqueles
pré-existentes descritos no Caṕıtulo 2. A combinação de classificadores avalia um conjunto
de oito diferentes regras de fusão. Encerrando o caṕıtulo, são apresentados estratégias e
critérios para a avaliação dos resultados obtidos e as considerações finais.
Diante da inviabilidade de testar todas as posśıveis combinações para as avaliações
realizadas pelos diferentes experimentos, alguns testes serviram para delinear os experi-
mentos seguintes.
4.1 Visão geral da arquitetura proposta
Esta seção apresenta o modelo proposto para a classificação de espécies florestais baseada
na seleção dinâmica de classificadores no espaço de dissimilaridade (Figura 4.1). Esse
está fundamentado na representação baseada em vetores de dissimilaridade descrita por
Bertolini et al. [7] e no modelo de combinação de classificadores apresentado por Hanu-
siak [43]. Diferente de Hanusiak, que combina classificadores no espaço ROC, a presente
proposta realiza a combinação das decisões individuais para os vetores de dissimilaridade
por meio de regras de fusão. Além disso, também foi inclúıdo um módulo para selecio-
nar dinamicamente um único classificador ou um agrupamento de classificadores dentre
aqueles dispońıveis, conforme descrito a seguir.
A Figura 4.1 ilustra (a) a fase de treinamento, com a construção dos modelos Ck e
da base de validação, bem como (b) a classificação de uma amostra questionada sq. Para
construir os modelos Ck, um conjunto de n imagens de madeira ru (u = [1..n]) é enviado
para o módulo de extração de caracteŕısticas e os vetores Vu resultantes são armazenados
81
em uma base de referências1. Dada a nomenclatura apresentada na Seção 2.3.1 e a
definição aleatória das imagens2, nesta fase uma mesma imagem pode ser utilizada como
amostra (Vu) e/ou como referência (Vv) para o cômputo dos vetores de dissimilaridade
Zu,v = | Vu − Vv | obtidos para as classes positiva e negativa3. Tais vetores Zu,v são
fornecidos para o treinamento dos classificadores SVM Ck e/ou armazenados para compor
o conjunto de validação utilizado para a seleção dinâmica de classificadores (no espaço de
dissimilaridade) durante a fase de classificação de sq.
Figura 4.1: Modelo proposto com base na seleção dinâmica de classificadores no espaço
de dissimilaridade: (a) treinamento e (b) classificação.
Para que sq seja classificada (Figura 4.1(b)), essa é apresentada ao sistema e passa pelo
mesmo processo de extração de caracteŕısticas, gerando o vetor de caracteŕıstica Vq. Dada
a independência entre as classes utilizadas nas fases de treinamento e classificação, bem
como a classe Cls à que sq supostamente pertence, as referências rj podem ser obtidas
diretamente da base constrúıda no momento em que os modelos foram treinados e/ou
fornecidas ao sistema no momento em que sq for submetida à classificação. No segundo
caso, os vetores de caracteŕısticas Vj são extráıdos e armazenados na base de referências.
1A base de imagens é apresentada no Apêndice A e os parâmetros considerados para cada descritor
durante a extração de caracteŕısticas são descritos na Seção 4.2.
2As imagens capturadas compreendem partes do lenho inicial, do lenho tardio e/ou de ambos, sem
qualquer organização quanto a este aspecto internamente às classes. A seleção aleatória de subconjuntos e
da ordem com que as imagens foram inclúıdas durante a geração dos vetores de dissimilaridade utilizados
nas fases de treinamento e teste permitiu um maior grau de generalização do sistema e evitou que se
privilegiasse um ou outro contexto (lenho inical e/ou lenho tardio).
3Este processo é apresentado na Seção 2.3.1 e a avaliação dos parâmetros para a geração dos vetores
de dissimilaridade empregados nas fases de treinamento e teste é descrita na Seção 4.3.
82
A partir de Vq e Vj, os vetores de dissimilaridade Zq,j = | Vq − Vj | são computados e os
classificadores Ck geram as decisões dk para cada Zq,j. De forma geral, as decisões parciais
D(Zq,j) dependem da seleção de apenas uma decisão dk dentre as geradas pelo conjunto
de classificadores dispońıveis. A única exceção refere-se ao uso do KNORA, pois mediante
a seleção de mais de um classificador, as decisões dk dos classificadores escolhidos deverão
ser combinadas para gerar D(Zq,j).
Devido à transformação do espaço de caracteŕısticas para o espaço de dissimilaridade,
com a geração dos vetores Zq,j, a decisão final D(sq) para a amostra questionada sq
depende da combinação das decisões parciais selecionadas (e/ou combinadas) D(Zq,j). As
abordagens analisadas e os métodos propostos para seleção dinâmica de classificadores,
bem como demais considerações para esta fase são descritos na Seção 4.4. Por fim, a
combinação dos classificadores selecionados no espaço de dissimilaridade é discutida na
Seção 4.5 e os critérios de avaliação dos resultados são apresentados na Seção 4.6.
4.2 Extração de caracteŕısticas e avaliação dos descritores
Durante esta fase analisou-se os 10 diferentes descritores apresentados na Seção 2.2:
SURF, MSER-SURF, SIFT, LPQ, LPQ-TOP, LBPu2, LBPri, LBPriu2, GLCM e filtros
de Gabor. Esta avaliação quanto à capacidade de representar as caracteŕısticas textu-
rais presentes nas imagens da madeira implicou na variação dos parâmetros utilizados,
de acordo com as possibilidades de configuração de cada descritor, e na identificação dos
valores que maximizaram as taxas individuais de reconhecimento.
Para todos os experimentos realizados, dada a descrição da Apêndice ??, a fase de
pré-processamento das imagens compreendeu apenas a conversão das imagens para ńıveis
de cinza, pois a utilização de corantes inviabilizou a utilização de caracteŕısticas referentes
à cor. Nestes experimentos foi empregado o classificador Máquina de Vetor de Suporte
(Support Vector Machine - SVM) proposto por Vapnik [142] e sua implementação dis-
ponibilizada pela biblioteca libSVM [18]. Dentre as possibilidades disponibilizadas pela
biblioteca, os melhores resultados foram obtidos com a função de base radial Gaussiana e
uma busca gulosa para encontrar os melhores parâmetros C e γ. A normalização dos da-
dos considerou a escala linear de cada atributo dos vetores de dissimilaridade no intervalo
[−1,+1].
Nas seções 4.2.1 à 4.2.7 são identificados os parâmetros avaliados para cada um dos
descritores utilizados e os valores para os quais se obteve os melhores resultados. A seção
4.2.8 finaliza as avaliações espećıficas e individuais para os 10 descritores, com um resumo
dos mesmos, suas complexidades algoŕıtmicas e seus custos computacionais.
83
4.2.1 Famı́lia de descritores LBP
Os três descritores da famı́lia LBP foram avaliados com oito vizinhos e distâncias um e
dois, sendo que os demais parâmetros foram mantidos com os valores padrão das imple-
mentações disponibilizadas por Maenpää e Pietikäinen [79] e Ahonen et al. [1].
Para a versão LBP u28,2, o vetor de caracteŕısticas é composto por 59 elementos. As
versões invariantes à rotação também tiveram seus descritores padrão utilizados, com 36
e 10 elementos nos vetores de LBPri8,2 e LBP
riu2
8,2 , respectivamente.
4.2.2 Famı́lia de descritores LPQ
LPQ e LPQ-TOP foram avaliados neste trabalho. Os descritores finais utilizados para
LPQ foram os vetores com 256 posições retornados pelas implementações e que contêm
os histogramas gerados para os códigos binários no intervalo [0, 255]. Já o descritor para
LPQ-TOP compreendeu apenas as 256 posições do plano XY, dentre as 756 posições
geradas (planos XY, XZ e YZ) e concatenas, visto que as imagens são estáticas.
Para ambos, testou-se diferentes dimensões na janela da STFT e os demais parâmetros
foram mantidos com valores padrão das implementações disponibilizadas por Ojansivu e
Heikkilä [105] e Päivärinta [106]. Foram avaliadas todas as possibilidades de janelas da
STFT com N×N pixels, para todos os N ı́mpares do intervalo [3, 21]. Os valores ı́mpares
para as dimensões da janela da STFT constituem uma exigência do próprio descritor.
Já o intervalo [3, 21] permitiu a análise das taxas de reconhecimento e a identificação das
dimensões que as maximizaram, além de uma tendência de queda com o aumento do valor
de N .
As melhores taxas com LPQ e LPQ-TOP foram obtidas com janelas 11×11 e 15×15
pixels, respectivamente. Tal diferença justifica-se pelos diferentes valores padrão dos
parâmetros utilizados nas implementações disponibilizadas por seus autores. Embora
as taxas alcançadas por LPQ e LPQ-TOP tenham ficado bem próximas, testes realizados
indicaram pequeno ganho diante da combinação das duas versões.
4.2.3 SIFT
Para este descritor foram testadas as implementações de Lowe [75] e Vedaldi [143], se-
guindo exatamente a mesma metodologia para ambos. Conforme descrito na Seção 2.2.1.3,
os vetores de caracteŕısticas foram gerados para cada ponto de interesse identificado pelo
detector SIFT, cada um com 128 elementos. Diante da variação do número de pontos de
interesse identificados para cada imagem, optou-se por utilizar momentos estat́ısticos para
padronizar sua representação. Esta abordagem é comumente utilizada para a extração de
caracteŕısticas com filtros de Gabor [148, 152, 153].
Foram calculadas média, variância, obliquidade e curtose para cada coluna dos vetores
gerados pelo descritor SIFT, dando origem a vetores com dimensões de 128 elementos
84
para cada um dos momentos estat́ısticos utilizados. A partir dos vetores obtidos para os
quatro momentos estat́ısticos, foram analisadas diferentes combinações de concatenação
entre eles e também incluindo o número de pontos de interesse identificados em cada
imagem. Tais opções englobaram vetores de caracteŕısticas com dimensões entre 128 e
513 elementos, sendo que os melhores resultados foram alcançados pela combinação do
número de pontos em cada imagem e do momento média, num total de 129 elementos no
vetor final de caracteŕısticas.
4.2.4 SURF
Dentre outras implementações, para este descritor foram testadas as disponibilizadas
pela biblioteca Open Source Computer Vision Library (OpenCV) [9], MatLab [89] e pelo
próprio Bay [6]. Seguindo exatamente a mesma metodologia para todas elas e, conforme
descrito na Seção 2.2.1.4, os vetores de caracteŕısticas foram gerados para cada ponto
de interesse identificado pelo detector SURF, cada um com 64 ou 128 elementos para as
versões original e SURF-128, respectivamente.
Semelhante ao SIFT, devido à variação do número de pontos de interesse identificados
para cada imagem (vide Tabela 5.6 da Seção 5.1.2), novamente utilizou-se momentos
estat́ısticos para padronizar sua representação. A partir da média, variância, obliquidade
e curtose, foram gerados vetores com dimensões de 64 e 128 elementos para cada um dos
momentos estat́ısticos utilizados.
Aqui também foram analisadas diferentes combinações de concatenação dos vetores
gerados e do número de pontos de interesse identificados nas imagens. Para a versão
original, o número de elementos dos vetores finais ficou entre 64 e 257, enquanto para
SURF-128 as dimensões variaram de 128 à 513. As melhores taxas foram alcançadas com
a versão SURF-128 da ferramenta Matlab, com a combinação do número de pontos de
interesse identificados na imagem e dos momentos média, variância e obliquidade, num
total de 385 elementos no vetor de caracteŕısticas.
4.2.5 MSER-SURF
O MSER possui apenas a opção de detecção. Assim, SURF foi utilizado como descritor
das regiões identificadas. Como antes, foram utilizadas as versões original e SURF-128,
com a mesma metodologia para ambas, e os vetores de caracteŕısticas com 64 ou 128
elementos, respectivamente.
Novamente, diante da variação do número de regiões identificadas para cada imagem,
optou-se por utilizar momentos estat́ısticos para padronizar sua representação. Para cada
um dos momentos anteriormente citados (média, variância, obliquidade e curtose) foram
gerados vetores com dimensões de 64 e 128 elementos, bem como as mesmas combinações
da seção anterior.
85
Os melhores resultados foram obtidos com vetores finais com 193 elementos, mediante a
combinação do número de regiões detectadas na imagem e dos momentos média, variância
e obliquidade. Salienta-se que para a combinação MSER-SURF apenas as implementações
disponibilizadas pela ferramenta MatLab [89] foram utilizadas e que a versão original do
descritor SURF obteve taxas superiores.
4.2.6 GLCM
Conforme apresentado na Seção 2.2.2.2, foram utilizados apenas seis dentre os 14 des-
critores propostos por Haralick. Tal decisão embasou-se no fato de que a maioria dos
trabalhos encontrados na literatura consideram diferentes subconjuntos dos 14 descrito-
res e afirmam haver correlações e/ou redundâncias entre as informações provenientes de
alguns deles. Assim, com a combinação de energia, contraste, entropia, homogeneidade,
probabilidade máxima e momento de terceira ordem, para as quatro direções, o vetor de
caracteŕısticas ficou com 24 componentes.
Para GLCM, foram avaliadas distâncias no intervalo [1, 10] pixels para a geração do
vetor de caracteŕısticas definido anteriormente. Os melhores resultados foram obtidos
para a distância d = 6 e os piores para d = 1. Destaca-se aqui o fato de que, em geral, os
estudos que empregam imagens macroscópicas têm seus melhores resultados para d = 1,
conforme apresentado no Caṕıtulo 3.
4.2.7 Filtros de Gabor
Para filtros de Gabor, foram mantidos os valores padrão da implementação de Zhu et al.
[153], com exceção do número de escalas e orientações. Foram avaliadas as combinações
entre escalas no intervalo [1,10] e quatro e oito orientações.
O melhor resultado foi alcançado com oito orientações (µ = [0, 7]) e cinco escalas (ν =
[0, 4]). Para cada uma das 40 imagens caracteŕısticas de Gabor geradas por esta famı́lia
de filtros, obteve-se os momentos estat́ısticos média, variância e obliquidade, chegando a
um vetor de caracteŕısticas com 120 elementos.
4.2.8 Resumo dos descritores utilizados
A Tabela 4.1 apresenta um resumo geral dos 10 descritores empregados, considerando sua
complexidade algoŕıtmica, as dimensões dos vetores de caracteŕısticas com os quais foram
obtidos os melhores resultados e o tempo médio por imagem para sua extração.
A utilização de um conjunto de diferentes bibliotecas e ferramentas, sem ter acesso aos
códigos-fonte, impossibilitou a avaliação da complexidade algoŕıtmica de forma detalhada
para cada etapa do processo de extração de caracteŕısticas definido para cada descri-
tor. Diante disto, a Tabela 4.1 apresenta uma avaliação geral de suas complexidades
algoŕıtmicas.
86
Para se ter uma noção de seus custos, avaliou-se também o tempo médio (por imagem)
para a extração dos vetores de caracteŕısticas utilizados para cada descritor, isto é, aqueles
que geraram as melhores taxas de reconhecimento. Para tal avaliação foi utilizado um
equipamento dotado de processador Intel Core i7 (2.2GHz), 8GB (1333MHz DDR3) de
memória RAM e sistema operacional Mac OS X em sua versão 10.8.4. Cabe destacar
que os tempos são representados em segundos (s) e consideraram apenas as operações de
extração, desprezando todas as demais, tais como leitura e escrita.
Tabela 4.1: Descritores utilizados, dimensões de seus vetores de caracteŕısticas, tempo
médio de extração e complexidade algoŕıtmica.
Descritor # Caracteŕısticas Tempo (s) Complexidade Algoŕıtmica
SURF 385 0,38 O(N log2 N)
MSER-SURF 193 1,66 O(N log2 N)
SIFT 129 1,57 O(N)
LPQ 256 0,34 O(N2 log2 N)
LPQ-TOP 256 0,93 O(N2 log2 N)
LBPu28,2 59 0,30 O(N)
LBPri8,2 36 0,33 O(N)
LBPriu28,2 10 0,31 O(N)
GLCM 24 1,2e−4 O(N)
GABOR 120 0,9e−4 O(N)
Tempo = segundos por imagem.
N = total de pixels em cada imagem.
4.3 Classificação: avaliação dos parâmetros inerentes à repre-
sentação baseada em vetores de dissimilaridade
Esta seção avalia a influência dos parâmetros empregados na transformação do espaço de
caracteŕısticas para o espaço de dissimilaridade. Tal avaliação considerou as quantidades
de classes, amostras por classe e referências por amostra utilizadas para gerar os vetores
de dissimilaridade que compuseram os conjuntos de treinamento e teste, bem como sua in-
fluência com relação às taxas de reconhecimento alcançadas pelas diferentes configurações
testadas.
Partindo dos resultados apresentados na Seção 4.2, foram selecionados o descritor
LPQ4 e a configuração que produziu as melhores taxas de reconhecimento para este des-
critor, sendo que as configurações que produziram os melhores resultados foram assumidas
para todos os descritores.
Tomando o contexto de dissimilaridade e a independência entre as classes utilizadas
durante treinamento e teste, a base de imagens foi dividida em cinco partes, em termos
4Os descritores baseados em pontos de atenção SURF, MSER-SURF e SIFT ainda não haviam sido
testados no momento em que este conjunto de experimentos foi realizado. Assim, LPQ foi escolhido por
ser o descritor para o qual o classificador constrúıdo apresentava os melhores resultados naquele momento.
87
de classes (espécies florestais). Diferentes combinações foram testadas para estas cinco
partes, com a proporção de 60%-40% para treinamento e teste, respectivamente. Ao
final das execuções, todas as cinco partes tiveram o mesmo número de participações nos
conjuntos de treinamento e teste, respectivamente. A maior amplitude para o primeiro
conjunto do que para o segundo, permitiu uma melhor avaliação da influência do número
de classes do conjunto de treinamento com relação às taxas de reconhecimento. Maiores
detalhes quanto ao processo de avaliação são apresentados na Seção 4.6.
O primeiro conjunto de testes avaliou a influência das p amostras por espécie florestal
e das n referências por amostra. A descrição algoŕıtmica do processo é apresentada no
Pseudo-código 4.1. Para a geração do conjunto de treinamento, p assumiu todos
os valores do intervalo [4, 20]. Para cada variação de p e para cada diferente espécie
florestal, as amostras si foram combinadas aos pares e (
p
2) vetores de dissimilaridade
foram gerados para a classe positiva. Ou seja, para cada amostra si, havia um total de
n referências (n = p − 1). Para equilibrar os conjuntos de vetores de dissimilaridade
positivos e negativos, (p2) vetores também foram gerados para a classe negativa. Para
isso, n amostras si e n referências rj foram sorteadas e utilizadas para gerar n vetores de
dissimilaridade para (p2)/n classes também definidas aleatoriamente. Tal escolha reduziu o
elevado custo de treinamento dos modelos decorrente do uso de todas as classes negativas,
além de provavelmente eliminar muitas repetições de padrões gerados para as mesmas e
que não contribuiriam para com os modelos.
Para a geração do conjunto de teste, foram gerados vetores de dissimilaridade entre
a amostra questionada sq e n (n ∈ [3, 19]) referências definidas aleatoriamente para cada
espécie florestal candidata. Cada um dos modelos de classificação foi testado com todos
os 16 conjuntos de teste. Ao final, observou-se que as melhores taxas de reconhecimento
foram alcançadas pelos conjuntos de treinamento que utilizaram 12 amostras e 11 re-
ferências para cada uma das 68 espécies florestais, num total de 8.976 (66×2×68) vetores
de dissimilaridade. Combinadas aos pares, as 12 amostras de cada espécie florestal gera-
ram 66 vetores de dissimilaridade positivos, sendo que outros 66 vetores foram gerados
para a classe negativa Cl−, por meio da combinação de 11 das 12 amostras com outras 11
referências de seis outras espécies escolhidas aleatoriamente. As 19 referências dispońıveis
foram utilizadas para cada uma das 20 amostras sq pertencentes às 44 espécies florestais
do conjunto de teste, num total de 735.680 (20×19×44×44) vetores de dissimilaridade.
A influência do número de classes utilizadas para o treinamento foi realizada mantendo
a configuração identifica nos experimentos anteriores. Assim, diferentes subconjuntos das
68 espécies florestais foram considerados no intervalo [9, 68], enquanto o conjunto de teste
foi mantido com as 44 espécies florestais. O Pseudo-código 4.1 pode ser utilizado para
representar este processo. A única alteração ocorre na linha 2 (dois) da geração dos
conjuntos de vetores de dissimilaridade utilizados para treinamento dos classificadores.
Neste ponto, o limite superior do laço ‘para’ assume diferentes valores no intervalo [9, 68].
Os melhores resultados foram obtidos pelo modelo de classificação inicialmente testado,
88
Pseudo-código 4.1. Avaliação do número de amostras por classe e referências
por amostra.
GeraConjuntosTreinamento
1: para p de 4 à 20 passo 1 faça
2: para cada espécie florestal Cli de 1 à 68 passo 1 faça
3: sorteie p amostras si, si∈Cli
4: gere os vetores de dissimilaridade para as (p2) combinações posśıveis
entre as amostras si para a classe Cl+
5: gere (p2) vetores de dissimilaridade para cada par (si, rj), si∈Cli e rj∈Clj ,
para a classe Cl−, utilizando p− 1 amostras si e p− 1 referências rj de
(p2)/n espécies florestais Clj diferentes de Cli
6: fim-para
7: fim-para
GeraConjuntosTeste
1: para p de 4 à 20 passo 1 faça
2: para cada espécie florestal Clq de 1 à 44 passo 1 faça
3: sorteie p amostras sq, sq∈Clq
4: para cada espécie florestal Clj de 1 à 44 passo 1 faça
5: sorteie p− 1 referências rj , rj∈Clj
6: gere os vetores de dissimilaridade para cada par (sq, rj)
7: fim-para
8: fim-para
9: fim-para
Principal
1: GeraConjuntosTreinamento
2: GeraConjuntosTeste
3: para cada conjunto de treinamento CTR gerado faça
4: construa modelo de classificação MTR
5: para cada conjunto de teste CTS gerado faça
6: avalie MTR em CTS
7: fim-para
8: fim-para
9: selecione configurações para CTR e CTS que maximizaram os resultados
o qual utilizou as 68 espécies florestais em sua construção.
Por fim, avaliou-se a robustez dos modelos anteriormente constrúıdos diante do cresci-
mento da base de teste. Para isso, manteve-se os modelos de classificação criados com as
configurações que apresentaram os melhores resultados. Exceto pelo número de espécies
florestais, que variou no intervalo [9, 44], as configurações utilizadas na criação dos conjun-
tos de teste também foram mantidas. O Pseudo-código 4.1 pode também ser utilizado para
representar este processo. As únicas alterações ocorrem nas linhas 2 (dois) e 4 (quatro)
da geração dos conjuntos de vetores de dissimilaridade utilizados na classificação (‘Gera-
ConjuntosTeste’). Neste ponto, os limites superiores dos laços ‘para’ assumem diferentes
valores no intervalo [9, 44].
Destaca-se que nem todos os valores dos intervalos anteriormente identificados foram
considerados na avaliação da influência do número de espécies florestais utilizadas na
geração dos vetores de dissimilaridade. Diante das amplitudes dos intervalos, no segundo
conjunto de experimentos, nove das 68 espécies florestais foram aleatoriamente escolhi-
das para treinamento. A partir deste subconjunto de espécies, outros foram gerados
89
pela agregação de três novas espécies, também aleatoriamente definidas, até que as 68
espécies florestais dispońıveis fossem contempladas. O mesmo procedimento foi seguido
durante a avaliação da robustez dos modelos de classificação com diferentes conjuntos
de teste. Assim, iniciou-se com nove espécies florestais, aleatoriamente escolhidas den-
tre as 44 dispońıveis. Como antes, novos subconjuntos foram gerados pela agregação de
três novas espécies, também aleatoriamente definidas, até que as 44 espécies florestais
fossem contempladas. Tal escolha permitiu a avaliação da influência destes parâmetros
e das tendências das taxas de reconhecimento, com a vantagem da redução dos custos
computacionais inerentes à avaliação de todos os valores dos intervalos.
4.4 Seleção de Classificadores
Os métodos propostos para seleção dinâmica de classificadores são apresentados nas
subseções seguintes. Para a avaliação destes e também daqueles descritos na Seção 2.4.2.1
foi empregado o modelo apresentado na Seção 4.1. Assim, a mesma metodologia foi em-
pregada para todos os métodos testados, exceto é claro pelo próprio método utilizado na
etapa de seleção. Maiores detalhes quanto aos critérios de avaliação estão definidos na
Seção 4.6.
Destaca-se nesta etapa o uso da representação baseada em vetores de dissimilaridade e
a seleção dinâmica dos classificadores neste espaço de representação. Ou seja, enquanto a
seleção no espaço de caracteŕısticas ocorreria uma única vez para a amostra questionada
sq, no espaço de dissimilaridade esta ocorre para cada vetor de dissimilaridade Zq,j criado
para sq e as referências utilizadas rj. Como ilustração, considere a Figura 4.2, com os veto-
res Zq,j criados para sq e cinco referências rj para três espaços de dissimilaridade sintéticos
com dimensões x1 e x2 quaisquer. Neste exemplo, cada espaço de dissimilaridade repre-
senta um diferente descritor dentre aqueles descritos na Seção 2.2. Conforme ilustrado
nas Figuras 4.2(a), 4.2(b) e 4.2(c), espera-se que as distribuições das instâncias Zq,j nos
diferentes espaços de dissimilaridade também sejam diferentes por refletir as teorias em
que seus descritores são baseados, as dimensionalidades de seus vetores de caracteŕısticas
e seus modelos de classificação.
Suponha ainda a minimização da distância Euclidiana entre Zq,j e a origem do respec-
tivo espaço de representação como critério de seleção. Diante desta situação hipotética,
as instâncias Zq,1, Zq,4 e Zq,5 seriam classificadas no espaço da Figura 4.2(a). Já Zq,2 e
Zq,3 seriam classificadas no espaço da Figura 4.2(b) e não haveria qualquer instância clas-
sificada no espaço da Figura 4.2(c). Além disso, devido ao fato de haver apenas um único
classificador em cada diferente espaço de representação, a seleção de um espaço espećıfico
implica diretamente na seleção do respectivo classificador.
Como a seleção dos classificadores ocorre no espaço de dissimilaridade, tanto a instância
questionada Zq,j quanto os vizinhos do conjunto de validação utilizados no processo de
seleção dos classificadores são vetores de dissimilaridade. Assim, é importante não con-
90
(a) (b) (c)
Figura 4.2: Situação hipotética para a seleção dinâmica de classificadores baseada na
minimização da distância entre a instância questionada Zq,j e a origem do respectivo
espaço de representação sintético com dimensões x1 e x2 quaisquer.
fundir os vizinhos do conjunto de validação utilizados para a seleção dos classificadores,
que muitas vezes podem ser vistos e/ou denominados como referências, com as referências
utilizadas para a geração dos vetores de dissimilaridade.
Diante da contextualização anterior, as definições de distância utilizadas por Woods
et al. [146] e similaridade definidas por Giacinto e Roli [36] tornam-se d(Zq,j, Zu,v) e
S(Zq,j, Zu,v). Como ilustrado na Figura 4.1, Zu,v representa o vetor de dissimilaridade
calculado para as amostras (imagens) ru e rv, ambas do conjunto de validação no espaço de
caracteŕısticas. Ou seja, Zu,v representa os vizinhos (referências) do conjunto de validação
no espaço de dissimilaridade utilizados na seleção do espaço de representação em que Zq,j
será classificada. Cabe destacar que, embora o modelo e os métodos propostos utilizem a
representação baseada em dissimilaridade, os métodos apresentados nesta seção também
podem ser aplicados para a seleção dinâmica de classificadores no espaço de caracteŕısticas.
Conforme apresentado na Seção 4.3, apenas 12 das 20 imagens existentes para cada
espécie florestal foram utilizadas para gerar os vetores de dissimilaridade empregados
na construção dos modelos de classificação. Considerando a necessidade de um con-
junto de validação no processo de seleção dinâmica de classificadores e buscando uma
independência quanto às amostras empregadas na construção dos modelos, foram seleci-
onadas aleatoriamente três das oito amostras restantes por espécie florestal. Diante da
existência de 68 espécies florestais na base de treinamento, um total de 408 (3×2×68)
vetores de dissimilaridade foram gerados. Para isso, combinou-se as três imagens entre si
para obter as instâncias positivas. Para as instâncias negativas, as mesmas três imagens
foram combinadas com uma imagem de referência de outras três espécies também sele-
cionadas aleatoriamente. Também foram realizados testes preliminares com cinco e oito
imagens para a geração dos vetores de dissimilaridade do conjunto de validação, mas não
se identificou diferenças significativas. No entanto, o aumento da quantidade de elemen-
tos gerados de 408 para 1.360 (10×2×68) e 3.808 (56×2×68) com cinco e oito imagens,
91
respectivamente, implicou na elevação do custo computacional do processo de seleção.
As seções seguintes apresentam os métodos avaliados para a seleção dinâmica de clas-
sificadores, o quais baseiam-se na distribuição das instâncias e nas decisões tomadas para
as vizinhanças das amostras questionadas.
4.4.1 Métodos de seleção dinâmica de classificadores baseados
na distribuição das instâncias no espaço de dissimilaridade
Nesta seção são apresentadas as alternativas avaliadas para a seleção dinâmica de clas-
sificadores tomando como base apenas a distribuição das instâncias (vetores de dissimi-
laridade) no espaço de dissimilidade. A principal motivação para o uso de tal critério
concentra-se no fato de que a transformação do espaço de caracteŕısticas para o espaço de
dissimilaridade tende a gerar conjuntos mais coesos, principalmente para a classe positiva,
conforme apresentado na Seção 2.3.1.
Para facilitar a compreensão dos critérios de seleção propostos nas subseções seguintes,
são apresentadas ilustrações com apenas três conjuntos sintéticos, isto é, gerados artifi-
cialmente. No entanto, todos os processos definidos nestas subseções consideram os 10
espaços de representação utilizados neste trabalho.
4.4.1.1 Seleção dinâmica de classificadores baseada na distância
entre a instância questionada e os centróides das classes
do conjunto de validação
A presente estratégia está embasada nos critérios de proximidade e vizinhança utilizados
por diversos métodos de seleção dinâmica de classificadores. Como cada classificador foi
constrúıdo em um espaço de dissimilaridade n-dimensional diferente, busca-se validar a
hipótese de que quanto menor a distância entre a instância questionada Zq,j e o centróide
de uma classe candidata Cll, maior é a probabilidade de Zq,j pertencer a Cll e do classifi-
cador prover tal predição. Em outras palavras, supõe-se que Zq,j deva ser classificada no
espaço de dissimilaridade que apresente a menor distância entre Zq,j e o centróide de Cll.
Neste caso, a classe selecionada Cll pode ser qualquer uma das classes (positiva ou nega-
tiva) dos conjuntos de validação dos 10 diferentes espaços de dissimilaridade considerados
neste estudo.
Para exemplificar graficamente esta estratégia, a Figura 4.3 apresenta três diferen-
tes conjuntos de validação sintéticos no espaço de dissimilaridade bidimensional com di-
mensões x1 e x2 quaisquer. Como ilustrado, supõe-se que as teorias em que os descritores
são baseados e as diferentes dimensionalidades de seus vetores de caracteŕısticas gerem
distribuições diversas para vetores de dissimilaridade Zu,v, embora as semelhanças ine-
rentes às classes (positiva e negativa) ainda sejam preservadas e posśıveis agrupamentos
sejam mantidos em cada espaço de representação.
92
Uma descrição algoŕıtmica desta estratégia é apresentada no Pseudo-código 4.2. A
partir dos vetores de dissimilaridade Zu,v dos conjuntos de validação, identificados por
(+) e (  ) nas Figuras 4.3(a), 4.3(b) e 4.3(c), os centróides (vetores médios) C+ e C− das
classes positiva e negativa, respectivamente, são calculados. Na sequência, calcula-se as
distâncias Manhattan entre Zq,j e os centróides C+ e C−, identificadas por d+ e d−. O uso
das distâncias Manhattan justifica-se pelas diferentes dimensionalidades dos vetores em
cada espaço de representação e desta métrica não influenciar no valor final das distâncias
em decorrência da normalização realizada pelo tamanho t do vetor gerado no respectivo
espaço. Após realizar tal procedimento para os três conjuntos de validação sintéticos no
espaço de dissimilaridade bidimensional, o espaço da Figura 4.3(a) é selecionado e Zq,j é
atribúıda à classe positiva representada pelo centróide C+.
(a) (b) (c)
Figura 4.3: Seleção dinâmica de classificadores baseada na minimização da distância
entre a instância questionada Zq,j e os centróides (C+ e C−) das classes positiva e negativa
dos conjuntos de validação.
Pseudo-código 4.2. Método min d(Zq,j , C).
Detalhes: classificadores abstratos, critério min d(Zq,j , C).
Entradas: conjunto de validação, Zq,j e predições de cada classificador Ck para Zq,j .
Sáıda: classificador Ck com min d(Zq,j , C).
1: para cada classificador Ck faça
2: calcule os centróides C para as classes (Cl+ e Cl−) do conjunto de validação
3: calcule distâncias Manhattan d(Zq,j , C) entre Zq,j e os centróides C
4: fim-para
5: selecione Ck com menor valor para d(Zq,j , C), calculada nos passos 1-4.
4.4.1.2 Seleção dinâmica de classificadores baseada na distância
entre a instância questionada e as fronteiras dos modelos
de classificação
Esta estratégia está embasada no fato de que os modelos foram constrúıdos com o clas-
sificador SVM, o qual procura maximizar a distância entre as margens do conjunto de
93
treinamento e o hiperplano que define a fronteira f entre as duas classes do problema
[25, 142]. Assim, dados os classificadores constrúıdos nos diferentes espaços de dissimila-
ridade n-dimensionais, busca-se validar a hipótese de que cada instância questionada Zq,j
deva ser classificada no espaço que apresente a maior distância entre Zq,j e f . Ou seja,
considera-se que quanto maior a distância d entre Zq,j e f , maior é a probabilidade do
classificador gerar uma predição correta para Zq,j no respectivo espaço.
Durante a fase de classificação, mediante ajustes no código da ferramenta libSVM
[18], obteve-se também a distância d entre a instância questionada Zq,j e f nos diferentes
espaços considerados, sendo desnecessário o uso dos conjuntos de validação. A Equação
4.1 apresenta o cálculo da distância d, com o módulo do ‘valor de decisão’ dividido pela
norma do vetor w, ortogonal ao hiperplano que representa f . O ‘valor de decisão’ pode
ser positivo ou negativo, dependendo do lado do hiperplano em que Zq,j estiver situada,
e representa a medida algébrica da distância entre Zq,j e f [25].
d(Zq,j, f) =
abs(valor de decissão)
|w|
(4.1)
Para exemplificar graficamente esta estratégia, a Figura 4.4 apresenta três conjuntos
sintéticos no espaço de dissimilaridade bidimensional com dimensões x1 e x2 quaisquer.
Nas Figuras 4.4(a), 4.4(b) e 4.4(c), os vetores de dissimilaridade Zu,v são identificados
por (+) e (  ) e representam, respectivamente, os elementos das classes positiva e negativa
dos conjuntos de treinamento. Novamente, supõe-se que as teorias em que os descritores
são baseados e as diferentes dimensionalidades de seus vetores de caracteŕısticas gerem
distribuições diversas para Zu,v, mas ainda mantenham as semelhanças inerentes às classes
(positiva e negativa) e seus agrupamentos em cada espaço de representação.
A partir das instâncias Zu,v, os modelos de classificação são constrúıdos e as frontei-
ras f são definidas. Tomando-se a ilustração dos três conjuntos sintéticos no espaço de
dissimilaridade bidimensional e a maximização de d como critério de seleção, o espaço
da Figura 4.4(c) é selecionado e Zq,j é atribúıda à classe predita pelo classificador deste
espaço. Uma descrição algoŕıtmica desta estratégia é apresentada no Pseudo-código 4.3.
Pseudo-código 4.3. Método max d(Zq,j , f).
Detalhes: classificadores abstratos, critério max d(Zq,j , f).
Entradas: predições de cada classificador Ck para Zq,j e distância d(Zq,j , f)
em cada espaço.
Sáıda: classificador Ck com max d(Zq,j , f).
1: para cada classificador Ck faça
2: obtenha d(Zq,j , f) calculada durante a classificação de Zq,j
3: fim-para
4: selecione Ck com maior valor para d(Zq,j , f), obtida nos passos 1-3.
94
(a) (b) (c)
Figura 4.4: Seleção dinâmica de classificadores baseada na maximização da distância entre
a instância questionada Zq,j e as fronteiras f dos modelos.
4.4.1.3 Seleção dinâmica de classificadores baseada na dispersão
das referências dos conjuntos de validação
Nesta estratégia busca-se validar a hipótese de que cada instância questionada Zq,j deva
ser classificada no espaço em que os vetores de dissimilaridade Zu,v obtidos com as re-
ferências ru e rv (rj, ru, rv∈Clj) apresentem a menor dispersão. Ou seja, considera-se
que quanto menor a dispersão maior é a probabilidade de Zq,j pertencer a Clj, pois a
transformação do espaço de caracteŕısticas para o espaço de dissimilaridade tende a gerar
conjuntos mais coesos, principalmente para a classe positiva, conforme apresentado na
Seção 2.3.1. Tal hipótese está embasada nos critérios de proximidade e vizinhança uti-
lizados por diversos métodos de seleção dinâmica de classificadores, sendo avaliada por
meio do método proposto por Davies e Bouldin [23] e que recebe o nome de seus autores,
Davies-Bouldin Index (DBI).
Uma descrição algoŕıtmica desta estratégia é apresentada no Pseudo-código 4.4. Se-
guindo a descrição da Seção 2.3.1, para cada amostra (imagem) questionada sq e para
cada classe candidata Cll, obtém-se as n referências rj utilizadas na geração dos vetores
de dissimilaridade Zq,j. Para cada uma das (
n
2 ) posśıveis combinações das referências rj,
gera-se os vetores de dissimilaridade Zu,v (u = [1, n] e v = [1, n], u 6=v). Na sequência,
calcula-se o centróide (vetor médio - C) dos vetores de dissimilaridade Zu,v e calcula-se
o ı́ndice de dispersão Disp(sq). A Equação 4.2 apresenta a expressão para o cálculo de
Disp(sq), dado pela distância média (Manhattan) entre os elementos Zu,v e seu centróide
C. Para se obter a distância média, utiliza-se o número de vetores de dissimilaridade (n)
e seu tamanho (t) para a normalização. O uso das distâncias Manhattan justifica-se pelas
diferentes dimensionalidades dos vetores em cada espaço de representação e desta métrica
não influenciar no valor final das distâncias em decorrência da normalização realizada com
a divisão por t.
95
Disp(sq) =
1
n×t
n∑
i=1
t∑
j=1
|Zu,v(j)− C(j)| (4.2)
Pseudo-código 4.4. Método minDisp(sq).
Detalhes: classificadores abstratos, critério minDisp(sq).
Entradas: predições de cada classificador Ck para Zq,j e relação de referências
rj para sq em cada espaço.
Sáıda: classificador Ck com minDisp(sq).
1: para cada classificador Ck faça
2: para cada classe candidata Cll (no espaço de caracteŕısticas) faça
3: obtenha as referências rj utilizadas para gerar os vetores Zq,j
4: gere os (n2 ) posśıveis vetores Zu,v para as combinações das referências rj
5: calcule o centróide C dos vetores Zu,v
6: calcule a dispersão Disp(sq), (Eq. 4.2)
7: fim-para
8: fim-para
9: selecione Ck com menor valor para Disp(sq), calculada nos passos 1-8,
para todos os vetores Zq,j .
Para exemplificar graficamente esta estratégia, a Figura 4.5 apresenta três conjuntos
sintéticos de instâncias Zu,v no espaço de dissimilaridade bidimensional com dimensões
x1 e x2 quaisquer. As Figuras 4.5(a), 4.5(b) e 4.5(c) apresentam os conjuntos gerados
para três diferentes classes candidatas Cll e suas instâncias identificadas por (+). Após
calcular a dispersão Disp(sq) para as três classes, a classe da Figura 4.5(b) é identificada
como vencedora por apresentar a menor dispersão.
Nesta estratégia, a classe selecionada Cll pode ser qualquer uma das 44 classes can-
didatas existentes em cada um dos 10 diferentes espaços de dissimilaridade considerados
neste estudo. Assim, diante da hipótese inicial para esta estratégia, das teorias em que
os descritores são baseados, das diferentes dimensionalidades de seus vetores de carac-
teŕısticas e também das distribuições diversas para os vetores de dissimilaridade Zu,v, as
três classes do exemplo podem pertencer a três espaços distintos ou até mesmo ao mesmo
espaço de representação. Dado que a medida de dispersão é obtida para todo o conjunto
de vetores de dissimilaridade Zu,v uma única vez, um único classificador é selecionado para
todos os n vetores de dissimilaridade Zq,j gerados para sq. Além disso, nesta estratégia
também não é necessário utilizar o conjunto de validação.
4.4.2 Métodos de seleção dinâmica de classificadores baseados
nas decisões para as vizinhanças das instâncias questiona-
das
A motivação dos métodos propostos nesta seção compreende o potencial quanto ao incre-
mento das taxas de reconhecimento alcançadas por meio da combinação de um conjunto
de fatores. O primeiro fator compreende a variação dos resultados obtidos para os métodos
propostos por Woods et al. [146] com a simples alteração dos critérios OLA e LCA para
96
(a) (b) (c)
Figura 4.5: Seleção dinâmica de classificadores baseada na minimização da dispersão
das instâncias positivas Zu,v obtidas para cada classe candidata.
a delimitação da vizinhança da amostra questionada sq. Ainda relacionado à vizinhança,
outro fator foi identificado por Giacinto e Roli [36] ao definirem o método MCB OLA,
os quais afirmam que uma das principais dificuldades ao se trabalhar com vizinhanças
consiste na determinação de um valor ideal para seu tamanho e na dependência que todo
o sistema terá deste valor. O terceiro fator refere-se ao incremento das taxas de reconhe-
cimento a partir do uso de probabilidades, tal como proposto por Giacinto e Roli [35] nos
métodos a priori e a posteriori, para os critérios OLA e LCA, respectivamente. Por fim,
tem-se o fato de que diferentes regras de combinação geram resultados diversos de acordo
com as caracteŕısticas do problema em questão.
Os métodos aqui propostos consideram as definições das Seções 2.4.2.1 e 4.4 e utilizam
a vizinhança de uma amostra questionada sq (Figura 4.6) para selecionar o classificador
utilizado na predição de sua classe. A definição de tal vizinhança ocorre a partir do
ı́ndice de similaridade definido por Giacinto e Roli [36] (Figura 4.6(a)), segundo o qual
os vizinhos em uma base de validação são ordenados (Figura 4.6(b)) e vizinhanças com
diferentes tamanhos podem ser consideradas.
Embora se possa avaliar vizinhanças com diferentes tamanhos, Giacinto e Roli [36]
afirmam que, por empregar informações baseadas no ı́ndice de similaridade definido para
MCB, o tamanho da vizinhança de sq é dinamicamente adaptado e não exerce o mesmo
ńıvel de influência como ocorre nos demais métodos. Especificamente, o número de vizi-
nhos h é incrementado ou decrementado de acordo com o grau de similaridade entre as
assinaturas MCB de sq e seus vizinhos rj.
Neste trabalho, foram considerados ı́ndices de similaridade para os espaços n-dimensionais
dos 10 classificadores utilizados. Dadas as diferenças em termos de precisão destes clas-
sificadores, a quantidade máxima de vizinhos avaliada nos experimentos foi limitada ao
número de acertos do classificador com menor taxa de reconhecimento no conjunto de
validação, além dos critérios OLA e LCA para a delimitação da vizinhança de sq. Além
disso, os resultados apresentados na Seção 5.3.2, referentes aos experimentos cuja meto-
97
dologia é descrita na Seção 4.4.1, demonstraram que as medidas de distância não podem
ser utilizadas, direta ou indiretamente, nas comparações entre os diferentes espaços de
representação n-dimensionais para a seleção dos classificadores, até mesmo quando tais
distâncias estejam normalizadas.
Assim, as versões KNORA-E-W e KNORA-U-W propostas por Ko et al. [64, 65] e
as propostas originais de Giacinto e Roli [36] para os métodos a priori e a posteriori
não foram utilizadas. Isto porque nestas versões, as distâncias são utilizadas como pesos
em uma combinação ponderada dos votos dos classificadores e das probabilidades dos
vizinhos, respectivamente. Neste ponto, ao se tomar o terceiro e quarto fatores inicial-
mente identificados, a combinação das decisões dos classificadores ocorreu por meio de
oito diferentes regras, tal como apresentado na Seção 4.5.
(a) (b)
Figura 4.6: Métodos baseados em local accuracy : (a) vizinhança da amostra questio-
nada sq; (b) ordenação da vizinhança segundo o critério da distância Euclidiana entre os
vizinhos rj e sq.
O primeiro método de seleção dinâmica de classificadores proposto neste trabalho está
baseado no fato de que os métodos que consideram o critério LCA para a delimitação
da vizinhança de sq geralmente apresentam melhores taxas de reconhecimento quando
comparados com aqueles que empregam o critério OLA [35][146]. Assim, este primeiro
método proposto mantém todas as definições originais do método MCB OLA, exceto pela
troca do critério OLA pelo critério LCA para a delimitação da vizinhança de sq durante
a seleção do classificador C∗, no último estágio do método MCB OLA (Seção 2.4.2.1).
Denominado MCB LCA (Pseudo-código 4.5), para este novo método, se Ck classificar
sq como pertencente à classe Cll, a vizinhança de sq será composta apenas pelas hl re-
ferências rj do conjunto de validação também pertencentes à Cll. A partir disto, durante
o processo final do método, ao se tomar as assinaturas MCB(rj), para cada classificador
Ck, contabiliza-se os acertos hlk para os hl vizinhos (referências) mais próximos à sq e
pertencentes à classe Cll. Por fim, tal como ilustrado na Equação 2.56, o classificador C
∗
que apresentar a maior taxa de classificações corretas, dentre todos os classificadores Ck,
é selecionado.
98
Pseudo-código 4.5. Método MCB LCA.
Detalhes: classificadores abstratos, critério LCA para delimitação da vizinhança.
Entradas: conjunto de validação, rótulos associados por cada classificador Ck para
todo o conjunto de validação, tamanho h da vizinhança, rótulo da classe Cll
associada por Ck à sq.
Sáıda: classificador Ck que maximiza a taxa de vizinhos corretamente classificados.
1: crie vetor MCB(si), conforme Eq. 2.61, para cada amostra si dos conjuntos
de teste e validação
2: ordene os elementos do conjunto de validação considerando sua similaridade
com sq (Eq. 2.62), em ordem decrescente
3: selecione os elementos do conjunto de validação com o ı́ndice de similaridade
maior ou igual ao do h-ésimo elemento
4: para cada classificador Ck faça
5: selecione os hl elementos da vizinhança previamente selecionada no passo 3
6: conte os hlk vizinhos corretamente classificados por Ck na vizinhança
previamente selecionada no passo 5
7: calcule a taxa de vizinhos corretamente classificados por Ck (Eq. 2.56)
8: fim-para
9: selecione Ck que maximiza a taxa de vizinhos corretamente classificados
calculada nos passos 4-8.
O segundo e o terceiro métodos propostos neste trabalho reúnem os potenciais ineren-
tes aos métodos baseados em MCB, ao uso de probabilidades e também a possibilidade
quanto ao emprego de diferentes regras de combinação devido à utilização de classifica-
dores probabiĺısticos (vide Seção 4.5). Tais propostas estão embasadas no fato de que
Giacinto e Roli [36] provaram que as acurácias dos métodos a priori e a posteriori são
equivalentes ou superiores às acurácias dos métodos OLA e LCA apresentados por Woods
et al. [146]. Assim, os critérios OLA e LCA, utilizados pelos métodos MCB OLA e MCB
LCA na delimitação da vizinhança de sq durante a seleção do classificador C
∗, foram
trocados pelos utilizados nos métodos a priori e a posteriori, respectivamente.
Em decorrência das trocas anteriores, as taxas de acertos (classificadores abstratos)
deram lugar aos resultados da combinação das predições corretas de classificadores proba-
biĺısticos. Assim, os dois novos métodos são denominados MCB a priori (Pseudo-código
4.6) e MCB a posteriori (Pseudo-código 4.7), para os quais as vizinhanças são limitadas
aos hk e hlk vizinhos do conjunto de validação, respectivamente. Como definido anterior-
mente, hk refere-se à quantidade de vizinhos corretamente classificados por Ck, bem como
hlk refere-se à quantidade de vizinhos corretamente classificados por Ck e pertencentes à
classe Cll, para a qual sq foi predita por Ck [64, 65, 146].
Neste ponto destaca-se a dinamicidade quanto ao tamanho da vizinhança utilizada
por cada classificador Ck. De forma geral, a vizinhança é limitada aos hk e hlk vizinhos
do conjunto de validação decorrentes dos critérios OLA e LCA, respectivamente. Tal
vizinhança torna-se ainda mais restrita devido ao emprego do subconjunto de vizinhos
determinado pelo ı́ndice de similaridade S definido por Giacinto e Roli [36]. Ao se to-
mar o subconjunto de vizinhos determinado pelo ı́ndice de similaridade S, a quantidade
final de vizinhos será ainda reduzida de acordo com a taxa de classificações corretas de
cada classificador neste subconjunto por serem utilizadas apenas as predições corretas dos
99
Pseudo-código 4.6. Método MCB a priori.
Detalhes: classificadores probabiĺısticos, critério OLA para delimitação da vizinhança
e restritos somente aos hk corretamente classificados por cada classificador Ck.
Entradas: conjunto de validação, probabilidades a posteriori associadas por cada
classificador Ck para todo o conjunto de validação, tamanho h da vizinhança.
Sáıda: classificador Ck que maximiza as probabilidades a posteriori dos hk
vizinhos mais próximos rj ponderadas pela distância Euclidiana dj entre sq e rj .
1: crie vetor MCB(si), conforme Eq. 2.61, para cada amostra si dos conjuntos
de teste e validação
2: ordene os elementos do conjunto de validação considerando sua similaridade
com sq (Eq. 2.62), em ordem decrescente
3: selecione os elementos do conjunto de validação com o ı́ndice de similaridade
maior ou igual ao do h-ésimo elemento
4: para cada classificador Ck faça
5: selecione os hk elementos corretamente classificados da vizinhança
previamente selecionada no passo 3
6: calcule a média ponderada das probabilidades a posteriori (Eq. 2.58) para
os hk elementos
7: fim-para
8: Selecione Ck que maximiza a média ponderada calculada nos passos 4-7.
classificadores probabiĺısticos.
Cabe destacar que, assim como os métodos OLA, LCA, a priori, a posteriori, KNORA-
E e KNORA-U, todos os métodos propostos nesta seção podem ser aplicados no espaço de
caracteŕısticas. No entanto, a abordagem utilizada neste trabalho e também representada
no modelo da Figura 4.1 impõem algumas alterações. A partir das definições anteriores,
ao se tomar o contexto deste trabalho e o fato da classificação ocorrer no espaço de dissi-
milaridade, as assinaturas MCB(si) = {C1(si), C2(si), ..., Ck(si), ..., CK(si)} passam a ser
MCB(Zu,v) = {C1(Zu,v), C2(Zu,v), ..., Ck(Zu,v), ..., CK(Zu,v)} com as predições Ck(Zu,v)
do classificador Ck(k = [1, K]) para cada instância Zu,v dos conjuntos de Teste (Zq,j)
e Validação (Zu,v). Conforme afirmado no ińıcio da Seção 4.4, o ı́ndice de similaridade
definido por Giacinto e Roli [36] passa de S(sq, rj) para S(Zq,j, Zu,v), tal como definido
nas Equações 4.3 e 4.4.
S(Zq,j, Zu,v) =
1
K
K∑
k=1
Tk(Zq,j, Zu,v) (4.3)
Tk(Zq,j, Zu,v) =
{
1, se Ck(Zq,j) = Ck(Zu,v)
0, se Ck(Zq,j) 6= Ck(Zu,v)
(4.4)
4.5 Combinação de Classificadores
As regras para combinação de classificadores apresentadas na Seção 2.4.1 foram empre-
gadas nas etapas de Seleção e Fusão (Figura 4.1). Em ambas, os elementos considerados
constituem os vetores de dissimilaridade Zq,j gerados para sq e não a própria sq. Na etapa
de seleção de classificadores, cada um dos métodos utiliza diferentes subconjuntos das
100
Pseudo-código 4.7. Método MCB a posteriori.
Detalhes: classificadores probabiĺısticos, critério LCA para delimitação da vizinhança
e restritos somente aos hlk corretamente classificados por cada classificador Ck.
Entradas: conjunto de validação, probabilidades a posteriori associadas por cada
classificador Ck para todo o conjunto de validação, tamanho h da vizinhança,
rótulo da classe Cll associada por Ck à sq.
Sáıda: classificador Ck que maximiza as probabilidades a posteriori dos hlk
vizinhos mais próximos rj ponderadas pela distância Euclidiana dj entre sq e rj .
1: crie vetor MCB(si), conforme Eq. 2.61, para cada amostra si dos conjuntos
de teste e validação
2: ordene os elementos do conjunto de validação considerando sua similaridade
com sq (Eq. 2.62), em ordem decrescente
3: selecione os elementos do conjunto de validação com o ı́ndice de similaridade
maior ou igual ao do h-ésimo elemento
4: para cada classificador Ck faça
5: selecione os hlk elementos corretamente classificados da vizinhança
previamente selecionada no passo 3
6: calcule a média ponderada das probabilidades a posteriori (Eq. 2.60) para
os hlk elementos
7: fim-para
8: Selecione Ck que maximiza a média ponderada calculada nos passos 4-7.
regras de combinação apresentadas. Woods et al. [146] (OLA e LCA), Giacinto e Roli
[36] (MCB OLA) e também o método proposto MCB LCA consideram apenas a conta-
gem de acertos, num processo de seleção baseado em kNN ou voto majoritário. Ko et al.
[64, 65] utilizam o mesmo critério para a seleção de subconjuntos de classificadores para
os métodos KNORA-E e KNORA-U, bem como votos ponderados pela distância entre
a amostra questionada e seus vizinhos para os métodos KNORA-E-W e KNORA-U-W.
Giacinto e Roli [35] (a priori e a posteriori), assim como os métodos propostos MCB a
priori e MCB a posteriori, utilizam apenas a probabilidade média, ou a mesma probabi-
lidade com média ponderada pela distância entre a amostra questionada e seus vizinhos,
para selecionar C∗.
Considerando que as diversas abordagens testadas com critérios de seleção baseados
em medidas de distância (vide Seção 4.4.1) não obtiveram sucesso (vide Seção 5.3.2),
concluiu-se que não é posśıvel aplicar a probabilidade média ponderada nem os votos
ponderados. Dado que diferentes regras de combinação, tais como as apresentadas por
Jain et al. [56] e Kittler et al. [62] (vide Seção 2.4.1), produzem resultados diversos depen-
dendo das caracteŕısticas do problema em questão, para todos os métodos que utilizaram
classificadores probabiĺısticos foi empregado um conjunto de regras de combinação mais
amplo e composto por: voto majoritário, borda count, soma, média, produto, máximo,
mı́nimo e mediana [8, 48, 56, 62]. O método KNORA constitui uma exceção nesta etapa.
Para este método, inicialmente realizou-se a contagem dos acertos dos classificadores na
vizinhança de Zq,j. Posteriormente, para os casos com mais de um classificador sele-
cionado, as decisões individuais foram combinadas por meio das regras anteriormente
mencionadas.
Na etapa de fusão, as decisões parciais D(Zq,j) são combinadas para obter a decisão
101
final D(sq) para sq. Tal combinação é consequência da transformação do espaço de ca-
racteŕısticas para o espaço de dissimilaridade, sendo necessária para retornar ao espaço
de caracteŕısticas e obter as taxas de reconhecimento, tal como descrito nas Seções 2.3.1
e 4.1. Ao final do processo, a classe candidata Cll (no espaço de caracteŕısticas) que ma-
ximizar as probabilidades para a classe positiva Cl+ será definida como a classe predita
Clp. Ou seja, neste processo de combinação são consideradas apenas as probabilidades
para a classe Cl+, enquanto que a classe Cl− é ignorada.
Destaca-se que, tanto na etapa de seleção quanto na etapa de fusão, os métodos
de seleção dinâmica de classificadores que consideraram as probabilidades dos vizinhos
corretamente classificados e o método KNORA (durante a combinação dos classificadores
selecionados) utilizaram a mesma regra de combinação.
Para analisar a efetividade dos métodos de seleção dinâmica de classificadores, testes
com a combinação de agrupamentos de classificadores também realizados. Nesta avaliação
foram testadas todas as posśıveis combinações dos 10 classificadores, o que eliminou o
estágio de seleção do modelo apresentado no ińıcio deste caṕıtulo. Ou seja, o mesmo
subconjunto de classificadores foi mantido para todos os vetores Zq,j.
4.6 Avaliação de Resultados
Para garantir que a escolha das imagens usadas nos conjuntos de treinamento, validação e
teste não influenciassem as taxas de reconhecimento, cada experimento foi realizado cinco
vezes com diferentes composições para os referidos conjuntos, conforme configurações
apresentadas nas Seções 4.3 e 4.4.
Os indicadores utilizados foram obtidos a partir de matrizes de confusão e curvas
ROC, sendo expressos por meio de taxas médias de reconhecimento (Equação 2.44) e
desvio padrão para avaliar a dispersão entre os resultados de cada execução. Por não ter
sido especificado um ponto de operação, todas as classificações consideraram a definição
da Equação 2.45.
Durante as avaliações dos resultados, considerou-se as afirmações de Barker [4] quanto
à possibilidade de se realizar a avaliação nos diferentes ńıveis definidos pela Botânica. Para
este autor, mesmo especialistas com o domı́nio dos conhecimentos inerentes à Anatomia
da Madeira podem encontrar grande complexidade para realizar a classificação em ńıvel
de espécies, principalmente ao se considerar espécies com caracteŕısticas intermediárias.
Conforme discutido na Seção 2.1.2, tal situação decorre do fato de que os ńıveis supe-
riores da hierarquia agrupam elementos dos ńıveis inferiores com caracteŕısticas comuns.
Assim, à medida em que se move dos ńıveis inferiores para os superiores (espécies para
filos), o número de classes em cada ńıvel diminui. De modo semelhante é esperado que
também diminuam as diferenças internas às classes e aumentem as externas, implicando
numa posśıvel elevação das taxas de reconhecimento nos ńıveis superiores da hierarquia.
As avaliações dos resultados ocorreram nos diferentes ńıveis e para os diferentes agru-
102
pamentos em cada um deles. Cabe ressaltar que, os ńıveis apresentados na Seção 2.1.2
foram definidos para manter uma estrutura única de classificação para todos os elemen-
tos existentes na natureza. Alguns deles não contribuem para a diferenciação de certos
subconjuntos de elementos, ou o fazem de forma muito restrita, conforme ilustrado nas
tabelas do Apêndice A. Consequentemente, os ńıveis filo, famı́lia, gênero e espécie fo-
ram utilizados em razão de suas contribuições para a classificação das espécies florestais
produtoras de madeira, conforme estratégias descritas nas subseções seguintes.
Os modelos constrúıdos neste trabalho diferenciam as classes positiva e negativa no
espaço de dissimilaridade. Entretanto, todos os resultados apresentados consideram a
decisão final do sistema representado na Figura 4.1 que se encontra no espaço de carac-
teŕısticas. Assim, o número de classes ‘reais’ nos ńıveis filo, famı́lia, gênero e espécie são
2, 30, 85 e 112, respectivamente.
4.6.1 Avaliação das taxas de reconhecimento nos diferentes ńıveis
definidos pela Botânica
Esta estratégia considerou o fato de que, dependendo da finalidade para a qual a madeira
é empregada, não há necessidade de certificação em ńıvel de espécie florestal. Assim, erros
de classificação internos a um agrupamento poderiam ser admitidos como acertos, pois
em muitos casos tais confusões não prejudicam as partes envolvidas na negociação e/ou
as caracteŕısticas necessárias ao produto final. Seguindo tal racioćınio e considerando a
relação de espécies das tabelas do Apêndice A, para o gênero Eucalyptus, erros de classi-
ficação entre classes reais e classes preditas que envolvam as espécies Eucalyptus globulus,
Eucalyptus grandis e Eucalyptus saligna poderiam ser contabilizados como acertos.
Nesta estratégia, inicialmente considerou-se a classificação no ńıvel de Espécies Flores-
tais. Neste ńıvel, a base de imagens utilizada compreende um total de 112 classes ‘reais’.
A partir das matrizes de confusão para as 112 espécies florestais, seguindo os agrupa-
mentos ilustrados na Figura 4.7, gerou-se diferentes matrizes de confusão. Tais matrizes
de confusão permitiram a apuração dos resultados nos ńıveis espécie (112×112), gênero
(85×85), famı́lia (30×30) e filo (2×2).
4.6.2 Uso de meta-classes para a abordagem de classificação
hierárquica
Neste conjunto de experimentos, optou-se pelos descritores SURF, SIFT e LPQ devido
a seus expressivos resultados quando comparados aos demais (vide Seção 5.1). Todos os
modelos mencionados nesta seção foram criados para as melhores configurações identifi-
cadas anteriormente nas Seções 4.2 e 4.3. Ao final, os resultados destas avaliações foram
generalizados para os demais descritores.
Esta estratégia focou o uso de subconjuntos menores de caracteŕısticas necessários
103
(a) (b)
(c) (d)
Figura 4.7: Identificação dos agrupamentos (espaços em branco) realizados nas matrizes
de confusão durante o deslocamento entre os ńıveis (a) espécie (112×112), (b) gênero
(85×85), (c) famı́lia (30×30) e (d) filo (2×2).
para alcançar a classificação no ńıvel desejado [27]. Dentre suas vantagens, destaca-se a
redução da sobrecarga acarretada pelo uso de informações desnecessárias nos ńıveis inferi-
ores da hierarquia [27, 49, 55, 140]. Neste sentido, Barker [4] declara que a distinção entre
Dicotiledôneas e Gimnospermas é um dos requisitos elementares para a identificação de
madeira. O autor ainda complementa com a afirmação de que, de forma geral, tal dis-
tinção ocorre facilmente devido às diferenças existentes entre as estruturas especializadas
das primeiras (inexistentes em Gimnospermas) e da organização com sobreposição de li-
nhas de células nos Gimnospermas. Seguindo tal linha de racioćınio, o primeiro conjunto
de avaliações ocorreu para o ńıvel filo. Diferentes espécies florestais, proporcionalmente
distribúıdas entre os filos Angiospermas e Gimnospermas, compuseram os conjuntos de
treinamento e teste. Especificamente neste caso, houveram duas classes tanto no espaço
de dissimilaridade quanto no espaço de caracteŕısticas.
Na sequência, outros dois modelos independentes foram constrúıdos. As mesmas
espécies florestais que compunham os conjuntos de treinamento e teste do experimento
104
anterior foram mantidas. Porém, tais espécies foram redivididas de acordo com o filo a
que pertenciam. Ou seja, do conjunto de treinamento derivou-se dois subconjuntos de
treinamento, um para Angiospermas e outro para Gimnospermas. O mesmo ocorreu para
o conjunto de teste.
Nas duas avaliações anteriores, seguiu-se o mesmo processo definido pela Figura 4.1.
A avaliação das taxas de reconhecimento para os experimentos desta seção considerou
apenas os rótulos das classes preditas, isto é, utilizou-se classificadores abstratos. Assim,
os acertos foram contabilizados apenas quando os classificadores de ambos os ńıveis (filo
e espécie) realizavam as predições corretamente. A partir dos resultados obtidos, esta
estratégia não apresentou contribuições significativas quando comparada com a da seção
anterior, não tendo havido outras tentativas para os ńıveis gênero e famı́lia.
4.7 Considerações Finais
Este caṕıtulo definiu as etapas e as atividades executadas no desenvolvimento deste tra-
balho. Também foram apresentados o modelo de classificação proposto, com ênfase na
extração de caracteŕısticas, na representação no espaço de dissimilaridade e nas estratégias
de classificação, seleção e combinação de classificadores.
Também foram apresentados três novos métodos para seleção dinâmica de classifica-
dores, os quais foram aplicados ao problema de identificação de espécies florestais e al-
cançaram resultados superiores às outras pré-existentes, tal como apresentado no caṕıtulo
seguinte.
CAPÍTULO 5
RESULTADOS
Este caṕıtulo apresenta os resultados obtidos ao final dos experimentos descritos no
caṕıtulo anterior. Inicialmente discute-se os melhores resultados individuais dos clas-
sificadores constrúıdos com as configurações previamente identificadas. Na sequência,
apresenta-se as avaliações do número de espécies florestais, amostras por espécie e re-
ferências por amostra utilizados para a geração dos vetores de dissimilaridade.
Para a seleção dinâmica de classificadores, os métodos apresentados nos Caṕıtulos 2 e
4 foram considerados. Segue-se com uma breve discussão quanto às diferentes regras de
fusão utilizadas neste trabalho, destacando-se a superioridade das taxas de reconhecimento
alcançadas com a aplicação da regra máximo. Por fim, tem-se as taxas de reconhecimento
alcançadas para os ńıveis espécie, gênero, famı́lia e filo, definidos pela Botânica, e as
considerações finais do caṕıtulo.
5.1 Avaliações dos descritores: melhores resultados individuais
A Tabela 5.1 apresenta um resumo com os melhores resultados alcançados pelos classifi-
cadores constrúıdos a partir dos descritores apresentados na Seção 4.2. Além das taxas
médias individuais de acerto, desvio padrão e AUC, são apresentados os valores para o
Oráculo Acumulado médio e seu desvio padrão. O Oráculo indica o limite superior para
as taxas de todo o conjunto de classificadores, pois seu cômputo considera que o melhor
classificador sempre seja selecionado [63]. Para o cálculo do Oráculo Acumulado, iniciou-
se com o SURF e seguiu-se agregando cada um dos demais classificadores, ordenados por
suas taxas de reconhecimento.
Tabela 5.1: Resultados individuais dos classificadores e oráculo acumulado.
Classificador Taxa Individual Oráculo Acumulado
% σ AUC % σ
SURF 89,14 2,39 85,17 89,14 2,39
MSER-SURF 87,80 2,17 82,15 95,77 1,33
SIFT 88,47 1,64 85,44 97,98 0,83
LPQ 86,74 2,07 80,39 98,84 0,52
LPQ-TOP 86,41 1,36 80,51 99,13 0,36
LBPu28,2 66,25 4,67 64,15 99,29 0,32
LBPri8,2 50,74 9,54 49,94 99,43 0,32
GABOR 25,67 2,53 30,05 99,52 0,27
LBPriu28,2 16,49 17,57 17,70 99,52 0,32
GLCM 4,09 1,13 5,26 99,54 0,28
A partir das taxas apresentadas na Tabela 5.1, as medidas de desempenho (taxas
106
médias de reconhecimento e AUC1) definem claramente a formação de três agrupamentos
distintos. Basicamente, o conjunto formado pelos cinco primeiros classificadores quase
permite que se alcance o valor máximo para o ‘Oráculo Acumulado’. O grupo inter-
mediário é formado apenas por LBPu28,2 e LBP
ri
8,2, já apresentando taxas inferiores em
mais de 20 pontos percentuais. Embora as diferenças sejam bastante elevadas, principal-
mente quando se considera o último grupo formado pelos classificadores filtros de Gabor,
LBPriu28,2 e GLCM, a contribuição de todo o conjunto para com os métodos propostos será
demonstrada na Seção 5.3.3.6.
Dada a amplitude de configurações avaliadas para cada um dos 10 descritores, destaca-
se aqui as variações das taxas de reconhecimento alcançadas pelos respectivos classificado-
res constrúıdos. Para a famı́lia LBP, houve vantagem para distância dois, com diferenças
de 2,78 pontos percentuais para LBP u28,2, 6,1 para LBP
ri
8,2 e 1,84 para LBP
riu2
8,2 . Já para
LPQ e LPQ-TOP as taxas de reconhecimento apresentaram diferenças de 7,92 e 7,82
pontos percentuais entre o melhor e o pior resultado, respectivamente.
Embora a mesma configuração tenha gerado os melhores resultados nas implementações
do descritor SIFT disponibilizadas por Lowe [75] e Vedaldi [143], a segunda implementação
garantiu resultados superiores, com 5,25 pontos percentuais de diferença. Para SURF,
apenas para a implementação OpenCV as melhores taxas foram obtidas por uma com-
binação diferente das demais. Contudo, a variação máxima entre as taxas de reconheci-
mento alcançadas pelas diferentes implementações testadas ficou em 1,51 pontos percen-
tuais.
Apenas as implementações disponibilizadas pela ferramenta MatLab [89] foram uti-
lizadas para a combinação MSER-SURF. Destas, a versão original do descritor SURF
obteve taxas de reconhecimento superiores, com diferença de 0,84 pontos percentuais.
Para GLCM, os melhores resultados foram obtidos para a distância d = 6 e os piores para
d = 1, tendo havido variação de 1,46 pontos percentuais entre o melhor e o pior caso.
Destaca-se aqui o fato de que os estudos que empregam imagens macroscópicas têm seus
melhores resultados para d = 1. Por fim, filtros de Gabor apresentou uma variação de
0,39 pontos percentuais entre as melhores e as piores taxas.
Na seção 5.1.1 avalia-se a capacidade de (manutenção da) representação das carac-
teŕısticas texturais considerando diferentes dimensões para recortes das imagens originais
e dos cantos escuros das imagens. Também realizou-se um estudo quanto à efetividade
dos detectores baseados em pontos de atenção, o qual é apresentado na Seção 5.1.2.
1Neste trabalho, as predições das cinco execuções foram reunidas e as curvas ROC e os valores para
AUC foram obtidos uma única vez para todas as rodadas, tal como descrito por Fawcett [31]. Tais valores
são expressos no intervalo [0, 100].
107
5.1.1 Avaliação da influência dos cantos escuros das imagens nas
taxas de reconhecimento
Após a aquisição das imagens utilizando o microscópio Olympus modelo CX40 (Figura
5.1(a)), visualmente percebeu-se algumas influências da iluminação e do formato das
lentes. Estes fatores podem ser melhor percebidos em algumas espécies e geraram um
escurecimento nas extremidades (principalmente nos cantos) das imagens, tal como ilus-
tra a Figura 5.1(b). Assim, avaliou-se uma posśıvel influência destes fatores nas taxas de
reconhecimento. Para isso, utilizou-se o descritor LPQ2 e sua configuração que alcançou
os melhores resultados (Seção 4.2.2). A partir da imagem da Figura 5.1(b), quatro no-
vos experimentos foram realizados seguindo exatamente a mesma metodologia anterior,
exceto pelas dimensões da imagens utilizadas. Para cada experimento, foram eliminadas
faixas das bordas das imagens (Figura 5.1(c)), gerando novas imagens com as dimensões
apresentadas na Tabela 5.2.
(a) (b) (c)
Figura 5.1: Avaliação da influência dos cantos escuros: (a) microscópio Olympus modelo
CX40, (b) imagem original e (c) imagem em escala de cinza com a identificação dos recortes
utilizados.
Tabela 5.2: Dimensões das faixas exclúıdas das imagens originais e dimensões das ima-
gens finais (em pixels) ilustradas na Figura 5.1(c).
Largura da Faixa Dimensões das Imagens
0 1.024×768 (original)
50 974×718
100 924×668
150 874×618
200 824×568
A Tabela 5.3 apresenta as taxas de reconhecimento obtidas nestes experimentos. Fo-
ram identificadas diferenças de apenas 1,04 e 3,01 pontos percentuais nas taxas com
a exclusão de faixas com 50 e 100 pixels, respectivamente, o que representa 11,08% e
2Os descritores baseados em pontos de atenção SURF, MSER-SURF e SIFT ainda não haviam sido
testados no momento em que este conjunto de experimentos foi realizado. Assim, LPQ foi escolhido por
ser o descritor para o qual o classificador constrúıdo apresentava os melhores resultados naquele momento.
108
21,51% das imagens originais. Embora os recortes mencionados tenham sido substanciais
com relação às dimensões da imagem original, a variação dos resultados foi relativamente
pequena.
Ao se considerar a quarta e a quinta linhas da Tabela 5.3, verifica-se diferenças de mais
de 10 e 20 pontos percentuais, respectivamente. No entanto, as faixas exclúıdas nestes
casos representam 31,32% e 40,49% das imagens originais.
Tabela 5.3: Taxas de reconhecimento obtidas para os diferentes recortes das imagens
originais com o descritor LPQ.
Largura da Faixa Dimensões das Imagens % σ AUC
0 1024×768 86,94 2,17 80,39
50 974×718 85,90 2,60 83,11
100 924×668 83,93 2,07 79,69
150 874×618 76,32 2,94 72,93
200 824×568 63,50 3,19 62,41
5.1.2 Avaliação quanto ao uso de pontos fixos para os descritores
baseados em pontos de atenção
Os algoritmos baseados em pontos de atenção dividem o processo em duas etapas, isto é,
detecção de pontos e extração das caracteŕısticas para os pontos detectados. Diante disto,
avaliou-se a efetividade do algoritmo de detecção SURF e a significância dos pontos por
ele identificados.
Os experimentos para os descritores SURF e SURF-128 foram repetidos conside-
rando a implementação disponibilizada pela ferramenta MatLab [89]. Em cada repetição,
empregou-se um conjunto diferente de pontos fixos para todas as imagens, o qual variou
entre 1.000 e 20.000 pontos por imagem. Para cada conjunto, inicialmente definiu-se o
espaçamento entre os pontos a serem utilizados. Para isso, o número total de pixels das
imagens (1024×768 = 786.432) foi dividido pelo número de pontos existentes no conjunto.
Partindo da coordenada (1,1) das imagens e seguindo com o incremento do espaçamento
previamente definido, os pontos foram identificados e as caracteŕısticas foram extráıdas.
Da mesma forma que no experimento original (Seção 4.2.4), utilizou-se os momen-
tos estat́ısticos média, variância, obliquidade e curtose, tendo sido gerados vetores com
dimensões de 64 ou 128 elementos para cada um deles. Também aqui, as diferentes com-
binações entre tais vetores foram testadas, com os descritores finais variando de 64 à
256 elementos para SURF e de 128 à 512 para SURF-128. Por ter sido considerado o
mesmo conjunto de pontos para todas as imagens, a quantidade de pontos detectados
nas imagens (que compunha os vetores de caracteŕısticas nos experimentos originais) foi
descartada nestes experimentos.
As melhores taxas foram obtidas para o conjunto de 15.000 pontos, tanto para a versão
padrão quanto para SURF-128, mais uma vez com vantagens para a segunda. A Tabela 5.4
109
apresenta as taxas de reconhecimento alcançadas pela versão SURF-128. Estas são 0,42
pontos percentuais superiores às apresentadas na Tabela 5.1, quando foi utilizado SURF
para a detecção dos pontos de interesse e também para a extração de suas caracteŕısticas.
Mesmo com esta pequena diferença, avaliou-se a combinação dos resultados de ambas as
abordagens (Tabela 5.5) e também foi identificado um ganho de 1,38 pontos percentuais
com relação às taxas apresentadas na Tabela 5.1.
Tabela 5.4: Resultados obtidos para o conjunto de 15.000 pontos fixos igualmente dis-
tribúıdos pelas imagens com o descritor SURF-128.
Regra de combinação % σ AUC
Média 73,88 3,25 70,65
Máximo 89,56 1,03 86,28
Tabela 5.5: Resultados da combinação das abordagens avaliadas para SURF cujos re-
sultados foram apresentadas nas Tabelas 5.1 e 5.4.
Regra de combinação % σ AUC
Média 82,88 2,32 77,74
Máximo 90,52 1,24 87,97
Mesmo com as diferenças e complementaridades encontradas, foi necessário empregar
15.000 pontos para obter taxas de reconhecimento próximas àquelas alcançadas ao se usar
SURF como detector e descritor dos pontos de interesse. Como apresentado na Tabela
5.6, este número caracteriza quase que o dobro do número máximo de pontos identificados
ao se utilizar SURF como detector. Tal fato conduziu à avaliação dos custos inerentes a
ambos os processos.
Tabela 5.6: Estat́ısticas referentes ao número de pontos detectados pela implementação
do algoritmo SURF disponibilizada pela ferramenta MatLab [89].
# Pontos
Máximo 8.893
Mı́nimo 990
Média 4.805
Desvio Padrão 1.345
Mediana 4.796
Moda 5.143
Embora tenha-se eliminado a etapa de detecção de pontos de interesse nestes ex-
perimentos, a extração de caracteŕısticas pode incorrer em um custo mais elevado pela
necessidade de se utilizar mais pontos por imagem do que a média identificada pelo
próprio SURF. Assim, seguindo as definições anteriores e as da Seção 4.2.8, o custo médio
apenas para a extração das caracteŕısticas dos 15.000 pontos foi de 0, 48 segundos por
imagem, num total de 1.075 segundos para as 2.240 imagens. Pela Tabela 4.1, ao se
utilizar SURF como detector e descritor, o custo total dos passos de detecção e extração
de caracteŕısticas foi inferior, com 0, 38 segundos por imagem, num total de 851 segundos
para as 2.240 imagens.
110
Os valores apresentados no parágrafo anterior confirmaram a efetividade do SURF em
termos de detecção de pontos de interesse. Ao mesmo tempo, ficou claro que o emprego
dos conjuntos de pontos fixos leva à necessidade de um número de pontos por imagem
muito maior do que a média identificada pelo próprio SURF. Portanto, é plauśıvel concluir
pela inviabilidade de se empregar os conjuntos de pontos fixos devido a seu maior custo,
mesmo utilizando apenas a funcionalidade de extração de caracteŕısticas do descritor
SURF.
5.2 Classificação: avaliação dos parâmetros inerentes à repre-
sentação baseada em vetores de dissimilaridade
Conforme descrito na Seção 4.3, nestes experimentos a base de imagens foi dividida em dois
subconjuntos com, respectivamente, 68 e 44 espécies florestais para treinamento e teste.
Após as cinco execuções, a avaliação de diferentes quantidades de amostras por espécie e
referências por amostra utilizadas na geração dos vetores de dissimilaridade para os con-
juntos de treinamento e teste identificou as taxas médias de reconhecimento da Tabela
5.7 como sendo as melhores. Tais taxas foram alcançadas com 12 amostras por espécie
e 11 referências por amostra para gerar o conjunto de treinamento, além de 20 amostras
por espécie com 19 referências cada uma para gerar o conjunto de teste. Uma avaliação
geral de tal influência pode ser realizada por meio da Figura 5.2, na qual se tem variação
das taxas médias alcançadas com os modelos de classificação constrúıdos com 12 amostras
por espécie e 11 referências por amostra com relação às diferentes configurações utiliza-
das para a geração dos conjuntos de teste. Basicamente, tal comportamento também foi
identificado para os demais modelos constrúıdos com diferentes quantidades de amostras
e referências (Seção 4.3), mas com taxas médias de reconhecimento inferiores às apresen-
tadas.
Tabela 5.7: Melhores taxas de reconhecimento obtidas para as variações dos experimen-
tos desta seção.
Regra de combinação % σ AUC
Média 63,83 2,34 59,24
Máximo 86,74 2,07 80,39
A partir dos resultados anteriores, a avaliação da influência do número de espécies
empregadas para gerar o conjunto de treinamento (Figura 5.3) identificou a necessidade
de empregar basicamente todas as classes dispońıveis para maximizar as taxas de reco-
nhecimento. Tais resultados confirmam aqueles apresentados na Tabela 5.7 como sendo
os melhores. Além disso, pela Figura 5.3, também se percebe que o aumento do número
de classes utilizadas para gerar o conjunto de treinamento conduz à redução do valor do
desvio padrão.
Durante a avaliação da robustez dos modelos (Figura 5.4), ao se partir do conjunto
111
Figura 5.2: Avaliação da influência do número de amostras por espécie florestal e re-
ferências por amostra nas taxas de reconhecimento.
Figura 5.3: Avaliação da influência do número de espécies florestais do conjunto de
treinamento nas taxas de reconhecimento.
original de teste com 44 espécies florestais para subconjuntos com apenas nove delas,
as taxas de reconhecimento são elevadas de 86,74% (σ = 2, 07) para 95,44% (σ = 1, 47).
Tais diferenças eram esperadas em decorrência da variação do número de espécies, embora
relatos de trabalhos com dissimilaridade mostrem que estas diferenças são minimizadas à
medida que o número de classes do conjunto de testes assume valores na casa das centenas.
Devido à limitação das espécies florestais dispońıveis, não foi posśıvel avaliar tal
tendência. Contudo, os valores do desvio padrão se mantêm relativamente estáveis no
intervalo σ = [1, 47..3, 14], similares à maior parte dos classificadores apresentados na
Tabela 5.1.
112
Figura 5.4: Avaliação da influência do número de espécies florestais candidatas do con-
junto de teste nas taxas de reconhecimento.
5.3 Seleção e Combinação de Classificadores
Para facilitar a compreensão dos experimentos realizados envolvendo os sistemas formados
por múltiplos classificadores, os estágios de seleção e combinação de classificadores foram
agrupados nesta seção. Assim, nas subseções seguintes são apresentados os resultados
obtidos com a combinação de diferentes subconjuntos dos 10 classificadores utilizados
neste trabalho e pelas técnicas de seleção dinâmica de classificadores descritas nas Seções
2.4.2 e 4.4. Inserida no contexto dos métodos de seleção dinâmica de classificadores, a
Seção 5.3.4 apresenta uma discussão quanto à influência das diferentes regras de fusão
empregadas no decorrer deste trabalho para a combinação das decisões individuais dos
classificadores selecionados para os vetores de dissimilaridade.
5.3.1 Combinação de agrupamentos de classificadores
Estes experimentos consideraram todas as posśıveis combinações entre os 10 classificado-
res avaliados por meio das regras voto majoritário, borda count, soma, média, produto,
máximo, mı́nimo e mediana. Os melhores resultados alcançados para os agrupamentos
com k (k = 1..10) classificadores são apresentados na Tabela 5.8. Embora tenham sido
avaliadas oito diferentes regras de combinação, todos os resultados apresentados foram
obtidos com a regra Máximo.
Diante da amplitude da avaliação realizada, verificou-se uma maior influência dos
classificadores que obtiveram as melhores taxas de reconhecimento. Exceto por filtros de
Gabor, todas as demais inclusões nos conjuntos de classificadores da Tabela 5.8 seguiram
a sequência apresentada na Tabela 5.1.
Conforme afirmado na discussão dos dados da Tabela 5.1, os cinco melhores classi-
113
Tabela 5.8: Resultados da combinação de agrupamentos com k (k = 1..10) classificado-
res, sendo todos alcançados pela regra de combinação máximo.
Agrupamento % σ AUC
(a) 89,14 2,39 85,17
(b) 90,10 1,65 87,26
(c) 90,51 2,38 86,83
(d) 90,57 2,26 86,56
(e) 90,71 2,45 86,62
(f) 90,66 2,44 86,62
(g) 90,61 2,33 86,60
(h) 90,48 2,34 86,58
(i) 81,28 10,42 78,24
(j) 59,37 20,07 57,03
(a) SURF;
(b) SURF e MSER-SURF;
(c) SURF, MSER-SURF e SIFT;
(d) SURF, MSER-SURF, SIFT e LPQ;
(e) SURF, MSER-SURF, SIFT, LPQ e LPQ-TOP;
(f) SURF, MSER-SURF, SIFT, LPQ, LPQ-TOP e Gabor;
(g) SURF, MSER-SURF, SIFT, LPQ, LPQ-TOP, LBPu28,2 e Gabor;
(h) SURF, MSER-SURF, SIFT, LPQ, LPQ-TOP, LBPu28,2, LBP
ri
8,2 e Gabor;
(i) SURF, MSER-SURF, SIFT, LPQ, LPQ-TOP, LBPu28,2, LBP
ri
8,2, LBP
riu2
8,2 e Gabor;
(j) SURF, MSER-SURF, SIFT, LPQ, LPQ-TOP, LBPu28,2, LBP
ri
8,2, LBP
riu2
8,2 , GLCM e Gabor.
ficadores quase permitem que se alcance o valor máximo para o ‘Oráculo Acumulado’ e
aqui compuseram o conjunto de classificadores para o qual se alcançou as melhores taxas.
Combinados, os classificadores SURF, MSER-SURF, SIFT, LPQ e LPQ-TOP alcançaram
90,71% (σ=2,45; AUC=86,62) por meio da regra de combinação máximo, melhorando as
taxas individuais dos classificadores em 1,57 pontos percentuais.
5.3.2 Métodos de seleção dinâmica de classificadores baseados
na distribuição das instâncias no espaço de dissimilaridade
Nesta seção são apresentadas as alternativas avaliadas para a seleção dinâmica de classi-
ficadores tomando como base apenas a distribuição das instâncias no espaço de dissimi-
laridade.
5.3.2.1 Seleção dinâmica de classificadores baseada na distância
entre a instância questionada e os centróides das classes
do conjunto de validação
A partir do método proposto na Seção 4.4.1.1, as melhores taxas de reconhecimento
foram obtidas para Média (61,48%; σ=1,51; AUC=59,20) e Máximo (55,11%; σ=1,43;
AUC=56,91). O mesmo experimento foi repetido considerando apenas a classe positiva
em cada espaço de representação, alcançando taxas similares às anteriores, também com
as regras Média (60,00%; σ=1,75; AUC=58,60) e Máximo (56,48%; σ=1,61; AUC=57,68).
114
Ao se considerar as taxas da Tabela 5.1, tomou-se apenas os sete melhores classifi-
cadores e obteve-se os melhores resultados para Média (69,20%; σ=2,15; AUC=66,01) e
Máximo (76,48%; σ=2,55; AUC=74,85). Já para os cinco melhores classificadores, tem-se
Média (70,23%; σ=1,82; AUC=65,36) e Máximo (79,89%; σ=1,78; AUC=77,59). Em de-
corrência da restrição a classificadores com melhores taxas houve um aumento também nas
taxas decorrentes da seleção de classificadores, mas as taxas ainda são inferiores àquelas
do melhor classificador (SURF).
Tais resultados conduziram à análise de cada espaço de representação e os dados apre-
sentados na Figura 5.5 justificam as baixas taxas deste processo de seleção. Como se pode
perceber, GLCM apresentou menor valor para a distância média entre as instâncias ques-
tionadas Zq,j e os centróides selecionados C, enquanto LBP
riu2
8,2 situa-se no outro extremo
com os maiores valores para a distância média e o desvio padrão. Embora caracterizem os
dois extremos quanto à distância entre as instâncias questionadas e os centróides selecio-
nados e estejam dentre os três piores resultados do conjunto de 10 classificadores, GLCM
e LBP riu28,2 foram os dois mais selecionados (Tabela 5.9). Mesmo com a maior distância
média para LBP riu28,2 , o alto valor para o desvio padrão o levou a ser o segundo com maior
número de seleções.
Figura 5.5: Distância média e desvio padrão entre as instâncias questionadas Zq,j e os
centróides (C+ ou C−) das classes selecionadas nos diferentes espaços de representação.
A Figura 5.6, com maiores detalhes nas Tabelas 5.10 e 5.11, confirma a inviabilidade
quanto ao uso da distância entre a instância questionada e os centróides das classes no
conjunto de validação. As instâncias questionadas estão mais próximas dos centros das
classes selecionadas (corretas ou incorretas) do que daquelas que indicariam a solução
ótima (‘Corretos’), isto é, com a predição correta e d(Zq,j, C) mı́nima.
Tomando ainda a Figura 5.6, ao se considerar apenas os classificadores ‘Selecionados’,
dividiu-se suas instâncias em dois grupos. O grupo ‘Acertos’ compreende as instâncias
115
Tabela 5.9: Taxa de seleção dos classificadores para os diferentes subconjuntos consi-
derados nos experimentos com seleção dinâmica de classificadores baseada nas distâncias
d(Zq,j, C).
# Classificadores
Classificador 10 7 5
selecionado % σ % σ % σ
LPQ 5,11 0,55 14,72 1,18 22,18 3,39
SIFT 1,45 0,36 7,77 0,81 10,93 0,92
SURF 1,80 0,32 12,04 1,00 19,23 0,97
MSER-SURF 2,25 0,41 9,89 0,67 14,91 1,43
LPQ-TOP 6,93 0,92 22,94 4,59 32,76 2,45
LBPu28,2 0,80 0,02 5,17 0,34 - -
LBPri8,2 7,61 0,77 27,47 3,67 - -
LBPriu28,2 15,46 1,32 - - - -
GLCM 50,22 7,44 - - - -
Gabor 8,38 1,01 - - - -
para as quais os classificadores selecionados acertaram a predição, enquanto ‘Erros’ com-
preende o conjunto de instâncias incorretamente classificadas. As predições corretas
(‘Acertos’) caracterizam-se por ter suas instâncias questionadas mais distantes das classes
para as quais foram preditas do que as incorretas (‘Erros’).
Figura 5.6: Distância média e desvio padrão entre as instâncias questionadas e os
centróides das classes selecionadas, considerando todos os espaços de representação.
5.3.2.2 Seleção dinâmica de classificadores baseada na distância
entre a instância questionada e as fronteiras dos modelos
de classificação
Seguindo os procedimentos descritos na Seção 4.4.1.2, alcançou-se as melhores taxas de
reconhecimento para Média (61,25%; σ=1,49; AUC=59,58) e Máximo (60,57%; σ=1,89;
116
Tabela 5.10: Estat́ısticas das distâncias entre as instâncias questionadas Zq,j correta-
mente classificadas e os centróides (C+ ou C−) das classes selecionadas nos diferentes
espaços de representação.
Classificador Mı́nimo Máximo Média Mediana D. Padrão
LPQ 0,07012 0,63622 0,21236 0,19996 0,07463
SIFT 0,07438 0,66885 0,23770 0,22914 0,06412
SURF 0,08015 0,82974 0,23025 0,21728 0,07309
MSER-SURF 0,06855 0,78291 0,23011 0,21415 0,07967
LPQ-TOP 0,07091 0,55565 0,20412 0,19277 0,06686
LBPu28,2 0,06258 0,92920 0,25520 0,23586 0,09665
LBPri8,2 0,03585 1,46755 0,25124 0,20166 0,15376
LBPriu28,2 0,01703 1,52734 0,25724 0,19192 0,17557
GLCM 0,02409 1,73905 0,17559 0,14880 0,11435
Gabor 0,06444 1,28513 0,23958 0,20982 0,11280
Tabela 5.11: Estat́ısticas das distâncias entre as instâncias questionadas Zq,j incorre-
tamente classificadas e os centróides (C+ ou C−) das classes selecionadas nos diferentes
espaços de representação.
Classificador Mı́nimo Máximo Média Mediana D. Padrão
LPQ 0,07147 0,61283 0,12506 0,11342 0,04301
SIFT 0,07759 0,39408 0,15740 0,15158 0,04019
SURF 0,08564 0,68014 0,15907 0,14673 0,04941
MSER-SURF 0,07326 0,55333 0,14357 0,13423 0,04530
LPQ-TOP 0,06794 0,53050 0,11867 0,10787 0,03891
LBPu28,2 0,07291 0,65413 0,15994 0,14705 0,04904
LBPri8,2 0,03826 0,82684 0,14926 0,13324 0,06182
LBPriu28,2 0,01812 0,99306 0,14657 0,13030 0,08080
GLCM 0,02489 1,67183 0,11325 0,09986 0,05496
Gabor 0,05991 0,68235 0,14063 0,12813 0,04899
AUC=57,44). Como antes, analisou-se cada espaço de representação na tentativa de jus-
tificar as baixas taxas. Os dados apresentados na Figura 5.7 nos auxiliam neste processo.
LBP riu28,2 apresentou maior valor para a distância média entre as instâncias questionadas
e as fronteiras dos modelos de classificação, além de também ter apresentado maior va-
riação (desvio padrão), enquanto GLCM situa-se no outro extremo com distância média
e desvio padrão muito baixos. Embora LBP riu28,2 e GLCM caracterizem os dois extremos
quanto à distância entre a instância questionada e a fronteira e também quanto à quanti-
dade de vezes em que foram selecionados (Tabela 5.12), ambos estão dentre os três piores
desempenhos no conjunto de 10 classificadores.
A partir dos resultados apresentados para esta estratégia, identificou-se taxas de re-
conhecimento inferiores à maioria dos classificadores individualmente. Considerando as
taxas da Tabela 5.1, ao se tomar os sete melhores classificadores, alcançou-se os melho-
res resultados para Média (78,41%; σ=2,09; AUC=71,89) e Máximo (90,23%; σ=1,91;
AUC=85,48). Também para os cinco melhores classificadores, obteve-se Média (80,91%;
σ=1,61; AUC=72,86) e Máximo (91,36%; σ=2,61; AUC=85,91). Somente com a exclusão
dos três piores classificadores do conjunto alcançou-se resultados similares àqueles obti-
dos com a combinação do melhor subconjunto de classificadores (Seção 5.3.1), mas ainda
117
Figura 5.7: Distância média e desvio padrão entre as instâncias questionadas Zq,j e as
fronteiras dos modelos f nos diferentes espaços de representação.
Tabela 5.12: Taxa de seleção de cada classificador para os diferentes subconjuntos consi-
derados nos experimentos com seleção dinâmica de classificadores baseada nas distâncias
d(Zq,j, f).
# Classificadores
Classificador 10 7 5
selecionado % σ % σ % σ
LPQ 2,83 0,21 12,54 2,47 14,62 1,29
SIFT 1,07 0,01 7,11 0,99 8,41 0,73
SURF 1,31 0,02 11,85 2,19 13,20 1,88
MSER-SURF 5,28 0,26 31,23 4,96 34,17 5,01
LPQ-TOP 5,55 0,81 26,83 2,75 29,60 3,97
LBPu28,2 0,64 0,01 4,05 0,67 - -
LBPri8,2 0,87 0,01 6,40 0,56 - -
LBPriu28,2 81,31 7,98 - - - -
GLCM 0,00 0,00 - - - -
Gabor 1,13 0,03 - - - -
cerca de 0,5 pontos percentuais abaixo. Ainda nesta linha de racioćınio, a utilização de
apenas os cinco melhores classificadores nesta estratégia conduziu a taxas cerca de 0,6
pontos percentuais acima daqueles obtidos com a combinação do melhor subconjunto de
classificadores e 2,22 pontos percentuais melhores que SURF individualmente.
A Figura 5.8, com maiores detalhes nas Tabelas 5.13 e 5.14, confirma a inviabilidade
quanto ao uso de d(Zq,j, f). Como se pode perceber, numa escala de 10
−4, basicamente
não há diferenças quanto à distância média e o desvio padrão entre os classificadores es-
colhidos durante o processo de classificação (‘Selecionados’) e aqueles que indicariam a
solução ótima (‘Corretos’). Neste caso, a ‘solução ótima’ é definida pela seleção do classi-
ficador que maximize a distância d(Zq,j, f) e que tenha sua predição correta. Além disto,
mais um indicativo quanto à inviabilidade foi identificado ao se tomar apenas o conjunto
de classificadores ‘Selecionados’ e dividir suas instâncias em dois grupos. O grupo ‘Acer-
118
tos’ compreende as instâncias para as quais os classificadores selecionados acertaram a
predição, enquanto ‘Erros’ compreende o conjunto de instâncias incorretamente classifi-
cadas. Novamente não houve variação significativa na distância média e desvio padrão
para uma escala de 10−4.
Figura 5.8: Distância média e desvio padrão entre as instâncias questionadas Zq,j e as
fronteiras dos modelos f , considerando todos os espaços de representação.
Tabela 5.13: Estat́ısticas das distâncias entre as instâncias questionadas Zq,j correta-
mente classificadas e as fronteiras f nos diferentes espaços de representação.
Classificador Mı́nimo Máximo Média Mediana D. Padrão
LPQ 0,00002 6,09867 1,50255 1,41439 0,71811
SIFT 0,00001 4,39536 1,20742 1,19692 0,59840
SURF 0,00001 4,38717 1,31711 1,27144 0,69246
MSER-SURF 0,00001 5,90550 1,72261 1,64491 0,82044
LPQ-TOP 0,00001 5,70286 1,73352 1,67729 0,81411
LBPu28,2 0,00004 4,25985 1,06105 1,04088 0,52368
LBPri8,2 0,00000 4,64067 1,17416 1,21231 0,51938
LBPriu28,2 0,00003 16,38230 4,95869 4,91049 2,50267
GLCM 0,00000 0,06663 0,00404 0,00223 0,00592
Gabor 0,00001 4,87142 0,98909 0,91171 0,65791
Os valores expressos nesta tabela devem ser multiplicados por 10−4.
5.3.2.3 Seleção dinâmica de classificadores baseada na dispersão
das referências dos conjuntos de validação
Seguindo os procedimentos descritos na Seção 4.4.1.3, as melhores taxas de reconheci-
mento foram obtidas por meio das regras de fusão Média (48,30%; σ=1,02; AUC=50,13)
e Máximo (34,66%; σ=1,53; AUC=34,52). Ao se considerar as taxas da Tabela 5.1 e
os sete melhores classificadores, alcançou-se os melhores resultados para Média (65,23%;
σ=1,68; AUC=62,57) e Máximo (85,57%; σ=1,75; AUC=79,57). Novamente, para os
119
Tabela 5.14: Estat́ısticas das distâncias entre as instâncias questionadas Zq,j incorreta-
mente classificadas e as fronteiras f nos diferentes espaços de representação.
Classificador Mı́nimo Máximo Média Mediana D. Padrão
LPQ 0,00017 4,79930 0,95010 0,76593 0,71588
SIFT 0,00039 3,06219 0,56990 0,45948 0,41903
SURF 0,00007 2,75995 0,56357 0,46456 0,38150
MSER-SURF 0,00009 4,35424 0,90272 0,74506 0,63665
LPQ-TOP 0,00011 4,78654 0,99228 0,80595 0,73497
LBPu28,2 0,00023 3,65285 0,68374 0,55833 0,50295
LBPri8,2 0,00037 3,71405 0,77682 0,64413 0,56101
LBPriu28,2 0,00522 12,43300 3,27257 3,02212 1,92326
GLCM 0,00000 0,06142 0,00056 0,00038 0,00123
Gabor 0,00021 2,83577 0,62318 0,55132 0,38151
Os valores expressos nesta tabela devem ser multiplicados por 10−4.
cinco melhores classificadores, identificou-se as regras de fusão Média (67,16%; σ=1,19;
AUC=64,52) e Máximo (88,52%; σ=2,23; AUC=83,87) com as melhores taxas. Em de-
corrência da restrição a classificadores com melhores taxas houve um aumento também
nas taxas decorrentes da seleção de classificadores, mas as taxas são inferiores àquelas do
melhor classificador (SURF). Tais resultados podem ser melhor compreendidos com as
ilustrações das Figuras 5.9 e 5.10. As menores dispersões médias foram obtidas para o
pior classificador em termos de resultados individuais (Tabela 5.1), o que gerou as taxas
de seleção de classificadores da Tabela 5.15.
Figura 5.9: Dispersão média das referências Zu,v e desvio padrão nos diferentes espaços
de representação.
A Figura 5.10, com maiores detalhes nas Tabelas 5.16 e 5.17, confirma a inviabilidade
quanto ao uso da dispersão das referências como critério de seleção. Como se pode per-
ceber, basicamente não há diferenças quanto à dispersão média e o desvio padrão entre
os classificadores escolhidos durante o processo de classificação (‘Selecionados’) e aqueles
que indicariam a solução ótima (‘Corretos’). Neste caso, a ‘solução ótima’ é definida pela
120
Tabela 5.15: Taxa de seleção de cada classificador para os diferentes subconjuntos con-
siderados nos experimentos com seleção dinâmica de classificadores baseada na dispersão
das referências Zu,v.
# Classificadores
Classificador 10 7 5
selecionado % σ % σ % σ
LPQ 6,83 0,93 13,65 1,54 15,88 1,42
SIFT 0,00 0,00 6,94 1,11 9,17 0,91
SURF 2,27 0,31 11,37 1,85 13,64 0,92
MSER-SURF 2,27 0,19 6,79 0,63 9,07 1,07
LPQ-TOP 29,53 2,69 47,70 6,87 52,24 9,60
LBPu28,2 0,00 0,00 0,00 0,00 - -
LBPri8,2 6,82 1,01 13,55 2,04 - -
LBPriu28,2 0,00 0,00 - - - -
GLCM 50,00 8,77 - - - -
Gabor 2,27 0,13 - - - -
seleção do classificador que minimize a dispersão das referências e que tenha sua predição
correta. Além disto, mais um indicativo quanto à inviabilidade foi identificado ao se to-
mar apenas o conjunto de classificadores ‘Selecionados’ e dividir suas instâncias em dois
grupos. O grupo ‘Acertos’ compreende as instâncias para as quais os classificadores se-
lecionados acertaram a predição, enquanto ‘Erros’ compreende o conjunto de instâncias
incorretamente classificadas. Novamente não houve variação significativa na dispersão
média e desvio padrão.
Figura 5.10: Dispersão média e desvio padrão das referências considerando todos os
espaços de representação.
121
Tabela 5.16: Estat́ısticas das dispersões das referências Zu,v nos diferentes espaços de
representação para os classificadores corretamente selecionados.
Classificador Mı́nimo Máximo Média Mediana D. Padrão
LPQ 0,05225 0,31955 0,11842 0,10881 0,05577
SIFT 0,06159 0,23252 0,12546 0,12856 0,03627
SURF 0,07062 0,27054 0,13030 0,11944 0,04471
MSER-SURF 0,06190 0,26664 0,12676 0,12170 0,04570
LPQ-TOP 0,05581 0,25829 0,10781 0,09873 0,04736
LBPu28,2 0,08057 0,30613 0,16985 0,16554 0,05283
LBPri8,2 0,05487 0,37043 0,16822 0,16204 0,05788
LBPriu28,2 0,05868 0,40913 0,17936 0,17442 0,06430
GLCM 0,02511 0,39542 0,09823 0,09151 0,05394
Gabor 0,06860 0,29850 0,13863 0,12341 0,04620
Tabela 5.17: Estat́ısticas das dispersões das referências Zu,v nos diferentes espaços de
representação para os classificadores incorretamente selecionados.
Classificador Mı́nimo Máximo Média Mediana D. Padrão
LPQ 0,05269 0,31955 0,09890 0,09033 0,03962
SIFT 0,06360 0,23252 0,12167 0,11637 0,03457
SURF 0,07068 0,27083 0,12238 0,11363 0,03970
MSER-SURF 0,06190 0,27119 0,11492 0,10676 0,04061
LPQ-TOP 0,05581 0,25829 0,08905 0,07536 0,03350
LBPu28,2 0,08228 0,30613 0,16184 0,15880 0,04818
LBPri8,2 0,05765 0,37043 0,16837 0,15649 0,05632
LBPriu28,2 0,05918 0,40913 0,18237 0,16195 0,06392
GLCM 0,02779 0,39542 0,08902 0,08094 0,04308
Gabor 0,06930 0,29850 0,12688 0,11584 0,04241
5.3.3 Métodos de seleção dinâmica de classificadores baseados
nas decisões para as vizinhanças das instâncias questiona-
das
Nesta seção são apresentados os resultados das alternativas avaliadas para a seleção
dinâmica de classificadores baseadas na distribuição das amostras no espaço de dissi-
milidade e nas decisões tomadas para a vizinhança (em uma base de validação) das
amostras questionadas. Embora os tamanhos das vizinhanças variem de acordo com os
critérios (OLA ou LCA) e classificadores utilizados, nas seções seguintes a representação
nos gráficos está limitada a 75 vizinhos, o que não prejudica a identificação de comporta-
mentos e tendências inerentes a cada método de seleção.
5.3.3.1 Avaliação dos métodos OLA e LCA
Este conjunto de experimentos avaliou os métodos propostos por Woods et al. [146] para
a seleção dinâmica de classificadores. Como se pode perceber (Figura 5.11), os métodos
OLA e LCA alcançaram resultados similares para todos os tamanhos de vizinhança avali-
ados. Apesar de tal similaridade em termos de taxas de reconhecimento, em geral, houve
pequena vantagem para o método OLA, o que contraria as referências encontradas na
122
literatura que indicam superioridade do critério LCA sobre o OLA.
Os melhores resultados obtidos com LCA foram 84,86% (σ=2,56; AUC=79,91; k=1)
e 69,41% (σ=2,06; AUC=65,91; k=45) para as regras de fusão máximo e média, res-
pectivamente. Além do melhor desempenho geral, OLA também alcançou taxas de re-
conhecimento superiores, com 86,19% (σ=1,76; AUC=83,06; k=300) e 71,58% (σ=2,40;
AUC=68,02; k=30) para as regras de fusão máximo e média, respectivamente.
Considerando os resultados com a aplicação da regra de fusão máximo e as vizinhanças
identificadas anteriormente, a Figura 5.12 apresenta os gráficos ROC para as configurações
em que os dois métodos alcançaram suas melhores taxas de reconhecimento. Neste caso,
identificou-se a superioridade do critério OLA sobre o LCA.
Figura 5.11: Taxas de reconhecimento alcançadas pelos métodos OLA e LCA para a
regra de fusão máximo e as vizinhanças entre um e 75 elementos.
5.3.3.2 Avaliação dos métodos a priori e a posteriori
Nesta seção são apresentados os resultados obtidos pelos métodos propostos por Giacinto
e Roli [35]. Como se pode concluir ao analisar as Figuras 5.11 e 5.13, estes métodos
obtiveram resultados superiores àqueles alcançados por OLA e LCA. Contrariando os
comportamentos dos métodos OLA e LCA, ao se considerar a Figura 5.13, constata-
se que a posteriori possui taxas de reconhecimento superiores que a priori para todos os
tamanhos de vizinhança avaliados, inclusive com maior estabilidade das taxas com relação
à variação do tamanho da vizinhança.
Os melhores resultados obtidos com o método a priori foram 90,28% (σ=1,69; AUC=86,24;
k=15) e 79,25% (σ=1,61; AUC=74,25; k=1) para as regras de fusão máximo e média, res-
pectivamente. Por sua vez, o método a posteriori atingiu 92,86% (σ=2,29; AUC=89,61;
k=8) e 87,78% (σ=2,18; AUC=81,24; k=135), também para as mesmas regras de fusão.
123
Figura 5.12: Gráfico ROC para as vizinhanças com os melhores resultados para os
métodos OLA e LCA e regra de fusão máximo.
Considerando os resultados com a aplicação da regra de fusão máximo e as vizinhanças
identificadas anteriormente, a Figura 5.14 apresenta os gráficos ROC para os melhores
resultados dos métodos a priori e a posteriori. Também neste caso, identificou-se a
superioridade do critério LCA sobre o OLA.
Figura 5.13: Taxas de reconhecimento alcançadas pelos métodos a priori e a posteriori
para a regra de fusão máximo e as vizinhanças entre um e 75 elementos.
124
Figura 5.14: Gráfico ROC para as vizinhanças com os melhores resultados para os
métodos a priori e a posteriori e regra de fusão máximo.
5.3.3.3 Avaliação dos métodos baseados no comportamento de
múltiplos classificadores
Proposto por Giacinto e Roli [36], MCB OLA alcançou taxas de reconhecimento de 84,36%
(σ=2,52; AUC=80,09; k=4) e 75,21% (σ=3,36; AUC=70,32; k=4) para as regras de
fusão máximo e média, respectivamente. O primeiro método proposto neste trabalho e
denominado MCB LCA atingiu taxas de reconhecimento de 86,27% (σ=1,77; AUC=81,75;
k=135) e 78,17% (σ=1,38; AUC=72,50; k=135) para as regras de fusão máximo e média,
respectivamente.
A Figura 5.15 confirma a superioridade identificada no parágrafo anterior do critério
LCA sobre o OLA, a qual ocorreu para todos os tamanhos de vizinhança avaliados, vali-
dando a hipótese inicial apresentada na Seção 4.4.2. Assim, o método proposto restringiu a
vizinhança por meio do critério LCA e apresentou taxas com comportamentos e tendências
mais estáveis diante da variação dos tamanhos das vizinhanças.
Considerando os resultados com a aplicação da regra de fusão máximo e as vizinhanças
identificadas anteriormente, a Figura 5.16 apresenta os gráficos ROC para os melhores re-
sultados dos métodos MCB OLA e MCB LCA. Mais uma vez constatou-se a superioridade
do critério LCA sobre o OLA, validando a hipótese inicial (vide Seção 4.4.2).
5.3.3.4 Avaliação dos métodos MCB a priori e MCB a poste-
riori
Os métodos MCB a priori e MCB a posteriori também foram propostos neste trabalho.
Para o primeiro atingiu-se taxas de reconhecimento de 86,78% (σ=2,09; AUC=80,40;
125
Figura 5.15: Taxas de reconhecimento alcançadas pelos métodos MCB OLA e MCB
LCA para a regra de fusão máximo e as vizinhanças entre um e 75 elementos.
Figura 5.16: Gráfico ROC para as vizinhanças com os melhores resultados para os
métodos MCB OLA e MCB LCA e regra de fusão máximo.
k=180) e 83,45% (σ=1,20; AUC=77,27; k=120) para as regras de fusão máximo e média,
respectivamente. Por meio das mesmas regras de fusão, o método MCB a posteriori
atingiu 93,03% (σ=1,36; AUC=89,37; k=8) e 90,00% (σ=1,30; AUC=83,39; k=75), res-
pectivamente.
As Figuras 5.17 e 5.18 ilustram a superioridade do critério LCA sobre o OLA para
todos os tamanhos de vizinhança avaliados. Além disso, ao se comparar as Figuras 5.13
e 5.17, facilmente se percebe que o método MCB a priori é mais estável que o método a
priori, enquanto os métodos a posteriori e MCB a posteriori possuem resultados muito
similares, validando a hipótese inicial (vide Seção 4.4.2).
126
Considerando os resultados com a aplicação da regra de fusão máximo e as vizinhanças
identificadas anteriormente, a Figura 5.18 apresenta os gráficos ROC para os melhores
resultados dos métodos MCB a priori e MCB a posteriori.
Figura 5.17: Taxas de reconhecimento alcançadas pelos métodos MCB a priori e MCB
a posteriori para a regra de fusão máximo e as vizinhanças entre um e 75 elementos.
Figura 5.18: Gráfico ROC para as vizinhanças com os melhores resultados para os
métodos MCB a priori e MCB a posteriori e regra de fusão máximo.
5.3.3.5 Avaliação dos métodos KNORA-E e KNORA-U
Nesta seção são apresentados os resultados obtidos pelos métodos propostos por Ko et al.
[64, 65]. KNORA-E alcançou taxas de reconhecimento de 88,30% (σ=3,73; AUC=84,70;
k=30) e 87,82% (σ=1,66; AUC=80,64; k=1) para as regras de fusão máximo e média,
127
respectivamente. Por meio das mesmas regras, o método KNORA-U atingiu, respecti-
vamente, taxas de 64,49% (σ=17,73; AUC=61,74; k=1) e 88,38% (σ=1,69; AUC=80,95;
k=90).
Cabe salientar que Ko et al. [64, 65] definiu que na versão KNORA-U, cada classi-
ficador Ci terá direito a um voto para cada vizinho rj por ele corretamente classificado
dentre os k vizinhos mais próximos (no conjunto de validação) à amostra questionada. Ou
seja, a precisão de Ci no conjunto de validação é utilizada como peso durante a fusão dos
classificadores dispońıveis e o número final de votos será definido pela soma do número
de vizinhos corretamente preditos pelos classificadores Ci.
Devido ao uso de um conjunto mais amplo de regras de fusão, para cada amostra
questionada, a predição de Ci foi repetida para cada vizinho rj corretamente classificado
por Ci na vizinhança da amostra questionada. Assim, manteve-se a definição de que a
precisão de Ci no conjunto de validação deva ser utilizada como peso durante a fusão dos
classificadores na versão KNORA-U.
Pela Figura 5.19, confirma-se a superioridade identificada anteriormente para a com-
binação da versão KNORA-U e a regra de fusão média para todos os tamanhos de vizi-
nhança avaliados. Diante de tais resultados, tem-se que tal combinação permite que os
classificadores menos precisos também sejam utilizados, mas impõe a combinação dos clas-
sificadores com a aplicação de pesos inerentes ao número de seus acertos na vizinhança do
conjunto de validação. Assim, amplia-se a possibilidade de se ter classificadores com maior
ńıvel de complementaridade enquanto restringe-se a influência dos piores classificadores
por meio dos referidos pesos.
Já para a regra máximo, a versão KNORA-U apresentou as piores taxas de reco-
nhecimento. Isso é consequência da incorporação dos classificadores menos precisos ao
conjunto considerado. Tais classificadores podem gerar probabilidades superiores àqueles
que apresentam as melhores taxas de reconhecimento e a regra máximo não é influenciada
pelo número dos acertos dos classificadores no conjunto de validação como as demais.
Por restringir o conjunto de classificadores àqueles com melhores resultados na vi-
zinhança da amostra questionada no conjunto de validação, a versão KNORA-E gerou
melhores taxas de reconhecimento quando combinada com a regra máximo. Neste ponto,
destaca-se os gráficos ROC na Figura 5.20 para os melhores resultados dos métodos
KNORA-E e KNORA-U, respectivamente, para as regras máximo e média. Neste caso,
constatou-se a superioridade do método KNORA-E sobre o KNORA-U ao se considerar
os gráficos ROC e o valor para a AUC.
A Tabela 5.18 nos auxilia na compreensão dos resultados previamente apresentados
por meio da taxa de seleção de cada um dos classificadores utilizados. Especificamente
para estes métodos, a soma das taxas de seleção dos classificadores ultrapassa o valor
de 100%. Isso decorre do fato de que as versões KNORA-E e KNORA-U selecionam
pelo menos um classificador para cada amostra questionada, podendo inclusive selecionar
todos os classificadores dispońıveis.
128
Figura 5.19: Taxas de reconhecimento alcançadas pelos métodos KNORA-E e KNORA-
U para as regras de fusão máximo e média e as vizinhanças entre um e 75 elementos.
Figura 5.20: Gráfico ROC para as vizinhanças com os melhores resultados para os
métodos KNORA-E e KNORA-U e as regras de fusão máximo e média, respectivamente.
Como demonstrado na Tabela 5.18, há uma alta dependência dos melhores classificado-
res. Embora isso também ocorra para os demais métodos de seleção (vide seção seguinte),
as versões do KNORA são ainda prejudicadas por combinarem os classificadores selecio-
nados, dentre os quais muitas vezes estão aqueles com baixas taxas de reconhecimento.
Para a versão KNORA-U, exceto para as vizinhanças com quantidades de vizinhos
muito reduzidas, todos os classificadores foram utilizados para cada uma das amostras
questionadas. Embora na versão KNORA-U as taxas de seleção de todos os classificadores
indiquem 100% para a maioria das vizinhanças avaliadas, ao se tomar os dados da Tabela
5.18, tem-se a dimensão efetiva da importância de cada um dos classificadores na fase
129
Tabela 5.18: Taxas de seleção dos classificadores para o método KNORA-E, conside-
rando os 30 e os 90 vizinhos dos conjuntos de validação mais próximos às instâncias
questionadas.
# Vizinhos
Classificador 30 90
selecionado % σ % σ
LPQ 15,28 3,88 11,99 9,65
SIFT 26,97 6,91 25,59 8,89
SURF 26,21 10,91 24,77 14,38
MSER-SURF 24,96 8,19 23,68 10,49
LPQ-TOP 27,44 7,23 22,10 10,39
LBPu28,2 6,30 2,50 1,60 0,93
LBPri8,2 13,24 6,95 7,06 8,35
LBPriu28,2 4,74 2,28 1,28 0,78
GLCM 5,80 2,43 1,54 1,38
Gabor 3,85 2,10 0,51 0,80
final de combinação definida por este método.
5.3.3.6 Avaliação geral dos métodos para seleção dinâmica de
classificadores baseada nas decisões para as vizinhanças
das instâncias questionadas
A Tabela 5.19 apresenta a caracterização dos métodos de seleção dinâmica de classifica-
dores apresentados nas Seções 2.4.2.1 e 4.4.2 seguindo os critérios quanto a definição da
vizinhança, delimitação da vizinhança e seleção do classificador. A definição da vizinhança
considera o uso de distância Euclidiana entre duas amostras ou o ı́ndice de similaridade
entre suas assinaturas MCB como definido por Giacinto e Roli [36]. A delimitação da
vizinhança, por sua vez, considera os critérios OLA e LCA definidos por Woods et al.
[146]. Para o terceiro critério, as possibilidades compreendem a maximização das taxas
de acerto no conjunto de validação proposta por Woods et al. [146] e a aplicação das
regras de combinação às predições corretas de classificadores probabiĺısticos no conjunto
de validação proposta por Giacinto e Roli [35].
Tabela 5.19: Caracterização dos métodos segundo os critérios: (a) definição da vizi-
nhança, (b) delimitação da vizinhança e (c) seleção do classificador.
Seleção do classificador
Definição da Delimitação da Taxas de acerto Probabilidades
vizinhança vizinhança Método % Método %
OLA OLA 86,19 a priori 90,28
Distância KNORA-E 88,30
Euclidiana KNORA-U 88,38
LCA LCA 84,86 a posteriori 92,86
Similaridade das OLA MCB OLA 84,36 MCB a priori 86,78
assinaturas MCB LCA MCB LCA 86,27 MCB a posteriori 93,03
De forma geral, os métodos baseados no critério LCA alcançaram resultados superio-
130
res àqueles baseados no critério OLA, com exceção dos próprios métodos OLA e LCA. Da
mesma forma, os métodos que aplicam as regras de combinação às predições corretas de
classificadores probabiĺısticos no conjunto de validação foram superiores aos que selecio-
nam os classificadores que maximizam as taxas de acerto no conjunto de validação. Estes
resultados confirmam as referências encontradas na literatura e validam as hipóteses iden-
tificadas na Seção 4.4.2 para a proposição dos métodos MCB LCA, MCB a priori e MCB
a posteriori. Com exceção do método MCB a priori, quando comparado com o a priori,
todos os métodos propostos obtiveram taxas de reconhecimento superiores aos demais
métodos que assumem as mesmas condições para cada um dos três critérios previamente
identificados.
Dado o melhor desempenho geral dos métodos de seleção dinâmica de classificado-
res baseados no critério LCA, estes são analisados na sequência. As Figuras 5.21 e 5.22
mostram que os métodos baseados no conceito MCB alcançaram taxas similares ou supe-
riores àqueles baseados somente na performance de um único classificador para realizar a
seleção. Esta diferença aumenta se tomarmos apenas os critérios baseados na porcentagem
de vizinhos corretamente classificados no conjunto de validação. De forma contrária, ao se
considerar os métodos baseados em estimativas de probabilidades a posteriori, verifica-se
a equivalência entre os métodos a posteriori e MCB a posteriori, com vantagem para o
segundo na maior parte dos tamanhos de vizinhança avaliados.
Figura 5.21: Taxas de reconhecimento alcançadas pelo métodos baseados no critério
LCA para a delimitação da vizinhança da instância questionada, a regra de fusão máximo
e as vizinhanças entre um e 75 elementos.
A Tabela 5.20 apresenta uma análise da frequência de seleção dos classificadores e o
desvio padrão para cada um dos métodos de seleção dinâmica após a realização das cinco
execuções. Primeiramente, identifica-se que os cinco melhores classificadores em termos
de performance foram selecionados entre 96,66% e 99,90% das vezes. Tal comportamento
demonstra que todos os métodos são dependentes dos melhores classificadores.
131
Figura 5.22: Gráfico ROC para as vizinhanças com os melhores resultados para os
métodos baseados no critério LCA para a delimitação da vizinhança da instância questi-
onada e a regra de fusão máximo.
Tomando as taxas individuais de seleção dos classificadores, os métodos LCA, MCB
LCA e MCB a posteriori apresentaram comportamentos semelhantes, principalmente ao
se considerar LPQ, SIFT e SURF. Destaca-se o fato destes terem apontado o classificador
LPQ como o melhor a ser escolhido em cerca de 80% dos casos. Por fim, o método a poste-
riori apresentou menor concentração das seleções dentre os cinco melhores classificadores
quando comparados aos demais métodos.
Tabela 5.20: Taxas de seleção dos classificadores para cada um dos métodos baseados
no critério LCA para a delimitação da vizinhança de sq.
Métodos de seleção dinâmica
Classificador A B C D
selecionado % σ % σ % σ % σ
LPQ 84,12 3,10 53,95 9,31 78,44 7,95 83,37 4,44
SIFT 12,65 2,15 25,79 4,04 12,55 7,02 12,33 4,37
SURF 2,27 0,52 14,56 7,01 3,74 1,12 2,10 0,26
MSER-SURF 0,67 0,35 2,93 0,77 1,11 0,51 1,07 0,44
LPQ-TOP 0,18 0,11 1,66 0,52 0,82 0,50 0,63 0,18
LBPu28,2 0,07 0,04 0,24 0,11 0,16 0,12 0,11 0,13
LBPri8,2 0,02 0,01 0,18 0,14 0,39 0,31 0,09 0,09
LBPriu28,2 0,00 0,00 0,19 0,19 1,92 1,04 0,07 0,08
GLCM 0,00 0,00 0,48 0,16 0,76 0,43 0,23 0,07
Gabor 0,00 0,00 0,02 0,01 0,11 0,11 0,00 0,00
A = LCA
B = A posteriori
C = MCB LCA
D = MCB a posteriori
Os apontamentos identificados nos parágrafos anteriores conduziram à análise dos
comportamentos dos métodos de seleção diante da restrição aos subconjuntos com os
132
melhores classificadores identificados na Seção 5.1. Assim, a Figura 5.23 apresenta os
gráficos com a evolução das taxas de reconhecimento para os métodos a posteriori e MCB
a posteriori, considerando todos os 10 classificadores, além dos sete e cinco melhores.
Destaca-se que a apresentação deste gráfico considerou o intervalo [90,0..93,5] ao invés
de [50..100] utilizado nos demais gráficos. A nova escala permite identificar as variações
inferiores a um ponto percentual no intervalo de 15 a 75 vizinhos.
Enquanto o método MCB a posteriori obteve taxas de reconhecimento de 93,03%
(σ=1,36; AUC=89,37; k=8) para os 10 classificadores, o mesmo atingiu 92,56% (σ=1,30;
AUC=89,02; k=30) e 92,27% (σ=1,52; AUC=88,68; k=45) para os sete e cinco me-
lhores classificadores, respectivamente. Considerando a mesma relação para o método
a posteriori, com os 10 classificadores alcançou-se 92,86% (σ=2,29; AUC=89,61; k=8),
enquanto que para os sete e cinco melhores classificadores obteve-se, respectivamente,
92,54% (σ=1,35; AUC=88,98; k=120) e 92,45% (σ=2,23; AUC=89,08; k=15).
Figura 5.23: Taxas de reconhecimento alcançadas pelos métodos a posteriori e MCB
a posteriori para a regra de fusão máximo, com diferentes subconjuntos com 10, 7 e 5
classificadores e as vizinhanças entre um e 75 elementos.
A estabilidade das taxas alcançadas por ambos os métodos é confirmada nas es-
tat́ısticas quanto à seleção dos classificadores apresentadas na Tabela 5.21. Devido à
identificação das melhores taxas para o conjunto originalmente testado com os 10 clas-
sificadores ter ocorrido com os oito vizinhos mais próximos do conjunto de validação,
assumiu-se este tamanho de vizinhança também para os subconjuntos com os sete e cinco
melhores classificadores.
As considerações anteriores quanto à concentração de seleções dos primeiros classifi-
cadores se mantêm e, como esperado, com pequeno aumento para os subconjuntos meno-
res avaliados. É importante salientar que, mesmo tendo taxas de seleção muito baixas,
os classificadores menos precisos também tiveram influência nos métodos baseados nos
comportamentos de múltiplos classificadores. Por comporem a assinatura MCB, a iden-
133
tificação de seus erros e acertos auxiliam na identificação de vizinhanças do conjunto de
validação com maior ńıvel de similaridade com a instância questionada.
Tabela 5.21: Taxas de seleção dos classificadores para os métodos a posteriori e MCB
a posteriori, considerando os oito vizinhos dos conjuntos de validação mais próximos às
instâncias questionadas, além de subconjuntos com os 10, 7 e 5 melhores classificadores.
# Classificadores
Método de Classificador 10 7 5
Seleção selecionado % σ % σ % σ
LPQ 83,37 4,44 86,99 2,96 88,13 3,54
SIFT 12,33 4,37 8,21 3,02 7,48 3,17
SURF 2,10 0,26 2,32 1,00 2,31 0,92
MSER-SURF 1,07 0,44 1,21 0,65 0,94 0,46
MCB LPQ-TOP 0,63 0,18 1,02 0,72 1,15 0,80
a posteriori LBPu28,2 0,11 0,13 0,13 0,17 - -
LBPri8,2 0,09 0,09 0,11 0,16 - -
LBPriu28,2 0,07 0,08 - - - -
GLCM 0,23 0,07 - - - -
Gabor 0,00 0,00 - - - -
LPQ 53,95 9,31 54,15 9,31 54,30 9,34
SIFT 25,79 4,04 25,90 4,04 25,96 4,03
SURF 14,56 7,01 14,67 6,99 14,75 6,96
MSER-SURF 2,93 0,77 3,07 0,75 3,16 0,74
a posteriori LPQ-TOP 1,66 0,52 1,75 0,56 1,82 0,59
LBPu28,2 0,24 0,11 0,27 0,12 - -
LBPri8,2 0,18 0,14 0,20 0,16 - -
LBPriu28,2 0,19 0,19 - - - -
GLCM 0,48 0,16 - - - -
Gabor 0,02 0,01 - - - -
5.3.4 Combinação dos classificadores selecionados
Nesta seção avalia-se a utilização de um conjunto de oito regras de fusão identificadas na
Seção 2.4.1, seguindo as considerações da Seção 4.5. Destaca-se que, em decorrência de
suas melhores taxas de reconhecimento, as regras máximo e média têm sido apresentadas
no decorrer deste trabalho. Além disso, por ter provido taxas de reconhecimento inferiores
aos melhores resultados individuais dos classificadores, as demais regras de combinação
não foram mencionadas no presente caṕıtulo.
A Figura 5.24 apresenta os resultados para as regras máximo e média. Contrariando as
proposições de Giacinto e Roli [36], ao se considerar um conjunto mais amplo de regras de
fusão, identificou-se que a regra de fusão máximo apresentou resultados muito superiores
àqueles resultantes da regra média para todos os tamanhos de vizinhança avaliados. Além
da conclusão anterior, com exceção dos métodos OLA e LCA, mais uma vez confirma-se
a superioridade dos métodos baseados no critério LCA sobre aqueles baseados no critério
OLA também para todos os tamanhos de vizinhança avaliados.
134
(a) (b)
(c) (d)
Figura 5.24: Taxas de reconhecimento alcançadas com as regras de fusão máximo e
média para as vizinhanças entre um e 75 elementos: (a) OLA e LCA, (b) a priori e a
posteriori, (c) MCB OLA e MCB LCA, e (d) MCB a priori e MCB a posteriori.
5.4 Perspectivas empregadas durante a avaliação dos resultados
Considerando os argumentos apresentados na Seção 4.6, apresenta-se aqui os resultados
das estratégias que consideraram os diferentes ńıveis definidos pela Botânica.
5.4.1 Avaliação dos resultados nos diferentes ńıveis definidos
pela Botânica
A Tabela 5.22 ilustra os resultados obtidos para os ńıveis espécie, gênero, famı́lia e filo, com
suas 112, 85, 30 e 2 classes ‘reais’, respectivamente. Conforme esperado, as taxas evoluem
positivamente quando se desloca entre os ńıveis espécie e filo. No entanto, as variações
entre as taxas obtidas para os ńıveis espécie, gênero e famı́lia não são tão representativas
quando comparadas com as variações entre famı́lia e filo.
Tomando as taxas de reconhecimento obtidas pelo melhor classificador (SURF) e pelo
melhor método de seleção dinâmica de classificadores, verifica-se uma diferença de 3,89
pontos percentuais no ńıvel espécie. No entanto, no ńıvel filo a comparação das taxas
obtidas com SURF e os demais itens da Tabela 5.22 conduzem à utilização direta e única
deste classificador. Isto por suas taxas de reconhecimento serem equivalentes às obtidas
135
pelo método KNORA-U e também aos custos inerentes aos métodos de seleção.
Ao se considerar os cinco melhores classificadores (Tabela 5.1), percebe-se que a di-
ferença entre suas taxas de reconhecimento caem de 2,73 para 0,96 pontos percentuais
quando se vai do ńıvel espécie para filo. De forma geral, as taxas indicam que a maior
parte dos erros encontra-se nos próprios filos Angiospermas e Gimnospermas, o que é
confirmado pelos testes da seção seguinte.
No outro extremo, LBPriu28,2 , GLCM e filtros de Gabor apresentam as piores taxas em
todos os ńıveis, mas ainda com a maior parte dos erros de classificação internamente aos
filos. Tomando o pior classificador (GLCM), identificou-se que no ńıvel espécie Cariniana
estrellensis, Pithecellobium jupunba e Ligustrum lucidum não tiveram classificações cor-
retas. Enquanto isso, Dinizia excelsa obteve 1.205% mais classificações do que o número
de imagens para ela existentes, embora esta espécie tenha alcançado apenas 85% de clas-
sificações corretas.
Tabela 5.22: Taxas de reconhecimento para os ńıveis definidos pela Botânica espécie,
gênero, famı́lia e filo com, respectivamente, 112, 85, 30 e 2 classes ‘reais’.
Classificador / Espécie Gênero Famı́lia Filo
Mét. de seleção / combinação % σ % σ % σ % σ
SURF 89,14 2,39 89,43 2,12 91,77 1,22 99,11 0,32
MSER-SURF 87,80 2,17 87,91 2,08 89,75 1,37 98,78 0,72
SIFT 88,47 1,64 89,54 0,82 91,45 1,38 98,15 0,36
LPQ 86,74 2,07 87,50 1,47 90,54 1,20 98,48 0,29
LPQ-TOP 86,41 1,36 87,46 1,24 90,07 1,66 98,55 0,17
LBPu28,2 66,25 4,67 66,99 4,16 73,28 5,42 96,21 0,95
LBPri8,2 50,74 9,54 51,87 9,06 62,07 5,47 95,18 2,36
Gabor 25,67 2,53 26,40 2,57 34,23 5,08 86,62 3,35
LBPriu28,2 16,49 17,57 17,06 17,33 26,33 15,21 66,73 21,30
GLCM 4,09 1,13 4,64 1,32 24,70 10,55 71,51 8,65
Combinações 90,71 2,45 91,31 1,85 93,12 1,13 98,91 0,39
KNORA-E 88,30 3,73 88,88 3,12 90,87 2,16 98,10 0,57
KNORA-U 88,38 1,69 88,54 1,66 91,62 1,62 99,13 0,32
OLA 86,19 1,76 87,05 1,36 89,28 2,48 98,01 0,60
LCA 84,86 2,56 85,73 1,89 88,94 1,78 98,26 0,45
MCB OLA 84,36 2,52 85,05 1,89 87,84 1,18 98,02 0,88
MCB LCA 86,27 1,77 86,62 1,62 88,98 2,34 98,87 0,57
a priori 90,28 1,69 90,62 1,44 92,49 0,49 98,84 0,54
a posteriori 92,86 2,29 93,11 2,14 94,61 0,97 98,79 0,50
MCB a priori 86,78 2,09 87,54 1,47 90,61 1,06 98,48 0,34
MCB a posteriori 93,03 1,36 93,30 1,24 94,73 0,42 98,80 0,60
5.4.2 Uso de meta-classes para a abordagem de classificação
hierárquica
A partir dos procedimentos definidos na Seção 4.6.2, obteve-se os resultados apresentados
na Tabela 5.23 para os classificadores LPQ, SIFT e SURF. A linha identificada com a
meta-classe ‘Filos ’ contém as taxas de reconhecimento obtidas pelos modelos de classi-
ficação constrúıdos para diferenciar Gimnospermas de Angiospermas. Já nas linhas ‘Gim-
nospermas ’ e ‘Angiospermas ’ tem-se os resultados obtidos pelos modelos de classificação
constrúıdos, respectivamente, para a diferenciação das espécies florestais pertencentes a
cada um destes grupos.
136
A penúltima linha da Tabela 5.23 combina os resultados obtidos em cada um dos ńıveis
por meio da intersecção dos acertos. Ou seja, acertos foram contabilizados apenas quando
os classificadores realizaram as predições corretas em ambos os ńıveis. Comparando tais
resultados com aqueles obtidos pela classificação direta no ńıvel espécies (com 112 classes
‘reais’), apresentados na última linha da Tabela 5.23, verificou-se que tal abordagem não
contribuiu para a melhoria das taxas de reconhecimento. Além disso, tanto os resultados
da seção anterior quanto estes demonstram que a maioria dos erros ocorre internamente
aos próprios filos.
Tabela 5.23: Comparação dos resultados obtidos pelos modelos de classificação cons-
trúıdos para distinguir as 112 espécies florestais e do processo de classificação hierárquica
seguindo os ńıveis definidos pela Botânica.
Classificador
LPQr11 SIFT SURF
# Meta-Classes % σ AUC % σ AUC % σ AUC
2 Filos 97,16 0,16 83,40 96,75 0,16 86,35 96,93 0,16 87,21
37 Gimnospermas 86,06 2,86 84,56 87,40 5,60 84,94 90,14 3,86 86,46
75 Angiospermas 86,93 4,33 82,24 89,53 2,77 87,76 91,20 3,70 87,96
112 Clas. 2 Nı́veis 86,05 0,97 81,99 88,26 0,97 85,71 89,01 0,97 86,88
112 Clas. 1 Nivel 86,74 2,07 80,39 88,47 1,64 85,44 89,14 2,39 85,17
5.5 Análise dos Erros de Classificação
Dados os resultados anteriores para o ńıvel das espécies florestais, esta seção apresenta
considerações quanto aos erros de classificação. As imagens da Figura 5.25 ilustram três
classes e suas caracteŕısticas texturais, enquanto a Tabela 5.24 apresenta as taxas de erros
dos classificadores e das alternativas testadas para seleção dinâmica de classificadores.
Estes exemplos representam casos extremos da base de imagens utilizada, mas não são
únicos. As Figuras 5.25(a) e (c) mostram exemplos com as caracterizações bem definidas
de suas espécies, as quais são comprovadas por meio das taxas de erros de classificação por
espécie (Tabela 5.24). No extremo oposto, a espécie ilustrada na Figura 5.25(b) mostra
caracteŕısticas das duas anteriores, o que dificulta sua diferenciação das demais espécies.
Esta dificuldade é refletida nas taxas de erros de classificação de suas imagens, cujos
menores valores foram apresentados pelo classificador LPQ (37,5%) e pelos métodos de
seleção dinâmica de classificadores KNORA-E e KNORA-U (27,5%).
Os resultados da Tabela 5.24 também permitem avaliar a acurácia individual dos classi-
ficadores. Aqueles constrúıdos com caracteŕısticas extráıdas com filtros de Gabor, LBPriu28,2
e GLCM apresentaram dificuldades na diferenciação das espécies florestais, mesmo daque-
las melhor definidas em termos de padrões texturais. As colunas ‘Conf’ da Tabela 5.24
definem a distribuição dos erros de classificação interna e/ou externamente ao filo à que
as espécies pertencem. Assim como nos experimentos da Seção 5.4, a análise desta dis-
tribuição confirmou que a maioria das confusões ocorre internamente aos filos a que cada
137
espécie pertence.
(a) (b) (c)
Figura 5.25: Exemplos de erros de classificação ocorridos por espécies florestais: (a)
Pinus caribaea; (b) Tibouchiana sellowiana; (c) Erisma uncinatum.
Tabela 5.24: Śıntese dos erros de classificação ocorridos para as espécies florestais da
Figura 5.25.
Classificador / Espécies
Método de (a) (b) (c)
Seleção % Conf % Conf % Conf
SURF 40,0
MSER-SURF 47,5
SIFT 47,5
LPQ 37,5
LPQ-TOP 42,5
LBPu28,2 67,5 32,5
LBPri8,2 25,0 90,0 57,5
Gabor 32,5 100,0 92,5
LBPriu28,2 100,0 ie 95,0 ie 100,0 e
GLCM 100,0 100,0 ie 100,0
KNORA-E 27,5
KNORA-U 20,0 27,5 7,0
OLA 50,0
LCA 45,0
MCB OLA 2,5 47,5
MCB LCA 50,0
a priori 2,5 47,5
a posteriori 40,0
MCB a priori 37,5
MCB a posteriori 32,5
Espaços em branco na coluna % identificam que todas as amostras da
classe foram classificadas corretamente, isto é, 0% de erros.
Distribução dos erros (Conf):
( i ) identifica que a maioria das confusões de classificação ocorre com
espécies internas ao próprio filo, tendo sido suprimida desta tabela.
( e ) identifica que a maioria das confusões de classificação ocorre com
espécies externas ao próprio filo.
( ie ) identifica confusões de classificação relativamente bem distribúıdas
entre as espécies de ambos os filos.
138
5.6 Considerações Finais
Neste caṕıtulo foram apresentados os resultados dos experimentos descritos no Caṕıtulo
4. Estes permitiram a identificação dos potenciais dos classificadores de forma individual,
da combinação de conjuntos de classificadores e da seleção dinâmica de classificadores no
espaço de dissimilaridade.
A partir de tais resultados, o modelo de classificação proposto foi validado por meio
da aplicação de diferentes métodos de seleção dinâmica de classificadores. Neste contexto,
identificou-se a superioridade dos métodos de seleção dinâmica de classificadores sobre as
demais estratégias avaliadas, sendo que os métodos propostos alcançaram taxas de reco-
nhecimento equivalentes ou superiores aos demais para todos os tamanhos de vizinhança
avaliados.
Para a combinação de classificadores, verificou-se taxas de reconhecimento superiores
para as regras de fusão máximo e média com relação às demais regras de fusão testadas,
com grande vantagem para a primeira. Destaca-se que tais diferenças ocorreram tanto
na combinação dos subconjuntos de classificadores utilizados para todas as instâncias
questionadas quanto na combinação dos classificadores dinamicamente selecionados.
Conforme esperado, a avaliação das taxas de reconhecimento nos diferentes ńıveis de-
finidos pela Botânica possibilitou a melhoria dos resultados à medida em que se desloca
do ńıvel espécie para o ńıvel filo. Neste contexto, por meio das duas estratégias empre-
gadas e da análise dos erros de classificação, identificou-se que a maior parte dos erros
de classificação encontra-se no ńıvel filo, o que confirma as asserções de vários autores
quanto a este aspecto e ao elevado ńıvel de semelhanças das espécies pertencentes a cada
filo. Ainda quanto a esta avaliação, verificou-se que a classificação no ńıvel filo deveria
ocorrer apenas por meio do classificador SURF, tanto por suas taxas serem equivalentes
àquelas obtidas com o método KNORA-U quanto pela eliminação dos custos inerentes
aos métodos de seleção e/ou combinação de classificadores.
CAPÍTULO 6
CONSIDERAÇÕES FINAIS
O presente caṕıtulo apresenta uma breve avaliação dos resultados alcançados, tendo como
base a motivação, os desafios, os objetivos e as contribuições deste trabalho, tal como
identificado no Caṕıtulo 1. Adicionalmente, são apresentadas sugestões para a realização
de trabalhos futuros, numa tentativa de complementar o presente trabalho e responder
questões que surgiram durante seu desenvolvimento, mas não estavam compreendidas em
seu escopo.
6.1 Discussão
Além dos resultados apresentados no Caṕıtulo 5, experimentos exploratórios foram reali-
zados e publicados durante o desenvolvimento deste trabalho. No primeiro, apresentou-se
um conjunto compacto de caracteŕısticas estruturais para diferenciar as espécies florestais
dos filos Angiospermas e Gimnospermas. Tal conjunto era composto por apenas cinco
elementos baseados em estat́ısticas das estruturas dos principais componentes conexos
das imagens [86]. Também avaliou-se o uso de descritores de textura extráıdos de GLCM
[84]. A base de imagens utilizada em todos os experimentos foi publicada em [85]. Nos
trabalhos [17] e [87] avaliou-se estratégias para a combinação de descritores texturais para
o reconhecimento de espécies florestais. Nos dois últimos, as combinações avaliadas ocor-
reram tanto por meio da concatenação dos vetores de caracteŕısticas quanto da aplicação
de regras de fusão aos resultados individuais dos classificadores.
Com relação à questão principal deste trabalho, concluiu-se pela viabilidade quanto
à construção de um sistema robusto para classificação de espécies florestais utili-
zando caracteŕısticas texturais presentes nas imagens microscópicas de madeira, a repre-
sentação no espaço de dissimilaridade e sistemas compostos por múltiplos classificadores.
É importante destacar que não foram encontradas referências quanto à seleção dinâmica
de classificadores no espaço de dissimilaridade na literatura, o que faz desta abordagem
um importante diferencial para o presente trabalho. A viabilidade da proposta foi compro-
vada pelos resultados apresentados no Caṕıtulo 5, os quais são superiores àqueles obtidos
nos primeiros experimentos exploratórios sob a abordagem da classificação tradicional e
publicados em [17, 84, 85, 86, 87], além de outros trabalhos desenvolvidos com o foco
em reconhecimento de espécies florestais [109]. Comparando os resultados apresentados
no Caṕıtulo 3 (Tabela 3.1) e no Caṕıtulo 5 (Tabela 5.22), verificou-se a equivalência ou
superioridade daqueles alcançados neste trabalho com relação aos identificados na lite-
ratura. Destaca-se o número de espécies florestais utilizadas, o qual é pelo menos cinco
vezes maior que o máximo identificado na Tabela 3.1, e a possibilidade dos classificadores
140
constrúıdos no espaço de dissimilaridade poderem ser empregados para rotular amostras
pertencentes a classes que não estavam presentes durante seu treinamento.
Ao se considerar as taxas alcançadas individualmente e as questões secundárias, verificou-
se que as representações baseadas em pontos de atenção mostraram-se superiores para a
descrição das caracteŕısticas texturais presentes nas imagens microscópicas de ma-
deira. Como apresentado na Figura 2.2, a grande variação nos tipos e frequência de
células provê padrões texturais distintos. Tais padrões também influenciam na quanti-
dade de pontos de máximos e mı́nimos existentes nas imagens em ńıveis de cinza e que
caracterizam as divisões das células (Tabela 5.6). Esta diversidade em termos de padrões
texturais e quantidade de pontos de máximos e mı́nimos garante também a diversidade de
caracteŕısticas necessárias para garantir a diferenciação das espécies florestais. A avaliação
dos algoritmos de detecção de pontos de interesse comprovou sua efetividade enquanto
que a utilização de pontos definidos aleatoriamente na imagem não provêem os mesmos
resultados ou o fazem com custos computacionais maiores em decorrência da elevada
quantidade de pontos necessários.
Tomando o fato da existência de um elevado número de espécies florestais, o qual chega
à casa de milhares, e o reduzido número de amostras por espécie, comprovou-se também
para este problema a garantia de independência entre as classes empregadas nos conjuntos
de treinamento e teste. Assim, para os classificadores constrúıdos no espaço de
dissimilaridade, verificou-se posśıveis influências da quantidade de classes, amostras
por classe e referências por amostra no processo de classificação. Com o objetivo de
avaliar a influência da quantidade de classes na construção dos modelos, foram utilizadas
60% das espécies florestais dispońıveis para gerar os conjuntos de treinamento, num total
de 68 espécies. Ao final das avaliações, identificou-se a necessidade de se empregar as
68 espécies para garantir a maximização das taxas de reconhecimento. Ao se considerar
a quantidade de classes empregadas na geração dos conjuntos de teste, identificou-se
queda das taxas à medida em que o número de espécies florestais candidatas aumentava.
Embora esperava-se que estas taxas estabilizassem para conjuntos maiores de classes, não
foi posśıvel comprovar tal fato por ter atingido o limite de espécies florestais dispońıveis
para a geração do conjunto de testes. Contudo, os valores similares para o desvio padrão
demonstram a estabilidade do modelo proposto.
Ao se empregar os MCSs no processo de classificação, identificou-se ganhos reais
com relação às taxas de reconhecimento. A partir dos melhores resultados individuais
obtidos para o classificador SURF, com taxas de reconhecimento de 89,14%, alcançou-se
90,71% e 93,03% para a combinação de agrupamentos de classificadores e a seleção de um
único classificador, respectivamente. Destaca-se, neste contexto, as vantagens advindas da
melhoria das taxas de reconhecimento em quase quatro pontos percentuais. No entanto,
agrega-se também as desvantagens inerentes à complexidade e aos custos computacionais
decorrentes da necessidade de um conjunto maior de classificadores e do processo de
seleção e/ou combinação de classificadores.
141
Sob o contexto dos MCSs, além do modelo de classificação, três novos métodos
para seleção dinâmica de classificadores foram apresentados e validados. Os novos
métodos apresentaram resultados (Tabela 5.19) equivalentes ou superiores àqueles pro-
postos por Woods et al. [146], Giacinto e Roli [33] e Ko et al. [64, 65], ao se considerar
suas caracterizações quanto aos critérios para definição da vizinhança, delimitação da vizi-
nhança e seleção do classificador. Além disso, os métodos propostos e validados no espaço
de dissimilaridade também podem ser aplicados para a seleção dinâmica de classificadores
no espaço de caracteŕısticas, sem a necessidade de qualquer alteração. Também o mo-
delo proposto pode ser utilizado em diferentes domı́nios de aplicação cuja solução envolva
MCSs, com a representação e seleção dos classificadores no espaço de dissimilaridade.
Outra importante questão tratada neste trabalho foi a avaliação das taxas de
reconhecimento do sistema nos ńıveis filo, famı́lia, gênero e espécie, definidos pela
Botânica. Tal estratégia justifica-se pelo elevado número de espécies florestais existentes,
pela complexidade imposta pela distinção de espécies muito próximas na hierarquia de
ńıveis definidos pela Botânica e por, algumas vezes, não haver necessidade de se realizar
a classificação a ńıvel de espécies. Ao final, concluiu-se que a maior parte dos erros de
classificação está compreendida internamente a cada filo. Concluiu-se ainda que, diante
da necessidade de classificação no ńıvel filo, a melhor alternativa constitui apenas no uso
do classificador SURF devido ao custo e complexidade adicionais ao se trabalhar com os
10 classificadores e métodos para seleção e/ou combinação de classificadores.
A dificuldade de acesso às bases existentes impôs a construção de uma base de
imagens própria para o desenvolvimento de pesquisas em classificação de espécies flo-
restais. Esta é também uma importante contribuição deste trabalho, dado que possui
número e variedade de espécies muito superior a qualquer outra encontrada na literatura
da área, sendo a única com imagens microscópicas que se tem conhecimento. Publicada
em [85], a base de imagens pode ser requisitada para o desenvolvimento de pesquisas no
endereço eletrônico http://web.inf.ufpr.br/vri/forest-species-database. Destaca-se ainda
uma contribuição no contexto social, com a identificação da espécie florestal, indepen-
dente de fatores que se perdem com o decorrer do tempo, tais como folhas, frutos, casca,
cor e odor, dentre outros. Também, sob o contexto tecnológico, a principal contribuição
constitui a criação de um sistema robusto para a classificação de espécies florestais. Este
sistema compreende a descrição apresentada no Caṕıtulo 4, tendo sido validado pelos
experimentos descritos também no Caṕıtulo 4 e seus resultados no Caṕıtulo 5. Sua im-
plantação, por parte de qualquer empresa que comercialize madeiras ou mesmo agências
fiscalizadoras, depende apenas da aquisição dos equipamentos e observação dos procedi-
mentos descritos no Apêndice A. Além destas observações, sugere-se uma pessoa treinada
para garantir que os procedimentos sejam seguidos corretamente. Enfatiza-se ainda que
as peças a serem analisadas, geralmente, possuem dimensões que permitem a identificação
dos eixos ilustrados na Figura 2.3(a). Assim, também não haveria a necessidade de um
especialista em Anatomia da Madeira para realizar a coleta das amostras.
142
6.2 Trabalhos Futuros
Durante o desenvolvimento do presente trabalho surgiram questões que, embora impor-
tantes para o problema, não foram abordadas por não estarem compreendidas em seu
escopo.
Diante da falta de conhecimento de outros trabalhos com imagens microscópicas e
também da proximidade dos resultados apresentados com aqueles obtidos com imagens
macroscópicas, uma posśıvel estratégia poderia combinar abordagens com a aplicação de
imagens macroscópicas e microscópicas no processo de reconhecimento, o que permiti-
ria avaliar os ńıveis de complementaridade das informações obtidas sob estas diferentes
perspectivas.
Durante os experimentos, diferentes subconjuntos de espécies florestais foram con-
siderados na avaliação da robustez dos modelos de classificação, sempre respeitando a
proporção das espécies existentes nos filos Gimnospermas e Angiospermas. No entanto,
nenhuma avaliação foi realizada quanto às semelhanças e diferenças entre as espécies.
Neste sentido, surge a questão: “Quais as espécies adequadas para a construção dos
modelos de classificação, considerando a variação da madeira em cada espécie flores-
tal e entre as espécies?”. Para identificar as espécies florestais mais adequadas para a
construção de um modelo mais robusto baseado em dissimilaridade poder-se-ia empregar
técnicas bio-inspiradas como Otimização de Agrupamentos de Part́ıculas (Particle Swarm
Optimization) ou Algoritmos Genéticos.
A questão anterior também poderia sanar o problema inerente ao número de espécies
florestais utilizadas para gerar os conjuntos de treinamento e teste. No primeiro caso,
basicamente foi necessário utilizar as 68 espécies dispońıveis para maximizar as taxas
de reconhecimento. Mesmo com o reduzido número de espécies utilizado na geração
dos conjuntos de testes, modelos criados com subconjuntos de espécies mais adequadas
poderiam garantir maior estabilidade às taxas de reconhecimento.
Diante da impossibilidade de se otimizar os subconjuntos utilizados na geração dos
conjuntos de treinamento e teste, ainda ter-se-ia a ampliação da base de imagens, tanto em
número de espécies florestais quanto de amostras por espécie. Mesmo diante de sua am-
plitude quando comparada com outras bases dispońıveis, o total de 112 espécies florestais
representa uma amostra muito reduzida com relação às milhares de espécies existentes.
Embora esta questão esteja relacionada às duas questões anteriores, a mesma caracteriza
um ponto pasśıvel de investigação independente dos resultados obtidos para as demais.
Outra possibilidade de investigação relaciona-se à seleção de atributos. Neste ponto,
tem-se claro que muitas vezes alguns elementos que compõem os vetores de caracteŕısticas
gerados por um descritor não contribuem para a melhoria das taxas de reconhecimento.
Além dos fato de que tais elementos possam afetar negativamente os resultados, há a
certeza do custo computacional adicional se estes forem mantidos.
REFERÊNCIAS
[1] T. Ahonen, J. Matas, C. He, e M. Pietikäinen. Rotation invariant image description
with local binary pattern histogram fourier features. Computer Science, 5575(3):61–
70, 2009.
[2] D. S. Amorim. Fundamentos de Sistemática Filogenética. Holos, Ribeirão Preto,
2002.
[3] M. R. Banham e A. K. Katsaggelos. Digital image restoration. Signal Processing
Magazine, IEEE, 14(2):24–41, 1997.
[4] J. A. Barker. A Prototype Interative Identification Tool to Fragmentary Wood
From Eastern Central Australia, and its Application to Aboriginal Australian Ethno-
graphic Artefacts. Tese de Doutorado, School of Earth and Environmental Sciences,
Adelaide University, 2005.
[5] H. Bay, A. Ess, T. Tuytelaars, e L. Van Gool. Speeded-up robust features (surf).
Comput. Vis. Image Underst., 110(3):346–359, 2008.
[6] H. Bay, T. Tuytelaars, e L. Van Gool. Surf: Speeded up robust features. In ECCV,
páginas 404–417, 2006.
[7] D. Bertolini, L. S. Oliveira, E. Justino, e R. Sabourin. Reducing forgeries in writer-
independent off-line signature verification through ensemble of classifiers. Pattern
Recognition, 43:387–396, 2010.
[8] D. Black. The Theory of Committees and Elections. Cambridge University Press,
London, 2 edition, 1958.
[9] G. Bradski. The opencv library. Dr. Dobb’s Journal of Software Tools, 2000.
[10] L. Breiman. Bagging predictors. Machine Learning, 24(2):123–140, 1996.
[11] P. Brodatz. Textures: A Photographic Album for Artists and Designers. Dover
Publications, 1999.
[12] C. C. Brunner, A. G. Maristany, e D. A. Butler. Wood species identification using
spectral reflectance. Forest Products Journal, 46(2):82–85, 1996.
[13] D. N. Buechler e D. K. Misra. Subsurface detection of small voids in low-loss solids.
First ISA/IEEE Conference Sensor for Industry, páginas 281–284, 2001.
[14] L. M. Burger e H. G. Richter. Anatomia da Madeira. Nobel, São Paulo, 1991.
144
[15] D. A. Butler, C. C. Brunner, e J. W. Funck. Wood-surface feature classification
using extended-color information. Holz als Roh- und Werkstoff, 59(6):475–482, 2001.
[16] A. CaronDecloquement. Extractives from Sitka spruce. Tese de Doutorado, Depart-
ment of Chemistry, University of Glasgow, 2010.
[17] P. R. Cavalin, M. N. Kapp, J. Martins, e L. E. S. Oliveira. A multiple feature
vector framework for forest species recognition. Proceedings of the 28th Annual
ACM Symposium on Applied Computing, SAC ’13, páginas 16–20, New York, NY,
USA, 2013.
[18] C-C. Chang e C-J. Lin. Libsvm: A library for support vector machines. ACM
Transactions on Intelligent Systems and Technology, 2:1–27, 2011.
[19] R. I. Chaplin, R. M. Hodgson, e S. Gunetileke. Automatic wane detection in the
images of planks using a neural network. Fifth International Symposium on Signal
Processing and its Applications, 2:657–659, 1999.
[20] L. Chen e J. Gasteiger. Knowledge discovery in reaction databases: Landscaping
organic reactions by a self-organizing neural network. Journal of the American
Chemical Society, 119(17):4033–4042, 1997.
[21] A. Conci, E. Azevedo, e F. R. Leta. Computação Gráfica: teoria e prática, volume 2.
Elsevier, Rio de Janeiro, 2008.
[22] R. W. Conners, D. E. Kline, P. A. Araman, e T. H. Drayer. Machine vision tech-
nology for the forest products industry. Computer, 30(7):43–48, 1997.
[23] D. L. Davies e D. W. Bouldin. A cluster separation measure. Pattern Analysis and
Machine Intelligence, IEEE Transactions on, 1(2):224–227, 1979.
[24] T. G. Dietterich. Ensemble methods in machine learning. Proceedings of the First
International Workshop on Multiple Classifier Systems, MCS ’00, páginas 1–15,
London, UK, 2000. Springer-Verlag.
[25] R. O. Duda, P. E. Hart, e D. G. Stork. Pattern classification. John Wiley & Sons,
Inc., New York, 2 edition, 2001.
[26] R. P. W. Duin e E. Pekalska. The dissimilarity space: bridging structural and
statistical pattern recognition. Pattern Recognition Letters, 33(7):826–832, 2012.
[27] R. P. W. Duin, E. Pekalska, P. Pacĺık, e D. M. J. Tax. The dissimilarity represen-
tation, a basis for a domain-based pattern recognition? Pattern representation and
the future of pattern recognition, a program for action, páginas 43–56, 2004.
145
[28] G. Eskander, R. Sabourin, e E. Granger. On the dissimilarity representation and
prototype selection for signature-based bio-cryptographic systems. E. Hancock e
M. Pelillo, editors, Similarity-Based Pattern Recognition, volume 7953 of Lecture
Notes in Computer Science, páginas 265–280. Springer Berlin Heidelberg, 2013.
[29] G. S. Eskander, R. Sabourin, e E. Granger. A bio-cryptographic system based on
offline signature images. Information Sciences, 259:170–191, 2014.
[30] P. A. Estevez, M. Fernandez, R. J. Alcock, e M. S. Packianather. Selection of
features for the classification of wood board defects. Ninth International Conference
on Artificial Neural Networks, 1:347–352, 1999.
[31] T. Fawcett. An introduction to roc analysis. Pattern Recognition Letters, 27:861–
874, 2006.
[32] P.-E. Forssen e D.G. Lowe. Shape descriptors for maximally stable extremal regi-
ons. Computer Vision, 2007. ICCV 2007. IEEE 11th International Conference on,
páginas 1–8, 2007.
[33] G. Giacinto e F. Roli. Adaptive selection of image classifiers. Alberto Bimbo, editor,
Image Analysis and Processing, volume 1310 of Lecture Notes in Computer Science,
páginas 38–45. Springer Berlin Heidelberg, 1997.
[34] G. Giacinto e F. Roli. Ensembles of neural networks for soft classification of remote-
sensing images. Proc. of the European Symposium on Intelligent Techniques, páginas
166–170, 1997.
[35] G. Giacinto e F. Roli. Methods for dynamic classifier selection. Proceedings of
the 10th International Conference on Image Analysis and Processing, ICIAP ’99,
páginas 659–665, Washington, DC, USA, 1999. IEEE Computer Society.
[36] G. Giacinto e F. Roli. Dynamic classifier selection based on multiple classifier
behaviour. Pattern Recognition, 34:1879–1881, 2001.
[37] G. Giacinto, F. Roli, e G. Fumera. Selection of image classifiers. Electronics Letters,
36(5):420–422, 2000.
[38] L. Goldfarb. What is distance and why do we need the metric model for pattern
learning? Pattern Recognition, 25(4):431–438, 1992.
[39] R. C. Gonzalez e R. E. Woods. Digital Image Processing. Prentice Hall, New Jersey,
3 edition, 2008.
[40] S. E. Grigorescu, N. Petkov, e P. Kruizinga. Comparison of texture features based
on gabor filters. IEEE Transactions on Image Processing, 11(10):1160–1167, 2002.
146
[41] O. Hagman. Multivariate prediction of wood surface features using an imaging
spectrograph. Holz als Roh- und Werkstoff, 55(6):377–382, 1997.
[42] S. Haker, W. M. Wells III, S. K. Warfield, I-F. Talos, J. G. Bhagwat, D. Goldberg-
Zimring, A. Mian, L. Ohno-Machado, e K. H. Zou. Combining Classifiers using their
Receiver Operating Characteristics and Maximum Likelihood Estimation, caṕıtulo
Part I, páginas 506–514. Springer-Verlag, Berlin Heidelberg - Germany, 2005.
[43] R. Hanusiak, L. Oliveira, E. Justino, e R. Sabourin. Writer verification using
texture-based features. International Journal on Document Analysis and Recog-
nition, páginas 1–14, 2011.
[44] R. M. Haralick. Statistical and structural approaches to texture. 67(5):786–804,
1979.
[45] R. M. Haralick, K. Shanmugam, e I. Dinstein. Textural features for image clas-
sification. IEEE Transactions on Systems, Man, and Cybernetics, 3(6):610–621,
1973.
[46] J. Heikkila, V. Ojansivu, e E. Rahtu. Improved blur insensitivity for decorrelated
local phase quantization. Pattern Recognition (ICPR), 2010 20th International
Conference on, páginas 818–821, 2010.
[47] T. K. Ho. The random subspace method for constructing decision forests. 20(8):832–
844, 1998.
[48] T. K. Ho, J. J. Hull, e S. N. Srihari. Decision combination in multiple classi-
fier systems. IEEE Transactions on Pattern Analysis and Machine Intelligence,
16(1):66–75, 1994.
[49] R. B. Hoadley. Identifying Wood: accurate results with simple tools. Taunton Press,
Newtown, CT, 1990.
[50] R. B. Hoadley. Understanding wood: a craftsman’s guide to wood technology. Taun-
ton Press, Newtown, CT, 2000.
[51] Y. S. Huang, K. Liu, e C. Y. Suen. The combination of multiple classifiers by a neu-
ral network approach. International Journal of Pattern Recognition and Artificial
Intelligence, 9(3):579–597, 1995.
[52] Y.S. Huang e C.Y. Suen. A method of combining multiple experts for the recognition
of unconstrained handwritten numerals. Pattern Analysis and Machine Intelligence,
IEEE Transactions on, 17(1):90–94, 1995.
[53] H. A. Huber. Economics of cutting hardwood lumber by two different methods.
Dissertação de Mestrado, University of Michigan, Michigan, 1969.
147
[54] H. A. Huber. A computerized economic comparison of a conventional furniture
rough mill with a new system of processing. Forest Products Journal, 21(2):34–39,
1971.
[55] K. Ioannou, D. Birbilis, e P. Lefakis. A pilot prototype decision support system for
recognition of greek forest species. Operational Research, 3(9):141–152, 2009.
[56] A. K. Jain, R. P. W. Duin, e J. Mao. Statistical pattern recognition: a review. Pat-
tern Analysis and Machine Intelligence, IEEE Transactions on, 22(1):4–37, 2000.
[57] A. K. Jain, A. Ross, e S. Pankanti. Biometrics: A tool for information security.
IEEE Transactions on Information Forensics and Security, 1(2):125–143, 2006.
[58] H. Kauppinen. A two stage defect recognition method for parquet slab grading.
15th International Conference on Pattern Recognition (ICPR’00), 4:803–806, 2000.
[59] M. Khalid, E. L. Y. Lee, R. Yusof, e M. Nadaraj. Design of an intelligent wood
species recognition system. International Journal of Simulation Systems, Science
& Technology Special Issue on: Artificial Intelligence, páginas 9–17, 2008.
[60] W. Khreich. Towards Adaptive Anomaly Detection Systems using Boolean Combina-
tion of Hidden Markov Models. Tese de Doutorado, École de Technologie Supérieure,
Université du Québec, Montreal, 2011.
[61] W. Khreich, E. Granger, A. Miri, e R. Sabourin. Iterative boolean combination
of classifiers in the roc space: An application to anomaly detection with hmms.
Pattern Recognition, 43(8):2732–2752, 2010.
[62] J. Kittler, M. Hatef, R. P. W. Duin, e J. Matas. On combining classifiers. IEEE
Trans. on Pattern Analysis and Machine Intelligence, 20:226–239, 1998.
[63] A. H. R. Ko, R. Sabourin, A. Britto, e L. S. Oliveira. Pairwise fusion matrix for
combining classifiers. Pattern Recognition, 40(8):2198–2210, 2007.
[64] A. H. R. Ko, R. Sabourin, e A. S. Britto, Jr. From dynamic classifier selection to
dynamic ensemble selection. Pattern Recognition, 41:1718–1731, 2008.
[65] A. H. R. Ko, R. Sabourin, e A. de Souza Britto. K-nearest oracle for dynamic
ensemble selection. Document Analysis and Recognition, 2007. ICDAR 2007. Ninth
International Conference on, volume 1, páginas 422–426, 2007.
[66] L. I. Kuncheva. Combining Pattern Classifiers: Methods and Algorithms. Wiley-
Interscience, 2004.
148
[67] R. D. Labati, M. Gamassi, V. Piuri, e F. Scotti. A low-cost neural-based approach
for wood types classification. Computational Intelligence for Measurement Systems
and Applications, 2009. CIMSA ’09. IEEE International Conference on, páginas
199–203, 2009.
[68] Forest Products Laboratory. Wood Handbook: wood as an engineering material. Ge-
neral Technical Report FPL-GTR-190. Department of Agriculture, Forest Service,
Forest Products Laboratory, Madison, WI: U.S., 2010.
[69] M. Lades, J. C. Vorbrüggen, J. Buhmann, J. Lange, C. von der Malsburg, R. P.
Würtz, e W. Konen. Distortion invariant object recognition in the dynamic link
architecture. IEEE Transactions on Computers, 42(3):300–311, 1993.
[70] M. Lambers e C. Veenman. Forensic authorship attribution using compression dis-
tances to prototypes. Z. Geradts, K. Franke, e C. Veenman, editors, Computational
Forensics, volume 5718 of Lecture Notes in Computer Science, páginas 13–24. Sprin-
ger Berlin Heidelberg, 2009.
[71] B. K. Lavine, C. E. Davidson, A. J. Moores, e P. R. Griffiths. Raman spectroscopy
and genetic algorithms for the classification of wood types. Applied Spectroscopy,
55(8):960–966, 2001.
[72] P. K. Lebow, C. C. Brunner, A. G. Maristany, e D. A. Butler. Classification of wood
surface features by spectral reflectance. Wood and Fiber Science, 28(1):74–90, 1996.
[73] I. R. Lewis, N. W. Daniel Jr, N. C. Chaffin, e P. R. Griffiths. Raman spectrometry
and neural networks for the classification of wood types - 1. Spectrochimica Acta
Part A: Molecular Spectroscopy, 50(11):1943–1958, 1994.
[74] M-X. Li, C-D. Wu, e Y. Yue. Automatic visual inspection and classification based
on rough sets and neural network. International Conference on Machine Learning
and Cybernetics, 2, páginas 3095–3099, 2003.
[75] D. G. Lowe. Object recognition from local scale-invariant features. Proceedings of
the International Conference on Computer Vision, volume 2 of ICCV ’99, páginas
1150–, Washington, DC, USA, 1999. IEEE Computer Society.
[76] D. G. Lowe. Distinctive image features from scale-invariant keypoints. International
Journal of Computer Vision, 60(2):91–110, 2004.
[77] G. A. P. Lópes. Aforapro: reconhecimento de objetos invariante sob transformações
afins. Dissertação de Mestrado, Escola Politécnica da Universidade de São Paulo,
São Paulo, 2011.
149
[78] D. M. Lyons e D. F. Hsu. Combining multiple scoring systems for target tracking
using rank-score characteristics. Information Fusion, 10, páginas 124–136, 2009.
[79] T. Maenpää e M. Pietikäinen. Texture Analysis with Local Binary Patterns, caṕıtulo
2.6, páginas 197–216. World Scientific, Singapore, 3 edition, 2005.
[80] S. G. Mallat. A theory for multiresolution signal decomposition: the wavelet re-
presentation. Pattern Analysis and Machine Intelligence, IEEE Transactions on,
11(7):674–693, 1989.
[81] J. N. C. Marchiori. Dendrologia das Gimnospermas. Editora da UFSM, Santa Maria
- RS, 1996.
[82] J. N. C. Marchiori. Dendrologia das Angiospermas: das magnoliáceas às fla-
curtiáceas. Editora da UFSM, Santa Maria - RS, 1997.
[83] C. Marrocco, M. Molinara, e F. Tortorella. On linear combinations of dichotomizers
for maximizing the area under the roc curve. Systems, Man, and Cybernetics, Part
B: Cybernetics, IEEE Transactions on, 41(3):610–620, 2011.
[84] J. G. Martins, Y. M. G. Costa, D. B. Gonçalves, e L. E. S. Oliveira. Uso de des-
critores de textura extráıdos de glcm para o reconhecimento de padrões em diferen-
tes domı́nios de aplicação. XXXVII Conferencia Latinoamericana de Informática,
páginas 637–652, 2011.
[85] J. G. Martins, L. E. S. Oliveira, S. Nisgoski, e R. Sabourin. A database for automatic
classification of forest species. Machine Vision and Applications, páginas 1–12, 2012.
[86] J. G. Martins, L. E. S. Oliveira, P. L. Paula Filho, e S. Nisgoski. Classificação
automática de grupos de espécies florestais. VII Workshop de Visão Computacional,
páginas 28–33, 2011.
[87] J. G. Martins, L.S. Oliveira, e R. Sabourin. Combining textural descriptors for forest
species recognition. IECON 2012 - 38th Annual Conference on IEEE Industrial
Electronics Society, páginas 1483–1488, 2012.
[88] J. Matas, O. Chum, U. Martin, e T. Pajdla. Robust wide baseline stereo from
maximally stable extremal regions. Proc. of the British Machine Vision Conference,
1:384–393, 2002.
[89] MATLAB. version 7.14 (R2012a). The MathWorks Inc., Natick, Massachusetts,
2012.
[90] T. Mäenpää, T. Ojala, M Pietikäinen, e M. Soriano. Robust texture classifica-
tion by subsets of local binary patterns. 15th International Conference on Pattern
Recognition, páginas 947–950, 2000.
150
[91] P. Mishra, R. Chatterjee, e V. Mahapatra. Texture Segmentation Using Gabor
Filters and Wavelets. Tese de Doutorado, Department of Computer Science and
Engineering, National Institute of Technology, Deemed University, Rourkela, Índia,
2010.
[92] G. Müller, C. Schöpper, H. Vos, A. Kharazipour, e A. Polle. Ftir-atr spectroscopic
analyses of changes in wood properties during particle- and fibreboard production
of hard- and softwood trees. BioResources, 4(1):49–71, 2009.
[93] J. Moody e P. Klinkhachorn. Automated lumber processing system (alps): an
industrial prototype. Thirtieth Southeastern Symposium on System Theory, páginas
476–479, 1998.
[94] J. P. R. do Nascimento. Análise e classificação de imagens baseadas em carac-
teŕısticas de textura utilizando matrizes de co-ocorrência. Dissertação de Mes-
trado, Programa de Pós-Graduação em Informática, Universidade Federal do Paraná
(UFPR), Curitiba, 2003.
[95] M. Nasirzadeh, A. A. Khazael, e M. B Khalid. Woods recognition system based
on local binary pattern. Second International Conference on Computational Intel-
ligence, Communication Systems and Networks, páginas 308–313, 2010.
[96] J. R. Nault. Differentiation of some Canadian coniferous woods by combined diffuse
and specular reflectance Fourier transform infrared spectroscopy. Tese de Doutorado,
Departament of Forestry, The University of British Columbia, 1989.
[97] J. R. Nault e J. F. Manville. Differentiation of some canadian coniferous woods by
combined diffuse and specular reflectance fourier transform infrared spectroscopy.
Wood and Fiber Science, 24(4):424–431, 1992.
[98] J. R. Nault e J. F. Manville. Species differentiation of two common lumber mixes by
diffuse reflectance fourier transform infrared (drift) spectroscopy. Wood and Fiber
Science, 29(1):2–9, 1997.
[99] D. Nilsson. Prediction of Wood Species and Pulp Brightness from Roundwood Mea-
surements. Tese de Doutorado, Faculty of Science and Technology, Department of
Chemistry, Ume̊a University, Ume̊a, 2005.
[100] D. Nilsson e U. Edlund. Pine and spruce roundwood species classification using
multivariate image analysis on bark. Holzforschung, 59(6):589–706, 2005.
[101] M. S. Nixon e A. S. Aguado. Feature Extraction and Image Processing. Elsevier,
London, UK, 2 edition, 2008.
151
[102] M. H. Nuopponen, G. M. Birch, R. J. Sykes, S. J. Lee, e D. Stewart. Estimation
of wood density and chemical composition by means of diffuse reflectance mid-
infrared fourier transform (drift-mir) spectroscopy. Journal of Agricultural and Food
Chemistry, 54(1):34–40, 2006.
[103] T. Ojala, M. Pietikainen, e T. Maenpaa. Multiresolution gray-scale and rotation
invariant texture classification with local binary patterns. Pattern Analysis and
Machine Intelligence, IEEE Transactions on, 24(7):971 –987, 2002.
[104] T. Ojala, M. Pietikäinen, e D. Harwood. A comparative study of texture measures
with classification based on featured distributions. Pattern Recognition, 29(1):51 –
59, 1996.
[105] V. Ojansivu e J. Heikkilä. Blur insensitive texture classification using local phase
quantization. Proceedings of the 3rd international conference on Image and Signal
Processing, ICISP ’08, páginas 236–243, Berlin, Heidelberg, 2008. Springer-Verlag.
[106] J. Päivärinta, E. Rahtu, e J. Heikkilä. Volume local phase quantization for blur-
insensitive dynamic texture classification. Proceedings of the 17th Scandinavian
conference on Image analysis, SCIA’11, páginas 360–369, Berlin, Heidelberg, 2011.
Springer-Verlag.
[107] C. Palm. Color texture classification by integrative co-occurrence matrices. Pattern
Recognition, 37(5):965–976, 2004.
[108] D. Partridge e W. B. Yates. Engineering multiversion neural-net systems. Neural
Comput., 8(4):869–893, 1996.
[109] P. L. Paula Filho. Reconhecimento de espécies florestais através de imagens ma-
croscópicas. Tese de Doutorado, Programa de Pós-Graduação em Informática do
Setor de Ciências Exatas da Universidade Federal do Paraná, Curitiba-PR, 2012.
[110] P. L. Paula Filho, L. E. S. Oliveira, e A. S. Britto Jr. A database for forest species
recognition. XXII Simpósio Brasileiro de Computação Gráfica e Processamento de
Imagens, páginas 1–2, 2009.
[111] P. L. Paula Filho, L. E. S. Oliveira, A. S. Britto Jr., e R. Sabourin. Forest species
recognition using color-based features. 20th International Conference on Pattern
Recognition (ICPR2010), páginas 4178–4181, 2010.
[112] H. Pedrini e W. R. Schwartz. Análise de Imagens Digitais: prinćıpios, algoritmos
e aplicações. Thomson Learning, São Paulo, 2008.
152
[113] E. Pekalska e R. P. W. Duin. Classification on dissimilarity data: a first look.
Annual Conference of the Advanced School for Computing and Imaging, páginas
221–228, 2000.
[114] E. Pekalska e R. P. W. Duin. Dissimilarity representations allow for building good
classifiers. Pattern Recognition Letters, 23(8):943–956, 2002.
[115] D. T. Pham e R. J. Alcock. Automated visual inspection of birch wood boards.
IEE Colloquium on Artificial Intelligence in Manufacturing, páginas 1–4, 1997.
[116] V. Piuri e F. Scotti. Design of an automatic wood types classification system by
using fluorescence spectra. IEEE Transactions on Systems, Man, and Cybernetics,
Part C, 40(3):358–366, 2010.
[117] Y. Plasencia, E. B. Garćıa-Reyes, R. P. W. Duin, H. Mendez-Vazquez, C. S. Mart́ın,
e C. Soto. Dissimilarity representations for thermal signature recognition at a dis-
tance. 15th Annual Conf. of the Advanced School for Computing and Imaging,
páginas 1–7, 2009.
[118] I. Podolak e A. Roman. Cores: fusion of supervised and unsupervised training
methods for a multi-class classification problem. Pattern Analysis & Applications,
páginas 1–19, 2011.
[119] S. Radovan, P. George, M. Panagiotis, G. Manos, A. Robert, e D. Igor. An appro-
ach for automated inspection of wood boards. International Conference on Image
Processing, 1:798–801, 2001.
[120] P. V. W. Radtke, E. Granger, R. Sabourin, e D. O. Gorodnichy. Adaptive en-
semble selection for face re-identification under class imbalance. 11th International
Workshop on Multiple Classifier Systems, páginas 95–108, Nanjing, China, 2013.
[121] P. V. W. Radtke, E. Granger, R. Sabourin, e D. O. Gorodnichy. Skew-sensitive
boolean combination for adaptive ensembles: an application to face recognition in
video surveillance. páginas 1–18. Elsevier, 2013.
[122] E. Rahtu, J. Heikkilä, V. Ojansivu, e T. Ahonen. Local phase quantization for
blur-insensitive image analysis. Image and Vision Computing, 30(8):501–512, 2012.
[123] E. D. Rinnhofer, E. Deutschl, R. Benes, e A. delBianco. Visible-and near infrared
imaging spectroscopy for wood inspection: preliminary results. 3rd IWSS, páginas
63–69, 1998.
[124] D. Rivard. Multi-feature approach for writer-independent offline signature verifi-
cation. Dissertação de Mestrado, École de Technologie Supérieure, Université du
Québec, Montreal, 2010.
153
[125] D. Rivard, E. Granger, e R. Sabourin. Multi-feature extraction and selection in
writer-independent off-line signature verification. International Journal on Docu-
ment Analysis and Recognition (IJDAR), 16(1):83–103, 2013.
[126] B. Rosen. Ensemble learning using decorrelated neural networks. Connection Sci-
ence, 8:373–384, 1996.
[127] D. Ruta e B. Gabrys. An overview of classifier fusion methods. volume 1, páginas
1–10. University of Paisley, 2000.
[128] A. Santana, R. G. F. Soares, A. M. P. Canuto, e M. C. P. Souto. A dynamic classifier
selection method to build ensembles using accuracy and diversity. Neural Networks,
2006. SBRN ’06. Ninth Brazilian Symposium on, páginas 36–41, 2006.
[129] S. Santini e R. Jain. Similarity measures. Pattern Analysis and Machine Intelligence,
IEEE Transactions on, 21(9):871–883, 1999.
[130] E. M. Santos. Static and Dynamic Overproduction and Selection of Classifier
Ensembles with Genetic Algorithms. Tese de Doutorado, École de Technologie
Supérieure, Université du Québec, Montreal, 2008.
[131] R. E. Schapire, Y. Freund, P. Bartlett, e W. S. Lee. Boosting the margin: A New
Explanation for the Effectiveness of Voting Methods. The Annals of Statistics,
26(5):1651–1686, 1998.
[132] E. Stamatatos. A survey of modern authorship attribution methods. J. Am. Soc.
Inf. Sci. Technol., 60(3):538–556, 2009.
[133] J. Tarŕıo-Saavedra, S. Naya, M. Francisco-Fernández, J. López-Beceiro, e R. Ar-
tiaga. Functional nonparametric classification of wood species from thermal data.
Journal of Thermal Analysis and Calorimetry, 104(1):87–100, 2011.
[134] L. Thomas, L. Mili, C. A. Shaffer, e E. Thomas. Defect detection on hardwood logs
using high resolution three-dimensional laser scan data. International Conference
on Image Processing - ICIP, páginas 243–246, 2004.
[135] J. Y. Tou, P. Y. Lau, e Y. H. Tay. Computer vision-based wood recognition system.
International Workshop on Advanced Image Technology, páginas 197–202, 2007.
[136] J. Y. Tou, Y. H. Tay, e P. Y. Lau. Gabor filters and grey-level co-occurrence
matrices in texture classification. MMU International Symposium on Information
and Communications Technologies, páginas 197–202, 2007.
[137] J. Y. Tou, Y. H. Tay, e P. Y. Lau. One-dimensional grey-level co-occurrence matri-
ces for texture classification. International Symposium on Information Technology
(ITSim 2008), páginas 1–6, 2008.
154
[138] J. Y. Tou, Y. H. Tay, e P. Y. Lau. A comparative study for texture classification te-
chniques on wood species recognition problem. International Conference on Natural
Computation, 5, páginas 8–12, 2009.
[139] J. Y. Tou, Y. H. Tay, e P. Y. Lau. Rotational invariant wood species recognition th-
rough wood species verification. First Asian Conference on Intelligent Information
and Database Systems, páginas 115–120, 2009.
[140] G. Tsoumis. Science and Technology of Wood: structure, properties, utilization.
Champan & Hall, New York, 1991.
[141] M. Tuceryan e A. K. Jain. Texture Analysis, caṕıtulo 2.1, páginas 235–276. World
Scientific, Singapore, 1 edition, 2005.
[142] V. N. Vapnik. Statistical learning theory. Adaptive and Learning Systems for Signal
Processing, Communications, and Control, New York, 1998. John Wiley & Sons Inc.
[143] A. Vedaldi e B. Fulkerson. VLFeat: An open and portable library of computer
vision algorithms, 2008.
[144] A. C. Wiedenhoeft e R. B. Miller. Structure and Function of Wood, caṕıtulo 2,
páginas 9–33. CRC Press, Washington, D.C., 2005.
[145] E. O. Wiley. Phylogenetics: the theory and practice of phylogenetic systematics.
John Wiley & Sons, Inc., US, 1981.
[146] K. Woods, W. P. Kegelmeyer, Jr., e K. Bowyer. Combination of multiple classifiers
using local accuracy estimates. IEEE Trans. Pattern Anal. Mach. Intell., 19(4):405–
410, 1997.
[147] H. Yang, I. R. Lewis, e P. R. Griffiths. Raman spectrometry and neural networks
for the classification of wood types. 2. kohonen self-organizing maps. Spectrochimica
Acta Part A: Molecular and Biomolecular Spectroscopy, 55(14):2783–2791, 1999.
[148] Y. Yang e S. Newsam. Comparing sift descriptors and gabor texture features for
classification of remote sensed imagery. Image Processing, 2008. ICIP 2008. 15th
IEEE International Conference on, páginas 1852–1855, 2008.
[149] W. Yu, G. Sommer, e K. Daniilidis. Using skew gabor filter in source signal sepa-
ration and local spectral multi-orientation analysis. 1:I–462–I–469, 2004.
[150] J. Zhang e T. Tan. Brief review of invariant texture analysis methods. Pattern
Recognition, 35(3):735–747, 2002.
155
[151] G. Zhao e M. Pietikäinen. Dynamic texture recognition using local binary patterns
with an application to facial expressions. IEEE Transactions on Pattern Analysis
and Machine Intelligence, 29(6):915–928, 2007.
[152] J. Zhu, S. C.H. Hoi, M. R. Lyu, e S. Yan. Near-duplicate keyframe retrieval by
nonrigid image matching. Proceedings of the 16th ACM international conference on
Multimedia, MM ’08, páginas 41–50, New York, NY, USA, 2008. ACM.
[153] J. Zhu, M. Vai, e P. Mak. A new enhanced nearest feature space (enfs) classifier
for gabor wavelets features-based face recognition. David Zhang e AnilK. Jain, edi-
tors, Biometric Authentication, volume 3072 of Lecture Notes in Computer Science,
páginas 124–130. Springer Berlin Heidelberg, 2004.
APÊNDICE A
BASE DE IMAGENS
Durante o desenvolvimento deste trabalho, identificou-se um reduzido número de bases
constrúıdas com foco no reconhecimento de espécies florestais, sendo CAIRO e FRIM as
mais referenciadas nesta área (vide Caṕıtulo 3). Diante da dificuldade para ter acesso
a estas bases e por não ter encontrado referências a bases compostas por imagens mi-
croscópicas, optou-se pela elaboração de um novo conjunto de imagens. A base elaborada
foi publicada em [85] e pode ser requisitada para o desenvolvimento de pesquisas no en-
dereço eletrônico http://web.inf.ufpr.br/vri/forest-species-database. Esta é composta por
112 espécies florestais, cada uma com 20 amostras, num total de 2.240 imagens. Estas
foram capturadas pelo Laboratório de Anatomia da Madeira, do curso de Engenharia
Florestal da Universidade Federal do Paraná (UFPR).
Seguindo as definições inerentes à Anatomia da Madeira (Seção 2.1), as imagens que
compõem a base proposta podem ser agrupadas de diferentes formas (Tabelas A.1 e A.2).
Considerando a divisão baseada no mais alto ńıvel posśıvel tem-se os 2 filos, Gimnosper-
mas e Angiospermas. As imagens de espécies pertencentes a Gimnospermas ainda estão
divididas em 2 classes, 2 ordens, 8 famı́lias, 23 gêneros e 37 espécies. Já as imagens de
espécies pertencentes a Angiospermas estão divididas em 2 classes, 13 ordens, 22 famı́lias,
62 gêneros e 75 espécies.
Tais imagens, como as apresentadas na Figura A.1, foram adquiridas por meio dos
seguintes procedimentos:
• Extração de amostras de peças maiores de madeira para cada uma das espécies,
sendo estas amostras caracterizadas por pequenos blocos com aproximadamente
2cm3;
• Cozimento dos blocos de madeira, por tempo variado de acordo com a espécie flo-
restal, para seu amolecimento;
• Realização dos cortes histológicos (pequenas amostras) de madeira, com espessura
de aproximadamente 25 micras1, de forma paralela à seção transversal (eixo X na
Figura 2.3(a)) e com o emprego de um micrótomo de deslizamento;
• Coloração dos cortes histológicos de madeira pelo processo de tripla coloração com
as substâncias acridina vermelha, crisoidina e azul de astra2;
• Desidratação em série alcoólica ascendente;
1Uma micra equivale à milionésima parte do metro ou 1×10−6 metro.
2Devido a este procedimento de coloração não é posśıvel utilizar caracteŕısticas relacionadas à cor para
a diferenciação das espécies.
157
• Montagem da lâmina para observação com a fixação dos cortes histológicos de ma-
deira entre lâmina e lamı́nula; e
• Coleta das imagens com o aux́ılio de um microscópio Olympus modelo CX40, produ-
zindo imagens com aproximação ótica de 100 vezes e resolução de 1024×768 pixels,
tais como as apresentadas na Figura A.1.
(a) (b)
Figura A.1: Amostras da Base de Imagens: (a) Gimnosperma; (b) Angiosperma.
Observando os exemplos de imagens microscópicas e macroscópicas de uma mesma
espécie na Figura A.2, pode-se perceber diferenças substanciais em seus padrões textu-
rais. Neste sentido, Burger e Richter [14] destacam que muitos aspectos anatômicos da
madeira podem ser identificados macroscopicamente, mas que a observação de imagens
microscópicas permite melhor identificação das estruturas apresentadas.
(a) (b)
Figura A.2: Amostras de ‘Araucaria angustifolia’: (a) Microscópica; (b) Macroscópica.
Diante de tal contexto, a abordagem baseada em padrões texturais permite que se-
jam utilizados os mesmos descritores empregados nos trabalhos com foco em imagens
macroscópicas. Neste sentido, a Seção 4.2 identifica os parâmetros avaliados e os valores
selecionados para cada descritor apresentado na Seção 2.2.
158
Tabela A.1: Gimnospermas: classificação Botânica das espécies.
ID Classe Ordem Famı́lia Gênero Espécie
1 Ginkgofita Ginkgoales Ginkgoaceae Ginkgo biloba
2 Pinopsida Pinales Araucariaceae Agathis becarii
3 Pinopsida Pinales Araucariaceae Araucaria angustifolia
4 Pinopsida Pinales Cephalotaxaceae Cephalotaxus drupacea
5 Pinopsida Pinales Cephalotaxaceae Cephalotaxus harringtonia
6 Pinopsida Pinales Cephalotaxaceae Torreya nucifera
7 Pinopsida Pinales Cupressaceae Calocedrus decurrens
8 Pinopsida Pinales Cupressaceae Chamaecyparis formosensis
9 Pinopsida Pinales Cupressaceae Chamaecyparis pisifera
10 Pinopsida Pinales Cupressaceae Cupressus arizonica
11 Pinopsida Pinales Cupressaceae Cupressus lindleyi
12 Pinopsida Pinales Cupressaceae Fitzroya cupressoides
13 Pinopsida Pinales Cupressaceae Larix lariciana
14 Pinopsida Pinales Cupressaceae Larix leptolepis
15 Pinopsida Pinales Cupressaceae Larix sp
16 Pinopsida Pinales Cupressaceae Tetraclinis articulata
17 Pinopsida Pinales Cupressaceae Widdringtonia cupressoides
18 Pinopsida Pinales Pinaceae Abies religiosa
19 Pinopsida Pinales Pinaceae Abies vejari
20 Pinopsida Pinales Pinaceae Cedrus atlantica
21 Pinopsida Pinales Pinaceae Cedrus libani
22 Pinopsida Pinales Pinaceae Cedrus sp
23 Pinopsida Pinales Pinaceae Keteleeria fortunei
24 Pinopsida Pinales Pinaceae Picea abies
25 Pinopsida Pinales Pinaceae Pinus arizonica
26 Pinopsida Pinales Pinaceae Pinus caribaea
27 Pinopsida Pinales Pinaceae Pinus elliottii
28 Pinopsida Pinales Pinaceae Pinus gregii
29 Pinopsida Pinales Pinaceae Pinus maximinoi
30 Pinopsida Pinales Pinaceae Pinus taeda
31 Pinopsida Pinales Pinaceae Pseudotsuga macrolepsis
32 Pinopsida Pinales Pinaceae Tsuga canadensis
33 Pinopsida Pinales Pinaceae Tsuga sp
34 Pinopsida Pinales Podocarpaceae Podocarpus lambertii
35 Pinopsida Pinales Taxaceae Taxus baccata
36 Pinopsida Pinales Taxodiaceae Sequoia sempervirens
37 Pinopsida Pinales Taxodiaceae Taxodium distichum
159
Tabela A.2: Angiospermas: classificação Botânica das espécies.
ID Classe Ordem Famı́lia Gênero Espécie
38 Gnetopsida Ephedrales Ephedraceae Ephedra californica
39 Magnoliopsida Ericales Lecythidaceae Cariniana estrellensis
40 Magnoliopsida Ericales Lecythidaceae Couratari sp
41 Magnoliopsida Ericales Lecythidaceae Eschweilera matamata
42 Magnoliopsida Ericales Lecythidaceae Eschweleira chartaceae
43 Magnoliopsida Ericales Sapotaceae Chrysophyllum sp
44 Magnoliopsida Ericales Sapotaceae Micropholis guianensis
45 Magnoliopsida Ericales Sapotaceae Pouteria pachycarpa
46 Magnoliopsida Fabales Fabaceae Copaifera trapezifolia
47 Magnoliopsida Fabales Fabaceae Eperua falcata
48 Magnoliopsida Fabales Fabaceae Hymenaea courbaril
49 Magnoliopsida Fabales Fabaceae Hymenaea sp
50 Magnoliopsida Fabales Fabaceae Schizolobium parahyba
51 Magnoliopsida Fabales Fabaceae Pterocarpus violaceus
52 Magnoliopsida Fabales Fabaceae Acacia tucunamensis
53 Magnoliopsida Fabales Fabaceae Anadenanthera colubrina
54 Magnoliopsida Fabales Fabaceae Anadenanthera peregrina
55 Magnoliopsida Fabales Fabaceae Dalbergia jacaranda
56 Magnoliopsida Fabales Fabaceae Dalbergia spruceana
57 Magnoliopsida Fabales Fabaceae Dalbergia variabilis
58 Magnoliopsida Fabales Fabaceae Dinizia excelsa
59 Magnoliopsida Fabales Fabaceae Enterolobium schomburgkii
60 Magnoliopsida Fabales Fabaceae Inga sessilis
61 Magnoliopsida Fabales Fabaceae Leucaena leucocephala
62 Magnoliopsida Fabales Fabaceae Lonchocarpus subglaucescens
63 Magnoliopsida Fabales Fabaceae Mimosa bimucronata
64 Magnoliopsida Fabales Fabaceae Mimosa scabrella
65 Magnoliopsida Fabales Fabaceae Ormosia excelsa
66 Magnoliopsida Fabales Fabaceae Parapiptadenia rigida
67 Magnoliopsida Fabales Fabaceae Parkia multijuga
68 Magnoliopsida Fabales Fabaceae Piptadenia excelsa
69 Magnoliopsida Fabales Fabaceae Pithecellobium jupunba
70 Magnoliopsida Gentianales Rubiaceae Psychotria carthagenensis
71 Magnoliopsida Gentianales Rubiaceae Psychotria longipes
72 Magnoliopsida Lamiales Bignoniaceae Tabebuia rosea alba
73 Magnoliopsida Lamiales Bignoniaceae Tabebuia sp
74 Magnoliopsida Lamiales Oleaceae Ligustrum lucidum
75 Magnoliopsida Laurales Lauraceae Nectandra rigida
76 Magnoliopsida Laurales Lauraceae Nectandra sp
77 Magnoliopsida Laurales Lauraceae Ocotea porosa
78 Magnoliopsida Laurales Lauraceae Persea racemosa
79 Magnoliopsida Magnoliales Annonaceae Porcelia macrocarpa
80 Magnoliopsida Magnoliales Magnoliaceae Magnolia grandiflora
Continua na próxima página
160
continuação da página anterior
ID Classe Ordem Famı́lia Gênero Espécie
81 Magnoliopsida Magnoliales Magnoliaceae Talauma ovata
82 Magnoliopsida Myrtales Melastomataceae Tibouchiana sellowiana
83 Magnoliopsida Myrtales Myristicaceae Virola oleifera
84 Magnoliopsida Myrtales Myrtaceae Campomanesia xanthocarpa
85 Magnoliopsida Myrtales Myrtaceae Eucalyptus globulus
86 Magnoliopsida Myrtales Myrtaceae Eucalyptus grandis
87 Magnoliopsida Myrtales Myrtaceae Eucalyptus saligna
88 Magnoliopsida Myrtales Myrtaceae Myrcia racemulosa
89 Magnoliopsida Polygalales Vochysiaceae Erisma uncinatum
90 Magnoliopsida Polygalales Vochysiaceae Qualea sp
91 Magnoliopsida Polygalales Vochysiaceae Vochysia laurifolia
92 Magnoliopsida Proteales Proteaceae Grevillea robusta
93 Magnoliopsida Proteales Proteaceae Grevillea sp
94 Magnoliopsida Proteales Proteaceae Roupala sp
95 Magnoliopsida Rosales Moraceae Bagassa guianensis
96 Magnoliopsida Rosales Moraceae Brosimum alicastrum
97 Magnoliopsida Rosales Moraceae Ficus gomelleira
98 Magnoliopsida Rosales Rhamnaceae Hovenia dulcis
99 Magnoliopsida Rosales Rhamnaceae Rhamnus frangula
100 Magnoliopsida Rosales Rosaceae Prunus sellowii
101 Magnoliopsida Rosales Rosaceae Prunus serotina
102 Magnoliopsida Rubiales Rubiaceae Faramea occidentalis
103 Magnoliopsida Sapindales Meliaceae Cabralea canjerana
104 Magnoliopsida Sapindales Meliaceae Carapa guianensis
105 Magnoliopsida Sapindales Meliaceae Cedrela fissilis
106 Magnoliopsida Sapindales Meliaceae Khaya ivorensis
107 Magnoliopsida Sapindales Meliaceae Melia azedarach
108 Magnoliopsida Sapindales Meliaceae Swietenia macrophylla
109 Magnoliopsida Sapindales Rutaceae Balfourodendron riedelianum
110 Magnoliopsida Sapindales Rutaceae Citrus aurantium
111 Magnoliopsida Sapindales Rutaceae Fagara rhoifolia
112 Magnoliopsida Sapindales Simaroubaceae Simarouba amara
