 
 
 
 
Abstract 
 
 Authorship attribution is the methodology of determining 
the specific author of a text originating from a corpus of texts 
created by one or multiple authors. By analyzing and 
measuring specific textual features, one can construct a profile 
to identify a specific author. This type of identification of 
authors via their writing style is one of the most engaging 
problems for researchers of stylometry. As it relates to 
authorship identification, the primary goal of our research is to 
identify an author of text through analysis of stylistic traits. We 
present a new feature that demonstrates initial success in 
identifying correct authors of text through the analysis of those 
authorsâ€™ text corpus. Byte Level N-Gram Term Frequency 
Inverse Token Frequency (BLN-Gram-TF-ITF) is successfully 
implemented on a set of text corpus and shows promising 
outcomes. 
 
 
Keywords: Authorship; TFIDF; N-grams; Stylometry; Text 
features.  
1. Introduction 
Biometrics is the science of analyzing human 
characteristics by using automated methods in a way that 
gives every person a unique profile. Biometric 
identification is a method to discover or verify the 
identity of who we claim to be through analysis of 
physiological and behavioral traits [1]. In the same way, 
writing style is unique for each human, even when that 
individual consciously attempts to alter his writing style. 
This phenomena is largely due to the individualâ€™s 
unconscious writing style which influences the text via 
traits specific to that author [2]. Roman et al conducted a 
survey on different behavioral biometrics [3]. 
Literary scholars have been the foremost experts on 
authorship. However, with the digital age and the 
evolution of Information Retrieval (IR), Machine 
Learning techniques, Natural Language Processing 
(NLP) and statistical analysis of style in literature, there 
are increasingly significant contributions from other 
research groups, such as computer scientists and 
statisticians. Further, the increased usage of the Internet 
and the plethora of continually growing digital media, 
such as blogs, email, forums, etc., have highlighted the 
need for authorship attribution studies.  
2. Related Work 
Authorship attribution is one of the oldest IR 
problems, and remains an active area of research, with 
many potential applications in forensics [4].  
By definition, authorship identification is the science 
of identifying an author of unclaimed and disputed 
document. Writers tend to leave idiosyncrasies in their 
writings, even if they intended not to do so. An authorâ€™s 
combined idiosyncrasies are more commonly known as 
â€œwriting styleâ€ [1]. 
Mendenhall attempted to quantify writing styles by 
studying the plays of Shakespeare [5]. Later, Zipf [6] 
and Yule [7, 8] were the first to apply statistical analysis 
on text for the purpose of  finding distinguishing features 
of authors. Mosteller and Wallace were the first to use 
computers for authorship analysis [9]. 
From a machine learning perspective, the authorship 
identification problem can be viewed as a multi-class 
single-label text-categorizing conundrum. Provided with 
a disputed text and a set of potential authors, the 
researcher is tasked with identifying the correct author. 
3.  Authorship Attribution 
In general, authorship identification tasks can be 
categorized as the following: 
â€¢ Authorship Verification: Given a text, one must 
decide if that text should or should not be attributed 
to a specific author [1]. 
â€¢ Plagiarism Detection: Identifying copied materials 
from a source to a target without reference, by 
finding similarities between the two texts [10]. 
â€¢ Author Profiling or Characterization: Extraction of 
authorship information from a text or texts [11]. 
â€¢ Authorship Recognition: Correct selection of an 
author from a set of potential authors, whom most 
likely authored a text. 
â€¢ Detection of Stylistic Inconsistencies: Detecting 
changes in traits where two or more authors are 
involved in authoring a text [2]. 
Currently, wide ranges of authorship attribution 
techniques are implemented for practical applications.  
For example, the analysis of instant messages for 
evidence of a crime and identification of its suspect is 
already practiced in courts of law [12]. It comes as no 
surprise then that researchers continue to analyze instant 
BLN-Gram-TF-ITF as a new Feature for Authorship Identification  
 
 
 
 Nawaf Ali1, Matthew Price2, Roman Yampolskiy3 
Computer Engineering and Computer Science Department1, 2, 3 
University of Louisville, Louisville, Kentucky. USA 
nawaf.ali@louisville.edu1, mepric05@louisville.edu2, roman.yampolskiy@louisville.edu3 
 
 
2014 ASE BIGDATA/SOCIALCOM/CYBERSECURITY Conference, Stanford University, May 27-31, 2014
Â©ASE 2014 ISBN: 978-1-62561-000-3 2
 
 
 
messaging and chatting session text for the benefit of 
authorship analysis [13-17]. Additional studies include 
code authorship in which the researcher attempts to 
discover authorship traits of the originator of source code 
[18-22]. Ali et al., has also implemented authorship 
identification for chat bots [23] and studied these bots 
for behavioral drift, which is confirmed to have occurred 
in their experiments [24]. 
3.1  Text Features 
Hundreds of text features for the use of defining 
authorship style were identified by previous researchers. 
While not all features performed well for authorship 
attribution, two features are recognized to perform better 
than others. These are the Term Frequency Inverse 
Document Frequency (TF-IDF) and N-grams. 
3.1.1  TF-IDF 
TF-IDF is one of the most widely used features in 
stylometry; this technique assigns a value to each term or 
token representing a weight for that token. For example, 
a word that occurs in every document in a corpus will 
have no value classifying the corpus. On the other hand, 
a token occurring in a smaller set of documents will have 
a higher value in the classifying process. 
In the Information Retrieval domain, vector space 
model elements represent corpus documents. After 
tokenizing and stemming these documents, Euclidean 
space axes represent each token. These documents are 
vectors in this n-dimensional space. For each token 
(term) in document (d), with (N) documents one can 
define the Inverse Document Frequency (IDF) as: 
IDF = 1 + log !!
!
    (1) 
The term (nt / N) in equation 1 represents the rarity of 
the term (t), such that (nt) is the number of occurrences 
for term (t) in document (n) over occurrence of (t) over 
all documents (N). This rarity measure is also considered 
an importance score for that term. 
Term Frequency (TF) is another measure for 
calculating the number of times term (t) occurs in 
document (d) relative to the total number of terms in that 
document as shown in equation 2. 
TF = !"#$(!,!!)
!!
    (2) 
  
Such that freq(t,dt) will calculate the frequency of term 
(t) in document (dt). ||dt|| is the number of terms (tokens) 
in document (dt) [25]. 
So the TF-IDF will be:  
TF-IDF = ğ‘‡ğ¹Ã—ğ¼ğ·ğ¹   (3) 
 
Other form of the TF-IDF will have different IDF 
calculation. See equation 4. 
IDF = log Â ( !
!!!!
)     (4) 
In this equation, the integer one is added to the 
denominator to avoid division by zero in the event that 
the term frequency for that document is zero.  
Assuming a term (t) appears in all the documents in 
the corpus, this will lead to the values of ||N|| and (nt) to 
be the same. The log will be zero, and the IDF will equal 
1 from equation 1. The TF-IDF will be equal to TF in 
this case, and a value close to zero from equation 4. 
The proximity of the TF-IDF value to zero directly 
corresponds to the weight this term has to classify the 
chosen document [26]. A TF-IDF value closer to zero 
corresponds to a decreased weight for the term. 
3.1.2  N-Grams 
When dealing with N-Grams, there are two types we 
are concerned with: Token (word) level grams, and the 
byte (character) level grams. 
 
A. Token N-Grams 
 
Token N-Grams are one of the first text features used 
in Stylometry. In this model, a researcher selects N 
successive words or tokens from the text, as if one has a 
sliding window of size N moving over the text. In all 
cases, N is a positive number and will determine the 
sliding window size. When N=1, the resulting gram will 
be what is known as a Bag Of Words (BOW). Likewise 
the term bigram is used for N=2, and trigrams for N=3 as 
seen in Fig 1. 
Different studies have shown different preferences for 
choosing N. In general, best results for authorship 
attribution are achieved with values of N>=3 [4, 27].  
 
Figure 1: Token- based N-Gram Example for N=3 
 
B. Byte Level N-Grams 
 
Byte Level N-Grams are a very useful feature for 
studying the style of authors. Additionally, they are 
substantially utilized for encoded messages deciphering. 
Investigating for possible bigrams and trigrams of 
characters as will as the frequencies of those N-grams, 
can lead one to decipher the text and obtain the original 
message. 
Stamatatos et al., used byte level N-grams to identify 
the developer of source code [28] used the same 
technique to detect plagiarism [29]. 
Generally, N-grams, whether token or byte level, 
outperformed other features when used for authorship 
attribution.  
2014 ASE BIGDATA/SOCIALCOM/CYBERSECURITY Conference, Stanford University, May 27-31, 2014
Â©ASE 2014 ISBN: 978-1-62561-000-3 3
 
 
 
 
Figure 2:  Character N-Gram for N=3 
4. Byte Level N-Gram Term Frequency Inverse 
Token Frequency (BLN-Gram-TF-ITF) 
The idea behind this feature originated from observing 
the importance of the N-Gram feature and the TF-IDF 
measure for classification. Several research studies show 
increased accuracy when using either one of these two 
features [8, 17, 26, 27, 30, 31]. Evaluating the text as 
characters rather than tokens as explained in Fig. 2, the 
Byte-Level N-Gram slides over the characters and forms 
trigrams when the value of N =3 [28]. 
BLN-Gram-TF-ITF implements the idea of TF-IDF 
but with a different perspective. In this case, the token is 
handled the same way TF-IDF handles documents, the 
terms are handled the same way TF-IDF handles words, 
and the terms are the trigram generated in the trigram 
list. 
For example, let us assume that the following text is 
saved in List1: 
List1=â€I will try to check my feature using this text as 
an exampleâ€, List1 will be converted to lower case, so 
the new list will be: 
List2=â€i will try to check my feature using this text as 
an exampleâ€. If N=3 is selected then the trigram of this 
list1 will be: 
Tri-gram-List= ['i w', ' wi', 'wil', 'ill', 'll ', 'l t', ' tr', 'try', 
'ry ', 'y t', ' to', 'to ', 'o c', ' ch', 'che', 'hec', 'eck', 'ck ', 'k m', 
' my', 'my ', 'y f', ' fe', 'fea', 'eat', 'atu', 'tur', 'ure', 're ', 'e u', 
' us', 'usi', 'sin', 'ing', 'ng ', 'g t', ' th', 'thi', 'his', 'is ', 's t', ' 
te', 'tex', 'ext', 'xt ', 't a', ' as', 'as ', 's a', ' an', 'an ', 'n e', ' 
ex', 'exa', 'xam', 'amp', 'mpl', 'ple']. 
For each unique term in Tri-Gram list, the TF-ITF will 
be calculated as followed: 
ğ‘‡ğ¹ = !"#$(!,!!!"#$)
!!!"#$
   (5) 
 
The calculated frequency is based on the number of 
times a term generated by the trigram, divided by length 
of trigram list. The ITF will be calculated as follows: 
ğ¼ğ‘‡ğ¹ = log Â ( !"
!! Â !"#! Â !
)   (6) 
Where ||NT|| is the total number of tokens in the 
corpus, and the (nT with t) is the number of tokens (T) 
containing the term (t), which corresponds to the IDF 
frequency of documents having token T. Fig.3 presents 
the flow chart for BLN-Gram-TF-ITF. 
5. Experiments and Results 
Experiments were conducted on two sets of corpora. 
One used the chat bot corpus used in [32] while the other 
utilized human authors from Gutenberg project [33]. The 
same experimental settings and data sizes were used to 
compare results.  
 
5.1  Chat bot Corpus experiments 
 
The chat botâ€™s corpus was configured for six chat 
bots, which consisted of 10 text files for each chat bot at 
4KB each. Following the flow chart in Fig. 3, the first 
step loaded the text files and preprocessed them. Next, 
BLN-G-Gram-TF-ITF feature was extracted for each 
chat bot. With (K=5)-Fold cross validation and KNN 
classification configured for N=4, the experiments 
outperformed the results obtained by Ali et al [32]. 
Table 1 displays the results of applying a t-test to 
analyze results for statistical significance. 
 
Table 1: T-Test result for Statistical Significant 
95% CI for difference (0.0385, 0.4275) 
T-Test of difference 0 (vs. not =) T-Value 2.59 
P-Value 0.022 DF 13 
Figure 3: The Byte Level N-Gram Term Frequency Inverse Token 
Frequency Flow Chart 
For each author, read the files 
 
For each file, tokenize, lower case, and 
remove punctuation 
  
Generate the Byte N-Gram 
  
For each unique term, calculate the TF-ITF  
  
Save the calculated TF-ITF for each 
corresponding author 
  
Read the saved TF-ITF and classify using 
K-Nearest Neighbor (KNN) classifier 
  
2014 ASE BIGDATA/SOCIALCOM/CYBERSECURITY Conference, Stanford University, May 27-31, 2014
Â©ASE 2014 ISBN: 978-1-62561-000-3 4
 
 
 
With an average accuracy of 83.33% and a maximum 
accuracy of 91.67%, the BLN-Gram-TF-ITF feature 
shows a promising start for further experiments on 
human corpora. Fig. 4 shows the comparison between 
authorship experiments using JGAAP [34] and the BLN-
Gram-TF-ITF feature within the same data set. 
 
Figure 4: BLN-Gram-TF-ITF vs. JGAAP average and Maximum 
Accuracies 
 
5.2   Human Corpus Experiments 
 
Six Authors were selected for the Experiments, and 10 
files per author were used with file sizes from 50 words 
to 1000 words per file. The corpus used the following 
books: 
â€¢ Emma by Jane Austen. 
â€¢ Paradise Lost by John Milton. 
â€¢ The Man who was Thursday by G. K. Chesterton 
â€¢ The Wisdom of Father Brown by G. K. Chesterton. 
â€¢ The Parentâ€™s Assistant by Maria Edgeworth. 
â€¢ Moby Dick by Herman Melville. 
â€¢ Hamlet by William Shakespeare. 
 
Figure 5: File size in word counts vs. average accuracy achieved for 
N=3  
 
The experiments were configured to evaluate files 
with sizes beginning with 50 words per file, and stepping 
up 50 per file, and stepping up 50 words each iteration 
until reaching 1000 word per file. A sample testing of 20 
runs for each set was conducted with 5 cross-validations 
for a total of 100 outcomes in each case. 
 
Figure 5 shows the resulting accuracy corresponding 
to each set of file size experiments. 
The accuracy increased with more words used in the 
experiments as expected. The overall accuracy of the 
proposed feature is notably high when considering that 
the experiments only used this feature alone. 
 
Another version of this feature was constructed by 
eliminating the spaces in the trigrams. The trigram list 
previously created was reconfigured to leave no spaces 
in the resulting trigram terms. 
Additionally, more than trigrams were experimented 
with, as N=4 and N=5 were tested too. Fig. 6 presents 
the average accuracy when N=4 with relation to varying 
file sizes. 
 
 
 Figure 6: File size in word counts vs. average accuracy achieved for 
N=4  
 
Fig. 6 represents the average accuracy when using 
N=4, while Fig. 7 represents the results for experiments 
when N=5. 
 Figure 7: File size in word counts vs. average accuracy achieved for 
N=5 
 
0	 Â 
10	 Â 
20	 Â 
30	 Â 
40	 Â 
50	 Â 
60	 Â 
70	 Â 
80	 Â 
90	 Â 
100	 Â 
JGAAP BLN-Gram-TF-ITF 
A
cu
ur
ac
y 
%
 
BLN-Gram-TF-ITF vs. JGAAP 
Average 
Maximum 
0%	 Â 
10%	 Â 
20%	 Â 
30%	 Â 
40%	 Â 
50%	 Â 
60%	 Â 
70%	 Â 
80%	 Â 
90%	 Â 
100%	 Â 
50
	 Â 
75
	 Â 
10
0	 Â 
15
0	 Â 
20
0	 Â 
25
0	 Â 
30
0	 Â 
35
0	 Â 
40
0	 Â 
45
0	 Â 
50
0	 Â 
55
0	 Â 
60
0	 Â 
65
0	 Â 
70
0	 Â 
75
0	 Â 
80
0	 Â 
85
0	 Â 
90
0	 Â 
95
0	 Â 
10
00
	 Â 
A
ve
ra
ge
  A
cc
ur
ac
y 
 
File Word Count 
Corpus File Size vs. Average Accuracy for N=3 
0%	 Â 
10%	 Â 
20%	 Â 
30%	 Â 
40%	 Â 
50%	 Â 
60%	 Â 
70%	 Â 
80%	 Â 
90%	 Â 
100%	 Â 
50
	 Â 
75
	 Â 
10
0	 Â 
15
0	 Â 
20
0	 Â 
25
0	 Â 
30
0	 Â 
35
0	 Â 
40
0	 Â 
45
0	 Â 
50
0	 Â 
55
0	 Â 
60
0	 Â 
65
0	 Â 
70
0	 Â 
75
0	 Â 
80
0	 Â 
85
0	 Â 
90
0	 Â 
95
0	 Â 
10
00
	 Â 
Av
er
ag
e A
cc
ur
ac
y 
File Word Count 
Corpus File Size vs. Average Accuracy for N=4 
0%	 Â 
10%	 Â 
20%	 Â 
30%	 Â 
40%	 Â 
50%	 Â 
60%	 Â 
70%	 Â 
80%	 Â 
90%	 Â 
100%	 Â 
50
	 Â 
75
	 Â 
10
0	 Â 
15
0	 Â 
20
0	 Â 
25
0	 Â 
30
0	 Â 
35
0	 Â 
40
0	 Â 
45
0	 Â 
50
0	 Â 
55
0	 Â 
60
0	 Â 
65
0	 Â 
70
0	 Â 
75
0	 Â 
80
0	 Â 
85
0	 Â 
90
0	 Â 
95
0	 Â 
10
00
	 Â 
A
ve
ra
ge
 A
cc
ur
ac
y 
File Word Count 
Corpus File Size vs. Average Accuracy for N=5 
2014 ASE BIGDATA/SOCIALCOM/CYBERSECURITY Conference, Stanford University, May 27-31, 2014
Â©ASE 2014 ISBN: 978-1-62561-000-3 5
 
 
 
As a comparison with the three experiments, Fig. 8 displays 
all the three line charts on a single graph. It is clear that all 
lines follow the same pattern, lower accuracy for small files, 
and have positive correlation of file sizes increases and 
accuracy. When N=5 the accuracy was highest for smaller files 
but was relatively the same as N=4 for files within 600 words. 
Overall, N=3 was the worst for small and large files but was 
like N=4 for files between 400-600 words. 
 
Figure 8: File size in word counts vs. average accuracy achieved for 
N=3, 4, and 5 
6. Conclusions and Future Work 
 
The BLN-Gram-TF-ITF was tested for the 
identification of text originators for both chat bots and 
human authors. The feature showed an improved 
accuracy when used over same data set experimented by 
[32].  
Different file sizes affected the accuracy of identifying 
authors. Files with word counts exceeding 300 words 
showed an accuracy of 96.7%. For files with word count 
of 200 and 100 words, the average accuracy achieved 
dropped to 91.7% and 75.0% respectively. 
A new version of the feature was tested by eliminating 
spaces in the trigrams as well as conducting additional 
experiments conducted for N=4 and N=5 for the N-Gram 
generation. The experiments demonstrated that accuracy 
was best when N=5 for small files and large files, while 
both N=3 or N=4 out perform N=5 for files with word 
counts between 400 and 600 words.  
More experiments and tests are needed with an 
increased number of authors. Additionally, investigation 
with the presence or absence of function words, which 
are the most frequent words used in English are 
necessary since the experiments conducted contained 
these words. 
Combining more features with the BLN-Gram-TF-ITF 
while experimenting with different classifiers will be the 
next step.  
Finally, we anticipate combining our work with 
continuous computer authentication utilizing multimodal 
biometrics, such as face, voice, keystroke, mouse 
dynamics, and style of writing. 
References 
[1] G. K. Zipf, Selected studies of the principle of relative frequency 
in language. Cambridge, Mass.: Harvard University Press, 1932. 
[2] A. Jain, "Biometric Identification," Communications of the ACM, 
vol. 43, pp. 91-98, 2000. 
[3] R. V. Yampolskiy and V. Govindaraju, "Behavioural biometrics: 
a survey and classification," International Journal of Biometrics 
(IJBM). vol. 1, pp. 81-113, 2008. 
[4] P. Juola, "Authorship attribution," Foundations and Trends in 
information Retrieval, vol. 1, pp. 233-334, 2006. 
[5] T. C. Mendenhall, "THE CHARACTERISTIC CURVES OF 
COMPOSITION," Science, vol. ns-9, pp. 237-246, March 11, 
1887 1887. 
[6] Alan. (2011, June 10). AI Research. Available: http://www.a-
i.com/show_tree.asp?id=59&level=2&root=115 
[7] Z. Chu, S. Gianvecchio, H. Wang, and S. Jajodia, "Who is 
tweeting on Twitter: human, bot, or cyborg?," presented at the 
Proceedings of the 26th Annual Computer Security Applications 
Conference, Austin, Texas, 2010. 
[8] S. Gianvecchio, X. Mengjun, W. Zhenyu, and W. Haining, 
"Humans and Bots in Internet Chat: Measurement, Analysis, and 
Automated Classification," Networking, IEEE/ACM Transactions 
on, vol. 19, pp. 1557-1571, 2011. 
[9] R. Arun, V. Suresh, and C. E. V. Madhavan, "Stopword Graphs 
and Authorship Attribution in Text Corpora," pp. 192-196, 2009. 
[10] ALICE. (2011, June 12). ALICE. Available: 
http://alicebot.blogspot.com/ 
[11] S. G. Efimovich and S. O. Gennadyevich, "Automatic search of 
indicators of text authorship," in Science and Technology, 2003. 
Proceedings KORUS 2003. The 7th Korea-Russia International 
Symposium on, 2003, pp. 185-188 vol.2. 
[12] S. Meyer zu Eissen, B. Stein, and M. Kulig, "Plagiarism 
Detection Without Reference Collections Advances in Data 
Analysis," R. Decker and H. J. Lenz, Eds., ed: Springer Berlin 
Heidelberg, 2007, pp. 359-366. 
[13] A. K. McCallum. (1996). Bow: A toolkit for statistical language  
modeling, text retrieval, classification and clustering. Available: 
http://www.cs.cmu.edu/~mccallum/bow 
[14] O. Angela, "An Instant Messaging Intrusion Detection System 
Framework: Using character frequency analysis for authorship 
identification and validation," in 40th Annual IEEE International 
Carnahan Conferences Security Technology, Lexington, KY, 
2006, pp. 160-172. 
[15] M. B. Malyutov, "Authorship attribution of texts: a review," 
Electronic Notes in Discrete Mathematics, vol. 21, pp. 353-357, 
2005. 
[16] H. G. Loebner. (2012, Jan 3). Home Page of The Loebner Prize. 
Available: http://loebner.net/Prizef/loebner-prize.html 
[17] T. Matsuura and Y. Kanada, "Extraction of authorsâ€™ 
characteristics from Japanese modern sentences via n-gram 
distribution," in Discovery Science, 2000, pp. 315-319. 
[18] H. Mohtasseb and A. Ahmed, "Two-layer classification and 
distinguished representations of users and documents for 
grouping and authorship identification," in Intelligent Computing 
and Intelligent Systems, 2009. ICIS 2009. IEEE International 
Conference on, 2009, pp. 651-657. 
[19] M. Koppel and J. Schler, "Authorship verification as a one-class 
classification problem," presented at the Proceedings of the 
twenty-first international conference on Machine learning, Banff, 
Alberta, Canada, 2004. 
[20] MyBot. (2011, Jan 8). Chatbot Mybot, Artificial Intelligence. 
Available: http://www.chatbots.org/chatbot/mybot/ 
0%	 Â 
10%	 Â 
20%	 Â 
30%	 Â 
40%	 Â 
50%	 Â 
60%	 Â 
70%	 Â 
80%	 Â 
90%	 Â 
100%	 Â 
50
	 Â 
75
	 Â 
10
0	 Â 
15
0	 Â 
20
0	 Â 
25
0	 Â 
30
0	 Â 
35
0	 Â 
40
0	 Â 
45
0	 Â 
50
0	 Â 
55
0	 Â 
60
0	 Â 
65
0	 Â 
70
0	 Â 
75
0	 Â 
80
0	 Â 
85
0	 Â 
90
0	 Â 
95
0	 Â 
10
00
	 Â 
Av
er
ag
e A
cc
ur
ac
y 
File Word Count 
Corpus File Size vs. Average Accuracy 
N=3 
N=4 
N=5 
2014 ASE BIGDATA/SOCIALCOM/CYBERSECURITY Conference, Stanford University, May 27-31, 2014
Â©ASE 2014 ISBN: 978-1-62561-000-3 6
 
 
 
[21] A. Orebaugh, "An Instant Messaging Intrusion Detection System 
Framework: Using character frequency analysis for authorship 
identification and validation," in 40th Annual IEEE International 
Carnahan Conference Security Technology, Lexington, KY, 
2006, pp. 160-172. 
[22] Pace_University. (2011, June, 4th). Stylometry. Available: 
http://utopia.csis.pace.edu/cs615/2006-2007/team2/ 
[23] N. Ali, M. Hindi, and R. V. Yampolskiy, "Evaluation of 
authorship attribution software on a Chat bot corpus," in 
Information, Communication and Automation Technologies 
(ICAT), 2011 XXIII International Symposium on, 2011, pp. 1-6. 
[24] N. Ali, D. Schaeffer, and R. V. Yampolskiy, "Linguistic Profiling 
and Behavioral Drift in Chat Bots," in Midwest Artificial 
Intelligence and Cognitive Science Conference, 2012, p. 27. 
[25] M. Kantardzic, Data mining: concepts, models, methods, and 
algorithms: Wiley-IEEE Press, 2011. 
[26] J. Ramos, "Using tf-idf to determine word relevance in document 
queries," in Proceedings of the First Instructional Conference on 
Machine Learning, 2003. 
[27] V. KeÅ¡elj, F. Peng, N. Cercone, and C. Thomas, "N-gram-based 
author profiles for authorship attribution," in Proceedings of the 
Conference Pacific Association for Computational Linguistics, 
PACLING, 2003, pp. 255-264. 
[28] G. Frantzeskou, E. Stamatatos, S. Gritzalis, C. E. Chaski, and B. 
S. Howald, "Identifying authorship by byte-level n-grams: The 
source code author profile (scap) method," International Journal 
of Digital Evidence, vol. 6, pp. 1-18, 2007. 
[29] E. Stamatatos, "Intrinsic plagiarism detection using character n-
gram profiles," threshold, vol. 2, pp. 1,500, 2009. 
[30] A. Mohan, I. M. Baggili, and M. K. Rogers, "Authorship 
attribution of SMS messages using an N-grams approach," 
CERIAS Tech Report 20112010. 
[31] J. Houvardas and E. Stamatatos, "N-Gram Feature Selection for 
Authorship Identification," in Artificial Intelligence: 
Methodology, Systems, and Applications. vol. 4183, J. Euzenat 
and J. Domingue, Eds., ed: Springer Berlin Heidelberg, 2006, pp. 
77-86. 
[32] N. Ali, M. Hindi, and R. V. Yampolskiy, "Evaluation of 
authorship attribution software on a Chat bot corpus," in XXIII 
International Symposium on Information, Communication and 
Automation Technologies (ICAT), Sarajevo, Bosnia and 
Herzegovina, 2011, pp. 1-6. 
[33] Gutenberg. (2012, Dec, 20). Project Gutenberg. Available: 
http://www.gutenberg.org 
[34] P. Juola. (2011, July, 4th). Java Authorship Attribution 
Application. Available: 
http://evllabs.com/jgaap/w/index.php/Main_Page 
2014 ASE BIGDATA/SOCIALCOM/CYBERSECURITY Conference, Stanford University, May 27-31, 2014
Â©ASE 2014 ISBN: 978-1-62561-000-3 7
