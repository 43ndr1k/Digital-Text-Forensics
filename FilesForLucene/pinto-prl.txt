Accepted Manuscript
A Graph-Based Multi-Level Linguistic Representation for Document Under-
standing
David Pinto, Helena Gómez-Adorno, Darnes Vilariño, Vivek Kumar Singh
PII: S0167-8655(13)00469-8
DOI: http://dx.doi.org/10.1016/j.patrec.2013.12.004
Reference: PATREC 5899
To appear in: Pattern Recognition Letters
Please cite this article as: Pinto, D., Gómez-Adorno, H., Vilariño, D., Singh, V.K., A Graph-Based Multi-Level
Linguistic Representation for Document Understanding, Pattern Recognition Letters (2013), doi: http://dx.doi.org/
10.1016/j.patrec.2013.12.004
This is a PDF file of an unedited manuscript that has been accepted for publication. As a service to our customers
we are providing this early version of the manuscript. The manuscript will undergo copyediting, typesetting, and
review of the resulting proof before it is published in its final form. Please note that during the production process
errors may be discovered which could affect the content, and all legal disclaimers that apply to the journal pertain.
  
A Graph-Based Multi-Level Linguistic Representation
for Document Understanding
David Pintoa, Helena Gómez-Adornoa, Darnes Vilariñoa, Vivek Kumar
Singhb
aBenemérita Universidad Autonóma de Puebla
Faculty of Computer Science, Mexico
Tel. (+52-222)2295500 Ext. 7223x159
bDepartment of Computer Science
South Asian University, New Delhi, India
Phone: (+91-11)24195148
Abstract
Document understanding goal requires discovery of meaningful patterns in
text, which in turn requires analyzing documents and extracting information
useful for a purpose. The documents to be analyzed are expected to be repre-
sented in some way. It is true that different representations of the same piece
of text might have different information extraction outcomes. Therefore, it
is very important to propose a reliable text representation schema that may
incorporate as many features as possible, and at the same time provides use
of efficient document understanding algorithms. In this paper, we propose
a graph-based representation of textual documents that employs different
levels of formal representation of natural language. This schema takes into
account different linguistic levels, such as lexical, morphological, syntactical
and semantics. The representation schema proposed is accompanied with a
Email addresses: dpinto@cs.buap.mx (David Pinto), helena.adorno@gmail.com
(Helena Gómez-Adorno), darnes@cs.buap.mx (Darnes Vilariño), vivekks12@gmail.com
(Vivek Kumar Singh)
Preprint submitted to Pattern Recognition Letters December 5, 2013
  
proposal for a technique which allows to extract useful text patterns based on
the idea of minimum paths in the graph. The efficiency of the representation
schema proposed has been tested in one case of study (Question-Answering
for machine Reading Evaluation - QA4MRE), and the results of experiments
carried in it, are described. The results obtained show that the proposed
graph-based multi-level linguistic representation schema may be successfully
used in the broader framework of document understanding.
Keywords: Text mining, Text representation, Graph-based representation
1. Introduction1
A huge amount of information produced on a daily basis is found in2
different forms of natural language written texts, such as magazines, books,3
e-books, journals, technical reports, etc. In fact, we are now overwhelmed4
with textual data, which increases every other day. The explosive growth5
in the number of such documents needs development of effective approaches6
to explore, analyze, and discover knowledge from documents. Developing7
automated tools for machine reading by discovering patterns and extracting8
knowledge from texts is one of the most important goals of Text Mining9
(TM) research. And the usual assumption in it is that texts are represented10
in some kind of structure.11
The present research work is mainly concerned with the construction of12
a suitable text representation model based on graphs, that can facilitate dis-13
covering of important text patterns from it. We propose to state and demon-14
strate that the features (text patterns) so discovered can be used in different15
tasks associated to document understanding (such as for document classi-16
2
  
fication, information retrieval, information filtering, information extraction17
and question answering).18
The text pattern discovering technique proposed here is based on the19
traversal of the graph representation of documents, using the shortest paths.20
This text pattern discovery is used in our experimental case study for estimat-21
ing similarities between pairs of texts. The case study of question answering22
validation for reading comprehension tests presented here demonstrates the23
working and efficacy of our framework. The results of experimental work24
reported are analyzed and key observations clearly stated.25
In summary, this research work presents a new text representation schema26
useful for mining documents, exploiting their lexical, syntactic, morphologic27
and semantic information. The representation schema is built over a syn-28
tactic analysis developed through a dependency parser for all the sentences29
in the document, including further morphologic and semantic information.30
The final result obtained is an enriched output in the form of a graph that31
represents the input document in the form of a multiple level formal rep-32
resentation of natural language sentences. The graph-based representation33
schema and the similarity measure proposed here, enables a more effective34
and efficient text mining process.35
The rest of the paper is organized as follows. Section 2 presents a litera-36
ture survey on the different text representation schemata proposed. It also37
emphasizes the contribution of using graph-based structures in the text rep-38
resentation research field. Section 3 explains in detail the graph-based text39
representation schema proposed. The diverse features that may be included40
into this representation are discussed along with suitable examples. Section41
3
  
4 describes our proposal of an efficient method for discovering texts patterns42
from the graph-based representation of text documents. Section 5 presents43
the performance assessment of the proposed schema of text representation,44
in the particular case study of QA4MRE. It first describes the task and then45
illustrates the process of discovering text patterns. Finally, the results ob-46
tained in the experiments are reported. Section 6 concludes the paper by47
presenting the main contribution and findings of this research work.48
2. State of the art49
The most conventional text representation schemata observed in appli-50
cations like information retrieval, text categorization, authorship attribution51
etc. are: Bag of Words (BoW) [1], n-grams model [2, 3], boolean models52
[4], probabilistic models [5] and vector-space models [6]. The majority of53
these text representations are based on the BoW representation, thus ignor-54
ing the words sequentiality and, hence, the meaning implied or expressed in55
the documents as well. This deficiency generally results in failure to perceive56
contextual similarity of text passages. This may be due to the variation of57
words that the passages contain. Another possibility is perceiving contextu-58
ally dissimilar text passages as being similar, because of the resemblance of59
their words.60
For many problems in natural language processing, a graph structure61
is an intuitive, natural and direct way to represent the data. There exist62
several research works that have employed graphs for representing text. A63
comprehensive study of the use of graph-based algorithms for natural lan-64
guage processing and information retrieval can be found in [7]. It describes65
4
  
approaches and algorithmic formulations for: (a) synonym detection and66
automatic construction of semantic classes using measures of graph connec-67
tivity on graphs built from either raw text or user-contributed resources; (b)68
measures of semantic distance on semantic networks, including simple path-69
length algorithms and more complex random-walk methods; (c) textual en-70
tailment using graph-matching algorithms on syntactic or semantic graphs;71
(d) word-sense disambiguation and name disambiguation, including random-72
walk algorithms and semi-supervised methods using label propagation on73
graphs; and (e) sentiment classification using semi-supervised graph-based74
learning or prior subjectivity detection with min-cut/max-flow algorithms.75
Although the work described in [7] covers a wide number of algorithms and76
applications, there exist other relevant works in literature worth mentioning.77
A great interest has grown in the computational linguistic community for78
using this kind of text representation in diverse tasks of natural language79
processing, such as in summarization [8], coreference resolution [9], word80
sense disambiguation [10, 11, 12], word clustering [13, 14], document clus-81
tering [15], etc. The majority of the approaches presented in literature use82
well known graph-based techniques in order to find and exploit the structural83
properties of the graph underlying a particular dataset. Because the graph is84
analyzed as a whole, these techniques have the remarkable property of being85
able to find globally optimal solutions, given the relations between entities.86
For instance, graph-based methods are particularly suited for disambiguat-87
ing word sequences, and they manage to exploit the interrelations among88
the senses in the given context. Unfortunately, most of the research works89
that use graph-based representations propose ad-hoc graph-structures that90
5
  
only work with the particular problem they are dealing with. It is, therefore,91
imperative to attempt to propose a general framework that may be used in92
different contexts with a minimum amount of changes.93
3. A Graph-Based Multi-Level Linguistic Representation Schema94
for Documents95
This section presents our proposed text representation schema that uti-96
lizes multiple linguistic levels of formal definition of natural language texts.97
The motivation for the schema is to capture most of the features present98
in a document, ranging from lexical to semantic level. By including lexical,99
syntactic, morphologic and semantic analysis in the representation, we at-100
tempt to represent how different text components (words, phrases, clauses,101
sentences, etc) are related.102
A labeled di-graph denoted by G = {V,E, LV , LE, α, β} is the starting103
point for representing the different levels of language description. Here:104
• V = {vi|i = 1, ..., n} is a finite set of vertices, V 6= ∅, and n is the105
number of vertices in the graph.106
• E = {(vi, vj)|vi, vj ∈ V, 1 ≤ i, j ≤ n}. Note that the notation (vi, vj)107
indicates that a given order is established.108
• LV is the tag set for the vertices.109
• LE is the tag set for the edges.110
• α : V → LV is a function that assigns tags to vertices.111
• β : E → LE is a function that assigns tags to the directed edges.112
6
  
The representation of each linguistic level together with their association113
with the graph components is described as follows.114
3.1. Lexical level115
At the lexical level we deal with words, one of the most basic units of116
text, describing their meaning in relation to the physical world or to abstract117
concepts, without reference to any sentence in which they may occur. Lexical118
definition attempts to capture everything that a term is used to refer to and,119
as such, is often too vague for many purposes. Therefore, it is used as a120
basic representation which need to be further enriched through higher levels121
of language description.122
To illustrate the lexical level of representation, let us consider the follow-123
ing example sentence:124
Text mining searches patterns in texts.125
Thus, given a di-graph G = {V,E, LV , LE, α, β}, the function α assigns126
lexical words to the vertices. In this case, the LV set (set of all the lexical127
words found in the document to be represented) is LV = {“Text”, “mining”,128
“searches”, “patterns”, “in”, “texts”}. At this point, we have only assigned129
lexical components to the vertices of the graph, thus, the edges are not defined130
yet. In other words, there are no edges to reflect any relationship among the131
words in the graph. This is a basic representation that it is barely useful for132
practical purposes. Therefore, we move ahead to capture and represent the133
morphological level details of the language description.134
7
  
3.2. Morphological level135
At the morphological level we deal with the identification, analysis and136
description of the structure of a given language’s morphemes and other lin-137
guistic units, such as root words, affixes and Parts of Speech (PoS). In order to138
introduce these morphological components into our proposed representation,139
we have obtained the PoS tags using the Stanford Log-linear Part-Of-Speech140
Tagger1. The word lemmas were obtained using the TreeTagger2. It would141
be in order to mention here that the Penn Treebank tag set [16] used in the142
morphological analysis of the texts contains 36 POS tags and 12 other tags143
(for punctuation and currency symbols).144
For the example sentence mentioned in the previous section, we include a145
second level of language description in the graph-based representation by146
considering both, PoS tags and the word lemmas in the graph vertices.147
Thus, LV = {“text NN”, “mining NN”, “search V BZ”, “pattern NNS”,148
“in IN”, “text NNS”}. Note that this representation does not consider the149
original words anymore, since they have been replaced with the correspond-150
ing lemmas.151
3.3. Syntactical level152
At the syntactical level we deal with rules and principles that govern153
the sentence structures. Usually, the lexical parser (or simply: the parser)154
can read various forms of plain text input and can output various analysis155
formats, including part-of-speech tagged text (morphological level), phrase156
1http://nlp.stanford.edu/software/tagger.shtml
2http://www.ims.uni-stuttgart.de/projekte/corplex/TreeTagger/
8
  
structure trees, and a grammatical relations (typed dependency) format. Dif-157
ferent syntactic-based parsers exist in literature, however, for the purposes158
of this work, we have shown the output generated by the Stanford parser3.159
Figure 1 shows the phrase structure tree for the example sentence con-160
sidered in the previous subsections. The tree structure starts from a phrasal161
label S which means “Sentence”, followed by other phrasal labels such as162
NP (Noun Phrase), V P (Verbal Phrase) or PP (Prepositional Phrase). The163
last level of the tree contains the PoS tags followed by the word tagged. The164
definitions make use of the Penn Treebank part-of-speech tags and phrasal165
labels 4. This type of parsing maintains the sequence of the words in the sen-166
tence. It may thus be used for enriching the representation with the parsing167
tags, but word dependencies are still not discovered.168
In Figure 2, we see another type of parsing (grammatical relations or169
typed dependency) applied to the same text of example. The dependencies170
are all binary relations: a grammatical relation holds between a governor171
(also known as a regent or a head) and a dependent. The description of the172
Stanford tags used in this paper are given in [17]. In this type of parsing,173
we may take advantage of the grammatical relation obtained between two174
components of the sentence. With respect to the phrasal parsing, this rep-175
resentation is more compact, as it will be seen in the next subsection. It is176
more flexible for adding higher level language description levels, such as the177
semantic one.178
3http://nlp.stanford.edu/software/lex-parser.shtml
4http://www.cis.upenn.edu/∼treebank/
9
  
S
NP_1 VP_1
JJ_1 NN_1 VBZ_1 NP_2
Text Mining searches NP_3 PP_1
NNS_1 IN_1 NP_4
patterns in NNS_2
texts
Figure 1: Phrase parsing of the sentence: “Text mining searches patterns in texts”
mining_NN text_NN
amod
search_VBZ
nsubj
pat tern_NNS
dobj
in_IN
prep
text_NNS
pobj
Figure 2: Syntactical representation of texts using word lemmas, PoS tags and dependency
tags
3.4. Semantic level179
At the semantic level we deal with the meaning of sentence, i.e., human180
expression stated through language. In general, semantic level refers to inter-181
pretation of signs or symbols used in agents or communities within particular182
circumstances and contexts. In written language, things like paragraph struc-183
10
  
ture, word usage and punctuation bear semantic content. There exist several184
papers in literature approaching the linguistic semantics area, however, in185
this paper we are particularly interested in semantic relationships. A num-186
ber of semantic relationships have been identified by researchers in different187
disciplines such as linguistics, logic, and cognitive psychology [18]. The most188
popular semantic relationships are: antonym, synonym, class inclusion, part-189
whole, and case. Semantic relationships, together with a description of them,190
have been proposed in the work developed by [19].191
Figure 3 shows the manner we can integrate “synonyms” in the graph-192
based representation, however, other semantic relationships could be also in-193
cluded in the graph. For instance, the vertex “text NN” is expanded with two194
synonyms: “document NN” and “manuscript NN”, which are then linked to195
the same vertices in the graph corresponding to the original node “text NN”196
(edge direction is kept).197
3.5. Formalization of the graph-based multi-level linguistic representation198
Given a text T = {t1, t2, · · · , t|T |} with ti a word in the document. Let199
PoS(ti) be the PoS tag of ti, Lem(ti) be the lemma of ti, Sem(ti) be a term200
semantically related with ti, and Dep(ti, tk) be the dependency tag obtained201
by some syntactical parser over the sequence “titk”. The graph-based multi-202
level linguistic representation of T can be formally expressed by a di-graph203
G = {V, E, LV , LE, α, β}, with:204
• V = {vi|i = 1, ..., n} is a finite set of vertices, V 6= ∅, and n is the205
number of vertices in the graph.206
• E = {(vi, vj)|vi, vj ∈ V, 1 ≤ i, j ≤ n}. Note that the notation (vi, vj)207
11
  
mining_NN
text_NN
amod
document_NN
amod
manuscript_NN
amod
search_VBZ
nsubj
pat tern_NNS
dobj
model_NNS
dobj
look_VBZ
nsubj
dobj
dobj
seek_VBZ
nsubj
dobj
dobj
explore_VBZ
nsubj
dobj
dobj
in_IN
prep
prep
text_NNS
pobj
document_NNS
pobj
manuscript_NNS
pobj
Figure 3: Semantical representation of texts using word lemmas, PoS tags, dependency
tags and word synonyms
indicates that a given order is established.208
• LV = {
⋃
i=1,···,|T |(Lem(ti)
⋃
Pos(ti))}209
210
• LE = {
⋃
i,j=1,···,|V | Dep(vi, vj) with vi, vj ∈ V, and (vi, vj) ∈ E}211
• α : V → LV212
• β : E → LE213
Here, we say that LE represents the dependency tag between a pair of214
words. However, it is more practical to have a numeric value as edge label215
in addition to the dependency tag. We, therefore, extend the graph-based216
representation using the following definition of LE.217
12
  
• LE = {∀i,j=1,···,|V |(Dep(vi, vj) : frec(Dep(vi, vj)) + frec((vi, vj)))}218
with vi, vj ∈ V , and (vi, vj) ∈ E219
where frec(x) is a function that counts the ocurrences of x in the entire220
graph.221
Thus, each edge contains the dependency tag together with a number222
that indicates the frequency of that dependency tag plus the frequency of the223
pair of vertices, both calculated over the complete graph. Figure 4 depicts224
the graph that considers the labeling extension in the graph edges. The225
figure shows the representation for the same example discussed throughout226
this paper. In this figure, we have added the numbers associated to the227
frequency of the dependency tag and the frequency of the edge between two228
given vertices as well. This have been done for descriptive purposes, however,229
in the final representation, those values are not stored in the graph, but230
only the sum of the two values. For instance, the edge between the vertices231
“mining NN” and “text NN” has been labeled as “amod:4”, which means232
that “amod” is the dependency tag that exists between these two vertices.233
Additionally, the number 4 means that the “amod” dependency tag appears234
3 times in the graph and the frequency of the pair (“mining NN”, “text NN”)235
in the graph is 1, thus 4=3+1.236
4. MinText: A feature extraction technique for discovering text237
patterns238
In this section we present a feature extraction technique for finding pat-239
terns in graph representation of a given text. The graph may represent one240
sentence, one paragraph, one document, or even a collection of documents.241
13
  
mining_NN
text_NN
amod:4(3+1)
document_NN
amod:4(3+1)
manuscript_NN
amod:4(3+1)
search_VBZ
nsubj:5(4+1)
pattern_NNS
dobj:9(8+1)
model_NNS
dobj:9(8+1)
look_VBZ
nsubj:5(4+1)
dobj:9(8+1)
dobj:9(8+1)
seek_VBZ
nsubj:5(4+1)
dobj:9(8+1)
dobj:9(8+1)
explore_VBZ
nsubj:5(4+1)
dobj:9(8+1)
dobj:9(8+1)
in_IN
prep:3(2+1)
prep:3(2+1)
text_NNS
pobj:4(3+1)
document_NNS
pobj:4(3+1)
manuscript_NNS
pobj:4(3+1)
Figure 4: Graph-based representation with numeric values in the edges
We assume that the graph uses the representations we discussed in the pre-242
vious section. The MinText technique proposes to find features in the graph243
by counting text components (word lemmas, PoS tags, grammatical tags)244
when different paths are traversed. These components would seem to be iso-245
lated elements of the graph, however, counted over a path of interest they246
are considered to be textual patterns.247
Let us consider the semantic representation shown in Figure 3, the mini-248
mum path from the node search V BZ to the node text NNS will have the249
following features at different language description levels:250
• Lexical level: search, model, text, in.251
• Morphological level: V BZ, NNS, IN , NNS.252
• Syntactical level: dobj, prep, pobj.253
14
  
Those features may be further used (perhaps as a bag of words or a vector254
space model based vector) for some particular task to be carried out. Thus,255
a textual document represented by a graph may provide a set of features for256
each of the minimum paths found in that graph. These features can be used257
for encoding a meta-representation of the text.258
In Table 1 we can see an example of the features extracted with minimum259
paths, in which each row represents one path.The number of pairs considered260
as initial and final node may vary, for instance, considering all the combi-261
nations for the n nodes in the graph (the complexity time will be O(n2)),262
or fixing the initial or the final node (the complexity time will be O(n)).263
Different decisions can be made based on the particular mining text task to264
be accomplished.265
Table 1: Representation of a text using the MinText technique
Initial node to Lexical Morphological Syntactical
Final node features features features
search model · · · text NN NNS · · · V BZ dobj prep · · · pobj
search VBZ to
text NNS 1 1 · · · 1 0 2 · · · 1 1 1 · · · 1
search VBZ to
document NNS 1 1 · · · 0 0 2 · · · 1 1 1 · · · 1
search VBZ to
in IN 1 1 · · · 0 0 1 · · · 1 1 1 · · · 0
.
.
.
.
.
.
.
.
.
.
.
.
look VBZ to
manuscript NN 0 0 · · · 0 2 0 · · · 1 0 0 · · · 0
The MinText technique takes advantage of the different linguistic de-266
scription levels represented in the graph. It codifies textual information to267
numeric values which may be further used, for instance, to feed machine268
learning methods, or to calculate textual similarities among different texts.269
15
  
5. Case Study: QA4MRE270
In order to analyze the performance of the graph-based multi-level lin-271
guistic representation and the MinText technique, we present their applica-272
tion in a particular problem of document understanding known as “Question273
Answering for Machine Reading Evaluation (QA4MRE)”. The details of im-274
plementation of both, the representation schema and the MinText technique,275
are described below. We also illustrate the case study corpora of evaluation276
and experimental results.277
5.1. Task Description278
The QA4MRE task was first proposed in the 2011 edition of the CLEF279
conference5. The main objective of this task has been to develop a method-280
ology for evaluating Machine Reading systems through Question Answering281
and Reading Comprehension Tests. Systems to be evaluated should be able282
to extract knowledge from large volumes of text and use this knowledge to283
answer questions.284
The task focuses on the reading of single documents and the identification285
of answers to questions about information that is stated or implied in the286
text. Systems should be able to use knowledge obtained automatically from287
input texts in order to answer a set of questions posed for single documents288
at a time.289
5Conference and Labs of the Evaluation Forum; http://www.clef-initiative.eu/
16
  
5.2. Corpus Description290
In order to determine the performance of the text representation pro-291
posed in this paper in a real scenario, we used the corpora provided in the292
QA4MRE task of the CLEF 2011 and 2012. Even though the two datasets293
look similar at first glance, in practice they produce different results in the294
systems developed. Most of the questions of the corpus provided in 2011295
have been written in first person, thus leading to obtain better performance296
if the system takes this issue into consideration. The first dataset (CLEF297
2011) contains the following three topics: Climate Change, Music & Society298
and AIDS. The second dataset (CLEF 2012) contains four topics: Climate299
Change, Music & Society, Alzheimer and AIDS. Both datasets provide 10300
questions for each one of the 4 reading tests given per topic. Therefore, the301
total number of questions is 120 for the first corpus (2011), whereas there302
are 160 questions for the second one. Each question has 5 multiple-choice303
answers from which only one answer must be selected as the correct one. For304
a complete description of these datasets see [20, 21].305
5.3. Applying the proposed representation and the MinText technique to QA4MRE306
The QA4MRE task aims to select the correct answer for a given ques-307
tion, using only one small document (≈500-1000 words) as reference. The308
approach proposed considers to formulate candidate answers (named “answer309
hypothesis”) which are then validated in order to determine the one that best310
matches with respect to the document of reference. These candidate answers311
are an improved version of the original question, removing some cue words312
associated to the questions, such as who, where, which, and replacing these313
cue words with one of the possible answers given in the test.314
17
  
Let us consider the following test (question-answers):315
Question 1: Who is the founder of the SING campaign?316
Answer 1: Nelson Mandela317
Answer 2: Youssou N’Dour318
Answer 3: Michel Sidibe319
Answer 4: Zackie Achmat320
Answer 5: Annie Lennox321
322
Therefore, we can construct five different answer hypothesis as follows:323
Hypothesis 1: Nelson Mandela is the founder of the SING campaign324
Hypothesis 2: Youssou N’Dour is the founder of the SING campaign325
Hypothesis 3: Michel Sidibe is the founder of the SING campaign326
Hypothesis 4: Zackie Achmat is the founder of the SING campaign327
Hypothesis 5: Annie Lennox is the founder of the SING campaign328
329
We can validate each one of these answer hypothesis by comparing its330
similarity with respect to the reference document. In order to do so, we331
propose to represent both, the answer hypothesis and the reference docu-332
ment using the graph-based multi-level linguistic representation presented in333
Section 3.334
Thereafter, we can use the MinText technique introduced in Section 4335
for obtaining numeric vectors and subsequently to calculate the similarity336
between the reference document and each of the hypotheses. The hypothesis337
that obtain the highest score will be the one that will be selected as the338
correct answer to the question given.339
18
  
The construction process and the validation procedure for the answer340
hypotheses is described below.341
The hypotheses generator module receives as input the question set with342
their corresponding multiple-choice answers. As mentioned before, each hy-343
pothesis is constructed as the concatenation of the question with each of344
the possible answers. In order to generate the hypothesis, the “question key-345
word” is identified first, and afterwards it is replaced with each one of the five346
possible answers, thereby obtaining five hypotheses for each question. This347
hypothesis is intended to become the input of the Answer Validation (AV)348
module. The benefit of using these hypotheses as queries for the AV module349
is to search passages containing words that are in both, the question and the350
multiple-choice answer, instead of searching passages containing words from351
the question and the answer, independently.352
5.4. Answer Validation353
The answer validation module aims to assign a score to each hypothesis354
generated in the Hypothesis generator module. The Hypothesis obtaining355
the highest score is selected as the correct answer to the question.356
Text documents along with its hypotheses are parsed to produce their357
lexical, morphological, syntactic and semantic graph representation (as de-358
scribed in Section 3). As a result of this process, each document is represented359
as a tree with branches to sub-trees that represent all the sentences in the360
document. The nodes of the tree represent the word lemmas of the sentences361
along with its part-of-speech tag. The branches represent the dependency362
tag between the two connecting nodes. In the same way the hypotheses are363
represented as a tree with the same characteristics as well.364
19
  
In Figure 5 we show the graph-based representation for two hypotheses365
considered in this case study: “Annie Lennox is the founder of the SING366
campaign” and “Nelson Mandela is the founder of the SING campaign”;367
whereas, Figure 6 shows the graph-based representation for the first sentences368
of the reference document associated to the given question.369
Lennox-NNP Annie-NNP
n n : 3
founder-NN
nsubj :2
is-VBZcop:2
the-DT
d e t : 3
of-IN
prep:2
ROOT-0
roo t :2
campaign-NN
pobj:2
d e t : 3
SING-NNP
n n : 3
a) “Annie Lennox is the founder of the SING campaign”
Mandela-NNP Nelson-NNP
nn:3
founder-NN
nsubj:2
is-VBZcop:2
the-DT
det:3
of-IN
prep:2
ROOT-0
root:2
campaign-NN
pobj:2
det:3
SING-NNP
nn:3
b) “Nelson Mandela is the founder of the SING campaign”
Figure 5: Graph-based representation of two different hypotheses
In order to extract the features and measure the similarity between a370
hypothesis and the reference document, the MinText technique is employed.371
The root node of the hypothesis graph is fixed as the initial node in the372
MinText technique, whereas the final nodes selected correspond to the rest373
nodes of the hypothesis graph. This leads to diminish the computational time374
to O(n), with n equal to the number of nodes in the hypothesis graph. We375
have used the Dijkstra algorithm[22] for finding the minimum path between376
the initial and each final node. Thereafter, following the MinText technique,377
20
  
activist-NN
Lennox-NNP
dep:4
nsubj:5
Why-WRB
advmod:3
am-VBP
cop:4
an-DT
det:5
HIVAIDS-JJ
nn:9
Annie-NNP
nn:11
ROOT-0
root:3
going-VBG
root:3
name-NN
root:3
nsubj:5
’m-VBP
aux:4
share-VB
xcomp:2
to-TO
aux:4
with-IN
prep:4
story-NN
dobj:2
you-PRP
pobj:3
the-DT
det:5
as-IN
prep:4
dep:2
campaigner-NNpcomp:2
nsubj:5
det:5
nn:9
how-WRB
advmod:3
have-VBPaux:4
become-VBN
cop:4
det:5
And-CC
cc:2
this-DTnsubj:5
is-VBZ
cop:4
of-IN
prep:4
campaign-NN
pobj:3
nn:9
nn:9
Campaign-NNP
appos:2
SING-NNP
nn:9
Figure 6: Graph-based representation for one reference document
we count the occurrences of all the multi-level linguistic features considered378
in the text representation, such as part-of-speech tags and dependencies tags379
found in the path. The same procedure is performed with the document380
graph by using the pair of words identified in the hypothesis as initial and381
final nodes. As a result of this procedure, we obtain two set of feature vectors:382
one for the answer hypothesis, and one for the reference document.383
For instance, the minimum path between the initial node “root 0” and384
the final node “SING NNP” calculated over the reference document (in Fig-385
ure 6) is “root 0” → “name NN” → “of IN” → “campaign NN” → “Cam-386
paign NNP” → “SING NNP”. In this path we can find two “NN” tags, one387
“IN” tag and two “NNP” tags. However, the number of “NNP” tags ex-388
tracted from the same path using the graph presented in Figure 5(a) is only389
one. Table 2 shows a partial view of the feature set for both, the correct390
21
  
answer hypothesis and the reference document, whereas, Table 3 shows a391
partial view of the feature set for both, an incorrect answer hypothesis and392
the reference document. Even if the reference document is the same for both393
answer hypothesis, the feature set for this document will change because394
these features are calculated taken as input the pair of nodes found in the395
corresponding answer hypothesis.396
Table 2: Representation of the answer hypothesis and the reference text (Answer hypoth-
esis: “Annie Lennox is the founder of the SING campaign”).
Initial node to Lexical Morphological Syntactical
Final node features features features
founder Lennox · · · campaign NN IN · · · NNP nsubj prep · · · pobj
Features extracted from the answer hypothesis graph-based representation
root 0 to
Annie NNP 1 1 · · · 0 1 0 · · · 2 1 0 · · · 0
root 0 to
is VBZ 1 0 · · · 0 1 0 · · · 0 0 0 · · · 0
.
.
.
.
.
.
.
.
.
.
.
.
root 0 to
SING NNP 1 0 · · · 1 2 1 · · · 1 0 1 · · · 1
Features extracted from the reference document graph-based representation
root 0 to
Annie NNP 0 1 · · · 0 1 0 · · · 2 1 0 · · · 0
root 0 to
is VBZ 0 0 · · · 0 1 0 · · · 0 0 0 · · · 0
.
.
.
.
.
.
.
.
.
.
.
.
root 0 to
SING NNP 0 0 · · · 1 2 1 · · · 2 0 1 · · · 1
The MinText technique extracts a set of vectorial features (
−→
ft,i) for each397
text t, with V equal to the total number of lexical, morphological and syntac-398
tical features. Thus, the reference document d will now be represented by m399
feature vectors (d∗ = {−→fd,1,−→fd,2, · · · ,−−→fd,m}), as well as the answer hypothesis400
h (h∗ = {−→fh,1,−→fh,2, · · · ,−−→fh,m}). Here, m is the number of different paths that401
may be traversed in both graphs, using the “ROOT-0” vertex as the initial402
22
  
Table 3: Representation of the answer hypothesis and the reference text (Answer hypoth-
esis: “Nelson Mandela is the founder of the SING campaign”).
Initial node to Lexical Morphological Syntactical
Final node features features features
founder Nelson · · · campaign NN IN · · · NNP nsubj prep · · · pobj
Features extracted from the answer hypothesis graph-based representation
root 0 to
Nelson NNP 1 1 · · · 0 1 0 · · · 2 1 0 · · · 0
root 0 to
is VBZ 1 0 · · · 0 1 0 · · · 0 0 0 · · · 0
.
.
.
.
.
.
.
.
.
.
.
.
root 0 to
SING NNP 1 0 · · · 1 2 1 · · · 1 0 1 · · · 1
Features extracted from the reference document graph-based representation
root 0 to
Nelson NNP 0 0 · · · 0 0 0 · · · 0 0 0 · · · 0
root 0 to
is VBZ 0 0 · · · 0 1 0 · · · 0 0 0 · · · 0
.
.
.
.
.
.
.
.
.
.
.
.
root 0 to
SING NNP 0 0 · · · 1 2 1 · · · 2 0 1 · · · 1
node and each word appearing in the hypothesis as the final node.403
Since each path of the answer hypothesis contains exactly the same num-404
ber and types of components as that of the reference document, it is possible405
to calculate the degree of similarity among each path traversed. For the pur-406
poses of this case study, we have used the cosine similarity measure, which407
is calculated as in Eq.(3).408
Similarity(h∗, d∗) =
m∑
i=1
Cosine(
−→
fh,i,
−→
fd,i) (1)
=
m∑
i=1
−→
fh,i .
−→
fd,i
||−→fh,i|| . ||−→fd,i||
(2)
23
  
=
m∑
i=1
∑|V |
j=1 (f(h,i),j ∗ f(d,i),j)√∑|V |
j=1 (f(h,i),j)
2 ∗
√∑|V |
j=1 (f(d,i),j)
2
(3)
If some path does not exist in the reference document, then the feature409
vector will have zero values in all the feature weights, which will lead to410
an undefined equation. In this particular case, we have considered that the411
similarity between the two feature vectors will be equal to zero.412
After obtaining all the similarity scores for the five hypotheses of one413
question, the hypothesis obtaining the highest score is selected as the correct414
answer.415
For instance, let us consider the first pair (i = 1) presented in Table416
2, which corresponds to the path “root 0” to “Annie NNP”. The following417
equations show the manner the cosine similarity between fh,1 and fd,1 is418
calculated.419
−→
fh,1 .
−→
fd,1 = 1∗0+1∗1+· · ·+0∗0+1∗1+0∗0+· · ·+2∗2+1∗1+0∗0+· · ·+0∗0
||−→fh,1|| =
√
(12 + 12 + · · ·+ 02 + 12 + 02 + · · ·+ 22 + 12 + 02 + · · ·+ 02)
||−→fd,1|| =
√
(02 + 12 + · · ·+ 02 + 12 + 02 + · · ·+ 22 + 12 + 02 + · · ·+ 02)
Cosine(fh,1, fd,1) =
−→
fh,1 .
−→
fd,1
||−→fh,1|| ∗ ||−→fh,1||
≈ 0.93 (4)
The same procedure is carried out with the remaining pairs. Therefore,420
the final score is obtained by adding the cosine score calculated with each421
pair.422
On the other hand, considering the first pair (i = 1) presented in Table423
3, which corresponds to the path “root 0” to “Nelson NNP”. This path does424
24
  
not exist in the graph representation of the reference document, therefore,425
all the features have zero values leading to an undefined equation. In this426
particular case, we have considered that the cosine similarity between the427
two feature vectors is equal to zero.428
−→
fh,1 .
−→
fd,1 = 1∗0+1∗0+· · ·+0∗0+1∗0+0∗0+· · ·+2∗0+1∗0+0∗0+· · ·+0∗0 = 0
||−→fh,1|| =
√
(12 + 12 + · · ·+ 02 + 12 + 02 + · · ·+ 22 + 12 + 02 + · · ·+ 02)
||−→fd,1|| =
√
(02 + 02 + · · ·+ 02 + 02 + 02 + · · ·+ 02 + 02 + 02 + · · ·+ 02) = 0
Cosine(fh,1, fd,1) = 0 (5)
Again, the same procedure is carried out with the remaining pairs. There-429
fore, the final score is obtained by adding the cosine score calculated with430
each pair.431
In summary, if we consider the hypothesis “Annie Lennox is the founder432
of the SING campaign” (h1), the following compute against the reference433
document (d) has to be done:434
Similarity(h1, d) = Cosine(“root 0 to Annie NNP”, d)+Cosine(“root 0435
to is VBZ”, d) + · · ·+ Cosine(“root 0 to SING NNP”, d) ≈ 2.59436
Whereas, considering the hypothesis “Nelson Mandela is the founder of437
the SING campaign” (h2), the following compute has to be done:438
Similarity(h2, d) = Cosine(“root 0 to Nelson NNP”, d)+Cosine(“root 0439
to is VBZ”, d) + · · ·+ Cosine(“root 0 to SING NNP”, d) ≈ 1.61440
25
  
Here we can see the evidence of the higher degree of similarity between441
the correct answer hypothesis (h1) and the reference document (d) than the442
one calculated using the incorrect answer hypothesis (h2).443
5.5. Experimental Results and Evaluation444
For the evaluation procedure we have used the c@1 measure, defined in445
Eq.(6). This measure was defined in the QA4MRE task of CLEF 2011 with446
the purpose of allowing to decide whether or not to answer a given question,447
i.e., the possibility of having questions with no answer. The aim of this448
measure is thus to reduce the amount of incorrect answers, maintaining the449
number of correct ones.450
c@1 =
1
n
(nR + nU
nR
n
) (6)
where:451
nR: number of correctly answered questions452
nU : number of unanswered questions453
n: total number of questions454
455
Table 4 presents the results obtained with different approaches. The ap-456
proach MinText TreeTagger considers the application of the MinText tech-457
nique when the words in the graph are lemmatized using the “TreeTagger”458
part of speech tagger. MinText Lancaster is the one that uses the Lancaster459
stemmer. MinText Synonym is an approach that expands each word with460
its corresponding synonyms (without applying the process of word sense dis-461
ambiguation). MinText Hyponym expands each word with its corresponding462
26
  
set of hyponyms. It is worth mentioning that all these approaches are im-463
plemented exclusively using basic techniques, but other variations may be464
suggested, for instance, considering a more complex analyses of the type of465
questions, or adding knowledge extracted from lexical or semantical resources466
such as ontologies.467
As an additional analysis, we have carried out experiments towards the468
solution of the QA4MRE task without the use of the proposed MinText469
technique. The aim is to evaluate whether or not, the MinText is useful470
for extracting meaningful features from the graph-based representation. The471
results obtained with this implementation are also shown in Table 4, with472
the label of Without MinText. Considering that the QA4MRE task requires473
to answer a question associated to the understanding of a given text, we have474
used the graph representation presented in Section 3 for both, the question475
(actually, the hypothesis of the question) and the document. Thereafter,476
we search the graph of the hypothesis in the document graph by means of477
partial matching. As a similarity measure, we count those edges that are in478
both graphs, using only the intersection of vertices between the two graphs479
(n) divided by the total number of posible edges (n∗(n−1)
2
). This exercise480
was performed, as mentioned before, for determining the contribution of the481
MinText technique. We can observe that the use of the Without MinText482
technique obtains a performance below the baseline for both datasets. This483
result indicates that the MinText alone is capable of extracting much more484
meaningful features than some other techniques that attempts to find the485
hypothesis (represented as a graph) directly in the document graph-based486
representation.487
27
  
With respect to the comparison with the state-of-the-art, the MinText488
technique obtains a third place using the 2011 dataset with a c@1 of 0.42; a489
performance below two runs submitted by the same authors which obtained490
a c@1 of 0.47 and 0.57 (see [20]). When we executed the same approach using491
the 2012 dataset, our performance was much more lower since it achieved a492
c@1 of 0.27, which rank us in the 11th place (see [21]). Those results may493
seem discouraging, however, a fast review of the other runs of the state-of-494
the-art indicates a possibility of other techniques that can be employed for495
improving the obtained results. Textual entailment judgment, named entity496
recognition, type of question analysis, are some of these NLP techniques497
that will surely improve the final results of the QA4MRE task. We consider498
that the use of domain-specific techniques of natural language processing499
should improve the performance of the algorithm for this particular problem.500
However, the aim of this work is to show the graph-based representation and501
propose a technique to extract features from the graph, rather than solve502
the case study in an optimal manner. To maintain the simplicity and logical503
clarity of our description, we have not tried to include description of other504
domain specific techniques.505
Nevertheless, it can be observed in Table 4 that in the QA4MRE 2011506
dataset, the average over all best runs and over all runs were exceeded. As507
we have just outperformed the baseline of the QA4MRE dataset, we con-508
sider that the second dataset have been constructed using other type of lan-509
guage phenomena in the test questions and the reference documents such as510
anaphoric or cataphoric expressions. Additionally, we have frequently found511
negations of questions in the second dataset (2012), thus leading to have a512
28
  
much more complex dataset for the QA4MRE task. In any case, we consider513
that the graph-based multi-level linguistic representation have performed well514
in this particular task.515
Table 4: A comparison of the results obtained in the QA4MRE task (English language)
Evaluated approach 2011 2012
MinText TreeTagger 0.40 0.24
MinText Lancaster 0.42 0.24
MinText Synonym 0.37 0.23
MinText Hyponym 0.36 0.27
Without MinText 0.12 0.18
State-of-the-art techniques
Best result 0.57 0.65
Avg. over all best runs 0.28 0.32
Avg. over all runs 0.21 0.26
Random baseline 0.20 0.20
Worst result 0.02 0.14
6. Conclusion516
In the work reported in this paper, we have proposed a graph-based multi-517
level linguistic representations for texts. We have employed graph theory for518
formally defining a way of representing lexical, morphological, syntactical519
and semantic features of a text into a single graph. The graph-based rep-520
resentation proposed can contain words, word lemmas, PoS tags, phrasal521
or grammatical tags, and it can even have semantic relationships such as522
synonymy, hyperonymy or antonymy. The capability of containing multiple523
levels of natural language formal definitions in a single structure makes it a524
rich representation of features that allows to extract useful information as525
compared to other text representations reported in literature. This claim is526
29
  
based on the fact that other models represent the documents, considering the527
complete sequence of words and without taking into account that other word528
relationships may occur (without an implicit sequence of the words being529
implied).530
Another contribution of this paper is the proposed MinText technique531
that allows to extract multi-level linguistic features by traversing minimum532
paths in the graph and counting these linguistic features. Although we could533
find other kind of paths different than the minimum one, we consider that534
the minimum path will contain the most representative contextual informa-535
tion for the words that are taken as initial and final node. We have relaxed536
the problem of searching the combinatorial number of minimum paths by537
suggesting to focus in a fixed initial node. This assumption might be valid538
in particular natural language problems, but it may be not so useful in other539
applications. The features extracted from the graph may be used in several540
ways, for instance, by introducing them to machine learning methods as fea-541
ture vectors or to be used as representative vectors in a document collection.542
In any case, these vectors contain information associated to multiple linguis-543
tic levels which is a clear advantage of the proposal presented here, over other544
models of representation.545
In order to analyze the performance of the representation proposed to-546
gether with the MinText technique, we have conducted a set of experiments547
in a case study, namely, QA4MRE. We have observed that the representa-548
tion model proposed allows us to find the correct answer for a given question549
between 23% to 42% of the time. It is worth noting that this case study is550
highly challenging, as can be seen from the result Table no.4, presented in551
30
  
the previous section.552
This kind of result shows that the methodology may not always obtain the553
correct result for the QA4MRE task. The performance of this methodology554
may vary according to different factors, such as on the particular graph tra-555
versal algorithm chosen. For example, let us consider the following question556
formulated in the QA4MRE task: “What is Annie Lennox’s profession?”. In557
this case we have to decide which one of the following possible answers is the558
correct one:559
1. mother560
2. nurse in a hospital561
3. farmer562
4. musician563
5. dancer564
The correct answer to this question should be “musician” (cosine score:565
3.39), but our method selects “Nurse in a hospital” (cosine score: 4.11), as the566
correct answer. This incorrect prediction made by our system is mainly due to567
the naive selection of initial and final nodes of the graph traversal algorithm568
and also because of the lack of information regarding the path length. In569
the evaluation carried out in these experiments, we assumed that the initial570
node of such traversal, for all the hypotheses, should be “root”; a decision571
that sometimes may lead to obtaining incorrect information. For the example572
above, we realize that the words “nurse” and “hospital” have been taken into573
account twice. Hence, the features extracted for the chosen answer are more574
significant (greater in number) than those of the correct answer. Using the575
path length and the information of the candidate answers for determining the576
31
  
initial node (and selecting the final nodes using the question words) should577
be a possible way to overcome this drawback.578
As future work we are planning to test the graph-based multi-level linguis-579
tic representation in other NLP tasks such as textual entailment, semantic580
similarity, authorship attribution etc. We are also interested in defining in581
detail the manner in which other semantic relationships can be integrated582
in the graph-based representation. We would like to evaluate the different583
configurations of parsing tools, in particular, for the syntactical level parsing584
in the task already tested. Finally, we would like to find ways of integrating585
other types of text tagging (such as name entity recognition) into the repre-586
sentation proposed here. It may be interesting to correlate and explore the587
applicability of the proposed representation framework to some of the past588
works on concept-tagging based semantic annotation (see [23]) and recom-589
mendation generation (see [24]) for E-books.590
References591
[1] D. Mladenic, M. Grobelnik, Word sequences as features in text-learning,592
in: In Proceedings of the 17th Electrotechnical and Computer Science593
Conference (ERK98), 1998, pp. 145–148.594
[2] E. Stamatatos, N. Fakotakis, G. Kokkinakis, Computer-based author-595
ship attribution without lexical measures, in: Computers and the Hu-596
manities, 2001, pp. 193–214.597
[3] V. Keselj, F. Peng, N. Cercone, C. Thomas, N-gram-based author pro-598
files for authorship attribution (2003).599
32
  
[4] M. L. Mauldin, Retrieval performance in ferret a conceptual information600
retrieval system, in: Proceedings of the 14th annual international ACM601
SIGIR conference on Research and development in information retrieval,602
SIGIR ’91, ACM, New York, NY, USA, 1991, pp. 347–355.603
[5] W. B. Croft, H. R. Turtle, D. D. Lewis, The use of phrases and struc-604
tured queries in information retrieval, in: Proc. of the 14th SIGIR con-605
ference, ACM, New York, NY, USA, 1991, pp. 32–45.606
[6] G. Salton (Ed.), Automatic text processing, Addison-Wesley Longman607
Publishing Co., Inc., Boston, MA, USA, 1988.608
[7] R. Mihalcea, D. Radev, Graph-based natural language processing and609
information retrieval, Cambridge university press, 2011.610
[8] H. Zha, Generic summarization and keyphrase extraction using mutual611
reinforcement principle and sentence clustering, in: SIGIR, ACM, 2002,612
pp. 113–120.613
[9] C. Nicolae, G. Nicolae, Bestcut: a graph algorithm for coreference reso-614
lution, in: Proc. of the EMNLP 2006 Conference, Association for Com-615
putational Linguistics, Stroudsburg, PA, USA, 2006, pp. 275–283.616
[10] B. Dorow, D. Widdows, Discovering corpus-specific word senses, in:617
EACL, The Association for Computer Linguistics, 2003, pp. 79–82.618
[11] J. Veronis, Hyperlex: lexical cartography for information retrieval, Com-619
puter Speech & Language 18 (3) (2004) 223–252.620
33
  
[12] E. Agirre, D. Mart́ınez, O. L. de Lacalle, A. Soroa, Two graph-based621
algorithms for state-of-the-art wsd, in: D. Jurafsky, É. Gaussier (Eds.),622
EMNLP, ACL, 2006, pp. 585–593.623
[13] Y. Matsuo, T. Sakaki, K. Uchiyama, M. Ishizuka, Graph-based word624
clustering using a web search engine, in: Proc. of the EMNLP 2006 Con-625
ference, Association for Computational Linguistics, Stroudsburg, PA,626
USA, 2006, pp. 542–550.627
[14] C. Biemann, Chinese whispers: an efficient graph clustering algorithm628
and its application to natural language processing problems, in: Proc.629
of the 1st Workshop on Graph Based Methods for Natural Language630
Processing, Association for Computational Linguistics, Stroudsburg,631
PA, USA, 2006, pp. 73–80.632
[15] S. Zhong, Generative model-based document clustering: a comparative633
study, Knowledge and Information Systems 8 (2005) 374–384.634
[16] M. P. Marcus, B. Santorini, M. A. Marcinkiewicz, Building a large anno-635
tated corpus of english: The penn treebank, Computational linguistics636
19 (2) (1993) 313–330.637
[17] M. catherine De Marneffe, C. D. Manning, Stanford typed dependencies638
manual (2008).639
[18] V. C. Storey, Understanding semantic relationships, VLDB J. 2 (4)640
(1993) 455–488.641
[19] I. Bejar, R. Chaffin, S. Embretson, Cognitive and psychometric analysis642
34
  
of analogical problem solving, Recent research in psychology, Springer-643
Verlag, 1991.644
[20] A. Peñas, E. H. Hovy, P. Forner, Á. Rodrigo, R. F. E. Sutcliffe,645
C. Forascu, C. Sporleder, Overview of QA4MRE at CLEF 2011: Ques-646
tion answering for machine reading evaluation, in: V. Petras, P. Forner,647
P. D. Clough (Eds.), CLEF (Notebook Papers/Labs/Workshop), 2011.648
[21] A. Peñas, E. H. Hovy, P. Forner, Á. Rodrigo, R. F. E. Sutcliffe,649
C. Sporleder, C. Forascu, Y. Benajiba, P. Osenova, Overview of650
QA4MRE at CLEF 2012: Question answering for machine reading eval-651
uation, in: P. Forner, J. Karlgren, C. Womser-Hacker (Eds.), CLEF652
(Online Working Notes/Labs/Workshop), 2012.653
[22] E. W. Dijkstra, A note on two problems in connexion with graphs,654
Numerische mathematik 1 (1) (1959) 269–271.655
[23] R. Piryani, A. Uddin, M. Devaraj, V. Singh, An algorithmic formulation656
for extracting learning-concepts and their relatedness in ebook texts, in:657
Proceedings of the MIKE’2013, Vol. 8284, Lecture Notes in Artificial658
Intelligence, 2013, pp. 524–540.659
[24] V. K. Singh, R. Piryani, A. Uddin, D. Pinto, A content-based eresource660
recommender system to augment ebook-based learning, in: Proceedings661
of the MIWAI’2013, Vol. 8271, Lecture Notes in Computer Science, 2013,662
pp. 257–268.663
35
  
Highlights 
 We proposed a graph-based representation that considers 
multiple linguistic levels 
 We introduced MinText, a technique useful for extracting features 
from the graph 
 We presented a study case for analyzing the performance of the 
methods proposed 
