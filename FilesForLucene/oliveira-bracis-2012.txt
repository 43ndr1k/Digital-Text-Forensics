O uso de Algoritmos de Compressão de Dados na Verificação da 
Autoria de Textos
Walter R. de Oliveira Jr.1, Edson J. R. Justino1, Luiz E. S. Oliveira2
1Programa de Pós-Graduação em Informática – Pontifícia Universidade Católica do Paraná (PUC-
PR)
Rua Imaculada Conceição, 1155 – 80.215-901 – Curitiba – PR – Brasil
2Departamento de Informática – Universidade Federal do Paraná (UFPR)
Curitiba, PR – Brasil
woliveirajr@gmail.com, justino@ppgia.pucpr.br, lesoliveira@inf.ufpr.br
Abstract. One demand in forensics is the analysis of apocrif documents, looking for the  
probable author. Computational tools can help in this task, giving objective results to  
the  forensic  examiner  or  helping  reducing  the  time  amount  spent  in  this  task.  The  
present work shows the use of a normalized compression distance (NCD) to verify the  
authorship attribution in Brazilian Portuguese documents. Tests were performed in a  
knowledge base with a reasonable amount of authors (100 authors, 3,000 documents),  
using two different methods of authorship attribution, and the results are shown and  
analyzed. With the PPM-D compressor an average of 74,04% of correct attributions  
were obtained.
Resumo. Uma das demandas forenses é a perícia em documentos apócrifos, buscando  
a  autoria  provável.  Ferramentas  computacionais  podem  auxiliar  neste  trabalho,  
fornecendo resultados mais objetivos para o perito ou auxiliando no tempo despendido  
nesta  tarefa.  Este  artigo  apresenta  o  uso  da  medida  de  distância  normalizada  de  
compressão (NCD) para atribuição de autoria em documentos de língua portuguesa.  
Os testes foram executados em uma base de documentos com uma quantidade razoável  
de autores (100 autores, 3000 documentos), com dois mecanismos de escolha de autor  
provável e os resultados são apresentados. Utilizando-se o compressor de dados PPM-
D foi  possível  obter  uma média  de  74,04% de atribuições  corretas  de autoria  aos  
documentos questionados.
1. Introdução
Em trabalhos de perícia de autoria de documentos encontra-se, entre outras tarefas, a busca do autor 
provável de um documento. Nesta situação, tem-se um documento de autoria desconhecida e uma 
lista de autores possíveis e a tarefa do perito é determinar quem é o autor provável. A verificação de 
autoria em documentos eletrônicos é um desafio que apresenta um agravante a esta tarefa, pois o 
fato do documento ser produzido em um computador faz com que alguns elementos (por exemplo, a 
cursividade da letra manuscrita) não estejam presentes nem possam auxiliar o perito.
Desta  forma  o perito  deverá  utilizar  outros  elementos  como a análise  de  características 
estilísticas  do  autor  do  documento.  Estas  características  estilísticas  são  produzidas 
inconscientemente pelo autor [Stamatatos 2008]. Há uma variedade de características estilométricas 
que poderiam ser analisadas com o uso de soluções computacionais, auxiliando o trabalho do perito 
e  minimizando  opiniões  subjetivas  das  perícias.  Estas  características  estilométricas,  conforme 
[Stamatatos 2008], podem ser divididas em:
– características léxicas:  são as características relacionadas às palavras  de um idioma.  Por 
exemplo,  a  contagem  do  tamanho  de  palavras  ou  frases,  a  riqueza  do  vocabulário 
empregado, ou mesmo o uso de vetores de frequência de palavras;
– características de caracteres: são as características associadas aos caracteres utilizados no 
documento. Por exemplo, contagem de caracteres alfabéticos, dígitos e sinais de pontuação, 
frequência de n-gramas de caracteres, algoritmos de compressão de dados;
– características sintáticas: são as características associadas aos elementos sintáticos utilizados 
pelo autor no documento. Por exemplo, a frequências de componentes sintáticos ou de  n-
gramas sintáticos;
– características  específicas  a  atividades:  são  características  que  estão  presentes  em  um 
determinado tipo de documento, por exemplo, a análise da utilização dos elementos HTML 
para verificações de paginas da internet.
Neste  trabalho são utilizadas características de caracteres para a atribuição de autoria por 
meio da verificação de semelhança entre documentos com o uso de compressores de dados. Adota-
se a distância normalizada de compressão (NCD), proposta por [Cilibrasi 2006], para que a medida 
entre  documentos  de  autoria  desconhecida  e  documentos  que  componham  uma  base  de 
conhecimento seja feita e,  por meio de mecanismos de escolha,  o resultado mais provável seja 
selecionado.
Em  um  trabalho  anterior,  [Varela  2010]  utilizou  uma  determinada  base  de  dados  para 
verificar a atribuição de autoria com o uso de classificadores SVM e estatísticas de palavras-função 
presentes nos documentos. Por exemplo, a proporção de artigos utilizados pelo autor em relação à 
quantidade  de  palavras  presentes  em cada  documento.  Ao  utilizar  a  mesma  base  da  dados,  o 
presente trabalho permite uma comparação do desempenho do uso da medida NCD e do uso de 
palavras-função com classificadores SVM.
Este artigo se divide em 6 partes, a  saber: a seção 1 contém esta introdução, na seção 2 é 
apresentada uma breve introdução sobre a distância normalizada de compressão, na seção 3 é feita 
uma apresentação das bases de dados que foram utilizadas neste trabalho, na seção 4 é feita uma 
apresentação do método proposto neste trabalho, na seção 5 são apresentados resultados obtidos 
com os testes que foram realizados e na seção 6 são apresentadas as conclusões e os trabalhos 
futuros que podem derivar da pesquisa feita até o momento.
2. Distância Normalizada de Compressão e Complexidade de Kolmogorov
A  distância  normalizada  de  compressão  decorre  diretamente  da  teoria  de  complexidade  de 
Kolmogorov. Inicialmente, é necessário explicar esta teoria.
Segundo [Kolmogorov 1965], a complexidade de uma informação é diretamente relacionada 
à  quantidade  de  símbolos  utilizados  para  expressar  esta  informação.  Se  estabelecermos  uma 
linguagem universal fixa para a descrição desta informação, a complexidade de Kolmogorov K(x)  
de uma informação é o tamanho da menor descrição possível do objeto nesta linguagem universal 
fixa de descrição.
É  possível  também  estabelecer  a  complexidade  condicional  de  Kolmogorov.  Esta 
complexidade condicional K(x|y) é o tamanho do menor programa binário que produz o resultado x 
quando é alimentado com uma entrada y, usando uma máquina de Turing universal fixa. As medidas 
de K(x) e K(x|y) são incomputáveis. 
A partir da teoria de Kolmogorov, [Vitanyi e Li 1993] estabeleceram que é possível verificar 
a  similaridade  entre  duas  informações,  estas  seriam  mais  semelhantes  quanto  menor  fosse  a 
complexidade condicional de Kolmogorov. Ou seja, quanto mais similares duas informações, menor 
seria a complexidade condicional de Kolmogorov, pois menor seria o programa binário capaz de 
produzir  ambas  informações.  Esta  similaridade  entre  informações  foi  denominada  de  distância 
normalizada de informações NID(x,y) e é expressa na equação (1) a seguir:
NID ( x , y)=max {K ( x∣y ) , K ( y∣x )}
max {K (x) , K ( y )} (1)
Sendo que K( x ) representa a complexidade de Kolmogorov de uma informação x e K( x |  
y  ) representa  a  complexidade  condicional  de  Kolmogorov  de  uma  informação  x, dada  uma 
informação y. Esta distância também é incomputável.
[Vitanyi e Li 1993] propuseram que compressores de dados podem ser utilizados para se 
obter, de maneira aproximada, a complexidade de Kolmogorov, pois compressores de dados buscam 
representar uma determinada informação da menor maneira possível. Isto é feito buscando-se um 
código que, alimentando um programa descompressor, represente a informação original , sendo que 
se busca que este código comprimido possua o menor tamanho possível.
A utilização de compressores para verificar a semelhança entre informações é denominada 
de distância normalizada de compressão (NCD), expressa na equação a seguir:
NCD( x , y)= tC (xy )−min {tC (x ) , tC ( y)}
max {tC (x ) , tC ( y)} (1)
onde tC( x ) representa o tamanho, em bytes, de um arquivo x comprimido e xy representam 
a concatenação de dois arquivos. Concatenação é o processo de agrupar dois arquivos em um único, 
sendo que o conteúdo do segundo arquivo é acrescentado imediatamente após o final do primeiro 
arquivo.
A NCD entre duas informações é expressa por um valor numérico compreendido entre 0 e 1, 
sendo que um valor NCD próximo a 0 indica que as informações são bastante semelhantes e um 
valor próximo a 1 indica que as informações não são semelhantes. A NCD pode ser utilizada para 
tarefas  nas quais é necessário verificar a semelhança entre  documentos  ou agrupar documentos 
conforme apresentem semelhança entre si, por exemplo, para identificar estilos musicais [Cilibrasi, 
Wolf e Vitanyi, 2004].
Também é possível utilizar a NCD para a atribuição de autoria de documentos, conforme 
mencionado  por  [Stamatatos  2008].  Documentos  produzidos  por  um  mesmo  autor,  devido  à 
presença de características estilométricas próprias ao autor, devem possuir uma menor NCD que 
documentos de autores diferentes. Assim, é possível realizar a atribuição de autoria pela medida da 
distância entre o documento questionado e documentos de autores prováveis.
2.1 Compressores de dados
Compressão de dados é o processo de converter uma sequência de dados de entrada em uma outra 
sequência de dados, de saída, que possua um tamanho menor. A compressão é feita pela eliminação 
de dados redundantes ou pela redução da quantidade de dados que são necessários para representar 
corretamente uma informação [Salomon 2007]. Os compressores de dados podem ser construídos 
segundo  diversas  abordagens.  No  presente  trabalho  foram testados  compressores  baseados  em 
estatísticas, em dicionários e em blocos de dados.
O compressor estatístico utilizado foi o PPM-D (prediction by partial matching D). Este 
compressor  estatístico  gera  um  modelo  estatístico  dos  símbolos  encontrados  no  documento 
considerando a probabilidade da ocorrência de um símbolo em função da ocorrência anterior de 
outros símbolos [Shkarin 2002]. Por exemplo, na língua portuguesa, após um símbolo “ç”, há uma 
maior  probabilidade  de  encontrar  um  símbolo  “ã”  ou  “õ”  do  que  um  símbolo  “r”  e  estas 
probabilidades são consideradas para a geração de modelos estatísticos otimizados.
Para  compressores  baseados  em  dicionários  foi  escolhido  o  compressor  Zip.  Este 
compressor implementa o algoritmo de compressão baseado em dicionário LZ77 (Lempel-Ziv77) e 
uma codificação de Huffmann. De maneira simplificada, os compressores baseados em dicionário 
utilizam as informações visualizadas anteriormente no documento como uma tabela de dicionário 
equando esta informação é encontrada novamente, é feita apenas uma referência à tabela.
Por  fim,  o  compressor  baseado em bloco de  dados  utilizado é  o compressor  Bzip,  que 
implementa  o algoritmo de  compressão  de  blocos  de  Burrows e  Wheeler  [Burrows e  Wheeler 
1994]. Este compressor caracteriza-se por separar o conteúdo a ser comprimido em blocos de dados 
e  efetuar  operações  em seu  conteúdo,  de  maneira  a  agrupar  informações  semelhantes  e  assim 
conseguir  representá-las  de  uma  maneira  que  possam  ser codificados  mais  eficientemente  por 
alguma codificação posterior. No caso do compressor Bzip, é utilizada a codificação de Huffmann.
O método NCD não apresenta restrições a qual modelo de compressor deva ser utilizado, 
pois sua função é apenas aproximar uma linguagem universal. Um estudo de [Cébrian, Alfonseca e 
Ortega 2005] indica que o desempenho de um determinado compressor para a medida de NCD pode 
ser afetado pelo tamanho dos arquivos. Segundo os autores, os arquivos concatenados não podem 
ser processados em fragmentos pelo compressor, pelo risco de informações que estejam presentes 
ao  final  do  arquivo  não  sejam  consideradas  conjuntamente  com  as  informações  do  início. 
Compressores Zip utilizam uma janela deslizante de 32kB para o processamento do conteúdo a ser 
comprimido. Assim, caso a soma dos tamanhos do arquivo questionado e do arquivo da base de 
conhecimento ultrapasse o valor de 32kB, o desempenho da medida da NCD é afetado, pois o 
compressor  não  utilizaria  ao  mesmo  tempo  as  informações  disponíveis  nas  extremidades  do 
arquivos. O mesmo problema ocorre em relação ao compressor Bzip, onde o conteúdo do arquivo é 
separado em blocos de tamanhos fixos. Para que este problema não ocorresse, foi verificado  que 
em  nenhum  caso  a  concatenação  de  arquivos  ultrapassou  32kB  de  tamanho.  Em  relação  ao 
compressor Bzip, o tamanho do bloco que foi utilizado (900k) é superior ao tamanho dos arquivos 
considerados nos testes, também não havendo impacto na medida NCD. Esta restrição de tamanho 
de bloco ou de janela deslizante não é verificada em relação aos compressores PPMD. Por este 
motivo, o presente trabalho pode comparar o desempenho dos três compressores mencionados sem 
que se incorresse na limitação mencionada.
3. Bases de dados
Neste trabalho a base de dados considerada foi a mesma utilizada anteriormente por [Varela 2010]. 
Os documentos desta base de dados foram obtidos por meio de da extração de documentos de blogs 
e jornais  publicados em língua  portuguesa. Foram escolhidas 10 áreas de conhecimento (direito, 
economia, esportes, gastronomia, literatura, politica, saúde, tecnologia, turismo). Para cada área de 
conhecimento foram escolhidos 10 autores, resultando assim em um total de 100 autores. Para cada 
autor foram extraídos 30 documentos, resultando em um total de 3.000 documentos. Esta base de 
dados foi denominada de “base bruta”.
Posteriormente,  esta  base  de  dados  foi  refinada  por  meio  das  seguintes  operações. 
Inicialmente foi  verificado que haviam alguns documentos repetidos  (tanto por serem idênticos 
como por apresentarem o mesmo conteúdo, diferenciando-se apenas na quantidade de linhas em 
branco ao início ou ao final dos documentos). Desta forma, 10 documentos (0,3% do total) foram 
substituídos por outros documentos do mesmo autor, elaborados aproximadamente na mesma época 
que os demais.  A seguir  foram retiradas informações que poderiam ser encontradas apenas nos 
documentos de um autor mas não em documentos de outros autores. Por exemplo, foram retiradas 
informações como “Publicado em:”, “por Denny Roger”, “saúde a todos”, “ícone postado”, “Paulo 
Coelho é ...”. Um total  de 21 operações de  retirada de informações foi efetuado. Este segundo 
conjunto de dados é denominado de “base refinada” ao longo deste artigo.
A tabela  1  apresenta as  informações estatísticas  sobre  os  arquivos  de  cada  base  de 
conhecimento.
Tabela 1. Dados estatísticos dos arquivos das bases de conhecimento
 tamanho médio dos 
arquivos (bytes)
mediana tamanho mínimo dos 
arquivos (bytes)
tamanho máximo dos 
arquivos (bytes)
base de dados bruta 3001,53 2997 213 17866
base de dados refinada 2989,31 2986 213 17866
Como pode ser observado os  arquivos das duas bases de dado são bastante semelhantes, 
com uma pequena diminuição de tamanho dos arquivos da base de dados refinada. A base de dados 
bruta possui diversas informações que são únicas a cada autor, o que poderia fazer com que os 
resultados obtidos não representassem uma situação real de perícia de documento. Por isto, os testes 
foram executados apenas nos documentos da base de dados refinada. O gráfico da Figura 1 ilustra a  
distribuição do tamanho dos arquivos desta base de dados.
Figura 1. Estatísticas das bases de dados
O uso da  mesma base de  dados  permite  que sejam feitas  comparações  entre  o  método 
utilizado  no  trabalho  de  [Varela  2010]  e  o  proposto  neste trabalho  (distância  normalizada  de 
compressão).  Brevemente,  o trabalho de [Varela 2010] consistiu  na verificação a  frequência de 
ocorrência  de  diversas  palavras funcionais  (como  artigos,  pronomes,  etc)  e  utilização  de  um 
classificador SVN considerando estas estatísticas para a descoberta do estilo de escrita de cada 
autor.
4. Método Proposto
O método proposto para o presente trabalho é composto pelas etapas que se seguem.
4.1 Separação de documentos
Os documentos de cada uma das bases de dados foram separados em dois grupos. O primeiro grupo, 
composto  de  7  documentos de  cada  autor,  escolhidos  aleatoriamente,  foram  separados  para 
constituírem a base de conhecimento de cada autor. Os demais documentos (23 documentos por 
autor) constituíram a base de documentos questionados, para os quais deseja-se saber a autoria. Esta 
separação é a mesma utilizada por [Varela 2010], permitindo a comparação do desempenho dos 
métodos.
4.2 Medida da NCD
Nesta  etapa  foram  medidas  as  distâncias  normalizadas  de  compressão  entre  cada  um  dos 
documentos questionados e todos os documentos da base de conhecimento. Foram utilizados os 
compressores Zip, Bzip e PPMD. 
Para cada um dos 2300 arquivos questionados a NCD foi medida em relação a cada um dos 
700 arquivos da base de conhecimento. Este procedimento é mostrado na Figura 2.
Figura 2: processo utilizado para obtenção dos termos da equação (1)
4.3 Decisão
A escolha do autor provável de um documento questionado é feita por meio  de um mecanismo de 
escolha. No presente trabalho foram estudados dois mecanismos de escolha, detalhados a seguir.
O primeiro mecanismo de escolha do autor provável, para cada documento questionado, é o 
menor valor da NCD. Desta forma o documento que possuísse maior semelhança era escolhido 
como o autor.
O segundo mecanismo de escolha do autor provável, para cada documento questionado, é o 
de votação. Como cada autor provável possui 7 documentos de conhecimento, foram verificados os 
7 menores resultados de NCD obtidos para documento questionado. Verificou-se quem eram os 
autores  atribuídos  para  estes  7  menores  resultados  e  o  autor  que tivesse  um maior  número de 
atribuições  foi  considerado  o  autor  provável.  Por  exemplo,  executando-se  o  teste  para  um 
determinado documento questionado do autor “A”, verifica-se quais são os 7 menores valores NCD 
obtidos. Supondo-se que estes menores valores NCD tenham sido obtidos em relação a documentos 
dos autores “C , A , A, B, D, C, A”, verifica-se que o autor “A” foi o autor mais votado, então a 
autoria  é  atribuída  a  ele.  Neste  último  mecanismo  não  foi  estabelecido  nenhum  critério  de 
desempate. Assim, em casos onde não houver um autor que tenha aparecido mais vezes entre os 7 
menores valores da NCD, o resultado era considerado “indefinido”.
5. Resultados
Os resultados obtidos estão expressos nos próximos itens.
5.1 Menor medida de NCD
O primeiro teste envolveu o mecanismo de escolha de menor valor da NCD e os documentos foram 
considerados apenas dentro da sua área de conhecimento. Ou seja, para documento questionado, 
haviam 10 autores possíveis. As taxas de acerto de atribuição correta de autoria dos documentos 
questionados são apresentadas na tabela 2. 
Tabela 2. Resultados da escolha pelo melhor valor NCD – apenas autores por área de conhecimento
Tema Varela (2010)
Compressor
Bzip PPMD Zip
Assuntos Variados 70,70% 79,57% 81,74% 83,04%
Direito 72,20% 63,91% 68,26% 65,65%
Economia 64,80% 77,83% 78,70% 79,57%
Esportes 68,30% 82,61% 85,65% 87,39%
Gastronomia 75,70% 44,78% 54,35% 53,04%
Literatura 72,20% 59,13% 66,96% 61,74%
Política 68,70% 81,74% 83,91% 83,04%
Saúde 72,20% 58,26% 61,30% 63,91%
Tecnologia 73,90% 74,78% 77,39% 79,13%
Turismo 78,30% 80,00% 82,17% 83,04%
Média 71,70% 70,26% 74,04% 73,96%
Desvio padrão 0,04 0,12 0,10 0,11
Em negrito  estão destacados os resultados que foram superiores aos obtidos por [Varela 
2010]. Verifica-se que a média dos resultados obtidos pelo método NCD foi superior quando foram 
utilizados os compressores de dados Zip e PPMD. Este resultado também mostra que em 6 áreas de 
conhecimento o desempenho do método NCD foi superior, independente do compressor utilizado. 
O uso de palavras-função com o classificador SVM, por outro lado, apresentou resultados mais 
homogêneos, com um desvio padrão inferior à metade dos obtidos com o NCD.
Se fossem considerados como possíveis todos os 100 autores presentes na base de dados, as 
taxas de acerto de atribuição correta de autoria dos documentos questionados seriam os mostrados 
na Tabela 3.
Tabela 3. Resultados da escolha pelo melhor valor NCD – todos autores possíveis
Tema Bzip PPMD Zip
Assuntos Variados 72,61% 72,61% 73,48%
Direito 53,91% 60,43% 59,13%
Economia 63,91% 64,78% 63,91%
Esportes 80,87% 84,78% 85,65%
Gastronomia 36,09% 46,09% 41,30%
Literatura 42,17% 49,57% 47,39%
Política 69,13% 73,48% 73,04%
Saúde 47,83% 53,91% 58,26%
Tecnologia 70,00% 73,04% 77,83%
Turismo 56,96% 68,26% 68,26%
Média 59,35% 64,70% 64,83%
Desvio Padrão 0,14 0,12 0,14
Conforme pode ser verificado, com o aumento da quantidade de autores possíveis, a tarefa 
de atribuição de autoria torna-se mais difícil e a quantidade de atribuições corretas diminui.
Na linha “Média” é exibido a média de atribuições corretas das categorias. O compressor 
Zip é o que obtém o melhor resultado, com um desempenho inferior à média anterior (onde eram 
considerados  como prováveis  apenas  os  autores  pertencentes  à  categoria  do  documento 
questionado).  Para  uma  quantidade  10  vezes  maior  de  autores,  o  desempenho  foi  inferior  em 
13,35%.
5.2 Menor média da NCD
O segundo  mecanismo  de  escolha  utilizado  foi  o  de  votação.  O  primeiro  teste  efetuado,  para 
comparação com os testes executados por [Varela 2010], considerava como possíveis apenas os 10 
autores existentes dentro de cada área do conhecimento. As taxas de acerto de atribuição correta de 
autoria dos documentos questionados são apresentadas na tabela 4.
Tabela 4. Resultados da escolha por votação – apenas autores da área
Tema Varela (2010) Compressor
Bzip PPMD Zip
Assuntos Variados 70,70% 84,78% 81,74% 78,26%
Direito 72,20% 60,87% 64,35% 67,83%
Economia 64,80% 75,65% 70,00% 74,78%
Esportes 68,30% 80,43% 83,91% 83,04%
Gastronomia 75,70% 50,87% 48,26% 51,74%
Literatura 72,20% 61,30% 59,13% 57,83%
Política 68,70% 80,87% 80,87% 84,35%
Saúde 72,20% 60,87% 63,48% 66,09%
Tecnologia 73,90% 75,22% 74,35% 78,26%
Turismo 78,30% 77,39% 78,26% 81,30%
Média 71,70% 70,83% 70,43% 72,35%
Desvio Padrão 0,03 0,11 0,12 0,11
Em negrito estão destacados os resultados que foram superiores aos obtidos por [Varela 
2010].
Verifica-se,  inicialmente,  que  apenas  o  compressor  Zip  apresentou  um resultado  médio 
superior ao obtidos por [Varela 2010]. Em 5 categorias os resultados obtidos pelos 3 compressores é 
superior e em uma delas (Turismo) apenas o compressor Zip apresenta resultados superiores.
Comparando-se  os  resultados  dos  dois  métodos  de  escolha  de  autor  para  atribuição  de 
autoria, verifica-se que os valores médios de atribuições corretas foram maiores pelo mecanismo de 
voto para o compressor Bzip em relação à escolha pelo melhor resultado (70,83% contra 70,26%). 
Para os demais compressores a escolha pelo voto apresentou resultados inferiores: para o PPMD, a 
escolha  por  votação  apresentou  acerto  de  70,43%  contra  74,04%  para  escolha  pelo  melhor 
resultado;  para  o Zip,  a  escolha  por  votação apresentou acerto  de 72,35% contra  73,96% para 
escolha pelo melhor resultado.
5.3 Influência da quantidade de autores prováveis
Como verificado nos resultados anteriores, há uma piora do desempenho quando há uma quantidade 
maior de autores possíveis. Para verificar o comportamento desta influência foi realizado um novo 
experimento. Foram escolhidos 10 autores para representar o grupo de documentos questionados e 
foram selecionados apenas 10 documentos questionados por autor. Assim, inicialmente, foi feita a 
atribuição  de  autoria  de  100  documentos  (10  autores,  10  documentos  por  autor).  O  grupo  de 
documentos  que  representam  os  autores  prováveis  permaneceu  inalterado,  sendo  considerados 
inicialmente todos os 100 autores, cada um com 7 documentos.
Em uma segunda etapa, foi diminuída a quantidade de autores prováveis para 90 autores e 
assim sucessivamente, até que restassem apenas 10 autores prováveis. Cuidou-se para que o autor 
verdadeiro dos documentos sempre estivesse entre os autores prováveis, não existindo documento 
questionado cujo autor provável não estivesse representado. Os testes foram realizados apenas com 
o compressor Zip. Na tabela 5 podemos ver as taxas de acerto de atribuição correta de autoria dos  
documentos questionados.
Tabela 5. Influência da quantidade de autores prováveis
Quantidade de autores possíveis
10 20 30 40 50 60 70 80 90 100
Atribuições 
corretas
81 % 77 % 75 % 74 % 73 % 72 % 71 % 71 % 71 % 70 %
Verifica-se que, nesta nova base de testes, quando eram considerados como possíveis todos 
os autores  disponíveis na base de testes, foram feitas atribuições corretas em 70 documentos que 
eram questionados. Com a diminuição da quantidade de autores possíveis, a taxa de atribuições 
corretas elevou-se até 81%. Ou seja, uma  diminuição da dificuldade em um grau de magnitude 
significou-se um desempenho superior em 11 pontos percentuais. Isto pode ser melhor visualizado 
no gráfico apresentado na figura 03.
Figura 03: influência da quantidade de autores prováveis
6. Conclusão e trabalhos futuros
Com este trabalho, verificou-se que a utilização da medida da distância normalizada de compressão 
pode apresentar  resultados  promissores para identificação da autoria de documentos.  A base de 
dados utilizada é bastante abrangente, com um número significativo de autores, o que representa um 
grande desafio.
10 20 30 40 50 60 70 80 90 100
0,00%
10,00%
20,00%
30,00%
40,00%
50,00%
60,00%
70,00%
80,00%
90,00%
100,00%
Influência da quantidade de autores prováveis
Quantidade de autores prováveis
At
rib
ui
çõ
es
 c
or
re
ta
s 
(%
)
O  mecanismo  de  escolha  que  apresentou  melhor  resultado  foi  a  escolha  do  autor  que 
possuísse o menor valor de NCD em relação ao documento questionado. Comparando-se com os 
resultados obtidos  anteriormente por Varela (2010), foram obtidos resultados superiores em 2,34 
pontos  percentuais  quando  utilizado  o  compressor  PPMD  e  2,26  pontos  percentuais  quando 
utilizado o compressor Zip. Ou seja, o uso da NCD significou um ganho de aproximadamente 2% 
em relação a resultados obtidos anteriormente, para uma base de dados que apresentava algumas 
dificuldades a mais (pois os 10 arquivos repetidos foram retirados da base original).
O aumento da quantidade de autores possíveis significou uma piora nos resultados obtidos. 
Para o compressor PPMD a diminuição de atribuições corretas foi de 9,34 pontos percentuais, para 
o compressor  Zip  a  diminuição foi  de 9,13 pontos  percentuais.  Em um teste  realizado em um 
subconjunto da base de testes, verificou-se que o aumento da quantidade de autores prováveis de 10 
para 100 resultou em uma piora de 11 pontos percentuais. Para um aumento de 10 para 30 autores  
possíveis houve uma diminuição de 6 pontos percentuais no desempenho.
A NCD pode ser calculada com qualquer compressor de arquivos. Nos testes, verificou-se 
que  os  compressores  PPMD  e  Zip  apresentam  os  melhores  resultados,  e  o  compressor  Bzip 
apresenta um resultado inferior ao obtido em um trabalho anterior que utilizava um classificador 
SVN. Para documentos de texto, em regra, são aplicados compressores que não apresentem perdas 
(lossless), pois é interessante que o documento de texto possa ser reconstruído fielmente a partir dos 
dados armazenados de maneira comprimida. Em trabalhos futuros, entretanto, deverá ser verificado 
se  o  uso  de  compressores  com  perdas  poderão  aceitáveis  para  o  cálculo  da  NCD,  pois  os 
compressores  de  dados  são  utilizados  para  aproximar  a  complexidade  de  Kolmogorov  e, 
eventualmente, perdas controladas no conteúdo do documento poderão levar a uma melhor extração 
de características estilométricas do autor.
O fato  dos  arquivos  da base de  dados bruta  apresentarem dados que possam auxiliar  a 
identificação da autoria ou da área de conhecimento pode ser significativa para os trabalhos de 
perícia. Não se  espera que um perito atribua a autoria de um documento eletrônico a um autor 
apenas porque há um nome como “Paulo Coelho” na última linha deste documento. Desta forma, 
antes do uso de ferramentas computadorizadas para o auxílio da perícia, é necessário que seja feita 
uma análise dos documentos questionados e dos documentos de conhecimento do autor, evitando-se 
que  estas  informações  se  tornem  significativas  para  a  técnica  utilizada  e  levem  a  resultados 
errôneos. O fato do presente trabalho utilizar uma base de dados refinada, com 10 documentos 
diferentes em relação à base utilizada por Varela (2010), poderia apresentar apenas uma diferença 
mínima nos resultados obtidos. Os 10 documentos representaram uma alteração de apenas 0,3% dos 
documentos presentes na base de dados. Por exemplo, no resultado médio obtido no primeiro teste 
efetuado (5.1 Menor medida de NCD), se houvessem os dez documentos duplicados apresentados 
originalmente e estes 10 documentos fossem testados e atribuídos ao autor correto, as taxas médias 
de acerto aumentariam para 70,69 % (Bzip), 74,47% (PPMD) e 74,39% (Zip), uma diferença de 0,4 
pontos percentuais.
Por fim, a possibilidade de comparação com resultados obtidos em outros trabalhos Varela 
(2010) permite que os avanços no uso de modelos computacionais para o auxílio do trabalho de 
peritos possam ser confrontados e aperfeiçoados. A possibilidade do uso de outros compressores 
(inclusive  com perdas)  e  o  uso  de  outros  mecanismos  de  escolha  a  partir  dos  resultados,  em 
trabalhos futuros, poderão aumentar os resultados obtidos pelo método NCD.
7. Referências
Burrows M, Wheeler DJ. A block-sorting lossless data compression algorithm. Digital Equipment 
Corporation: SRC Research Report 124, 1994.
Cebrián,  M.,  Alfonseca,  M. e  Ortega,  A. “Common pitfalls  using the Normalized Compression 
Distance:  what  to  watch  out  for  in  a  compressor”.  In  Communications  In  Information  And 
Systems, volume 5, n. 4, p. 367-384, 2005.
Cilibrasi,  R.  (2006)  “Statistical  Inference  Through  Data  Compression”.  Institute  for  Logic, 
Language and Computation, Universiteit van Amsterdam.
Kolmogorov, A. N. Three Approaches to the Quantitative Definition of Information. Problems of 
Information Transmission, vol. 1, número 1, 1965
M.  Li  and  P.M.B.  Vitanyi,  An  Introduction  to  Kolmogorov  Complexity  and  its  Applications, 
Springer-Verlag, New York, First Edition, 1993
R. Cilibrasi, R. de Wolf, P. Vitányi, Algorithmic clustering of music, Proc IEEE 4th International 
Conference on Web Delivering of Music (WEDELMUSIC 2004), IEEE Comp. Soc. Press, 2004, 
110-117.
Salomon, D. Data Compression: The Complete Reference, Volume 10, 2007, Springer.
Shkarin,  D.  PPM: One Step  to  Practicality,  Proceedings  of  the  Data  Compression  Conference, 
p.202, Abril, 2002 
Stamatatos,  E.  (2008) “A survey of  modern  authorship  attribution  methods”.  In  Journal  of  the 
American Society for  Information Science and Technology,  volume 60, issue 3,  p.  538-556, 
Março de 2009.
Varela,  P.  J.  (2010)  “O uso  de  atributos  estilométricos  na  identificação  da  autoria  de  textos”. 
Programa  de  Pós-Graduação  em  Informática  Aplicada,  Pontifícia  Universidade  Católica  do 
Paraná, Brasil.
