Binary Cybergenre Classification Using Theoretic Feature Measures 
 
 
Lei Dong, Carolyn Watters, Jack Duffy, Michael Shepherd 
Dalhousie University, Halifax, Nova Scotia, Canada 
{ldong, watters, shepherd@cs.dal.ca; jack.duffy@dal.ca} 
 
 
Abstract 
 
In this study, we conducted an investigation on 
automatic genre classification for three common types of 
web pages addressing the effect of three theoretic feature 
selection measures, a range of feature set size, and three 
machine classifiers on the accuracy of the web page 
classification in the context of a set of controlled 
experiments. Our results are encouraging and we 
conclude that for binary classification tasks, at least for 
these web page genres, it is possible to reach satisfying 
results with small content-based feature sets generated 
with a sound feature selection measure and furthermore 
there is no evidence of interaction between these feature 
selection measures and the machine classifiers used. 
 
1. Introduction 
 
The issue of relevance has become more critical as 
search engines retrieve too many documents and most 
users are now only  check out the top 20 retrieved pages. 
Furthermore, the traditional ranking of search results is 
not particularly useful to users of the Web. The use of 
classification within the retrieved results of search engine 
is one approach to this problem. Genre is a variation of 
classification that is based on shared understandings of 
the communicative purpose that has been used for a long 
time to classify discourse and written communication. 
Genre may be used to help the user by identifying types 
of pages within the retrieved documents, which reflect to 
some extent the intend of the author.  In a recent study 
Meyer and Stein [10] found that 64% of the students in 
the study regarded automated genre classification as 
potentially very useful for web search.  
The Web affords instances of genre that are both 
familiar, such as scholarly papers and newspapers, and 
novel, such as FAQ and home pages [2, 15]. These digital 
genre constantly change and evolve from variants of 
existing paper-based genres such as news to emergent or 
novel cybergenres such as the FAQ and the home page. 
Various attempts at classifying cybergenre have resulted 
in the identification of up to 1000 genres [2, 12].  
There are two difficulties with genre classification of 
web pages; understanding the taxonomy of web genre and  
automatic identification of genre. In this paper we 
concentrate on the automatic identification of web genre.  
Key to the success of automatic genre identification is the 
selection of feature sets from the source documents to 
optimize the results of classifying algorithms. 
 
2. Background review and issues 
 
Genre theory [6,11,19] has recently been of interest to 
the digital world to address information communication 
issues on the Web [2]. Shepherd & Watters [15] proposed 
the term cybergenre as the triple (content, form, 
functionality), which takes the functionality afforded by 
the Web into account. This definition extends the possible 
attributes from which computer-recognizable information 
elements could be retrieved [1, 4]. Early work on 
automatic genre classification [7, 17, 8] was largely done 
without a clear discussion of genre on the Web.  
Concerns over the role of genre reflect, in part, the role 
of the Web as a social communication medium [3]. 
Progress on automatic genre classification of web pages 
requires both an articulation of such genre and the 
identification of feature sets that can be used by classifiers 
in a robust and efficient manner. 
Santini [13] used a feature set that included both 
linguistic features and HTML tags in cluster analysis to 
identify potential relationships between genre,   rhetorical 
types and layout structures.  Lim et al. [9] investigated the 
usefulness of a variety of feature sets using a data corpus 
of 16 genres from a collection of Korean Web pages. 
They found most useful features included the URL, 
HTML tags, token information, function words, and 
punctuation marks and chunks. In earlier work Shepherd 
et al [16] used Principal Component Analysis on a 
combined feature set of content, form, and functionality 
features, and showed that it was possible to correctly 
classify personal homepages and corporate homepages 
while difficult to classify correctly organizational 
homepages. 
In this paper, we examine the potential of three 
theoretic measures, Information Gain, Mutual 
Information, and Chi statistic as feature set selection tools 
from Web page content. The advantage of using theoretic 
measures rather than observational characteristics [17, 5, 
Proceedings of the 2006 IEEE/WIC/ACM International Conference
on Web Intelligence (WI 2006 Main Conference Proceedings)(WI'06)
0-7695-2747-7/06 $20.00  © 2006
10] is that explorations of the effects of known changes 
can be conducted that may be generalizable. We argue 
that it is important to employ feature measuring 
algorithms that have solid theoretical background, based 
on the goodness of each individual feature and rule out 
the less informative ones according to the resulting 
goodness scores. More over, it is also important to 
explore all possible features with no preference imposed 
on a particular type of features, so that the best set of 
features can be generated using a feature selection 
measure over all the candidate features. 
 
3. Research problem 
 
In this work, we address the problem of identifying 
instances of a specific genre out of sets of documents of a 
variety of genres. For this study we have chosen three 
specific genres, FAQ, e-Shopping and personal 
homepages. Our goal is to develop a genre classification 
process that is both efficient and reasonably accurate. 
There are two components of this process; feature set 
identification and document classification. Our hypothesis 
is that we can use theoretically sound means to generate 
compact feature sets that will be effective input to 
classification algorithms. 
 
4. Feature selection measures 
 
Three well known feature selection measures [18], 
Information Gain, Mutual Information and Chi Statistic, 
were used in this study. Information Gain and Mutual 
Information are probability based measures while the Chi 
Statistic is statistically based. Statistical analyses were 
applied to examine any significant differences in the 
results of these measures. 
 
5. Data corpus 
 
The experiments  evaluate the feature sets generated by 
the three theoretic measures for three specific web genres, 
Personal Homepage, FAQ and e-Shopping. A data corpus 
of 1170 web pages was created that included 190 
instances of each of these genre in the test collection plus 
600 random web pages as true noise. The FAQ and e-
Shopping pages were taken from the Santini’s genre 
collection (www.itri.brighton.ac.uk/~Marina.Santini/). A 
set of 190 PHPs were collected and validated using the 
random Google feature at http://www.mangle.ca. In 
addition, a random sampling of 600 web pages, called 
MIX, was also created using http://www.mangle.ca. The 
web pages in the MIX component were judged not to be 
FAQ, e-Shopping or personal home pages by the 
researchers. 
 
6. Experimental method 
 
Three conventional supervised classifiers were used to 
classify the pages from the data corpus: Naïve Bayes 
(NB), Neural Networks (NN) and Support Vector 
Machine (SVM). Statistical analyses were applied to the 
resulting accuracy of the classification to reveal any 
significant differences. 
For each of the three feature selection methods we 
used three feature set sizes; 5, 20 and 100.  As the sample 
size is relatively small 10-fold cross validation was 
applied in each experiment for validity.  
Each experiment was a binary classification, where the 
goal was to identify one of the genre from a data set 
containing examples of the genre of interest plus noise 
data that was a combination of samples from the other 
genre and the random noise web pages. The noise data 
were referred to as MIXP, MIXF and MIXE, where 
MIXP were documents other than personal home pages, 
MIXF were documents other than FAQ pages, and MIXE 
were pages other than e-Shopping pages. Feature sets, of 
5, 20, and 100 features, were first derived for each of the 
three genre using the three different metrics. For each pair 
of categories, the three classifiers were then applied in 
turn to each of the three feature sets per genre, running a 
ten-fold cross validation. 
 
7. Results 
 
Since the membership of each genre was known at the 
outset two measures of accuracy were used: Precision and 
Recall.  
 
Figure 1 Precision and recall rates of e-shop and MIX 
 
Figure 1 shows the precision and recall rates resulting 
from classification experiments between e-shop and MIX 
categories, which were done with different settings of 
feature selection measures, classifiers and feature sizes. 
The average precision rates are 0.853 for 5 features, 0.88 
Proceedings of the 2006 IEEE/WIC/ACM International Conference
on Web Intelligence (WI 2006 Main Conference Proceedings)(WI'06)
0-7695-2747-7/06 $20.00  © 2006
for 20 features, 0.87 for 100 features, and 0.868 for all 
cases.  The average recall rates are 0.832 for 5 features, 
0.867 for 20 features, 0.858 for 100 features, and 0.852 
for all cases.   
 
Figure 2 Precision and recall scores of FAQ and MIX 
 
Figure 2 shows the precision and recall rates resulting 
from classification experiments between FAQ and MIX 
categories, which were done with different feature 
selection measures, classifiers and feature sizes. The 
average precision rates are 0.886 for 5 features, 0.92 for 
20 features, 0.974 for 100 features, and 0.927 for all 
cases.  The average recall rates are 0.873 for 5 features, 
0.903 for 20 features, 0.973 for 100 features, and 0.916 
for all cases.   
 
 
Figure 3. Precision and recall scores of PHP and MIX 
Figure 3 shows the precision and recall rates resulting 
from classification experiments between PHP and MIX 
categories, which were done with different settings of 
feature selection measures, classifiers and feature sizes. 
The average precision rates are 0.834 for 5 features, 0.87 
for 20 features, 0.864 for 100 features, and 0.927 for all 
cases.  The average recall rates are 0.821 for 5 features, 
0.86 for 20 features, 0.85 for 100 features, and 0.844 for 
all cases. 
ANOVA was applied over feature selection measures, 
which were calculated based upon the classification rates 
of precision and recall respectively, in various feature 
sizes and participating categories.  Only in the case of 
FM005 (5 features with FAQ and MIX in the experiment) 
was significance reached for precision and recall at .05 
level, which means there is a significant difference of 
measure in term of affecting classification accuracy. A 
further look at the results (Figure 2) shows that Mutual 
Information is the most unstable measure among the 
measures used. 
Factorial ANOVA on the interaction effect between 
feature selection measures, learners and categories used 
was applied.  There is no interaction at a significance 
level of .05, between the feature selection measures and 
classifier algorithm, in term of either precision or recall. 
From this observation, we can tell that in our studies, 
feature selection measures and classifiers affect 
experiment results independently 
 
8. Discussion 
 
The performance for e-Shopping (EM) and Personal 
Homepage (PM) was very similar. In the experiments of 
Frequently Asked Questions (FM), the performance of 
both precision and recall is very high with most of the 
rates between 90 and 100 percent.  
The ANOVA indicates that the three feature selection 
measures do not differ at the 0.05 level in term of both 
precision and recall, using 20 or 100 features. In this case, 
one can suggest that all of the measures performed 
equally well and that considerations of efficiency may 
determine which one is more appropriate to use. 
The observation that all three feature set selection 
methods work well can be explained by the amount of 
overlap that exists in the feature sets generated separately 
using the three measures. When the feature set is 
restricted to a very small number of features, the 
classification performance would be sensitive to even 
slight differences among the features generated by the 
different measures. As result, significant difference could 
be more easily observed with very small number of 
features. As the feature size increases to 20 or 100, the 
performance becomes less sensitive to the slight 
differences of ranking of the terms.  
The ANOVA analysis with respect to measures shows 
that only 2 out of 18 cells were significant. Therefore, we 
declined to over interpret the 2 significant differences. 
Instead, we conclude that the three feature selection 
measures achieve a certain degree of agreement on the 
good features resulting in overlap in the resulting feature 
sets and that preference may be given to the simplest 
method, the Chi Statistic.  
Proceedings of the 2006 IEEE/WIC/ACM International Conference
on Web Intelligence (WI 2006 Main Conference Proceedings)(WI'06)
0-7695-2747-7/06 $20.00  © 2006
No significant interaction between the learning 
methods and the feature selection measures across all the 
conditions and for both precision and recall.  From this 
we conclude that the feature sets are robust enough to be 
independent of the machine classifier used. 
 
9. Conclusions 
 
The results of this work indicate promise in the use of 
theoretic measures to identify small feature sets from the 
contents of web pages that are useful as input to typical 
machine classifiers for the three genres in question: 
Personal home pages, FAQ, and e-shopping. Average 
recall rates of the results were over 80%; 85.2% for e-
shop and MIX, 91.6% for FAQ and MIX and 84.4% for 
PHP and MIX, and average precision rates of the results 
were 86.8% for e-shopping, 92.7% for FAQ, and 92.7% 
for PHP. 
Although all  three theoretic feature selection 
measures, Information Gain, Mutual Information and Chi 
Statistic, have enough power to detect small sets of 
discriminating features for this purpose, Information Gain 
and Chi Statistic provided consistently good performance 
even for feature sets as small as 5. 
Furthermore, no interaction was found between the 
feature selection measures and the machine classification 
methods used, which indicates that fine tuning of systems 
to pair the best feature set selection method to the most 
appropriate classifier may not be a critical issue 
 
10. References 
 
[1] Askehave, I. and Ellerup Nielsen, A., What are the 
Characteristics of Digital Genres? - Genre Theory from a Multi-
Modal Perspective, Proceedings of the 38th Annual Hawaii 
International Conference on System Sciences, 2005 
[2] Crowston, K. and Williams, M. 1997. Reproduced and 
Emergent Genres of Communication on the World-Wide-Web. 
Proceedings of the Thirtieth Annual Hawaii International 
Conference on Systems Sciences, vol. 6, pp. 30-39. 
[3] Dillon, A. & Gushrowski, B. 2000. Genres and the Web: Is 
the personal home page the first uniquely digital genre? Journal 
of the American Society for Information Science, 51 (2), 
202-205. 
[4] Erickson, T., “Social Interaction on the Net: Virtual 
Community as Participatory Genre”, In Proceedings of the 
Thirtieth Annual Hawaii International Conference on 
System Sciences, Maui, Hawaii, 1997, Vol. VI, pp. 13-21. 
[5] Finn, A. and Kushmerick, N. 2003. Learning to classify 
documents according to genre. In IJCAI-03 Workshop on 
Computational Approaches to Style Analysis and Synthesis. 
[6] Holman, C. H. 1972. A handbook to literature (3rd ed). 
New York: Odyssey Press. 
[7] Karlgren, J. and Cutting, D. 1994. Recognizing text genres 
with simple metrics using discriminant analysis. In Proceedings 
of the 15th. International Conference on Computational 
Linguistics (COLING 94), volume II, pages 1071 – 1075, 
Kyoto, Japan. 
[8] Lee, Y. and Myaeng, S. H. 2002. Text Genre Classification 
with Genre-Revealing and subject-Revealing Features. 
Proceedings of SIGIR-02, 25th ACM International 
Conference on Research and Development in Information 
Retrieval, eds. M. Beaulieu, R. Baeza-Yates, S.H. Myaeng & 
K. Jarvelin, ACM Press, New York, US: Tampere, FI, pp. 145–
150. 
[9] Lim, C.S., Lee, K. J. and Kim, J. C. 2005. Multiple sets of 
features for automatic genre classification of web documents. 
Information Processing & Management Volume 41, Issue 5, 
Pages 1263-1276 
[10] Meyer zu Eissen S. and Stein, B. 2004. Genre classification 
of web pages. In Proc. of the 27th German Conference on AI 
(KI-2004), Ulm, Germany, Sept. 20-24. 
[11] Orlikowski, W. J. and Yates, J. 1994. Genre repertoire: The 
structuring of communicative practices in organizations. 
Administrative Sciences Quarterly, 33, 541-574.  
[12] Roussinov, D., Crowston, K., Nilan, M., Kwasnik, B., Cai, 
J. and Liu, X. 2001. Genre based navigation on the web. In 
Proceedings of the 34th Hawaii International Conference on 
System Sciences. IEEE Computer Society Press 
[13] Santini, M. 2005. Genres In Formation? An Exploratory 
Study of Web Pages using Cluster Analysis, Proceedings of the 
8th Annual Colloquium for the UK Special Interest Group 
for Computational Linguistics (CLUK 05), University of 
Manchester (UK). 
[14] Shepherd, M. & Watters, C. 1998. The Evolution of 
Cybergenres. In Proceedings of the 31st Hawaii International 
Conference on System Sciences. IEEE Computer Society Press 
[15] Shepherd, M. & Watters, C. 1999. The Functionality 
Attribute of Cybergenres. In Proceedings of the 32nd Hawaii 
International Conference on System Sciences. IEEE 
Computer Society Press 
[16] Shepherd, M., Watters, C. and Kennedy, A. 2004. 
Cybergenre: automatic identification of home pages on the Web. 
Journal of Web Engineering, Vol. 3, No. 3&4. pp. 236-251. 
[17] Stamatatos, E., Fakotakis, N. and Kokkinakis, G. 2000 . 
Text genre detection using common word frequencies. 
International Conference On Computational Linguistics 
archive Proceedings of the 18th conference on 
Computational linguistics - Volume 2. 
[18] Yang, Y. and Pedersen, O. 1997. A Comparative Study on 
Feature Selection in Text Categorization. In Proceedings of 
ICML-97, 14th International Conference on Machine 
Learning. 412--420. 
[19] Yates, J. and Orllikowski, W. J. 1992. Genres of 
organizational communication: A structurational approach to 
studying communication and media. Academy of Management 
Review, 17(2), 299-326. 
Proceedings of the 2006 IEEE/WIC/ACM International Conference
on Web Intelligence (WI 2006 Main Conference Proceedings)(WI'06)
0-7695-2747-7/06 $20.00  © 2006
