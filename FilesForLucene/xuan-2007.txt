 
A. Gelbukh (Ed.): CICLing 2007, LNCS 4394, pp. 186 – 195, 2007. 
© Springer-Verlag Berlin Heidelberg 2007 
Tagging Sentence Boundaries in Biomedical Literature 
Weijian Xuan, Stanley J. Watson, and Fan Meng 
Molecular and Behavioral Neuroscience Institute and Department of Psychiatry 
University of Michigan, Ann Arbor, Michigan 48109 
mengf@umich.edu 
Abstract. Identifying sentence boundaries is an indispensable task for most 
natural language processing (NLP) systems. While extensive efforts have been 
devoted to mine biomedical text using NLP techniques, few attempts are 
specifically targeted at disambiguating sentence boundaries in biomedical 
literature, which has a number of unique features that can reduce the accuracy 
of algorithms designed for general English genre significantly. In order to 
increase the accuracy of sentence boundary identification for biomedical 
literature, we developed a method using a combination of heuristic and 
statistical strategies. Our approach does not require part-of-speech taggers or 
training procedures. Experiments with biomedical test corpora show our system 
significantly outperforms existing sentence boundary determination algorithms, 
particularly for full text biomedical literature. Our system is very fast and it 
should also be easily adaptable for sentence boundary determination in 
scientific literature from non-biomedical fields.  
1   Introduction 
High throughput experiment approaches, such as genome-wide or organism-wide 
expression profiling studies, significantly enrich biomedical literature and at the same 
time, make computer-based literature mining almost a necessity in biomedical 
research.  Since most of the experiment results are still summarized and presented in 
free text format, automated methods for extracting relevant information in Medline as 
well as full length text literature can be very helpful for the understanding of 
biological significance of high throughput results. The Medline database [1] already 
contains over 16 million citations, and more than half a million new records were 
added into the Medline database last year. In addition, the availability of full length 
papers in electronic format has also greatly improved in the last decade. Out of 19448 
journals included in the PubMed, 5426 journals provide online access of full length 
papers in electronic format. The extensive access to full length papers as well as 
abstracts provides unprecedented opportunities for understanding the biomedical 
significance of high throughput data through computer-based literature mining. In 
deed, extensive efforts have been devoted to develop literature mining systems that 
aim at mining important entities, experimental evidences, interactions, hypothesis and 
other domain knowledge from free text.  
One of the common features of text mining systems is the incorporation of NLP 
techniques. Many NLP techniques, such as part-of-speech (POS) taggers [2], sentence 
 Tagging Sentence Boundaries in Biomedical Literature 187 
 
alignment [3] and text segmentation [4], require that texts have already been 
segmented into sentences. In the Information Retrieval (IR) field, recent researches 
have taken the sentence as the frame/conceptual unit for the identification of true term 
dependencies [5] and the evaluation of pairwise sentence similarity [6]. In practice, 
isolating sentences is a prerequisite for virtually any syntactic analysis of text corpus. 
Sentence Boundary Disambiguation (SBD) may appear to be an easy task. In 
reality, however, achieving high accuracy for the purpose of literature mining is not a 
trivial problem due to the ambiguity of punctuation marks. For example, while an 
exclamation point or a question mark is almost always indicating the end of a 
sentence, the most frequently used period is very ambiguous. A period can signal a 
decimal point, a sentence boundary, an abbreviation, or even an abbreviation at a 
sentence boundary. In about 6 million Medline abstracts we investigated, about 33% 
of the periods are ambiguous.  
There are already some reports on identifying sentence boundaries in general 
English literature. The first class of approaches for SBD uses rule-based methods. 
Cherry and Vesterman [7] implemented the UNIX STYLE program that recognized 
sentence boundaries mainly through a short list of abbreviations and a lexicon of 
known words. Aberdeen at al [8] developed a sentence splitting module containing 75 
abbreviations and over 100 regular expression rules written in Flex. There are also 
two Perl modules (http://www.cpan.org), Text::Sentence and Lingua::EN::Sentence, 
designed for the SBD purpose using regular expressions.  
Machine learning algorithms are used in the second class of approaches. They 
basically utilize features of context words surrounding the ambiguous punctuation 
mark and treat the sentence tagging task as a classification problem. The Wall Street 
Journal (WSJ) corpus and the Brown corpus are usually used for the evaluation of 
various SBD solutions. Palmer and Hearst [9] presented a system, SATZ, for SBD 
task. They used POS information of context words. Nevertheless, they found the SBD 
task and POS tagging is a chicken and egg problem. To circumvent this problem, they 
utilized prior probabilities of POS assignments, as opposed to definite POS 
assignments, as contextual information. They achieved around 99% accuracy on the 
WSJ corpus. Humphrey and Zhou [10] described a feed-forward neural network to 
disambiguate periods, but did not report the accuracy of their results. Stamatatos et al 
[11] presented a simplified version of Transformation Based Learning theory for the 
automatic extraction of rules for the SBD task. Mikheev [12] tackled the SBD task 
through a variation of POS tagging framework. They claimed 0.8% and 1.2% error 
rate on WSJ and Brown corpus, respectively. Reynar and Ratnaparkhi [13] applied a 
maximum entropy approach to the problem. They presented a trainable model that 
requires no hand-crafted rules, lexicon, POS tags, or domain knowledge. Their 
method achieved 98.8% accuracy on the WSJ corpus and 97.9% on the Brown 
corpus.  
Given the high accuracy of aforementioned methods, it would seem that the SBD 
problem has largely been solved. However, these approaches were not designed to 
deal with the SBD problem in biomedical literature thus some of their assumptions 
and methods are not appropriate for biomedical texts. For example, a common 
postulation in rule-based approaches stipulates if the word immediately before an 
ambiguous period is a single uppercase letter then the period does not denote a full-
stop. Nevertheless, in molecular biology literature, a lot of gene/protein names end 
188 W. Xuan, S.J. Watson, and F. Meng 
 
with a single uppercase letter, e.g. cyclin F, and it is common to have such gene 
names at the end of a sentence. The performance of machine learning approaches 
highly depends on the quality, the content and even the size of the training corpus. 
Generating an appropriate corpus that covers most of the unique issues in biomedical 
literature for effective training purpose requires considerable human effort. 
Furthermore, in biomedical literature, there are much more unknown words and 
abbreviations than in general domain. As a result, none of these methods perform well 
on biomedical corpora. 
In this paper, we present an efficient method for tagging sentence boundaries in 
biomedical literature using a combination of heuristic and statistical strategies. Our 
method does not require part-of-speech taggers or training procedures. Experiments 
with both Medline abstracts and full length papers show the accuracy of our method is 
significantly better than existing systems on biomedical corpora. Our program is also 
very fast and it allows the on-the-fly processing of biomedical literature. The program 
is available upon request, and the online evaluation version is available at: 
http://brainarray.mbni.med.umich.edu/sbd.asp. 
2   Methods 
In this section, we will first describe the special features of biomedical text related to 
the SBD problem and then present our solution. 
2.1   Special SBD Issues in Biomedical Literature 
After a comprehensive investigation of characteristics of sentence boundaries in 
biomedical literature, we identified several unique features that differentiate 
biomedical literature from regular English text for the SBD task.  
1. Abbreviations 
It is well known that biological and medical literature contain considerable number 
of abbreviations. For example, E.coli, i.c.v., N. lactamdurans, Hs.1259, M.HsaIIP, C. 
elegans, H2B.1B, S. pombe, etc. Large amount of abbreviations containing period(s) 
is one of the major sources of errors in sentence boundary determination of existing 
SBD programs. 
2. Proper names 
In biomedical field, especially in molecular biology, there are a lot of domain-
specific proper names, e.g. gene/protein names. They can be in various case forms, 
i.e., uppercase, lowercase, capitalized or mixed forms, e.g., A2MP and hA2aR. It’s not 
uncommon to begin a sentence with lowercased proper names such as, “hKv beta 3 
was …”, “p230 also includes …” and “hRCE1 activity was …”. 
In regular English corpus, when an abbreviation is followed by a period and the 
word following a period is number or lowercased word, then the period does not 
denote a sentence boundary [12]. Apparently, this assumption does not hold in 
biomedical literature, as we have a large amount of abbreviations appear at the end  
of sentences and lowercased proper names frequently show up at the beginning  
of sentences. 
 
 Tagging Sentence Boundaries in Biomedical Literature 189 
 
3. Lack of naming convention 
Unlike general English literature, biomedical text contains a large amount of 
compound words not recorded in regular dictionaries. The lack of naming convention 
has led to the naming “chaos” and the same concept can be expressed in many 
different ways. This situation significantly degrades the results of classic POS taggers. 
As a result, SBD algorithms based on POS taggers will obtain less accuracy on 
biomedical corpora than on general corpora. 
4. Complex citations 
Biomedical text corpus usually contains citations. These citations consist of, 
among others, author names and journal/conference names. These names often appear 
in the form of abbreviation (e.g., “Acta Physiol. Pol. 1975, 26 (1): 1-11.”, “Roe. Li, 
Z., Xia, L., Lee, L. M., Khaletskiy, A., Wang, J., Wong, J. Y. C. and Li, J-J.”, and “M. 
Fransen, P.P. Van Veldhoven, S. Subramani, Biochem. J. 340 (1999) 561-568”). Even 
in Medline abstracts, various forms of citations appear frequently. Existing SBD 
algorithms were not designed to handle such citations effectively.  
5. Conversion problem 
Another problem we identified in Medline records or full text papers is that the 
conversion from either PDF or HTML to text format, or the generation of text using 
Optical Character Recognition (OCR) may produce erroneous results. For example, 
“Ang I·mL-1·h-1” may become “Ang I. mL(-1). h(-1)”, and “1.5-3.0 mM” may become 
“1 . 5-3 . 0 mM” after format conversion. 
In general, these issues are more significant in full length papers since more 
abbreviations, citations, alternative descriptions are used than those in Medline 
abstracts. The diversity as well as the subtleness of these unique features makes 
machine learning approaches inefficient for achieving high accuracy in SBD for 
biomedical literature, unless significant efforts can be devoted for tagging large 
volumes of error-free training corpus from different areas of biomedical research. 
Consequently, we believe that the rule-based approach is more suitable for the SBD 
task on biomedical literature.  
2.2   Rule-Based Approach for Biomedical Literature SBD 
Based on the above analysis, we developed a set of heuristic rules to deal with unique 
issues for sentence boundary determination in biomedical literature. These rules are 
combined with resources derived from statistical analysis of biomedical literature for 
higher accuracy. We implemented our approach in Perl. 
1. Potential sentence boundaries 
In our system, we consider the “.”, “?”, “!” as potential sentence terminals. While 
there are also cases where the “:” and “;” may signal the end of a sentence, the 
frequency of their occurrence are negligible. For biomedical text, we found it is 
sufficient only to consider cases where “.”, “?”, “!” are immediately followed by 
spaces or punctuation marks.  
We first split the text at all potential boundaries, and use a series of rules to 
disambiguate the punctuation marks. Multiple adjacent fragments are concatenated if 
the punctuation marks between them do not signal a sentence terminal. 
2. Resources for abbreviation and author names 
Several existing knowledge bases in biomedical domain can be utilized for the 
SBD task. We extracted all abbreviations that contain periods (excluding decimal 
190 W. Xuan, S.J. Watson, and F. Meng 
 
points) from Unified Medical Language System (UMLS) [14] and the Entrez Gene 
database [15]. A total of 14746 compound abbreviations were extracted from these 
resources. We counted the frequency of every bigram, i.e., words immediate before 
and after a period. For example, “S. cerevisiae”, which occured 41 times in UMLS 
and Entrez Gene as a sub-string of compound terms. In addition, we manually 
constructed a list of 31 commonly used abbreviations, e.g. Dr., Prof. 
In order to better discriminate abbreviations associated with author names, we 
pulled out 320347 unique last names from over 12 million Medline citation records. 
Furthermore, we also compiled a list of 1223 tokens that potentially represent 
biomedical measuring units, e.g. mM, ng, kb, mol, kDa. Meanwhile, we compiled a 
list of 25143 common English words from expanded UNIX spelling dictionary. While 
these lists may never be complete, they are fairly comprehensive and can be easily 
integrated into our system. Such a collection of frequently used abbreviations in 
biomedical domain noticeably helps the disambiguation process. 
3. Sub-section segmentations 
We manually constructed a short list of 76 common words and their plural forms 
that are often used as a concise sub-title in an abstract. Some examples from this list 
are Aim, Background, Case, Comment, Conclusion, Design, Discussion, Guideline, 
Introduction, Method, Objective, Patient, Site, etc. If a potential sentence split in the 
first step contains only a capitalized word in this list, it indicates the beginning of a 
sub-section. Using such patterns, we are able to not only split sentences but also 
accurately segment the document into semantically coherent sub-sections. 
4. Sequential groups 
It’s common to find abstracts that contain multiple facts, e.g. assumptions, 
procedures, or results. For clarity and simplicity, these facts are usually grouped into 
sequential sentences by numbering “1., 2., 3., …”, “A., B., C., …”, “I., II., III., …”. A 
special algorithm was developed to identify such sequential groups. We first scan the 
document to detect potential sequential groups. We consider a target paragraph 
contains sequential groups if it consists of more than two consecutive Arabic 
numbers, English or Roman numerals, in increasing order. The identification of 
sequential sentences helps the disambiguation of sentence boundaries, particularly 
when there are multiple ambiguous abbreviations in a sentence. 
5. Embedded segmentations 
Some punctuation marks, including quotation marks, round brackets “()”, and 
square brackets “[]”, are usually used to enclose textual material, or to classify or 
group text. Multiple statements enclosed by these punctuation marks are semantically 
coherent. For example, in the sentence “The AMPK gene from rat has recently been 
cloned [Carling et al., J. Biol. Chem. 269 (1994) 11442-11448].”, a citation is 
enclosed by square bracket thus multiple periods in this passage indicate 
abbreviations rather than sentence stops. 
6. Abbreviation extraction 
While we constructed a large resource for biomedical abbreviations, it is 
impossible to include all abbreviations in our resource since new abbreviations are 
showing up from time to time. To dynamically identify abbreviations, we make use of 
three types of document- and corpus-level statistics: unigrams/bigrams, surface clues 
and templates.  
 Tagging Sentence Boundaries in Biomedical Literature 191 
 
For each period, except those denote decimal points, we consider the word 
immediately before it as a unigram. As mentioned previously, a bigram is defined as 
the word immediately before the period together with the word right after the period. 
We extract unigrams and bigrams in each document, excluding those that contain 
words included in our compiled list of common English word. Unigrams and bigrams 
occur frequently in corpus are likely to be abbreviations in the domain of a given 
corpus. Unigrams and bigrams occur frequently only in a subset of documents are 
potentially field-specific abbreviations.  
There are also surface clues we can use for high confidence dynamic abbreviation 
identification. For example, when a word is followed by a period and then a comma, 
the corresponding word must be an abbreviation. Conversely, when a word is 
followed by a period in some places but not by any punctuation marks in other 
contexts in the same document, it suggests that this word is usually not an 
abbreviation. When this occurs, it indicates that the period followed by this word 
signals a sentence terminal. 
For the high frequency abbreviations extracted from corpus-wide statistics, we also 
examine the features of their suffix, i.e. the characteristics of the word following it, 
for the purpose of generating templates useful for increase the accuracy of dynamic 
abbreviation identification. 
For example,  
− Abbreviations often followed by a numeral, e.g. Jan., No. 
− Abbreviations often followed by a lowercased word, e.g. i.e., vs. 
− Abbreviations often followed by a capitalized proper name, e.g. Prof. Fred,  
Dr. La 
7. Citation identification 
Biomedical literature frequently quotes other publications in the middle or at the 
end of sentences. Many journals use citation formats that contain author name initials 
and/or journal/conference abbreviations. Consequently, periods in citations are a 
major source of sentence boundary ambiguity.  
We found the following citation patterns frequently occur in biomedical literature: 
(1) Quotations in parenthesis or brackets. (2) Numbers including publication dates, 
journal volume/issues, and page numbers; single letter initials. (3) Last name for 
multiple authors. (4) Journal abbreviations that are often composed of multiple 
adjacent short words, e.g. “Natl. Acad. Sci.”. 
To enhance the accuracy of the identification of journal titles, we extracted 3610 
unique journal abbreviations from titles of 5748 journals that covered by ISI Journal 
Citation Report [16]. 
We consider a phrase as citation if it satisfies two or more of the above patterns. 
Periods within citations will not be treated as signals for the termination of a sentence. 
8. Handling Medline conversion error 
We found two main problems in the process of generating Medline records from 
journal publications. One is the conversion from superscript in formatted journal 
publications to regular characters in plain text and the conversion of middle dot 
symbol to period, i.e. “·” to “.”. This type of errors can be identified based on the 
observation that the superscripts are often enclosed by parentheses, which are added 
192 W. Xuan, S.J. Watson, and F. Meng 
 
during their conversion into regular character. In addition, in biomedical domain 
superscripts are usually digits or used mainly for expressing measuring units. For 
example, “Ang I ·mg of tissue-1· h-1”, is usually converted to “Ang I. mL(-1). h(-1)”. 
Once such patterns are detected immediately before and after a period, it indicates the 
occurrence of a dot symbol instead of a full sentence stop.  
The second problem is the insertion of spaces between digits and decimal points. If 
there is one single space both before and after a period, and the word before and after 
the space are both digits or measuring units or short symbols with case variations, it 
signals that a conversion problem rather than a sentence boundary. For example, 
“ADP.Pi” may become “ADP . Pi”, and “0.75 mM” may become “0 . 75 mM” in the 
Medline database. 
3   Results 
The maximum entropy method proposed by Reynar and Ratnaparkhi [13] is the most 
frequently cited work for sentence boundary determination. The maximum entropy 
approach does not require any supporting resources beyond the sentence-boundary 
annotated corpus. We therefore use their system as a benchmark in the evaluation of 
our method for sentence boundary determination in biomedical corpus. 
For evaluation purpose, we constructed a test corpus from depression research 
literature by retrieving all Medline abstracts related to the keyword “depression”. This 
search resulted in 101,048 abstracts. We randomly selected 500 of them as our test 
corpus and manually tagged sentence boundaries. In total, there are 3928 sentences in 
our test corpus.  
We use the standard measure of precision and recall for the performance evaluation 
of various methods. Errors fall into two categories: (1) false positive: a punctuation 
mark that a method erroneously labels as a sentence boundary; (2) false negative: an 
actual sentence boundary that a method does not label correctly. 
Since maximum entropy method requires a training corpus, we randomly selected 
another 1000 Medline abstracts related to depression, and we tagged sentence 
boundaries manually. We trained the maximum entropy system using 2000, 4000, and 
6000 sentences, and obtained error rate of 2.91%, 2.02% and 2.24% respectively.  
For comparison, we also evaluated two other publicly available programs: the 
MMTx from the National Library of Medicine [17] and the Sentence Splitter from 
University of Illinois (http://l2r.cs.uiuc.edu/~cogcomp). MMTx has a component for 
SBD. In our evaluation, we used its latest version (v2.4.B). Sentence Splitter is a 
program dedicated to sentence segmentation, and it is used by quite a number of NLP 
research groups. Table 1 is the summary of the comparison results from our test 
corpus. It seems all methods perform reasonably well with Medline abstracts but the 
error rate of our method is about one order of magnitude lower than other methods. 
Considering that SBD is usually a pre-processing step, even a small error rate in this 
phase may lead to a domino effect in some NLP applications such as identifying 
conceptual relationships. 
 
 
 Tagging Sentence Boundaries in Biomedical Literature 193 
 
Table 1. Results from the 500 Medline abstracts test corpus 
Methods Error rate 
Sentence 
detected 
False 
Positives 
False 
Negatives 
Our method 0.27% 3923 3 8 
Maximum Entropy 2.02% 3958 56 26 
Sentence Splitter 3.40% 3849 59 79 
MMTx 5.03% 3928 128 76 
Furthermore, full-length papers usually contain more complications than Medline 
abstracts. Therefore we further benchmarked the accuracy of above approaches on 
full-length biomedical literature. We selected 8 full-length papers in the area of 
molecular biology from the list of the most read papers on the PNAS website and 
manually tagged 1615 sentences. 
Table 2 clearly demonstrates that our method outperforms other approaches in 
disambiguating sentence boundaries of full-length biomedical text. Other approaches 
have higher false positive/false negative ratio, which suggests that they tend to over-
split sentences. For example, maximum entropy method generates false positive at 
some multi-word biomedical terms such as “C. elegans”, and MMTx raises false 
positives at author names such as “D. A. Pollen”. 
Table 2. Results on the molecular biology full-length test corpus 
Methods Error Rate 
Sentence 
Detected 
False 
Positives 
False 
Negatives 
Our method 1.23% 1598 4 21 
Maximum Entropy 6.75% 1700 111 26 
Sentence Splitter 5.27% 1624 58 49 
MMTx 15.6% 1686 128 76 
Most of the false negatives are due to abbreviations at the end of sentences. There 
are also some hard-to-catch rare exceptions, such as extraneous punctuations, e.g. 
ellipse, dashes, and unpaired parenthesis. 
Besides its accuracy, our method is also very fast. We analyzed whole Medline 
corpus from 1965 to July 21, 2006. There are a total of 15,995,358 citations, among 
which 8,325,901 have abstracts. On a PC (P4 2.8GHz) running Windows 2000, it 
took our system only 5.5 hours to tag sentence boundaries for the entire Medline 
collection. 
4   Discussion 
Biomedical text has some features that clearly differentiate it from text in the general 
genre for sentence boundary determination. By identifying these features and utilizing 
existing resources, we successfully developed a program that can determine sentence 
boundary in biomedical text with very high accuracy. In contrast, without taking note 
194 W. Xuan, S.J. Watson, and F. Meng 
 
of the aforementioned features of biomedical literature, other SBD approaches were 
unable to achieve good performance. 
We believe the accuracy of our system can be further improved by analyzing SBD 
errors on various biomedical sub-fields. Since our approach does not rely on any other 
natural language processing tools, particularly part-of-speech taggers and syntactic 
parsers, it significantly reduces processing overhead and achieves very good 
computing performance. Meanwhile, our method does not require any training 
procedures that are usually very time consuming. It can be easily integrated into many 
large biomedical literature mining systems.  
Given the performance of our method, it can be used in various literature mining 
systems. For example, it can be used to enhance the accuracy of biomedical entity 
identification [18]. When sentences are isolated, it becomes easier to disambiguate 
entity terms. Meanwhile, some biomedical mining systems use sentence as 
fundamental conceptual units [19]. Segmenting text into sentences with high accuracy 
will thus improve the effectiveness of these systems. 
Although our program is mainly targeted for the biomedical literature, it is likely to 
achieve good sentence boundary determination results for typical scientific literature. 
In fact, except for the resource for biomedical abbreviation, most of the complications 
specifically addressed by our program are shared by publications from different areas 
of scientific research. The fact that our program can incorporate abbreviation lists 
along with corpus-wide statistics will make the adaptation of our program for 
processing text from different scientific disciplines an easy task.  
Acknowledgements 
The authors are members of the Pritzker Neuropsychiatric Disorders Research 
Consortium, which is supported by the Pritzker Neuropsychiatric Disorders Research 
Fund L.L.C. This work is also partly supported by the National Center for Integrated 
Biomedical Informatics through NIH grant 1U54DA021519-01A1. 
References 
1. PubMed: http://www.ncbi.nlm.nih.gov/entrez, (2006) 
2. Brill, E.: Transformation-Based Error-Driven Learning and Natural Language Processing: 
A Case Study in Part of Speech Tagging. Computational Linguistics, 21(4) (1995) 543-565 
3. Brown, P.F., J.C. Lai, and R.L. Mercer: Aligning Sentences in Parallel Corpora. In 
Proceedings of the 29th Annual Meeting of the Association for Computational Linguistics, 
Berkeley, CA, USA (1991) 
4. Choi, F.Y.Y.: Advances in Domain Independent Linear Text Segmentation. In Proceedings 
of NAACL, Seattle, WA, USA (2000) 
5. Nallapati, R. and J. Allan: Capturing Term Dependencies Using a Sentence Tree Based 
Language Model. In Proceedings of CIKM ’02 conference, McLean, VA, USA (2002) 
6. Ponte, J.M. and W.B. Croft: Text Segmentation by Topic. In European Conference on 
Digital Libraries, Pisa, Italy (1997) 
7. Cheery, L.L. and W. Vesterman: Writing Tools - The STYLE and DICTION Programs. In 
4.4 BSD User's Supplementary Documents, Computer Science Research Group, Berkeley, 
CA, USA (1994) 
 Tagging Sentence Boundaries in Biomedical Literature 195 
 
8. Aberdeen, J., J. Burger, D. Day, L. Hirschman, P. Robinson, and M. Vilain: MITRE: 
Description of The Alembicsystem Used for MUC-6. In Proceedings of the 6th message 
understanding conference, Columbia, MD, USA (1995) 
9. Palmer, D.D. and M.A. Hearst: Adaptive Sentence Boundary Disambiguation. In 
Proceedings of the 4th Conference on Applied Natural Language Processing, Stuttgart, 
Germany (1994) 
10. Humphrey, T.L. and F. Zhou: Period Disambiguation Using a Neural Network. In 
International Joint Conference on Neural Networks, Washington, DC, USA (1989) 
11. Stamatatos, E., N. Fakotakis, and G. Kokkinakis: Automatic Extraction of Rules For 
Sentence Boundary Disambiguation. In Proceedings of the Workshop in Machine Learning 
in Human Language Technology, Advance Course on Artificial Intelligence, Chania, 
Greece (1999) 
12. Mikheev, A.: Tagging Sentence Boundaries. In Proceedings of NAACL, Seattle, WA, 
USA (2000) 
13. Reynar, J.C. and A. Ratnaparkhi: A Maximum Entropy Approach to Identifying Sentence 
Boundaries. In Proceedings of the 5th Conference on Applied Natural Language 
Processing, Washington, DC, USA (1997) 
14. Humphreys, B.L., D.A.B. Lindberg, S.H. M., and B.G. O.: The Unified Medical Language 
System: An informatics research collaboration. Journal of the American Medical 
Informatics Association, 5(1) (1998) 1-11 
15. Pruitt, K.D. and D.R. Maglott: RefSeq and LocusLink: NCBI Gene-Centered Resources. 
Nucleic acids research, 29(1) (2001) 137-140 
16. ISI: Journal Citation Reports. http://www.isinet.com, (2003) 
17. Aronson, A.R.: Effective Mapping of Biomedical Text to the UMLS Metathesaurus: The 
MetaMap Program. In Proceedings of AMIA Annual Symposium, Washington, DC, USA 
(2001) 
18. Xuan, W., S.J. Watson, H. Akil, and F. Meng: Identifying Gene and Protein Names from 
Biological Texts. In Proceedings of Computational Systems Bioinformatics, Stanford, CA, 
USA (2003) 
19. Christian Blaschke, M.A.A., Christos Ouzounis, Alfonso Valencia: Automatic Extraction 
of Biological Information from Scientific Text: Protein-Protein Interactions. In 
Proceedings of the AAAI Conference on Intelligent Systems in Molecular Biology, 
Bethesda, MD, USA (1999) 
  
  
