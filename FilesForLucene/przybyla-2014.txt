This article was downloaded by: [University of Aegean]
On: 19 August 2014, At: 06:25
Publisher: Routledge
Informa Ltd Registered in England and Wales Registered Number: 1072954
Registered office: Mortimer House, 37-41 Mortimer Street, London W1T 3JH,
UK
Journal of Quantitative
Linguistics
Publication details, including instructions for authors
and subscription information:
http://www.tandfonline.com/loi/njql20
Analysing Utterances in Polish
Parliament to Predict Speaker’s
Background
Piotr Przybyłaa & Paweł Teisseyrea
a Institute of Computer Science, Polish Academy of
Sciences, Warsaw, Poland
Published online: 13 Aug 2014.
To cite this article: Piotr Przybyła & Paweł Teisseyre (2014): Analysing Utterances in
Polish Parliament to Predict Speaker’s Background, Journal of Quantitative Linguistics,
DOI: 10.1080/09296174.2014.944330
To link to this article:  http://dx.doi.org/10.1080/09296174.2014.944330
PLEASE SCROLL DOWN FOR ARTICLE
Taylor & Francis makes every effort to ensure the accuracy of all the
information (the “Content”) contained in the publications on our platform.
However, Taylor & Francis, our agents, and our licensors make no
representations or warranties whatsoever as to the accuracy, completeness, or
suitability for any purpose of the Content. Any opinions and views expressed
in this publication are the opinions and views of the authors, and are not the
views of or endorsed by Taylor & Francis. The accuracy of the Content should
not be relied upon and should be independently verified with primary sources
of information. Taylor and Francis shall not be liable for any losses, actions,
claims, proceedings, demands, costs, expenses, damages, and other liabilities
whatsoever or howsoever caused arising directly or indirectly in connection
with, in relation to or arising out of the use of the Content.
This article may be used for research, teaching, and private study purposes.
Any substantial or systematic reproduction, redistribution, reselling, loan, sub-
licensing, systematic supply, or distribution in any form to anyone is expressly
forbidden. Terms & Conditions of access and use can be found at http://
www.tandfonline.com/page/terms-and-conditions
D
ow
nl
oa
de
d 
by
 [
U
ni
ve
rs
ity
 o
f 
A
eg
ea
n]
 a
t 0
6:
25
 1
9 
A
ug
us
t 2
01
4 
Analysing Utterances in Polish Parliament to Predict
Speaker’s Background*
Piotr Przybyła and Paweł Teisseyre
Institute of Computer Science, Polish Academy of Sciences, Warsaw, Poland
ABSTRACT
In this study we use transcripts of the Sejm (Polish parliament) to predict speaker’s back-
ground: gender, education, party affiliation and birth year. We create learning cases consist-
ing of 100 utterances by the same author and, using rich multi-level annotations of the
source corpus, extract a variety of features from them. They are either text-based (e.g. mean
sentence length, percentage of long words or frequency of named entities of certain types) or
word-based (unigrams and bigrams of surface forms, lemmas and interpretations). Next, we
apply general-purpose feature selection, regression and classification algorithms and obtain
results well over the baseline (97% of accuracy for gender, 95% for education, 76–88% for
party). Comparative study shows that random forest and k nearest neighbour’s classifier usu-
ally outperform other methods commonly used in text mining, such as support vector
machines and naïve Bayes classifier. Performed evaluation experiments help to understand
how these solutions deal with such sparse and highly-dimensional data and which of the
considered traits influence the language the most. We also address difficulties caused by
some of the properties of Polish, typical also for other Slavonic languages.
One of the most astounding features of natural languages is their redun-
dancy – almost every information can be expressed in a huge variety of
ways. Every utterance is a result of a choice, conscious or unconscious,
made by a speaker to accomplish his current goal. Of course, these choices
are highly influenced by the speaker’s background: gender, age, ethnicity,
education, etc.
This dependence makes it possible to predict (i.e. guess) automatically
these features of a speaker based on some amount of his utterances. In the
next section several existing solutions of such problems are presented.
*Address correspondence to: Paweł Teisseyre, Institute of Computer Science, Polish
Academy of Sciences, Room 225, ul. Jana Kazimierza 5, 01–248 Warszawa. E-mail:
teisseyrep@ipipan.waw.pl
© 2014 Taylor & Francis
Journal of Quantitative Linguistics, 2014
http://dx.doi.org/10.1080/09296174.2014.944330
D
ow
nl
oa
de
d 
by
 [
U
ni
ve
rs
ity
 o
f 
A
eg
ea
n]
 a
t 0
6:
25
 1
9 
A
ug
us
t 2
01
4 
However, most of them are based on a very specific type of text, obtained
from blogs or social networks, and are therefore rich in personal and emo-
tional statements. We have decided to take up another challenge – to deduce
the speaker’s background from such formal and constrained messages as
parliamentary speeches. For example, consider words important for gender
prediction in Schler et al. (2006): “mom”, “cried”, “freaked” or “gosh” –
their appearance in parliament is highly unlikely. Moreover, the authors of
our texts are publicly known, which leads us to expand the traditional set
of predicted traits (gender, age) with new ones (education and political affil-
iation). We also want to find the best way to deal with such problems, so
we implement features of different types, both word- and text-based, several
classifiers and various numbers of used tokens.
We work with texts in Polish, which, as a Slavonic language, differs a
lot from English, which attracts most of the attention; in this task the
important distinction lies in much richer conjugation. Although any of the
personal traits mentioned above may influence morphology of utterances,
gender is the only one which directly enforces appearance of particular
forms by language rules. That is because a Polish verb in past tense or
conditional mode inflects for gender, which may betray a speaker’s sex in
case he speaks in the first person. For example, the words “I came”
would be translated to Polish as przyszedłem in case of male speaker and
przyszłam otherwise. It is a strong dependence; but are the expressions in
the first person common enough in formal speeches to make it a valuable
feature for classification? To sum up, the goal of this study is to check
the following:
 Is influence of personal traits (gender, birth year, education, party affil-
iation) of an author of formal text strong enough to successfully per-
form classification?
 What are the most useful features in such a task?
 How does number of features used determine classification accuracy?
 Which of the popular classifiers perform best in so highly-dimensional
space?
 Does the rich conjugation in Polish substantially facilitate the task of
gender prediction?
This paper is organized as follows: we devote the next section to an
overview of existing approaches to similar problems. The Method section
outlines our solution to the problem: gathering the data, extracting features
2 P. PRZYBYŁA AND P. TEISSEYRE
D
ow
nl
oa
de
d 
by
 [
U
ni
ve
rs
ity
 o
f 
A
eg
ea
n]
 a
t 0
6:
25
 1
9 
A
ug
us
t 2
01
4 
and classification. We also describe the evaluation process. The Results
section contains quantitative and qualitative outcome of evaluation of our
solution. The discussion of results concludes the paper.
RELATED WORK
The problem of automatically determining age and gender as well as ana-
lysing how these traits influence language use has attracted a lot of atten-
tion; experiments have been carried out on a variety of corpora. Argamon
et al. (2007) investigated if and how age and gender affect the writing style
of blog authors. The main result is that a number of stylistic and content-
based indicators are significantly affected by both traits. Authors extracted
factors that depict distinct themes, like family, home, politics, etc. It turns
out that usage of words related to family, politics, religion, business and
internet increases with age, while usage of words associated with home,
romance, music, school and fun decreases significantly. It is interesting that
the linguistic factors, usage of which increases with age, are just those
employed more by males of any age, and conversely, those that decrease in
use with age are those frequently applied by females of any age. Classifica-
tion of gender of blog authors was also considered by Mukhherjee and Liu
(2010), who proposed a novel feature selection method that is based on the
ensemble of several feature selection criteria. The proposed algorithm com-
bined with SVMs achieves a classification accuracy of 88.56% (with base-
line at 51.2%) on blog data-set (3100 blog posts collected from numerous
blog hosting sites).
Argamon et al. (2003) studied differences between fiction and non-fiction
documents from the British National Corpus with respect to author gender.
In Koppel (2002) the problem of determining gender of a formal docu-
ment’s author, based on function words and part-of-speech n-grams, was
investigated. Experiments performed on 920 documents from the British
National Corpus show that the highest accuracy (around 80%) could be
achieved by a linear classifier with both groups of features included.
Nguyen, Smith and Rosé (2011) employed a linear regression model to pre-
dict age using different data sets: blogs, telephone conversations and online
forum posts concerning breast cancer. A linear regression model based on
unigrams, n-grams of parts of speech and word classes results in mean
absolute errors between 4.1 and 6.8 years. Some authors have also studied a
problem of age and gender classification of social network users, which is
ANALYSING UTTERANCES IN POLISH PARLIAMENT TO PREDICT SPEAKER’S
BACKGROUND
3
D
ow
nl
oa
de
d 
by
 [
U
ni
ve
rs
ity
 o
f 
A
eg
ea
n]
 a
t 0
6:
25
 1
9 
A
ug
us
t 2
01
4 
important for detection and monitoring of possibly false user profiles.
Peersman et al. (2011) presented an exploratory study based on chat texts,
collected from the Belgian social networking site Netlog. Singh (2001)
introduced lexical richness measures in conversational speeches and showed
that using these measures based on word frequencies makes it possible to
guess gender with 74% accuracy.
Let us also mention the recent PAN 2013 conference (see more at http://
www.uni-weimar.de/medien/webis/research/events/pan-13/pan13-web/index.
html), during which several research groups analysed a corpus consisting of
blogs written both in English and Spanish. The task concerned predicting
author’s demographics (gender and age) from her/his writing. The best per-
formance (for English) was achieved by Meina et al. (2013), who employed
several groups of features: structural (e.g. number of paragraphs, usage of
hyperlinks), parts of speech, n-grams of parts of speech, text difficulty and
readability measures, dictionary-based (e.g. number of abbreviations, emo-
tional, bad, persuasive or connective words), number of language mistakes
and topical similarity (estimated using Latent Semantic Analysis). The
authors tested different classifiers, of which random forest achieved the
highest accuracy. Random forest was also used by Aleman et al. (2013).
Additional tests were carried out on each of the aforementioned groups of
features separately (only for Spanish) and it turned out that n-grams of parts
of speech are most useful for prediction. Some authors have found other
classifiers to work effectively on this data, e.g. SVMs were included in
Santosh, Bansal, Shekhar and Varma (2013), while a single decision tree
was used in Mechti et al. (2013). Note that in all the papers from the PAN
conference age prediction is considered as a multiclass classification
problem with three age groups, not as a regression task as in our approach.
Utterances of politicians have also been studied previously. Savoy (2010)
presented main characteristics of a US political corpus and compared the
most frequently used English words by John McCain and Barack Obama in
2007 and 2008. Dahllöf (2012) considered a problem of prediction of age,
gender and political affiliation based on speeches by Swedish politicians.
They analysed different cohorts of politicians and found that accuracy rates
for gender prediction using SVMs are considerably higher for the older
cohort (81.2%) than for the younger cohort (72.7%) and also considerably
higher for the right-wing cohort (80.1%) than for the left-wing cohort
(72.8%). In addition, accuracy rates for age prediction are considerably
higher for the right-wing cohort (78.9%) than for the left-wing cohort
(73.3%). Diermeier et al. (2011) studied political ideologies based on
4 P. PRZYBYŁA AND P. TEISSEYRE
D
ow
nl
oa
de
d 
by
 [
U
ni
ve
rs
ity
 o
f 
A
eg
ea
n]
 a
t 0
6:
25
 1
9 
A
ug
us
t 2
01
4 
legislative speech records from the 101st to the 108th Congress of the US
Senate. They were predicting political orientation (conservative or liberal)
using a SVM classifier. According to the feature study, cultural references
seem more important than economic references in discriminating conserva-
tive and liberal views.
Related line of research concerns predicting political opinions based
on texts. Conover et al. (2011) described several machine learning meth-
ods for predicting political alignment of Twitter users. O’Connor et al.
(2010) found that political opinions correlate to frequencies of words
expressing sentiment. Their study shows that simple sentiment score
based on short Twitter messages can be used to predict outcomes of
political opinion polls (they used a daily tracking poll for the presidential
job approval rating during 2009). Such a simple text-based model could
be a faster and cheaper alternative to traditional polls (e.g. via tele-
phone). Digrazia et al. (2013) showed that there is a statistically signifi-
cant association between tweets that mention a candidate for the US
House of Representatives and his/her subsequent electoral performance.
Authors used linear regression to model a relationship between the num-
ber of mentions of Republicans in tweets and respective results of con-
gressional elections in different districts. According to the analysis, there
is a significant relationship between these two variables even when some
additional control variables (like median age or median household
income) are introduced into the model.
METHOD
The problem we are facing here is to automatically predict four properties
of a speaker: gender, birth year, party affiliation and education, using the
content of his/her utterances in the Polish parliament. It could be expressed
in terms of well-known machine learning tasks: linear regression (for con-
tinuous variable, i.e. birth year) and classification (in case of categorical
variables, i.e. all the remaining). The task is more challenging than the simi-
lar one presented in Dahllöf (2012), where only binary classification (female
or male, left-wing or right-wing, older or younger) is considered. The fol-
lowing section describes the process of implementing the classification
framework to the problem, i.e. transforming corpus into learning cases,
feature extraction, applying classifiers and evaluation.
ANALYSING UTTERANCES IN POLISH PARLIAMENT TO PREDICT SPEAKER’S
BACKGROUND
5
D
ow
nl
oa
de
d 
by
 [
U
ni
ve
rs
ity
 o
f 
A
eg
ea
n]
 a
t 0
6:
25
 1
9 
A
ug
us
t 2
01
4 
Data
As a corpus, we use the Polish Sejm Corpus, described in detail by
Ogrodniczuk (2012). It contains stenographic transcripts from the Sejm (the
lower house of the Polish parliament) of six terms (years 1991–2011). Each
term is divided into sittings, which, in turn, are divided into utterances, i.e.
small pieces of text with a speaker assigned. Unfortunately, their length var-
ied a lot – it may contain a long paragraph, but also a single sentence (e.g.
when a speech is frequently interrupted). We divide sets of utterances corre-
sponding to one deputy into subsets, containing 100 utterances each and
treat them as learning cases, assigning properties of the speaker to them. In
this way we obtain 8780 learning cases containing from 203 to 16,720
words (on average 7937). For statistics of sizes of sub-corpora belonging to
different classification categories, see Table 1.
The corpus is annotated automatically at the following levels: segmenta-
tion, morphological analysis with disambiguation, syntactic groups and
named entities. First, it has been divided into sentences and segments (i.e.
words) and annotated with morphosyntactic description (a list of possible
lemmas and interpretations for each segment) by a dictionary-based mor-
phological analyser Morfeusz SGJP (Woliński, 2006). Next, the best inter-
pretations of words have been chosen by a transformation-based Brill
tagger for Polish, PANTERA (Acedański, 2010). Then a shallow parser
using a hand-written cascade grammar, Spejd (Buczyński & Przepiórkowski,
2007), has annotated syntactic groups. Finally, a Named Entity Recognition
(NER) tool based on Conditional Random Fields (CRF), NERF (Savary &
Table 1. Size of the corpus.
Task Statistic Number of cases Number of words
Gender, two levels Class = F 1505.00 11,370,023
Class = M 7275.00 58,317,075
Education (4th term), six levels Mean 359.67 2,955,638
Minimum 33.00 220,952
Maximum 1527.00 12,669,262
Standard deviation 582.28 4,840,323
Party, 27 levels Mean 306.11 2,428,170
Minimum 38.00 338,299
Maximum 778.00 5,865,385
Standard deviation 209.30 1,606,047
Notes: The table contains statistics describing sizes of sub-corpora belonging to classification
categories. The statistics are expressed by numbers of words and learning cases (each con-
taining 100 utterances).
6 P. PRZYBYŁA AND P. TEISSEYRE
D
ow
nl
oa
de
d 
by
 [
U
ni
ve
rs
ity
 o
f 
A
eg
ea
n]
 a
t 0
6:
25
 1
9 
A
ug
us
t 2
01
4 
Waszczuk, 2010), has been employed. The results are stored in the NKJP
(Narodowy Korpus Jezyka Polskiego – National Corpus of Polish) format
(Przepiórkowski & Bański, 2011), based on TEI P5 XML.
Traits of the speakers (only deputies are taken into account) are gathered
from the Sejm website using our own Python script. Gender proportion is
highly uneven – only 17% of cases belong to female speakers. Possible edu-
cational stages are the following (in brackets we provide English equivalents
and percentages of cases in the 4th term): podstawowe (primary or voca-
tional school, 1.5%), średnie zawodowe (vocational high school, 14%), śred-
nie ogólne (high school, 1.7%), policealne (vocational college, 2.5%),
wyższe (university level, 71%), naukowe (PhD or professor, 9%). During the
considered 20 years there was a huge variety of parties in Polish parliament.
Moreover, during the terms some of them split, merged, changed names or
composition, so we have decided to stick to the campaign committee, with
which a deputy obtained his mandate. In total, there were 52 campaign com-
mittees in the six terms; section “Classification” describes how we use this
information to construct classification tasks. The birth year is represented
continuously, i.e. it takes into account values of month and day. The deputies
were born between 1920 and 1985 (mean = 1953, st. dev. = 9.4). Using
speakers’ ages may seem a more standard option, but our data covers a per-
iod of 20 years, so 100 utterances, constituting a learning case, correspond to
the same speaker, but with different age. We could build learning cases only
of utterances from the same year, but that would limit the amount of data
available (many of the deputies did not produce 100 utterances in any single
year). Therefore, we have decided to predict the birth year.
In total there were 2909 deputies during the six terms of Sejm (counting
multiple elections of the same person separately because of their changing
party affiliation), but only 2133 of them had at least 100 utterances to build
a training case.
Feature Extraction
Each learning case is described by a set of features, belonging to one of
two types: word-based and text-based. We represent word-based features as
frequencies (i.e. number of occurrences divided by text length) of certain
tokens, derived from actual text words. We use six basic token types: sur-
face form, lemma (prefixed by $), morphological interpretation (i.e. set of
morphological tags, prefixed by :) and bigrams of the above (prefixed by #,
#$ or #: respectively). The employed tagset has been designed for the
National Corpus of Polish and its detailed description can be found in
ANALYSING UTTERANCES IN POLISH PARLIAMENT TO PREDICT SPEAKER’S
BACKGROUND
7
D
ow
nl
oa
de
d 
by
 [
U
ni
ve
rs
ity
 o
f 
A
eg
ea
n]
 a
t 0
6:
25
 1
9 
A
ug
us
t 2
01
4 
Przepiórkowski et al. (2012) and Przepiórkowski and Woliński (2003).
Because of the multitude of interpretations in Polish, features derived from
their bigrams are extremely sparse, so we also include one additional fea-
ture type: bigrams of parts of speech (denoted by #;). For example, if an
expression czarne koty (“black cats”) appears in text, it would affect the fol-
lowing features: czarne, koty (surface forms), $czarny, $kot (lemmas), :adj:
pl:nom:m2:pos (morphological interpretation: part of speech = adjective,
number = plural, case = nominative, gender = masculine animate, degree =
positive), :subst:pl:nom:m2 (part of speech = noun, number = plural, case =
nominative, gender = masculine animate), #czarne_koty, #$czarny_kot, #:
adj:pl:nom:m2:pos_subst:pl:nom:m2 and #;adj_subst (bigrams). In total,
there are 14,259,202 word-based features in the learning cases, but we limit
our analysis to those 37,916, which occur in at least 10 learning cases.
Text-based features (prefixed by @), computed using the whole text of a
learning case, are the following: average word length (in letters), average
sentence length (in words), percentage of words longer than six letters
(@longWords), percentage of words longer than eight letters (@longlong-
Words), percentage of words longer than 10 letters (@longlonglongWords),
average number of syntactic groups per sentence, average group length and
average number of named entities of four types (numbers, persons, places,
dates) per sentence. Numbers are not available in the named entity layer
included in the corpus, so we annotate them using our own code. Both the
word- and text-based features presented here are commonly used both in
tasks of text classification and authorship attribution; a thorough overview
of them is to be found in Stamatatos (2009).
Classification
Statistical classification can be a very effective tool to measure and analyse
how the considered traits (gender, political affiliation, education and birth
year) influence language use. We consider three types of prediction prob-
lems, depending on type of modelled variable, i.e. binary classification in
case of gender, multi-class problem in case of party and education and
regression in case of birth year. We use the following models for classifica-
tion: decision tree (CART – classification and regression trees), random for-
est (RF), support vector machine (SVM), naïve Bayes classifier (NB), k
nearest neighbours classifier (KNN) and regularised logistic regression (only
for the binary classification). For regression task we use: regression tree,
random forest, regularised linear regression, partial least squares regression
(PLSR), principal component regression (PCR) and k nearest neighbours
8 P. PRZYBYŁA AND P. TEISSEYRE
D
ow
nl
oa
de
d 
by
 [
U
ni
ve
rs
ity
 o
f 
A
eg
ea
n]
 a
t 0
6:
25
 1
9 
A
ug
us
t 2
01
4 
regression (KNN). We use the implementations of all the above methods
from R statistical software (R Core Team, 2013). A detailed description of
the above methods as well as their theoretical justification can be found in
Hastie et al. (2009). For a comprehensive review of machine learning tech-
niques in text categorization we refer to Sebastiani (2002). The two most
commonly used models in text classification are SVM and NB. However,
our experiments show that these two methods can be significantly outper-
formed by other competitors, especially random forests and nearest neigh-
bour classifier. Observe that usually in the case of text data the number of
features highly exceeds the number of observations, which makes statistical
modelling much more challenging. There is a need to use methods tailored
to the high-dimensional task. For example, instead of using classical logistic
or linear regression, one has to add regularization term which prevents
over-fitting. Let us briefly present some basic information about the imple-
mentations of the considered methods. For decision trees we use R package
rpart (Therneau et al., 2012); for regularised regressions R package glmnet
(Friedman et al., 2010); for support vector machines R package e1071
(Meyer et al., 2012); for random forest R package randomForest (Liaw &
Wiener, 2002); for naïve Bayes classifier R package e1071; for PLSR and
PCR R package pls (Mevik et al., 2011); nearest neighbour method for
regression is implemented in R package FNN (Beygelzimer et al., 2013). A
summary of employed methods, including information regarding parameter
tuning for each of them is presented in Table 2.
As noted above, because of the abundance of available predictors, the
feature selection stage is crucial and consists of two steps:
(1) Initially discard word-based features corresponding to tokens which
occur in less than ten learning cases (as mentioned in section
“Feature extraction”).
(2) Select features having the largest value of information gain (for clas-
sification) or correlation (for regression) ratio between the target and
the considered variable. Predictive models are built using 500, 5000
and 10,000 features having the largest value of the appropriate ratio.
Text-based features are always included in the model.
When it is possible we also fit models using all the features remaining
after the first stage of the above procedure. Note that the second step of the
procedure is model-free, i.e. it does not depend on a particular machine
learning algorithm.
ANALYSING UTTERANCES IN POLISH PARLIAMENT TO PREDICT SPEAKER’S
BACKGROUND
9
D
ow
nl
oa
de
d 
by
 [
U
ni
ve
rs
ity
 o
f 
A
eg
ea
n]
 a
t 0
6:
25
 1
9 
A
ug
us
t 2
01
4 
The information gain ratio is one of the most popular and commonly
used measures in text mining; a comparison with other quantities can be
found in Forman (2003). However, we stress that information gain ratio, as
Table 2. Characterization of machine learning methods.
Method
Prediction
type R package Parameters
Values of parameter/tuning
method
Decision tree
(CART)
c rpart Mode Early stopping
Random
forest (RF)
c randomForest Number of
trees
500
Subspace
size
Root of number of features
Support
vector
machines
(SVM)
c e1071 Kernel
function
Linear
Cost
parameter
Optimized via 5-fold cross-
validation
Naïve Bayes
(NB)
c e1071 Smoothing
parameter
1
Regularised
logistic
regression
(lasso)
c glmnet Penalty
parameter
Optimized via 5-fold cross-
validation
k nearest
neighbours
(KNN)
c, r class Number of
neighbours
1
Preprocessing Scaling and standardisation
Regression
tree
r rpart Mode Early stopping
Random
forest
r randomForest Number of
trees
500
Subspace
size
Number of features divided by
3
Regularised
linear
regression
(lasso)
r glmnet Penalty
parameter
Optimized via 5-fold cross-
validation
Partial least
squares
regression
(PLSR)
r pls Number of
principal
components
Lower value of the two:
number of features and number
of observations reduced by one
Principal
component
regression
(PCR)
r pls Number of
principal
components
Lower value of the two:
number of features and number
of observations reduced by one
Notes: The table contains information about machine learning methods used for classification
(c) and regression (r) tasks.
10 P. PRZYBYŁA AND P. TEISSEYRE
D
ow
nl
oa
de
d 
by
 [
U
ni
ve
rs
ity
 o
f 
A
eg
ea
n]
 a
t 0
6:
25
 1
9 
A
ug
us
t 2
01
4 
well as correlation coefficient, measures individual discriminative power of
a given variable; they are appropriate for preliminary filtering out spurious
features. Also observe that selecting features based on information gain
does not require to keep all data in memory, which is an important advan-
tage in case of large datasets. Note that predictive power of the selected fea-
tures is also assessed after the classification, see section “Evaluation”.
Finally, let us outline which parts of the corpus are used for respective
tasks. During the analysed period the Polish political scene was very
dynamic, therefore in case of political parties we analyse each term sepa-
rately and skip the first term in which there were 34 different parties. We
also discard classes with less than five observations (learning cases), i.e.
very small parties, which representatives had less than five sets of 100 utter-
ances. Finally we obtain between four and six parties per term. In the case
of education we explore only the fourth term which has the greatest diver-
sity of this factor; in the remaining ones more than 80% of politicians had
a university degree. Due to the large range of birth years in the considered
period, we build models for each term separately and calculate the average
accuracy. Only for gender prediction do we use the whole corpus at once.
Evaluation
The evaluation is based on running the considered classifiers and examining
their output in response to previously unseen learning cases. One needs to
remember that, unlike in Dahllöf, 2012), we treat learning cases (built of
100 utterances by the same deputy) separately, neglecting relation between
cases with common speaker.
The prediction methods described above are tested using five-fold cross-
validation. As a basic measure of performance we use the estimated proba-
bility of correct classification, called the classification accuracy rate. We
would like to stress that selection of features based on information gain
(described in the previous section) is performed for each cross-validation
fold separately. Otherwise we would obtain a too optimistic estimation of
accuracy. The results are compared with the naïve classifier, which assigns
all observations to the majority class.
We also consider two additional measures which are commonly used in
information retrieval:
precision ¼ truepositives
truepositivesþ falsepositives; recall ¼
truepositives
positives
(1)
ANALYSING UTTERANCES IN POLISH PARLIAMENT TO PREDICT SPEAKER’S
BACKGROUND
11
D
ow
nl
oa
de
d 
by
 [
U
ni
ve
rs
ity
 o
f 
A
eg
ea
n]
 a
t 0
6:
25
 1
9 
A
ug
us
t 2
01
4 
where positive items are test examples from featured class (in the case of
gender prediction it is F class). For gender prediction, large value of preci-
sion indicates that among observations assigned to class F, many were clas-
sified correctly. When recall is close to one, it means that a large fraction of
women are recognized correctly. For multi-class problems (party affiliation
and education) we compute precision and recall for a category, treating each
of its possible values as the featured one. In addition, for education and
party affiliation, we calculate precision and recall averaged over all classes.
Classification measures are averaged over all cross-validation folds.
In case of regression the basic measure of performance is root of mean
squared error:
RMSE ¼
ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi
1
n
X
ðyi  ŷiÞ2
r
; (2)
where yi is a true response on a test set, ŷi is a predicted response and the
summation is taken over all n items in a test set. The final value is obtained
by averaging over all cross-validation splits. RMSE for considered predic-
tion methods is compared with the naïve model which returns mean of birth
year. Since regression is performed for each term separately (see final para-
graph of previous section), we actually calculate a root of mean of squares
of residuals weighted by the number of observations in the terms.
Finally we would like to assess relevance and predictive power of the
features. Since in the majority of cases random forests outperform other
methods we have decided to use variable importance measures based on
random forests (Breiman, 2001). The measure pertains to an average
decrease of node impurity (using Gini index or entropy for classification
and residual sum of squares for regression). The average is taken over all
splitting nodes and over all trees used to construct an ensemble classifier.
The measure shows usefulness of a given feature for prediction when ran-
dom forest is used as a prediction tool. One of the properties of random-
forest-based measure is that in case of two highly correlated variables, both
of them will be recognised as equally relevant. Although in some disci-
plines (e.g. in genetics) it is an advantageous feature, here it is a weakness
as different grammatical forms of the same word co-occur on top of a rank-
ing list (see, e.g., the results in Table 5).
Note that information gain, as a universal and model-free method, is used
to select features, whereas the measure based on random forest is employed
to assess final usefulness of the features.
12 P. PRZYBYŁA AND P. TEISSEYRE
D
ow
nl
oa
de
d 
by
 [
U
ni
ve
rs
ity
 o
f 
A
eg
ea
n]
 a
t 0
6:
25
 1
9 
A
ug
us
t 2
01
4 
RESULTS
In this section we present the main results of our experiments. Let us recall
that features are selected using information gain ratio (for classification) and
correlation coefficient (for regression), as described in the previous section.
In case of parties, education and birth year, for which we consider each
term individually, we are also able to fit models using all possible features.
In case of gender, due to the computational limitations, the maximal number
of predictors is 20,000. In case of random forest and SVM we perform
experiments for less features in all considered tasks (for 20,000 the proce-
dures become computationally too demanding).
Figure 1 shows precision, recall and classification accuracy rates with
respect to number of features used for gender prediction. It turns out that
regularised logistic regression performs surprisingly well in the task.
Decision tree and random forest work slightly worse, which indicates that
non-linear methods are weaker in this case. Since the data is not balanced,
precision and recall are particularly important to assess the performance.
The highest value of recall is obtained for logistic regression, which indi-
cates that with this method we can recognize the largest fraction of women
correctly. On the other hand, random forest yields the highest precision, so,
in other words, it gives many correct classifications among utterances
belonging to the group of women.
In order to investigate how much the rich conjugation in Polish facilitates
the task of gender prediction, we performed an additional experiment, dis-
carding the most relevant features corresponding to gender-dependent con-
structions (top 14 features from Table 5). Classification accuracy with
10,000 features is lower than for original data-set, but still significantly
above the baseline, i.e. 89% for logistic regression, 87% for decision tree
and 86% for random forest and support vector machines.
Figure 2 shows classification accuracy rates with respect to number of
features used for education. In this task KNN reaches the highest accuracy
for large number of variables. It seems interesting that with a smaller group
of variables (500) available its accuracy is lower than of other methods.
Table 3 shows precision and recall for possible values of education. Note
that the highest values are obtained for the largest class, corresponding to
university education.
Figure 3 shows party classification accuracy for different numbers of fea-
tures used. Here random forest outperforms other methods in majority of
cases. The only exception is the third term, in which KNN wins (for large
ANALYSING UTTERANCES IN POLISH PARLIAMENT TO PREDICT SPEAKER’S
BACKGROUND
13
D
ow
nl
oa
de
d 
by
 [
U
ni
ve
rs
ity
 o
f 
A
eg
ea
n]
 a
t 0
6:
25
 1
9 
A
ug
us
t 2
01
4 
numbers of features). The best classification accuracy varies among terms,
e.g. it is 71% for the second term and 88% for the fourth term. Naïve
Bayes classifier works poorly for the all of these tasks. Observe that all
methods give accuracy rates above baseline level. Table 4 shows values of
precision and recall for each party in all considered terms. Precision is usu-
ally large for small parties (e.g. PSL) or niche parties (e.g. Samoobrona); it
seems much more difficult to recognize correctly major political parties
(e.g. SLD in 2nd term or PO and PiS in 5th term).
Finally note that classification performance varies among the considered
tasks. It turns out more difficult to predict political affiliation, for which the
best accuracy is around 88% than gender and education, for which we
number of features
Pr
ec
is
io
n
500
number of features
R
ec
al
l
500 5000 10000 20000
0.
70
0.
75
0.
80
0.
85
0.
90
0.
95
1.
00
number of features
C
la
ss
ifi
ca
tio
n 
Ac
cu
ra
cy
500
0.
0
0.
2
0.
4
0.
6
0.
8
1.
0
5000 10000 20000
5000 10000 20000
CART
KNN
SVM
RF
NB
LOGISTIC MAJOR CLASS
0.
0
0.
2
0.
4
0.
6
0.
8
1.
0
CART
KNN
SVM
RF
NB
LOGISTIC
CART
KNN
SVM
RF
NB
LOGISTIC
Fig. 1. Precision, recall and classification accuracy rate with respect to number of word-
based features included in a model for gender prediction. The horizontal line corresponds to
naïve classifier described in section “Evaluation”.
14 P. PRZYBYŁA AND P. TEISSEYRE
D
ow
nl
oa
de
d 
by
 [
U
ni
ve
rs
ity
 o
f 
A
eg
ea
n]
 a
t 0
6:
25
 1
9 
A
ug
us
t 2
01
4 
achieved accuracy rates above 95%. It is worth noting that usually classifi-
cation accuracy is positively correlated with number of features. This may
indicate that information gain ratio is not the most appropriate measure for
filtering. On the other hand, wrapper methods (i.e. methods using a given
predictive model to score variables), which would probably improve the
results, are extremely computationally intensive and it would not be feasible
to use them to rank so many predictors.
0.
2
0.
4
0.
6
0.
8
1.
0
number of features
C
la
ss
ifi
ca
tio
n 
Ac
cu
ra
cy
500 5000 10000 19244
CART
KNN
SVM
RF
NB MAJOR CLASS
Fig. 2. Classification accuracy rate with respect to the number of word-based features
included in the model for education prediction. The horizontal line corresponds to naïve clas-
sifier described in section “Evalutation”. The best performance achieved for KNN is 0.95.
Table 3. Precision and recall for education prediction.
Education Precision Recall
PhD or professor 82.88% 74.06%
University level 91.95% 92.99%
High school 73.33% 45.37%
Vocational high school 74.82% 78.76%
Vocational college 74.10% 70.40%
Primary 44.82% 56.38%
Mean 73.65% 69.66%
Notes: The table contains values of precision and recall for education for the best performing
method (KNN) for 10,000 features. The last row contains the averaged results.
ANALYSING UTTERANCES IN POLISH PARLIAMENT TO PREDICT SPEAKER’S
BACKGROUND
15
D
ow
nl
oa
de
d 
by
 [
U
ni
ve
rs
ity
 o
f 
A
eg
ea
n]
 a
t 0
6:
25
 1
9 
A
ug
us
t 2
01
4 
0.
0
0.
2
0.
4
0.
6
0.
8
Term 2
number of features
C
la
ss
ifi
ca
tio
n 
Ac
cu
ra
cy
500 5000 10000 all
CART
KNN
SVM
RF
NB MAJOR CLASS
0.
0
0.
2
0.
4
0.
6
0.
8
Term 3
number of features
C
la
ss
ifi
ca
tio
n 
Ac
cu
ra
cy
500 5000 10000 all
CART
KNN
SVM
RF
NB MAJOR CLASS
0.
0
0.
2
0.
4
0.
6
0.
8
Term 4
number of features
C
la
ss
ifi
ca
tio
n 
Ac
cu
ra
cy
500 5000 10000 all
CART
KNN
SVM
RF
NB MAJOR CLASS
0.
0
0.
2
0.
4
0.
6
0.
8
Term 5
number of features
C
la
ss
ifi
ca
tio
n 
Ac
cu
ra
cy
500 5000 10000
CART
KNN
SVM
RF
NB MAJOR CLASS
0.
0
0.
2
0.
4
0.
6
0.
8
Term 6
number of features
C
la
ss
ifi
ca
tio
n 
Ac
cu
ra
cy
500 5000 10000 all
CART
KNN
SVM
RF
NB MAJOR CLASS
Fig. 3. Classification accuracy rates with respect to number of word-based features included
in a model for party prediction for five terms. The horizontal line corresponds to naïve clas-
sifier described in section “Evaluation”.
16 P. PRZYBYŁA AND P. TEISSEYRE
D
ow
nl
oa
de
d 
by
 [
U
ni
ve
rs
ity
 o
f 
A
eg
ea
n]
 a
t 0
6:
25
 1
9 
A
ug
us
t 2
01
4 
Regression task (birth year prediction) seems to be the most challenging.
The models are not fitted very well to the data, e.g. in case of random for-
est (using all features) coefficient of determination (proportion of variance
explained by the model) is 41.27%. Figure 4 shows prediction error
(RMSE), averaged over all six terms, for birth year prediction. Decision tree
gives practically no improvement over the naïve method. Random forest
performs quite stably; for large number of features it is outperformed by the
nearest neighbour regression. Among two methods based on principal com-
ponents, PCR and PLSR, the latter works much better. This may be because
in PCR we only use principal component analysis on design (feature)
matrix, whereas in PLSR the principal components are determined to be
maximally correlated with the response variable.
Table 4. Precision and recall for party prediction.
Party 2nd term 3rd term 4th term 5th term 6th term
BBWR P: 95%
R: 71%
KPN P: 100%
R: 69%
PSL P: 91% P: 88% P: 98% P: 100% P: 100%
R: 58% R: 84% R: 67% R: 83% R: 82%
SLD P: 64% P: 79% P: 81% P: 82% P: 92%
R: 92% R: 86% R: 98% R: 82% R: 64%
UD/UW P: 73% P: 84%
R: 63% R: 81%
UP P: 90%
R: 75%
AWS P: 84%
R: 80%
ROP P: 90%
R: 82%
LPR P: 85% P: 99%
R: 94% R: 76%
PIS P: 99% P: 69% P: 74%
R: 87% R: 93% R: 92%
Samoobrona P: 93% P: 100%
R: 89% R: 76%
PO P: 98% P: 75% P: 82%
R: 74% R: 65% R: 77%
mean P: 86% P: 85% P: 92% P: 87% P: 87%
R: 71% R: 83% R: 85% R: 79% R: 79%
Notes: The table contains values of precision and recall for political parties for the best per-
forming method (random forest for all the terms except the third one, for which KNN was
winner) for 10,000 features. The last row contains the results averaged over parties.
ANALYSING UTTERANCES IN POLISH PARLIAMENT TO PREDICT SPEAKER’S
BACKGROUND
17
D
ow
nl
oa
de
d 
by
 [
U
ni
ve
rs
ity
 o
f 
A
eg
ea
n]
 a
t 0
6:
25
 1
9 
A
ug
us
t 2
01
4 
Below we present the analysis of the most relevant features. Tables 5–8
list the top features ranked by variable importance measure (VI) based on
random forest fitted to the whole data. The measure is described in section
“Evaluation”. For education and birth year we present results for the fourth
term; for party affiliation we present results for the third term. In our opin-
ion the lists for these two periods contain the most interesting features.
As expected, the list for gender prediction (Table 5) includes features
derived from gender-dependent constructions in Polish. For example, the
expression powiedziałem (“I said” – masculine) is divided into two seg-
ments: powiedział- (“said” – masculine) and -em (masculine suffix for first
person singular). Tags generated by interpretations (and their bigrams) of
such expressions of both genders occupy first five places in the list. Also, a
related surface form appears – chciała (“wanted” – feminine), most likely
from common chciałam or chciałabym (“I’d like to” – feminine). Among
the useful tokens are surface forms: dzieci “children”, państwo “state”, and
lemmas: kobieta “woman”, dziecko “child” and rodzina “family”, all more
frequent in women”s speeches. According to our data, females also use
slightly longer words (cf. results for @avgWordLength, @longWord, @long-
longWords and @longlonglongWords).
5
6
7
8
9
number of features
R
M
SE
500 5000 10000 19244
CART
LASSO
SVR
RF
PCR
PLSR
KNN NAIVE RMSE
Fig. 4. Prediction error (RMSE) with respect to the number of word-based features included
in the model for birth year prediction. The horizontal line corresponds to naïve classifier
described in section “Evaluation”.
18 P. PRZYBYŁA AND P. TEISSEYRE
D
ow
nl
oa
de
d 
by
 [
U
ni
ve
rs
ity
 o
f 
A
eg
ea
n]
 a
t 0
6:
25
 1
9 
A
ug
us
t 2
01
4 
Table 5. Important features for gender prediction.
Average feature value
for genders
Feature VI F M
:praet:sg:m1:imperf 131.02 3.20 8.71
:praet:sg:f:imperf 119.95 7.62 3.44
#:praet:sg:f:imperf_qub 103.91 2.10 0.06
:aglt:sg:pri:imperf:nwok 68.47 4.56 2.11
#:praet:sg:m1:imperf_qub 66.35 0.01 2.36
chciała 65.69 1.48 0.00
m 62.98 5.28 2.79
#chciała_by 59.01 1.16 0.00
chciał 37.52 0.00 1.88
#:praet:sg:f:imperf_aglt:sg:pri:imperf:nwok 33.50 0.52 0.00
#:beg_praet:sg:f:imperf 32.10 0.63 0.00
:praet:sg:f:perf 31.77 5.30 3.44
#chciała_by 27.15 0.00 1.46
#:praet:sg:f:perf_aglt:sg:pri:imperf:nwok 24.79 0.35 0.00
$dziecko 20.46 2.38 0.40
#beg_chciała 19.11 0.41 0.00
dzieci 14.15 0.92 0.14
@nePersonsPerSen 13.60 0.06 0.08
#:beg_praet:sg:m1:imperf 13.23 0.00 0.88
$kobieta 12.42 0.62 0.07
państwo 11.16 1.13 0.49
@longWords 10.98 433.74 424.37
@nePlacesPerSen 10.5 0.09 0.10
#;interp_interp 10.45 9.78 8.27
#:praet:sg:m1:imperf_aglt:sg:pri:imperf:wok 10.29 0.00 0.72
#:aglt:sg:pri:imperf:nwok_interp 10.03 0.21 0.01
#:interp_interp 9.80 9.78 8.27
@avgWordLength 9.61 6.02 5.99
@longlongWords 9.46 246.59 242.47
$rodzina 9.15 1.56 0.50
@longlonglongWords 9.01 118.90 115.70
#;brev_interp 8.93 9.58 8.69
@groupsLength 8.87 2.21 2.24
#$,_który 8.87 12.49 12.62
$. 8.58 102.28 98.29
Notes: Most relevant features for gender prediction in the fourth term. Features are ordered
according to variable importance measure (VI) based on mean decrease of Gini index in ran-
dom forest. Detailed description of prefixes is given in “Feature Extraction” section. Values
of all features based on frequencies are multiplied by 1000 for reader’s convenience.
ANALYSING UTTERANCES IN POLISH PARLIAMENT TO PREDICT SPEAKER’S
BACKGROUND
19
D
ow
nl
oa
de
d 
by
 [
U
ni
ve
rs
ity
 o
f 
A
eg
ea
n]
 a
t 0
6:
25
 1
9 
A
ug
us
t 2
01
4 
Table 6 shows the most relevant features for prediction of education with
average values for learning cases belonging to particular education stages
A–F, ordered in the same way as presented in section “Data” (roughly con-
sistent with a number of years necessary to obtain a corresponding degree).
The top 10 features are tokens generated from the name of the party
Samoobrona Rzeczpospolitej Polskiej “Self-defence of the Republic of
Poland”, which included a distinctive number of members with elementary
education and was very seldom mentioned in utterances of other deputies
(e.g., observe the top of the “F” column – according to the data in the train-
ing cases, none of the PhDs used the word samoobrona even once). Then
follow the text-based features (mostly based on word-length), but they do
not rise steadily with the length of the education, as expected (e.g. it seems
that graduates of vocational high school use shorter words than those that
completed only elementary school).
The importance of features used in party prediction clearly differs with
respect to terms – we have decided to show the most diversified table (from
the third term, see Table 7). It turns out that deputies are most likely to
refer to their own party, in particular Polskie Stronnictwo Ludowe (PSL)
“Polish Peasant Party” and Unia Wolności (UW) “Freedom Union”. How-
ever, the strongest impact on classification has the frequency of question
marks; the deputies of the opposition (PSL, SLD) were more likely to ask
questions and refer to government (rząd) or ministers (minister) than those
of the ruling coalition (AWS, UW). The same difference appears in case of
vocative, used to directly approach somebody (here singular male, cf. subst:
sg:voc:m1 in the table).
Table 8 shows the most important features for birth year prediction with
the average speaker”s age1 weighted by values of the respective feature.
The words popular among deputies older than mean (49.75) are: emeryt
“senior”, emerytura “retirement”, sprawa “matter” and zagadnienie “ques-
tion, issue”, whereas the younger ones used frequently: naprawdę “really”,
sprawiedliwość “justice”, and obywatelski “civic” (it seems that these
tokens come from names of parties with slightly younger members, i.e.
Prawo i Sprawiedliwość “Law and Justice” and Platforma Obywatelska
“Civic Platform”).
1For the reader”s convenience, the deputies birth year is replaced by age, calculated in the
middle of the term.
20 P. PRZYBYŁA AND P. TEISSEYRE
D
ow
nl
oa
de
d 
by
 [
U
ni
ve
rs
ity
 o
f 
A
eg
ea
n]
 a
t 0
6:
25
 1
9 
A
ug
us
t 2
01
4 
Table 6. Important features for education prediction.
Average feature value for education
Feature VI A B C D E F
$samoobrona 5.82 3.45 2.89 1.14 1.25 0.25 0.00
#$parlamentarny_samoobrona 4.57 1.95 1.13 0.90 1.05 0.11 0.00
#$samoobrona_rzeczpospolita 4.19 1.79 1.02 0.76 0.31 0.08 0.00
samoobrona 4.14 2.73 1.76 0.90 1.13 0.16 0.00
#:subst:sg:nom:f_subst:sg:gen:f 3.70 3.26 2.08 1.46 1.66 0.84 0.86
#rzeczypospolitej_polskiej 3.68 2.04 1.61 0.89 0.35 0.33 0.37
#samoobrona_rzeczypospolitej 3.25 1.58 0.79 0.65 0.26 0.07 0.00
#$rzeczpospolita_polski 3.09 2.28 1.64 0.91 0.49 0.38 0.42
rzeczypospolitej 2.67 2.73 2.02 1.17 0.80 0.61 0.57
$polski 2.67 8.59 11.14 12.9 6.26 7.11 8.79
@longlonglongWords 2.63 110.14 101.96 115.10 113.09 118.61 118.64
@longlongWords 2.63 236.33 224.24 243.52 235.66 246.23 244.62
@avgWordLength 2.37 5.93 5.84 6.04 5.95 6.02 6.00
polskiej 2.12 2.91 2.67 2.17 0.88 1.10 1.45
#;ger_subst 2.12 17.55 14.61 17.93 16.54 18.07 16.34
$nasz 2.10 3.03 4.23 2.92 3.95 2.70 3.97
$rzeczpospolita 2.06 3.01 2.16 1.29 1.05 0.74 0.64
#;fin_interp 2.06 19.02 20.00 15.79 16.34 15.29 16.10
:ign 2.04 42.79 43.59 46.58 39.22 45.16 43.96
@longWords 1.85 412.24 402.98 429.33 416.61 429.07 426.21
@groupsPerSen 1.83 6.97 7.14 7.36 7.47 7.91 8.20
panie 1.81 15.66 11.06 11.12 9.01 8.60 7.00
#;adj_interp 1.78 43.00 44.63 45.74 44.97 48.84 50.36
:subst:sg:voc:m1 1.76 30.59 21.12 20.23 17.48 16.08 12.90
:adj:pl:nom:m1:pos 1.74 5.12 5.70 4.20 3.56 3.43 4.23
:adj:sg:gen:n:pos 1.74 9.00 8.45 9.17 8.04 9.67 10.24
$pieniądz 1.72 0.39 1.59 0.93 0.61 0.44 0.52
#:subst:sg:voc:m1_interp 1.71 14.77 10.24 9.85 8.64 7.89 6.28
@groupsLength 1.68 2.14 2.18 2.20 2.23 2.24 2.23
:ger:sg:gen:n:imperf:aff 1.66 8.18 5.94 7.49 8.07 8.25 7.73
:subst:pl:nom:m1 1.64 7.80 8.88 9.06 5.43 6.19 6.38
@avgSenLength 1.61 15.67 16.14 16.4 16.97 17.85 18.54
:subst:pl:gen:f 1.61 20.49 22.60 25.30 23.09 25.97 24.99
#;subst_ger 1.58 8.69 6.99 9.23 8.73 9.60 8.72
#;adj_subst 1.56 116.78 118.21 129.53 123.2 120.50 122.73
Notes: Most relevant features for education prediction in the fourth term. Features are
ordered according to variable importance measure (VI) based on mean decrease of Gini
index in random forest. Detailed description of prefixes is given in “Feature Extraction” sec-
tion. Values of all features based on frequencies are multiplied by 1000 for reader’s conve-
nience. Symbols A to F are education status indicators in order of increasing education
length. A denotes primary education, whereas F denotes PhD or professor.
ANALYSING UTTERANCES IN POLISH PARLIAMENT TO PREDICT SPEAKER’S
BACKGROUND
21
D
ow
nl
oa
de
d 
by
 [
U
ni
ve
rs
ity
 o
f 
A
eg
ea
n]
 a
t 0
6:
25
 1
9 
A
ug
us
t 2
01
4 
DISCUSSION
In this study we take up the challenge of analysing speeches in the Polish
parliament to predict speaker’s traits: gender, education, party affiliation and
birth year. The results (see a summary in Table 9) show that in each of the
tasks we are able to succeed, i.e. obtain results better than the baseline. This
means that the influence of speaker’s background on his utterances is strong
enough to be recognisable even in such constrained and formal texts. The
best accuracy (97%) is obtained in case of gender prediction, whereas the
regression task (birth year prediction) turns out to be the hardest one; we
get squared error equal 6.48, while baseline is at 8.55.
Tables of important features show that all the types of features are useful
in some task: both word-based (surface forms, lemmas, interpretations and
their bigrams) and text-based (using numbers of named entities and lengths
of words, sentences or groups). The dependence between number of used
word-based features and accuracy differs between tasks and classifiers.
However, in majority of cases we see no signs of saturation, which could
Table 7. Important features for party prediction.
Average feature value for party affiliation
Feature VI AWS PSL ROP SLD UW
$? 5.07 6.43 8.21 6.36 12.22 2.92
#$polski_stronnictwo 4.96 0.00 2.44 0.00 0.00 0.00
? 4.91 6.43 8.21 6.36 12.22 2.92
$stronnictwo 4.88 0.05 2.48 0.00 0.00 0.03
rząd 4.78 0.92 3.04 0.67 3.17 0.82
$minister 4.73 4.86 6.72 3.75 9.78 3.10
#$stronnictwo_ludowy 4.65 0.00 2.45 0.00 0.00 0.00
#$unia_wolności 4.54 0.05 0.01 0.20 0.08 1.4
$ludowy 4.40 0.06 2.65 0.00 0.02 0.00
wolności 4.29 0.15 0.14 0.21 0.13 1.68
#unii_wolności 4.11 0.02 0.00 0.11 0.03 1.08
minister 3.84 0.88 1.77 0.64 3.05 0.63
stronnictwa 3.79 0.05 1.96 0.00 0.00 0.02
$pan 3.75 14.36 14.38 15.94 22.81 10.52
:subst:sg:voc:m1 3.75 12.96 13.80 11.16 19.74 8.19
Notes: Most relevant features for party prediction in the third term. Features are ordered
according to variable importance measure (VI) based on mean decrease of Gini index in ran-
dom forest. Detailed description of prefixes is given in “Feature Extraction” section. Values
of all features based on frequencies are multiplied by 1000 for reader’s convenience.
22 P. PRZYBYŁA AND P. TEISSEYRE
D
ow
nl
oa
de
d 
by
 [
U
ni
ve
rs
ity
 o
f 
A
eg
ea
n]
 a
t 0
6:
25
 1
9 
A
ug
us
t 2
01
4 
be explained either by insufficient quality of feature selection algorithm or
impossibility to select a satisfactory subset (i.e. most of the features are nec-
essary for classification).
Table 8. Important features for birth year prediction.
Feature VI Weighted average age
$sprawiedliwość 3687.38 45.68
:ign 2551.71 51.23
#$być_być 1535.96 75.86
#;prep_ign 1342.25 51.30
$emeryt 1313.81 63.47
#,_które 1148.63 49.86
$emerytura 1062.29 60.07
#:fin:sg:pri:imperf_interp 939.72 51.10
#;adv_comp 890.08 46.07
sprawą 830.81 60.88
$który 796.65 50.14
:fin:sg:pri:imperf 704.13 50.86
#:adv:pos_qub 698.66 48.58
które 634.39 49.89
#:ign_interp 607.03 51.19
$sejm 585.92 50.64
#;ign_interp 568.03 51.19
emerytów 537.03 66.31
sprawiedliwości 523.88 45.16
$naprawdę 518.18 45.14
:pcon:imperf 515.56 51.09
tej 504.28 50.16
$marszałek 483.01 50.13
#$prawo_i 471.29 45.52
:praet:sg:f:perf 467.94 51.02
@groupsLength 462.22 50.50
? 453.65 50.26
naprawdę 450.30 45.14
$stan 443.61 51.77
#$,_który 443.50 50.06
$ten 442.46 50.27
:inf:imperf 437.12 50.44
$zagadnienie 430.44 60.09
$wniosek 412.81 49.26
$obywatelski 409.62 46.79
Notes: Most relevant features for age prediction in the fourth term. Features are ordered
according to variable importance measure (VI) based on mean decrease of residual sum of
squares in random forest. The average age is 49.75. Detailed description of prefixes is given
in “Feature Extraction” section. Values of all features based on frequencies are multiplied by
1000 for reader’s convenience.
ANALYSING UTTERANCES IN POLISH PARLIAMENT TO PREDICT SPEAKER’S
BACKGROUND
23
D
ow
nl
oa
de
d 
by
 [
U
ni
ve
rs
ity
 o
f 
A
eg
ea
n]
 a
t 0
6:
25
 1
9 
A
ug
us
t 2
01
4 
None of the classifiers obtains the best results in all the tasks, but two of
them usually perform significantly better: random forest and nearest neighbour
(nearest neighbour regression in case of birth year). The worst results usually
come from the naïve Bayes classifier, although it still beats the baseline.
One of the properties of Polish, typical for Slavonic languages, i.e. rich
inflexion strongly influences the results. Firstly, multiple variants of the
same lexeme cause very high dimensionality of feature space (14,259,202),
which in some cases makes it impossible to work on whole data because of
performance reasons. Secondly, the gender-dependent conjugation in past
tense and conditional mode turns out to be very useful in gender prediction
task.
We see two obvious directions of research to further improve the results.
In so highly-dimensional spaces, the feature selection step is crucial. We
use information gain for classification and correlation for regression, but
there are more available. In case of classification Forman (2003) presented
an extensive study of feature selection metrics. Also for regression exist
some interesting solutions, taking into account also nonlinear dependencies,
e.g. distance correlation (Li et al., 2012) or maximal information coefficient
(Reshef et al., 2011). Assessing the performance of these measures,
designed for genetic data, in text classification seems to be one of the possi-
ble approaches.
Table 9. Summary of the results.
Task Best method
Number of
features
Classification accuracy/
RMSE Baseline
Gender Logistic
regression
All 96.72% 82.85%
Education (4
term)
Nearest
neighbours
All 95.40% 70.76%
Party (2 term) Random forest 10,000 75.74% 34.77%
Party (3 term) Nearest
neighbours
All 86.02% 40.66%
Party (4 term) Random forest 10,000 88.31% 32.57%
Party (5 term) Random forest 10,000 80.91% 29.19%
Party (6 term) Random forest All 81.83% 39.41%
Birth year Nearest
neighbours
All 6.48 8.55
Notes: The table contains the name of the best performing method, optimal number of fea-
tures for the given method, classification accuracy (RMSE for regression task) and accuracy
for naïve model, for all considered tasks.
24 P. PRZYBYŁA AND P. TEISSEYRE
D
ow
nl
oa
de
d 
by
 [
U
ni
ve
rs
ity
 o
f 
A
eg
ea
n]
 a
t 0
6:
25
 1
9 
A
ug
us
t 2
01
4 
Secondly, there definitely is a space for improvement in birth year predic-
tion. Relaxation of the task, i.e. changing it into classification is one of the
possibilities; e.g. Dahllöf (2012) took this approach, differentiating only
between young and old politicians. Analogous approach could also be used
to cluster similar parties for different terms. The other way is to investigate
the dependence between birth year and age – which one of these two influ-
ences language more strongly? This difference is important for our data,
which was gathered for over twenty years. The modifications proposed
above may not only improve classification accuracy, but also give better
insight on how a text is influenced by author’s background.
ACKNOWLEDGEMENTS
This study was supported by research fellowship within “Information technologies: research
and their interdisciplinary applications” agreement number POKL.04.01.01-00-051/10-00.
Critical reading of the manuscript by Jan Mielniczuk and Agnieszka Mykowiecka is grate-
fully acknowledged.
REFERENCES
Acedański, S. (2010). A morphosyntactic Brill Tagger for inflectional languages. Proceedings
of the 7th International Conference on Advances in Natural Language Processing
(IceTAL’10), Heidelberg, pp. 3–14.
Aleman, Y., Loya, N., & Vilari, D. (2013). Two methodologies applied to the author profiling
task. PAN Poznań, Polan – Uncovering Plagiarism, Authorship, and Social Software
Misuse A Benchmarking Activity on Uncovering Plagiarism, Authorship and Social
Software Misuse. Retrieved from http://www.uni-weimar.de/medien/webis/research/
events/pan-13/pan13-papers-final/pan13-author-profiling/aleman13-notebook.pdf
Argamon, S., Koppel, M., Fine, J., & Shimoni, A. R. (2003). Gender, genre, and writing
style in formal written texts. Text, 23, 321–346.
Argamon, S., Koppel, M., Pennebaker, J. W., & Schler, J. (2007). Mining the Blogosphere:
Age, gender and the varieties of self-expression. First Monday. Retrieved from http://
ojphi.org/ojs/index.php/fm/article/view/2003/1878
Beygelzimer, A., Kakadet, S., Langford, J., Arya, S., Mount, D., & Li, S. (2013). FNN: Fast
Nearest Neighbor Search Algorithms and Applications. Retrieved from http://cran.r-
project.org/package=FNN
Breiman, L. (2001). Random forests. Machine Learning, 45, 5–32.
Buczyński, A., & Przepiórkowski, A. (2007). Spejd: A shallow processing and morphologi-
cal disambiguation tool. Proceeding of the 3rd Language and Technology Conference,
LTC 2007, Poznań, Poland, pp. 131–141.
Conover, M. D., Goncalves, B., Ratkiewicz, J., Flammini, A., & Menczer, F. (2011). Predict-
ing the Political Alignment of Twitter Users. 2011 IEEE Third Int’l Conference on
Privacy, Security, Risk and Trust and 2011 IEEE Third Int’l Conference on Social
ANALYSING UTTERANCES IN POLISH PARLIAMENT TO PREDICT SPEAKER’S
BACKGROUND
25
D
ow
nl
oa
de
d 
by
 [
U
ni
ve
rs
ity
 o
f 
A
eg
ea
n]
 a
t 0
6:
25
 1
9 
A
ug
us
t 2
01
4 
Computing, pp. 192–199. IEEE. Retrieved from http://ieeexplore.ieee.org/lpdocs/
epic03/wrapper.htm?arnumber=6113114
Dahllof, M. (2012). Automatic prediction of gender, political affiliation, and age in Swedish
politicians from the wording of their speeches. A comparative study of classifiability.
Literary and Linguistic Computing, 27, 139–153.
Diermeier, D., Godbout, J.-F., Yu, B., & Kaufmann, S. (2011). Language and ideology in
congress. British Journal of Political Science, 42, 31–55.
Digrazia, J., McKelvey, K., Bollen, J., & Rojas, F. (2013). More tweets, more votes: Social
media as a quantitative indicator of political behavior. PloS One, 8(11), e79449.
Forman, G. (2003). An extensive empirical study of feature selection metrics for text classifi-
cation. Journal of Machine Learning Research, 3, 1289–1305.
Friedman, J., Hastie, T., & Tibshirani, R. (2010). Regularization Paths for Generalized Linear
Models via Coordinate Descent. Journal of Statistical Software, 33(1), 1–22.
Hastie, T., Tibshirani, R., & Friedman, J. (2009). The Elements of Statistical Learning: Data
Mining, Inference, and Prediction. New York: Springer.
Koppel, M. (2002). Automatically categorizing written texts by author gender. Literary and
Linguistic Computing, 17, 401–412.
Li, R., Zhong, W., & Zhu, L. (2012). Feature screening via distance correlation learning.
Journal of the American Statistical Association, 107, 1129–1139.
Liaw, A., & Wiener, M. (2002). Classification and Regression by randomForest. R News, 3,
18–22.
Mechti, S., Jaoua, M., & Belguith, L. H. (2013). Author profiling using style-based features
PAN – Uncovering Plagiarism, Authorship, and Social Software Misuse A Bench-
marking Activity on Uncovering Plagiarism, Authorship and Social Software Misuse.
Retrieved from http://www.uni-weimar.de/medien/webis/research/events/pan-13/pan13-
papers-final/pan13-author-profiling/santosh13-notebook.pdf, http://www.uni-weimar.de/
medien/webis/research/events/pan-13/pan13-papers-final/pan13-author-profiling/mech
ti13-notebook.pdf
Meina, M., Brodzińska, K., Celmer, B., Czoków, M., Patera, M., Pazecki, J., & Wilk, M.
(2013). Ensemble-based classification for author profiling using various features Note-
book for PAN at CLEF 2013. PAN – Uncovering Plagiarism, Authorship, and Social
Software Misuse A Benchmarking Activity on Uncovering Plagiarism, Authorship and
Social Software Misuse. Retrieved from http://www.uni-weimar.de/medien/webis/
research/events/pan-13/pan13-papers-final/pan13-author-profiling/meina13-notebook.pdf
Mevik, B.-H., Wehrens, R., & Hovde Liland, K. (2011). Pls: Partial least squares and princi-
pal component regression. Retrieved from http://cran.r-project.org/package=pls
Meyer, D., Dimitriadou, E., Hornik, K., Weingessel, A., & Leisch, F. (2012). e1071: Misc
functions of the Department of Statistics (e1071), TU Wien. Retrieved from http://
cran.r-project.org/package=e1071
Mukhherjee, A., & Liu, B. (2010). Improving gender classification of blog authors. Proceed-
ings of the 2010 Conference on Empirical Methods in Natural Language Processing,
Massachusetts, pp. 207–217.
Nguyen, D., Smith, N. A., & Rosé, C. P. (2011). Author age prediction from text using lin-
ear regression. Proceedings of the 5th ACL-HLT Workshop on Language Technology
for Cultural Heritage, Social Sciences, and Humanities, Stroudsburg: Association for
Computational Linguistics, pp. 115–123. Retrieved from http://dl.acm.org/citation.
cfm?id=2107636.2107651
O’Connor, B., Balasubramanyan, R., Routledge, B. R., & Smith, N. A. (2010). From tweets
to polls: Linking text sentiment to public opinion time series. Fourth International
AAAI Conference on Webblogs and Social Media. Washington, DC, USA.
26 P. PRZYBYŁA AND P. TEISSEYRE
D
ow
nl
oa
de
d 
by
 [
U
ni
ve
rs
ity
 o
f 
A
eg
ea
n]
 a
t 0
6:
25
 1
9 
A
ug
us
t 2
01
4 
Ogrodniczuk, M. (2012). The Polish Sejm Corpus. Proceedings of the Eighth International
Conference on Language Resources and Evaluation, LREC 2012, Istanbul, Turkey,
European Language Resources Association (ELRA), pp. 2219–2223.
Peersman, C., Daelemans, W., & Van Vaerenbergh, L. (2011). Predicting age and gender in
online social networks. Proceedings of the 3rd International Workshop on Search and
Mining User-generated Contents, pp. 37–44. New York: ACM Press.
Przepiórkowski, A., Bańko, M., Górski, R. L., & Lewandowska-Tomaszczyk, B. (2012). Na-
rodowy Korpus Języka Polskiego. [National Corpus of Polish] Warszawa: Wydawnic-
two Naukowe PWN. p. 331.
Przepiórkowski, A., & Bański, P. (2011). XML text interchange format in the national cor-
pus of polish. The proceedings of Practical Applications in Language and Computers
PALC-2009, Frankfurt, pp. 55–65.
Przepiórkowski, A., & Woliński, M. (2003). A flexemic tagset for polish. Proceedings of the
Workshop on Morphological Processing of Slavic Languages, EACL 2003, Budapest,
Hungary, pp. 33–40.
R Core Team. (2013). R: A Language and Environment for Statistical Computing. Vienna:
Austria. Retrieved from http://www.r-project.org/
Reshef, D. N., Reshef, Y. a., Finucane, H. K., Grossman, S. R., McVean, G., Turnbaugh, P.
J., ... Sabeti, P. C. (2011). Detecting novel associations in large data sets. Science,
334, 1518–1524. doi:10.1126/science.1205438
Santosh, K., Bansal, R., Shekhar, M., & Varma, V. (2013). Author profiling: Predicting age and
gender from blogs notebook for PAN at CLEF 2013. PAN - Uncovering Plagiarism,
Authorship, and Social Software Misuse A benchmarking Activity on Uncovering Pla-
giarism, Authorship and Social Software Misuse. Retrieved from http://www.uni-wei
mar.de/medien/webis/research/events/pan-13/pan13-papers-final/pan13-author-profiling/
santosh13-notebook.pdf
Savary, A., & Waszczuk, J. (2010). Towards the annotation of named entities in the National
Corpus of Polish. Procedings of the 7th International Conference on Language
Resources and Evaluation, LREC 2010, pp. 3622–3629.
Savoy, J. (2010). Lexical analysis of US political speeches. Journal of Quantitative Linguis-
tics, 17(2), 123–141. doi:10.1080/09296171003643205
Schler, J., Koppel, M., Argamon, S., & Pennebaker, J. (2006). Effects of age and gender on
blogging. Proceedings of AAAI Spring Symposium on Computational Approaches for
Analyzing Weblogs: Papers from the AAAI Spring Symposium, Menlo Park: The
AAAI Press, pp. 199–205. Retrieved from http://www.citeulike.org/user/ChaTo/article/
6557090
Sebastiani, F. (2002). Machine learning in automated text categorization. ACM Computing
Surveys, 34(1), 1–47. Retrieved from http://dl.acm.org/citation.cfm?id=505282.505283
Singh, S. (2001). A pilot study on gender differences in conversational speech on lexical in
richness measures. Literary and Linguistic Computing, 16, 251–264. doi:10.1093/llc/
16.3.251
Stamatatos, E. (2009). A survey of modern authorship attribution methods. Journal of the
American Society for Information Science and Technology, 60, 538–556. doi:10.1002/
asi.21001
Therneau, T., Atkinson, B., & Ripley, B. (2012). Rpart: Recursive partitionin g. R package
version 4. 1-4.
Woliński, M. (2006). Morfeusz – A practical tool for the morphological analysis of polish.
In M. Kłopotek, S. Wierzchoń & K. Trojanowski (Eds), Intelligent Information Pro-
cessing and Web Mining. Ustroń, Poland: Springer, pp. 511–520.
ANALYSING UTTERANCES IN POLISH PARLIAMENT TO PREDICT SPEAKER’S
BACKGROUND
27
D
ow
nl
oa
de
d 
by
 [
U
ni
ve
rs
ity
 o
f 
A
eg
ea
n]
 a
t 0
6:
25
 1
9 
A
ug
us
t 2
01
4 
