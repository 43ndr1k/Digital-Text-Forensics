                  International Journal of Modern Computer Science and Applications (IJMCSA)                                  ISSN: 2321-2632 (Online) 
                  Volume No.-3, Issue No.-3, August, 2015 
 
RES Publication © 2012                                                                                                                            Page | 1  
http://www.ijmcsa.org 
Plagiarism Detection in Document Images using Modified 
Harris and Belief Propagation 
 
Neha Bansal 1st  
Department of Information Technology 
Chandigarh Engineering College, Landran 
Mohali, Punjab, India  
E-mail: bansal.neha03@gmail.com 
 
Manish Mahajan 2nd  
Computer Science Engineering Department 
CGC-College of Engineering, Landran 
 Mohali, Punjab, India  
E-mail: cgccoe.hodcse@gmail.com 
 
 
Shashi Bhushan 3rd  
Department of Information Technology 
Chandigarh Engineering College, Landran 
 Mohali, Punjab, India 
E-mail: shashibhushan6@gmail.com 
 
Abstract: Plagiarism detection is an important domain for detecting the copy paste in documents which enables the original users the power to 
prove the copyright of their document contents in others contents. The proposed scheme utilizes the advantage of the discrete features of text 
orientation using Harris filtering modified to overcome the mixture of text with the image forgery, this techniques also utilizes the extraction 
match of the features on the basis of propagation belief by validating the occurrence of the feature in a localized region of the document, on the 
basis of the detected features the system recognizes and detects the copied document contents in the database made by user and shows the 
matched document in the database, the efficiency and accuracy of matching is calculated with the total processing time required to complete the 
detection. The results are compared with that of the previous technique showing considerable improvement. 
 
Keywords: Plagiarism, feature detection, filtering, SIFT, copy detection 
_______________________________________________________________________________________________
I. INTRODUCTION 
Since the time that we entered the advanced communication 
era, the simplicity of data sharing through the web has 
encouraged online literature search. With this comes the 
potential danger of an ascent in scholastic wrong doing and 
licensed innovation burglary. As concerns over literary theft 
develop, more consideration has been coordinated towards 
programmed written plagiarism detection. This is a 
computational methodology which helps people in judging 
whether bits of writings are counterfeited. On the other 
hand, most existing written falsification recognition 
methodologies are constrained to string-coordinating 
procedures. In the event that the content has experienced 
considerable semantic and syntactic changes, string-
coordinating methodologies don't perform well. Keeping in 
mind the end goal to recognize such changes, phonetic 
systems which have the capacity to perform a more 
profound investigation of the content are required. To date, 
exceptionally restricted examination has been directed on 
the point of using semantic systems in written plagiarism 
detection. 
Copyright infringement, which is the demonstration of going 
of another person's unique words and thoughts as one's own, 
is seen as an ethical offense and regularly likewise a lawful 
offense. Literary theft has an antiquated root, as the word 
itself is gotten from the Latin words \plagiaries", which 
implies abductor, and \plagiare", which intends to take. The 
lexicon meaning of copyright infringement is \The move or 
routine of making another person's work, thought, and so 
on and passing it off as one's own; scholarly burglary." 
(Oxford  English Dictionary1). Since we entered the web 
time, the quick, endless, and simple access of data has 
further heightened the issue of written falsification.  
Written falsification exists in a wide range of situations, and 
is frequently hard to demonstrate or understand. From a 
present day instructive viewpoint, the ascent of the web as a 
data imparting stage has given understudies to more 
approaches to get to electronic materials. Contrary to 
prevalent thinking, understudies are by all account not the 
                  International Journal of Modern Computer Science and Applications (IJMCSA)                                  ISSN: 2321-2632 (Online) 
                  Volume No.-3, Issue No.-3, August, 2015 
 
RES Publication © 2012                                                                                                                            Page | 2  
http://www.ijmcsa.org 
only ones who face investigation. Aside from scholarly 
wrongdoing allegations, unoriginality can likewise bring 
about budgetary and notoriety misfortunes. There have been 
various embarrassments where prominent creators were 
discovered copying in the production business, and others 
where even government clergymen were found stealing their 
PhD proposals. There have likewise been situations where 
scholastics reused substantial parts of content for 
subsidizing proposals. As more data gets to be accessible on 
the web, the sheer sum of data for manual examination gets 
to be overpowering. Subsequently, computational 
techniques have been acquainted with help content reuse, 
initiation and heading recognizable proof. This is the place 
programmed written falsification location began to pick up 
attention, as it might have the capacity to offer a powerful 
and effective arrangement, at a lower financial expense than 
utilizing Human Resources. 
In the old days, plagiarism could just be identified 
physically by depending on the readers' own particular 
information. As cognizance shifts from individual to 
individual, and the limitless measure of materials is difficult 
to accomplish, the procedure of recognizing written 
falsification inside of content can be a troublesome 
assignment. Much of the time, written falsification is 
distinguished by perusing a content that triggers a \Deja vu" 
in the reader, where the reader has remembered it. The 
undeniable hindrance of the manual strategy is that when the 
measure of data expands, a reader is less inclined to have the 
capacity to recognize the similarities. As the human mind 
does not capacity like a PC hard-plate where data is 
effectively open on interest. One of the soonest strategies for 
plagiarism detection   was presented by Bird (1927), which 
researched the use of factual techniques in identifying 
literary theft of various decision answers. Later systems 
grew through the 1960s were centred around recognizing 
copyright infringement in various decision tests. Early 
plagiarism detection systems for composed writings began 
to show up around the 1990s. These instruments utilized 
measurable techniques to ascertain closeness in the middle 
of writings, and most apparatuses concentrated on composed 
content plagiarism   while some engaged just on PC source 
code copyright infringement. 
II. PREVIOUS WORK 
Ankit Gandhi, C.V.  Jawahar (2013) [1] proposed that many 
documents are created by copying the text and image from 
existing documents. A technique is used to detect this 
plagiarism in document images. Their solution was 
recognition free and scalable to large number of documents. 
They have used SIFT for feature detection and extraction. 
They have used linear programming method to achieve an 
average accuracy of 90%. We will use belief propagation to 
enhance detection accuracy. 
 
Stamatatos (2009) [2] proposed a study of creation 
attribution frameworks by outlines existing initiation 
attribution procedures as \inadequate" all alone. They assert 
that profound components, for example, syntactic and 
semantic data are just helpful as a supplement to other 
shallow elements, for example, lexical data and n-grams. 
The contention is that the commotion presented by NLP 
devices amid handling could add to their disappointment, 
which additionally applies to the utilization of NLP 
procedures for unoriginality discovery. Likewise, for 
unoriginality recognition, the computational many-sided 
quality is normally higher due to the quantity of pair-wise 
correlations that should be performed. 
 
 Stein et al. (2009) [3] likewise presented meta examination 
for initiation attribution, which incorporates a three-stage 
approach: a pre-investigation stage to figure out what sort of 
model to apply in consequent stages, an arrangement stage 
where composing styles are sketched out, and a post-
preparing stage where the consequence of the past stage is 
broke down with extra data. The first stage depends on 
components, for example, archive length, kind, issuing 
association, and speaks to said elements by dialect models. 
The second stage regards the record as one-class 
classification issue. The final stage explores extra data, for 
example, reference and uses a VSM to rep-dislike highlights 
for Meta learning. This technique serves to figure out if an 
                  International Journal of Modern Computer Science and Applications (IJMCSA)                                  ISSN: 2321-2632 (Online) 
                  Volume No.-3, Issue No.-3, August, 2015 
 
RES Publication © 2012                                                                                                                            Page | 3  
http://www.ijmcsa.org 
arrangement of writings is a subset of different writings.  
 
Allan et al. [4] showed a structure for unimaginativeness 
distinguishing proof. The advancement of web, with 
plenteous information online compounds the issue even. The 
makers have found four particular ways to deal with 
methodology artistic burglary recognizable proof. They 
decided to take after far reaching looking and took the 
middle ground framework rather than completely or 
heedlessly looking for sentences in an understudy paper on 
the web. They found the possible wellsprings of obtained 
contemplations. Unimaginativeness can be related to adroit 
determination of sentences from papers, which can in like 
manner be found using web crawlers. They directed this 
toward make freeware that for any teacher or indicating 
accomplice can use to perceive duplicating in their classes.  
 
Francisco et al. [5] say that lab work assignments are crucial 
for programming designing learning. Study says that over 
the span of the latest 12 years 400 understudies copy the 
same work around the same time in settling their errand. 
This has made the teachers to give cautious thought on 
finding the duplicating. Henceforth they developed a forging 
acknowledgment mechanical assembly. This device had the 
full gadget set for helping in the organization of the 
exploration focus work assignment. They used four 
closeness criteria to measure the similarities between two 
assignments. Their paper delineated how the instrument and 
the experience of using them all through the latest 12 years 
in four particular programming undertaking.  
 
Hermann et al. [6] say that fake is to robe credit of another 
person's work. According to the inventors, substance 
composed distortion means is basically duplicating the work 
of an author without giving him the certified credit. They 
delineate the first attempt to recognize duplicated segments 
in a substance using genuine vernacular models and 
perplexity. The tests were done on two specific and 
masterful corpora. The two specific works contained the 
first chronicles and linguistic frame and stemmed variations. 
They perceived the unimaginativeness on these reports and 
the results were affirmed.  
 
Jinan et al. [7] focused on the enlightening setting and stood 
up to tantamount troubles. They delineate on the most 
capable strategy to check the unimaginativeness cases. In 
like manner they needed to produce learning gatherings of 
understudies, instructors, association, staff and staff all 
cooperating and building strong associations that give the 
foundation to understudies to perform their destinations with 
more noticeable accomplishment. They similarly propelled 
information sharing. They outfitted reliable joining with 
legacy and diverse applications in some basic, modifiable, 
and reusable way. Learning entryway may give a support 
mechanical assembly to this learning system. In any case, 
building and changing learning passage is not a basic task. 
This paper gives the item to recognize the scholarly burglary 
from java understudy assignments.  
 
Nathaniel et al. [8] describes artistic burglary as a huge issue 
that infringes copyrighted records/materials. They say that 
composed misrepresentation is extended now days as a 
result of the creations in on the web. They proposed a novel 
composed distortion disclosure framework called as 
SimPaD. The inspiration driving this strategy is to develop 
the comparable qualities between two documents by taking a 
gander at sentence by sentence. Trials say that SimPaD 
distinguishes replicated chronicles more correct and beats 
existing copyright encroachment acknowledgment 
approaches. 
 
III. PROPOSED WORK 
Detection of Plagiarism in Document Images using Linear 
Programming provides an average accuracy of 90%; we will 
enhance detection accuracy of plagiarism in our proposed 
work. Detection of Plagiarism in Document Images for both 
text as well as edited images as in previous work, plagiarism 
is detected only for images that have not been tampered i.e. 
images are copied as it is from the document. Problem with 
the interference of noise patterns in document images. 
 
                  International Journal of Modern Computer Science and Applications (IJMCSA)                                  ISSN: 2321-2632 (Online) 
                  Volume No.-3, Issue No.-3, August, 2015 
 
RES Publication © 2012                                                                                                                            Page | 4  
http://www.ijmcsa.org 
 
The work done will concentrate on following:- 
 To detect plagiarism in documents for text copied 
from other documents. 
 To detect plagiarism of edited photo and images 
from various documents. 
 To identify accuracy of plagiarism detection in 
document images.  
 To identify average efficiency, processing time, 
PSNR, MSE, performance on basis of camera 
quality, noise in documents. 
 To compare the proposed work with the previous 
techniques under defined parameters. 
IV. RESULTS AND DISCUSSION 
The following are simulation Results for a number of 
documents which were forged with text and image copying 
in order to test and compare the output of the proposed 
system with that of the previous system. 
4.1 Results for normal level recovery 
 
Figure1.  Query document that is to be tested for   identifying 
plagiarism 
 
Figure2.  Detected documents which are similar to that of the query 
document 
 
 
Figure3.  Output for accuracy of base system 
The above figure shows the accuracy of the base system for 
5 runs in order to detect the copy source of the main query 
document least accuracy is 68% and maximum is 100% for 
all cumulative runs 
 
Figure4.  Output for accuracy of proposed system 
The above figure shows the accuracy of the base system for 
5 runs in order to detect the copy source of the main query 
document least accuracy is 72% and maximum is 100% for 
all cumulative runs. 
Table1.  Accuracy values of base and proposed system 
Method Run1 Run2   Run3   Run4    Run5 
Base  0.68 0.79   0.98      1       1 
Proposed 0.72 0.95   0.89      1       1 
  
 The above table shows that average accuracy of base 
system is 89% whereas that of proposed system is 91.2%. 
Figure5. Output for efficiency of the base system 
                  International Journal of Modern Computer Science and Applications (IJMCSA)                                  ISSN: 2321-2632 (Online) 
                  Volume No.-3, Issue No.-3, August, 2015 
 
RES Publication © 2012                                                                                                                            Page | 5  
http://www.ijmcsa.org 
The above figure shows the efficiency of the base system for 
5 runs in order to detect the copy source of the main query 
document least efficiency is 73% and maximum is 100% for 
all cumulative runs. 
 
Figure6.  Output for efficiency of the proposed system 
The above figure shows the efficiency of the base system for 
5 runs in order to detect the copy source of the main query 
document least efficiency is 82% and maximum is 100% for 
all cumulative runs. 
Table2.  Efficiency values of base and proposed system 
Method Run1  Run2   Run3  Run4  Run5 
Base  0.73  0.90   0.88     1     1 
Proposed 0.85  0.82   0.94     1     1 
 
The above table shows that average efficiency of base 
system is 90.2% whereas that of proposed system is 92.2%. 
 
Figure7.  Output for time efficiency of the base and proposed system 
The above figure shows the time required to process the 
document using base method and proposed method, for base 
the time required was 4.9 sec for 5 runs and proposed 
method requires 3.8 sec to process 5 document sets, the 
proposed system has reduced the time for processing by 1.1 
seconds and hence improves the efficiency of the system. 
 
Figure8.  Line graph of PSNR and MSE values for noisy and de-noised 
image documents 
 
Figure9.  Bar graph of PSNR and MSE values for noisy and de-noised 
documents 
Both the above figures show that higher the PSNR value, 
higher will be the quality of the image document and more 
accurate results will be obtained. Noisy image documents 
have low PSNR value so less accurate results will be 
obtained, whereas de-noised image documents have high 
PSNR values so more accurate results will be obtained. On 
other hand, lower the value of MSE, higher will be the 
quality of image document and more accurate results will be 
obtained. Noisy image documents have high MSE value 
whereas de-noised image documents have low MSE value. 
This means that noisy image documents have low PSNR 
value and high MSE value whereas de-noised image 
documents have high PSNR value and low MSE value. So 
results of noisy image documents will be less accurate as 
compared to de-noised image documents. 
 
Table3.  PSNR and MSE values for noisy and de-noised image 
documents 
Parameter   Run1    Run2   Run3   Run4 
PSNR 
(noisy) 
20.5997  20.3801 20.2001 20.0099 
PSNR 
(de-noised) 
21.0009  20.9886 20.6990 20.3999 
 MSE 
(noisy) 
570.000  602.001 620.002 638.001 
 MSE 
(de-noised) 
509.998 525.090 560.900 595.990 
 
The above table shows PSNR value decreases whereas MSE 
values increases with increase in noise level. This means we 
                  International Journal of Modern Computer Science and Applications (IJMCSA)                                  ISSN: 2321-2632 (Online) 
                  Volume No.-3, Issue No.-3, August, 2015 
 
RES Publication © 2012                                                                                                                            Page | 6  
http://www.ijmcsa.org 
will get less accurate results in case of noisy documents as 
quality of noisy document is low. On other hand, PSNR 
value increases whereas MSE value decreases when 
documents are de-noised. This means that we will get more 
accurate results in case of de-noised documents as quality of 
documents is high. 
V. CONCLUSION 
The proposed approach shows the detection and match of 
the plagiarism detection of the proposed system on the basis 
of modified Harris filter and belief propagation feature 
detection for changed and copied text and image features in 
the database of documents on the basis query for suspected 
forged document, the system accuracy and efficiency in 
terms of feature match and time efficiency is shown in 
above graphical analysis, which proves the improvement of 
the proposed system over the past approach. 
ACKNOWLEDGMENT 
Author thanks to all research experts of the Information 
Technology department of CEC and Computer Science 
Department of CGC,   Landran,   Mohali, Punjab, India. 
REFERENCES 
[1] Ankit Gandhi and C. V. Jawahar, “Detection of Cut-And-
Paste in Document Images,” in proceedings of 12th IEEE 
International Conference on Document Analysis and 
Recognition ,pp. 653-657, 2013. 
[2] Stamatatos, E., “A survey of modern authorship 411 
attribution methods”, pp.1-28, 2009. 
[3] Stein, Benno, Paolo Rosso, EfstathiosStamatatos, Moshe 
Koppel, and Eneko Agirre, editors in Proceedings of the 
SEPLN Workshop on “Uncovering Plagiarism,Authorship, 
and Social Software Misuse”, PAN’09, Donostia-San 
Sebasti´an, Spain. Universidad Polyt´ecnica de 
Valencia,2009. 
[4] Allan K., Kevin A., and Bruce B., “An Automated System 
for Plagiarism Detection Using the Internet,” in 
Proceedings of World Conference on Educational 
Multimedia, Hypermedia and Telecommunications, 
Chesapeake, pp. 3619-3625, 2004.  
[5] Francisco R., Antonio G., Santiago R., Jose L., Pedraza M., 
and Manuel N., “Detection of Plagiarism in Programming 
Assignments,” IEEE Transactions on Education, vol. 51, 
no. 2, pp. 174-183, 2008. 
[6] Nathaniel G., Maria P., and Yiu N., “Nowhere to Hide: 
Finding Plagiarized Documents Based on Sentence 
Similarity,” in Proceedings of IEEE/WIC/ACM 
International Conference on Web Intelligence and 
Intelligent Agent Technology, NSW, pp. 690-696, 2008.  
[7] Jinan F., Alkhanjari Z., Mohammed S., and Alhinai R., 
“Designing a Portlet for Plagiarism Detections within a 
Campus Portal,” Journal of Science, vol. 1, no. 1, pp. 83-
88, 2005. 
[8] Hermann M., Frank K., and Bilal Z., “Plagiarism -A 
Survey,” Universal Computer Science, vol. 12, no. 8, pp. 
1050-1084, 2006. 
[9] M. Fontani, T. Bianchi, A. De Rosa, A. Piva and M. Barni, 
“A framework for decision fusion in image forensics based 
on Dempster-Shafer theory of evidence,” IEEE 
Transactions on Information Forensics and Security, vol. 8, 
no. 4, pp. 593-607, 2013. 
[10] G. Chierchia, G. Poggi, C. Sansone, and L. Verdoliva, “A 
Bayesian-MRF approach for  PRNU-based image forgery 
detection,” IEEE Transactions on Information Forensics 
and Security, vol. 9, no. 4, pp. 554-567, 2014 
[11] G. Chierchia, D. Cozzolino, G. Poggi, C. Sansone, and L. 
Verdoliva, “Guided filtering for PRNU-based localization 
of small-size image forgeries,” IEEE International 
Conference on Acoustics, Speech and Signal Processing, 
pp. 6273-6276, 2014. 
[12] D. Gragnaniello, G. Poggi, C. Sansone, and L. Verdoliva, 
“Fingerprint liveness detection based on Weber local image 
descriptor,” IEEE Workshop on Biometric Measurements 
and Systems for Security and Medical Applications, pp. 46-
50, 2013. 
[13] Y.Q. Shi, C. Chen, and G. Xuan, “Steganalysis versus 
splicing detection,” International Workshop on Digital 
Watermarking, vol. 5041, pp. 158-172, 2008. 
[14] Z. He, W. Lu, W. Sun, and J. Huang, “Digital image 
splicing detection based on Markov features in DCT and 
DWT domain,” Pattern Recognition, vol. 45, pp. 4292–
4299, 2012. 
[15] Sahar Q. Saleh, Muhammad Hussain, Ghulam Muhammad, 
and George Bebis, “Evaluation of image forgery detection 
using multiscale weber local descriptors,” ISVC 2013, Part 
II, LNCS 8034, pp. 416–424, 2013. 
