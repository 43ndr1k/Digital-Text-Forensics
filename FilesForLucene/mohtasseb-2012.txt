Knowl Inf Syst (2012) 31:1–21
DOI 10.1007/s10115-011-0398-0
REGULAR PAPER
Two-layered Blogger identification model integrating
profile and instance-based methods
Haytham Mohtasseb · Amr Ahmed
Received: 25 January 2010 / Revised: 19 November 2010 / Accepted: 30 January 2011 /
Published online: 20 April 2011
© Springer-Verlag London Limited 2011
Abstract This paper introduces a two-layered framework that improves the result of
authorship identification within larger sample numbers of bloggers as compared with earlier
work. Previous studies are mainly divided into two categories: profile-based and instance-
based methods. Each of these approaches has its advantages and limitations. The two-layered
framework presented here integrates the two previous approaches and presents a new solution
to a key problem in authorship identification, namely the drop in accuracy experienced as
the number of authors increases. The paper begins by illustrating the regular instance-based
core model and the investigated features. It then introduces a new psycholinguistic profile
representation of authors, presents similarity grouping extraction over profiles, and applies
blogger identification utilizing the two-layered approach. The results confirm the improve-
ment introduced by the proposed two-layered approach against our regular classifier, as well
as a selected baseline, for an extended number of users.
Keywords Blog mining · Authorship identification · User representation ·
Group extraction · Profile modeling
1 Introduction
The Web 2.0 generation opens new opportunities for communication and facilitates
collaboration all over the world with a large number of individually written electronic texts
being available online. The need to authenticate those documents is becoming increasingly
important, as the users can present numerous identities in the online world and may behave
differently in each context. Identifying the author of anonymous text messages could be use-
ful in various applications. These include intelligence, forensic purposes, or online security
H. Mohtasseb (B) · A. Ahmed
School of Computer Science, University of Lincoln,
Lincoln LN6 7TS, UK
e-mail: hmohtasseb@lincoln.ac.uk
123
2 H. Mohtasseb, A. Ahmed
where it is valuable to extract groups of authors who may discuss similar ideas, such as
terrorism. Authorship identification has been used in this domain to capture the identity of
the author based on the textual materials analyzed.
We study authorship identification in personal blogs as it is one of the prevalent forms
of users’ contribution to web content with large numbers of individually written electronic
texts. There are mainly three arguments for conducting blogger identification. First, it is not
always the case that blogs display opinions, experience, and other materials that are valid,
legitimate, or even useful. Sometimes, bloggers publish illegal contents and may run counter
the law [6]. Second, people who are not socially active find themselves more comfortable
in the online world and may do many things that they would be unlikely to perform face-
to-face. Many create a variety of personas and identities in several online environments.
Third, the anonymity may encourage harmful behavior by some users as it is hard to catch
them [46]. Bloggers may try to hide their identities using various software tools (IP hiding,
proxies) and by obtaining ambiguous email addresses. This raises the need for having other
technologies that are capable of capturing bloggers’ identities from text such as authorship
identification.
Authorship identification is mainly characterized as a text classification research prob-
lem. The area of text classification contains, in addition to authorship identification, numer-
ous research topics and applications such as mood prediction, opinion mining, document
categorization, and demographics attribution. The proposed problem is different from the
other types as in most of them the number of classes considered is reasonably small
compared with the number of classes (authors) in authorship identification. Herein lies
one of the key problems in practically applying authorship identification, namely that of
a dramatic drop in identification accuracy experienced where large number of authors is
considered.
In this paper, we address this problem and introduce a novel solution using a proposed
two-layered approach. We present a new method of authorship identification that utilizes two
classification layers. The function of the top layer is to predict the group to which a given
document, written by an anonymous blogger, belongs. After identifying the potential group,
author identification can be applied locally within that group. Identifying an author within a
group that contains a limited number of authors is more accurate and practically achievable
than conducting the classification over the full set of authors.
The two-layered method integrates two common approaches in authorship identification
namely the instance-based and profile-based methods [42]. As there is no previous informa-
tion about the grouping of authors, we need to extract the hidden groups using unsupervised
learning or clustering. We exploited the profile-based approach by introducing a new user rep-
resentation that creates a psycholinguistic profile for each author based on his/her keywords.
The profiles are then used to find similarity between authors to be grouped. The two-layered
classification model utilizes the induced groups by creating the instance-based top classifi-
cation layer and then for each group, assigns its separate classification model for the member
authors.
The rest of the paper is organized as following. In Sect. 2, we review the recent work
related to our domain. The corpus and text properties are described in Sect. 3. Section 4
displays the implementation and results of our regular instance-based blogger identification
model, which is the core of the two-layered classification model. Our extended two-layered
framework is demonstrated in Sect. 5, with its stages and evaluation. Finally, the paper is
concluded in Sect. 6.
123
Two-layered Blogger identification model integrating profile 3
2 Background
The area of authorship analysis includes three domains: authorship profiling (characteriza-
tion), similarity detection, and authorship identification (attribution). Authorship profiling
aims to discover the demographic attributes of the author. Argamon et al. [2] conducted a
collection of experiments to discover the gender, personality, native language, and age of the
author. Identifying the native language of an author has also been investigated by Koppel
et al. [23] using a collection of idiosyncratic features.
On the other hand, similarity detection evaluates the similarity between different text
documents regardless of the author of text. It is different from authorship identification in
that it employs unsupervised learning as there are no previously defined classes (authors) to
be detected. Abbasi and Chen [1] used the writeprint methodology to discover the similar-
ity between authors. They utilized, in addition to the individual writeprint features for each
author, the usage patterns of other features which are less likely to be used by that author, but
are important when comparing an author to another anonymous identity. Wan [45] proposed
the notion of document structural similarity that evaluates document similarity by comparing
document subtopic structures in order to detect plagiarism. Likewise, Jing et al. [19] pre-
sented a new knowledge-based vector space model associated with ontological distances to
calculate the dissimilarity between two documents.
In this study, the main focus is on one category of authorship analysis: authorship iden-
tification that is targeted to detect the author of a given text. In fact, to address the problem
that exists with larger number of authors, we combined two categories of authorship anal-
ysis: similarity detection and authorship identification. Similarity detection is not the target
of this paper, but it is used to improve the identification task. We generalized the similarity
detection from being detected across two documents belonging to two authors, to detect sim-
ilarity groups across several authors. The extracted groups are then used to build a learning
model fed by the documents that have been labeled with the corresponding groups. The other
category, authorship identification, is applied first in the higher layer to identify the group
to which a given document belongs. It is then applied in the second layer to identify the
potential author of this given anonymous document. In the rest of this section, we review
the key related work in authorship identification. Starting from the comprehensive survey
introduced by Stamatatos [42], authorship attribution methods have been divided mainly into
two categories: profile-based and instance-based approaches.
In profile-based approaches, the texts written by the author are accumulated and collected
into one large file from which can be extracted a stylistic representative profile. An anony-
mous document is then identified by measuring the distances toward the profiles, and then
selecting the most likely author. This method discards the author differences within his/her
documents. Keselj et al. [20] used a dissimilarity distance measure to calculate the differences
across the profiles built that is based on the most frequent n-grams of the text. Frantzeskou et
al. [11] proposed a novel measure called simplified profile intersection that evaluates the sim-
ilarity based on the amount of common n-grams between the two profiles. Furthermore, the
profile-based approach was also manipulated in probabilistic methods. Early work on author-
ship identification, in the Federalist Papers [32], applied probabilistic modeling to identify
the author by taking the maximum conditional probability between the author texts and the
anonymous document. Similarly, Peng et al. [35] augmented the Naive Bayes classifier with
Markov chains to handle the stylistic identity.
In the instance-based approach, each training document is treated individually and con-
tributes separately as an instance in the authorship identification model. A machine learning
algorithm takes the numerical features vectors that represent the individual texts of a specific
123
4 H. Mohtasseb, A. Ahmed
author and builds a corresponding attribution model, which is used to find the potential author
of an anonymous document. Argamon et al. [3] take the advantage of multiplicative learning
with orthographic features to identify authors in a news group corpus. In e-mail corpus, de
Vel et al. [7] analyzed stylistics attributes using Support Vector Machines (SVM) to discover
plagiarism in e-mail texts, while Koppel and Schler [22] depend mainly on misspelling fea-
tures in addition to other lexical and syntactic sets to identify the author in e-mail text. To
the best of our knowledge, SVM is the best of the machine learning algorithms in this area
[8,50]. In addition to SVM, numerous machine learning techniques have been considered,
such as decision trees based on syntactic structures to attribute the author in a books corpus
[44] and in a newswire corpus [49], genetic algorithms, revisiting federalist papers, in [18],
and neural networks by Zheng et al. [50] comparing Chinese and English language results
and in literature by Matthews and Merriam [27].
The two-layered framework introduces the solution of using two stages of classification
to address the limitation experienced by increased number of authors. The profile-based
approach is limited by using a unified set of stylistic features for all of the authors. As we
exploited profiles in the similarity detection task rather than in the identification task, the
limitation of the profile-based approach is avoided by converting the outcome of profiles
grouping in the extended two-layered instance-based model to an adapted set of stylistic fea-
tures that vary according to the group of authors. Finally, our method of profiles extraction is
different from previous studies, as it is based on representative keywords instead of n-grams
(Sect. 5.1).
Using prior knowledge over the training dataset will improve the classification. The two-
layered model exploited clustering to automatically extract some knowledge, thereby improv-
ing classification of authors. Clustering has been used before in literature to improve text
classification. It helps to discover the distribution of data instances in training and testing
sets. This was developed to add/remove features or to build a new classification structure
[24]. Baker and McCallum [4] extracted groups of words based on the distribution of the
target class of each word. The resulting clusters have been adopted for feature selection,
which in turn improved classification performance. Slonim and Tishby [41] also modified
the features and reduced the dimensionality based on word-groups. This has been achieved
by utilizing the Information Bottleneck method [43]. In Raskutti et al. [40], they developed a
new algorithm that utilizes unlabeled data in addition to original labeled data in clustering to
improve the classification results. The result of clustering has been used to extract new fea-
tures for classification. Kyriakopoulou and Kalamboukis [24] applied clustering on training
and testing data to exploit the structure of testing instances. The resulting clusters have been
turned into new features, expanding the feature vector in the new classifier. In our work, we
used the result of clustering over the profiles of authors as a new class labeling in the top
layer. Furthermore, we used Information Gain for each group to select the best representing
features. Each classifier associated with a group has its own features that are different from
other groups based on the forming authors.
While most of the studies utilized the same feature sets for all the authors, few studies tried
to adopt customized features for each author. Li et al. [25] developed a genetic model to select
the best combination of key features for author identification. Koppel et al. [21] introduced a
new measure, feature stability, to select the stylistic stable features among the documents for
a specified author. Furthermore, Abbasi and Chen [1] also developed “Writeprints”, which
separately models the features of each individual author, instead of using one model for all
authors. They build a writeprint for each author using the author’s key features.
One of the common aspects in all of the above work is that they focus on other types of
text than that presented in personal blogs. Blog text is different from other types of text and
123
Two-layered Blogger identification model integrating profile 5
has its own properties. It tends to be informal text and contains lots of slang, words imported
from other languages, and a high percentage of out-of-vocabulary words (see Sect. 3).
Gehrke et al. [12] studied authorship identification in blogs. Using a Bayesian classifier,
they represent each author using a probabilistic model by calculating the prior probabil-
ity between the bi-grams and the author, producing an individual classifier for each author.
Moreover, Mohtasseb and Ahmed [29,30] have investigated the key parameters and linguis-
tic features that are effective in identifying and capturing the style of authors in personal
blogs. They found that the Linguistic Inquiry Words Count (LIWC) [36] is a good candidate
feature set to represent the author in personal blogs, and the identification accuracy is better
when authorship identification has been applied over a group of authors who share some
common characteristics [31]. These two results motivated us to find the similarity groups
among authors using the LIWC categories. Modeling users groups from text has received
little or no attention as far as we know. We adopt unsupervised learning (clustering) to extract
the groups relating similar authors, use supervised learning to build the two classification
layers, and apply authorship identification across the two layers. The proposed framework,
explained in Sect. 5, presents a new solution to the problem exhibited in most of the previous
work featuring larger number of authors.
3 Corpus
This section illustrates the characteristic of the personal blogs (diaries) and corpus used in
the experiments. The style of writing in personal blogs is different from other types of text
such as e-mails, books, or articles. The text in online diaries is less focused and directed than
other media. It contains thoughts, everyday stories and experiments, feelings, and opinions.
The nature of diaries contains the personal details of the blogger’s life and his/her experience.
This type of text is rarely found in other corpora. The text in news columns might look similar
to personal blogs as it comments about an event, opinion, or experiment, but usually in diaries
there is no pre-determined subject or criteria for specific readers as in news text. Personal
blog posts are different from e-mails as they are not written to a dedicated person, but are
available publicly to be accessed by everyone, sharing problems and ideas with friends and
others. The authors are publishing their own diaries, and they are more likely to use words
that express their feeling, mood, opinion, and emotions, at least from their point of view and
according to their writing style.
Mishne [28] in his study of the language of personal blogs compares the personal blogs
(LiveJournal1) with other types of web genres regarding the out-of-vocabulary (OOV) rate.
OOV measures the percentage of new words that appear in testing and do not exist during
training. Figure 1 shows a high OOV percentage in personal blogs, which indicates less
focusing on specific topics. This complexity of text motivates us to search for the features
that best capture the style of user.
We chose LiveJournal a free personal blog Web site forming a community on the Internet
that contains millions of users publishing their own ongoing personal diaries. We downloaded
28,183 blog posts for 100 authors with 300 posts as an average for each author. The total
number of words is 9,427,293.
1 http://www.livejournal.com.
123
6 H. Mohtasseb, A. Ahmed
Fig. 1 Out-of-vocabulary percentages: personal blogs compared with various web genres
4 Core instance-based model
In this section, we introduce our regular instance-based authorship identification model in the
blogosphere. It is the core of the two-layered classification model. There are two main factors
that affect the outcome of the instance-based model, namely the features and machine learn-
ing techniques. We illustrate the utilized linguistic features and machine learning application
within the experiment along with the results.
4.1 Feature set
In text classification tasks, in addition to the classification algorithm, feature representation
plays an important role in the final results. In our study of the nature of text in blogs, we used
the features that best suit the author’s style in personal blogs. We have in total 295 features
that performed very well in our study. This section explains more about the utilized features
according to their category.
4.1.1 LIWC features
We select the Linguistic Inquiry Word Count (LIWC) [36] as it has a psychology basis and is
known to relate well with an author’s style and/or personality [13,37]. As the text of personal
blogs contains lots of feelings, personal activities, and thoughts, the properties of the text are
captured more thoroughly using our selected features sets. The selected 63 LIWC features
are grouped into four types:
1. Standard linguistic features (e.g., total word count, word per sentence, pronouns, punc-
tuations, articles, time)
2. Psychological features (e.g., affect, cognition, biological processes)
3. Personal concerns features (e.g., work, sports, religion, sexuality)
4. Paralinguistic features assents (e.g., agrees, ok), fillers (e.g., err, umm), non fluencies
(e.g., I mean, you know)
The LIWC can handle the different stems of the word, which is one of the common issues
in natural language processing (NLP). Therefore, the stem hungr captures the words hungry,
123
Two-layered Blogger identification model integrating profile 7
Fig. 2 Misspelling errors categorizations
hungrier, hungriest. LIWC had been used successfully in numerous text analysis tasks for
analyzing the emotions of users in blog text [14–16], identifying the gender of bloggers [34],
recognizing the personality [13,26], and for author identification [29,30].
4.1.2 Misspelling errors features
Blogging text contains many vernacular words, shortcuts, and other words imported from
languages other than English. This may reflect the background, home country, and the previ-
ous experience of the blogger. We extract the misspelling error words from each post using
the ASPELL algorithm,2 classify the errors, using a set of regular expressions, into seven
categories as depicted in Fig. 2, and find the correction suggestions of each word. We used
three versions of the ASPELL English dictionaries: the General English, the British, and
the American to catch as many English words as possible. For finding the corrections, we
rely on Levenshtein3 string edit distance algorithm to find the suggested correction for the
misspelled word. The distance between two words is the minimum number of operations
(inserting, deleting, or replacing a character) needed to change one word into the other word.
The features in this part represent the frequencies of error categories as well as the total
number of corrections.
4.1.3 Keywords and syntactic features
Many previous studies in authorship identification have utilized a set of function words and
n-grams as features involved in the classification process. In this study, we extract the impor-
tant keywords used by bloggers (explained in Sect. 5.1.2) and chose the top 200 keywords.
The keywords list has been used as features by calculating the frequency usage within each
post. The keywords features are more representative than features such as the function words,
as they are extracted from the corpus itself rather than from a general predefined list. The
syntactic features count the number of words and sentences, the frequencies of punctuations
and abbreviations.
2 http://aspell.net.
3 http://www.merriampark.com/ld.htm.
123
8 H. Mohtasseb, A. Ahmed
Fig. 3 Identification accuracy comparison across the machine learning algorithms
4.2 Experiment setup
In this section, we explain the experiment setup details of the instance-based model. The
blog posts are converted to numerical vectors in which the entries contain the corresponding
feature values. There are two parameters that have been selected to be evaluated against
classification accuracy: the number of authors and the text length. We divided the corpus
into many datasets according to the combination of those two parameters. For each selected
dataset, the model is evaluated and the results are shown.
The next step after moving to feature space is using machine learning. We chose three
algorithms from the ten most influential machine learning algorithms [48]; Support Vector
Machines (SVM), Naive Bayes (NB), and Example Based Learning (IB1). As we do not
have specific criteria to divide the data into training and testing, the system is evalu-
ated using tenfold crossvalidation. This means that there are 10 cycles of validation, and
the identification accuracy will be calculated among the average of these cycles. In each
cycle, 90% of the dataset of each author is used for training and the remaining 10% is
used for testing. Weka toolbox has been selected to provide the needed machine learning
algorithms.
4.3 Results
Figure 3 shows the summarized results of the three algorithms according to the number
of authors. Detailed results of the experiments are shown in Tables 1, 2, and 3 for the three
machine learning algorithms SVM, NB, and IB1, respectively. Generally, author identification
using SVM outperforms the other algorithms as depicted in Fig. 3. We can see more details
about the accuracy results from the tables. Using SVM, identification accuracy exceeds, as an
average, 85% for capturing the author out of five candidates. On the other hand, the accuracy
resulted by NB is more or less better than the resulted by IB1. However, IB1 improved very
quickly compared with NB in longer posts attaining the same results. Furthermore, we can
notice that the classification accuracy is improved by having more words within the text.
123
Two-layered Blogger identification model integrating profile 9
Table 1 Authorship
identification accuracy (Acc) for
a variety of text lengths and
number of authors (U) using
SVM
Text length Acc (%)
U=5 U=10 U=15 U=20
200 78.46 72.97 66.42 62.18
250 83.91 74.90 68.50 65.90
300 84.64 77.78 71.72 66.04
350 86.25 80.49 71.87 66.84
400 87.71 80.95 72.28 68.92
450 88.89 81.18 72.57 69.59
500 88.93 81.52 73.19 69.95
550 88.94 82.56 75.33 71.68
Table 2 Authorship
identification accuracy (Acc) for
a variety of text lengths and
number of authors (U) using NB
Text length Acc (%)
U=5 U=10 U=15 U=20
200 70.07 63.41 55.80 52.34
250 72.70 63.44 56.26 54.04
300 73.18 64.09 56.69 54.50
350 76.96 66.28 56.96 54.53
400 78.26 66.67 58.89 54.65
450 78.28 68.18 59.07 55.12
500 79.09 69.00 60.87 55.41
550 81.25 69.38 60.89 59.17
Table 3 Authorship
identification accuracy (Acc) for
a variety of text lengths and
number of authors (U) using IB1
Text length Acc (%)
U=5 U=10 U=15 U=20
200 65.08 52.61 42.52 38.75
250 65.17 54.27 43.70 39.73
300 67.82 54.68 43.86 43.20
350 71.54 58.71 45.47 43.89
400 75.12 62.36 47.35 46.84
450 79.33 63.10 49.58 47.77
500 80.00 67.53 56.76 53.81
550 81.05 71.32 60.87 56.65
In most cases, regardless of the utilized classifier, the result decreases as the number of
authors increases. This provides the main motivation to develop the two-layered approach in
authorship identification that achieves higher levels of accuracy overall; this is described in
the following section.
123
10 H. Mohtasseb, A. Ahmed
5 Two-layered framework
In Sect. 4, we explored our core instance-based model. The selected features produced sat-
isfactory identification accuracy, which varies according to the employed machine learning
algorithm. However, a common limitation in this model is mainly with the increased number
of authors. This is a common problem in text classification when the number of classes is
large. To overcome this limitation, we build our two-layered model that introduces a new
solution to this problem.
Figure 4 shows the two-layered model that identifies the author through two stages. First, it
finds the group that the author belongs to. Then, it searches within the group to determine the
individual author. In order to detect the hidden grouping among the authors, we should first
have the appropriate representation of authors, rather than individual documents. Applying
clustering over the documents themselves will end up with clusters that contain the similar
documents irrespective of the authors. Moreover, in such a case, it is highly expected that
each author will also belong to more than one cluster.
In this paper, as depicted in Fig. 5, we present a new profile representation of authors. The
profiles are utilized to extract the similarity and build the clusters. This section explains the
required stages to build the profiles, the methodology of finding the similarity groups, and
finally the development of the core instance-based model to produce the two classification
layers.
5.1 Profile building
In this section, we present the stages of constructing the new representation of authors by
creating the individual psycholinguistic profiles for users based on the extracted keywords.
Fig. 4 Authorship identification across two layers of classification, n: number of groups, m: number of authors,
and n << m.
123
Two-layered Blogger identification model integrating profile 11
Fig. 5 Profile and group extraction framework
Fig. 6 Measures building stages
The Bag-of-Words (BOW), discussed in Sect. 5.1.1, is a common representation of
documents in the literature. Previous Work has utilized the term-frequency (TF) or the
term-frequency inverse-document-frequency (TFIDF) to produce a vector representing each
document.
However, the profiles in our case (in the top layer) are related to the individual authors/
users, not to individual documents. The task is to cluster the author profiles into groups of
related author profiles. To build the author’s profile, out of multiple documents, we adopted
various measures to account for the individual authors, not individual documents.
Figure 6 provides an illustration of the stages we used to convert from the representa-
tion of individual documents to the representation of individual authors, as well as reducing
123
12 H. Mohtasseb, A. Ahmed
dimensionality. First, utilizing the BOW of the document representation, we extract the
author’s keywords and their frequencies as explained in Sect. 5.1.2. However, the frequency
of those keywords is still based on the overall corpus. To emphasize the importance of a
keyword for an individual author, we developed two new measures, as discussed in Sect.
5.1.3. This produces an author representation based on the author’s keywords. But this rep-
resentation still has a high dimensionality, which is not useful in the clustering task.
The second stage, explained in Sect. 5.1.4, is to reduce this dimensionality by mapping
the author’s keywords to a limited number of Psycholinguistic categories from the LIWC.
This produces a limited dimensionality author profile vector that is useful for the cluster-
ing/grouping task. This is explained in Sect. 5.2.
5.1.1 Text to BOW
The first stage in profile extraction is to convert the text posting to a bag-of-words (BOW) rep-
resentation. BOW representation is commonly used in information retrieval and text mining
systems. The document is converted to a list or bag of weighted terms. Generally, the weight-
ing is computed according to term-frequency TF, or term-frequency inverse-document-
frequency TFIDF. Stemming has been used as an effective way to get back the multiple forms
of the word to their base root or stem. In order to reduce the dimensionality of term space,
stop words are removed. Stop words are topic neutral words such as articles or prepositions.
Removing stop words is accomplished by utilizing two lists: the SMART list4 and Onix
list.5 We used the standard Porter stemming algorithm [39] to produce the roots of the words.
Finally, the post is represented by a vector of terms and their corresponding frequencies in
the post.
5.1.2 Keywords extraction
First, utilizing the BOW and TFIDF of the document representation, we extract the unique
keywords and their frequencies within the overall corpus. To account for documents and
authors, we developed the Term Importance (TI) measure as following:
T I (t) = T F(t). DF(t)|D| .
AF(t)
|A| (1)
where TF(t) is the total frequency of term ‘t’ in the corpus, DF(t) is the number of documents
which contain term ‘t’, |D| is the total number of documents (posts), AF(t) is the number of
authors who use term ‘t’, and |A| is the total number of the authors (users). As can be seen
from the equation, TI takes into account the normalized user usage frequency AF(t)|A| and the
normalized document usage frequency DF(t)|D| .
Stop words are removed given that they are neutral and usually in use by almost all
authors. Moreover, as discussed in Sect. 5.1.4, stop words will not contribute to any of the
Psycholinguistic categories—the final dimensionality of the profiles.
The result of this stage (keywords extraction) is a list of important keywords. Experi-
mentally, we use the top 1,500 terms (out of 100,000) for the rest of the processing in our
framework. Hence, although TI does not directly appear in the rest of the measures, it is used
to provide the term importance which is used for ranking the top n keywords (n = 1,500 in
this case).
4 http://jmlr.csail.mit.edu/papers/volume5/lewis04a/a11-smart-stop-list/english.stop.
5 http://www.lextek.com/manuals/onix/stopwords1.html.
123
Two-layered Blogger identification model integrating profile 13
5.1.3 Keywords profile
The aim at this stage is to construct a keyword-based author profile out of the top 1500
keywords extracted in the previous stage 5.1.2. However, the frequency of those keywords is
still based on the overall corpus. To emphasize the importance of a keyword for an individual
author, we developed two new measures: TFIAF and ATI as explained elsewhere.
Firstly, we adopted the same principle of the TFIDF and developed TFIAF term-
frequency inverse-author-frequency measure, as an analogy for TFIDF. TFIAF is focused on
the frequency that is related to an author, rather than to a document. Hence, it highlights the
importance of the term (or keyword) to a specific author. TFIAF is defined as:
T F I AF(t, a) = T F(t, a)log
( |A| + 1
AF(t)
)
(2)
where TF(t,a) is the total frequency of term ‘t’ for author ‘a’. The TFIAF value increases
when the other authors less commonly use this term. This gives more information about the
value of a term for a specific author. Similar modification to TFIDF, but in different contexts,
has been explored in [5,17].
Secondly, to account for the document usage, associated with a term/keyword (no. of doc-
uments using it, within a specific author’s documents/posts), we developed a new measure,
Author Term Importance ATI, as defined in the equation
AT I (t, a) = T F I AF(t, a)DF(t, a)|D A| (3)
where DF(t,a) is the number of documents for author ‘a’ that contain the term ‘t’ and |D A| is
the total number of documents for author ‘a’. Thus, the ATI measure is related to an individ-
ual author, but also taking into account the normalized document usage within this author’s
posts.
5.1.4 Psycholinguistic profile
As discussed in Sect. 5.1.3, the keyword-based profile produces an author representation
based on the author’s keywords. But this representation still has a high dimensionality, which
is not helpful in the clustering task.
To reduce this dimensionality, we map the keywords to a limited number of psycholinguis-
tic categories from the LIWC. This produces a user profile vector, containing the Category
Importance values. This is a limited length vector that can be projected on the categories
space for clustering. A new dictionary has been constructed that contains the selected 54
LIWC categories with their related keywords. The dictionary is used to represent the author
profile as a numerical vector a = (Ic1 , Ic2 , . . . Ici , . . . , Icn ), where n is the number of LIWC
categories and Ici is the importance degree of the category ci for the specified author that is
defined as:
I aci =
k∑
j=1
AT I (t j , a) (4)
The value of Ici is produced by accumulating the ATI values of keywords related to the
category that exists in all documents of the author a (the keywords that are annotated with
the corresponding category) and then normalized to the range between [0-100] as depicted
in Fig. 7. ‘k’ is the number of keywords related to category ci . Table 4 illustrates the ten
123
14 H. Mohtasseb, A. Ahmed
Fig. 7 Resulted clusters centroids based on (Ici ) of the top ten categories, Ici ∈ [0 − 100]
important LIWC categories according to the average of importance of each category across
the authors. The table also shows the top five keywords of each category.
5.2 Groups extraction
As there is no previous information about the relations or links between users, extracting
similarity groups is an unsupervised learning task without previously defined classes. The
K-means clustering algorithm, implemented in the Weka machine learning toolbox [47], has
been chosen to induce the clusters/groups based on the vectors representation of users pro-
files (see Sect. 5.1). There are two parameters that have to be initialized to start the k-means
algorithm namely: the prior number of clusters and the seed value. We test the system with
the number of users ranging from 20 up to 100. In order to get the best clustering result, for
each set of users, k-means run using various combinations of setup parameters.
Figure 7 presents the centroids of the resulting clusters for 100 bloggers. The top ten
dimensions have been selected for the centroid, as it will be difficult to visualize appropri-
ately the full 54 dimensions (LIWC categories). The value of each dimension represents
the importance weighting of the corresponding category Ici in the selected cluster. As the
dimensions of the centroids are based on the expressive psycholinguistic categories of LIWC,
the clusters can be described according to the highest values of their attributes. For exam-
ple, we notice that “cluster 1” has a high value for affective process, while “cluster 9” is
more described by the work and cognitive process categories. These results are useful to
add a high-level knowledge that describes each group of bloggers. This knowledge is an
important issue for those interested in applying social network analysis techniques on very
large networks. It provides a guide to discovering the characteristics and interests of bloggers
communities [33].
Measuring the quality of a clustering algorithm is a common problem in text as well as
data mining. It is easy to compare the exact measures, such as time and space complexity,
123
Two-layered Blogger identification model integrating profile 15
Table 4 Top ten categories with
their top five keywords
Category Keywords
Affective processes Love, friend, hope
(AF.P) Risk, heaven
Relativity Time, day, night
(REL) Move, world
Cognitive processes Feel, wait, write
(CGN.P) Decide, remember
Biological processes Love, life, head
(BLG.P) Drink, sex
Social processes People, talk, girl
(SCL.P) Meet, mom
Positive emotion Happy, fun, friend
(POS.E) Party, kiss
Negative emotion Hate, hurt, stupid
(NEG.E) Devil, victim
Perceptual processes Watch, cool, voice
(PRC.P) Touch, scream
Work School, class, busy
(WRK) Computer, test
Leisure Read, play, family
(LSR) Weekend, music
but the quality of the results needs human judgment, which introduces a high degree of
subjectivity [9]. The quality of clustering is mainly based on the tasks we would like to
optimize by the algorithms. Therefore, comparing such measures for clusters produced by
different algorithms only shows which algorithm results in a better approximation of the
general optimization problem for the particular case.
Given a set of labeled (manually classified) instances, it is possible to use this bench-
mark labeling for an evaluation of clustering. The most common measure is purity. Assume
{L1, L2, . . . , Ln} are the manually labeled classes of data instances, and {C1, C2, . . . , Cm}
are the clusters returned by the clustering process. Then, the purity of a cluster is defined:
Purity(Ci) = max j |L j ∩ Ci ||Ci |
Pfitzner et al. [38] introduced a new method of evaluation that distinguishes between the
goodness and the similarity of clusters by clarifying the degree to which different measures
conflate the two. Other measures include the entropy of classes in clusters, mutual informa-
tion between classes and clusters, and so on. However, all these measures suffer from the
limitation that there are several equally correct ways of classifying an instance. Moreover,
in our case, we do not have any previous labeling about the structure of the group. Probably,
the most useful evaluation is the straightforward measure of the utility of the resulting clus-
tering in its intended application. In our case, there are two main constraints that have to be
considered:
123
16 H. Mohtasseb, A. Ahmed
(1) The individual documents are highly related to the resulting groups (clusters).
(2) The resulting clusters are balanced containing reasonable number of instances
(bloggers).
In order to select the best clustering/grouping form, it has to be evaluated against the
previous two constraints. Doing different clustering experiments, based on different param-
eters, may result in different memberships for the same author. This is due to not having
any previous group labeling over the authors. The first constraint measures how much the
resulted grouping is related to the individual documents of authors. This is directly related
and affects authorship identification results as classification is achieved across two stages.
Therefore, missing the group in the top layer certainly reduces the accuracy. The evaluation of
this constraint is achieved by testing documents classification with the corresponding group
across all of the experiments.
It is important to remember that the accuracy of authorship identification reduces along
with a large number of users. Hence, having balanced clusters prevents the existence of
clusters with large numbers of authors. In other words, the second constraint justifies the
identification result of an individual author within the group by stopping the drop in the
result, when a larger number of authors has to be checked for attribution the author.
We developed a new measure that evaluates the balancing degree of the resulted clusters.
Assume {E1, E2, . . . , En} are the clustering experiments of N users resulting from different
initial numbers of clusters and seed values. The balanced rate of a clustering experiment is
defined by R(E j ) = N|E j | . Let the resulting clusters produced for experiment E j be denoted
by {C1, C2, . . . , Cm}, and |E j | is equal to the number of clusters resulted by E j . Then, the
balanced experiment would be selected as following:
Balanced(E) = min j
∑
i
U (C ji ) − R(E j ) | U (C ji ) > R(E j ) (5)
where U (Ci ) gives the number of instances (users) within cluster ci . The selection of the best
grouping for a set of candidate authors is accomplished by picking a fixed list of the balanced
experiments and then by choosing the one achieving the highest score in classification.
5.3 Integration and evaluation
Extracting the similarity groups (Sect. 5.2) using the profile representation (Sect. 5.1) is
an essential step in building the two classification layers. This section integrates the previ-
ous stages of the two-layered approach, presents the methodology of performing authorship
identification, and evaluates the framework.
The two-layered classification model is constructed based on an enhanced version of our
regular instance-based model and the representation of profiles and groups. The learning
model used in the instance-based model (described in Sect. 4) is developed to contain the
new “groups” top layer. Building the new differs from the bottom layer in that the target class
of the classifier, which was previously the individual author is now the corresponding group.
After creating the group layer, for each group an independent instance-based model is
built, for the bottom layer, by creating the classification model of authors within the specified
group. SVM has been chosen as the machine learning algorithm as it gave the best outcome
compared with other algorithms as shown in Sect. 4.3.
The schema of features used in the associated classifier of a group, in the bottom layer,
has been optimized to pick the best features that distinguish those authors for the determined
group. Information Gain measure [10] has been used to select the best discrimination features
123
Two-layered Blogger identification model integrating profile 17
Fig. 8 Authorship identification for regular versus. two-layered (LiveJorunal Dataset)
Fig. 9 Authorship identification for regular versus two-layered (Blogger Dataset)
that represent the candidate authors within a group. This means that the utilized features, for
identifying an author within a specific group, are adapted according to the group and may
vary from one group to another.
In order to evaluate the two-layered approach, two comparisons are carried out using ten-
fold crossvalidation. The first one compares our regular instance-based model, previously
explained in Sect. 4, with the two-layered model. The second comparison is to confirm the
validity of our method against a regular classifier that is built based on baseline features.
The selected baseline contains a set of 327 features that variously had been utilized in sev-
eral authorship identification studies [1,7,25]. The baseline feature set combines lexical,
structural, syntactic, and content-specific features. The comparison against the baseline is
accomplished for 25, 50, and 100 authors and averaged across the different text lengths.
We carried out the above evaluation on two different datasets; the first dataset is the Live-
Journal corpus explained in details in Sect. 3. The second dataset is another corpus grabbed
from Blogger.com Web site. Figures 8 and 9 show the evaluation results that compare the
two-layered classifier against our regular classifier. The enhancement brought by the two-
layered model is about 12–15% as an average in both datasets. The identification result for 20
authors exceeds 75% for shorter posts and reaches up to 85% for longer ones. Furthermore,
the second evaluation confirms the effectiveness of our method against the baseline as shown
123
18 H. Mohtasseb, A. Ahmed
Table 5 Evaluation of
two-layered versus the baseline
No. of authors Baseline Two-layered
LiveJournal Blogger
25 64.8 81.74 78.00
50 54.4 72.30 68.02
100 39.7 60.51 55.84
in table 5. It can also be seen that the relative improvement of accuracy increases, compared
with the baseline, with the increase in number of authors. This confirms that our two-layered
model is superior, especially with large number of authors. With 100 authors, a reasonable
accuracy of over 60% is achieved by our framework in the first dataset compared with 37.9%
in the baseline. The resultant accuracy confirms the validity of our method in the application
of authorship identification.
6 Conclusion
In this paper, we have presented a two-layered framework that enhances the identification
accuracy within a large number of authors as compared with previous studies. There are at
least four novelties in this paper. First, we showed our instance-based model and the utilized
features, testing different parameters such as text length, machine learning algorithm, and the
number of users. From the result of that experiment, we confirmed the limitation experienced
in identification accuracy which decreases when the number of authors is increased. The sec-
ond novelty is the improvement of the identification accuracy over larger number of authors
based on our two-layered framework. We extended our instance-based model, added a new
layer constructed through finding the groups among the psycholinguistic profiles of authors
and splited the classification to be across two stages. Therefore, the third contribution is the
psycholinguistic user representation. The desired architecture requires finding a suitable rep-
resentation of bloggers, rather than documents, for extracting the hidden groups. The induced
groups, based on the psycholinguistic profiles, fed the classification system to build a group
classification model in the top layer. Each group is assigned the corresponding classifier of
the author within that group. The fourth novelty is inducing the high-level knowledge of the
bloggers. This is based on the extracted groups (clusters) that are descriptive and meaningful
of their users, as the dimensions have psychological backgrounds. The evaluation, on two
different datasets, shows that the two-layered approach outperformed our instance-based
model by up to 14% as an average. Furthermore, the comparison against a chosen baseline
showed that our method gave better identification accuracy. The main disadvantage in our
method is the computation time required to build the whole framework, consumed in profile
modeling, group extraction, and making classification across two stages. However, in most
applications, many of the above tasks are not done in real time. Thus, it can be done offline,
which eliminates the weakness.
Acknowledgments The authors would like to thank Dr. David Cobham for his cooperation and help to
produce this work. This project is fully funded by Damascus University, Syria.
123
Two-layered Blogger identification model integrating profile 19
References
1. Abbasi A, Chen H (2008) Writeprints: A stylometric approach to identity-level identification and simi-
larity detection in cyberspace. ACM Trans Inform syst 26(2):1–29
2. Argamon S, Koppel M, Pennebaker JW, Schler J (2009) Automatically profiling the author of an anony-
mous text. Commun ACM 52(2):119–123
3. Argamon S, Saric M, Stein SS (2003) Style mining of electronic messages for multiple authorship discrim-
ination: First results. In: Proceedings of the ninth ACM SIGKDD international conference on Knowledge
discovery and data mining, ACM, New York, pp 475-480
4. Baker LD, McCallum AK (1998) Distributional clustering of words for text classification. In: Proceed-
ings of the 21st annual international ACM SIGIR conference on research and development in information
retrieval, ACM, pp 96–103
5. Chan S, Pon RK, Cardenas AF (2006) Visualization and clustering of author social networks. In: Distrib-
uted multimedia systems conference, pp 174–180. http://www.cs.ucla.edu/~cardenas/cardenas2.html
6. Dardick GS, Roche CRL, Flanigan MA (2007) Blogs: Anti-forensics and counter anti-forensics. In:
Proceedings of the 5th Australian digital forensics conference, p 199
7. de Vel O, Anderson A, Corney M, Mohay G (2001) Mining e-mail content for author identification
forensics ACM. SIGMOD Rec 30(4):55–64
8. Diederich J, Kindermann J, Leopold E, Paass G (2003) Authorship attribution with support vector
machines. Appl Intell 19(1):109–123
9. Feldman R, Sanger J (2007) The text mining handbook. Cambridge University Press, New York
10. Forman G (2003) An extensive empirical study of feature selection metrics for text classification. J Mach
Learn Res 3:1289–1305
11. Frantzeskou G, Stamatatos E, Gritzalis S, Katsikas S (2006) Effective identification of source code authors
using byte-level information. In: Proceedings of the 28th international conference on Software engineer-
ing, ACM, p 896
12. Gehrke GT, Reader S, Squire KM (2008) Authorship discovery in blogs using Bayesian classification
with corrective scaling
13. Gill A (2003) Personality and language: The projection and perception of personality in computer-med-
iated communication
14. Gill AJ, French RM, Gergle D, Oberlander J (2008) The language of emotion in short blog texts. In:
Proceedings of the ACM 2008 conference on computer supported cooperative work, ACM New York,
pp 299–302
15. Hancock JT, Gee K, Ciaccio K, Lin JMH (2008) I’m sad you’re sad: emotional contagion in cmc, in
‘Proceedings of the ACM 2008 conference on computer supported cooperative work’, ACM New York,
pp. 295–298
16. Hancock JT, Landrigan C, Silver C (2007) Expressing emotion in text-based communication. In: Proceed-
ings of the SIGCHI conference on human factors in computing systems, ACM New York, pp 929–932
17. He Y, Hui SC, Fong ACM (2003) Citation-based retrieval for scholarly publications. IEEE Intell Syst
18(2):58–65
18. Holmes D, Forsyth R (1995) The Federalist revisited: new directions in authorship attribution. Lit Linguist
Comput 10(2):111
19. Jing L, Ng MK, Huang JZ (2009) Knowledge-based vector space model for text clustering. Knowl Info
Syst 25(1):35–55
20. Keselj V, Peng F, Cercone N, Thomas C (2003) N-gram-based author profiles for authorship attribution.
In: Proceedings of the conference pacific association for computational linguistics, PACLING 3, Citeseer,
pp 255–264
21. Koppel M, Akiva N, Dagan I (2006) Feature instability as a criterion for selecting potential style markers.
J Am Soc Info Sci Technol 57(11):1519–1525
22. Koppel M, Schler J (2003) Exploiting stylistic idiosyncrasies for authorship attribution. In: Proceedings
of IJCAI’03 workshop on computational approaches to style analysis and synthesis, pp 69–72
23. Koppel M, Schler J, Zigdon K (2005) Determining an author’s native language by mining a text for errors.
In: Proceedings of the eleventh ACM SIGKDD international conference on Knowledge discovery in data
mining, ACM New York, pp 624–628
24. Kyriakopoulou A, Kalamboukis T (2006) Text classification using clustering. In: The Discovery challenge
workshop, Citeseer, p 28
25. Li J, Zheng R, Chen H (2006) From fingerprint to writeprint. Commun ACM 49:76–82
26. Mairesse F, Walker MA, Mehl MR, Moore RK (2007) Using linguistic cues for the automatic recognition
of personality in conversation and text. J Artif Intell Res 30:457–500
123
20 H. Mohtasseb, A. Ahmed
27. Matthews RAJ, Merriam TVN (1993) Neural computation in stylometry. In: An application to the works
of shakespeare and fletcher. Lit Linguist Comput 8(4):203
28. Mishne GA (2007) Applied text analytics for blogs. Universiteit van, Amsterdam
29. Mohtasseb H, Ahmed A (2009a) Mining online diaries for blogger identification. In: The 2009 Interna-
tional conference of data mining and knowledge engineering (ICDMKE’09)
30. Mohtasseb H, Ahmed A (2009b) More blogging features for author identification. In: The 2009 Interna-
tional conference on knowledge discovery (ICKD’09)
31. Mohtasseb H, Ahmed A (2010) The affects of demographics differentiations on authorship identification.
Springer, Netherlands 60:409–417
32. Mosteller F, Wallace DL (1964) Inference and disputed authorship: the federalist. Addison-Wesley,
Reading
33. Narasimhamurthy A, Greene D, Hurley N, Cunningham P (2009) Partitioning large networks without
breaking communities. Knowl Info Syst 25(2):1–25
34. Nowson S, Oberlander J (2006) The identity of bloggers: openness and gender in personal weblogs. In:
Proceedings of the AAAI spring symposia on computational approaches to analyzing weblogs
35. Peng F, Schuurmans D, Wang S (2004) Augmenting naive bayes classifiers with statistical language
models. Info Retr 7(3):317–345
36. Pennebaker JW, Francis ME, Booth RJ (2001) Linguistic inquiry and word count: Liwc 2001. Lawrence
Erlbaum Associates, Mahway
37. Pennebaker JW, King LA (1999) Linguistic styles:Language use as an individual difference. J Pers Soc
Psychol 77(6):1296–1312
38. Pfitzner D, Leibbrandt R, Powers D (2009) Characterization and evaluation of similarity measures for
pairs of clusterings. Knowl Info Syst 19(3):361–394
39. Porter M.(n.d.) The porter stemming algorithm, Accessible at http://www.tartarus.org/martin/
PorterStemmer
40. Raskutti B, Ferra HL, Kowalczyk A (2002) Using unlabelled data for text classification through addition
of cluster parameters. In: Proceedings of the nineteenth international conference on machine learning,
Morgan Kaufmann, p 521
41. Slonim N, Tishby N (2001) The power of word clusters for text classification. In: Proceedings of ECIR-01,
23rd European colloquium on information retrieval research, citeseer
42. Stamatatos E (2009) A survey of modern authorship attribution methods. J Am Soc Info Sci Technol
60(3):538–556
43. Tishby N, Pereira FC, Bialek W (2000) The information bottleneck method. Arxiv preprint phys-
ics/0004057
44. Uzuner O, Katz B (2005) A comparative study of language models for book and author recognition. Lect
Notes Comput Sci 3651:969
45. Wan X (2008) Beyond topical similarity: a structural similarity measure for retrieving highly similar
documents. Knowl Info Syst 15(1):55–73
46. Willard N, JD D (2005) Educator’s guide to cyberbullying addressing the harm caused by online social
cruelty. Accessible at http://cyberbullying.org 19, 2005
47. Witten IH, Frank E (2005) Data mining: practical machine learning tools and techniques. Morgan Kauf-
mann, San Francisco
48. Wu X, Kumar V, Quinlan JR, Ghosh J, Yang Q, Motoda H, McLachlan GJ, Ng A, Liu B, Yu PS (2008) Top
10 algorithms in data mining. Knowl Info Syst 14(1):1–37
49. Zhao Y, Zobel J (2005) Effective and scalable authorship attribution using function words. Lect Notes
Comput Sci 3689:174–189
50. Zheng R, Li J, Chen H, Huang Z (2006) A framework for authorship identification of online messages:
writing-style features and classification techniques. J Am Soc Info Sci Technol 57(3):378–393
123
Two-layered Blogger identification model integrating profile 21
Author Biographies
Haytham Mohtasseb received his BEng. degree from the Artificial
Intelligence department in Damascus University, Damascus, Syria, in
2004. From 2008 to present, he is a Ph.D. student doing his research
work in analyzing the patterns of users in the blogosphere at the
School of Computer Science, University of Lincoln, Lincoln, UK. He
is a member of IAENG (International Association of Engineers) and
IACSIT (International Association of Computer Science and
Information Technology). His research interests include text mining,
psycholinguistic, social network analysis, and machine learning.
Amr Ahmed (B.Sc.’93, M.Sc.’98, Ph.D.’04, MBCS’05, IEEE-CS’08)
is a Senior Lecturer, the Founder and Leader of the DCAPI (Dig-
ital Contents Analysis, Production, and Interaction) research group
at the School of Computer Science, University of Lincoln, UK. His
research focuses on the semantic analysis of textual and visual con-
tents. Amr’s current research interests include text analysis of blogs for
social and security aspects, and the semantic analysis of images/videos
for multimedia search and retrieval, where knowledge is innovatively
integrated. Amr worked in the industry for several years, including
Sharp Labs of Europe, Oxford. Dr. Ahmed is a Member of the Brit-
ish Computer Society (MBCS) and the IEEE Computer Society. He
received his B.Sc. in Electrical Engineering (1993) and M.Sc. degree
(by research) in Computer and Systems Engineering (1998) from Ain
Shams University, Egypt. He received his Ph.D. in Computer Graphics
and Animation from the University of Surrey, UK, in 2004.
123
