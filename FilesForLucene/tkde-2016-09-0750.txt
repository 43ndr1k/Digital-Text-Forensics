For Peer Review
 O
nly
 
 
 
 
 
External Plagiarism Detection Based on Human Behavior in 
Producing Paraphrases of Sentences in English and Persian 
Languages  
 
 
Journal: Transactions on Knowledge and Data Engineering 
Manuscript ID TKDE-2016-09-0750 
Manuscript Type: Regular 
Keywords: 
Plagiarism, Paraphrasing, External Plagiarism Detection, Information 
Retrieval 
  
 
 
Transactions on Knowledge and Data Engineering
For Peer Review
 O
nly
IEEE TRANSACTIONS ON JOURNAL NAME,  MANUSCRIPT ID 1 
 
External Plagiarism Detection Based on Human Behavior in Producing 
Paraphrases of Sentences in English and Persian Languages 
Abstract— With the advent of the internet and easy access to digital libraries, plagiarism has become a major issue. 
Applying search engines is one of the plagiarism detection techniques in the field of information retrieval that is based 
on submitting queries to a search engine. Generating suitable queries is the heart of this technique and existing 
methods suffer from lack of Precision and speed. This research proposes a framework to alleviate these problems that 
namely ParaMaker. It generates accurate paraphrases of any sentence similar to human behaviors and sends them to a 
search engine as search queries. ParaMaker framework as well as with regard to the retrieved document with highest 
rank as result document is trying to maintain acceptable precision.  In order to evaluate ParaMaker, six of the best 
methods along with standard datasets introduced in PAN2014 competition were examined. For English language, 
results show an improvement of 34% in terms of Recall parameter when Precision and Speed parameters are 
maintained. In Persian language, statements of suspicious documents were examined by a search engine, entirely. The 
obtained results are compared to exact searching. ParaMaker showed an improvement of at least 42% along with 
maintaining Precision and Speed. 
Index Terms: Plagiarism, Paraphrasing, External Plagiarism Detection, Information Retrieval, Search Engine. 
——————————      —————————— 
1 INTRODUCTION
lagiarism is a way in which an individual uses the ideas of 
others and attributes them to himself without referencing to 
their names, as if he himself has created it [1]. In the digital age, 
many existence resources have been added to the web that re-
sults in getting worse plagiarism problem, naturally. For a small 
set of documents, one by one comparison of suspicious docu-
ments with each source document seems reasonable, but this 
approach is not applicable for large set of documents on the 
web. The solution for this problem is using resource retrieval 
techniques. Resource retrieval includes using a search engine 
to retrieve potential sources of plagiarism for a suspicious doc-
ument. The most important part of retrieval techniques is pro-
ducing and submitting queries to obtain search results [2]. The 
whole methods mostly use Precision and Recall parame-
ters for evaluation. Recall mentions that if a document is 
theft, it is surely retrieved, while Precision says that if a 
document is retrieved then it must be theft.  
Producing and sending inefficient queries to search engines 
is a common problem among the methods that use retriev-
ing techniques. It subsequently results in obtaining weak Re-
call parameter. Some methods try to improve the Recall pa-
rameters naturally; however, this improvement leads to a sharp 
reduction of Precision and speed parameters. In this research 
the hypothesis is that producing paraphrases of sentences based 
on human behaviors in generating more accurate queries re-
sults in retrieving more suitable documents by search engines. 
As a result along with maintaining Precision and speed, Recall 
parameter improves in plagiarism detection, eventually. The 
scope of this paper is limited to English and Persian documents. 
The article aims to improve quality of queries to improve exter-
nal plagiarism detection. Obtained results show that the Re-
call parameter is improved %34 compared to the highest val-
ues inPAN2014 competition, while Precision and Speed param-
eters are maintained in an acceptable level. 
The rest of this paper is organized as follows: Section-2 in-
troduces research works done in the field of resource retrieval. 
Section-3 describes the details of the proposed method in detail. 
Section-4 provides information on the experiments conducted. 
The outcomes of the experiment are reported and analyzed in 
Section-5. Section-6 includes conclusion remarks. 
2 LITERATURE REVIEW 
Many techniques have been developed for plagiarism detection 
in natural languages that are classified in Figure 1. The high-
lighted area illustrates the mainstream of this research. 
 
 
Figure 1: Taxonomy of Plagiarism Detection Techniques 
Monolingual plagiarism detection refers to identifying plagia-
rism in a homogeneous language environment. Multilingual 
plagiarism detects the plagiarism between two or more lan-
guages. In external plagiarism, suspicious documents are com-
pared with a collection of documents, while intrinsic plagia-
rism detects plagiarism against checking only one document 
[3]. Plagiarism from other perspective and based on the 
behavior of plagiarizer is classified in two types of plagia-
rism literal and intelligent. In the literal plagiarism, a pla-
giarizer does not spend a lot of time to hide his academic 
xxxx-xxxx/0x/$xx.00 © 200x IEEE        Published by the IEEE Computer Society 
P 
Page 1 of 13 Transactions on Knowledge and Data Engineering
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
For Peer Review
 O
nly
2 IEEE TRANSACTIONS ON JOURNAL NAME,  MANUSCRIPT ID 
 
offense, for instance, simply copy the text from the inter-
net. While in the intelligent plagiarism, a plagiarizer 
hides, obfuscates and changes the original work with in-
telligent methods such as manipulating text, translating 
and getting an idea is trying to deceive readers [3,4]. 
One of the most important types of plagiarism is paraphrasing, 
which means expressing the same ideas or contents with words 
different from source documents [5]. Many methods were de-
veloped to detect paraphrase of texts such as text alignment 
methods that compares a suspicious document with source doc-
uments one by one. Applying these methods is not justified for 
large data sets such as the Internet. Recently, search engines are 
used for comparison of a suspicious document with the source 
documents. Table 1 shows the main differences between 
two groups. 
Table 1: Comparison of Text Alignment and Resource Retrieval Tech-
niques 
 
The research works done on plagiarism detection based on 
resource retrieval are presented as follows. In [6] a ranking 
system is presented in which each word is assigned a weight 
(tf.idf
1
) that is based on frequency of each word in a document. 
In addition, three different strategies are presented that are used 
in making queries including: (1) one query per 50-lines 
chunk containing the top ten words scored by tf.idf val-
ues, (2) first 8-gram with three words from one per chunk, 
(3) fifteen phrases based on head noun clusters[7] and fo-
cuses on the top 10 results of a query and downloads a 
result document when at least 90% of the 4-grams in a 
500-character snippet are contained  in the suspicious 
document.  
Authors in [8] select five-sentence sections and choose ten 
phrases with the highest ranking. In this way, there are four 
methods to extract key words that include: BM251 [9], tf2, 
tf.idf, EW3 [10]. In this method for ranking extracted key-
words, a ranking model based on SVM algorithm is used. Fi-
nally, to build queries for each section of the suspicious docu-
ment, the best group of keywords is selected. Then three results 
with the highest ranking for each query will be retrieved. 
Authors in [11] breaks down a documents into (100 or 200)-
word sections. In this method the following items are used in 
making search queries: 1) top-five terms ranked by the term 
frequency
4
 method in document level, 2) top-five terms ranked 
by the term frequency method in paragraph level, 3) names of 
subgroups in each sentence. Keyword extraction method is 
based on two well-known strategies including term frequen-
cy, and co-occurrence words. 
The role of words is determined based on the maximum entro-
py [12] and all names are extracted as keywords. Each section 
is made up of four queries and ensuring that 60% of the queries 
 
1 Term frequency–inverse document frequency 
1BM25 ranking function is based on a 2-Poisson model of term frequen-
cies in documents  
2 Term frequency 
3 Evaluating words 
4 The number of times a term occurs in a document is Recalled its term 
frequency 
are different from previously sent queries. Method [13] divides 
a text into five-sentence sections. This method uses very sim-
ple strategy to extract key phrases so that only nouns, adjectives 
and verbs are included in key phrases. This method tries to train 
a classifier using snippet results retrieved by several search 
engines.  
Research work [14] divides a suspicious document into 
weighted sentences. Weight is determined according to the 
amount of overlaps with other sentences. One of the problems 
of weighted sentences is that selected sentences are not distrib-
uted on the whole document so that certain parts of the docu-
ment may be left without keywords. Based on the first seven 
pieces returned by search engine and similarity of available 
sentences, similarity of sentences in a suspicious document is 
calculated. Finally, the document with the highest similari-
ty is retrieved. After removing articles, pronouns, prepo-
sitions, high-frequency words from the highest ranked 
sentence, six entities (phrases and words) of the most 
weighted entities in each sentence are extracted and used 
in making queries. 
In [25] three types of text chunking were applied: sentence and 
word chunking for keywords extraction; headers detection; and 
paragraph chunking. Several types of queries were prepared. 
keywords-based queries, paragraph-based queries and headers-
based queries were combined together. All prepared queries 
were processed according to their priority. After each query all 
its results were processed and positions of discovered similari-
ties were stored. For each search engine result a snippet based 
on the given query can be obtained prior to the full document 
download. It contains a portion of the document up to 500 char-
acters around a given textual string. 
Table 2 illustrates a comparison of resource retrieval 
methods that are in the shades are of Figure 1. Segmenta-
tion method, the way of making queries, search control 
and retrieval filters are compared along with mentioning 
advantages and disadvantages of each method.  
3 PROPOSED APPROACH 
Methods using document retrieval techniques have high-
er speed and are more scalable than other methods. Recall 
parameter plays an important role in the evaluation of 
these techniques and resource retrieval methods have 
weak Recall either. ParaMaker framework presented in 
this section, tries to make paraphrases of a sentence based 
on human behaviors in generating new sentences from 
one sentence. After generating paraphrases from one sen-
tence, search queries are made and sent to a search en-
gine. It is expected that this method will increase Recall 
parameter along with maintaining quality of speed and 
Precision. According to Figure 2, ParaMaker framework 
includes five phases: preprocessing, segmentation, que-
ries generation, searching control, and filtering of re-
trieved documents. Innovations of this research fall in the 
queries generation, and search control phases.
Page 2 of 13Transactions on Knowledge and Data Engineering
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
For Peer Review
 O
nly
AUTHOR ET AL.:  TITLE 3 
 
 
Table 2: Comparison of Resource Retrieval Methods 
Research 
Text segmentation 
method 
Query making method 
Search control and retrievals filter 
method 
Advantages and Dis-
advantages 
E
liza
ld
e 
[8
] 
-Divides the text into 
sections of 50 linear 
 
-Using Coefficient (tf.idf) docu-
ment frequency or  identifying 
nominal phrases in making queries 
- Focuses on the top ten results of 
each query 
-Very good runtimes 
- Relatively low Recall 
K
o
n
g
 
[9
] 
- Divides the text into 
sections of 5 sentences 
-Selection of the ten best phrases in 
each section based on the key-
words extraction method BM25 
and weighted tf.idf 
-A rating model based on SVM 
ranking  for  grouping keywords in 
ranking queries 
 
-retrieve stop three results per que-
ry 
- Low  Precision 
- High number of 
generated queries 
-High Recall 
P
ra
k
a
sh
 
[1
0
] 
- Divides the text into 
sections of 100 words 
based on title detection 
-Selects five terms with the highest 
rank in the document level as well 
as five terms in the paragraph lev-
el. 
- Extracts keywords based on two 
well-known strategies, long term 
frequency and co-occurrence 
words 
 
-Retrieve a document from the ten 
highest results when at least one to 
five-grams of 500 characters are in a 
suspected document 
-Relatively good 
runtime 
- Relatively low Recall 
S
u
ch
o
m
el 
[2
5
] 
-Considers titles as sepa-
rate sections 
- Divides the documents 
into sections using titles 
-Using three different strategies to 
generate queries based on key-
words, paragraphs, and titles 
-Deletes duplicated similar posi-
tions 
-Uses snippet of 500 characters for 
each query 
-Very low Precision  
-High number of gen-
erated queries 
W
illiam
s 
[2
6
] 
- Divides a  suspected 
documents into para-
graphs with 5sentences 
- The formation of key phrases by 
nouns, adjectives, and verbs 
-Trains a classifier to retrieve fea-
tures using several search engines 
-The highest Precision 
-High number of gen-
erated queries 
Z
u
b
a
rev
 
[2
4
] 
- Divides the suspected 
document to formatted 
sentences 
 
-Forms queries by deleting articles, 
pronouns, prepositions, and re-
peated words 
-Choices six entities (phrases or 
words) from the main (most 
weighted) entities 
 
- Removes queries that are poten-
tially mapped to retrieved resources 
-Low number of gen-
erated queries 
P
a
ra
M
a
k
e
r 
(T
h
is P
a
p
e
r) 
-Divides the text into 
sentences 
- Use paraphrases of a sentence 
based on human behavior in mak-
ing queries 
- Exact sentence searching 
-Use proximity parameter for words 
of each sentence 
- Retrieve the highest result per 
query 
 
-Very high Recall 
parameter 
-Acceptable Precision 
and speed parameters 
-Generating more 
efficient and more 
precise queries 
-Retrieving relevant 
documents 
-High number of gen-
erated queries 
 
Page 3 of 13 Transactions on Knowledge and Data Engineering
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
For Peer Review
 O
nly
4 IEEE TRANSACTIONS ON JOURNAL NAME,  MANUSCRIPT ID 
 
 
Figure 2: The Proposed ParaMaker Framework
 
 
 
Figure 3: Various Paraphrases of Sentences in ParaMaker 
3.1 Phase I: Preprocessing 
Preprocessing includes performing suitable operations on 
a text that results in obtaining better inputs for similarity 
detection algorithms. The operations increase Precision 
and speed of phases next to the preprocessing phase. The 
preprocessing phase for English language involves the 
following steps [15,16]: 1) dividing the text into segments; 
2) replacing the numbers; 3) replacing tabs and new lines 
with a space character; 4) keeping letters and converting 
them all notation, numbers and others to spaces; 5) con-
verting all letters to lowercase; 6) replacing juxtaposed 
space characters with one space character; 7) deleting 
words that are less than three letters; 8) removing com-
mon words; 9) stemming the remained words using an 
algorithm such as Porter's stemming algorithm [17]. 
3.2 Phase II: Segmentation 
In this phase, context of a suspicious document is divided 
into its constituent sentences. Sentence diagnostic tools 
should pay attention to separator characters in sentences 
in order to recognize sentences in the input text. Precise 
output of algorithms in many languages depends on tools 
applied in this phase. 
3.3 Phase III: Query Generation 
In this phase, various paraphrases of a sentence are gen-
erated and sent as several search queries to the search 
engine. As is usually the case, plagiarizer follows several 
steps in paraphrasing as follows: 1) rearranging or changing 
the order of words in sentences or phrases; 2) removing words 
or phrases in sentences; 3) adding words or phrases; 4) replac-
ing words or phrases with their synonyms; 5) splitting or 
combining sentences [18]. 
Producing paraphrases of sentences: According to Fig-
ure 3, paraphrasing of a sentence falls into following cat-
egories 1) Near copy; 2) Light paraphrasing; 3) Heavy 
paraphrasing.  
Near copy includes slight changes in a sentence that is 
result of the preprocessing phase. These changes include 
removing or adding general words, replacing synonyms 
for general words, partial changes in the form of words 
and verbs or adding/removing signals in a sentence.  
Light paraphrasing includes removing one/more words, 
Page 4 of 13Transactions on Knowledge and Data Engineering
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
For Peer Review
 O
nly
AUTHOR ET AL.:  TITLE 5 
 
adding one/more sequential words, replacing words 
with their synonyms, and changing the order of words or 
phrases. In SenParaMaker algorithm, generating light 
paraphrasing includes at most three sequential words will 
be removed provided that words of a sentence will not 
become fewer than three words. Because a sentence with 
words fewer than three is a short phrase and short phrase 
searching causes wrong detection. Replacing synonym 
words is done by search engine in the search control 
phase.  
Heavy paraphrasing includes splitting complex sentences, 
deleting one or more words/phrases, adding one/more 
words/phrases, and permutation of words/phrases. Initially 
using a dependency parser [19], a sentence is analyzed 
and partitioned into its dependency units that will be ex-
plained more in the sequel. From now on, the remove 
operation is performed on dependency units instead of 
words. Removing each word from a sentence may result in 
producing trivial sentences. It prevents producing meaningless 
paraphrases and bypasses unnecessary processing which 
speeds up the detection process, consequently. 
According to [20], basically there are two assumptions in 
producing dependency grammar: 1) each sentence in-
cludes one central verb; 2) based on the type and number 
of mandatory/arbitrary complements of the central verb, 
determining fundamental structures that are built on this 
verb will be possible. In connecting two words by a de-
pendency relation, one word is root and another word is 
dependent. In order to parsing dependency of phrases, 
each element in a sentence must be tagged as a root or 
dependent element. It means that dependents of each root 
element and the root element of each dependent must be 
determined. Figure 4 shows the root/dependent words in 
the sentence “economic news had little effect on financial 
markets” 
Preprocessing includes performing suitable operations on 
a text that results in obtaining better inputs for similarity 
detection algorithms. The operations increase Precision 
and speed of phases next to the preprocessing phase. The 
preprocessing phase for English language involves the 
following steps [15,16]: 1) dividing the text into segments; 
2) replacing the numbers; 3) replacing tabs and new lines 
with a space character; 4) keeping letters and converting 
them all notation, numbers and others to spaces; 5) con-
verting all letters to lowercase; 6) replacing juxtaposed 
space characters with one space character; 7) deleting 
words that are less than three letters; 8) removing com-
mon words; 9) stemming the remained words using an 
algorithm such as Porter's stemming algorithm [17]. 
3.2 Phase II: Segmentation 
In this phase, context of a suspicious document is divided 
into its constituent sentences. Sentence diagnostic tools 
should pay attention to separator characters in sentences 
in order to recognize sentences in the input text. Precise 
output of algorithms in many languages depends on tools 
applied in this phase. 
3.3 Phase III: Query Generation 
In this phase, various paraphrases of a sentence are gen-
erated and sent as several search queries to the search 
engine. As is usually the case, plagiarizer follows several 
steps in paraphrasing as follows: 1) rearranging or changing 
the order of words in sentences or phrases; 2) removing words 
or phrases in sentences; 3) adding words or phrases; 4) replac-
ing words or phrases with their synonyms; 5) splitting or 
combining sentences [18]. 
Producing paraphrases of sentences: According to Fig-
ure 3, paraphrasing of a sentence falls into following cat-
egories 1) Near copy; 2) Light paraphrasing; 3) Heavy 
paraphrasing.  
Near copy includes slight changes in a sentence that is 
result of the preprocessing phase. These changes include 
removing or adding general words, replacing synonyms 
for general words, partial changes in the form of words 
and verbs or adding/removing signals in a sentence.  
Light paraphrasing includes removing one/more words, 
adding one/more sequential words, replacing words 
with their synonyms, and changing the order of words or 
phrases. In SenParaMaker algorithm, generating light 
paraphrasing includes at most three sequential words will 
be removed provided that words of a sentence will not 
become fewer than three words. Because a sentence with 
words fewer than three is a short phrase and short phrase 
searching causes wrong detection. Replacing synonym 
words is done by search engine in the search control 
phase.  
 
Figure 4: Root/Dependent Elements in a Sample Sentence 
Heavy paraphrasing includes splitting complex sentences, 
deleting one or more words/phrases, adding one/more 
words/phrases, and permutation of words/phrases. Initially 
using a dependency parser [19], a sentence is analyzed 
and partitioned into its dependency units that will be ex-
plained more in the sequel. From now on, the remove 
operation is performed on dependency units instead of 
words. Removing each word from a sentence may result in 
producing trivial sentences. It prevents producing meaningless 
paraphrases and bypasses unnecessary processing which 
speeds up the detection process, consequently. 
According to [20], basically there are two assumptions in 
producing dependency grammar: 1) each sentence in-
cludes one central verb; 2) based on the type and number 
of mandatory/arbitrary complements of the central verb, 
determining fundamental structures that are built on this 
verb will be possible. In connecting two words by a de-
pendency relation, one word is root and another word is 
dependent. In order to parsing dependency of phrases, 
each element in a sentence must be tagged as a root or 
dependent element. It means that dependents of each root 
element and the root element of each dependent must be 
determined. Figure 4 shows the root/dependent words in 
the sentence “economic news had little effect on financial 
markets”. 
 
Page 5 of 13 Transactions on Knowledge and Data Engineering
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
For Peer Review
 O
nly
6 IEEE TRANSACTIONS ON JOURNAL NAME,  MANUSCRIPT ID 
 
 
Figure 5: Heavy Paraphrase Detection Algorithm 
At this stage, as long as the sentence length is not less than half, 
removing the sequential dependency units is continued. The 
pseudo code of heavy paraphrase detection algorithm is shown 
in Figure 5. At first a sentence is broken into its dependen-
cy units. If the number of dependency units is less than or 
equal to five then the sentence is considered as a short 
sentence and function smallSentence is invoked; while the 
sentences with a dependency unit larger than five are 
considered as long sentences and function largeSentence 
is called, consequently. A long sentence might be a com-
pound sentence that is analogous to dividing the sentence 
into its constituent sentences S1 and S2. If the number of 
words in S1 or S2 is less than five, the sentences are con-
sidered as short phrases.  
 
 
Figure 6: SenParaMaker Flowchart to Detect Plagiarism of Sentences 
Figure 6 shows the whole SenParaMaker flowchart that 
detects plagiarism of a sentence. Producing paraphrases by 
changing order of words in sentences is taken place by setting 
proximity parameter that is described in the next phase. Syno-
nym replacement can be automatically done by the search en-
gine during search operation. 
1.1 Phase IV: Search Control  
In this phase, generated paraphrases for each sentence are 
sent to search engine as queries along with a proximity 
parameter. The proximity parameter finds words that are 
within a certain distance of each other, regardless of the 
order in which they are placed. For example, exact matches 
are proximity zero, and word transpositions “bar foo” are prox-
imity equal to one. Searching the term "foo bar" with a proximi-
ty parameter equal to one, is capable of detecting the phrase 
"bar foo" but is not able to detect the "bar text foo" because the 
words "foo" and "bar" are placed within two words of each 
other at least. If proximity parameter is set to two or more, it is 
analogues to the term "foo bar". It is remarkable that query 
searching along with proximity value is a type of exact search-
ing and ensures that the words within query terms are searched 
based on their proximity value. 
In this phase, words in every sentence are replaced by 
their synonyms in the dictionary along with setting prox-
imity parameter of search engine, simultaneously. Prox-
imity parameter for each paraphrase is the length of sentence in 
this step. Queries with proximity parameter are expected to 
have higher rank compared to words which are merely close 
together. As mentioned previously, this parameter deter-
mines irregularities of words and attaches phrases or words to 
sentences of an original document. 
Replacing words with synonyms: At this step, synonyms of 
words (without stop words) are identified and replaced by ap-
plying the dictionary. Synonym detection is applied due to the 
fact that people attempt to hide plagiarism by replacing the 
words with appropriate synonyms. In this research, to achieve 
higher Precision, entire synonyms of a word are replaced. 
1.2 Phase V: Filtering  retrieved documents 
It is usually the case that query searching retrieves several doc-
uments some of which are not source documents. It reduces 
Precision of plagiarism detection drastically. This is the reason 
why ParaMaker framework considers the top retrieved docu-
ment. In order to avoid crating intricate filters, ParaMaker tries 
to make more accurate queries. The default ranking algorithm is 
mostly based on Cos similarity between two documents. Con-
sidering proximity value between search queries and source 
documents affects ranking of results. Documents included in 
result of previous search terms are not considered again. 
1.3 Case Study 
Suppose the suspicious document containing the following 
text: 
 "the main purpose of this study is checking acceptance fac-
tors of this advertisement through this new technology. Joan 
Bynvayt from America won gold medal of women's 
marahon... Cool running is a complete resource for runners, 
offering a race calendar, race results listings!" 
Page 6 of 13Transactions on Knowledge and Data Engineering
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
For Peer Review
 O
nly
AUTHOR ET AL.:  TITLE 7 
 
 
Table 3: Case Study of ParaMaker 
Sentence-1 
Original sentence "checking and crititic of the acceptanance factors of advertisment through novel material, 
are purpose of this research." 
Suspecious  "the main purpose of this study,is checking acceptance factors of this advertisment 
through this new technology." 
Type of plagiarism Light paraphrase 
Sentence-2 
Original sentence "Joan Bynvayt won gold medal of marathon." 
Suspicious sentence "Joan Bynvayt from America won gold medal of women's marathon..." 
Type of plagiarism Heavy paraphrase-short  sentence 
Sentence-3 
Original sentence "Cool Running is a complete resource for runners, offering a race calendar, race results listings." 
Suspicious sentence "|Cool running is a complete resource for runners, offering a race calendar, race results listings!" 
Type of plagiarism Near Copy 
 
Table 3 includes original sentences along with their equiva-
lent suspicious sentences, and plagiarism type as well (Related 
to the above text). In addition, the following sections focus on 
how to detect plagiarized sentences and retrieve the resources 
which contain original sentences. 
1) Text preprocessing: having preprocessed, the above text 
may seem as follows: "main purpose study check 
acceptance factor advertisment technology. joan bynvayt 
america win gold medal women marathon. cool run 
complete resource run offer race calendar race result list." 
Table 4: Segmentation of Text into Its Sentences
 
2) Segmentation of text into its sentences: Table 4 shows a 
text that is segmented into sentences. 
3) Generating Queries: Table 5 shows generated queries 
for each sentence. 
4) Search control: In this phase,  entire sentences of a 
suspicious document along with paraphrasesof 
thesentences are sent to a search engine as queries. 
Replacing synonyms,and setting proximity parameter are 
of crucial importance in making suitable queries. Table 6 
shows the Search control phase. 
 
Table 6: Search Control 
 
In Sentence-1 (suspicious text) the word "study" is 
replaced with "research"," technology" is replaced with 
"material" and "new" is replaced with "novel'.Detection 
plagiarism requiresreplacing words with their synonyms 
which is done in thesearch engine applyinga dictionary 
during search operation for each sentence. 
The term "the main purpose of this study"is the case that 
uses relocation in addition to synonym replacement. This 
relocation also is recognizedin the search control phase by 
setting engine proximity parameter for each sentence, 
separately. Figure 7 showes steps taken in the case study 
of ParaMaker. The rest of the sentences in Table 3 are 
processed like Sentence-1. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Page 7 of 13 Transactions on Knowledge and Data Engineering
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
For Peer Review
 O
nly
8 IEEE TRANSACTIONS ON JOURNAL NAME,  MANUSCRIPT ID 
 
Table 5: Generating Queries 
 
 
 
 
Figure 7 : Case Study of ParaMaker 
 
Page 8 of 13Transactions on Knowledge and Data Engineering
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
For Peer Review
 O
nly
AUTHOR ET AL.:  TITLE 9 
 
 
Figure 8:  ParaMaker Evaluation Environment
4 EVALUATION 
In this section, datasets applied in the experiments for 
two both English and Persian languages are introduced 
first, and then two categories of experiments are used for 
both languages.  
1.4 Datasets 
Datasets for English Language Experiments: The evalua-
tions of this study are based on PAN2014 competition that is 
accessible from Webis-TRC-13[21]. A collection of web doc-
uments in ClueWeb2009 are provided in 145 topics that are 
manually searched. Each of the produced suspicious documents 
has a set of source documents (Dsrc). Source documents in-
clude series of phrases so that any phrase contains at least 50 
long words, and each document contains one term at least. In 
addition, terms are not repetitive and each term is also ex-
tracted from a set of terms. 
In order to mimic human behaviors in paraphrasing, each 
term is obfuscated and then a suspicious document is 
provided by attaching obfuscated terms, entirely. Suspi-
cious documents are finally paired with their peers in 
source documents. 
Some documents are produced in order to form sample docu-
ments without plagiarism. Dataset contains 3653 suspicious 
documents as well as 4774 source documents. Suspicious doc-
uments are divided into three categories: 1) no obfuscation that 
applies exact or near copies, 2) random obfuscation, and 3) no 
plagiarism. The aim of random obscurity is studying whether or 
not the detection algorithm is able to detect reused terms. 
Datasets for Persian Language Experiments: In order to 
evaluate ParaMaker in Persian language, three datasets 
are used as follows. 1) TMC (Tehran Monolingual Cor-
pus) has been created by university of Tehran and in-
cludes news extracted from Hamshahri newspaper and 
ISNA news agency. TMC is a huge monolingual corpus 
that contains 1000 source documents and 400 suspicious 
documents; 2) IranDoc which is an Iranian research center 
is responsible for gathering scientific documents specially 
students’ thesis. IranDoc has prepared 230 documents 
along with 220 suspicious documents; 3) Prozhe.com is a 
website in which 440 source documents along with 160 
suspicious documents are chosen and created based on 
several scientific reports and students’ papers.  
According to [22], two document sets are created for de-
tecting plagiarism, specifically. Five categories of queries 
are produced in these datasets that are features as fol-
lows: 1) synonym replacement; 2) structural changing; 3) 
synonym replacement and structural changing; 4) Re-
Page 9 of 13 Transactions on Knowledge and Data Engineering
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
For Peer Review
 O
nly
10 IEEE TRANSACTIONS ON JOURNAL NAME,  MANUSCRIPT ID 
 
moving words; and 5) adding words. 
1.5 Evaluation Criteria 
Performance of resources retrieval algorithms for any sus-
picious document is evaluated using the following five 
criteria [2,23]: 1) the number of submitted queries; 2) the 
number of retrieved documents; 3) Precision; 4) Recall, 
and 5) average runtime in minutes. Suppose a suspicious 
document contains phrases from a text including terms 
that have been plagiarized from a set of source documents 
Dsrc, and Dret represents a set of retrieved documents 
returned by a retrieval algorithm. Precision and Recall are 
calculated based on the following formulas. Finally, in order 
to measure the cost-effectiveness of a source retrieval algo-
rithm in retrieving Dret set, workload is calculated in terms of 
number of queries and retrievals.  
Precision =
|𝐷ret∩𝐷src|
|𝐷ret|
 Recall =
|𝐷ret∩𝐷src|
|𝐷src|
 
5 EXPERIMENTS AND EXPERIMENTAL SETUP 
The presented ParaMaker framework is examined for 
both English and Persian languages. For retrieving doc-
uments Apache Solr5, open source search engine is ap-
plied. PAN2014 uses Indri6 search engine for searching 
queries; while ParaMaker applies Solr. In [24], both Solr 
and Indri were compared in 2009 and 2012. According to 
Table 7 indexing time in Indri is quicker then Solr, and 
size of produced index file is less in Indri. Precision of 
retrieving and ranking of documents in Indri is better 
than precision of Solr. However, for heavy queries the 
speed of searching documents in Solr is ten times quicker 
than Indri that is the reason why for the experiments that 
compare the searching time are ten folded to be compara-
ble with Indri. 
Table 7: Comparison of Search Time in Solr and Indri
 
An illustration of experiment environment has been 
shown in Figure 8 in which every component of Para-
Maker framework is implemented by a suitable tool. In 
addition several experiments are considered for evaluat-
ing the ParaMaker framework in both English and Per-
sian languages as shown in Table 8. Experiment-1 studies 
the effects of preprocessing on ParaMaker framework. 
Experiment-2 measures Precision and Recall parameters 
for exact, light paraphrase, and heavy paraphrasing. Ex-
periment-3 studies the relation between number of re-
trieved documents and Precision and Recall parameters 
for each query. Expriment-4 compares the performance of 
ParaMaker and PAN2014 participants. Finally, Experi-
ment-5 is performed on three datasets in Persian lan-
guage and studies Precision and Recall parameters. 
 
5 http://lucene.apache.org/solr/ 
6 http://www.lemurproject.org/indri/ 
Table 8: Design of Experiments  
 
1.6 Experiments for English and Persian Lan-
guages 
1.6.1 Experiment-1: Evaluation of Preprocessing 
The experiment shown in Figure 9 shows the effects of prepro-
cessing on Precision and Recall parameters. The parameters are 
measured with/without pre-processing and obtained results are 
compared finally. 
 Preprocessing includes removing stop words, replacing syno-
nyms, and stemming. Compared to the time when there is no 
preprocessing, Recall parameter increased to 16% after remov-
ing stop words, with synonym replacement to 5% and with 
stemming to 7%. On the other hand Precision parameter de-
creases to3%, 12%, and 8%, respectively. 
 
Figure 9: Evaluations of Pre-processing 
1.6.2 Experiment-2: Evaluating various types of 
paraphrasing 
This experiment aims at evaluating the recognition algo-
rithm. According to Figure 10, compared to near copy, 
Recall parameter increased to 12% for light paraphrasing, 
and 32% for heavy paraphrasing. Having more number of 
retrieved documents in the collection Dret, increases Re-
call parameter, due to having more number of common 
documents in both source and retrieved documents. In-
creasing Recall is analogous to decreasing Precision crite-
rion. However, Dret is in denominator part of Precision 
formula and as a result increasing the number of re-
trieved documents affects Precision parameter, inversely. 
In order to solve this problem, retrieved documents must 
be from source documents, mostly. It can be realized 
when downloads are constrained and higher ranked doc-
uments are retrieved. 
Page 10 of 13Transactions on Knowledge and Data Engineering
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
For Peer Review
 O
nly
AUTHOR ET AL.:  TITLE 11 
 
Table 9: Comparison of ParaMaker against PAN2014’s Best Detectors 
 
 
Figure 10: Evaluation of Various Paraphrasing Types 
1.6.3 Experiment-3: Evaluating number of down-
loads for each query 
As shown in Figure 11, selecting top three documents from re-
sults returned by the search engine instead of considering 
the whole results, improves parameters Precision about 11%, 
and decrease Recall  about 5%. If a document is selected with 
the highest rank, Precision is increased significantly to 18%, 
while Recall decreases lightly about 6% that is negligible. 
 
Figure 11: Evaluation of Number of Downloads for Each Query 
1.6.4 Experiment-4: Comparison of ParaMaker 
against PAN2014’s Best Detectors 
In this experiment, the performance of six plagiarism detectors 
participated in PAN2014 competition is studied against the pro-
posed system. The Comparison of results in Table 9 showed 
that Recall parameter improved 34% compared to Prakash 
[11] that had highest Recall previously. 
1.6.5 Experiment-5: Measuring evaluation crite-
ria for ParaMaker in Persian language in compari-
son to exact search. 
The same experiments similar to the experiments for Eng-
lish language were repeated for Persian language. Ob-
tained results showed that ParaMaker increased Recall 
parameter in Persian language as well. Moreover in com-
parison to increasing Recall parameter, decreasing Preci-
sion can be waived. According to the previous experi-
ments, evaluation criteria are measured for exact search-
ing by a search engine. The obtained results are compared 
to exact searching after preprocessing, searching light 
paraphrasing of sentences, and finally heavy paraphras-
ing of sentences. The whole evaluations are performed on 
three Persian datasets including TMC, IranDoc, and 
Prozhe.com. Evaluation results showed that Recall pa-
rameter for TMC dataset is improved around 45% in Fig-
ure 12, 42% in Figure 13 on IranDoc Dataset, and 61% in 
Figure 14 on Prozhe.com dataset. Reducing Precision is 
due to increasing the number of retrieved documents. 
Page 11 of 13 Transactions on Knowledge and Data Engineering
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
For Peer Review
 O
nly
12 IEEE TRANSACTIONS ON JOURNAL NAME,  MANUSCRIPT ID 
 
 
Figure 12: Evaluating ParaMaker in Persian Language on TMC Dataset 
 
Figure 13: Evaluating ParaMaker in Persian Language on IranDoc Dataset 
 
 
Figure 14: Evaluating ParaMaker in Persian Language on Prozhe.com Da-
taset 
2 Discussions 
Pre-processing operation has a positive impact on improving 
the performance of detection algorithms. Whatever number of 
generated paraphrases is greater, number of queries increases. 
Increasing number of queries, the number of retrieved docu-
ments and possibility of retrieved resources are also increased, 
and Recall parameter increased. If the selected document was 
of the highest rank, Precision increased greatly; however, Re-
call parameter reduced a negligible amount. Using natural 
language processing techniques and producing correct para-
phrase for each sentence in a suspicious document, more effi-
cient queries were generated in the query construction phase. 
Having retrieved the best related documents for each sentence, 
the plagiarism detection algorithm would be able to improve 
Recall parameter along with maintaining Precision and Speed 
of plagiarism detection. 
3 Conclusions and Future Works 
Earlier plagiarism detection methods searched in local 
databases, while realistic approaches should look at available 
resources on the Internet. Inspecting suspicious documents and 
producing queries which are then sent to search engines is 
known as resource retrieval. A common issue in plagiarism 
detection methods that use resource retrieval techniques is 
having low Recall parameter. Some methods try to improve 
this parameter that led to a sharp Precision and speed reduction. 
This research aims at presenting a plagiarism detection ap-
proach that improves Recall parameter while maintains Preci-
sion and Speed. The comparison of the proposed system with 
six methods in PAN2014 showed an improvement of 34%, 
while the proposed method has an average Precision and speed. 
This study focused on paraphrases of sentences; however, 
changes such as summarizing sentences are not studied. As text 
summary is mostly used in idea plagiarism, it is suggested that 
our idea get extended in idea paraphrasing. Moreover in query 
generation phase, paraphrases of a sentence can be combined 
with key phrases to generate more precise queries. Itis also sug-
gested that in order to generate more precise queries, para-
phrased sentences must be ranked and only more important 
sentences considered for query generation. Control search 
and/or filtering documents can also be improved to reduce 
retrieved resources instead of retrieving the highest rank doc-
uments that is focus of this paper. 
REFERENCES 
[1] Maurer، H.A.، F. Kappe، and B. Zaka، Plagiarism-A Survey. 
J. UCS، 2006. 12(8): p. 1050-1084. 
[2] M. Potthast، M. Hagen، A. Beyer، M. Tippmann، M. Busse، P. 
Rosso، and B. Stein،"Overview of the 6th international com-
petition on plagiarism detection،" in CLEF Conference on 
Multilingual and Multimodal Information Access Evaluation، 
2014، pp. 845-876 
[3] S. M. Alzahrani، et al.،"Understanding Plagiarism linguistic 
patterns، textual features، and detection methods،" Systems، 
Man، and Cybernetics، Part C: Applications and Reviews، 
IEEE Transactions on، vol. 42، pp. 133-149، 2012. 
[4] Z. Ceska، et al.،"Multilingual plagiarism detection،" Artificial 
Intelligence: Methodology، Systems، and Applications، pp. 
83-92، 2008. 
[5] Ho، C.، et al.، Extracting lexical and phrasal paraphrases: a 
review of the literature. Artificial Intelligence Review، 2012: 
p. 1-44. 
[6] Elizalde، V.: Using Noun Phrases and tf-idf for Plagiarized 
Document Retrieval—Notebookfor PAN at CLEF 2014. 
[7] Barker، K.، Cornacchia، N.: Using Noun Phrase Heads to 
Extract Document Keyphrases.In: Hamilton، H.J. (ed.) Ad-
vances in Artificial Intelligence، 13th Biennial Conference of 
theCanadian Society for Computational Studies of Intelli-
gence، AI 2000، Montréal، Quebec،Canada، May 14-17، 
2000، Proceedings. Lecture Notes in Computer Science، vol. 
1822، pp  .40–52 . Springer (2000( 
[8] Kong، L.، Han، Y.، Han، Z.، Yu، H.، Wang، Q.، Zhang، T.، Qi، 
H.: Source Retrieval Based onLearning to Rank and Text 
Alignment Based on Plagiarism Type Recognition for Plagia-
rism Detection—Notebook for PAN at CLEF 2014. 
Page 12 of 13Transactions on Knowledge and Data Engineering
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
For Peer Review
 O
nly
AUTHOR ET AL.:  TITLE 13 
 
[9] Robertson، S.، et al. Simple BM25 extension to multiple-
weighted fields. In Proc. of the CIKM’04، 2004. 
[10] Gaston H. Gonnet، Ricardo A. Baeza-yates، Tim Snider. New 
Indices for Text:Pat Trees and Pat Arrays. Information Re-
trieval Data Structures & Algorithms،Prentice Hall، pp. 66-82، 
1992. 
[11] Prakash، A.، Saha، S.: Experiments on Document Chunking 
and Query Formation forPlagiarism Source Retrieval—
Notebook for PAN at CLEF 2014.  
[12] K. Toutanova and C. D. Manning،"Enriching the knowledge 
sources used in a maximum entropy part-of-speech tagger،" in 
Proceedings of the 2000 Joint SIGDAT conference on Empiri-
cal methods in natural language processing and very large 
corpora: held in conjunction with the 38th Annual Meeting of 
the Association for Computational Linguistics-Volume 13، 
2000، pp. 63-70. 
[13] K. Williams, H. Chen, and C. Giles, "Supervised Ranking for 
Plagiarism Source Retrieval،"Notebook for PAN at CLEF 
2014, 2014. 
[14] D. Zubarev and I. Sochenkov ،"Using Sentence Similarity 
Measure for Plagiarism Source Retrieval،" Notebook for PAN 
at CLEF 2014 ،2014.  
[15] Chong، M.، Specia، L. & Mitkov، R، Using Natural Lan-
guageProcessing for Automatic Detection of Plagiarism، In: 
Proceedings ofthe 4th International Plagiarism Conference، 
Newcastle-upon-Tyne،UK، 2010. 
[16] Ceska، Zdenek and Fox، Chris ،The Influence of Text Pre-
processingon Plagiarism Detection. In: Angelova، Galia and-
Bontcheva،Kalina and Mitkov، Ruslan and Nicolov، Nicolas 
and Nikolov، Nikolai،(eds.) International Conference on Re-
cent Advances in Natural Language Processing 2009. Associa-
tion for Computational Linguistics،pp. 55-59، 2011. 
[17] P. Willett, "The Porter stemming algorithm: then and 
now,"Program, vol. 40, pp. 219-223, 2006. 
[18] P.Clough،" Plagiarism in natural and programming languages: 
an overview of current tools and technologies،" Department of 
Computer Science، University of Sheffield ،2000 . 
[19] S. Kübler، R. McDonald، and J. Nivre، "Dependency pars-
ing،" Synthesis Lectures on Human Language Technologies، 
vol. 1، pp. 1-127، 2009. 
[20] J. Nivre، "Dependency grammar and dependency parsing،" 
MSI report، vol. 5133، pp. 1-32، 2005. 
[21] Potthast، M.، Hagen، M.، Völske، M.، Stein، B.: Exploratory 
Search Missions for TRECTopics. In: Wilson، M.L.، Russell-
Rose، T.، Larsen، B.، Hansen، P.، Norling، K. (eds.) 3rd Euro-
pean Workshop on Human-Computer Interaction and Infor-
mation Retrieval(EuroHCIR2013). pp. 11–14. CEUR-WS.org 
(Aug 2013) 
[22] S. Rakian, F. S. Esfahani, and H. Rastegari, "A Persian Fuzzy 
Plagiarism Detection Approach،" Journal of Information Sys-
tems and Telecommunication, Vol. 3, No. 3, 2015. 
[23] M. Potthast، M. Hagen، T. Gollub، M. Tippmann، J. Kiesel، P. 
Rosso، E. Stamatatos، and B. Stein،"Overview of the 5th in-
ternational competition on plagiarism detection،" in CLEF 
Conference on Multilingual and Multimodal Information Ac-
cess Evaluation، 2013، pp. 301-331. 
[24] H. Turtle ،Y. Hegde ،and S. Rowe ،"Yet another comparison 
of lucene and indri performance،" in SIGIR 2012 Workshop 
on Open Source Information Retrieval ،pp. 64-67 ،2012. 
[25] Š. Suchomel and M. Brandejs، "Heterogeneous Queries for 
Synoptic and Phrasal Search،"Notebook for PAN at CLEF 
2014،2014. 
 
 
 
 
 
Akram Shojaii has received her master's degree in software engi-
neering from Islamic Azad University, Najafabad branch, Iran. Her 
current research interests include Information Retrieval, Search En-
gines, and Plagiarism Detection. 
 
Faramarz Safi-Esfahani received his Ph.D. in Intelligent Computing 
from University of Putra Malaysia in 2011. He is currently on faculty 
at Department of Computer Engineering, Islamic Azad University, 
Najafabad branch, Iran, since 2002. His research interests include 
intelligent computing, Cloud Computing, Autonomic Computing, and 
Bio-inspired. 
 
Page 13 of 13 Transactions on Knowledge and Data Engineering
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
