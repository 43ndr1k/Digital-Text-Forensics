 
 
UNIVERSITE PARIS 8 – VINCENNES – SAINT – DENIS 
U.F.R. 6 INFORMATIQUE 
 
N° attribué par la bibliothèque 
       
 
 
THESE 
pour obtenir le grade de 
DOCTEUR DE L'UNIVERSITE PARIS 8 
en Informatique 
présentée et soutenue publiquement 
par 
 
Anna PAPPA 
 
 
17 décembre 2003 
 
 
 
START : analyse syntaxique automatique de surface sur grand corpus en français 
 
 
  
 
Directeur de thèse: Gilles BERNARD 
 
  
 
JURY 
 
M. GREUSSAY Patrick Président 
Mme BALMAS Françoise Examinatrice 
M. SAINT DIZIER Patrick Rapporteur 
M. SCHINIOTAKIS Kostas Examinateur 
M. WERTZ Harald Examinateur 
M. WILKS Yorick Rapporteur 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
à Néphèli, à Matthaios ... 
 
 
3  Remerciements 
START 2003 
Remerciements 
Je suis profondément reconnaissante envers Gilles Bernard qui a dirigé ce travail. Sa 
rigueur, ses compétences son esprit vif et surtout sa patience m’ont guidée tout au long de 
mes recherches. Je le remercie pour son soutien et sa confiance qui m’ont amenée à faire 
partie de son équipe de recherche C.S.A.R, et qui m’ont motivée à découvrir les pratiques et 
les théories du traitement du langage naturel dans le cadre de l'intelligence artificielle. 
Je garderai toujours un souvenir, entouré de beaucoup d’émotion, de l’accueil qui m’a été 
réservé par Patrick Greussay et son laboratoire d’Intelligence Artificielle, à l’Université 
Paris 8. Ce fut très instructif de suivre ses cours, et sa pédagogie restera l’exemple à suivre. 
Je remercie Harald Wertz qui fut en partie co-directeur de ce travail et surtout pour être 
discrètement présent à chaque étape avec toujours le bon conseil et la dose de confiance 
nécessaires pour dépasser les craintes des jeunes chercheurs. 
Je remercie chaleureusement mes rapporteurs Yorick Wilks, et Patrick Saint Dizier pour 
avoir accepté d’examiner et évaluer ce travail. Leur présence est un grand honneur pour moi 
et le Laboratoire. 
Je remercie Kostas Schiniotakis qui m’a fait l’honneur de faire partie de mon jury. La 
langue grecque présente dans ce travail a trouvé un correspondant direct pour se faire 
entendre. 
Je dois beaucoup à Françoise Balmas qui a manifesté très tôt son intérêt pour l'avancement 
de mes recherches et m'a encouragée à continuer même quand le moral ne suivait pas. C’est 
un grand honneur pour moi de pouvoir la compter parmi les membres de mon jury. 
Je remercie tous les membres de l’équipe CSAR : Jean-Jacques Mariage, Jym Feat, Giorgos 
Archodakis ainsi que Patricia Duclos pour m’avoir aidée avec le matériel et les bons 
conseils, des réflexions pertinentes et des propos amicaux. Merci aux néophytes du groupe 
Hind Oukerradi et Gregory Faruch dont la présence fut précieuse durant le parcours final de 
la thèse. 
4  Remerciements 
START 2003 
Je remercie également D. Goossens, B. Alicherif, J. Méhat, et J.J. Bourdin pour leurs 
conseils amicaux pendant les débogages ou les pauses café. 
Je dois beaucoup au Laboratoire d’Intelligence Artificielle qui embrasse de nombreux 
aspects de recherche, ainsi qu'à ses membres, collègues et amis, qui m’ont aidée pendant les 
interminables heures de travail mais aussi et non pas moins pendant les rapides moments de 
détente, ils sont nombreux, je les remercie tous et particulièrement Vincent Boyer, Nicolas 
Jouandeau, et Mark Hufshmitt. 
Je voudrais remercier le personnel de l'UFR 6 et spécialement Souris Martinet et Philippe 
Pinon dont l'amitié et le soutien m'ont accompagnée tout au long de cette aventure. 
Je tiens à remercier mes parents qui m’ont soutenue et aidée jusqu’à la fin de mes études. 
Merci à Sophie Cudek pour ses relectures et son aide pour la mise en forme. Je lui dois 
beaucoup, bien plus que je ne saurai le dire. 
Corinne et Fabrice Orlando m’ont beaucoup aidée ; le matériel qu’ils m’ont prêté m’a 
permis de finir la rédaction, malgré les contre-temps qu’une grande majorité des thésards 
connaît vers la fin de la thèse. Je les remercie. 
Un grand merci à mon compagnon Pascal Delbano dont les relectures et l’impatience m’ont 
poussée à mettre le point final. 
Merci à tous mes amis et personnes du cercle familial pour leur soutien et encouragements 
tout au long de cette recherche. 
 
Sommaire  5 
START 2003 
Sommaire 
 
 
INTRODUCTION 
PROBLEMATIQUE 
ETAT DE L’ART 
METHODOLOGIE 
LE SYSTEME « START » 
RESULTATS ET EXPERIMENTATIONS 
CONCLUSIONS ET PERSPECTIVES 
 
 
 

Résumé  7 
START 2003 
Abstract 
Our research study presents a rule-based system of shallow parsing : START (System of 
Textual Analysis Recognition and Tagging) extracts form constituents such as noun and 
verb phrases from unrestricted untagged corpora and proceeds in a partially grammatical 
tagging.  
The method is based on the distributional analysis of the grammatical words (such as 
articles, pronouns, negation, etc.) which are used as "noyau" for the rules. The rules are 
based on statistics about grammatical words' distribution in large corpora. The system 
produces the following :  
! Recognition of phrases (the punctuation role is mentioned and a method of 
disambiguation is proposed), the accuracy exceeds 99% and the error is inferior to 1%. 
This algorithm has also been tested with success to untagged Greek corpora,  
! Recognition of internal phrases, constituents that form a unit for example a noun phrase. 
The system determines the frontiers of the constituent and extract it. The precision is 
around 93 % with an error rate of 0,7% for both nominal and verbal phrases and a 
comparison is given with the articles that mention recognition of nominal phrases. We 
insist on the fact that our method uses no previous knowledge.  
! Tagging partially terms of the extracted constituents. For instance for a nominal phrase 
"...étendait ses bras vides..." the system extracts /ses bras vides/ and tags "bras" as a 
noun,  
! Disambiguates the article / pronoun ambiguity in French "le, la, les, l'" can be article or 
pronoun, the accuracy is over 98,5% and the error rate inferior to 1%. The 
disambiguation is the result of a three-pass parsing.  
8  Résumé 
START 2003 
! Creates a lexicon which entries are the tagged terms of the constituents. For example 
"bras" can be added to the dictionary base as a noun. The dictionary is composed by 
nouns, verbs, past participes and adverbs in their flexional form.  
The dictionary is used for the third pass of the disambiguation algorithm, like a self learning 
process.  
The low error rate of the different applications gives us the possibility to automatically 
annotate corpora (considering the existing methods of annotating corpora where the error is 
very high).  
Other perspective is that of automatically tagging the syntactic role of the constituents, if we 
take for example the nominal phrase we mentioned before "... étendait ses bras vides " the 
system would produce the tag of "complement d'objet" for the extracted nominal phrase /ses 
bras vides/.  
In a future work we will also consider the possibility of rules generation from the system 
itself. 
 
Guide de lecture  9 
START 2003 
Guide de lecture 
Le guide de lecture se répartit ainsi : 
* introduction : description générale du système élaboré sur la 
reconnaissance automatique des parties du discours. 
* chapitre I : problématique de l’étude avec définition et complexité du 
problème, présentation détaillée des mots grammaticaux et 
de leur distribution dans la phrase.  
* chapitre II : l’état de l’art, bref historique et travaux existants dans le 
domaine. Les bases théoriques et pratiques dont on dispose, 
les outils, les statistiques, etc. 
* chapitre III : méthodologie : méthodes adoptées, observation des 
régularités basées sur des statistiques effectuées qui nous 
permettent l’élaboration d’un algorithme. 
* chapitre IV : algorithme et système réalisé, description de différentes 
étapes synthèse et application des règles élaborées, 
dictionnaire. 
* chapitre V : expérimentations et résultats obtenus ; création du 
dictionnaire, résultats analytiquement répartis pour les 
différents groupes syntaxiques. 
* conclusion / perspectives Amélioration du taux de résolution, tout en gardant un taux 
d’erreur bas, utiliser les connaissances lexicales obtenues, 
possibilité de générer automatiquement les règles, 
annotation automatique du corpus. 
10  Guide de lecture 
START 2003 
A la fin nous trouverons l’index des figures et l’index des tableaux. 
Nous trouverons également un glossaire de terminologie ainsi qu’une liste d’abréviations 
employés tout au long de cette étude. 
En annexe, nous trouverons quelques extraits des résultats obtenus à partir des différents 
tests effectués sur l’ensemble du corpus. 
 
 
 
 
 
 
 
INTRODUCTION 
12  Introduction 
START 2003 
« Le langage évolue à la manière 
des êtres qui ont vie » 
[Guillaume 1961] 
 
La recherche que nous présentons concerne le développement d’un système informatique 
qui effectue la reconnaissance automatique superficielle des parties du discours et procède 
à l’étiquetage automatique des mots du corpus. En phase finale il crée un dictionnaire avec 
des entrées lexicales stockées selon leur type grammatical, qui peuvent être utilisées soit 
pour la désambiguïsation soit pour améliorer les résultats de la première analyse syntaxique. 
L’algorithme a été conçu à partir des statistiques de la distribution de marques 
grammaticales qui reflètent leurs propriétés syntaxiques et sémantiques.  
Notre système START1 constitue une incursion dans un domaine situé au point de rencontre 
entre l’intelligence artificielle et la linguistique. Le système illustre la tendance actuelle qui 
consiste à faire évoluer des modèles linguistiques de façon à les combiner de plus en plus 
étroitement avec des techniques statistiques. On ne peut se passer de l’analyse linguistique 
même dans un domaine où le recours à des algorithmes de plus en plus élaborés tend à 
remplacer l’étude de la langue. Le cadre théorique linguistique étendu que nous suivons est 
le développement des réflexions sur le langage de G. Guillaume  et de E. Benveniste 
[Guillaume 1961] [Benveniste 1966], mais en même temps celui qui s’est construit à partir 
de la théorie des opérations énonciatives élaborée par A. Culioli. Le cadre de travail est 
énonciatif [Culioli 1990], structuraliste, fonctionnaliste et prend en compte l’aspect 
dynamique du langage. La méthodologie est fondée sur l’analyse morpho –syntaxique des 
mots grammaticaux et leurs régularités. 
La seule notion qui serve de base à cette recherche des régularités, est celle de contexte 
linéaire ou d’environnement [Ducrot et Todorov 1972]. L’environnement sert aussi à 
                                                   
1. START (System of Textual Analysis Recognition and Tagging) : Système d’analyse textuelle pour la 
reconnaissance et l’étiquetage. 
Introduction  13 
START 2003 
définir la distribution des constituants immédiats : c’est l’ensemble des environnements 
dans lesquels on la rencontre dans le corpus (le rôle fondamental de cette notion a conduit 
les linguistes qui se réclament de L. Bloomfield, notamment R.S. Wells et Z.S. Harris, au 
début de leurs travaux, à s’appeler distributionnalistes)1 [Bloomfield 1970], [Wells 1947], 
[Harris 1954]. 
L’étendue d’un groupe verbal ou nominal varie en nombre de mots; nous présentons les 
principaux travaux dans le domaine de la linguistique concernant ces parties du discours 
afin de comprendre leurs caractéristiques et particularités. Notre but est de définir ces 
caractéristiques afin de pouvoir les formaliser dans un système automatique. Il faudra donc 
automatiser toute procédure intellectuelle qui nous permet de distinguer un tel groupe d’un 
autre sans l’aide d’un dictionnaire, car nous sommes capables de reconnaître par exemple 
un groupe nominal même lorsqu’il comporte des mots inconnus (ceci nous est impossible 
dans une langue complètement inconnue). 
La simulation de cette faculté de la compréhension du langage, dont tout être humain est 
doté, est à l’étude depuis longtemps. A l’heure actuelle, les systèmes de compréhension 
existants permettent le traitement d’une langue contrainte (ou sublanguage chez Z.S. 
Harris) : l’utilisateur est limité, soit dans la variation structurelle de ses phrases (syntaxe 
contrainte par une grammaire artificielle), soit dans ce qu’il peut dire (domaine avec une 
sémantique contrainte). Le langage courant tel qu’il est pratiqué la plupart du temps n’est 
pas toujours correctement analysé, ce qui justifie que la compréhension du langage naturel 
soit toujours un domaine de recherche très actif en Intelligence Artificielle. 
L’intérêt du traitement automatique du langage naturel, initialement orienté vers la 
traduction automatique, est qu’il s’est recentré vers une description complète du langage. 
                                                   
1. Des notions précédentes, le distributionnalisme tire d’abord une méthode pour décomposer les énoncés du corpus, 
ou selon la terminologie usuelle, pour faire leur analyse en (C.I.) selon R.S. WELLS. Cette analyse qui amène à 
attribuer à la phrase une construction hiérarchique, consiste à décomposer d’abord l’énoncé en quelques segments 
assez vastes, qui sont appelés ses C.I., puis à subdiviser chacun de ceux-ci en sous-segments, qui sont 
respectivement les C.I. des C.I. et ainsi de suite jusqu’à ce qu’on arrive à des unités minimales. 
14  Introduction 
START 2003 
Cette description peut être basée sur une description manuelle du lexique ou sur des 
procédures plus ou moins automatiques d’étiquetage de textes. L’étiquetage devient un outil 
indispensable en raison de l’ambiguïté du lexique. L’analyseur parcourt mot à mot et, selon 
le cas, attribue une étiquette (tag) à chaque mot. 
La syntaxe est un composant essentiel de toute application en traitement automatique des 
langues naturelles. Ces trente dernières années, des progrès importants ont été effectués. 
Nous sommes passés d’une simple application de techniques d’analyse des langages 
formels à l’émergence d’un véritable domaine de recherche qui provient essentiellement de 
réflexions menées à l’intersection de la linguistique et de l’informatique sur la question de 
la syntaxe. Des systèmes reposant sur des informations syntaxiques très générales ont 
évolués vers des approches permettant de décrire plus finement des phénomènes 
syntaxiques complexes comme les dislocations, malgré les difficultés d’implantations que 
présentent les formalismes autorisant ce type de description. L’axe commun de 
l’automatisation est la phase d’analyse automatique qui se décompose à trois niveaux 
d’analyse : 
- L’analyse morphologique (identification des mots ou des morphèmes) 
- L’analyse syntaxique (identification des syntagmes et de leur fonctions) 
- L’analyse sémantique 
Nous pouvons mentionner également l’analyse lexicale qui peut être considérée comme un 
composant des analyses mentionnées ci-dessus, et dans laquelle on peut distinguer : 
- la segmentation (identification des frontières des mots et des mots composés), 
- la lemmatisation (identification du mot sous sa forme canonique), 
- l’étiquetage (identification de la bonne catégorie morpho – syntaxique pour une 
forme donnée, en contexte). 
Les premières applications (système de dialogue, traduction automatique) utilisaient en fait 
non pas une analyse syntaxique au sens propre du terme, mais des procédures de bas niveau 
Introduction  15 
START 2003 
(transfert lexical, ordonnancement, etc.). L’accès à l’information reposait sur une recherche 
des mots clés. Pour l’anglais l’extraction d’informations à partir des données textuelles, tels 
les dépêches d’agence, a connu plusieurs générations de programmes, évalués dans le cadre 
des conférences MUC1 (Message Understanding Conference). Par ailleurs, nous avons vu 
des systèmes performants basés sur des moules (frames) avec très peu de connaissances 
syntaxiques, par exemple ceux de l’école de R. Schank pour qui les relations conceptuelles 
l’emportaient sur les connaissances linguistiques comme le montre le système Atrans 
[Lutinen et Gershman 1986] [Schank 1986]. Les tendances actuelles privilégient des 
systèmes d’analyse partielle connue aussi sous le nom de skimming (« écrémage des textes 
[Abeillé et Blache 2000]) ou shallow parsing (analyse superficielle ou analyse de surface). 
Mais comme le mentionne très bien P. Jacobs on a besoin d’autant d’informations pour 
savoir ce qu’on ne peut analyser, que pour analyser [Jacobs 1990]. On voit alors l’analyse 
syntaxique se décomposer en niveaux distincts : 
- le parenthésage (identification des frontières syntagmatiques majeures), 
- l’assignation de fonctions aux syntagmes distingués (ou à leur tête ou noyau), 
- la désambiguïsation syntaxique des têtes prédicatives (cadre de sous-catégorisation, 
actif / passif, etc.), 
- l’assignation d’une structure syntaxique arborescente à chaque phrase étudiée. 
Cette décomposition est jugée nécessaire car les objectifs semblent réalistes, cependant d’un 
point de vue linguistique ces tâches ne sont pas indépendantes les unes des autres, et à 
chaque niveau, des connaissances obtenues aux autres niveaux d’analyse, sont nécessaires.  
Les corpus sur lesquels les analyses sont effectuées sont préalablement « annotés ». Nous 
citons le grand projet The Penn Treebank (PTB) [Marcus et al. 1993] qui a été largement 
sollicité pour produire automatiquement des grammaires dérivées. Un parseur qui utilise ces 
grammaires peut donner une précision de 80% [Charniak 1996]. Depuis la création du PTB 
plusieurs projets ont vu le jour avec la naissance des algorithmes de compression des 
                                                   
1. Voir le site http://www.muc.saic.com 
16  Introduction 
START 2003 
grammaires dérivées [Krotov et al.1998] ou des algorithmes basés sur des techniques 
statistiques [Charniak 1997] qui donnent une précision de l’ordre de 90%. 
Nous présentons un système qui reconnaît les différents syntagmes syntaxiques qui 
composent une phrase : les syntagmes substantifs ou nominaux (SS ou SN), les syntagmes 
verbaux (SV), les syntagmes prépositionnels (SP) qui se décomposent en Prép + SN ou SV 
et les subordonnées relatives (SR). Reconnaître un groupe syntaxique dans un texte peut 
être considéré :  
- comme le résultat d’un processus : le groupe est délimité avec les séquences de mots 
qui le composent du début à la fin et dans ce cas on parle de localisation, 
- ou comme le processus lui-même, dans ce cas alors on parle de description. 
Notre algorithme s’intéresse à la localisation. Mais si nous voulons utiliser les résultats de la 
reconnaissance pour une traduction, par exemple dans le cas d’un syntagme nominal 
reconnu à son étendue « la maison de l’ancienne propriétaire », il nous faut sa description 
également : dét + nom + prép + dét + adj + nom. Il nous la faut également dans le cas où 
nous voudrions chercher les relations binaires entre les adjectifs et les noms pour essayer 
d’isoler leur relation particulière comme dans « l’ancienne propriétaire », ou nous voudrions 
procéder à un étiquetage des fonctions [Blaheta et Charniak 2000] comme dans notre 
exemple où une relation d’appartenance est exprimée par la construction nom + prép + dét 
+ nom.  
Les analyseurs actuels en français [Vergne et Giguet 1998] ; [Clément 2001] comme en 
anglais [Carlson et al. 2001] ont utilisé et continuent d’utiliser des corpus annotés1. Le 
système que nous avons développé n’utilise pas de corpus annoté et aucun lexique préalable 
pour effectuer l’analyse syntaxique. L’intérêt de ce projet se trouve dans la conception de 
                                                   
1. L’annotation consiste en deux types d’informations : les informations externes, qui sont relatives à la production 
du texte (lieu, date, type d’enregistrement, méthode de retranscription etc.) et qui peuvent être utilisées pour des 
études diachroniques ou sociolinguistiques. Et les informations internes, qui portent sur une description 
linguistique des éléments du discours (la segmentation et l’étiquetage des unités, leurs caractéristiques 
sémantiques ou syntaxiques, etc.), et qui servent à l’étude empirique des régularités de la langue. 
Introduction  17 
START 2003 
l’algorithme qui permet la reconnaissance automatique des parties du discours et la 
détermination de leur étendue dans un grand corpus non annoté de textes français, d’auteurs 
et de styles très variés. 
Notre système fait émerger des structures syntaxiques très variées à partir d’un minimum de 
règles, le moins possible (selon le cas nous aboutirons à une vingtaine ou à une trentaine de 
règles) et sans connaissance préalable. Le système se situe dans la dernière lignée des 
travaux de l’analyse syntaxique et de l’étiquetage et ses performances en font un outil 
précieux pour tout traitement linguistique ultérieur. Nous nous sommes intéressés à cette 
étude dans l’objectif d’obtenir des informations (des connaissances) nécessaires pour 
avancer dans le domaine de la représentation naturelle des connaissances. 
Comme ni la syntaxe ni le sens que donne la syntaxe ne peuvent être réduits à ce qui relève 
des catégorisations, nous espérons que cette étude sera une contribution à la recherche 
générale des modèles linguistiques pour le traitement automatique du langage naturel dans 
le cadre de l’intelligence artificielle1.  
Afin de définir les différents groupes comme par exemple le groupe nominal qui joue des 
rôles tellement différents dans la phrase, (soit sujet, soit complément d’objet direct (COD), 
soit complément d’objet indirect (COIND) précédé d’une préposition, soit en groupe 
prépositionnel qui montre le temps (ou la durée), le mouvement, etc., ) ainsi que leur nature, 
il faudra étudier leur comportement syntaxique et sémantique, car la syntaxe et la 
sémantique sont liées, dans la mesure où la syntaxe impose des catégorisations du réel dans 
le domaine des désignations ainsi que dans celui des relations. Ces catégorisations relèvent 
de ce que Cl. Hagège appelle la sémantique de la syntaxe [Hagège 1985]. L’analyse doit 
d’abord commencer par les phénomènes syntaxiques, car la sémantique de la syntaxe 
fournit, en dernier ressort, la seule possibilité d’interprétation de l’organisation des énoncés. 
                                                   
1. Les rapports de la linguistique avec l’IA sont subordonnés à ses rapports avec l’informatique. 
18  Introduction 
START 2003 
Dans cette étude nous espérons donner des notions essentielles sur la nature et le 
comportement des parties du discours que nous analysons. Sans faire la division entre 
sémantique et syntaxe, [Rastier 1991]1, nous voulons montrer et comprendre les 
caractéristiques – de distribution et d’appartenance – propres à chaque lexème grammatical 
afin de créer un processus de reconnaissance sans recours à l’étiquetage traditionnel ou à 
d’énormes bases de données d’entrées lexicales. 
Tout en gardant présentes à l’esprit les exigences de la méthode distributionnelle, nous 
aurons constamment recours au sens, non seulement pour identifier des énoncés, mais aussi 
pour établir des règles de comportement syntaxique, persuadés que le fonctionnement d’un 
signe [Saussure 1960] ne peut être distingué de son signifié. On peut se poser la question : 
qu’est-ce qui relève, dans le sens d’un énoncé, des informations syntaxiques et sémantiques 
stockées avec l’appartenance de ses différents constituants à telle ou telle partie du 
discours ? La nature des constituants détermine largement la structure des énoncés, mais le 
choix d’un certain type de mots n’a pas seulement des conséquences sur la syntaxe de 
l’énoncé, il contribue aussi à la communication du sens. Syntaxe et sémantique sont liées : 
la syntaxe met en place les catégorisations du réel aussi bien au niveau des désignations que 
dans celui des relations ou dans celui des formulations, ces catégorisations relèvent de ce 
que Cl. Hagège appelle sémantique de la syntaxe. 
La reconnaissance des parties du discours rentre dans une problématique beaucoup plus 
étendue ; jusqu’où l’expression de sens peut-elle se distribuer à travers la forme ? Dans le 
                                                   
1. Dans le parcours interprétatif comme dans le parcours génératif, les structures syntaxiques sont premières et 
reçoivent une interprétation sémantique. Trois questions relèvent de cette thèse : -est-il possible de faire une 
analyse syntaxique sans recourir à des considérations sémantiques ? - est-il possible de faire une analyse 
sémantique sans recourir à des considérations syntaxiques ? - et sinon, à quel degré l’analyse syntaxique est-elle 
nécessaire ? Les meilleurs analyseurs (parsers) d’aujourd’hui utilisent des critères syntaxiques et sémantiques à 
chaque étape du traitement sans recourir à des modules syntaxiques distincts. Selon F. RASTIER : on met, très 
sainement, en cause la tripartition proposée par Morris entre syntaxe, sémantique et pragmatique, qui a été 
reprise d’ailleurs par tous les courants de la linguistique formelle, car ce qui divise principalement l’opinion en 
IA, pour ce qui concerne l’interprétation du langage naturel, c’est de savoir si cette partition est ou non 
approximativement correcte, c'est-à-dire si la division du processus d’interprétation en ces trois étapes est le bon 
point de départ.  
Introduction  19 
START 2003 
cas présent, qu’est-ce qui révèle, dans le sens d’un syntagme, des informations syntaxiques 
et sémantiques stockées avec l’appartenance de ses différents constituants à tel ou tel 
groupe ? 
On doit, donc, partir pour notre analyse, de définitions syntaxiques ; il n’est pas possible de 
s’appuyer sur des définitions sémantiques pour distinguer les parties du discours. La 
distribution des parties du discours n’en détermine pas moins un certain découpage du réel, 
qui constitue un premier aspect de la sémantique de la syntaxe. 
Pour la réalisation de ce projet dans le cadre linguistique, nous utilisons principalement 
l’analyse distributionnelle des mots grammaticaux qui jouent le rôle d’outils dans la phrase. 
Le comportement distributionnel d’un élément est estimé par son comportement dans un 
grand corpus. La vérification du contexte est basée sur l’analyse distributionnelle des parties 
du discours en général, ainsi que des déterminants pour traiter les substantifs et des pronoms 
pour traiter les verbes. La méthode distributionnaliste nous permet d’évaluer la présence et 
les occurrences des mots grammaticaux qui composent le noyau des règles. Ces petits 
éléments qui ne sont pas porteurs de sens par eux-mêmes, sont indispensables pour assurer 
la grammaticalité et la sémantique d’une phrase. Pour déterminer l’étendue des parties du 
discours, nous nous sommes principalement basés sur la grammaire traditionnelle, qui 
fournit une liste exhaustive des différents emplois des mots grammaticaux et de l’ensemble 
de leur contexte. 
Cette liste exhaustive nous a permis d’effectuer différentes requêtes concernant la place et 
la combinaison des mots grammaticaux dans les textes. Les statistiques nous ont fourni les 
pourcentages de leur différentes fonctions dans différents contextes, et nous avons pu 
ensuite évaluer les occurrences de chaque lexème afin de créer les règles de reconnaissance 
des Parties du discours. 
Contrairement aux méthodes actuelles qui ont recours à des entrées lexicales nous avons 
créé un analyseur syntaxique sans dictionnaire préalable et sans aucune connaissance 
morphologique sur le corpus. Suite à l’analyse de la reconnaissance, le programme permet 
20  Introduction 
START 2003 
la création d’un dictionnaire avec les entrées lexicales qu’il récupère après le traitement et 
qu’il étiquette avec les types grammaticaux de : nom, verbe, participe, ou adverbe. 
 
 
 
 
 
 
 
 
Chapitre I 
 
 
PROBLEMATIQUE 
22  Chapitre I : Problématique 
START 2003 
Sommaire du Chapitre I 
 
PROBLEMATIQUE 
 
1.1 La grammaire 
1.2. La syntaxe 
1.3. Les parties du discours 
1.4. Les mots grammaticaux 
1.5. Relation entre forme et sens 
 
Chapitre I : Problématique  23 
START 2003 
 
Dans ce chapitre nous évoquerons le problème de la définition et de la distribution de 
différents groupes syntaxiques, qui sont d’une grande conséquence pour la structure des 
systèmes syntaxiques. Pour cela nous exposerons brièvement l’aspect général de la langue 
comme un processus cognitif mettant en œuvre plusieurs connaissances de sources variées 
et son approche en IA au niveau du traitement automatique du langage naturel. Nous 
décrivons ensuite les caractéristiques des mots grammaticaux afin de mieux construire 
l’ensemble des règles du système. Par la suite, nous établirons le cadre général, dont notre 
recherche sur la reconnaissance automatique superficielle des parties du discours, fait partie 
et qui est celui de l’automatisation du processus de la compréhension. Nous exposerons un 
schéma général qui permet la coopération efficace des différentes sources de connaissances 
dans tout domaine d’application. Nous commençons par la grammaire qui est la base de la 
syntaxe et qui nous permet de savoir ce que l’on peut accepter des résultats des règles 
appliquées de notre système d’analyse. L’énumération des idées, méthodes et courants de la 
pensée langagière nous permet de mesurer la richesse des propositions offertes à la 
réflexion. 
Les travaux sur la grammaire française consacrés à la structure du GN ou du GV ces 
quarante dernières années pourraient remplir plusieurs volumes de littérature linguistique. 
Nous nous contenterons d’évoquer uniquement les lignes théoriques qui nous ont permis de 
dégager les règles qui forment notre algorithme, en passant par la tradition scolaire, 
l’influence distributionnaliste et structuraliste, ainsi que le compromis fonctionnaliste 
[Wilmet 1986]. 
La tradition scolaire [Grevisse 1980] quant au GN, isole les catégories du substantif, de 
l’article et de l’adjectif. Les adjectifs se partagent en a) qualitatifs et b) déterminatifs qui se 
subdivisent en 1) numéraux, 2) possessifs, 3) démonstratifs, 4) relatifs, 5) interrogatifs-
exclamatifs et 6) indéfinis. C’est cette représentation (avec quelques variantes) que l’on 
trouve dans la plupart des manuels et traités descriptifs. Jusqu’à présent les rapports des 
deux parties du discours l’adjectif et le nom sont traités comme des rapports de parties 
24  Chapitre I : Problématique 
START 2003 
voisines mais pourtant différentes l’une de l’autre. Pour les GV l’étude des pronoms et 
éventuellement les connaissances obtenues à partir des GN nous amène à étiqueter avec 
exactitude les mots du type verbal ainsi que ceux du type nominal. 
1.1 La grammaire 
1.1.1 Au fil de l’histoire 
Nous évoquerons ici en quelques lignes les grands traits de l’histoire de la pensée humaine 
sur le langage, afin de situer les racines de la grammaire et de la syntaxe actuelles [Denis et 
Sancier-France 1994]. Sans prétendre être exhaustifs nous montrerons les réflexions 
humaines sur le langage et la formalisation de celles-ci. 
L’homme s’exprime par le moyen du langage, dont nous distinguons trois sortes : le 
langage parlé, le langage écrit et le langage mimique. Selon le Bon Usage de M. Grevisse, 
«  c’est par phrases que nous pensons et que nous parlons ; la phrase est un assemblage 
logiquement et grammaticalement organisé en vue d’exprimer un sens complet : elle est la 
véritable unité linguistique » [Grevisse 1975]. 
Les textes anciens tels que le Cratyle de Platon où l’on trouve une conception dite naturelle 
du langage ou la Logique d’Aristote avec une conception conventionnelle du langage, ou 
encore le stoïcien Diogène de Laërte, qui pose les bases fermes de l’analyse grammaticale 
après avoir formulé une théorie précise du signe, nous offrent, outre des réflexions 
grammaticales et métaphysiques sur le langage, des idées sur la matérialité de ce langage 
ainsi que sur ses fonctions pour la communication. La réflexion se formalise dans 
l’Antiquité grecque : celle-ci pose les bases d’une conception de l’analyse de la langue dite 
traditionnelle, parce qu’elle est fondée sur le sens et la logique. Le langage étant le reflet 
d’un aspect philosophique nous aboutissons à la perception plus complexe qui surgit entre 
les rapports des mots et du monde. 
Ce sera la pensée stoïcienne  qui posera les bases de l’analyse grammaticale. Pour les 
stoïciens le langage n’est pas le reflet d’une réalité préétablie [Mounin 1967]. Le langage ne 
Chapitre I : Problématique  25 
START 2003 
reproduit pas une image structurée, il la produit. La langue devient alors l’objet d’une 
description scientifique. On s’intéresse aux seuls constituants de la chaîne discursive : de 
l’unité minimale (syllabe) entrant dans la formation du lexis (mot) aux différentes unités ou 
parties du discours. C’est aux stoïciens que l’on doit l’examen le plus complet des parties 
du discours et des fonctions grammaticales. Ils distinguent alors la catégorie du nom divisée 
en noms propres et noms communs, la catégorie du verbe qui a une relation avec le nom et 
qui exprime le temps comme l’aspect – opposant le durant à l’achevé, les conjonctions, les 
pronoms, catégorie où l’on trouvera l’article également. 
Ainsi naît la grammaire. Denys de Thrace, le grammairien le plus connu de l’école 
d’Alexandrie, dans son ouvrage Système Grammatical, décrit empiriquement et 
méthodiquement les faits de langue, en dehors de toute théorie philosophique. Car le 
grammairien se doit de découvrir les règles grammaticales de sa langue en regroupant les 
faits identiques (recherches des analogies). Il répartit alors les mots en classes, ces 
catégories demeurent jusqu’à nos jours : nom, verbe, participe, article, pronom, préposition, 
adverbe, conjonction. L’opposition entre le mot (lexis) et la proposition (logos) est abordée, 
mais ce sera Apollonios Dyscole qui développera ces notions en une syntaxe où l’on trouve 
l’analyse du système des cas, distinction entre pronoms déictiques et pronoms 
anaphoriques, définition de la coordination. 
Les grammairiens latins appuient leur réflexion sur cet acquis théorique et méthodologique, 
et s’appliquent à faire inscrire les faits de langue spécifiques au latin dans le cadre des 
théories et classifications grecques. Nous mentionnons uniquement Saint Augustin qui dans 
son dialogue De magistro souligne l’importance des contextes dans la compréhension de 
l’énoncé et marque les difficultés de la communication du sens dans tout échange humain. 
Les premières grammaires françaises font leur apparition au début du XVIe siècle1 mais ce 
n’est qu’un siècle plus tard que la Grammaire Générale de Port Royal fait son apparition et 
son impact n’est sensible qu’au XVIIIe siècle. Cette grammaire place les mots dans la 
                                                   
1. Par exemple nous trouvons « l’Eclaircissement de la Langue Française » de l’Anglais Palsgrave en 1530, qui 
propose cet ouvrage à ses compatriotes pour mieux maîtriser le français.  
26  Chapitre I : Problématique 
START 2003 
proposition, unité profonde où ils s’associent. Le verbe est conçu comme le pivot de cette 
unité appelée proposition : il permet de la déterminer. Autour de lui s’organisent 
hiérarchiquement les éléments du discours. Le nom et le verbe n’ont plus rangs égaux : 
c’est ici la rupture avec la tradition aristotélicienne. Mais l’analyse des cas reste moins 
novatrice : elle consiste en l’étude de la place des mots et le relevé de leur marque. 
Au XIXe siècle s’ouvre une autre conception de l’étude des langues : l’hypothèse de l’indo-
européen. Cette mutation épistémologique donnera naissance à une véritable science 
linguistique avec des précurseurs en France et au Danemark. C’est le linguiste allemand 
Frantz Bopp1 qui formule l’hypothèse fondamentale du changement des langues : 
identiques à l’origine, elles auraient subi des modifications, accessibles à une description 
rigoureuse. C’est le siècle qui permet un immense progrès des connaissances, et la langue 
rigoureusement saisie dans sa dimension temporelle et spatiale, décrite selon les principes 
objectifs, peut être comprise comme un système organisé de signes, c’est-à-dire une 
structure. 
Le XXe siècle s’ouvre sur une nouvelle mutation épistémologique où le mouvement 
structuraliste connaît un développement parallèle en Europe et aux Etats-Unis. F. de 
Saussure dans son ouvrage Cours de Linguistique Générale pose les principales thèses du 
structuralisme et affirme la nécessité d’une science générale du langage, à la recherche des 
universaux, ayant la conception de la langue comme système. Outre Atlantique la 
linguistique américaine est souvent décrite comme une ligne continue partant du 
distributionnalisme de L. Bloomfield [Bloomfield 1933], à la grammaire générative de N. 
Chomsky – pour qui la grammaire d’une langue quelconque peut être conçue comme un 
système de règles qui fait correspondre une représentation sémantique et une représentation 
phonétique des phrases de cette langue [Chomsky 1971] – en passant par le 
                                                   
1. Selon L. Tesnière et les historiens des idées, F. Bopp n’a jamais dépassé le niveau d’un bon technicien spécialisé 
(en grammaire comparée), et c’est Guillaume de Humboldt, « esprit universel hautement cultivé armé d’une 
culture scientifique approfondie », qui mérite le titre de linguiste mais que l’histoire de la pensée allemande ne 
mentionne souvent même pas. (cf. J. Vendryes, La comparaison en linguistique, Bulletin de la Société de 
Linguistique de Paris, 42, tome 1, p.7). 
Chapitre I : Problématique  27 
START 2003 
transformationnalisme de Z.S. Harris [Harris 1962]. Les réels progrès que les méthodes 
américaines ont apporté dans la compréhension des faits de langue, ne restent pas sans 
nuances. Le refus de toute théorisation générale prive la linguistique d’une véritable 
syntaxe, d’une conception d’ensemble de la phrase et des relations fonctionnelles entre 
constituants à l’intérieur de ce cadre : la méthode, purement analytique ne permet pas la 
synthèse. La langue désormais n’est que l’occasion d’élaborer une description technique, 
formalisée, calculable et donc mathématiquement opératoire. En France, les travaux de M. 
Gross s’inscrivent dans ce projet de la description neutre et empirique de la langue à l’aide 
des méthodes de distribution et de transformation [Gross 1975]. 
A partir des années 1960 une nouvelle idée émerge, celle d’une vision dynamique du fait 
linguistique. Deux tendances voient le jour : le formalisme (issu des méthodes du 
structuralisme américain) et le courant sémantico-pragmatique dont l’objet d’étude est 
l’activité concrète de parole plutôt que l’analyse des structures abstraites de la langue. Le 
courant sémantique avec B. Pottier remet en question la signification et la représentation du 
monde et le courant pragmatique qui est attaché à replacer le langage dans les circonstances 
concrètes1 de l’énonciation dont l’œuvre pionner de A. Culioli est le représentant. Les 
linguistes s’intéressent aussi aux interactions verbales effectives caractéristique du 
fonctionnement communicatif du langage : on parle alors d’analyse conversationnelle. 
Après cette brève énumération des idées, méthodes et courants de la pensée langagière nous 
pouvons mesurer la richesse des propositions offertes à la réflexion. L’hétérogénéité des 
points de vue offrent plusieurs positions et tendances dans les grammaires actuelles. La 
description grammaticale se détache de la pensée logique et métaphysique, et intègre la 
composante sémantique, pour replacer la grammaire dans le cadre plus large de la 
linguistique, en prenant en compte la dimension dynamique du langage. 
                                                   
1. Les linguistes s’intéressent aux diverses réalisations discursives en posant la question de savoir ce qui se passe 
réellement dans l’interaction verbale : la théorie des actes de langage, élaborée par les Anglais J.L. Austin et J. 
Searle, distingue plusieurs types d’actes réalisés dans et par le discours, et elle décrit les effets pragmatiques. Les 
questions sur l’implicite et l’inférence sont au cœur de réflexion. 
28  Chapitre I : Problématique 
START 2003 
1.2. La syntaxe 
Que nous soyons auditeur ou lecteur, la langue se présente à nous comme une suite de 
signes dans laquelle nous découpons des éléments significatifs en nous aidant des formes et 
du sens. L’analyse linguistique a comme départ l’étude des phénomènes syntaxiques. Selon 
A. Lemaréchal : 
« syntaxe et sémantique sont liées : la syntaxe des différentes langues impose des 
catégorisations du réel aussi bien dans le domaine des « désignations » que dans celui 
des « relations » ou dans celui des « formulations ».(p. 29) [Lemaréchal 1989]. 
La syntaxe est l’ensemble des règles qui régissent l’arrangement des mots et la construction 
des propositions1, (ou phrases)2. L’objet de la syntaxe est l’étude de la phrase. Et, selon L. 
Tesnière, les linguistes allemands ont trouvé le meilleur équivalent pour syntaxe dans 
Salzlehre, « science de la phrase » [Tesnière 1959]. La phrase est un ensemble organisé 
dont les éléments constituants sont les mots. Selon la syntaxe structurale : 
‘Construire une phrase, c’est mettre la vie dans une masse amorphe de mots en 
établissant entre eux un ensemble de connexions.’ 
‘Comprendre une phrase, c’est saisir l’ensemble des connexions qui en utilisent les 
différents mots.’ 
Nous exposerons brièvement quelques principes de l’œuvre de L. Tesnière car nous 
trouverons tout au long des exposés sur l’analyse syntaxique des notions que sa syntaxe 
structurale a introduites. L’étude de la phrase qui est l’objet de la syntaxe structurale est 
essentiellement l’étude de sa structure c’est-à-dire la hiérarchie de ses connexions. Et 
puisque l’on parle de hiérarchie, le trait de connexion sera vertical puisqu’il symbolise le 
lien entre un terme supérieur et un terme inférieur. Tout ce qui commande plusieurs 
subordonnés est un nœud, et l’ensemble des traits de connexion constitue le stemma. 
                                                   
1. GREVISSE M. Le bon usage (10e édition), éd. Duculot, France, 1975. 
2. Les grammairiens ont souvent voulu éclairer la notion de phrase en lui substituant le terme de proposition, 
emprunté à la logique. 
Chapitre I : Problématique  29 
START 2003 
Les exemples qui suivent sont une matérialisation visuelle de la structure de la phrase. Pour 
le stemma 1 nous avons « mon ami parle » et le stemma 2 représente la phrase « mon vieil 
ami chante cette chanson ». Le stemma 3 est un stemma virtuel identique au stemma 2. 
 
 
 
 
 
Stemma 1 Stemma 2 Stemma 3 
 
O = substantif, A = adjectif, 
E = adverbe, I = verbe. 
Figure 1 :   Visualisation des connexions et des nœuds dans la phrase.  
L’œuvre de L. Tesnière (mentionné plus haut) se situe à l’intersection de la syntagmatique 
et la sémantique. Le centre de sa pensée syntaxique est la notion de classes des mots. Il ne 
s’agit pas ici des parties du discours au sens ancien, considérées comme des espèces 
identifiables par l’observateur de leurs formes, mais par exemple du fait que donner une 
information sur un événement à l’aide, d’un verbe, ou de groupes à fonction substantivale 
(sujet, objet) et adverbiale (temps, lieu), implique une première activité conceptuelle, avec 
des idées de procès, de participant actif et non-actif du procès, de circonstance de l’action. 
Parmi les rapports dont s’occupe la syntaxe ceux qui concernent l’accord ont une 
importance particulière. Les règles d’accord sont fondées sur la logique et découlent 
nécessairement des relations créées par l’esprit entre les choses. 
parle 
mon 
ami 
chante
ami 
mon vieil 
chanson 
cette 
I
O 
A A 
O 
A 
30  Chapitre I : Problématique 
START 2003 
1.3. Les parties du discours 
La distribution des parties du discours varie largement d’une langue à l’autre et ces 
différences sont d’une grande conséquence pour la structure des systèmes syntaxiques 
[Lemaréchal 1989]. Le problème est la définition des parties du discours, comment repérer 
des « parties du discours » ou comme préfèrent dire les guillaumiens des « parties de la 
langue » : on peut le concevoir soit comme un problème « extérieur » aux relations entre les 
signifiants et leurs signifiés, soit comme un problème « intérieur » du rôle des différentes 
classes de signes dans la phrase. L’orientation d’un terme est une caractéristique attachée à 
la sous-classe à laquelle il appartient et qui fait que, pour chaque constituant en relation 
avec lui, un certain rôle dans la situation réelle (comme agent, patient, destinataire, 
bénéficiaire, causateur, etc.) est associé à un certain rang dans la hiérarchisation de l’énoncé 
(sujet premier actant, second actant, etc., circonstant). 
La notion de partie du discours ou classe de mots doit satisfaire aux paramètres des trois 
plans dont relève un mot : le plan notionnel (ou sémantico- référentiel) qui propose un 
classement selon les contenus, le plan fonctionnel et enfin le plan formel défini par la 
conjonction de marques morphosyntaxiques. Mais à chaque plan apparaissent des 
contradictions internes. Sous le terme de nom sont regroupés des éléments dont la définition 
va de la désignation d’une entité (le nom propre) à la prédication (les noms d’agent, par 
exemple). La notion de classe est dotée d’une double ambiguïté [Boisson et al. 1994]. Elle 
peut être conçue soit à la manière des anciens (point de vue syntagmatique ou fonctionnel) à 
partir d’un découpage de la phrase en ses parties, soit à la manière de « parties de la 
langue » des guillaumiens, à partir d’un classement des notions exprimées dans une langue 
donnée, ou nécessairement exprimables dans toute langue humaine (le point de vue 
paradigmatique ou sémantique).  
Chapitre I : Problématique  31 
START 2003 
 Parties de phrase (µέρη του λόγου) 
 Fléchies (κλιτικά) 
Appellation F.. Nom
όνοµα 
2. Verbe 
ρήµα 
3. Participe 
µετοχή 
4. Article 
άρθρο 
Définition 
(dans Technê de 
Denys de Thrace) 
Le nom est une 
partie de phrase 
casuelle désignant 
un corps ou une 
action, et qui 
s’emploie avec 
valeur commune ou 
particulière. 
Le verbe est un mot 
non casuel, qui 
admet temps, 
personnes et 
nombres, et qui 
exprime l’actif ou 
le passif. 
Le participe est un 
mot qui participe 
de la propriété des 
verbes et de celle 
des mots. 
L’article est une 
partie de phrase 
casuelle préposée 
ou postposée à la 
flexion des noms. 
 Non fléchies (άκλιτα) 
Appellation 5. Pronom 
αντωνυµία 
6. Préposition 
πρόθεση 
7. Adverbe 
επίρρηµα 
8. Conjonction 
σύνδεσµος 
Définition 
(dans Technê de 
Denys de Thrace) 
Le pronom est un 
mot employé en 
place d’un nom, et 
qui indique des 
personnes définies. 
La préposition est 
un mot qui se 
prépose à toutes les 
parties de phrase, 
en composition et 
en construction. 
L’adverbe est une 
partie de phrase 
non fléchie, dite du 
verbe ou appliqué 
au verbe. 
La conjonction est 
un mot qui conjoint 
la pensée en 
ordonnant, et qui 
révèle l’implication 
de l’expression. 
Tableau 1 :  Les parties de la phrase définies par Denys de Thrace 
Pour distinguer les parties du discours d’une langue, il suffit d’établir un nombre de critères 
discriminatoires (généralement combinatoires) minimum. Mais pour les définir il faudra 
décrire la totalité de leurs caractéristiques morphologiques et syntaxiques, et donner 
l’ensemble des contraintes distributionnelles qui les caractérisent. 
32  Chapitre I : Problématique 
START 2003 
1.3.1. Définition et détermination des GN et GV 
Un groupe (ou syntagme) est un ensemble des mots formant une unité à l’intérieur de la 
phrase. Pour F. de Saussure le syntagme se compose toujours de deux ou plusieurs unités 
consécutives, par exemple re-lire, contre tous, s’il fait beau, etc. 
Tableau 2 : Exemples des Groupes Nominaux, utilisation de « de ». 
Nous avons mentionné précédemment que pour définir un groupe il faut décrire en totalité 
ses caractéristiques morphologiques et syntaxiques. On se rend compte de la complexité du 
problème quand on essaie de suivre la même démarche pour décrire la totalité des 
caractéristiques morphologiques et syntaxiques des GN par exemple. On rencontre déjà 
beaucoup de difficultés pour répondre à la simple question de la définition d’un groupe 
nominal. Y a-t-il des régularités dans un groupe nominal qui permettent d’établir une règle 
de reconnaissance ? Comment peut-on construire des procédures formelles qui reflètent, 
plus ou moins bien, la structure et le fonctionnement d’un syntagme nominal ? Il est 
difficile d’y répondre quand on sait que l’étendue d’un groupe nominal peut varier selon la 
nature du texte ou de l’énoncé. 
1.3.1.1. Le nom et le verbe 
Le nom ne se distingue pas des autres mots analysés par la grammaire comme parties du 
discours grâce à ses propriétés sémantiques mais grâce à un ensemble de particularités 
morphologiques et syntaxiques. Une même notion peut être exprimée par un nom (le 
voyage) ou par un verbe (voyager). Le nom exprime une substance plus ou moins concrète, 
quand le verbe évoque l’action. On peut dire que le nom peut signifier la même chose 
qu’une autre partie du discours mais il le fait différemment. Les propriétés 
morphosyntaxiques des noms sont les suivantes : 
développem ent de relations am icales entre nations , 
peuples de N ations U nies ont proclam é à 
instaurer de m eilleures conditions de vie dans 
 
Chapitre I : Problématique  33 
START 2003 
- ils assument des fonctions principales dans la proposition (sujet, objet, attribut), 
- ils sont indépendants quant à leur genre, le déterminant permet de préciser le 
nombre qu’évoque « ce qui est désigné par le nom », 
- ils nécessitent la présence des déterminants à l’exception du nom propre (ceci n’est 
pas le cas de la langue grecque, où l’emploie des déterminants s’étend aux noms 
propres). 
Le verbe est l’une des parties du discours les plus importantes. Il joue un rôle fondamental 
car il réunit des mots ou des groupes de mots (verbes au sens strict comme manger ou 
locutions verbales comme avoir faim) dotés de caractéristiques particulières. Quant à sa 
morphologie le verbe est un mot variable. Le verbe change de forme lorsqu’on l’utilise à un 
mode conjugué. Il porte les marques du mode, du temps, de la personne et du nombre. Il est 
parfois non conjugué, comme dans le cas de l’infinitif (dans ce cas, il peut servir comme 
équivalent d’un nom). Quant à la syntaxe le verbe joue un rôle central à l’intérieur de la 
phrase dont il relie les divers éléments. Pour la syntaxe structurale le verbe est le nœud de la 
proposition. 
1.3.1.2. Distinction entre nom et substantif 
Selon L. Tesnière la distinction entre nom et substantif est une opposition entre 
morphologie et syntaxe [Tesnière 1959]. Pour A. Lemaréchal l’opposition s’effectue au 
niveau des parties du discours, correspondant aussi bien à des faits de syntaxe qu’à des faits 
sémantiques [Lemaréchal 1989]. Le substantif est souvent utilisé comme adjectif, on 
‘substantivise’ l’adjectif, il s’agit en effet d’un nombre important de vocables dont on hésite 
à affirmer qu’ils sont plutôt adjectifs ou plutôt substantifs. La tradition scolastique, et avec 
elle la conscience linguistique, réunissent d’ailleurs les deux sous la catégorie du nom, ce 
qui s’est perpétué, même si selon [Blanche-Benveniste et Chervel 1966], on n’ose plus, en 
général, s’avouer que le substantif c’est la substance et l’adjectif la qualité. 
On appellera substance la désignation d’un objet individualisé du monde réel, au sens de la 
logique traditionnelle. Les limites entre les deux catégories (adjectif – substantif) ne sont 
pas aussi tranchées qu’entre nom et verbe ou adjectif et adverbe, par exemple, et il reste 
34  Chapitre I : Problématique 
START 2003 
commode de substituer sous l’ancien terme générique de nom le substantif et l’adjectif, 
étant donné qu’au sein du constituant de l’énoncé ils ne s’opposent que comme déterminé et 
déterminant, un même mot pouvant être tantôt adjectif, tantôt substantif : un jaune crème, 
une crème jaune. 
Le groupe nominal (ou syntagme substantif) peut occuper les fonctions de sujet (le grand 
champion a encore gagné), de complément (j’aime les choses simples), ou d’attribut (Louis 
XIV était un roi de France). 
Si l’on part des fonctions on doit renoncer au classement en deux groupes distincts les noms 
déterminants et les noms déterminés. 
Si l’on part des signifiés on procède plutôt à un classement intuitif fondé sur la distinction 
substance / qualité ; mais dans aucune des deux classes on ne parvient à décrire des 
comportements syntaxiques, même si l’on a limité son observation aux fonctions 
généralement reconnues pour la classe, par exemple sujet ou complément d’objet direct 
pour le groupe nominal. 
Le nom (ou substantif) a toujours un genre en français ; le genre est donné par le 
dictionnaire. Le nom peut varier en nombre de manière visible (les enfants, les généraux, les 
femmes ...). Le nom est la composante minimale d’un groupe minimal. Il peut entrer dans 
un groupe comportant : un ou plusieurs déterminants, qui donnent des précisions sur le 
niveau de connaissance de celui/celle qui parle sur le nom. Le déterminant s’accorde avec le 
nom qu’il accompagne. 
Chapitre I : Problématique  35 
START 2003 
1.3.2. Les adjectifs (épithètes) 
La difficulté de la définition et détermination d’un groupe nominal est due en partie à la 
place qu’occupe l’adjectif. Nous exposerons brièvement les caractéristiques de ceux que les 
grammairiens appellent qualitatifs afin de pouvoir déterminer un groupe nominal en sa 
totalité. Nous donnons quelques définitions prises au hasard parmi les plus récentes  sur le 
terme épithète dans un sens très formel : « l’épithète se joint à un nom propre ou commun, 
avant ou après lui, dans une structure liée directe » [Noailly 1990]. Une autre définition : 
« Aucune virgule ne la sépare de son support, ce qui la distingue de l’apposition. Aucun 
verbe n’intervient pour assurer une liaison avec le support, ce qui l’oppose à l’attribut du 
sujet comme de l’objet ». 
Un ou plusieurs adjectifs peuvent facultativement s’ajouter au nom [Bernard 1988], et 
s’accordent aussi avec lui, en genre et en nombre. L’adjectif peut être épithète, soit 
directement attaché au nom (un grand homme, une table basse) ou attribut, c’est-à-dire mis 
en relation avec le nom qu’il qualifie par un verbe d’état (cette dame est restée seule).  
Pour la plupart des auteurs la place de l’épithète est une question d’habitude. Selon G. 
Bernard, seule l’hypothèse, selon laquelle le nom comme l’épithète ont des valeurs 
syntaxiques distinctes et reposent sur des fonctions propres comme par exemple les 
constructions sujet-verbe ou verbe-objet, est valable : chaque position de l’épithète marque 
une fonction distincte, définissant deux catégories d’épithète (EG et ED) [Bernard 1988]. 
L’inversion est due au changement de catégorie d’épithète ou transposition selon C. Bally 
[Bally 1950]1. Donc, le rapport de ‘un nouveau jouet’ et ‘un jouet nouveau’, est dans cette 
                                                   
1. Nous exposons les hypothèses de Bally sur la transposition : « tout transposé est un syntagme dont le déterminé 
est le transpositeur et le déterminant le transponend. La contre-partie de cette règle se formule ainsi : est transposé 
tout déterminant de syntagme dont la catégorie n’est pas complémentaire de celle du déterminé. Or le principe de 
complémentarité est que : un adjectif et un verbe sont prédestinés à déterminer un substantif, qu’un adverbe est 
prédestiné à déterminer un adjectif ou un verbe ». (Linguistique Générale et Linguistique Française, p. 121). 
1  Chapitre I : Problématique 
START 2003 
analyse, un rapport de dérivation fonctionnellement semblable à celui qui existe entre 
homme et humain, marqué formellement par le changement de position. 
Concernant les fonctions des épithètes la thèse soutenue par G. Bernard est donc qu’il y a 
deux catégories de détermination : le repérage, qui singularise l’instance et la spécification 
qui spécialise la substance. A gauche on trouve les repères de l’instance ; à droite les 
spécifiants de la substance. Nous citons la conclusion de cette analyse qui est que le SS se 
décompose en deux parties : 
« l’une, contenant les déterminations singulières, enchâsse l’autre, contenant les 
déterminations notionnelles : [le petit [livre rouge] du Président Mao]. Le noyau 
notionnel contient le substantif, les ED notionnels, les compléments notionnels 
(couteau de boucher, livre de géographie) ». [Bernard 1998] 
 
Repérant EG Substantif Cpl. Not. ED not. ED sing. Ci/là même Cpl. Sing Participe Relative 
Le tableau qu’il utilise (ci-dessus) schématise l’ordre des mots dans un syntagme substantif. 
Nous allons présenter par la suite les mots grammaticaux qui sont les mots-clés ou les mots 
qui forment le noyau de l’ensemble de règles du système. Leurs caractéristiques nous ont 
permis de définir leur contexte. Nous donnons une brève description de leur fonction. 
1.4. Les mots grammaticaux 
1.4.1. Les déterminants 
Notre étude sur la détermination des groupes syntaxiques met en évidence les 
caractéristiques de l’appartenance et de la distribution des mots grammaticaux ainsi que 
celle des lexèmes qui les entourent (voisinage proche). La définition d’un syntagme 
engendre la détermination de son étendue. Nous donnons la liste des marques 
grammaticales utilisées pour la définition d’un groupe nominal : 
Partition Prép 
Chapitre I : Problématique  37 
START 2003 
Article défini  le, la, l’, les, au, aux 
Article indéfini  un, une, des 
Article partitif  du, de l’, de la 
Adjectif possessif  mon, ton, son, ma, ta, sa, notre, votre, 
leur, mes, tes, ses, nos, vos, leurs 
Pronom démonstratif  ce, cet, cette, ces 
Pronom interrogatif  quel, quelle, quels, quelles 
Adjectif indéfini  quelqu’, quelque, quelques 
Adjectif  certain, certaine, certains, certaines 
Adjectif  nul, nulle, aucun, aucune 
Pronom indéfini  chaque 
Adjectif  plusieurs 
Tableau 3 : Les déterminants 
Il faudrait éventuellement avant de citer les déterminants, préciser la frontière entre 
déterminants et épithète gauche (EG). Il y a deux positions concernant les déterminants : 
1. celle de G. Bernard, pour qui les déterminants se réduisent à la liste que nous 
évoquerons plus loin dans ce même paragraphe, et d’où les numéraux – cardinaux 
sont absents, et pour qui dans « deux hommes », nous avons un syntagme substantif 
sans déterminant [Bernard 1998]. 
2. et celle soutenue par beaucoup d’auteurs comme M. Forsgren, où dans « deux 
hommes », deux est un déterminant et non dans « les deux hommes » [Forsgren 
1978]. 
Pour ce dernier, il y aurait donc deux catégories de déterminants : 
a. des déterminants grammaticaux : articles, démonstratifs, possessifs et interrogatifs, 
appartenant à un paradigme fermé, qui ne peuvent être précédés d’un déterminant et 
ne sont jamais EG ; 
38  Chapitre I : Problématique 
START 2003 
b. des lexèmes (surtout cardinaux) qui peuvent être déterminants ou EG, pouvant être 
précédés d’un déterminant de classe (a).  
Certains éléments de la classe (b) proviennent de la classe (a) [Bernard 1998]. L’indéfini 
qui dérive du cardinal un, est un mode du syntagme qui s’oppose au défini, au démonstratif, 
etc. alors que le lexème cardinal s’oppose à tous les autres cardinaux. L’EG tel fournit un 
déterminant ; le changement de fonction s’accompagne d’un net changement de sens.  
Article défini, indéfini et partitif : il s’agit de déterminants spécifiques. 
« On appelle indéfini un trait inhérent de certains articles, adjectifs ou pronoms, 
par opposition au trait défini, qui caractérise d’autres articles, adjectifs ou 
pronoms ... ». [Dubois 1973]  
 
le, la, l’, les, au, aux 
un, une, des 
du, de l’, de la 
Un / Une : son emploi implique une opération d’extraction, de prélèvement. L’article 
indéfini permet d’extraire d’un ensemble formé de plusieurs êtres ou objets un élément 
unique : c’est ce qui explique la pronominalisation du groupe nominal par en ... un / une : je 
vois des pommes, j’en veux une. L’emploie de un / une présuppose donc l’existence d’un 
ensemble qui ne peut être vide ni se réduire à un seul élément. Ce mécanisme d’extraction 
peut fonctionner à plusieurs niveaux, le contexte seul permettant de les distinguer : 
niveau général : un roi se gêne mais n’est pas gêné. N’importe quel élément de l’ensemble 
est considéré. Ce qui est dit, est vrai pour l’ensemble de la classe désignée par le nom. 
Niveau intermédiaire : Pierre veut planter un arbre dans son jardin. Ici le propos concerne 
un seul élément, non spécifique, de la classe considérée : la représentation de l’objet reste 
en somme abstraite (ce n’est pas un arbre concret qui est désigné). 
Niveau particularisant : Pierre est en train de planter un arbre. Il s’agit bien d’un objet 
particulier isolé dans un ensemble, donc d’un élément unique et spécifique. On a deux 
Chapitre I : Problématique  39 
START 2003 
possibilités ; ou bien cet objet est spécifié et identifié par l’énonciateur (il sait de quel arbre 
il s’agit) ou bien au contraire il n’est pas identifié, l’élément spécifié reste inconnu (la seule 
chose que sache l’énonciateur, c’est qu’il ne s’agit pas de fleurs ni de buissons, mais 
d’arbres). 
Dans une remarque d’ordre général [Chevalier et al. 1964], l’article indéfini marque qu’il 
s’agit d’une application particulière de la vérité générale : un soldat ignore la fatigue. 
L’article indéfini appliqué à une substance continue, marque qu’il s’agit d’un cas 
particulier. On opposera ainsi la lumière et une lumière, le silence et un silence, la vérité et 
une vérité. Par contraste avec l’effet de familiarité de l’article défini, l’article indéfini 
permet des effets de relief remarquables : 
1. il présente sous un aspect surprenant, nouveau, une chose ou un être familier, 
2. il permet d’envisager quelque chose de très particulier sur un plan général, 
3. il crée une impression de relief, de singularité, quand il est répété devant plusieurs 
substantifs, 
4. il entre ainsi dans des tournures très expressives : il est d’une humeur ! 
L’article indéfini engage le nom comptable dans la voie de la particularisation. Partant 
d’une perception générale et globale de l’objet (homme), l’article indéfini aboutit à en 
proposer une vision particulariste (un homme). On opposera ainsi ces deux états de sens de 
l’article indéfini : un homme sera toujours un homme (vision globale) et un homme est assis 
sur le banc (vision particulière). Ce mouvement de particularisation oppose l’article indéfini 
à l’article défini. 
Nous continuons notre présentation avec les différents emplois des démonstratifs. 
Démonstratif, (déterminants spécifiques) qui désigne (cet homme est riche).  
Ce, cet, cette, ces 
L’adjectif démonstratif [Sandfelf 1970] ce s’emploie devant les substantifs : cette ville, ces 
maisons, etc., et devant les adjectifs qui rappellent (en général) un substantif précédent : elle 
40  Chapitre I : Problématique 
START 2003 
regardait cette douce princesse et se sentait (...). Il s’emploie de plus devant plusieurs 
pronoms indéfinis : ce quelqu’un, ce quelque chose. Il se place devant d’autres adjectifs 
excepté tout, ( qui se trouve toujours devant ce) qu’il suit comme les articles et les adjectifs 
possessifs : toute cette ville, et il se répète ou ne se répète pas suivant les mêmes règles que 
les articles : j’admire cette maison et ce jardin – j’admire cette grande et belle ville.  
Ce sert à marquer ce qui, pour le sujet parlant, est présent dans l’espace : Ah ! je connais 
cette rue. S’il s’agit de plusieurs personnes ou choses, on peut ajouter ci ou là au substantif 
pour marquer la proximité ou l’éloignement : prenez cette route-ci et tournez à droite. Dès 
qu’il y a possibilité d’erreur, on emploie là pour relever ce qui est tout proche du sujet 
parlant (c’est que dans la langue courante, là est en train de remplacer ici). S’il est question 
seulement d’une présence fictive, le sens de ce + substantif correspond à celui-ci. On 
emploie l’adjectif démonstratif pour désigner des personnes présentes, sauf pour le cas de 
monsieur, madame, mademoiselle en s’adressant à une personne, monsieur désire ? sinon 
son emploi dénote la grossièreté ou la raillerie. L’adjectif démonstratif marque ce qui est 
présent dans le temps1. Il désigne aussi ce qui est rapproché du temps présent, soit dans le 
passé, soit dans le futur. Si l’on ajoute là au substantif, cela marquera un temps plus reculé2 
qui n’a plus de rapport avec le temps présent : cette année-là ...  
L’adjectif démonstratif sert à marquer ce que l’on évoque comme présent. Il s’emploie pour 
rappeler un fait, une chose ou une personne comme connus ou mentionnés. Dans la 
conversation, il s’emploie fréquemment dans des interrogations (souvent elliptiques) pour 
s’informer d’une chose dont on a parlé, salut Marie, alors ce fameux roman ? Il sert en plus 
à désigner quelque chose comme généralement connu : c’était une de ces jolies et 
charmantes filles ... la chose présentée comme connue peut servir à préciser un mot 
précédent. 
                                                   
1. Avec les noms des jours, l’adjectif démonstratif est employé par quelques-uns en style épistolaire : ce mardi 4 
septembre, il s’agit alors d’un pur archaïsme. 
2. L’usage de là dans le style indirect est inadmissible : elle lui a demandé si elle était disponible cet après-midi (et 
non pas cet après-midi-là). 
Chapitre I : Problématique  41 
START 2003 
Comme le montrent les exemples, le substantif est ordinairement déterminé par un membre 
de phrase (une relative ou ce qui en est l’équivalent) qui permet à l’auditeur de saisir 
immédiatement la pensée du sujet parlant : un de ces longs cigares est bien vague, tandis 
que un de ces longs cigares havanais est précis. 
Toutefois, il y a des cas où cette détermination ne se fait pas : quand le substantif est régi 
par le partitif dans des cas comme j’ai eu une de ces peurs !, quand le substantif, au pluriel, 
est sujet de la phrase et qu’il est question de quelque chose qui est commun à tous les 
individus désignés par ce substantif, ces artistes sont incorrigibles. Employé avec un nom 
de personne, l’adjectif démonstratif sert encore à désigner la personne en question comme 
connue de l’auditeur ou présente dans son esprit. Il s’emploie ainsi avec un nom de 
personne qualifié par un adjectif : il ne pouvait plus rien faire pour cette pauvre Isabelle. 
De la même manière on emploie l’adjectif démonstratif en parlant d’une personne présente : 
Ah ! voilà ce bon docteur ! Ou avec un nom propre tout seul, ce peut servir à marquer que la 
personne en question est présente ou absente : ah ! ce Pascal qui est toujours en retard ! Il 
se met aussi devant un nom qui, dans la conversation ou dans la narration, rappelle un mot 
précédent : il aurait pu prononcer un mot, un seul ; il n’a pas prononcé ce mot. 
Ce + subst. Peut aussi rappeler un mot qui est seulement suggéré par ce qui précède, ou il 
s’emploie devant un nom qui définit ou résume un énoncé précédent : un homme qui ..., je 
tiens à ce détail car ... Employé au pluriel, ces + subst. Peut prendre un sens généralisant et 
ces équivaut à tels ou cette sorte de. Il faut également mentionner l’emploi de ce en tant que 
pronom démonstratif neutre. Il ne se trouve que comme sujet atone : comme, ce disant, elle 
l’embrassait ... Ce sont des archaïsmes, employés la plupart du temps pour donner un style, 
une touche légère de plaisanterie ou d’ironie. Après ce en emploi verbal, on trouve : une des 
formes du verbe être (est, sera, fut, soit, etc.), une des marques verbales (le, l’, ne, n’), ou un 
auxiliaire à la troisième personne (pouvoir, devoir, etc.). En supplément, on trouve ce suivi 
d’une proposition introduite par (qui, que, qu’, dont), ou par une suite prépositionnelle (à, 
vers, pour, etc.) + quoi. 
Possessif : (déterminants spécifiques) (ma voiture, leurs enfants).  
Mon, ton, son , ma, ta, sa, notre, votre, 
42  Chapitre I : Problématique 
START 2003 
leur, mes, tes, ses, nos, vos, leurs 
Les adjectifs possessifs s’emploient toujours comme formes atones devant un substantif (ou 
nom substantivé). D’une façon générale, un seul adjectif possessif peut précéder le 
substantif : son caractère et le tien. Il est pourtant possible d’en combiner deux avec une 
conjonction : tel mot peut être remplacé par son ou ses synonymes [Bally 1950].  
Ils peuvent être séparés du substantif par d’autres adjectifs : son meilleur ami, mon plus 
grand souhait. Ordinairement les adjectifs possessifs se rapportent à un mot précédent, mais 
rien n’empêche de les faire renvoyer à un mot suivant.  
Les adjectifs possessifs mis avec le sujet d’une proposition relative peuvent renvoyer à 
l’antécédent du conjonctif : de simples poèmes que leur ancienneté rend pour les ... Si l’on 
a affaire à deux substantifs réunis par la préposition de, on mettra l’adjectif possessif devant 
celui auquel il convient le mieux : J’ai fait mes exercices de maths. Mais cette pièce n’était 
plus le lieu de son repos. Dans des expressions du type un coquin de valet, les possessifs se 
placent régulièrement devant le premier substantif : mon brave homme d’oncle, sa canaille 
de fils. Si l’on mettait le possessif devant le deuxième substantif cela donnerait à 
l’expression un sens tout autre : votre ours de frère est autre chose que l’ours de votre frère. 
Les adjectifs possessifs se trouvent toujours devant le nom (ou un mot substantivé). Ils se 
classent dans la catégorie des déterminants spécifiques du nom (ils ne peuvent se combiner 
ni avec l’article ni avec le démonstratif). Ils ajoutent à la signification de l’article défini la 
référence à la personne qui est en relation avec l’être désigné. Le déterminant possessif 
cumule deux valeurs : celle de la détermination du nom et celle de la désignation de la 
personne en relation avec l’objet déterminé. Deux paramètres interviennent donc dans sa 
formation : le rang personnel et les genre et nombre de l’objet désigné. Au pluriel, 
l’opposition des genres se neutralise, phénomène commun également aux articles et aux 
déterminants démonstratifs. Au singulier, l’opposition est marquée sauf si le nom féminin 
commence par une voyelle. Nous avons cité plusieurs exemples différents tirés du corpus, 
pour montrer la diversité du contexte ainsi que les particularités de leurs emplois. 
Chapitre I : Problématique  43 
START 2003 
Quand des noms sont coordonnés, on fait ordinairement précéder chacun d’un adjectif 
possessif : elle a perdu son père et sa mère. Mais ils sont sentis comme faisant unité, donc 
on peut se contenter d’un seul possessif devant le premier d’entre eux : a) deux noms au 
singulier, ils désignent alors une seule et même personne (le plus souvent) : en langage 
populaire on dit bonjour, messieurs dames ! b) deux noms de nombre différents. Il s’agit 
surtout de quelques expressions courantes de style du palais (archaïques), donnez-moi vos 
nom et qualités. C) deux noms au pluriel, comme pour le cas a, d) plusieurs noms : veuillez 
me laisser vos nom, profession et domicile. Si les adjectifs sont coordonnés devant un 
substantif, on ne répète généralement pas le possessif dans le cas où les adjectifs se 
rapportent à une même personne ou à une même chose : il lui fis ses adieux, ses 
remerciements pour sa longue et bonne hospitalité. Les possessifs qui indiquent une 
pluralité de possesseurs s’emploient de deux façons différentes. Tantôt ils marquent qu’une 
ou plusieurs choses appartiennent à plusieurs possesseurs en commun, tantôt ils ont une 
valeur distributive.  
Interrogatif : (déterminants spécifiques) (quelle fille ?). 
quel, quelle, quels, quelles 
L’adjectif interrogatif s’emploie : 1) devant un substantif : quelle langue parlez-vous ? 2) 
devant un substantif qu’on reprend, quel marque alors que le sujet parlant ignore ou prétend 
ignorer de quoi il s’agit : Arrête ton cinéma ! Quel cinéma ? 3) comme attribut : quel est le 
prix du billet ? En parlant de personnes, quel devient ainsi synonyme de qui : Quel est ce 
Marc ? sauf quand le sujet est un pronom personnel, il faut alors mettre qui : Qui êtes vous ?  
Jusqu’à présent on a vu que quel sert à déterminer un individu ou une chose parmi d’autres 
de la même espèce. Mais il s’emploie aussi, comme à l’origine, pour interroger sur la 
qualité d’un individu ou d’une chose : 1) devant un substantif : quelle femme celle-là ! 2) 
comme attribut : tu peux imaginer quelle a été mon enfance ! 
Dans le langage très familier, quel s’emploie parfois au lieu de lequel : Moi qui t’apportais 
une grande nouvelle ! – Quelle ? Cet usage est généralement supposé incorrect. S’il s’agit 
de phrases abrégées, il en est autrement pour les cas suivants : de nous deux, quel est le plus 
44  Chapitre I : Problématique 
START 2003 
grand ? Quel est le premier des deux ? L’emploie de quel s’explique ici par le fait qu’il est 
possible de le prendre comme attribut. 
Indéfini : (déterminants spécifiques et déterminants secondaires comme plusieurs) 
quelqu’, quelque, quelques 
certain, certaine, certains, certaines 
nul, nulle, aucun, aucune 
chaque 
plusieurs 
Quelqu’un s’emploie, d’une façon absolue, pour désigner un individu indéterminé. Se 
rapportant à un mot pluriel ou collectif, pour désigner un individu ou une chose 
indéterminée appartenant au groupe marqué par ce mot : j’ai toutes les qualités, n’est-ce 
pas ? Quelques-unes seulement. Dans les cas cités quelqu’un se rapporte à un mot 
précédent. Il peut aussi se rapporter à un mot suivant régi par de partitif : vous avez réuni 
dans la salle du patronage quelques-uns de nos paroissiens (Vautel, Curé riches). Dans le 
premier de ces emplois, quelqu’un est ordinairement invariable quant au genre. Souvent il 
prend le sens de « personne considérée, personne d’importance ». Il peut être qualifié par un 
adjectif ajouté à l’aide de de : donnez ceci à quelqu’un de sûr. Si cependant l’adjectif en 
question est suivi d’un complément, il peut être ajouté directement à quelqu’un : j’étais 
quelqu’un de semblable aux autres. Si quelqu’un est repris dans la phrase suivante, il peut 
dans ce second emploi être précédé d’un adjectif démonstratif ou d’un article : je 
m’aperçois que quelqu’un me suit, ce quelqu’un presse le pas.  
Le pluriel quelques indique un nombre indéterminé par trop grand : dans les rues quelques 
chiens et quelques hommes. Il s’emploie également pour marquer un nombre indéterminé 
excédant les chiffres vingt, trente etc. j’ai seulement trente et quelques pages à écrire pour 
finir mon mémoire.  
Quelque chose est le pronom neutre correspondant à quelqu’un et se dit de choses 
indéterminées : Quelqu’un ! Ce doit être Conan ! Il a oublié quelque chose ... Il se dit par 
Chapitre I : Problématique  45 
START 2003 
euphémisme pour « quelque chose de mauvais, un malheur ». Il s’emploie comme attribut 
en parlant de personnes pour indiquer qu’on a une fonction ou une position quelconque. 
Certain, certaine, s’emploie tantôt avec la fonction d’article, tantôt comme déterminatif 
complémentaire [Chevalier et al. 1964] : avec la fonction d’article, certain, alors 
caractéristique de l’usage littéraire, marque le refus de celui qui parle de préciser l’identité 
connue de la substance désignée : certain élève que je connais bien a encore oublié son 
devoir. Comme déterminatif complémentaire, certain utilisé après un et, plus rarement, 
après ce, marque l’impossibilité de préciser l’identité ou les qualités de ce dont on parle : un 
certain sourire. Avec un nom propre, il marque qu’on ne connaît que l’identité de l’individu 
désigné : un certain monsieur Blot. Parfois on trouve certain utilisé comme qualitatif (en 
fonction d’épithète, toujours postposé) signifie alors « assuré » : une nouvelle certaine. 
Aucun se dit de personnes et de choses et s’emploie de préférence se rapportant à un mot 
précédent ou à un mot suivant précédé de de. Il s’emploie d’une façon absolue dans des 
expressions toutes faites comme aucun1 n’est prophète chez soi. Aucun fait aussi fonction 
d’adjectif : aucun bruit ne se fait entendre. Aucun s’emploie avec une valeur négative : a) 
avec la négation ne auprès du verbe, b) dans des phrases sans verbe. La négation peut être 
exprimée par un mot négatif autre que ne : c’est elle sans aucun doute. Parfois il s’emploie 
comme personne dans des phrases où il y a d’avance un autre mot nié par ne auprès du 
verbe : elle n’a jamais été la femme d’aucun autre homme. 
Nul est synonyme de personne et d’aucun, mais ne s’emploie guère dans la langue parlée 
sauf dans la locution nulle part. Nous avons trouvé un exemple dans le texte Micromegas : 
je n’ai trouvé nulle part le bonheur. Nul est toujours singulier, et employé de façon absolue 
en parlant de personnes, il est souvent masculin et sujet de la phrase. Appartenant au style 
soutenu et solennel, il se trouve dans des phrases comme : nul n’est prophète en son pays, 
ou nul n’est parfait. Nous citons deux exemples tirés de « Candide » de Voltaire :  Pour 
                                                   
1. On trouve la même expression absolue avec nul, (voir plus loin). 
46  Chapitre I : Problématique 
START 2003 
moi, je n’ai nulle curiosité de voir la France, dit Candide. Pangloss fit un beau mémoire 
par lequel il prouvait que le baron n’avait nul droit sur sa sœur (..). 
Chaque est l’adjectif qui correspond à chacun. Comme celui-ci, il a parfois le sens d’un 
pluriel. Chaque s’emploie devant un substantif pour marquer la totalité des personnes ou 
des choses indiquées par le substantif en question. Cet usage appartient plutôt à la langue de 
tous les jours, et la langue littéraire emploie de préférence dans ce cas tout. Il s’emploie 
aussi pour marquer la totalité des personnes ou des choses qui appartiennent à un groupe ou 
à un nombre déterminés. Chaque se dit de ce qui se répète ou se succède. Avec des mots 
comme jour, nuit, mois, an, fois, on emploie chaque si l’on veut insister sur la répétition 
régulière. Parfois dans le langage familier et populaire, on emploie chaque au lieu de 
chacun. 
Plusieurs est un déterminant secondaire qui peut se combiner avec les déterminants 
spécifiques, j’ai lu plusieurs livres. Il s’agit d’un déterminant quantifiant, qui désigne la 
quantité des êtres auxquels le nom est appliqué (ce que l’on nomme parfois l’extensité) : il 
limite ainsi l’ensemble des objets du monde auxquels renvoie le substantif. Contrairement 
aux cardinaux, plusieurs marque une quantité imprécise qui évoque la pluralité : après 
plusieurs questions de cette nature...(extrait de Micromegas). 
1.4.2. Les pronoms 
Nous allons exposer brièvement les pronoms. Presque tous les groupes nominaux (GN) 
peuvent être remplacés par un pronom, et la plupart des pronoms varient de forme selon la 
fonction qu’ils occupent. Par contre, contrairement au nom, les pronoms ne peuvent pas être 
définis par le dictionnaire, car ils peuvent remplacer n’importe quel nom : on ne peut donc 
les comprendre qu’en sachant à quel nom ils font référence, dans le contexte d’une phrase 
précise. Ils prennent donc le genre et le nombre des groupes nominaux qu’il remplacent, de 
leurs antécédents. 
On trouve : 
− des pronoms personnels qui renvoient à des personnes ; (Je lis, Marie m’appelle...), 
Chapitre I : Problématique  47 
START 2003 
− des pronoms possessifs, qui renvoient à un nom (ou GN) dans un rapport de possession 
(ce livre est le mien), 
− des pronoms démonstratifs, qui renvoient à un nom dans un rapport de désignation (ceci 
est compliqué pour celui qui est fatigué ...), 
− des pronoms relatifs, qui renvoient à un nom dans un rapport de relation entre une 
proposition et une autre (le cours auquel j’assiste est très intéressant), 
− des pronoms interrogatifs, qui permettent de poser des questions sur un type de nom (qui 
es-tu ?), 
− des pronoms indéfinis (personne ne l’a vu), 
− En et y (j’en veux, j’y tiens). 
1.4.3. Les relatifs 
Nous citons également l’organisation de la phrase car nous nous y sommes intéressés au 
travers des relatifs : si une phrase simple ne comporte qu’un seul verbe conjugué, une seule 
proposition, il existe plusieurs sortes de phrases complexes, composées de deux, trois, 
quatre (ou plus)... verbes conjugués. On peut trouver, dans les cas des phrases complexes, 
divers rapports entre les verbes. 
L’autre possibilité est d’établir un rapport de supériorité, hiérarchique, d’un verbe sur 
l’autre : c’est le cas de la subordination (il mange (tout ce qu’il trouve)), où une proposition 
(la principale) domine, contient, commande l’autre (la subordonnée).  
Les propositions subordonnées sont dites relatives quand elles sont introduites par un 
pronom relatif (qui, dont, où, ...) ; comme les adjectifs, ces propositions décrivent, 
expliquent, donnent des informations souvent facultatives (ce livre qui est écrit en français, 
vient du France). Elles sont dites complétives quand elle ont valeur de nom et complètent 
un verbe, comme par exemple un complément d’objet (il demande que je l’appelle). 
Elles sont dites conjonctives quand elles sont soumises au verbe par une conjonction de 
subordination (mot qui joint en mettant sur un plan inférieur) comme : que, parce que, de 
48  Chapitre I : Problématique 
START 2003 
manière que, bien que, sans que, ...) Elles ont une fonction adverbiale équivalente à un 
complément circonstanciel (temps, manière), ex : il est parti parce qu’il était malade. 
1.4.4. Les prépositions 
Les prépositions sont des mots grammaticalement invariables qui aident à construire un 
complément. La préposition est un outil qui permet de mettre en relation syntaxique des 
éléments de la phrase afin d’exprimer le lieu, la manière, le temps, etc. De cette façon elle 
marque la dépendance entre les termes qui sont dans son environnement proche. La 
différence avec les conjonctions de coordination est que les prépositions ne permettent pas 
d’insérer une phrase dans une autre ni de mettre en relation des phrases ou des propositions. 
La préposition fait partie du statut de nom, qu’il s’agisse d’un groupe nominal ou 
pronominal, d’un infinitif (avec valeur nominale par exemple intéressant à observer) ou 
même d’une subordonnée. Des travaux récents sur la représentation des prépositions ainsi 
que des groupes prépositionnels (GP) ont vu le jour avec une approche sémantique, en 
conjonction avec les prédicats (les verbes et les noms prédicatifs) [Saint Dizier et Vazquez 
2001]. 
Nous pouvons dire que la préposition permet d’intégrer dans la phrase un groupe 
essentiellement nominal, qui reste syntaxiquement dépendant. 
1.4.5. Les conjonctions 
La conjonction désigne un outil de liaison. La présence de la conjonction de coordination1 
crée dans la phrase un syntagme unique, dont les membres sont solidaires et constituants 
d’un tout. Les principales conjonctions de coordination (mots qui joignent en mettant sur le 
même plan) sont : mais, ou, et, donc, or, ni, car. Pour les purs coordonnants2 « et, ni, ou » 
                                                   
1. Cette classe grammaticale concerne des mots invariables, qui se distinguent des adverbes et des prépositions. 
2. Coordination et juxtaposition : la coordination établit des rapports analogues à ceux que crée la simple 
juxtaposition des termes. Dans des séries énumératives, la présence de la conjonction de coordination n’est pas 
Chapitre I : Problématique  49 
START 2003 
nous pouvons décrire certaines caractéristiques qui permettent à repérer des rôles 
syntaxiques : 
- les termes qu’ils unissent ont le même rôle syntaxique dans la phrase 
- la nature grammaticale des éléments reliés n’est pas nécessairement identique 
Pour les autres « mais, car, or, donc », nous mentionnons leur caractère associatif qui se 
distingue de purs coordonnants, car leur capacité de coordination est plus limitée. Ils ne 
peuvent coordonner fondamentalement que des propositions ou des phrases et non des 
éléments de phrase. 
1.4.6. Les adverbes 
L’adverbe est un mot invariable. Les adverbes font partie d’une catégorie assez homogène 
qui intègre des mots d’origine et de fonctionnement différents. Leur fonction principale est 
d’offrir un appoint sémantique à un autre mot de la phrase par exemple un adjectif, un verbe 
ou un autre adverbe, c’est assez rare pour un nom. Les critères qui permettent de reconnaître 
la catégorie des adverbes (dans laquelle on ajoute les locutions adverbiales par exemple de 
toute façon, en même temps, etc.) sont les suivants :  
- l’invariabilité (c’est la différence principale avec l’adjectif qualitatif), 
- la dépendance (l’adverbe n’a aucune autonomie syntaxique), et 
- l’intransitivité (la différence avec la préposition, l’adverbe ne peut pas introduire de 
complément). 
Quant à leur traits morphologiques une grande majorité peut être extraite de la totalité des 
adverbes grâce à une désinence dotée de signification –ment. C’est le suffixe qui marque la 
manière de faire ou d’être et il est dérivé des adjectifs de la forme féminine. 
                                                                                                                                                     
obligatoire, par exemple : « liberté, égalité, fraternité, sont des … », dans cette perspective la juxtaposition peut 
être décrite comme coordination zéro.  
50  Chapitre I : Problématique 
START 2003 
1.5. Relation entre forme et sens 
Nous avons décrit de façon non exhaustive les principales caractéristiques des unités qui 
composent une phrase afin de connaître leurs particularités. Les divers usages de 
constituants, leur place, distribution, voisinage et inter-relation, forment le cadre dans lequel 
nous allons effectuer nos requêtes et évaluer les statistiques. La reconnaissance des parties 
du discours rentre dans une problématique beaucoup plus étendue ; jusqu’où l’expression de 
sens peut-elle se distribuer à travers la forme ? Qu’est-ce qui révèle, dans le sens d’un 
syntagme, des informations syntaxiques et sémantiques stockées avec l’appartenance de ses 
différents constituants à tel ou tel groupe ? On doit, donc, s’appuyer sur des définitions 
syntaxiques pour distinguer les parties du discours. La distribution des parties du discours 
n’en détermine pas moins un certain découpage du réel, qui constitue un premier aspect de 
la sémantique de la syntaxe. 
Les marques de la langue française appartiennent à des catégories grammaticales bien 
définies. La présence d’une marque révèle souvent la catégorie du mot qui suit. Chaque 
lexème grammatical a un rôle grammatical particulier selon son contexte et le même lexème 
peut se définir dans différentes catégories grammaticales, ceci peut créer un problème 
d’ambiguïté. Nous allons nous baser sur les particularités du contexte, propre à chaque 
catégorie grammaticale pour résoudre le problème d’ambiguïté quant à l’article défini et le 
pronom personnel. Nous connaissons la répartition des lexèmes dans le voisinage proche de 
mots grammaticaux. Les statistiques effectuées sont basées sur les propriétés 
distributionnelles de chaque lexème utilisé dans la base des mots grammaticaux. Les 
statistiques sur la distribution de marques grammaticales reflètent leurs propriétés 
syntaxiques et sémantiques.  
Nous avons exposé brièvement l’aspect général de la langue comme un processus cognitif 
mettant en œuvre plusieurs connaissances de sources variées. Nous avons observé les 
caractéristiques contextuels des mots grammaticaux, nous allons exposer ensuite les 
méthodes et travaux sur l’analyse du langage naturel avec un accent sur la syntaxe. 
 
 
 
 
 
 
 
Chapitre II 
 
 
ETAT DE L’ART 
52  Chapitre II : Etat de l’Art 
START 2003 
Sommaire du Chapitre II 
 
ETAT DE L’ART 
 
2.1. Bref historique 
2.2. Méthodes et travaux informatiques pour le langage naturel 
2.3. Situation de START dans ce contexte 
 
Chapitre II : Etat de l’Art  53 
START 2003 
 
Ces trente dernières années d’importants progrès ont été effectués sur les applications de 
traitement automatique du langage et en particulier concernant la syntaxe. Nous sommes en 
effet passés de systèmes reposant sur des informations syntaxiques très grossières à des 
approches beaucoup plus fines capables de décrire des phénomènes syntaxiques complexes 
(comme les dislocations, extractions, etc.). Les formalismes qui permettent ce type de 
description sont souvent difficiles à implanter. En conséquence, il y a une appréhension 
superficielle des problèmes visés car la conciliation entre finesse d’analyse et efficacité 
d’implantation s’avère une rude tâche. Bien évidemment, il n’est pas exclu que selon le type 
d’application et en fonction du type d’informations requis, on puisse être satisfaits d’une 
analyse très superficielle. 
Dans ce chapitre nous allons rendre compte de tous ces aspects, effectuer un bilan de ce qui 
existe (pour le français et dans une moindre mesure pour l’anglais et le grec) ainsi que du 
chemin parcouru. Nous décrivons un éventail de méthodes et systèmes existants pour mieux 
situer notre travail dans le domaine de recherches portant sur le langage naturel et plus 
précisément au niveau de l’analyse syntaxique. 
2.1. Bref historique  
Au début des années cinquante, des chercheurs comme W. Weaver ont étudié la possibilité 
d’utiliser des ordinateurs pour la traduction automatique [Weaver 1955]. Vue de manière 
très simplifiée, la tâche de traduction revient à remplacer les mots d’une phrase par leurs 
équivalents dans la langue cible, puis à réarranger cette séquence de manière à retrouver 
l’ordre des mots approprié pour la langue cible. Beaucoup de problèmes inattendus ont 
rendu cette entreprise plus difficile qu’elle n’en avait l’air. On est revenu alors sur l’étude 
de problèmes plus fondamentaux liés à la compréhension : si une machine peut comprendre 
le sens d’une phrase, elle peut la paraphraser, répondre à des questions sur cette phrase, ou 
la traduire dans une autre langue [Stévenin-Barbier 1996]. 
54  Chapitre II : Etat de l’Art 
START 2003 
Dans ce cadre l’outil informatique intervient avec l’idée que l’on peut modeler 
l’intelligence des machines sur celle des mécanismes de compréhension et d’expression. On 
définit l’humanité par la possession du langage [Auroux 1994]. Le langage humain se 
réalise sous la forme d’une multiplicité de langues – incompréhensibles entre elles pour la 
plupart. On estime le nombre de ces langues à 6000, dont 1200 sont assez bien connues. 
Cette somme de connaissances est considérable et elle nécessite un effort de recherche 
intensif, à l’aide d’un outil puissant. Comme le note S. Auroux l’universalité réside dans la 
méthode et non plus nécessairement dans l’étude d’un objet ou – partie linguistique – d’une 
langue spécifique [Auroux 1989]. La machine intelligente serait alors une machine avec 
laquelle on pourrait communiquer par le langage écrit ou plus récemment parlé. On cherche 
depuis longtemps à doter les machines de cette maîtrise du langage mais nous ne sommes 
pas au bout de nos peines. 
Dans les années soixante, le développement des langages de haut niveau, l’accroissement 
des capacités de calcul et de mémoire des ordinateurs ainsi que les découvertes de l’école 
générative en linguistique ont permis le développement d’un nouveau type de systèmes qui 
marquent le début de l’approche IA en traitement automatique du langage naturel. La 
langue est vue comme un processus cognitif mettant en œuvre des sources de connaissance 
variées : structures des phrases, sens des mots, modèle de l’utilisateur, règles de 
conversation, et un grand nombre des connaissances préalables et communes à tous les 
utilisateurs (pragmatique). La plupart des entreprises de développement de la traduction 
automatique ont connu des échecs. Le programme américain des années 60 a fait l’objet 
d’un enterrement officiel (rapport Alpac). 
Depuis les années soixante-dix, les recherches sur le langage naturel sont étroitement liées 
aux recherches sur la parole. Mais les entreprises de traduction et de compréhension 
automatique font souvent l’objet d’une critique austère et sèche : 
« Du programme canadien anglais-français, il ne subsiste qu’une procédure de 
traduction des bulletins de la météorologie, qui semble fonctionner à un coût inférieur 
à celui de la traduction humaine. Le programme européen EUROTRA, important par 
son volume puisqu’il devait traduire mutuellement toutes les langues de la 
Communauté, vient de subir une faillite honteuse, mais discrète. Des projets et des 
produits subsistent sur le marché, mais il est difficile de s’en faire une opinion claire 
Chapitre II : Etat de l’Art  55 
START 2003 
sauf dans les cas extrêmes. Le spectaculaire téléphone traducteur, miracle de la 
technologie japonaise, est présenté comme une révolution. Imaginez deux 
interlocuteurs, l’un japonais, l’autre allemand : leurs paroles sont transcrites par des 
programmes de reconnaissance de la parole, puis traduites par des traducteurs 
automatiques, et enfin diffusées dans les écouteurs, en langue maternelle, par des 
générateurs de discours. Le tout se fait en temps réel, sinon l’ergonomie du système 
n’est pas satisfaisante. C’est de la science fiction ! ». [Gross 1997] 
Nous présentons deux systèmes pionniers en IA pour introduire la représentation des 
connaissances. Les premiers systèmes à intégrer des analyses syntaxiques et sémantiques 
avec des connaissances pragmatiques sur un domaine limité sont apparus dans les années 
70. 
LUNAR, [Woods 1973] est un système expérimental qui transfère des requêtes sur des 
données géologiques entrées en anglais dans un langage formel d’interrogation de bases de 
données. Ce système utilise un analyseur syntaxique ATN et des informations heuristiques 
qui incluent de la sémantique. Ceci reste un très bel exemple d’utilisation d’un analyseur 
syntaxique ATN sur un problème réel. T. Winograd a développé dans les mêmes années un 
système (SHRDLU) qui dialogue avec l’utilisateur pour commander un bras de robot simulé 
qui manipule des blocs sur une table [Winograd 1983]. La réussite de ce système est due au 
fait qu’il y a une interaction entre une composante de raisonnement (PLANNER), une 
analyse sémantique, et un langage de programmation (PROGRAMMAR) qui fournit à 
l’utilisateur des fonctions primitives pour construire des structures syntaxiques décrites de 
façon systémique. Ce système est le premier à considérer la combinaison de modèles 
linguistiques et de méthodes de raisonnement au sein de la procédure de compréhension. Il 
a beaucoup influencé le développement d’une approche IA en traitement du langage naturel. 
Ce type d’approche a toujours été et est utilisé dans la mesure où il peut être efficace pour 
des problèmes précis et bien définis. Deux de rares systèmes de primitives qui aient été 
construits et utilisés dans des systèmes automatiques de compréhension sont le programme 
de traduction automatique de Y. Wilks [Wilks 1973] et le système de dépendances 
conceptuelles de R. Schank [Schank 1972]. 
 
56  Chapitre II : Etat de l’Art 
START 2003 
Une autre approche consiste à encoder les connaissances dans des structures de données 
passives et à interpréter ces connaissances à l’aide de procédures extérieures. La structure la 
plus utilisée est une structure de données dont les unités sont composées d’une liste de 
couples attributs – valeurs. Ces structures peuvent donc représenter aussi bien des 
décompositions sémantiques (les attributs étant alors des traits) que des réseaux 
sémantiques (les attributs sont alors des relations entre unités). 
Les réseaux sémantiques ont été introduits par R. Quillian, comme un modèle de la 
mémoire associative humaine [Quillian 1968]. R. Quillian est parvenu à programmer des 
opérations simples correspondant à des inférences. Les réseaux sémantiques ont été à la 
base de la représentation des connaissances dans de nombreux systèmes, notamment en 
compréhension de la parole. Les notions de base des réseaux sémantiques regroupent les 
propriétés d’un objet ou d’un événement au sein d’un seul concept. R. Schank dans sa 
théorie de la dépendance conceptuelle pose ses bases sur la notion de primitives 
sémantiques, c’est-à-dire qu’il essaie de faire la construction de toutes les notions 
sémantiques à partir d’un ensemble de onze concepts élémentaires [Schank 1986 ] (par 
exemple, « attraper un objet », « changer la position d’un objet », etc.). 
2.1.1. Le premier exemple des règles 
Dans les histoires racontées au sein d’Intelligence Artificielle nous trouvons le premier 
exemple [Crevier 1997] de système de connaissances transcrites en règles empiriques ou 
heuristiques donné par l’histoire de papyrus d’Edwin Smith en 1882 [Breasted 1930]. Ce 
papyrus égyptien a été acheté par Edwin Smith, un collectionneur américain, en 1882. 
Cinquante ans plus tard un archéologue au nom de James Breasted (mentionné plus haut) a 
réussi à situer l’origine de papyrus au 17e siècle avant J.-C. En fait, ce papyrus était la copie 
d’un manuscrit encore plus ancien de cinq mille ans environ. Dans cette copie il y a 
quarante-huit observations chirurgicales relatives à des blessures à la tête. Elles sont 
présentées toujours suivant le même protocole : titres, symptômes, diagnostic, traitement. 
Le couple symptômes – diagnostic se présente d’une formalité assez familier dans le cadre 
de règles « SI l’examen du malade présentant ces symptômes, ALORS on peut dire : Il s’agit 
de telle blessure ». Ensuite le pronostic est composé de trois formes invariables : « blessure 
Chapitre II : Etat de l’Art  57 
START 2003 
que je guérirai », « blessure contre laquelle je lutterai » et « blessure contre laquelle je ne 
peux rien ». Aux années 60 – 70 les spécialistes en IA sont amenés à résoudre des 
problèmes concrets. Il semble alors que la clef de solution à ce problème sont les 
connaissances, ils essaient donc de doter leurs machines avec du savoir. Cette quête les 
amena à définir des formats du type SI … ALORS, ressemblant à ceux utilisés par leurs 
prédécesseurs égyptiens. 
2.2. Méthodes et travaux informatiques pour le langage 
naturel 
Nous allons survoler les méthodes développées pour le traitement automatique du langage 
naturel. Ces dernières années avec le développement de grandes bases de données, un grand 
volume de textes électroniques est devenu disponible à l’analyse. Pour la plupart ces bases 
de données contiennent des textes sans restriction concernant la taille, le style ou la 
complexité (unrestricted text). Des textes alors, contiennent des titres ou autres formes 
(non-phrases), avec des expressions idiomatiques, dialectes ainsi qu’une pléthore de mots 
qui ne se trouvent même pas dans les dictionnaires électroniques les plus volumineux. De 
plus, ces textes contiennent des erreurs surtout s’ils proviennent d’outils de reconnaissance 
optique des caractères (optical character recognition tools, outils OCR). 
Tous les systèmes de traitement automatique de la langue contiennent d’une manière ou 
d’une autre une composante pour l’analyse syntaxique. Nous allons citer les différentes 
grammaires qui ont joué le rôle d’outil de traitement pour l’analyse syntaxique. 
2.2.1. La composante grammaire 
Une grammaire d’un langage a pour rôle de spécifier les phrases acceptables dans ce 
langage, et indique les règles syntaxiques permettant de combiner les mots pour obtenir des 
phrases bien formées. 
Les grammaires qui ont beaucoup influencé les travaux sur le traitement automatique des 
langues sont les grammaires de dépendance introduites par L. Tesnière [Tesnière 1959] et 
58  Chapitre II : Etat de l’Art 
START 2003 
les grammaires formelles, introduites par l’école générative de N. Chomsky [Chomsky 
1969]. On distingue les grammaires indépendantes du contexte et les grammaires dites 
contextuelles. 
Ensuite, nous avons les grammaires transformationnelles qui se situent dans le 
prolongement des grammaires à règles de dérivation (comme les grammaires formelles). 
Les grammaires transformationnelles chomskiennes n’ont pas donné lieu à beaucoup de 
réalisations. 
Une autre école linguistique fondée par Z.S. Harris a construit un cadre théorique utilisé 
dans plusieurs analyseurs syntaxiques [Harris 1962]. Les concepteurs du système ont dû 
étendre la grammaire de manière à traiter les expressions incorrectes apparaissant de façon 
régulière. L’analyseur syntaxique a été utilisé comme pré-processeur. Pour ce faire, ils ont 
utilisé une technique de remplissage de questionnaire qui assigne des morceaux de phrase à 
des colonnes dans une table. 
L’utilisation de cette technique de remplissage est révélatrice d’un autre problème lié aux 
techniques uniquement syntaxiques : un arbre d’analyse n’est pas une méthode de 
représentation des connaissances efficace. Connaître le sujet et l’objet d’un verbe ne suffit 
pas à déterminer le sens d’une phrase. Malgré tout, il est souvent plus facile de travailler à 
partir d’une représentation issue d’analyse syntaxique que sur la phrase originale, ce qui 
explique dans certains systèmes l’utilisation d’analyseurs syntaxiques comme première 
étape dans une série de traitements. Le plus souvent, un module final convertit l’arbre 
syntaxique en une forme interne de traitement, par exemple un transfert en langage 
d’interrogation de base des données. 
La plupart des analyseurs syntaxiques actuels ne se situent pas dans le cadre 
transformationnel mais dans la lignée des grammaires évoquées comme grammaires de 
dérivation (ou grammaires formelles). 
Les banques des données arborescentes telles que le Penn Treebank (PTB) [Marcus et al. 
1993], offrent une approche simple pour obtenir une large couverture grammaticale : il 
Chapitre II : Etat de l’Art  59 
START 2003 
suffit de lire la grammaire produite aux arbres parcourus. De telles grammaires est facile 
d’obtenir, mais le problème étant que l’ensemble de règles grammaticales atteint de 
proportions équivalentes à la taille de corpus, a conduit à des applications d’algorithmes qui 
compactent les grammaires dérivées en éliminant des règles redondantes, c’est-à-dire des 
règles dont la partie droite peut être analysée par d’autres règles [Krotov et al. 1998]. 
Nous allons évoquer maintenant une série de modèles syntaxiques apparus plus récemment, 
les grammaires d’unification. 
Les grammaires catégorielles qui ont été introduites par Y. Bar-Hillel [Bar-Hillel 1964], ont 
été développées dans de nombreuses variantes, notamment les grammaires de R. Montague 
[Montague 1974]. 
La grammaire syntagmatique généralisée de [Gazdar et al. 1985] qui a une base 
syntagmatique non contextuelle, n’utilise que la concaténation pour former les chaînes 
linguistiques de surface. Cette grammaire repose sur un système traits / valeurs (structures 
de traits). 
Les grammaires de tête et la grammaire syntagmatique guidée par la tête, par C. Pollard et I. 
Sag [Pollard et Sag 1988]. 
La grammaire lexicale fonctionnelle développée par J. Bresnan [Bresnan 1982].  
Bien d’autres formalismes ont été proposés, grammaires d’unification fonctionnelles par M. 
Kay [Kay 1973] et, grammaires à clauses définies par F. Pereira et D. Warren [Pereira et 
Warren 1980]. 
Du point de vue informatique il n’est pas surprenant que tant de paradigmes de description 
linguistique puissent être directement encodés dans des structures traits / valeurs dans la 
mesure où de telles structures ont été proposées par divers chercheurs en informatique 
comme mécanismes généraux de représentation des connaissances et de types des données. 
Cette classe de modèles a été utilisé dans de nombreux systèmes de compréhension du 
langage naturel et plus spécialement dans la compréhension de la parole. 
Les grammaires sémantiques : un des moyens pour ajouter du sens à une grammaire 
consiste à étendre les catégories syntaxiques. Une grammaire sémantique est une grammaire 
libre de tout contexte dans laquelle le choix de non-terminaux et de règles de production est 
60  Chapitre II : Etat de l’Art 
START 2003 
gouverné par une fonction aussi bien sémantique que syntaxique. Une très grande 
grammaire sémantique a été mise au point pour le système LADDER par [Hendrix et al. 
1978], ce système donne accès au langage naturel à une grande base de données distribuée 
qui est utilisée comme aide au management pour la marine. Cette grammaire, plutôt que de 
contenir des catégories syntaxiques de non-terminaux comme les groupes nominaux (GN) 
et groupes verbaux (GV), utilise les catégories sémantiques telles que « BATEAU » par 
exemple. Dans le système LADDER les concepts de BATEAU, PORT et ARMEMENT par 
exemple sont représentés par des règles de production différentes dans la grammaire, alors 
que dans une grammaire standard (anglaise ou française) ils seraient tous répertoriés comme 
noms.  
Les grammaires sémantiques ont des avantages – les questions syntaxiques qui n’affectent 
pas la sémantique peuvent être ignorées – mais il est évident que l’ajout de sémantique dans 
une grammaire accroît significativement le nombre de règles et d’états, on a donc une 
augmentation de la complexité et du temps de traitement nécessaire. 
Les grammaires de cas par C. Fillmore apportent une autre approche du problème de savoir 
comment des interprétations sémantiques et syntaxiques peuvent être combinées [Fillmore 
1968]. Les règles de grammaire se concentrent plus sur les régularités syntaxiques que sur 
les régularités sémantiques. 
Ces grammaires ont été à l’origine de théories comme la dépendance conceptuelle que nous 
présenterons dans la suite de ce paragraphe. Nous présenterons également les outils de 
traitement permettant l’analyse syntaxique.  
Les Réseaux de Transition Récursifs (RTN) sont une extension des automates1 à nombre 
fini d’états, qui permettent d’accepter tous les langages non contextuels, et seulement ceux-
ci. Les Réseaux de Transition Augmentés (ATN) par W. Woods et T. Winograd, sont une 
extension des réseaux de transition récursifs [Woods 1970] [Winograd 1983]. Ils se 
                                                   
1. Un automate à nombre fini d’états déterministe est composé par un ensemble E d’états, i est un élément de E qui 
s’appelle état initial, F est l’ensemble des états finaux, V est le vocabulaire sur lequel est défini le langage accepté 
par l’automate, et ∂ est la fonction de transition de l’automate. 
Chapitre II : Etat de l’Art  61 
START 2003 
distinguent des autres car ils permettent d’associer aux arcs des graphes1 des conditions et 
des actions. Les actions permettent de créer et de modifier des registres associés aux 
différents réseaux. 
L’unification est un outil largement utilisé, ce qui s’explique peut-être du fait de son 
adéquation à la plupart des grammaires formelles. Les formalismes basés sur l’unification 
utilisent comme domaine d’information un système basé sur des traits et des valeurs 
associées à ces traits. Les structures de traits ont une nature où la relation d’ordre sur les 
structures de traits par [Schieber 1990], mesure la compatibilité et la spécificité relative de 
l’information qu’elles contiennent. Il faut noter que des informations de tout type peuvent 
être codées dans ce format attribut – valeur ; c’est ce qui a été réalisé pour la plupart des 
analyseurs de systèmes de compréhension utilisant l’unification. [Fuchs et Victorri 1993] 
évoquent des analyseurs syntaxiques utilisant des représentations attribut – valeur mais 
utilisant d’autres opérations que l’unification comme moteur de traitement. 
[Debrock et al. 2000] ont conçu un analyseur VERTEX qui effectue une analyse syntaxique 
automatique pour les grammaires d’unification. Il s’agit d’un analyseur tabulaire (chart 
parser) utilisant une stratégie de recherche qui part d’un élément précis du constituant, à 
savoir la tête syntaxique pour former ce constituant. La grammaire partielle ne comporte 
qu’une trentaine de règles. Ceci permet d’effectuer une analyse syntaxique qui fournit des 
constituants sans expliciter pour autant des relations entre eux. Etant donné qu’une telle 
règle peut comporter des éléments (sous-constituants) facultatifs ainsi que des contraintes 
sur les propriétés des éléments, elle regroupe en fait plusieurs règles des grammaires 
communément employées (typiquement des grammaires hors contexte ou régulières). 
Nous ne développerons pas le traitement sémantique de manière séparée car il n’existe pas 
de modules sémantiques en tant que tel. L’introduction de sémantique dans les analyseurs 
prend généralement deux formes. La première consiste à utiliser des traits sémantiques qui 
sont de nature binaire (telle unité lexicale possède ou non tel ou tel trait comme « animal » 
ou « humain »). Une autre technique consiste à décomposer les unités lexicales en 
                                                   
1. Les arcs d’un graphe d’un réseaux de transition récursif peuvent porter comme étiquette le nom d’un réseau 
plutôt que le nom d’un élément de V. 
62  Chapitre II : Etat de l’Art 
START 2003 
primitives sémantiques. Les primitives sémantiques sont le plus souvent choisies de 
manière empirique en s’inspirant des connaissances sur le domaine. 
2.2.2. La composante syntaxe 
D’abord nous désignons le terme « analyse » en correspondance avec terme anglais parsing 
largement employé dans la littérature internationale de notre domaine. Nous distinguons 
trois méthodes d’analyse sous les termes de : analyse robuste (robust parsing), analyse 
partielle (partial parsing) et analyse superficielle (shallow parsing). Nous verrons plus loin 
plusieurs travaux basés sur ces méthodes. 
La plupart des analyseurs (parseurs) du langage naturel sont des programmes qui essaient 
d’assigner automatiquement une structure syntaxique à une phrase en entrée, en utilisant un 
modèle du langage formel par exemple une grammaire. En général le but d’un analyseur 
(parser) est de faire correspondre une structure syntaxique dans le texte en entrée. Par 
exemple, l’analyseur syntaxique met en correspondance une au moins structure syntaxique 
avec un texte. 
Les approches antérieures sont basées sur des ressources complexes comme des lexiques 
contenant des milliers de mots et des grammaires contenant des centaines de règles. Un 
système indépendant de langue pour l’analyse de textes sans restrictions (unrestricted text) 
basé sur les formalismes de grammaires des contraintes (Constraint Grammar) est présenté 
par [Karlsson et al. 1995]. Cette approche offre une désambiguïsation de n’importe quelle 
partie du texte. Mais elle demande un dictionnaire principal assez volumineux et quelques 
lexiques dépendant de la procédure ainsi qu’une grammaire composée de milliers de règles. 
En général, ces solutions exigent un grand coût en matière de calcul, et leurs constructions 
mais surtout leur transformations seraient des procédures très difficiles à gérer et très 
gourmandes en matière de temps. 
Le problème de l’analyse syntaxique (syntactic parsing) est l’usage d’un grand modèle 
linguistique formel (par exemple une grammaire), dans le parseur qui analyse les phrases en 
entrée et fournit une correspondance syntaxique en sortie. La plupart des analyseurs 
Chapitre II : Etat de l’Art  63 
START 2003 
syntaxiques procèdent à l’assignation de « marques » syntaxiques ou grammaticales dans la 
phrase, par exemple pour la phrase « le chat mange la souris » elles produisent une structure 
arborescente comme celle montrée ci-dessous. Nous trouvons les notions de nœuds et de 
connexions de la syntaxe structurale dans cette conception arborescente qui reste le modèle 
le plus courant de la représentation syntaxique de la structure de la phrase. 
 
 
 
 
 
Figure 2 :  A parse tree. 
Dans cet exemple nous adoptons les abréviations standards : P pour phrase, GN pour groupe 
nominal, GV pour syntagme verbal, Dét pour déterminant. 
Nous pouvons conclure qu’un analyseur syntaxique est un programme qui permet de 
convertir une entrée texte (une phrase extraite d’un texte ou une demande d’utilisateur dans 
le cas de l’interrogation de Bases de Données) en une représentation structurée pouvant 
contenir des informations syntaxiques ou sémantiques qui n’étaient pas de manière explicite 
dans la phrase initiale. 
2.2.3. L’étiquetage 
A partir des années ’90 nous trouvons une forte croissance de développement des processus 
d’étiquetage ou tagging ou encore marquage [Vergne et Giguet 1998]. Ceci consiste à 
affecter une étiquette (tag ou catégorie) à chaque mot d’un texte. Les étiqueteurs des parties 
du discours les plus simples sont de modèles bi-grams et tri-grams [Church 1989], 
Dét Nom 
Verbe 
GN 
le chat mange
Nom 
la souris 
P 
64  Chapitre II : Etat de l’Art 
START 2003 
[Charniak et al. 1993]. Ils présupposent l’existence d’un corpus relativement grand et 
annoté. Les étiqueteurs basés sur la transformation [Brill 1993] présupposent également un 
corpus préalablement annoté pour l’apprentissage. Ces dernières années cette méthode 
d’étiquetage automatique est beaucoup développé comme une alternative au copieux 
étiquetage manuel qui se pratiquait par le passé. L’étiquetage1 des syntagmes ouvre la voie 
au renouveau de l’analyse syntaxique. L’algorithme d’étiquetage des groupes consiste à 
tester l’applicabilité d’un nombre constant de règles. 
Dans le tagging, la nouveauté vient avec une nouvelle chaîne de traitement, le tagger qui se 
substitue à l’analyseur morpho-lexical et fournit à l’analyseur syntaxique une liste de 
« tokens » munis chacun d’une seule étiquette, ainsi on arrive à réduire au maximum, la 
combinatoire des catégories possibles en utilisant de nouvelles ressources qui sont les 
déductions contextuelles. Nous pouvons dire que le tagging est une analyse syntaxique qui 
isole un noyau dans la phrase à l’aide des mots grammaticaux puis procède à des déductions 
locales ou contextuelles pour désambiguïser les cas ambigus ; par exemple pour une ferme 
→ une = déterminant mais pour ne ferme → ne = négation et donc on peut déduire que le 
premier ferme est un nom et le deuxième est un verbe. 
Nous allons survoler les méthodes d’étiquetage automatique qui ont comme élément 
commun l’étiqueteur qui attribue une étiquette soit en consultant des lexiques qui associent 
une liste d’étiquette à chaque forme comme le DELAS ou le DELAC [Silberztein 1993], 
contrairement à notre processus dans lequel il n’y a pas de lexique préalable, soit par 
l’application de règles morphologiques. 
2.2.3.1. Les étiqueteurs 
En français certaines suites de catégories sont impossibles, par exemple un déterminant ne 
peut jamais être suivi d’un verbe. L’exhaustivité combinatoire des séquences de catégories 
d’une suite textuelle peut être représentée par un unique graphe dont certains parcours sont 
                                                   
1. Le concept principal et original de l’étiquetage (tagging) selon J. VERGNE et E. GIGUET sont des déductions 
contextuelles. Nous trouverons les processus explicités à la fin de la thèse (voir §Terminologie). 
Chapitre II : Etat de l’Art  65 
START 2003 
illicites. Les règles négatives permettent de marquer ces parcours pour ne laisser que leurs 
alternatives, comme le mentionnent E. Giguet et J. Vergne : 
« les déductions contextuelles s’appuient sur des ressources lexicales, et doivent s’articuler avec 
elles, il y a trois articulations possibles :  
- dans tel contexte, tel token ne peut pas avoir telles catégories 
- dans tel contexte, tel token a une catégorie 
- la dernière consiste à remarquer les différentes catégories possibles d’un token et choisir celle 
qui est la plus fréquente comme catégorie par défaut, exemple : le, la, l’, les, article. Elles 
seront pronom dans un contexte particulier (ces informations liées au contexte sont codées dans 
les règles de déduction contextuelle du tagging) ». [Giguet et Vergne 1997] 
Inversement un graphe permet de décrire les suites possibles de catégories et elles seules. 
Le plus souvent ces graphes sont établis à partir d’une forme particulière ; ils décrivent les 
contextes immédiats possibles pour une forme donnée. Ces règles décrivent alors une 
grammaire ne faisant pas intervenir de notion de constituance mais les seules suites 
possibles qui précèdent ou qui suivent une forme. On parle alors de grammaire locale. Le 
système INTEX [Silberztein 1993] permet de construire de telles règles sous la forme d’un 
automate. Les étiqueteurs par règles sont fiables mais ils demandent des données 
nombreuses qui sont pour la plupart écrites à la main. Ces données peuvent être 
partiellement établies automatiquement grâce aux méthodes stochastiques. 
Les étiqueteurs stochastiques exploitent un corpus d’apprentissage pour établir la 
probabilité de l’assignation d’une étiquette en fonction d’un contexte. On parle alors de bi-
grammes pour une suite de deux étiquettes, de tri-grammes pour une suite de trois 
étiquettes, etc. Le corpus d’apprentissage doit être un corpus de référence par rapport au 
type de texte qui sera étiqueté. Il doit aussi être d’une taille suffisante pour contenir de 
façon statistiquement significative les contextes d’une étiquette ambiguë. 
Le modèle de Markov, du nom du statisticien russe qui étudia en 1907 les contraintes 
statistiques des suites de lettres, revient à calculer la probabilité conditionnelle de réalisation 
d’une étiquette en fonction de la probabilité conditionnelle de la réalisation des étiquettes 
précédentes. Il s’agit d’un système dont le passage à chaque état dépend d’une probabilité 
66  Chapitre II : Etat de l’Art 
START 2003 
en fonction des états qui le précèdent. Le nombre d’états significatifs qui précèdent fixe 
l’ordre du modèle. Son implémentation est facile, c’est certainement l’une des raisons de 
son succès et il offre en plus la possibilité d’exploiter des algorithmes rapides et 
économiques. 
L’étiqueteur de [Brill 1992] (trained rule-based tagger) est basé sur une méthode 
probabiliste en ce sens où l’ensemble de la procédure peut être mise en œuvre grâce à un 
corpus d’apprentissage. Mais, à la différence avec les autres méthodes probabilistes, elle 
permet d’intégrer des connaissances linguistiques sur l’étiquetage morpho-syntaxique. Cette 
méthode fait l’usage de règles très proches de celles des étiqueteurs par règles, cependant 
une probabilité est appliquée fixant un niveau de performance des règle. Seules sont 
appliquées les règles qui maximalisent la probabilité d’améliorer l’étiquetage et qui 
minimisent la probabilité de le dégrader. La méthode de Brill (mentionné plus haut) nous 
montre qu’il est possible de combiner des méthodes stochastiques avec des connaissances 
linguistiques qui seront exploitées pour établir le type de règles contextuelles. 
D’autres travaux sur le tagging viennent de l’Université de Pennsylvania. [Brill et Marcus 
1994] travaillent sur l’étiquetage d’un texte inconnu (unfamiliar en anglais). Ils utilisent 
l’analyse distributionnelle pour « déduire toute information linguistique ». L’analyse 
distributionnelle se fait sur un très grand corpus dont l’environnement (contexte) est 
grammaticalement correct. Le module d’étiquetage se décrit comme suit : d’abord on a un 
grand corpus de textes en entrée sans aucun traitement, aucune information lexicale ou 
syntaxique. L’information d’étiquetage est extraite du corpus grâce à une analyse 
distributionnelle. Le système actuel permet de créer un étiqueteur, qui pourrait étiqueter un 
texte avec une très grande précision, en une langue inconnue, en quelques heures seulement 
et avec l’aide d’un très bon connaisseur de la langue en question. Le système est basé sur 
des règles contextuelles de désambiguïsation ; les règles utilisées sont de deux types : 
- corriger les fautes sur les mots qui sont dues à l’étiqueteur, et 
- utiliser des informations contextuelles pour de meilleures performances. 
Les résultats atteignent plus de 84% de solution mais ceci grâce à l’utilisation d’un lexique 
provenant d’un corpus au préalable étiqueté.  
Chapitre II : Etat de l’Art  67 
START 2003 
Contrairement à l’analyse syntaxique traditionnelle [Sabah 1989]1 cet étiquetage explicite le 
processus mais n’explicite pas les structures. 
L’analyseur syntaxique de [Vergne et Giguet 1998] combine les techniques de l’étiquetage 
grammatical pour construire des segments non récursifs et un algorithme de calculs de 
dépendances pour calculer la structure fonctionnelle. L’analyseur est déterministe et a une 
complexité linéaire.  
Si l’on compare le tagging avec l’analyse syntaxique traditionnelle on trouve quelques 
différences non négligeables pour toute analyse syntaxique. Dans l’analyse syntaxique 
traditionnelle il y a deux modules : l’analyseur morpho-lexical, qui à partir de ressources 
lexicales considérées comme exhaustives, produit une liste de tokens munis chacun d’une 
ou plusieurs étiquettes, suivi de l’analyseur syntaxique proprement dit, qui pour chaque 
phrase, produit zéro, un ou plusieurs arbres syntagmatiques. 
Le problème central de l’analyse syntaxique traditionnelle (ci-après AST) est son aspect 
combinatoire ; ceci est du au fait que l’AST est fondée sur des principes de compilation, 
analyse d’un langage formel dont le lexique est clos (les mots ayant une seule catégorie) et 
dont la syntaxe est exhaustivement définie par une grammaire formelle, alors qu’une langue 
a un lexique ouvert, et une syntaxe partiellement définie. 
Personne ne met en question l’utilité des étiqueteurs syntaxiques (POS taggers) pour 
l’analyse syntaxique [Voutilainen 1998]. Puisque les étiqueteurs réduisent significativement 
l’ambiguïté des phrases en entrée, les analyseurs (parsers) sont supposés être plus rapides et 
les résultats qu’ils fournissent moins ambigus. Ceci veut dire que l’analyseur essaie de 
choisir parmi une multitude de possibilités l’alternative qui est la plus appropriée pour la 
phrase en entrée. Nous pouvons donc considérer qu’un analyseur syntaxique a comme 
fonction la désambiguïsation massive dont les problèmes principaux sont les suivants : 
                                                   
1. Dans l’analyse syntaxique traditionnelle (nous entendons l’analyse syntaxique dans son état canonique comme la 
décrit G. SABAH dans le chapitre 2 de L’IA et le langage, pages 37 à 71), l’ensemble des structures syntaxiques 
attendues est exhaustivement explicité sous la forme d’une grammaire syntagmatique. 
68  Chapitre II : Etat de l’Art 
START 2003 
- déterminer l’analyse qui correspond à une phrase, spécialement dans le cas de 
phrases longues fait qui peut exiger beaucoup de temps et de mémoire (problème du 
calcul) 
- décider parmi les choix d’analyses possibles, ceci peut être difficile en raison de a) 
l’ambiguïté syntaxique inhérente à la phrase ou b) les manques de spécification du 
modèle du langage formel de l’analyseur (problème linguistique), 
- assigner une analyse syntaxique à une phrase syntaxique peut échouer du fait que le 
modèle de langage formel de l’analyseur puisse ne pas accepter la structure qui 
émerge en tant que phrase (problème linguistique). 
2.2.4. La division du texte (text chunking) 
Par text chunking nous désignons la division du texte en groupes syntaxiques suite à la série 
de processus suivante :  
- la division du texte en parties de mots syntaxiquement corrélés entre eux (groupes), 
- l’identification de ces groupes parmi une séquence de segments (tokens) et, 
- la classification de ces groupes dans des catégories grammaticales. 
Par exemple la phrase : « Les peuples des Nations Unies ont proclamé leur foie dans les 
droits fondamentaux de l’homme », peut être divisée comme suit : 
[GN Les peuples des Nations Unies] [GV ont proclamé] [GN leur foie] [GP dans [GN les 
droits fondamentaux de l’homme]]. 
Les abréviations GV, GN et GP sont utilisées pour désigner le groupe verbal, nominal et 
prépositionnel respectivement. La division du texte en petites structures syntaxiques est vue 
comme une étape intermédiaire de l’analyse syntaxique complète (full parsing). 
Un chunk (groupe syntaxique, syntagme) est un groupe de mots formant une unité à 
l’intérieur de la phrase. Pour [Saussure 1960] le syntagme se compose toujours de deux ou 
plusieurs unités consécutives. Une première étape de la construction d’analyseurs de corpus 
Chapitre II : Etat de l’Art  69 
START 2003 
est la détection et la détermination de groupes de mots qui forment une unité au sein de la 
phrase (les chunks). L’exemple que nous montrons ci-dessous, que nous avons emprunté à 
[Tjong Kim Sang et Buchholz 2000], illustre trois types de chunks (NP, VP et PP) pour la 
phrase : « He reckons the current account deficit will narrow to only £1.8 billion in 
September » : 
[NP He ] [VP reckons ] [NP the current account deficit ] [VP will narrow ] [PP to ] [NP 
only £1.8 billion ] [PP in ] [NP September ]. 
Les auteurs reconnaissent dans le pronom personnel « He » une unité qui peut se tenir seule 
en tant que groupe nominal, ensuite « reckons » est doté du chunk VP et ainsi de suite pour 
les prépositions « to » et « in ». La plupart des analyseurs de surface (à l’exception de 
[Brants 1999]), procèdent à la reconnaissance de la « tête » d’un groupe sans ses arguments 
qui se trouvent à sa droite, dans l’exemple plus haut les deux « prepositional phrases » sont 
reconnues seulement à leur tête « to » et « in » respectivement sans inclure leur argument 
qui le groupe nominal qui suit. Dans les travaux de segmentation guidée par les données 
(data-driven chunking), beaucoup d’attention a été dirigée vers le développement de 
méthodes de reconnaissance des groupes nominaux simples non récursifs, que l’on appelle 
également « base NP chunks » [Church 1988], [Cardie et Pierce 1998], [Skut et Brants 
1998]. Il faut aussi mentionner que la plupart de recherches sur le chunking ont été orientés 
vers le développement des analyseurs guidés par les données pour l’anglais, comme c’était 
le cas des étiqueteurs des parties du discours (PoS tagging) quelques années auparavant. La 
raison principale étant qu’il y avait toujours un corpus en anglais correctement annoté le 
Penn Treebank [Marcus et al. 1993], ce genre de corpus manquent dans la plupart des 
langues. Etant donnée la masse des données correctement analysées et étiquetés, toute 
application ou développement ou évaluation par les approches guidées par les données 
devient plus facile et plus efficace. Depuis, plusieurs travaux dans d’autres langues ont vu le 
jour comme le suédois [Magyesi 2001], le grec[Stamatatos et al. 2000]. 
Un des problèmes de ces parseurs est celui des mots inconnus. Il y a des chercheurs qui 
utilisent des méthodes heuristiques (comme par exemple la reconnaissance de certains 
suffixes ou celle de la première lettre majuscule pour les noms propres), et d’autres qui 
ignorent les mots inconnus et essaient de reconnaître la partie restante du texte [Hobbs et al. 
1996]. Plus récemment nous trouvons des méthodes statistiques qui offrent l’évaluation la 
70  Chapitre II : Etat de l’Art 
START 2003 
plus probable selon l’information morphologique, syntaxique ou les deux, des mots qui 
n’ont pas été trouvés dans le dictionnaire [Dermatas et al. 1995], [Mikheev 1997]. 
Plusieurs tâches du Traitement Automatique du Langage Naturel peuvent être considérées 
comme du chunking. Parmi les exemples nous pouvons citer l’identification des groupes 
nominaux en anglais (base NP1 chunking), l’identification des groupes syntaxiques de base 
en anglais (chunking), l’identification et l’extraction des entités nommées en japonais 
(bunsetsu). Si nous considérons que chaque caractère est un token alors nous pouvons 
conclure que la tokenization et l’étiquetage (tagging) des parties du discours (Part-of-
Speech) sont des tâches du chunking. 
2.2.4.1. Divers systèmes et applications 
En 1991 [Abney 1991] a proposé une approche d’analyse en commençant par assembler les 
mots qui sont liés syntaxiquement dans la même phrase. Ensuite [Ramshaw et Marcus 
1995] ont introduit une nouvelle approche de division en groupes en utilisant une méthode 
d’apprentissage par machine (machine learning method) pour la division du texte en 
groupes nominaux. La méthode consiste en l’estimation d’une fonction d’identification 
selon l’information (feature) disponible dans le contexte proche. Plusieurs approches basées 
sur la technique du machine learning ont été proposées par [Tjong Kim Sang 2000], [Tjong 
Kim Sang et al. 2000], [Sassano et Utsuro 2000] et [Van Halteren 2000].  
Cette méthode s’oppose aux techniques de machine learning conventionnelles comme le 
Hidden Markov Model (HMM) et le Maximum Entropy Model (ME) qui présupposent une 
sélection attentive d’informations (ou de caractéristiques) afin de parvenir à une meilleure 
performance. Ces modèles ne fournissent pas de méthode pour la sélection automatique des 
caractéristiques données. De nouvelles techniques statistiques d’apprentissage ont été 
proposées comme le Support Vector Machines (SVMs) [Cortes et Vapnik 1995] et le 
Boosting [Freud et Schapire 1996] pour le chunking. Ces techniques optent pour une 
                                                   
1. NP pour Nominal Phrase. 
Chapitre II : Etat de l’Art  71 
START 2003 
stratégie qui maximise les marges de possibilité d’appartenance à une catégorie ou pas. 
Elles sont également utilisées dans les travaux NLP en général et leurs auteurs 
[Joachims 1998], [Taira et Haruno 1999], [Kudo et Matsumoto 2000] rapportent une grande 
performance. 
Nous pouvons produire des grammaires à l’aide des algorithmes génétiques[Losee 1996]. 
Les grammaires du langage naturel peuvent être apprises en utilisant des algorithmes 
génétiques qui reproduisent et mutent des règles grammaticales et des étiquettes des parties 
du discours en améliorant la qualité des dernières générations des composants 
grammaticaux. Les règles syntaxiques sont générées aléatoirement puis elles évoluent ; ces 
règles aboutissent à une analyse efficace et occasionnellement améliorent l’extraction et 
filtrent des performances qui sont nécessaires aux étapes du filtrage suivant. 
Une approche connexionniste pour l’analyse du langage naturel nous est proposée par [Lane 
et Henderson 2001], qui utilisent des Simples Réseaux Synchrones (Simple Synchrony 
Networks) (SSNs) [Henderson et Lane 1998] pour l’apprentissage de l’analyse des phrases 
en anglais. Les SSNs ont la capacité, contrairement aux Simple Recurrent Networks – qui 
ont été désignés pour prédire le mot suivant dans une phrase – de représenter en sortie 
toutes les relations structurales possibles pour spécifier une structure. L’analyse des phrases 
pour les SSNs se résume ainsi : nous prenons une séquence des mots en entrée en on produit 
en sortie une structure hiérarchique qui représente la manière dont ces mots se mettent 
ensemble pour former des constituants tels que les groupes nominaux ou verbaux. L’état de 
l’art des techniques qui abordent cette tâche est celui d’apprentissage du langage à base des 
méthodes statistiques [Charniak 1993], [Charniak 1997], [Collins 1996]. 
Pour construire la base des connaissances d’un analyseur du langage naturel il existent deux 
méthodologies principales : la méthodologie linguistique et la méthodologie guidée par les 
données (data driven). Selon [Voutilainen 1995] l’analyse des parties du discours (Part-of-
Speech (POS) analysis) consiste en : 
- introduction de l’ambiguïté (analyse lexicale), et 
- désambiguïsation (élimination des alternatives illégitimes). 
72  Chapitre II : Etat de l’Art 
START 2003 
Dans l’approche linguistique, les généralisations sont basées sur les abstractions du 
linguiste (elles-mêmes basées sur les observations sur le corpus) quant aux paradigmes et 
syntagmes de la langue. Les généralisations distributionnelles sont manuellement codées 
comme une grammaire : un système de règles est utilisé pour éviter des analyses 
contextuelles illégitimes. Cette approche est très exigeante : elle nécessite des capacités et 
des efforts intenses pour écrire une grammaire complète. 
Dans l’approche guidée par des données d’information, et basée sur la fréquence 
d’apparition des mots, la base des connaissances est automatiquement extraite du corpus. Le 
corpus d’apprentissage peut être basé sur un corpus non annoté mais les meilleurs résultats 
sont obtenus avec des corpus annotés [Merialdo 1994], [Elworthy 1994]. L’information 
basée sur corpus peut être représentée soit par des réseaux de neurones [Eineborg et 
Gambäck 1994], [Schmid 1994], soit par des règles locales [Brill 1992], soit par des 
matrices de co-locutions (collocational) de mots qui peuvent se mettre ensemble par 
exemple on peut dire « un café fort » mais moins **« un café faible » [Garside 1987]. 
Notons que malgré l’absence de création manuelle de règles il faut déterminer le groupe 
d’étiquettes [Cutting et al. 1992] qui sera l’outil ainsi que le corpus annoté.  
Souvent l’approche linguistique est préférée car elle offre la possibilité d’une 
désambiguïsation directe avec l’ajout d’une règle simple quant à un déterminant ambigu par 
exemple dans « il la porte » nous savons que « la » est un pronom vu qu’il est précédé d’un 
autre pronom. Nul ne peut contester le fait que nous pouvons créer des règles linguistiques 
fiables pour résoudre quelques ambiguïtés des parties du discours. Le problème de cette 
approche est que la résolution de l’ambiguïté à grande échelle crée un fort taux d’erreur. En 
effet, il n’y a pas beaucoup de systèmes à base de règles qui reportent une reconnaissance 
conséquente à l’exception de [Voutilainen et al. 1992] qui dans le ENGCG (English 
Constraint Grammar Parser) rapporte que la désambiguïsation morphologique à base de 
règles atteint un succès de 99,7 % des mots qui ont reçu une analyse morphologique 
correcte, ce système laisse pourtant un pourcentage assez élevé de l’ordre de 3-7% de mots 
ambigus. 
Chapitre II : Etat de l’Art  73 
START 2003 
L’identificateur – classificateur (chunk) de type nominal a rencontré beaucoup de succès par 
rapport aux autres identificateurs – classificateurs (chunks). Le travail le plus complet est 
présenté par [Buchholz et al. 1999] qui donne des résultats pour les GN, GV, GP, GA1 
chunks. [Veenstra 1999] travaille avec des chunks GN, GV et GP, et [Ramshaw et Marcus 
1995] ont reconnu des chunks arbitraires et ont classé tout groupe qui n’est pas un groupe 
nominal comme un groupe verbal. [Ratnaparkhi 1996] a reconnu des chunks arbitraires 
également comme une tâche d’un analyseur syntaxique, mais ne mentionne pas leur 
performance. Le processus de la désignation des GN s’occupe d’une seule tache : 
reconnaître les identificateurs (chunks) des groupes nominaux. 
La méthode de Ramshaw et Marcus (mentionnés plus haut) très sollicitée pour évaluer les 
algorithmes se présente ainsi : Les données sont divisées en deux parties : des données 
traitées et des données à tester. Le but est de créer un algorithme d’apprentissage à partir 
des données traitées et d’évaluer sa performance sur les données à tester. La performance de 
l’algorithme se mesure avec deux scores : la précision et le rappel, (precision and recall). 
La mesure de précision indique combien de GN trouvés dans le texte ont été correctement 
annotés et celle de rappel contient le pourcentage de GN définis dans le corpus et trouvés 
par le programme d’identification – classification (chunking). Les deux mesures peuvent se 
combiner en une seule : le pourcentage F [Van Rijsbergen 1979], où : 
F = 2 * précision * rappel / (rappel + précision) 
L’ensemble des données fait partie du corpus du Wall Street Journal, les sections 15-18 en 
tant que données traitées et la section 20 de ce corpus a servi comme données à tester. Les 
résultats publiés sont les suivants : 
                                                   
1. GA signifie groupe adverbial. 
74  Chapitre II : Etat de l’Art 
START 2003 
Travaux testés sur le même corpus 
(par ordre d’année d’apparition) 
Précision
en % 
Rappel 
en % 
F-mesure 
en % 
[Kudo et Matsumoto 2001] 94,15 94,29 94,22 
[Tjong Kim Sang et al. 2000] 94,18 93,55 93,86 
[Tjong Kim Sang 2000] 93,63 92,89 93,26 
[Tjong Kim Sang et Veenstra 1999] 92,50 92,25 92,37 
[Muñoz et al. 1999] 92,40 93,10 92,80 
[Cardie et Pierce 1999] 89,00 90,90 89,90 
[Argamon et al. 1999] 91,60 91,60 91,60 
[XTAG Research Group 1998] 91,80 93,00 92,40 
[Veenstra 1998] 89,00 94,30 91,60 
[Cardie et Pierce 1998] 90,70 91,10 90,90 
[Ramshaw et Marcus 1995] 91,80 92,27 92,03 
Tableau 4 :  Résultats publiés obtenus par la méthode de l’apprentissage 
Les résultats donnés par [Argamon et al.1999], [Cardie et Pierce 1998] et [Cardie et Pierce 
1999] sont obtenus sans utilisation d’informations lexicales, seulement avec l’usage 
d’étiquettes des parties du discours. Par ailleurs [Ramshaw et Marcus 1995] ont rapporté un 
travail sur un corpus plus étendu pour lequel leur algorithme atteint une meilleure 
performance que le test précédent grâce au grand nombre de données. 
 
Travaux testés sur un corpus non 
annoté 
Précision
en % 
Rappel 
(calculé 
manuellement
en % 
F-mesure 
en % 
Reconnaissance des GN 92,8 99,71 96,13 
Tableau 5 :  Résultats obtenus par notre système 
Chapitre II : Etat de l’Art  75 
START 2003 
Une autre approche par rapport aux analyseurs conventionnels est celle des analyseurs de 
surface (shallow parsers) qui offrent des analyses partielles. Un shallow parser reconnaît 
quelques structures dans la phrase par exemples les nominatives sans aucune précision 
quant à leur structure interne ou leur rôle dans la phrase [Church 1988]. 
Le système LEXTER [Bourigault 1992] est un analyseur syntaxique de surface qui extrait 
des groupes nominaux de grande étendue depuis des textes français utilisés pour les 
processus d’extraction automatique de terminologie (terminology acquisition). Il apporte 
une reconnaissance des groupes nominaux de grande étendue de l’ordre de 95% mais la 
précision équivalente n’est pas mentionnée.  
Un autre système d’extraction de groupes nominaux de grande étendue est le NPTool 
[Voutilainen 1993]. Cet outil est basé sur un lexique construit manuellement et deux 
analyseurs d’état fini (finite state parsers) dont un est « l’ami » et l’autre « l’ennemi » des 
groupes nominaux. La combinaison de ces deux analyseurs produit une liste de groupes 
nominaux acceptables qui peuvent être utilisés par les applications d’extraction de 
terminologie. Ce système a été évalué sur un corpus de 20.000 mots contenant de textes de 
provenances diverses et atteint une précision de l’ordre de 95-98% et un rappel de 98-100%. 
Un autre parseur partiel efficace (partial parser) qui combine des étiquettes renforcées des 
parties du discours (part-of-speech tags) que l’on nomme aussi super-étiquettes (supertags) 
avec un analyseur de légère dépendance (lightweight dependency analyzer) est proposé par 
[Srinivas 1997]. Cet analyseur atteint une précision de l’ordre de 91,8% et un rappel de 
l’ordre de 93%. 
Un autre système le FACTUS [Hobbs et al. 1996] offre l’extraction d’information de textes 
anglais et travaille comme un automate en cascade non- déterministe (cascaded non-
deterministic automaton). Ce système au départ reconnaît des groupes nominaux et verbaux 
simples, basé sur une grammaire à l’état fini puis procède ensuite à la reconnaissance des 
groupes plus complexes en combinant les groupes simples déjà reconnus. Les mots 
inconnus sont ignorés de l’analyse sauf s’ils se trouvent dans un contexte où il y a la 
possibilité d’être des noms propres. La comparaison de FACTUS avec des systèmes plus 
76  Chapitre II : Etat de l’Art 
START 2003 
évolués montre qu’il s’agit d’une analyse satisfaisante, à l’aide de techniques simples et 
d’une reconnaissance rapide. 
Un analyseur syntaxique SYNTEX [Bourigault et Fabre 2000] est utilisé pour les corpus 
spécialisés, par exemple médicaux. Le résultat de l’analyse effectuée par SYNTEX est un 
réseau de mots et de syntagmes : un syntagme verbal (respectivement nominal, adjectival) 
est un groupe de mots dont la tête syntaxique est un verbe (respectivement nom, adjectif). 
Dans le réseau construit chaque syntagme est relié d’une part à sa tête et d’autre part à ses 
expansions. Les éléments du réseau (mots et syntagmes) sont appelés candidats termes. A 
chaque candidat terme sont associées un certain nombre d’informations numériques, sur 
lesquelles l’utilisateur peut se baser pour organiser son dépouillement par exemple la 
fréquence (nombre d’occurrences du candidat terme détectées par l’analyseur). La difficulté 
essentielle pour l’utilisateur vient de la masse des résultats issus de l’extraction, que seule 
l’expertise de l’analyste peut gérer (l’expérience a montré qu’aucune mesure statistique 
n’est suffisante). 
Un modèle de détection automatique de structures syntaxiques a été proposé par [Bernard 
2003] basé sur l’algorithme de [Harris 1968] qui procède à l’analyse de chaînes signifiantes 
sans connaissances préalables (recurrent stochastic dependency process). Les résultats 
demandent encore à être affinés mais cette approche donne la possibilité d’intégrer cet 
algorithme, moyennant un certain nombre d’adaptations, dans le traitement du langage 
naturel. 
Nous voyons actuellement un intérêt pour l’hypothèse harissienne selon laquelle il est 
possible d’induire des catégories sémantiques propres à un corpus à partir des régularités 
syntaxiques des mots qu’il contient [Harris et al. 1989], comme par exemple, les travaux 
dédiés à l’acquisition automatique de catégories sémantiques [Grefenstette 1994] en misant 
sur le recours à une analyse syntaxiques préalable pour recueillir des contextes pertinents, 
par opposition à un calcul fondé sur les cooccurrences au sein d’une fenêtre graphique (k 
mots à droite ou à gauche). Les résultats sur l’utilisation de Zellig, un autre outil 
d’acquisition de classes sémantiques, dans des corpus spécialisés [Bouaud et al. 1997], 
Chapitre II : Etat de l’Art  77 
START 2003 
montrent que les regroupements effectués constituent une bonne approximation des 
catégories conceptuelles. 
2.2.4.2. Analyse robuste 
Plusieurs applications du traitement des langues naturelles, comme la détection de 
l’information (information retrieval) [Lewis et Spärk 1996] ainsi que l’extraction de 
l’information (information extraction) [Cowie et lehnert 1996], nécessitent une analyse 
rapide et robuste de grands volumes de données sans restrictions. Dans ce genre de 
traitements ce qui compte le plus est la rapidité même si les résultats ne sont pas les 
meilleurs qui soient. 
Nous trouvons le terme d’analyse robuste dans les années ’70, mais récemment il est 
devenu en vogue à cause d’énormes quantités de données disponibles sous forme 
électronique, fait qui a stimulé la création de systèmes d’analyses robustes pour le 
traitement du langage naturel. Il est également utilisé dans le processus de la parole en 
intégrant des connaissances contextuelles [Görz et Hanrieder 1995]. Par analyse robuste 
(robust analysis ou robust parsing) nous désignons non seulement le processus qui traite 
partiellement tout texte grammaticalement incorrect [Weng 1993] mais aussi plus 
généralement les textes non annotés produits par des utilisateurs-finaux dans des situations 
variées. Pour [Chanod 1997] la robustesse consiste en l’exploration de toutes les 
constructions langagières qu’un humain puisse produire, grammaticalement acceptables, 
conformes aux modèles formels, peu importe leur fréquence. Car les phénomènes 
linguistiques aussi bizarres ou rares soient-ils doivent avoir une segmentation appropriée 
dans le texte analysé. 
[Briscoe 1994] mentionne que malgré les efforts de ces trois dernières décennies «  … no 
practical domain-independent parser of unrestricted text has been developed ». Un tel 
analyseur devrait produire une analyse correcte ou une analyse utile très proche de l’analyse 
manuelle (useful close analysis) pour plus de 90% des phrases en entrée. Il devrait 
également résoudre au moins les trois problèmes mentionnés ci-dessous, lesquels créent des 
78  Chapitre II : Etat de l’Art 
START 2003 
difficultés d’analyse aux analyseurs conventionnels qui utilisent des algorithmes d’analyse 
standards avec une grammaire générative. Ces trois problèmes sont les suivants : 
- chunking ou division du texte en unités syntaxiques appropriées, 
- disambiguation ou sélectionner l’analyse sémantique et pragmatique qui correspond 
parmi les solutions proposées, et 
- undergeneration ou comment traiter les entrées qui ne correspondent pas au cadre 
lexical ou syntaxique du système. 
Les analyseurs conventionnels échouent quant à leur tâche de retourner des informations 
utiles quand il sont sensés résoudre un problème de sous-génération ou de division-
classification par ailleurs, pour le problème de désambiguïsation, ils utilisent des 
informations sémantiques spécifiques détaillées sur le domaine qui est analysé.  
2.2.5. Le découpage en phrases et la ponctuation 
Les travaux concernant la détection automatique des phrases représentent un premier pas 
pour une analyse morphologique ou syntaxique et ne font pas l’objet d’une recherche. 
[Mikheev 1994] et [Say et Akman 1997] regroupent dans deux articles respectivement les 
travaux sur la détection de fin des phrases et la désambiguïsation de la ponctuation. D’un 
point de vue linguistique nous suivons le point de vue sémiotique de Harris pour qui l’écrit 
n’est pas simplement la projection de l’oral. Les signes écrits sont analysés selon le type 
d’activité (forme, processus et interprétation) qui jouent dans la phrase. Selon Harris : 
‘the disposition of written forms relative to each other within the graphic space’ 
devient important. Surtout pour le texte électronique où l’espace est dynamique (opposé au 
statique) et la hiérarchie des signes devient évidente. 
Les techniques utilisées (souvent des listes grammaticales et de longues listes 
d’abréviations) visent à reconnaître les cas les plus courants. Dans leur majorité ces 
techniques sont orientées vers la détection des phrases dans de corpus ou dans une langue 
de type donné, ce qui rend difficile leur adaptation à un autre type de textes ou à une autre 
langue sans avoir à modifier l’algorithme. De plus, puisque la détection de phrases est juste 
Chapitre II : Etat de l’Art  79 
START 2003 
une première étape dans le traitement automatique du langage naturel, elle ne doit pas 
demander trop de ressources ni de calcul au niveau de l’exécution. Donc, le développement 
d’un système basé sur de grandes listes d’abréviations, ou de lexiques spécialisés avec des 
informations qui ne s’utiliseront plus par la suite, n’est pas la meilleure solution. Say et 
Akman (mentionnés plus haut) donnent également un bref historique sur la ponctuation et 
sa place dans l’écrit d’aujourd’hui. Nous allons mentionner brièvement quelques uns de ces 
travaux qui indiquent un minimum d’erreur. 
Plusieurs travaux mentionnent l’utilisation d’un détecteur de phrases, mais aucune 
information sur sa conception ou sur sa performance n’est donnée [Voutilainen 1993]. 
L’approche la plus simple consiste à l’usage de règles qui reconnaissent des suites de 
caractères (par exemple : point – espace – lettre majuscule), accompagnées de longues listes 
d’exceptions pour les abréviations. La première grande classe de détection de fin des 
phrases utilise des règles construites manuellement qui codent des expressions des 
grammaires régulières accompagnées de listes d’abréviations et de noms propres. Un 
exemple est le programme Unix STYLE [Cherry et al. 1991] qui applique une liste 
d’abréviations et de noms propres aux mots qui précèdent et aux mots qui suivent les signes 
de ponctuation et prend une décision basée sur quelques heuristiques prédéfinies. Par 
exemple une des heuristiques impose la décision de fin de phrase à un point précédé d’une 
lettre majuscule seulement si le mot qui suit commence par une lettre majuscule et ce mot 
est un mot fonctionnel (ex. article). L’erreur mentionnée de ce programme est autour de 6%. 
[Mikheev 1994] propose une approche unique car elle traite simultanément le problème 
d’ambiguïté de fin des phrases, des noms propres et identification des abréviations, un 
utilisant un minimum de ressources pré requis. La méthode a été testée sur le corpus Brown 
et elle a atteint 99% pour la reconnaissance des noms propres et 99,3 – 99,7 % pour la 
détection des frontières des phrases. Les étiqueteurs des parties du discours traitent le 
problème de noms propres par exemple mais souvent ils présupposent un texte pré-traité où 
les tokens ont déjà identifié des phrases ainsi que des abréviations [Brill 1995], 
[Ratnaparkhi 1996]. 
80  Chapitre II : Etat de l’Art 
START 2003 
Une approche différente a été proposée par [Muller et al. 1980] : à la place des listes 
d’abréviations, une analyse morphologique filtre les mots ayant les mêmes suffixes, pour 
lesquels la probabilité d’être une abréviation est minime ou nulle. De telles approches 
demandent plusieurs heures de travail pour construire et renouveler les listes de règles et 
d’abréviations. De plus, elles sont orientées pour un type particulier de corpus.  
L’approche avec le plus grand taux de détection [Riley 1989] est basée sur un corpus annoté 
de 25 millions de mots. Sa performance pour le corpus Brown atteint 99,8%. Pour chaque 
mot du dictionnaire, ce modèle demande le calcul de probabilités qu’il soit le premier ou le 
dernier mot d’une phrase. Cette information est inutile aux analyses qui peuvent suivre 
morphologiques ou syntaxiques. 
De plus la détection n’est qu’un moyen pour permettre à divers outils d’effectuer leur 
analyse des phrases découpées, donc le coût de calcul doit être minime. C’est pour cette 
raison que [Reynar et Ratnaparkhi 1997] proposent un modèle basé sur la plus grande 
entropie qui ne nécessite aucun calcul ni le coût d’une information compliquée. 
L’information utilisée par ce modèle est fondée sur le segment (token) qui contient le signe 
de la ponctuation candidat pour la fin d’une phrase, ainsi que les autres tokens, juste avant 
et juste après celui-là. Pour la construction d’une liste d’abréviations extraite du corpus 
annoté, un algorithme simple est utilisé. L’approche de la plus grande entropie atteint 
97,7% de solution pour le corpus Brown, avec utilisation d’une liste manuellement 
construite d’abréviations, d’appellations et d’acronymes. Si on enlève cette information 
supplémentaire, le taux est de 97,5%. 
[Baldwin et al. 1997] mentionne dans le projet EAGLE un module de normalisation de 
casses (majuscule – minuscule). Ce pré-processus inclut un autre modèle, le détecteur de fin 
des phrases MAXTERMINATOR [Reynar et Ratnaparkhi 1997] (mentionnés plus haut). 
Les modules ne communiquent pas entre eux, le module de la normalisation utilise une 
heuristique qui dit que le mot en majuscule trouvé dans une position forte doit se convertir 
en mot en minuscule si le même mot a été trouvé dans le même document avec une lettre 
minuscule. Ils montrent également une base des données de bi-grams et de uni-grams des 
mots en minuscule et des mots en majuscule trouvés dans des positions sans aucune 
Chapitre II : Etat de l’Art  81 
START 2003 
ambiguïté. Cette base des données décide le changement en minuscule des mots qui 
commencent une phrase et des mots dans les titres ayant toutes les lettres en majuscule. 
Malheureusement aucune évaluation de performance ou autres détails sur cette méthode ne 
sont mentionnés dans l’article. 
Une autre approche est le système SATZ [Palmer et Hearst 1997], qui utilise un réseau 
neuronal pour la désambiguïsation des frontières d’une phrase appliqué sur un texte 
morphologiquement marqué. Il est basé sur des probabilités d’appartenance d’un mot à une 
partie du discours principale (prior part-of-speech). Par exemple, le mot portes peut être un 
verbe mais il est plus probable qu’il soit un nom selon les textes utilisés. Ce système utilise 
un dictionnaire de 30000 entrées lexicales et une information sur 6 différents tokens 
concernant leur contexte : 3 tokens avant et 3 après la fin candidate, et sa performance est 
de 98,5%, sur un corpus composé d’articles du Wall Street Journal. Le système SATZ peut 
être utilisé pour d’autres types de corpus ou d’autres langues naturelles après apprentissage 
effectué, puisqu’il n’utilise pas d’informations sur la capitalisation il peut être appliqué à 
une langue comme l’allemand. Le problème demeure du fait qu’il existe des types de 
corpus, ou même des langues, pour lesquelles des dictionnaires spécifiques contenant des 
informations sur les principales parties du discours ou sur la façon de les détecter 
automatiquement n’existent pas. Les auteurs insistent sur le fait que la performance du 
système n’est pas influencée par la diminution de la taille du dictionnaire. Même si cette 
information est vraie, et peut être utile par la suite à un autre traitement du langage, il y a 
des traitements pour lesquels elle ne s’y applique pas, comme l’alignement des phrases 
[Santos 2001] (sentence alignement).  
Il faut préciser que le système SATZ ainsi que l’approche de l’entropie maximale, ne 
distinguent pas les différents usages des signes de ponctuation qui montrent la fin d’une 
phrase, et qu’ ils utilisent les mêmes règles partout. Or, il y a des ambiguïtés qui ne sont pas 
traitées. Par exemple, un point peut être utilisé pour une abréviation mais ce n’est pas le cas 
d’un point d’interrogation ou d’un point d’exclamation. Pour la langue grecque nous 
pouvons citer le travail de [Stamatatos 2000], qui décrit un système de découpage en 
phrases basé sur la technique de transformation-based learning introduite par [Brill 1993]. 
Cette théorie, dont les applications comme par exemple le text chuncking [Ramshaw et 
82  Chapitre II : Etat de l’Art 
START 2003 
Marcus 1995] sont largement répandues dans le domaine du TALN, consiste à extraire 
automatiquement de la connaissance linguistique sous forme de règles à partir des corpus 
annotés. 
2.3. Situation de START dans ce contexte 
Nous avons présenté un panorama des travaux effectués dans le domaine du traitement 
automatique du langage en insistant sur les dernières méthodes systèmes d’analyse 
syntaxique. L’attention des analyseurs porte sur les résultats mais aussi sur l’affinité et la 
capacité du système à résoudre le maximum de problèmes rencontrés. Nous avons essayé de 
distinguer l’accumulation et la formalisation des ressources syntaxiques nécessaires pour les 
différentes méthodes appliquées (artisanales ou basées sur des corpus annotés, ou utilisant 
des formalismes motivés d’une théorie linguistique ou ad hoc) en montrant leur utilisation 
informatique directe (en désambiguïsation, analyse syntaxique, étiquetage). Bref, nous 
constatons que ce qui était une simple application de techniques d’analyse des langages a 
conduit à l’émergence d’un véritable domaine de recherche.  
Notre système n’utilise aucune connaissance préalable et respecte les conditions de 
robustesse, il procède à : 
- la reconnaissance et extraction des syntagmes syntaxiques, 
- l’étiquetage partielle des composants des syntagmes 
- la désambiguïsation du cas ambigu entre article défini et pronom personnel 
- la création d’un dictionnaire par catégorie grammaticale. 
Nous verrons ensuite les options et les décisions prises pour réaliser notre système de 
l’analyse superficielle, START. 
 
Anna PAPPA, Université PARIS VIII, Labo d’I.A., Programmation Holistique, groupe CSAR 
 
 
 
 
 
Chapitre III 
 
 
METHODOLOGIE 
 
84  Chapitre III : Méthodologie 
START 2003 
Sommaire du Chapitre III 
 
METHODOLOGIE 
3.1. Principes pour la création d’un système 
3.2. Lignes théoriques 
3.3. Les outils 
3.4. De la méthode vers l’algorithme 
Chapitre III : Méthodologie  85 
START 2003 
“It will be bags of tricks and not 
theory that would advance 
computational linguistics in the 
future” 
[Bar-Hillel 1964] 
 
Nous abordons dans ce chapitre les aspects méthodologiques qui nous ont amené à choisir 
tel ou tel processus pour l’analyse superficielle des parties du discours. Nous exposons le 
processus de gestion des connaissances (par exemple la grammaire correspond aux 
connaissances syntaxiques décrites dans des modèles linguistiques) puis comment gérer ces 
connaissances nécessaires pour développer notre algorithme de reconnaissance. La méthode 
d’application et le système réalisé consistent en un système à base de règles créées à partir 
des statistiques effectuées sur l’ensemble du corpus. Les statistiques portent sur la 
distribution et l’ordre des mots et leur relation avec leur environnement. Nous explorons les 
statistiques et les outils qui nous permettent d’aboutir à notre algorithme de l’analyse 
syntaxique de surface qui n’utilise pas de connaissances lexicales préalables.  
3.1. Principes pour la création d’un système 
La première étape dans la réalisation d’un système (informatique) consiste en 
l’identification des connaissances susceptibles d’intervenir dans le processus de la 
reconnaissance (ou plus étendu : la compréhension). Pour déterminer l’interprétation d’une 
expression écrite, on se concentrera essentiellement sur les connaissances lexicales, 
syntaxiques, sémantiques et pragmatiques. Un travail important réside dans la manière 
d’utiliser les différentes sources de connaissances. Une approche assez commune consiste à 
émettre des hypothèses aux différentes étapes du traitement, en s’appuyant à la fois sur les 
connaissances disponibles et sur des indices variés issus des données. Ces hypothèses sont 
ensuite vérifiées ou annulées par d’autres sources de connaissances. 
Nous allons présenter un schéma général permettant la coopération efficace des différentes 
sources de connaissances pour tout domaine d’application. Le diagramme qui suit 
86  Chapitre III : Méthodologie 
START 2003 
représente la structure générale d’un système de compréhension. Cette structure est 
applicable dans plusieurs domaines de l’IA où la complexité de la tâche rend nécessaire 
l’utilisation de sources d’informations variées, par exemple le traitement de la langue. 
Chacune des sources de connaissances (SC) possède son propre mécanisme d’activation 
(MA). Un programme d’activation permet l’utilisation des connaissances appropriées au 
cours du traitement.  
Les sources de connaissances qui interviennent dans un système de traitement automatique 
du langage comportent des éléments de natures différentes, par exemple, morphologiques, 
syntaxiques, sémantiques, pragmatiques et contextuels [Sabah 1988]. L’utilisation d’une 
seule catégorie crée des ambiguïtés qui ne sont pas dues au langage lui-même 
(interprétation selon les connaissances utilisées). Les architectures des systèmes sont 
souvent modulaires pour refléter les séparations artificielles entre toute les connaissances. 
 
 
 
 
 
 
 
 
Figure 3 :  Diagramme d’un système de compréhension. 
Mécanisme 
d’Activation n 
Tout domaine d’application 
Source de 
connaissances 1 
Source de 
connaissances 2
Source de 
connaissances n 
Mécanisme 
d’Activation 2
Mécanisme 
d’Activation 1 
Programme qui active 
les mécanismes 
TRAITEMENT ENTREE SORTIE 
Chapitre III : Méthodologie  87 
START 2003 
3.2. Lignes théoriques 
Nous allons suivre les démarches distributionnalistes de [Benveniste 1966] concernant le 
nom en fonction sujet afin de trouver le départ pour l’analyse du substantif en espérant 
dégager une entité substantif-sujet. Seule une confrontation avec les autres fonctions du 
substantif et avec les autres types de sujets permettrait d’isoler le substantif pur. Nous allons 
donc écarter tout ce qui, en fonction sujet, est autre chose qu’un nom : propositions (sujets), 
infinitifs, pronoms (personnels, indéfinis, numéraux, interrogatifs, relatifs). Nous disposons 
d’un constituant nominal, dont il faut isoler le noyau, et ici on rencontre le problème de 
distinction entre déterminé et déterminant. Il y a trois types de noms sujets : 
 
Nom + Verbe   
Prédéterminant + Nom  + Verbe 
Nom + Nom  + Verbe 
Le premier cas est rencontré dans les traits de la syntaxe de télégrammes par exemple (lettre 
suit), ou bien dans le cas de construction de proverbes et maximes comme (pauvreté n’est 
pas vice) ou bien l’usage des noms employés sans déterminant devant un verbe au passif 
comme il s’entend souvent à la radio par exemple dans les phrases hommage lui fut rendu 
par ... ou satisfaction a été accordée aux demandes ... Ce dernier groupe semble très limité 
et les caractéristiques apparentes sont les suivantes : ces passifs correspondent tous à une 
locution verbale du type verbe + nom sans article comme « prendre rendez-vous ». Le 
passif est impossible avec : prendre feu, froid, date, femme ... de plus la négation est 
impossible (sauf avec ne ...que) ; le pronominal est impossible ; l’expression de l’agent 
semble dans la plupart des cas impossible. 
# N’importe quel nom employé devant un verbe, en dehors de ces restrictions, sera 
nom propre ; Claude m’a dit..., Monsieur désire ... ? sont des noms propres. Le nom 
propre sans article se laisse donc isoler, en dehors de toute considération de signifié, 
par une simple approche syntaxique. 
88  Chapitre III : Méthodologie 
START 2003 
# Dans le deuxième cas, les prédéterminants du substantif sont les articles, l’adjectif 
possessif, l’adjectif démonstratif, les indéfinis et l’interrogatif.  
 
Ce + que + a) pronom personnel (70-80%) 
    b) les autres déterminants composent le reste 
Ce + qu’ + Pronom (100%) 
Ce + qui + a) Verbe (75-85%) 
    b) Pronom personnel (le reste 15-25%) 
Tableau 6 :  structures avec ce 
Le tableau ci-dessus nous montre le pourcentage de différentes constructions des syntagmes 
qui commencent par ce. 
En général le pourcentage de présence de ce + {qui, que, qu’} est faible ; il atteint 2 à 5% 
pour chaque texte (cela dépend des textes). Le c’ étant toujours suivi d’une forme fléchie ou 
canonique du verbe être, ne représente pas un cas difficile à définir et ne fait pas partie de 
GN. 
Dans notre corpus nous avons isolé la distribution suivante : 
Chapitre III : Méthodologie  89 
START 2003 
ce + subst + adject + , + comme  
ce + subst + adject + au + milieu de 
ce + subst + adject + ? +   
ce + adject + Nom Propre +  +   
ce + subst + où +  +   
ce + adject + subst + , + dont  
ce + subst + « , » ou « . » +  +   
ce + subst + - + ci / là +   
ce + subst + qui +  +   
ce + subst + que +  +   
Tableau 7 :   structures avec ce 
Tout particulièrement pour la détermination des groupes substantifs la démarche a été basée 
sur le travail de [Bernard 1994] présenté dans l’article : typologie neuromimétique des 
substantifs, où l’on voit que pour détecter des substantifs dans un texte, on cherche ce qui 
prédit leur présence, une marque grammaticale. Nous reprenons l’idée de G. Bernard qui est 
la suivante : 
« les différents types sémantiques de substantifs (noms de parties du corps, noms abstraits, 
noms d’individu, etc.) influent sur l’emploi des marques de repérage, du nombre, et sans 
doute aussi sur le choix des prépositions ». [Bernard 1994] 
Plusieurs types de marques grammaticales sont utilisés pour effectuer les statistiques sur la 
distribution quantitative de leur emploi. Ceci pourrait être un outil précieux de « typage » 
sémantique grossier des noms. 
3.2.1. Définition des parties du discours 
La définition des parties du discours est un point essentiel car la distribution des parties du 
discours varie largement d’une langue à l’autre et ses différences sont d’une grande 
conséquence pour la structure des systèmes syntaxiques. Il faudra donc, étudier et analyser 
chaque ensemble de distribution afin de pouvoir déterminer les différentes classes de 
90  Chapitre III : Méthodologie 
START 2003 
constituants. Pour déterminer ces classes il faut d’abord les définir. Nous renvoyons ici à  
concernant la procédure de détermination – définition : 
« Mais quand il s’agit de les définir, il faut – au moins, dans l’idéal – décrire la totalité de 
leurs caractéristiques morphologiques et syntaxiques (en premier lieu, les fonctions 
qu’elles peuvent remplir, mais aussi les morphèmes avec lesquels elles sont compatibles, et 
(...) l’ensemble des contraintes distributionnelles qui les caractérisent, et enfin les 
transformations et autres opérations auxquelles elles peuvent donner lieu, etc.). Seule une 
définition des parties du discours la plus complète possible peut permettre de dégager leur 
distribution d’ensemble et, de là comprendre leur articulation avec les autres dimensions 
du système de la langue (...) ». [Lemaréchal 1989] 
Nous allons, donc, étudier la fonctionnalité et la distribution quantitative des différentes 
catégories et classes grammaticales dans la phrase, afin de reconnaître les syntagmes 
substantifs. 
3.2.2. Analyse distributionnelle 
Le terme distributionnalisme désigne le courant linguistique des années 1930 apparu aux 
Etats-Unis avec Leonard [Bloomfield 1933] et ses disciples comme Zelling [Harris 1954]. 
Ses racines se trouvent dans les besoins de décrire des langues très différentes du modèle 
indo-européen, en conséquence les préoccupations théoriques sont réduites au strict 
minimum indispensable au travail descriptif. L’analyse distributionnelle fait partie de la 
linguistique structurelle où les éléments de la langue se définissent par leurs relations à 
l’intérieur d’une phrase, on parle des relations syntagmatiques. Les postulats théoriques sont 
les suivants : 
a. l’objet d’étude est la langue par opposition à la parole, 
b. l’étude est synchronique (car les langues sont souvent seulement parlées, sans 
écriture), 
c. la langue est composée d’unités discrètes, que la segmentation permet de 
dégager. 
Chapitre III : Méthodologie  91 
START 2003 
Bloomfield procède à une segmentation de l’énoncé linguistique en unités – la phrase est 
segmentée en constituants immédiats, puis en morphèmes, dont il étudie la distribution et 
classe les variantes. Il élabore une théorie béhavioriste qui refuse l’approche mentaliste et la 
prise en compte du sens des énoncés pour ne travailler que sur les comportements associés à 
l’usage des énoncés. La communication y est ramenée de façon presque mécanique, au 
modèle stimulus-réponse détaillé dans son ouvrage « le langage » qui est consacré à la 
linguistique descriptive et qui restera longtemps la référence pour tous les linguistes 
américains, en particulier Z. Harris. En même temps en Europe, les théories de Ferdinard de 
[Saussure 1960], pratiquement inconnu aux Etats Unis, se rapprochent de celles de 
Bloomfield. Plus tard on appellera ce courant, des deux côtés d’Atlantique, la linguistique 
structurale. 
La volonté de Harris de renforcer la cohérence théorique de l’analyse linguistique, l’amena 
à formuler les principes de l’analyse distributionnelle. Il nous enseigne comment décrire la 
structure d’une langue (appelée procédure de découverte par [Chomsky 1969]). Il repousse 
lui aussi l’utilisation du critère de sens, et tente de fonder la linguistique sur l’inventaire de 
la distribution de constituants de la phrases, c’est-à-dire les morphèmes et les phonèmes, 
dans leur environnement, c’est-à-dire leur contexte. Dans un premier temps il faut réunir un 
corpus, autrement dit un ensemble d’énoncés qui sera l’échantillon de la langue. Il est 
préférable que le corpus soit homogène et représentatif. Une fois le corpus assemblé on le 
segmente. On cherche à rapprocher des morceaux d’énoncés comparables, dont la 
comparaison permet de déterminer quels sont les morphèmes dont les différences de forme 
correspondent à des différences de sens. La conception de Harris du rapport entre la syntaxe 
et la sémantique se fonde alors sur la distribution des mots dans les phrases. L’hypothèse 
distributionnelle met en relation la distribution syntaxique des mots (ou unités) avec leur 
contenu informationnel :  
(…) La signification des unités et de leur relations grammaticales est liée à la restriction 
imposée sur les combinaisons de ces unités avec d’autres (…). [Harris 1954] 
Harris a proposé une conception de la distribution (de la cooccurrence) qui permet de relier 
les phrases entre elles, d’où la notion de transformation, et de là aussi la possibilité de 
92  Chapitre III : Méthodologie 
START 2003 
dépasser la phrase pour passer à l’analyse du discours. Sa théorie évoluera par la suite vers 
une linguistique transformationnelle. 
A partir de la notion de sous-langage définie par [Harris 1968] a été développée une 
méthode d’analyse de corpus pour mettre au jour les classes de mots e les structures (ou 
modèles) syntaxiques caractéristiques ‘une langue spécialisée. Dans les travaux de Harris, 
l’analyse et la normalisation syntaxiques sont effectuées à la main. Dans la communauté du 
traitement automatique des langues, un certain nombre de travaux ont été menés pour 
exploiter le principe de l’analyse distributionnelle, dans lesquels l’analyse syntaxique 
initiale est réalisée par un analyseur syntaxique [Hirshman et al. 1975], [Sager et al. 1987], 
[Hindle 1990], [Grefenstette 1994]. 
Dans la communauté française ce type d’approche est principalement convoité depuis le 
milieu des années ’90 pour l’ingénierie des connaissances [Assadi et Bourigault 1995], 
[Habert et Nazarenko 1996]. Et plus récemment est devenu un outil pour l’exploitation des 
corpus. Le module d’analyse distributionnelle UPERY [Bourigault 2002] exploite 
l’ensemble des données présentes dans le réseau pour effectuer un calcul des proximités 
distributionnelles entre les mots et syntagmes du réseau. Les données de l’analyse sont 
construites à partir des liens de dépendance présents dans le réseau : chaque lien dans le 
réseau de dépendance produit une ou plusieurs informations élémentaires pour l’analyse 
distributionnelle. Il s’agit de l’analyse distributionnelle dite « étendue » car cette méthode 
prend en compte non seulement des mots mais aussi des syntagmes, que ce soit en tant que 
terme ou en tant que contexte. Il faut préciser que ce module est appliquée après l’analyse 
syntaxique des phrases de corpus et la construction du réseau de dépendances. 
Après ces descriptions théoriques et pratiques nous exposerons les divers outils employés 
qui nous ont permis d’avancer dans notre étude et de former un algorithme de 
reconnaissance syntaxique. 
Chapitre III : Méthodologie  93 
START 2003 
3.3. Les outils 
Dans cette section nous essaierons d’exposer les différents outils qui sont employés au sein 
de notre système ainsi que les différents emplois les plus courants des mots grammaticaux 
dans la phrase. Nous étudierons, également, leur comportement entre eux et entre les 
lexèmes de leur contexte, dans la perspective de faire émerger les régularités des marques 
qui servent comme limiteurs de l’étendue d’un groupe syntaxique. Grâce aux descriptions 
des différentes fonctions des mots grammaticaux que nous avons vu dans le premier 
chapitre, nous avons pu effectuer des statistiques sur les occurrences des mots 
grammaticaux, afin de créer notre base des règles. Les statistiques à leur tour nous ont 
permis de dégager les informations nécessaires sur la nature des syntagmes substantifs et 
d’élaborer, finalement, la table des règles qui permet la détermination d’un syntagme dans 
son étendue. 
3.3.1. Le corpus 
Afin d’aboutir à ce processus de règles, qui sont généralement créées à partir des 
particularités du contexte ainsi que de la fréquence de la distribution, nous avons besoin 
d’un corpus de textes pour assurer la validité des statistiques que nous avons effectuées 
dans le contexte des mots grammaticaux étudiés. Le texte est un ensemble cohérent d’unités 
plus ou moins complexes, une manifestation particulière de l’activité d’écriture. Chaque 
unité s’articule avec les autres et contribue à la réalisation d’un équilibre global. Ainsi la 
présence ou l’absence d’une ponctuation est significative, la position d’un mot, d’une 
phrase n’est jamais fortuite. Il nous faut donc un corpus [Dewitte 1998] qui fournisse à la 
fois un nombre d’apparitions suffisant et une diversité importante d’emploi des termes 
analysés. 
Le recours aux corpus n’a jamais cessé comme source d’information dans les années 1960 – 
1980 même si les partisans de cet empirisme se sont vu opposer un faux procès d’intention, 
celui du retour au positivisme [Clément 2001]. En langue anglaise le Brown Corpus a été 
construit dès 1961 par [Francis et Kučera 1961] aux Etats Unis et le Survey of English 
Usage en 1959 par R. Quirk en Grande Bretagne. En France, l’INaLF a constitué une base 
94  Chapitre III : Méthodologie 
START 2003 
de textes littéraires gigantesques (160 million de mots) pour construire le Trésor de la 
Langue Française (T.L.F.). Les textes ont été compilés depuis les années 60 et ont été 
informatisés dans la base Frantext. Les corpus aujourd’hui deviennent de plus en plus 
représentatifs par leur taille mais aussi par leur qualité d’échantillonnage et d’annotation. 
Les résultats statistiques sur ces corpus rendent légitimes des hypothèse que nous n’aurions 
pas pu faire par la simple intuition. La linguistique de corpus en ce sens est une nouvelle 
technologie qui construit et exploite de nouvelles ressources. Les corpus annotés lui 
reviennent comme source première. Ainsi les corpus informatisés peuvent faire l’objet 
d’études statistiques pour entraîner des systèmes stochastiques. Les corpus annotés servent 
à évaluer des systèmes d’étiquetage automatique, d’analyse syntaxique automatique, et pour 
cela il est nécessaire qu’ils aient été corrigés à la main afin de se confronter avec les 
résultats attendus. La construction d’un corpus annoté revient aussi comme expérience de 
l’analyse automatique. La technologie mise en œuvre pour annoter un corpus suppose un 
ensemble de traitements automatiques portant sur des productions langagières dont on ne 
sait rien a priori. Il s’agit d’une procédure d’analyse robuste. 
Nous mentionnons au passage que le problème lors de la constitution d’un corpus est 
d’obtenir une représentation la plus juste de la langue étudiée, c’est-à-dire obtenir un corpus 
équilibré. Les deux approches habituelles utilisées pour les sondages sont les suivantes :  
# la méthode des quotas où le corpus que l’on utilise doit comporter des textes choisis 
selon un découpage très précis de la langue en différents domaines ; 
# la méthode probabiliste où les textes sont pris au hasard, mais où leur quantité très 
importante assure une bonne représentativité. 
Pour l’obtention des textes sur support informatique l’équipe CSAR a eu recours 
principalement à l’A.B.U. (Association des Bibliophiles Universels) hébergé par le CNAM 
et qui offre des textes d’époques différentes. L’objectif était d’avoir un ensemble de textes 
littéraires contemporains, car cela donne la possibilité d’étudier des thèmes et des styles 
différents sans cible particulière. Le corpus actuel dépasse 40.000.000 de mots. 
Chapitre III : Méthodologie  95 
START 2003 
Le corpus grec se compose de textes recueillies pour la plupart dans sur le web et sont des 
articles de journaux quotidiens ou hebdomadaires. Aussi-existe-t-il une partie constituée de 
romans électroniques. Ce corpus qui ne cesse de grossir comporte 120.000 mots. 
L’étude sur les fonctions et la distribution des parties du discours est appuyée sur notre 
corpus. Nous utilisons ce terme dans le sens habituel de la linguistique, à savoir un 
ensemble de textes regroupés autour d’un thème ou à partir d’une utilisation précise. Dans 
ce but nous utilisons un corpus de textes qui offre une quantité suffisante d’emplois de 
chaque déterminant dans différents contextes.  
3.3.2. Méthodes statistiques 
Les statistiques consistent à faire émerger les régularités des occurrences des mots 
grammaticaux. Nous donnons quelques résultas des statistiques effectuées sur le corpus afin 
de pouvoir juger les signes nous permettant de définir un syntagme en son étendue ainsi que 
dans ses limites. A partir de ces observations nous avons traité le corpus d’une façon 
empirique pour extraire les meilleurs résultats en respectant toujours le seuil ne devant pas 
dépasser 1 %. 
La ponctuation est traitée comme des mots, car les statistiques effectuées ont montré qu’elle 
est significative quant à l’étendue d’un syntagme substantif. La ponctuation, qu’elle soit 
placée juste après le déterminant ou après le premier substantif qui suit le déterminant , est 
toujours un point d’arrêt. Suite au tableau ci-dessous concernant la ponctuation, nous 
remarquons que la place la plus fréquente (26,87%) de la ponctuation se situe dans le 
deuxième contexte (CD2) après le déterminant. Et dans ce cas, il n’y a aucune erreur de 
décision quant aux frontières d’un groupe nominal. Les résultats qui sont présentés dans le 
dernier chapitre nous le montrent. Par contre, dans le tableau de la présence de la 
ponctuation dans le contexte des pronoms, nous observons que le pourcentage le plus élevé 
se trouve dans le contexte gauche immédiat (CG1) des pronoms. 
 
96  Chapitre III : Méthodologie 
START 2003 
Ponctuation en % de présence selon le contexte des déterminants 
CG3 CG2 CG1 CD1 CD2 CD3 CD4 CD5 CD6 
11,24 11,70 14,87 
Déterm
inants 
0,43 26,87 10,89 11,78 13,96 12,21 
Tableau 8 :   présence de signes de ponctuation dans le contexte gauche et droit des 
déterminants 
Le tableau nous montre que la fréquence d’apparition de la ponctuation reste également 
assez élevée dans d’autres contextes. 
Ponctuation en % de présence selon le contexte des pronoms 
CG3 CG2 CG1 CD1 CD2 CD3 CD4 CD5 CD6 
14,77 18,08 49,01 
Prono
ms 
5,01 8,82 9,92 11,07 13,07 14,26 
Tableau 9 :   présence de signes de ponctuation dans le contexte gauche et droit des pronoms 
Le déterminant se place toujours à gauche du substantif. Le déplacement parfois possible du 
mot entraîne une modification de sens : le déterminant devient adjectif qualitatif, mais ceci 
est possible avec des déterminants secondaires. Nous avons donc a) les déterminants 
spécifiques qui ne peuvent se combiner entre eux et b) les déterminants secondaires, qui 
peuvent se combiner avec les déterminants spécifiques. 
Nous adoptons la position de [Bernard 1998] concernant les déterminants, car d’un point de 
vue informatique pratique, pour l’implémentation, la position de [Forsgren 1978] 
impliquerait d’intégrer aux marques une liste infinie ; la liste des cardinaux étant infinie. 
Donc, dans notre algorithme, seuls un / une seront traités en tant qu’articles indéfinis. 
 
Chapitre III : Méthodologie  97 
START 2003 
Figure 4 : La présence de la ponctuation dans le contexte des déterminants (présentés 
par la ligne verticale noire). 
La figure qui suit donne le pourcentage de fréquence des certaines classes des mots dans le 
corpus.  
 
Ponctuation
CD6CD5
CD4CD3
CD2
CG1
CG2
CG3
CD1
0
5
10
15
20
25
30
35
40
45
50
55
%
Déterminants
Pronoms
Contexte Gauche Contexte Droit
98  Chapitre III : Méthodologie 
START 2003 
Figure 5 :  La répartition des mots grammaticaux dans le texte 
Les relatifs du CD1 sont essentiellement précédés du déterminant ce, mais l’on trouve 
également un ou une, certains et quelqu’un. La décision renvoie immédiatement à 
« subordonnée relative » et il n’y a pas d’erreur. Pour les relatifs d’autres contextes nous 
avons utilisé comme marque d’arrêt le relatif jusqu’au CD4, nous n’avons pas voulu 
marquer les CD5 et les CD6 car il est rare qu’un syntagme substantif atteigne le CD5 et soit 
suivi immédiatement d’un relatif. 
Il faut mentionner que pour l’élaboration des règles concernant les démonstratifs, on a retiré 
du nom toute finale en –ci, -là. Les marques {ce, le, la, l’, les, leur} ne sont pas ambiguës 
quand elles précèdent les noms au pluriel commençant par une majuscule (les Gaules, était-
ce Max, l’Odéon). Dans ce cas on vérifie le contexte gauche (ci-après CG) de ces marques 
en observant si elles sont précédées d’une autre marque grammaticale comme le ton, l’une, 
ton son, etc. Si tel est le cas le premier mot est normalement une marque grammaticale 
(nominale) et le deuxième un lexème. Ce test n’est pas sûr à 100%, car il y a des 
occurrences de marques suivies d’un mot qui ne fait pas partie des substantifs comme dans 
l’exemple il m’en a donné un pour lui et un pour moi, ou un des enfants, etc. Dans notre 
programme on regroupe ces cas avec les autres. A la fin, on peut effectuer une analyse plus 
Les types des mots dans le texte
65%4%
6%
12%
4%
9%
Reste
Relatifs
Pronoms
Déterminants
Conjonctions
Prépositions
Chapitre III : Méthodologie  99 
START 2003 
fine, une fois que l’on a mis les mots qui font partie du contexte droit (ci-après CD) dans le 
dictionnaire, on fait un tri en donnant une liste des mots « non substantifs », et pour ceux 
qui en font partie, comme les mots pour ou de, nous les excluons du dictionnaire. 
Il y a des GV reconnus par le traitement de la reconnaissance des groupes nominaux, il 
s’agit surtout de règles qui consistent à désambiguïser les cas qui peuvent prêter à confusion 
avec les syntagmes substantifs. L’inverse se fait également avec le système de 
reconnaissance des Groupes Verbaux. 
Nous évoquerons les règles qui consistent à évaluer la place des relatifs et des déterminants. 
Les relatifs peuvent être sujet à confusion ; selon leur place dans le contexte ils peuvent 
donner des décisions pour les syntagmes substantifs ainsi que pour les syntagmes verbaux. 
Pour les déterminants nous avons utilisé des règles de marque d’arrêt jusqu’au CD3, car 
chaque déterminant est traité séparément, donc nous le traitons comme marque d’arrêt. Le 
déterminant n’est pas toujours par lui tout seul une marque d’arrêt, il est souvent précédé 
par une préposition. En effet les règles qui concernent les déterminants sont composées 
avec l’emploi des prépositions. 
3.2.3. Vers une méthode 
La stratégie de la détection des groupes syntaxiques a été élaborée à partir de l’observation 
des tableaux de statistiques effectuées sur la distribution du contexte des mots 
grammaticaux. 
Pour la détection des groupes syntaxiques dans la phrase nous nous basons sur les marques 
grammaticales et syntaxiques. Afin d’atteindre notre objectif nous devons étudier les 
fonctions des mots grammaticaux ainsi que leur distribution dans la phrase. Le problème de 
la distribution des marques grammaticales qui déterminent les substantifs ainsi que les 
parties du GN (déterminants, substantifs, épithètes), et celui de la distribution et du rôle des 
adjectifs, sont des problèmes ouverts et font jusqu’à aujourd’hui l’objet de nombreuses 
recherches. La base de données s’impose lorsqu’on veut manipuler et échanger une quantité 
100  Chapitre III : Méthodologie 
START 2003 
importante de données à travers un standard. La base de données textuelles est un outil qui 
permet d’analyser les phénomènes distributionnels. Cette base nous donne la possibilité 
d’effectuer de nombreuses recherches sur les rapports qu’entretiennent les mots entre eux et 
dans leur contexte. L’utilisation du langage standard SQL nous permet une liberté, relative 
aux architectures logicielles spécifiques dans lesquelles pourrait être utilisé notre système. 
L’apport distributionnaliste établit des filtrages successifs comme l’orientation, la 
commutation, la compatibilité, la hiérarchie, la forme, la nature etc. Ces notions consistent 
à déterminer les rapports entre des segments qui entourent le noyau substantif et le noyau. 
Par exemple, l’orientation d’un segment donné par rapport au substantif-noyau, consiste à 
dissocier des pré-déterminants (ex : certains gens) des post-déterminants (ex : chien noir). 
Le compromis fonctionnaliste commence par [Mahmoudian 1970] et [Buyssens 1975] qui 
considèrent comme critère décisif la compatibilité ou l’incompatibilité des déterminants1 en 
faisant une synthèse du formalisme et de la tradition scolaire. 
Tous les mots ont : une nature (une identité, ce qu’ils sont), qui est liée à leur sens ; une 
fonction (le rôle qu’ils jouent dans une phrase ou un groupe particulier, ce qu’ils y font), qui 
s’analyse. La nature n’est pas déterminée par la fonction : elle peut être trouvée dans le 
dictionnaire (ex : n.m., adv., prép.). Plusieurs fonctions peuvent être remplies par des mots 
de natures différentes (ex : le COD : elle veut du pain (nom) / elle veut manger (infinitif) / 
elle en veut (pronom). Les difficultés qui se présentent sont les suivantes : 
• Un même mot peut avoir plusieurs identités, c’est-à-dire plusieurs natures, selon les 
groupes et les combinaisons dans lesquels il entre (ex : l’ambiguïté entre pronom 
personnel et article défini !). 
• Un même mot peut avoir des rôles, des fonctions diverses selon la phrase ex. : apprendre 
est difficile (sujet) / J’aime apprendre (COD).  
                                                   
1. Voir chapitre II. « Etat de l’art » pour plus de détails sur les déterminants. 
Chapitre III : Méthodologie  101 
START 2003 
On doit, donc, partir pour notre analyse, de définitions syntaxiques ; il n’est pas possible de 
s’appuyer sur des définitions sémantiques pour distinguer les parties du discours. La 
distribution des parties du discours n’en détermine pas moins un certain découpage du réel, 
qui constitue un premier aspect de la sémantique de la syntaxe. Selon [Lemaréchal 1989], si 
la description du linguiste s’appuie sur des critères syntaxiques, l’encodage par le locuteur 
passe par les catégorisations de la langue dans laquelle il va s’exprimer ; le locuteur doit 
analyser le réel dans la perspective des structures et possibilités que lui offre la langue ; 
c’est pour cette raison que la sémantique de la syntaxe donne la possibilité de 
l’interprétation d’un énoncé. 
Pour notre système les ressources utilisées pour la définition des règles qui analysent les 
phrases sont réduites à un lexique qui comporte des mots grammaticaux ou mots clés 
(keywords) c’est-à-dire les pronoms personnels, les articles, les prépositions, les 
conjonctions, et quelques types fléchis du verbe auxiliaire être et avoir. Pour les tests sur la 
langue grecque les désinences des verbes étant significatives sont utilisées également. 
Notre étude essaie de réduire le plus possible les données de l’analyse, en profitant des 
particularités des langues. Le français est une langue bien ordonnée si nous la comparons à 
la langue grecque, qui est une langue sans pré définition d’ordonnance des mots qui 
composent une phrase (quasi-free word order). La langue grecque a une morphologie très 
complexe puisqu’elle est composée d’une pléthore de catégories clitiques. L’observation 
empirique a montré que les désinences des verbes sont dotées de caractéristiques uniques 
qui peuvent amener à des conclusions avec une grande précision, a contrario, en français les 
désinences ne peuvent pas jouer un rôle de critère infaillible car il peut y avoir des 
ambiguïtés. Pour le grec, il faut aussi mentionner l’usage particulier des déterminants qui 
sont utilisés même avant les noms propres. Ex. : Η µεγάλη µου αδερφή, η Μαρία, έφυγε 
χτες για το νησί. ***/ La grande à moi sœur, la Marie, est partie hier pour l’île./ 
Nous présentons dans le tableau qui suit la liste des mots grammaticaux utilisés pour 
l’analyse syntaxique. Nous n’avons pas eu recours aux désinences des verbes. Cette 
approche, contrairement à la philosophie des approches coûteuses des ressources 
102  Chapitre III : Méthodologie 
START 2003 
exhaustives, remplace parfaitement les dictionnaires volumineux des lemmes dotés 
d’informations morphologiques et grammaticales. 
Chapitre III : Méthodologie   103 
START 2003 
N° Adverbes Prépositi
ons 
Conjonctions 
Disjonctions 
Verbe 
Auxiliaire 
Détermi
nants 
Ponctuatio
n 
Pronoms 
Personnels 
Pronoms 
Toniques 
Relatifs Pronominaux Négation Pronom 
Possessif 
1 
2 
3 
4 
5 
6 
7 
8 
9 
10 
11 
12 
13 
14 
15 
16 
17 
18 
19 
20 
21 
22 
23 
24 
25 
26 
27 
28 
29 
trop 
tellement 
bien 
beaucoup 
parce 
tant 
plus 
peu 
moins 
encore 
enfin 
soudain 
aussi 
maintenant 
toujours 
 
avec 
sans 
par 
de 
dans 
en 
à 
pour 
parmi 
sur 
sous 
vers 
après 
avant 
devant 
depuis 
selon 
derrière 
hors 
chez 
 
et 
ou 
mais 
quand 
comme 
si 
quoi 
comment 
car 
 
ai 
as 
a 
avons 
avez 
ont 
suis 
es 
est 
sommes 
êtes 
sont 
aurai 
auras 
aura 
aurons 
aurez 
auront 
aurais 
aurait 
aurions 
auriez 
auraient 
aient 
soient 
fût 
ait 
soit 
un 
une 
de 
du 
la 
le 
l’ 
les 
des 
aux 
mon 
ton 
son 
ma 
ta 
sa 
mes 
tes 
ses 
ce 
ces 
cette 
chaque 
certains 
certaine 
certaines 
quelques 
certain 
quelque 
. 
? 
, 
! 
... 
; 
: 
- 
 
je 
tu 
il 
elle 
nous 
vous 
ils 
elles 
le 
la 
les 
l’ 
lui 
leur 
y 
en 
moi 
toi 
lui 
elle 
nous 
vous 
eux 
elles 
 
que 
qui 
qu’ 
où 
dont 
 
me 
m’ 
te 
t’ 
se 
s’ 
nous 
vous 
 
ne 
ni 
n’ 
pas 
guère 
plus 
point 
aucun 
aucune 
rien 
nulle 
null 
jamais 
 
mien 
mienne 
miens 
miennes 
tien 
tienne 
tiens 
tiennes 
sien 
sienne 
siens 
siennes 
nôtre 
nôtres 
vôtre 
vôtres 
leur 
leurs 
 
Tableau 10 :  Les mots grammaticaux utilisés pour définir les règles de la reconnaissance automatique des parties du discours

Chapitre III : Méthodologie  105 
START 2003 
3.4. De la méthode vers l’algorithme 
La méthode que nous avons adoptée est basée sur l’idée de faire émerger des catégories 
grammaticales – syntaxiques sans dictionnaire préalable. Notre méthode fait partie des 
programmes qui utilisent : 
- la division du système en niveau et, 
- la méthode d’analyse morphologique (découpage et interprétation). 
La plupart des POS (Parts of Speech) taggers actuels sont basés sur des méthodes 
probabilistes [Weischedel et al. 1993] ; [Charniak 1997], ou statistiques [Collins 1996], ou 
sur une architecture d’apprentissage qui génère les règles du « taggage » [Brill 1997] ; 
[Roth et al. 1999] et utilisent des corpus préalablement annotés comme le Penn Tree Bank 
[Marcus et al. 1993]. Il y a des algorithmes pour l’étiquetage des mots dont les propriétés de 
parties du discours sont inconnues [Schütze 1995]. Cet algorithme a été testé sur le corpus 
Brown. Ils sont donc dépendants d’un lexique pour pré-étiqueter les textes. Si le tagger 
rencontre un mot nouveau il le traite comme un nom. Nous ne disposons pas de lexique 
contenant l’ensemble des mots présents dans notre corpus. L’étiquetage syntaxique que 
nous proposons sans décrire la totalité des phénomènes syntaxiques différencie avec succès 
les principales catégories grammaticales. Nous avons procédé à l’étude de mots 
grammaticaux et nous avons essayé de dégager des régularités qui régissent le 
fonctionnement des groupes nominaux et des groupes verbaux ainsi que des régularités 
concernant les limites contextuels de ces groupes. Pour notre recherche, nous avons utilisé 
un corpus de textes français de différents auteurs qui portent sur des sujets différents d’une 
longueur qui varie selon la nature et le style de la source. Les textes ont été découpés en 
phrases où nous avons isolé les déterminants et leur contexte. Pour ce qui est de notre 
algorithme nous traitons les signes de ponctuation séparément car ils font partie des 
marques d’arrêt dans les règles élaborées. 
Dans un premier temps nous avons découpé les textes en phrases et ensuite nous avons isolé 
les mots grammaticaux dans leur contexte pour les besoins de ce projet. En effet, dans le but 
106  Chapitre III : Méthodologie 
START 2003 
d’établir les règles pertinentes qui permettront la reconnaissance automatique des parties du 
discours nous avons créé un programme qui isole les mots grammaticaux dans un contexte 
donné à gauche et à droite. Nous avons utilisé un contexte gauche assez restreint (3 mots), 
et un contexte droit assez large (6 mots) partant du fait que le contexte droit est plus 
pertinent pour la détermination de l’étendue des groupes syntaxiques. Les statistiques ont 
montré qu’il est rare (dans notre corpus) de trouver par exemple un GN qui s’étende au delà 
de 7 mots. Donc, le contexte droit de 6 mots (qui suivent le mot grammatical ou noyau) est 
suffisant pour définir l’étendue d’un GN, dans la plupart des cas, et pour montrer le 
contexte probable des marques d’arrêt (déterminants). Les mots sont distinctement séparés 
par des espaces en tenant compte des particularités de la langue française, par exemple les 
mots composés (séparés par le tiret1). 
La représentation de notre base de règles est faite comme une suite de mots dans des 
tableaux avec mise en valeur des noyaux et de leur contexte2. 
L’algorithme qui détermine les syntagmes verbaux et nominaux, est donné 
schématiquement ci-après : 
                                                   
1. Certains de tirets servent à faire des mots composés mais d’autres sont utilisés pour montrer des expressions 
grammaticales, telles que l’inversion sujet verbe dans une phrase interrogative par exemple. 
2. Voir tableau des règles au § 4. Le système des règles, de ce chapitre. 
Chapitre III : Méthodologie  107 
START 2003 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 6 :  Schéma général de l’algorithme 
Corpus 
(composé de textes français) 
Découpage en phrases 
Isolation des marques grammaticales 
avec leur Contexte Gauche (CG) 
et leur Contexte Droite (CD) 
Traitement de l’ambiguïté 
entre article défini et pronom 
personnel le, la, l’, les 
Isolation de « c’ » 
Groupe verbal 
Détermination de la longueur des parties du 
discours à l’aide de marques 
(grammaticales) d’arrêt (après avoir 
effectué des statistiques concernant l’ordre 
des mots) 
Construction du lexique à partir 
du Contexte des MG. 
Détermination des 
groupes verbaux des 
pronoms personnels le, 
la, l’, les 
108  Chapitre III : Méthodologie 
START 2003 
Nous développerons l’algorithme en expliquant ce qu’il fait ainsi que le résultat attendu, 
dans le chapitre suivant.  
Nous avons établi le cadre général, dont notre recherche sur la reconnaissance automatique 
superficielle des parties du discours, fait partie et qui est celui de l’automatisation du 
processus de la compréhension. Nous avons exposé un schéma général qui permet la 
coopération efficace des différentes sources de connaissances dans tout domaine 
d’application. 
La méthode d’application et le système réalisé consistent en un système à base de règles 
créées à partir des statistiques effectuées sur l’ensemble du corpus. Les statistiques portent 
sur la distribution, l’ordre des mots et leur relation avec leur environnement. 
Notre méthode fait partie de la génération des programmes qui traitent :  
- la division du système en niveaux 
- le recours nécessaire à une morpho-syntaxe conséquente 
- la méthode d’analyse morphologique (découpage et interprétation) 
 
 
 
 
 
 
 
 
 
 
Chapitre IV 
 
 
LE SYSTEME « START » 
110  Chapitre IV : START 
START 2003 
Sommaire du Chapitre IV 
 
LE SYSTEME « START » 
 
4.1. Introduction 
4.2. Pré-traitement des données textuelles 
4.3. Découpage en phrases 
4.4. Le colonage 
4.5. Le système des règles 
4.6. Dictionnaire 
Chapitre IV : START  111 
START 2003 
START 
System of Textual Analysis Recognition and Tagging1 
 
“It will be bags of tricks and not 
theory that would advance 
computational linguistics in the 
future” [Bar-Hillel 1964] 
 
Ce chapitre sera centré sur l’algorithme et le système élaboré. Nous avons voulu créé un 
analyseur de surface sans effort ni intervention humaine pour le français principalement et 
pour le grec comme expérimentation. Notre analyseur est doté des propriétés suivantes :  
- rapide et robuste, 
- indépendant de corpus, qu’il puisse être appliqué à n’importe quel corpus, 
- avoir une représentation hiérarchique de phrase pour qu’il soit utilisé dans 
d’autres applications. 
Notre méthode est principalement fondée sur les connaissances acquises à partir de 
différents niveaux d’analyse effectuée. Après avoir défini les textes qui composent notre 
corpus, dans un premier temps nous procédons au découpage des textes en phrases. Ensuite 
l’analyse distributionnelle nous permet d’évaluer le contexte du noyau (mots 
grammaticaux) et procéder à leur découpage contextuel. Dans un deuxième temps, les 
statistiques nous permettent d’évaluer la probabilité afin de définir la priorité d’application 
de chaque règle. Une fois les groupes syntaxiques définis, nous procédons à l’inscription 
des lemmes dans le dictionnaire tout en évaluant la catégorie grammaticale de ces entrées. 
Le traitement de désambiguïsation nous permet d’effectuer une analyse syntaxique avec une 
grande précision et fournit également des entrées pour le lexique. Le niveau d’analyse 
suivant permet d’évaluer les cas non résolus à partir des cas similaires mais dans un 
                                                   
1. Système d’analyse textuelle de la reconnaissance et d’étiquetage. 
112  Chapitre IV : START 
START 2003 
contexte qui n’a pas été défini par les règles de l’analyse précédente. C’est le niveau d’auto-
apprentissage et ceci nous donne la possibilité de ne pas être exhaustifs quant à l’écriture 
des règles. Les cas non résolus sont diminués et le pourcentage de segmentation augmente. 
Ainsi le dernier volet de l’analyse trouve recours au dictionnaire créé par le système et 
évalue des cas non résolus en diminuant le nombre des groupes sans reconnaissance.  
La figure qui suit montre la représentation structurale du système START.  
Chapitre IV : START  113 
START 2003 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 7 :  Représentation schématique du système START 
Textes non annotés 
Découpage en phrases
Colonage selon MG MG : Mots 
Grammaticau
Moteur 
des règles
Définition des GN, GV, 
GP, SR 
Création 
dictionnaire
Analyse 
distributionnelle 
Statistiques 
Etiquetag
Détermination de l’étendue 
des Groupes Syntaxiques 
Désambiguïsation des 
cas ambigus 
114  Chapitre IV : START 
START 2003 
4.1. Introduction 
Nous avons développé un système à base des règles et de méthode d’auto-apprentissage qui 
reconnaît de façon non exhaustive de différentes catégories grammaticales et de différentes 
structures syntaxiques. L’analyse s’effectue par ordre de petits groupes de syntagmes et le 
traitement aboutit à la création d’un dictionnaire. Nous présenterons dans ce chapitre le 
système mis au point, qui est un système à niveaux utilisant des règles dictées par l’analyse 
distributionnelle sur un grand corpus, l’apprentissage ainsi que le dictionnaire sont 
automatiquement créés par le système lui-même.  
Nous présentons le système informatique START, un système robuste, qui dans un premier 
temps reconnaît et détermine l’étendue de différents syntagmes syntaxiques (parties du 
discours) qui composent une phrase, ensuite il désambiguïse les cas ambigus entre l’article 
défini et le pronom personnel et étiquette les mots reconnus par le système comme des 
verbes des substantifs des participes passées et quelques adverbes. A la chaque étape finale 
entre les divers processus le système peut alimenter un dictionnaire avec des entrées 
lexicales extraites du corpus automatiquement selon le traitement appliqué. Le système n’ a 
aucun dictionnaire et il utilise un minimum de règles grammaticales et syntaxiques. Il est 
basé sur des statistiques issues de l’analyse distributionnelle des mots grammaticaux. Le 
processus est novateur car il n’utilise pas de corpus étiqueté et aucune connaissance 
préalable. Les résultats sont très encourageants dépassant 92% de reconnaissance pour des 
GV et des GN et un taux très élevé pour le cas de désambiguïsation de l’ordre de 99,6% 
avec un taux d’erreur inférieur à 1%. De plus, des tests effectués sur un corpus grec donnent 
de bons résultats montrant ainsi l’adaptabilité de notre méthode à d’autres langues qui 
présentent la même structure que le français. 
4.2. Pré-traitement des données textuelles 
Toute exploitation linguistique des données textuelles peut être vue comme une 
transformation progressive de textes originaux. Avant toute analyse syntaxique sur le 
corpus, souvent deux transformations sont déjà faites. La première consiste en la séparation 
du texte en phrases, puisque la phrase constitue l’unité d’étude pour la plupart des 
Chapitre IV : START  115 
START 2003 
grammaires. La deuxième consiste en la séparation du flux des caractères qui composent la 
phrase en plus petites unités qui sont les mots. Cette procédure s’appelle tokenization 
[Grefenstette et Tapanainen 1994]. Les résultats de cette procédure sont de deux types, le 
premier correspond à des unités reconnaissables telles que la ponctuation, les nombres, les 
dates etc. et le deuxième type correspond à des unités qui « subiront » par la suite une 
analyse morphologique. Dans la littérature la procédure de tokenization est souvent décrite 
comme une étape inintéressante du pré-processus avant de procéder à l’analyse linguistique. 
La figure ci-dessous schématise le processus de la transformation. 
 
 
 
 
 
 
 
Figure 8 :  Transformations textuelles avant l’analyse linguistique 
Le texte électronique est facilement récupérable de nos jours et nous n’avons plus recours à 
des textes scannés et traités comme des images. Les textes contiennent souvent trop de 
blancs (espacements), et un ensemble de marques qui indiquent les caractères spéciaux, les 
changements de police, et autres informations qui font partie de la normalisation décrite par 
Pré – processus 
Tokenization 
Analyse 
morphologique
116  Chapitre IV : START 
START 2003 
la présence du code SGML1.. Malgré le fait que ces indications soient nécessaires pour le 
lecteur puisqu’elles offrent des informations sur la nature du texte, souvent elles sont 
filtrées dans un pré-traitement pour être éliminées. Les stations UNIX offrent un outil de but 
général qui s’appelle lex ou flex, et il permet de traiter le flux de caractères en proposant des 
actions quand certaines expressions régulières correspondent avec le texte en entrée. La 
figure qui suit donne un exemple de programme qui élimine le code SGML présent dans le 
texte. 
 
/* Call this file StripSGML.lx and then run: 
flex –8 –CF StripSGML.lx; gcc –o StripSGML lex 
.yy.c –lfl –s 
To pass this simple filter over a text file 
called test, run: 
StripSGML < test     
    */ 
%% 
“<”[^\n<>]+”>” ; 
.   ECHO; 
[\n]   ECHO; 
%% : 
Figure 9 :  Un programme flex qui filtre le code SGML. 
Toutes les données SGML sont mises à part. L’exemple qui suit donne les différentes 
versions d’un extrait du texte « Aurélien ». 
                                                   
1. Un parseur qui permet la manipulation et l’élimination du code SGML présent dans les textes est disponible dans 
un site ftp anonyme ifi.uio.no. dans le répertoire /pub/SGML/SGMLS, où SGMLS est un parseur du domaine 
publique. 
Chapitre IV : START  117 
START 2003 
 
< !doctype cesDoc PUBLIC « -//CES//DTD cesDoc//EN » 
[]> 
<cesDoc version=”4.3”> 
<cesHeadercreator=”CSAR”version=”4.1” 
date.created=”Fri Apr 3 16:02:14 CEST 2001”> 
<fileDesc> 
<titleStmt> 
<h.titlen=”2527” id=”unknown”>aurelien.txt</h.title> 
 <respStmt> 
 <respType>NONE</respType>  
 <respname>CSAR(www.ai.univ-paris8.fr/~csar.html) 
</respname> 
 </respStmt> 
</titleStmt> 
<editionStmt version=”4”> 
</editionStmt> 
<publicationStmt> 
<distributor>Association des BiblioFiles Universels 
(ABU) </distributor> 
<pubAddress>6, rue Paul Albert,75018 Paris 
</pubAddress> 
<eAddress 
type=”WWW”>http://www.abu.org/ABU/</eAddress>  
 <availability status=”FREE”>0</availability> 
 <pubDate></pubDate> 
</publicationStmt> 
<sourceDesc> 
 <biblStruct> 
 <monogr> 
 <h.title>Aurelien</h.title> 
 <h.author id=”inknwon”>u, k (-)</h.author> 
 <imprint> 
 <pubPlace></pubPlace> 
 <publisher></publisher> 
 </imprint> 
 </monogr> 
 </biblStruct> 
</sourceDesc> 
</fileDesc> 
<encodingDesc>  
<projectDesc></projectDesc> 
<editorialdecl> 
<conformance level=1>CES level1</conformance> 
</editorialdecl> 
<classdecl> 
<taxonomy> 
 <category 
id=prose><catDesc>Texte</catDesc></category> 
 </taxonomy> 
</classdecl>  
</encodingDesc> 
<profileDesc> 
<langusage> 
118  Chapitre IV : START 
START 2003 
 <languageid=”fr” 
iso639=”fr”>French</language> 
</langusage> 
<annotations> 
<annotation type=”GRAM” ann.loc=””></annotation> 
</annotations> 
</profileDesc> 
</cesHeader> 
<text><body><divtype=wholetext><p></p></div><DIV 
type=chapter><HEAD><TITLE>CHAPITRE 1</TITLE></HEAD> 
<p> 
Figure 10 :  Extrait du code SGML présent au début du fichier texte 
Une fois le filtre lex appliqué on obtient le texte sans marques comme le montre l’exemple 
qui suit. Extrait de « Aurelien.txt » : 
 La première fois qu’Aurélien vit 
Bérénice, il la trouva franchement laide. Elle 
lui déplut, enfin. Il n’aima pas comment elle 
était habillée. Une étoffe qu’il n’aurait pas 
choisie. Il avait des idées sur les étoffes. 
Une étoffe qu’il avait vue sur plusieurs 
femmes. Cela lui fit mal augurer de celle-ci 
qui portait un nom de princesse d’Orient sans 
avoir l’air de se considérer dans l’obligation 
d’avoir du goût. Ses cheveux étaient ternes ce 
jour-là, mal tenus. Les cheveux coupés, ça 
demande des soins constants. Aurélien n’aurait 
pas pu dire si elle était blonde ou brune. Il 
l’avait mal regardée. Il lui en demeurait une 
impression vague, générale, d’ennui et 
d’irritation. Il se demanda même pourquoi. 
C’était disproportionné. Plutôt petite, pâle, 
je crois... Qu’elle se fût appelée Jeanne ou 
Marie, il n’y aurait pas repensé, après coup. 
Mais Bérénice. Drôle de superstition. Voilà 
bien ce qui l’irritait. 
 Il y avait un vers de Racine que ça lui 
remettait dans la tête, un vers qui l’avait 
hanté pendant la guerre, dans les tranchées, et 
plus tard, démobilisé. Un vers qu’il ne 
trouvait même pas un beau vers, ou enfin dont 
la beauté lui semblait douteuse, inexplicable, 
mais qui l’avait obsédé, qui l’obsédait 
encore : 
Chapitre IV : START  119 
START 2003 
 Je demeurai longtemps errant dans 
Césarée... En général, les vers, lui... Mais 
celui-ci revenait et revenait. Pourquoi ? C’est 
ce qu’il ne s’expliquait pas. Tout à fait 
indépendamment de l’histoire de Bérénice... 
l’autre, la vraie... D’ailleurs il ne se 
rappelait que dans ses grandes lignes cette 
romance, cette scie. Brune alors, la Bérénice 
de la tragédie. Césarée, c’est du côté 
d’Antioche, de Beyrouth. Territoire sous 
mandat. Assez moricaude même, des bracelets en 
veux-tu en voilà, et des tas de chichis, de 
voiles. Césarée... un beau nom pour une ville. 
Figure 11 :  Extrait du fichier texte « Aurélien ». 
Le processus de l’isolation des phrases et des mots présuppose la résolution de l’ambiguïté 
de certains signes de ponctuation. La section qui suit nous éclaircit sur le rôle ambigu du 
point par exemple dans des références alphanumériques (ex. S-2.DR.1.2) ou dans les 
abréviations (ex. Chap. 1). Le traitement offre une grande précision sans erreur et il a été 
testé pour les deux langues français et grec sans changement majeur, juste en tenant compte 
des particularités de l’écriture de chaque langue. 
4.3. Découpage en phrases 
La grande majorité des applications de traitements du langage naturel présuppose le 
découpage de textes en phrases. Cette tâche est depuis très longtemps automatisée, on parle 
alors de reconnaissance de frontières des phrases1. La phrase est considérée comme l’unité 
centrale des processus du traitement du langage naturel, comme par exemple l’étiquetage. 
On reconnaît comme phrase la suite des mots qui se trouvent entre des signes de 
ponctuation dits majeurs tels que le point, le point d’exclamation, le point d’interrogation. 
Le rôle des signes de ponctuation, on les appelle également signes syntaxiques, consiste à 
distinguer, selon le sens, les phrases ainsi que les membres qui les composent. 
                                                   
1. Dans la bibliographie anglosaxone la phrase est sentence et les propositions (principales et secondaires) sont des 
clauses. 
120  Chapitre IV : START 
START 2003 
Formellement la ponctuation désigne l’ensemble des signes qui permettent l’interprétation 
des textes écrits. Traditionnellement la ponctuation est le module de la compétence 
langagière le plus difficile à maîtriser, d’une part à cause de son caractère écrit, d’autre part 
à cause de différents styles appliqués par les auteurs dans la littérature. Les marqueurs de 
ponctuation jouent un rôle important pour indiquer les relations structurelles dans le 
discours (écrit), comme par exemple les relations rhétoriques particulières qui résident dans 
un texte [Dale 1991]. Avant de procéder à la construction de systèmes de génération ou 
d’analyse automatique des documents écrits, il faut s’assurer que ces systèmes incorporent 
un modèle adéquat pour ces aspects textuels. 
Le corpus1 sur lequel nous avons travaillé contient plus de 200 textes français (5000000 de 
mots) qui sont codés en SGML. Avec la DTD CES ce codage identifie chaque paragraphe 
entre deux étiquettes <P> </P>. A l’aide de sgmlQL on peut extraire les paragraphes des 
textes et enlever toute étiquette SGML comme nous l’avons déjà décrit dans la section 
précédente. Ensuite nous avons utilisé un algorithme (développé au sein du groupe CSAR 
sous la direction de G.Bernard) qui découpe des paragraphes en phrases en tenant compte 
des particularités de la langue et de la ponctuation (avec désambiguïsation du rôle du point 
etc.). 
4.3.1. Le rôle de la ponctuation 
Des études linguistiques sérieuses sur le rôle de la ponctuation ont commencé récemment. 
[Nunberg 1990] présente le début d’une théorie linguistique sur la ponctuation où les signes 
de ponctuation sont des indicateurs de surface pour plusieurs catégories syntaxiques. La 
ponctuation est traitée comme un système linguistique à part entière et l’auteur réfléchit sur 
une « grammaire textuelle » en utilisant pour ce but des mécanismes de grammaires 
conventionnelles ou lexicales. Plusieurs chercheurs par la suite ont intégré à des systèmes 
                                                   
1. Le corpus grec comporte des articles des journaux quotidiens et mensuels qui apparaissent en version 
électronique et que nous avons pu les utiliser pour effectuer nos tests. Ce corpus sans prétention de l’exhaustivité 
de tous les cas de structure de la langue grecque, il reste significatif. 
Chapitre IV : START  121 
START 2003 
NLP les signes de ponctuation et plus particulièrement d’un point de vue syntaxique 
[Briscoe 1994], [White 1995]. 
Le problème de la détection automatique des phrases se pose à cause de l’ambiguïté de 
certains signes de ponctuation. Par exemple un point peut être utilisé pour déclarer la fin 
d’une phrase mais aussi pour exprimer une abréviation ou un acronyme (ex. : E.D.F. ou 
U.S.A.), ou même un nombre décimal, par exemple : 3.14 (écriture anglosaxone). 
Les phrases1 qui suivent montrent l’ambiguïté des signes de ponctuation comme le point : 
Là où cela n’engage à rien, M.Filoche est pour les 37,5 annuités. 
Les pays membres de l’U.E. seront confrontés à une reforme concernant leur régime 
de retraites. 
Ce qui figure dans l’avant-projet de loi Fillon est considéré comme entièrement 
maintenu… et donc avalisé par la CFDT. 
Alors T., mère de deux enfants, ouvrit sa porte. 
« Est-ce qu’il sera là ? » demanda-t-il à son tour. 
(…) appuyés par des hélicoptères, qui, - une fois n’est pas coutume ! – n’ont tiré ni 
missiles, ni roquettes, ni balles, (…) 
Cette ambiguïté varie selon le type de texte ou de corpus. Des statistiques effectuées à partir 
d’un corpus composé d’articles du Wall Street Journal montrent que plus de 47% des points 
utilisés sont des points qui se trouvent dans des abréviations, contrairement à 10% pour le 
corpus Brown [Church 1991]. Ceci démontre que si l’on coupe un texte en phrases sans 
tenir compte des particularités de l’ambiguïté on n’aurait que 53% des phrases correctement 
découpées pour le premier et 90% pour le second. La plus fréquente source d’ambiguïté est 
le point d’une abréviation par exemple : ex. 
                                                   
1. Ces exemples sont extraits du corpus traité composé des journaux quotidiens, hebdomadaires ou mensuels ainsi 
que des textes littéraires. 
122  Chapitre IV : START 
START 2003 
4.3.2. Désambiguïsation du point (.) 
Notre application est fondée sur des paramètres comme la lettre finale d’un mot ou sa 
longueur dont le coût de calcul est minime, et des règles de désambiguïsation pour les 
signes de ponctuation. Ces règles sont extraites des informations tirées des statistiques sur 
des corpus non annotés et sont applicables pour les langues testées français et grec 
(récemment nous l’avons testé avec les textes écrits en arabe et le taux de reconnaissance 
fut aussi élevé que pour le grec et le français). 
Avant de procéder à la détection des frontières des phrases d’un texte (pour toutes les 
langues testées), nous définissons un ensemble de segments (tokens), ex. : caractères, 
nombres, signes de ponctuation. Pour chaque langue, ces signes sont différents, à part 
quelques signes comme le point final ou le point d’exclamation, qui sont communs aux trois 
langues. 
La procédure de la segmentation suit la règle suivante : deux segments sont séparés par des 
espaces. Un segment qui est suivi par un des signes de ponctuation décrits ci-dessous, est 
considéré comme fin probable de la phrase (en respectant la forme particulière de chaque 
langue). 
 - Point . 
 - Point d’exclamation ! 
 - Point d’interrogation ? 
 - Points de suspension … 
Une autre frontière probable est quand les signes mentionnés ci-dessus se trouvent juste 
avant ou après des suites de caractères doubles comme les parenthèses (), les crochets {}, 
les guillemets, comme dans l’exemple : « super ! ». Le tableau qui suit montre le découpage 
effectué dans une partie du corpus. 
Chapitre IV : START  123 
START 2003 
Les tableaux contiennent des extraits des corpus (français, grec), les phrases sont découpées 
et balisées ; les balises <s> <\s> désignent la phrase (sentence), et les balises <po> <\po> la 
ponctuation de la fin de phrase.  
1 <s>Ainsi avons-nous analysé la Théorie physique <po>.</po> </s> 
2 <s>La première tache question que nous rencontrions est celle-
ci<po> :</po> </s> 
3 <s>quel est l’objet d’une théorie physique <po> ?</po> </s> 
Tableau 11 :   Extrait du corpus français : 
Les corpus sont composés de textes de styles divers : journaux, magazines, littérature, etc. 
et ils sont non annotés. Aucune connaissance préalable ou dictionnaire ne sont utilisés pour 
notre algorithme. Il faut préciser que le corpus français atteint les 100 millions des mots, le 
corpus grec qui est moins volumineux néanmoins pas moins significatif, atteint 
progressivement le million. 
4.3.2.1. Particularités des langues naturelles traitées 
Il n’y a pas de différences quant à l’utilisation de la ponctuation dans les langues étudiées 
au sein de notre recherche [Pappa et al. 2003]. Les différences se résument à la graphie et 
aux particularités morphologiques que nous décrivons brièvement. Les textes sont codés en 
UTF-8, afin de permettre l’utilisation du même algorithme pour les langues étudiées. Au 
sein de notre groupe de recherche le même algorithme a été testé avec succès avec des 
textes en arabe [Kouloughli 1994] en respectant les particularités morphologiques et le 
codage de la graphie. 
Le mot arabe graphique (il existe aussi la notion du mot arabe phonique mais ce n’est pas le 
cas de notre recherche), est facile à identifier : c’est ce qui s’écrit en un seul bloc entre deux 
blancs. En arabe, on ne distingue pas minuscules ou majuscules, mais il existe néanmoins 
trois formes graphiques : initiale, médiale et finale [Siamak 2001]. Ceci est intéressant pour 
la reconnaissance des acronymes car nous pouvons les identifier suivant les mêmes règles 
que pour les langues occidentales : « Majuscule – Point – Majuscule – Point » etc. Mais il y 
a encore des problèmes d’ambiguïté qui persistent, car l’unicode ne permet pas de 
124  Chapitre IV : START 
START 2003 
distinction (au niveau programmation) des trois formes mentionnées plus haut. Mais dans le 
corpus traité nous n’avons pas trouvé d’acronymes non identifiables. 
Il faut juste mentionner que pour le grec moderne le signe de ponctuation point virgule ( ;) 
correspond au point d’interrogation et signifie donc la fin d’une phrase (voir exemple n° 2 
dans le tableau 3 ci-dessous). Il faut aussi mentionner que le double point « : », étant donné 
qu’il peut signifier la fin d’une proposition, est marqueur de fin de phrase. Ceci est le cas 
pour plusieurs langues comme le français, l’italien, l’espagnol. 
1 
<s>Η φύση του νου σας, είναι στην πραγµατικότητα 
καθαρή<po>.</po> </s> 
2 <s>Η αντανάκλαση εµφανίζεται ακόµα κι αν ο ήλιος ή το φεγγάρι 
δεν έχουν αυτή την πρόθεση <po>:</po> </s> 
3 <s>Πώς µπορούν τ’ αποτυπώµατα, τα οποία δεν έχουν µορφή να 
καθορίσουν κάτι φυσικό όπως τα σώµατά µας<po>;</po> </s> 
Tableau 12 :   Extrait du corpus grec. 
4.3.2.2. Les paramètres et les règles 
Nous allons décrire le choix des paramètres pour la reconnaissance des fins des phrases en 
prenant comme modèle la langue grecque, sachant que les informations équivalentes ont été 
extraites du français (les particularités de chaque langue faisant partie d’un module 
spécifique où ,selon le codage, le module s’active ou non). La procédure est empirique et 
exploite les caractéristiques du grec moderne [Chatzivasiliou 1995]. Les informations 
extraites des statistiques qui nous ont permis de fabriquer les règles de reconnaissance sont 
résumées ci-dessous : 
- La longueur (en caractères) du dernier mot avant la fin de la phrase a peu de 
probabilité d’être petite (1 ou 2 caractères). 
- La grande majorité des mots en grec moderne ont comme caractère final le ς ou le 
ν, ou les voyelles. 
Chapitre IV : START  125 
START 2003 
- Les signes de ponctuation qui se trouvent à coté d’une possible fin de phrase sont 
significatifs quant à leur utilisation. 
 
 Type de signe de ponctuation Exemples 
 Initial 
Final 
Aucun 
(, [, {, «  
), ], }, » 
 Type de caractère Exemples 
français fréquent minuscule 
très peu fréquent minuscule 
fréquent majuscule 
très peu fréquent majuscule 
e, s, t, n, a, etc. 
w, k, j, etc. 
I, II, V, etc. 
W, K, J, etc. 
grec fréquent minuscule 
très peu fréquent minuscule 
fréquent majuscule 
très peu fréquent majuscule 
α, ε, η,  etc. 
Μ, κ, λ, etc. 
Α, Ε, Η, etc. 
Μ, Κ, Λ, etc. 
 nombre 
spécial 
0, 1, 2, etc. 
%, #, $, etc. 
Tableau 13 :   Informations statistiques sur les caractères finaux en français et en grec 
Les informations extraites des statistiques effectuées sur les corpus à partir des segments 
composent les paramètres suivants : 
SG : la longueur (en caractères), le type du caractère, contient-il un point. 
SD : la longueur (en caractères), le type du caractère, contient-il un point. 
SPF : type de signe de ponctuation qui se trouve en position finale (à la fin d’un mot). 
SPI : type de signe de ponctuation qui se trouve en position initiale (au début d’un mot). 
126  Chapitre IV : START 
START 2003 
 
 
 
 
 
… de « cette b a t a i l l e ». ( Les soldats, se … 
 
 
 
 
Figure 12 :  Exemple des segments utilisés 
Le tableau qui suit donne les informations extraites de l’exemple donné en figure ci-dessus. 
 
SG longueur : 8 
type du premier caractère : minuscule, peu 
probable pour se trouver comme caractère final 
d’un mot 
type du dernier caractère : minuscule, final très 
probable 
contient-il un point : non 
SD longueur : 3 
type du premier caractère : majuscule, probable 
final 
type du dernier caractère : minuscule probable 
final 
contient-il un point : non 
SPF type de signe de ponctuation : final – couple peut 
encadrer un paragraphe. 
SPI type de signe de ponctuation : initial – couple. 
Tableau 14 :   Explicatif des segments utilisés. 
Possible fin d'une phrase 
SG SD 
SPF SPI 
Chapitre IV : START  127 
START 2003 
Le processus de la désambiguïsation des signes de ponctuation, ainsi que l’extraction 
automatique de règles que nous décrivons, est une variante de la théorie des règles de 
transformation. La différence consiste dans le fait que nous utilisons des corpus non annotés 
et que nous avons utilisé le même algorithme pour des langues différentes. 
Selon notre méthode, la reconnaissance des frontières d’une phrase peut se diviser en trois 
parties : dans la première nous effectuons une série de statistiques pour évaluer le contexte 
des signes de ponctuation. L’analyse distributionnelle nous permet de dégager des règles 
qui évaluent ensuite le contexte d’un signe particulier. Dans un premier temps nous 
considérons que tous les signes de ponctuation qui peuvent être signes de la fin d’une 
phrase indiquent une fin de phrase. La précision atteinte est la plus basse de notre système. 
En deuxième partie nous appliquons des règles de type 1 : 
 SI contexte 
 ALORS éloigner signe de fin de phrase 
Le contexte décrit la condition qui active la règle qui se compose soit d’une combinaison 
entre SG et SD soit entre SPF et SPI. L’exemple de la figure plus haut devient :  
 
128  Chapitre IV : START 
START 2003 
SG longueur : 8 
type du premier caractère : miniscule, peu fréquent comme caractère finale 
d’un mot 
type du dernier caractère : minuscule, final très probable 
contient-il un point : non 
 ET 
SD longueur : 3 
type du premier caractère : majuscule, probable final 
type du dernier caractère : minuscule probable final 
contient-il un point : non 
 OU 
SPF type de signe de ponctuation : final  
 ET 
SPI type de signe de ponctuation : initial 
Tableau 15 :   Exemple du contexte 
Une fois les règles de type 1 appliquées, le système procède à l’application des règles de 
type 2 (troisième partie) :  
 SI contexte 
 ALORS introduire signe de fin de phrase 
Le contexte décrit la condition qui active la règle comme elle est définie plus haut. La 
procédure de règles peut se résumer comme le montre la figure 2 ci-dessous : tout d’abord 
nous appliquons les règles qui transforment un signe de fin de phrase en un simple signe de 
ponctuation, puis toutes les règles qui transforment un simple signe de ponctuation en un 
signe de fin de phrase. 
Chapitre IV : START  129 
START 2003 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 13 :  Procédure de désambiguïsation 
Pour chaque combinaison entre contexte et signe possible comme fin de phrase, les 
informations suivantes en clauses Prolog [Sterling et Shapiro 1990] sont extraites du corps 
d’apprentissage  
Le SIGNE DE PONCTUATION est un des quatre possibles comme fin de phase (point, 
point d’interrogation, point d’exclamation et points de suspension). 
Le CONTEXTE est soit une combinaison entre SG – SD soit entre SPF – SPI. 
Le C1 est un entier qui indique le nombre de fois qu’un signe de ponctuation particulier 
n’est pas fin de phrase. 
Le C2 est un entier qui indique le nombre de fois qu’un signe de ponctuation particulier est 
fin de phrase. 
Ensuite si l’on veut inclure une de ces clauses dans les règles de type 1 il faut respecter les 
contraintes suivantes : 
Corpus 
Analyse distributionnelle 
Eloignement de signes de fin de phrase 
Introduction de signes de fin de phrase 
Règles type 1
Règles type 2
Corps 
d’apprentissage
textes découpés en phrases 
130  Chapitre IV : START 
START 2003 
C1 > C2 
ET 
 C2 < SCFP * VERITE 
Le SCFP représente la totalité de Signes Candidats pour Fin de Phrase, et vérité est un 
nombre entre 0 et 1 qui indique le degré de crédibilité des règles générées. Plus la vérité est 
grande, plus il y a des règles générées (moins de précision). Et plus la vérité est petite, plus 
les règles sont précises. Les tests effectués montrent une vérité de l’ordre de 0,01 (ou 99%) 
de crédibilité. Les contraintes pour les règles de type 2 sont respectivement : 
  C1 = 0 
 ET 
  C2 > 0 
La définition des contraintes a été basée sur des statistiques. Dans un premier temps les 
contraintes pour les deux types de règles étaient symétriques mais l’analyse a montré que 
les contraintes de type 2 devaient être augmentées afin d’atteindre plus de précision.  
Le système de découpage en phrases produit deux types d’erreur : 
- erreur positive : quand un signe de ponctuation est considéré comme fin de phrase, 
mais c’est faux, et 
- erreur négative : quand un signe de ponctuation qui est fin de phrase n’est pas 
reconnu par le système. 
Le tableau qui suit regroupe quelques résultats pour les deux langues testées. La première 
colonne indique le choix des langues, la deuxième les 4 signes qui indiquent la fin d’une 
phrase (P pour le point, PI pour le point d’interrogation, PE pour point d’exclamation et PS 
pour points de suspension). La troisième colonne EP indique l’erreur positive, la suivante 
l’erreur négative (EN) et la dernière donne le taux de précision. 
Chapitre IV : START  131 
START 2003 
Langue Signe Phrases EP EN Précision 
en % 
 
français 
P 
PI 
PE 
PS 
1516868
80847
41812
50009
3189
1
3
1631
858 
642 
353 
128 
99,7
99,2
99,1
96,4
total  1689536 4824 1981 99,5
 
grec 
P 
PI 
PE 
PS 
56672
3028
1566
1873
168
0
0
63
99 
29 
17 
6 
99,5
99,1
98,9
96,3
total  63139 231 151 99,4
TOTAL  1788425 5183 2212 99,5
Tableau 16 :   Résultats avec l’erreur. 
4.3.3. Evaluation du découpage 
La procédure de découpage en phrases constitue un pré-traitement pour toute analyse du 
langage naturel. Nous avons développé un système robuste qui reconnaît les frontières 
d’une phrase et qui s’adapte à différentes langues. Il a été testé avec succès sur des corpus 
des langues naturelles comme le français et le grec. Nous n’utilisons aucune connaissance 
préalable (dictionnaire, liste d’abréviations, etc.), et les corpus ne sont pas annotés. Le taux 
de découpage sans faute atteint en moyenne pour les trois corpus 99,5%. La 
désambiguïsation des signes de ponctuation tels que le point, s’effectue grâce à un moteur 
de règles simples extraites des statistiques basées sur l’analyse distributionnelle des 
segments différents. Les balises produites par le système au cours du traitement offrent un 
outil précieux pour toute analyse syntaxique postérieure. 
132  Chapitre IV : START 
START 2003 
4.4. Le colonage 
Avant de décrire la disposition de mots grammaticaux dans leurs contexte nous passons en 
revue un système très connu du nom de KWIC (KeyWord In Context), qui permet 
l’indexation des données autour du mot clé demandé. Les indexeurs contextuels sont utilisés 
depuis longtemps. Les concordances ont approximativement toutes la même forme en 
s’appuyant sur la définition du problème d’indexation et de rotation proposée par [Parnas 
1972]. Il a utilisé des critères différents afin de décomposer un système en modules. Il décrit 
deux solutions : la première est basée sur la décomposition fonctionnelle avec accès partagé 
aux données représentées, et la deuxième est basée sur une décomposition qui cache les 
décisions désignées. Cette dernière a été utilisée pour promouvoir le cache des 
informations, principe que nous trouvons dans les types des données abstraites et la 
programmation orientée objet. Depuis cette définition le problème d’indices contextuels a 
été ré-étudié entre autres par [Karlan et al. 1992] qui l’utilisent pour illustrer les schémas 
des modules basés sur les outils qui intègrent la réactivité (reactive integration).  
Notre système, qui présente les données en colonnes, peut se définir comme une variante de 
la réactivité intégrée. Nous récupérons des textes dans leurs aspects bruts non traités, 
démunis de toute information morphologique ou autre. Dans la version qui suit nous avons 
le même extrait de texte après avoir espacé la ponctuation des mots car elle est significative 
pour le contexte des groupes syntaxiques. Ainsi nous avons pu obtenir des informations sur 
le contexte des signes de ponctuation pour enlever l’ambiguïté du point (.) soit comme le 
signe de fin de phrase soit le signe utilisé dans un acronyme ou une abréviation. Nous 
verrons ensuite, que le découpage en phrases n’est pas utilisé directement dans notre 
système de reconnaissance mais il s’agit d’une étape importante pour récupérer les données 
de l’analyse partielle afin de les reconstituer dans la phrase initiale. Nous en parlerons plus 
en détails dans les perspectives. 
Dans l’exemple qui suit nous présentons un extrait de texte espacé mot par mot et signe par 
signe. Contrairement aux méthodes qui ignorent toute occurrence de signe de ponctuation 
nous privilégions l’hypothèse que la présence de tout signe est significative non seulement 
en soi mais aussi pour la qualité du contexte voisin. Nous montrerons plus loin dans le 
Chapitre IV : START  133 
START 2003 
même chapitre que la fréquence des signes de ponctuation avant des mots grammaticaux est 
supérieure à tout autre mot et ceci nous permet de les utiliser comme repères afin de 
déterminer les différents groupes syntaxiques. 
Chap . 1 La première fois qu’ Aurélien vit 
Bérénice , il la trouva franchement laide . Elle 
lui déplut , enfin . Il n’ aima pas comment elle 
était habillée . Une étoffe qu’ il n’ aurait pas 
choisie . Il avait des idées sur les étoffes . 
Une étoffe qu’ il avait vue sur plusieurs femmes 
. Cela lui fit mal augurer de celle – ci qui 
portait un nom de princesse d’ Orient sans avoir 
l’ air de se considérer dans l’ obligation d’ 
avoir du goût . Ses cheveux étaient ternes ce 
jour – là , mal tenus . Les cheveux coupés , ça 
demande des soins constants . Aurélien n’ aurait 
pas pu dire si elle était blonde ou brune . Il l’ 
avait mal regardée . Il lui en demeurait une 
impression vague , générale , d’ ennui et d’ 
irritation . Il se demanda même pourquoi . C’ 
était disproportionné . Plutôt petite , pâle , je 
crois … Qu’ elle se fût appelée Jeanne ou Marie , 
il n’ y aurait pas repensé , après coup . Mais 
Bérénice . Drôle de superstition . Voilà bien ce 
qui l’ irritait . Il y avait un vers de Racine 
que ça lui remettait dans la tête , un vers qui 
l’ avait hanté pendant la guerre , dans les 
tranchées , et plus tard , démobilisé . Un vers 
qu’ il ne trouvait même pas un beau vers , ou 
enfin dont la beauté lui semblait douteuse , 
inexplicable , mais qui l’ avait obsédé , qui l’ 
obsédait encore : Je demeurai longtemps errant 
dans Césarée … En général , les vers , lui … Mais 
celui – ci revenait et revenait . Pourquoi ? c’ 
est ce qu’ il ne s’ expliquait pas . Tout à fait 
indépendamment de l’ histoire de Bérénice … l’ 
autre , la vraie … D’ ailleurs il ne se rappelait 
que dans ses grandes lignes cette romance , cette 
scie . Brune alors , la Bérénice de la tragédie . 
Césarée , c’ est du côté d’ Antioche , de 
Beyrouth . Territoire sous mandat . Assez 
moricaude même , des bracelets en veux – tu en 
voilà , et des tas de chichis , de voiles . 
Césarée … un beau nom pour une ville . 
Souvent la question qui se pose est : le tokenizer doit-il faire la correspondance par exemple 
entre « d’abord » et une classe de mots ou « d’ » « abord » et deux classes des mots. Cette 
présentation nous permet d’isoler chaque mot séparément même les mots suivis d’une 
134  Chapitre IV : START 
START 2003 
apostrophe afin de les traiter en tant que tels, c’est-à-dire les articles, la négation, les 
pronoms avec apostrophe. Les mots sont distinctement séparés en tenant compte du 
caractère particulier de chaque unité. Le choix que nous avons adopté nous amène à 
résoudre le problème d’ambiguïté posé par l’isolation du « l’ » en tant qu’article ou pronom 
selon le contexte. Nous verrons ensuite dans ce même chapitre comment nous réussissons à 
enlever cette ambiguïté et récupérer les résultats pour améliorer la reconnaissance des 
parties du discours. Cette technique de désambiguïsation est un des programmes 
d’étiquetage qui définissent les parties du discours en utilisant leur contexte immédiat car la 
forme peut correspondre à un ou deux tokens. 
L’alignement sur le noyau (ici mots grammaticaux) est une procédure de découpage qui 
permet mieux définir son contexte gauche et droit afin de pouvoir établir des règles 
pertinentes qui permettent la reconnaissance de différents syntagmes syntaxiques. Nous 
présentons deux extraits du corpus présentant le colonage selon le type des mots 
grammaticaux choisi facilitant ainsi l’étude du contexte. Afin de mieux déterminer les 
groupes verbaux et les groupes nominaux nous présentons séparément l’extrait du corpus 
avec les pronoms qui introduisent les groupes verbaux et l’extrait avec les déterminants qui 
introduisent les groupes nominaux. 
Chapitre IV : START  135 
START 2003 
Extrait du texte « Pin-Up » alignement sur les pronoms personnels : 
 
Contexte Gauche (CG)  MG Contexte Droit (CD) 
Est pas du tout dans ce sens-là que je comptais diriger cette petite étude, et, par une 
 moins traîné que le premier. J’ ajoute qu’ il  ne veut pas dire grand-chose non plus ; 
j’ ai peut-être tort : je crois que je  ne mords pas assez à la philosophie pour pouvoir  
diaboliques, et c’ est la fin du préambule. Je  ne tiendrai pas compte d’ une erreur communément  
sens connu est «les mains en l’ air». Je  n’ en ferai pas état, car il est évident 
air». Je n’ en ferai pas état, car il  est évident que des deux expressions sont calquées l’  
qui comble le premier sauve la décence. Mais je  quitte la sémantique pour me précipiter sur le sujet, 
l’ interdiction de la censure américaine : il  doit y avoir des pin-up d’ origine, 
et il faudrait, pour être complet, que je vous décrivisse aussi mes réactions. Il est inutile d’ ajouter 
que je vous décrivisse aussi mes réactions. Il  est inutile d’ ajouter, vous le savez bien, 
aussi mes réactions. Il est inutile d’ ajouter, vous le savez bien, que la pin-up, 
hebdomadaires les gros tirages que l’ on sait. Nous  présentions à cet égard un retard considérable, soit dit 
mêmes de l’ armée. En plein accord avec elles sans aucun doute. Toujours est-il que l’ 
avec elles sans aucun doute. Toujours est- il que l’ hebdomadaire militaire «Yank» a publié, 
fréquemment le sujet d’ intérêt du militaire. Ils font des calembours, là-dedans. J’ ai 
 
136  Chapitre IV : START 
START 2003 
Extrait du texte « Chabert », alignement sur les déterminants : 
saute – ruisseaux , et qui mordait en ce moment de fort bon appétit dans un morceau 
En ce moment de fort bon appétit dans un morceau de pain ; il en arracha un 
un morceau de pain ; il en arracha un peu de mie pour faire une boulette et 
en arracha un peu de mie pour faire une boulette et la lança railleusement par le vasistas 
peu de mie pour faire une boulette et la lança railleusement par le vasistas d’ une fenêtre 
une boulette et la lança railleusement par le vasistas d’ une fenêtre sur laquelle il s’ 
et la lança railleusement par le vasistas d’ une fenêtre sur laquelle il s’ appuyait . Bien 
laquelle il s’ appuyait . Bien dirigée , la boulette rebondit presque à la hauteur de la 
dirigée , la boulette rebondit presque à la  hauteur de la croisée , après avoir frappé 
la boulette rebondit presque à la hauteur de la croisée , après avoir frappé le chapeau d’ 
hauteur de la croisée , après avoir frappé le chapeau d’ un inconnu qui traversait la cour 
croisée , après avoir frappé le chapeau d’ un inconnu qui traversait la cour d’ une maison 
le chapeau d’ un inconnu qui traversait la cour d’ une maison située rue Vivienne , 
d’ un inconnu qui traversait la cour d’ une maison située rue Vivienne , où demeurait Me 
Simonnin , ne faites donc pas de sottises aux gens , ou je vous mets à la 
aux gens , ou je vous mets à la porte . Quelque pauvre que soit un client 
à la porte . Quelque pauvre que soit un client , c’ est toujours un homme , 
. Quelque pauvre que soit un client , c’ est toujours un homme , que diable ! 
que soit un client , c’ est toujours un homme , que diable ! >> dit le 
un homme , que diable ! >> dit le Maître clerc en interrompant l’ addition d’ un 
! >> dit le Maître clerc en interrompant l’ addition d’ un mémoire de frais . Le 
Maître clerc en interrompant l’ addition d’ un mémoire de frais . Le saute – ruisseau 
l’ addition d’ un mémoire de frais . Le saute – ruisseau est généralement , comme était 
est généralement , comme était Simonnin , un garçon de treize à quatorze ans , qui 
treize à quatorze ans , qui dans toutes les études se trouve sous la domination spéciale du 
qui dans toutes les études se trouve sous la domination spéciale du Principal clerc dont les  
 
Chapitre IV : START  137 
START 2003 
Extrait du texte « Micromégas » alignement sur l’adjectif possessif : 
dans tous les êtres. La taille de Son  Excellence étant de la hauteur que j’ai dite 
nos peintres conviendront sans peine que sa  ceinture peut avoir cinquante mille pieds de roi 
fait une très jolie proportion. Quant à son esprit, c’est un des plus cultivés que 
la coutume, au collège des jésuites de sa  planète, lorsqu’il devina, par la force 
lorsqu’il devina, par la force de Son  esprit, plus de cinquante propositions d’Euclide. 
En se jouant, à ce que dit sa  sœur, devint depuis un géomètre assez  
lui fit quelques affaires. Le muphti de Son  pays, grand vétillard, et fort ignorant 
vétillard, et fort ignorant, trouva dans Son  livre des propositions suspectes, malsonnantes,  
avec esprit ; il mit les femmes de Son côté ; le procès dura deux cent vingt 
Derham se vante d’avoir vu au bout de sa  lunette. Ce n’est pas que je prétende 
en voyant la petitesse du globe et de ses  habitants, se défendre de ce sourire de 
. Il s’en moqua un peu d’abord avec ses  gens, à peu près comme un musicien 
AVEC CELUI DE SATURNE Après que Son Excellence se fut couchée, et que le 
et que le secrétaire se fut approché de Son visage : « Il faut avouer, dit 
savez trop bien que quand il faut rendre Son corps aux éléments, et ranimer la nature 
des gens de bon sens qui savent prendre leur  parti et remercier l’auteur de la nature. 
 Votre petite habitation. J’admire en tout sa  sagesse ; je vois partout des différences, 
Saturnien ; et quand nous divisons un de ses rayons, nous trouvons qu’il contient sept  
en avait découvert trois mille autres dans ses voyages, étonna prodigieusement le philosophe  
 
138  Chapitre IV : START 
START 2003 
Extrait du texte « Corfu » alignement sur les déterminants : 
Άλλο Σινοαπωνικό , το Ιστορικό Αρχείο , τη ∆ηµόσια Βιβλιοθήκη  
∆ηµόσια βιβλιοθήκη , την Αναγνωστική Εταιρεία , το Λαογραφικό Μουσείο  
Αναγνωστική Εταιρεία , το Λαογραφικό Μουσείο Σιναράδων , το Μουσείο  
Μουσείο Σιναράδων, το Μουσείο Σολωµού, 20 µουσικές , το Ιόνιο 
Σολωµού 20 µουσικές , το Ιόνιο Πανεπιστήµιο , πλήθος πολιτιστικών  
συλλόγων κ.λ.π . Όλα αυτά αποτελούν για το νησί µας , 
Αυτά αποτελούν για το νησί µας , πόλους έλξης όλου 
ναοίπου κρατούν τα κειµήλια του πολιτισµού και της σοφίας 
Κερκυραίων . Αυτήν την ιστορία , αυτόν τον πολιτισµό θα 
Την ιστορία , αυτόν τον πολιτισµό θα σας παρουσιάσω , 
Ιστορία , αυτόν τον πολιτισµό θα σας παρουσιάσω , σύντοµα 
, αρχίζοντας από το 229 π.Χ. Το κράτος των 
229 π.Χ. Το κράτος των Φαιάκων ταλαιπωρηµένο από εσωτερικές 
και κατεστραµένο από την απόβαση το 229 π.Χ. της βασίλισσας  
από την απόβαση το 229 π.Χ. της βασίλισσας των Ιλλυριών  
κατοχική φρουρά . Η βασίλισσα τοποθέτησε , άρχοντα του τόπου  
άρχοντα του τόπου τον Ιλλυριό στρατηγό , ∆ηµήτριο Φάριο .  
µετά από προσκάλεσαν τους Γενοβέζους , όπου ο στόλος τους  
Γενοβέζους , όπου ο στόλος τους προσορµίστηκε στο λιµάνι της  
όπου ο στόλος τους προσορµίστηκε στο λιµάνι της Κέρκυρας .  
στόλος τους προσορµίστηκε στο λιµάνι της Κέρκυρας . Έχουµε δηλαδή  
. Έχουµε δηλαδή την Α’ Βενετική κατοχή . Το 1214  
Βενετική κατοχή . Το 1214 έως το 1267 , η  
Το 1214 έως το 1267 , η Κέρκυρα έρχεται στην κυριαρχία 
Une fois les phrases alignées en colonnes en ayant comme noyau les mots grammaticaux 
qui nous servent pour nos statistiques ; nous récupérons dans une table les phrases 
découpées avec les mots grammaticaux entourés de leur contexte gauche et droit comme 
nous montre la figure qui suit où nous avons isolé quelques déterminants en alignant leur 
contexte mot par mot ou signe par signe et nous les observons. 
Chapitre IV : START  139 
START 2003 
 
J’ ai un peu de fièvre depuis quelques jours . 
Et voilà un homme très bien fait et ... qui 
Les peuples de Nations Unies ont proclamé à nouveau leur 
et qui la dévorait des yeux . CHAPITRE HUITIEME  
Figure 14 :  Extrait du tableau avec les déterminants comme noyau. 
Le développement de cette approche a été basé sur l’étude des marques grammaticales ou 
marques de repérage [Bernard 1994]. Et c’est l’approche qui introduit le processus de text 
chunking dont nous avons parlé dans le chapitre précédent (état de l’art). 
4.5. Le système des règles 
4.5.1. Elaboration des règles 
Après avoir « examiné » les régularités de la distribution des mots grammaticaux ainsi que 
celle de leur contexte, nous avons pu élaboré une synthèse des règles qui nous permettent de 
déterminer l’étendue des groupes syntaxiques tels que le groupe nominal et le groupe verbal 
ainsi que le groupe prépositionnel et les subordonnées relatives. La présence des marqueurs 
permet la construction des règles. Les marqueurs sont des mots qui prédisent la présence de 
différentes catégories grammaticales, par exemples les articles pour les substantifs, les 
pronoms pour les verbes etc. Les statistiques effectuées dans l’ensemble du corpus basées 
sur l’analyse distributionnelle [Harris 1954], nous ont permis d’étudier le contexte des mots 
grammaticaux1. 
                                                   
1. Nous avons utilisé plusieurs types de marques grammaticales pour effectuer les statistiques sur la distribution 
quantitative de leur emploi. Ceci pourrait être un outil précieux de “typage” sémantique grossier des noms. 
140  Chapitre IV : START 
START 2003 
Les règles élaborées de notre système informatique sont issues des observations sur des 
statistiques effectuées dans l’ensemble du corpus, après avoir étudié les fonctions et le 
comportement des mots grammaticaux. Les règles sont pertinentes pour le traitement 
automatique que nous effectuons au sein de ce projet. 
Nous présentons quelques figures où l’on voit la présence de différents types de mots 
grammaticaux utilisés dans les règles. Selon le contexte nous constatons une hausse ou une 
baisse de certaines catégories grammaticales, par exemple la présence des relatifs est quasi-
nulle au contexte droit (CD1) juste après les pronoms personnels. 
Figure 15 :  Présence des relatifs, prépositions et conjonctions dans le contexte des 
pronoms 
Présence des relatifs - prépositions - conjonctions
0
5
10
15
20
25
relatifs
prépositions
conjonctions
CG3
CG2
CG1
CD1
CD2
CD3
CD4 CD5 CD6
%
Contexte Gauche Contexte Droit
Chapitre IV : START  141 
START 2003 
Pour définir l’étendue d’un groupe nominal ou verbal les signes de ponctuation jouent un 
rôle majeur surtout après observation de leur présence forte dans certains contextes. Le 
graphe qui suit nous montre la présence des mots grammaticaux qui ne sont pas utilisés 
étant que noyau.. 
Figure 16 :  Proportion d’apparition de certaines catégories grammaticales 
Le détecteur des structures syntaxiques a la forme d’un tableau de règles où l’on trouve la 
correspondance entre les unités lexicales du texte et les règles à appliquer. Nous présentons 
3 types de tables de règles :- 
$ le premier type de table correspond avec les règles qui définissent les frontières 
d’un groupe syntaxique, dans le tableau 3.7. nous pouvons voir les règles qui 
déterminent un syntagme substantif. 
unités lexicales
relatifs
5%
prépositions
7%
conjonctions
2%
reste de mots
86%
142  Chapitre IV : START 
START 2003 
$ le deuxième type de table montre les règles utilisées pour extraire les groupes 
syntaxiques, les colonnes de « décision » et « cas » sont vides. Le tableau 3.8. donne 
les règles qui sont utilisés pour extraire les groupes verbaux, et 
$ le troisième type de table donne les règles de désambiguïsation entre l’article défini 
et le pronom personnel. 
Nous présentons ci-dessous les tables de règles correspondant à chaque type mentionné plus 
haut. Sans avoir la prétention de montrer une liste exhaustive (la langue est riche en 
expressions et tournures), nous avons élaboré une liste qui correspond au maximum de cas 
rencontrés après des statistiques faites sur le corpus. 
Chapitre IV : START   143 
Anna PAPPA, Université PARIS VIII, Labo d’I.A., Programmation Holistique, groupe CSAR 
Tableau 17 :  Table des règles du système pour la reconnaissance de l’étendue de GN 
 
 
N° CG3 CG2 CG1 Mot_Gr CD1 CD2 CD3 CD4 CD5 CD6 Décision Cas Prio
1  * * * =Verbal * * * * * Syntagme Verbal Subordonnée 1 
2  * * * * =De * *=Relatif * * CD4=marque d'arrêt Dét+Subst+de+Subst+Relatif 4 
3  * * * =Relatif * * * * * Sub Relative avec SS Relatif + Substantif 2 
4  * * * * =Déterminant * * * * CD2=marque d'arrêt Dét+Subst+(Dét+Subst) 2 
5  * * * * * * =Ponctuation * * CD4=marque d'arrêt Dét+EG/Subst+Subst/ED 4 
6  * * * * =Préposition * * * * CD2=marque d'arrêt Dét+Substantif 2 
7  * * * * =Ponctuation * * * * CD2=marque d'arrêt Dét+Substantif 2 
8  * * * * * =De * =Ponctuation * CD5=marque d'arrêt Dét+Subst+De+Subst 5 
9  * * * * =Préposition =Déterminant * * * CD2=marque d'arrêt Dét+Subst 2 
10  * * * * * =Pronom * * * CD3=marque d'arrêt Dét+Subst+ED-EG 3 
11  * * * * * =Ponctuation * * * CD3=marque d'arrêt Dét+Subst+ED-EG 3 
12  * * * * =Conjonction * * * * CD2=marque d'arrêt Dét+Subst+Conjoc+Dét(autre SS) 2 
13  * * * * =De =Déterminant * * * CD5/CD6=marque d'arrêt Dét+Subst+De+Subst 2 
14  * * * * * =Conjonction * * * CD3=marque d'arrêt Dét+Subst/EG+Subst/ED 2 
15  * * * * =Relatif * * * * CD2=marque d'arrêt Dét+Subst+Relatif 2 
16  * * * * * =Relatif * * * CD3=marque d'arrêt Dét+Subst /EG+Subst/ED 3 
17  * * * * * =Préposition * * * CD3=marque d'arrêt Dét+Subst /EG+Subst/ED 3 
18  * * * * =De * =Ponctuation * * CD5=marque d'arrêt Dét+Subst+Prep 5 
19  * =Pronom * * * * * * * Syntagme Verbal Pronom+Pronom 1 
20  * * * * =De * =Relatif * * CD4=marque d'arrêt Dét+Subst+De+Nombre 4 
144   Chapitre IV : START  
START 2003 
Tableau 18 :  Table des règles définissant les GV 
  
N° CG3 CG2 CG1 Mot_Gr CD1 CD2 CD3 CD4 CD5 CD6 Num Décisio Cas Priori Vérité 
1 * * * * =avoir =Preposition * =Prapd * * 1   1 1 
2 * * * * * =Preposition =Negation * * * 2   1 1 
3 =Pronomina * - * =Ponctuation * * * * * 3   1 1 
4 * * =Majuscu * * =Prapd * * * * 4   1 1 
5 * * * * =Pro =Verbe_Aux =Pracpdn * * * 5   1 1 
6 =Prac1 * - * =Ppad * * * * * 6   1 1 
7 * * =Prepositi * =Ppad * * * * * 7   1 1 
8 * * =Nere * * =Pracpdn * * * * 8   1 1 
9 * * =Pro * * =Prapd * * * * 9   1 1 
10 * * * * =Negation =Pro * =Pracpdn * * 10   2 2 
11 =Negation * - * =Negation * * * * * 11   2 2 
12 * * =Prac1 * =Negation * =Pracpdn * * * 12   2 2 
13 * * * * =Negation * =Nere * * * 13   1 1 
14 * * * * =avoir =Ppad * * * * 14   1 2 
15 * * * * =avoir * =Pracpdn * * * 15   1 1 
16 * * * * =Verbe_Aux =Ppad * * * * 16   2 2 
17 * * * * =etre * =Pracpdn * * * 17   2 2 
18 * * * * =Verbe_Aux * =PronomT * * * 18   2 2 
19 * * * * =Pro =Pro * * * * 19   1 1 
20 * * * * =Pro * =Pracpdn * * * 20   1 1 
21 * * =Relatif * =Ppad * * * * * 21   2 2 
22 * * * * =Negation =Pro * * * * 22   2 2 
23 * * * * * *er * * * * 23   2 2 
24 * * * * * *ment * * * * 24   2 2 
25 * * * * * *re * * * * 25   2 2 
26 * * =Pracpdn * * =Pracpdn * * * * 26   2 2 
27 * * =Prac * * =Pro * * * * 27   2 2 
28 * * * * =Negation * =Pracpdn * * * 28   2 2 
29 * * * * * *ir * * * * 29   2 2 
30 * * =Prac * =Pro * * =Pracpdn * * 30   3 3 
31 * * =Pracpdn * =Negation * =Pro * *  31   2 3 
 
Chapitre IV : START   145 
Anna PAPPA, Université PARIS VIII, Labo d’I.A., Programmation Holistique, groupe CSAR 
N° CG3 CG2 CG1 Mot_Gr CD1 CD2 CD3 CD4 CD5 CD6 Num Décision Cas Priorité Vérité 
4 la porte sur le médecin , et , se précipitant 22 /GP/sur /GN/  le médecin/ <S>médecin 1 1 
5 se précipita
nt 
vers le lit où était couchée sa maîtresse 22 /GP/vers / GN/ e lit/ <S>lit 1 1 
7 se mit avec une frénésie de bonheur et une furie 15 /GP/avec /GN/une frénésie de 
bonheur/ 
<S>frénésie 1 1 
8 de bonheur et une furie de caresses à embrasser , 12 /GN/une furie de caresses/ <S>furie 2 1 
9 par - dessus les couvertures , le pauvre corps tout 20 /GP/dessus /GN/ les 
couvertures/ 
<S>couvertures 5 1 
12 tout petit dans le lit trop grand comme un corps 23 /GP/le lit trop grand/ <S>lit 4 1 
13 trop grand comme un corps d' enfant . La vieille 12 /GN/un corps d' enfant/ <S>corps 2 1 
16 la tête dans ses deux mains , la serra contre 21 /GP/dans/GN/ es deux mains/ <S>deux 2 1 
18 la serra contre son coeur , poussa un soupir , 22 /GP/contre /GN/ son coeur/ <S>coeur 1 1 
19 coeur , poussa un soupir , et laissa échapper : 20 /GV/poussa /GN/ un soupir/ <S>soupir 5 1 
23 de tôle , des lignes de toits , et au 12 /GN/des lignes de toits/ <S>lignes 2 1 
24 toits , et au loin , entre deux maisons qui 13 /GN/au loin/ <S>loin 2 1 
25 touchaient presque , la branche sans feuilles d' un arbre 13 /GN/la branche/ <S>branche 2 1 
26 sans feuilles d' un arbre qu' on ne voyait pas 22 /GP/d' /GN/un arbre/ <S>arbre 1 1 
27 pas . Dans la chambre , sur la cheminée , 22 /GP/Dans /GN/ la chambre/ <S>chambre 1 1 
28 chambre , sur la cheminée , posait dans une boîte 22 /GP/sur /GN/ la cheminée/ <S>cheminée 1 1 
29 , posait dans une boîte d' acajou carrée une pendule 16 /GP/dans/GN/ une boîte/ <S>boîte 1 1 
32 large cadran , aux gros chiffres , aux heures lourdes 24 /GN/aux gros chiffres/ <S>gros 5 3 
33 gros chiffres , aux heures lourdes . A côté deux 24 /GN/aux heures lourdes/ <S>heures 5 3 
35 col autour d' un carquois doré , étaient sous verre 21 /GP/d'/ un carquois doré/ <S>carquois 2 1 
38 un fauteuil à la Voltaire , recouvert d' une de 22 /GP/à / la Voltaire/ <S>Voltaire 1 1 
40 d' une de ces tapisseries à dessin de damier que 14 /GP/de ces tapisseries à dessin/ <S>tapisseries 2 1 
42 petites filles et les vieilles femmes , étendait ses bras 24 /GN/les vieilles femmes/ <S>vieilles 5 3 
44 Italie , dans le goût de Bertin , une aquarelle 15 /GP/dans /GN/le goût de Bertin/ <S>goût 1 1 
45 de Bertin , une aquarelle de fleurs avec une date 12 /GN/une aquarelle de fleurs/ <S>aquarelle 2 1 
46 de fleurs avec une date à l' encre rouge au 16 /GP/avec/GN/ une date/ <S>date 1 1 
48 au bas , quelques miniatures , pendaient accrochés au mur 13 /GN/quelques miniatures/ <S>miniatures 2 1 
50 mur . Sur la commode d' acajou , d' un 15 /GP/Sur /GN/la commode d' 
acajou/ 
<S>commode 1 1 
51 acajou , d' un style Empire , un Temps en 21 /GP/d'/ un style Empire/ <S>style 2 1 
52 style Empire , un Temps en bronze noir et courant 13 /GN/un Temps/ <S>Temps 2 1 
Tableau 19 :  Table des règles de désambiguïsation entre l’article défini et le pronom personnel 
146  Chapitre IV : START 
START 2003 
Ces tableaux sont le résultat de l’étude sur l’étendue et les propriétés de différents 
syntagmes. Le code est complètement transparent dans la mesure où l’utilisateur peut 
intervenir dans la table des règles, en ajoutant une ou en enlevant une autre si toutefois cela 
semble sujet à d’éventuelles erreurs, sans qu’il y ait besoin de modifier quoi que ce soit 
dans le programme. Nous pouvons considérer ces règles comme des règles d’une 
grammaire à contraintes. La grammaire anglaise du ENGCG système contient 1185 
contraintes linguistiques de l’ordre linéaire d’étiquettes morphologiques [Voutilainen 1995]. 
4.5.1.1. Notation des tableaux de règles 
Le tableau est composé de 10 colonnes et d’une trentaine de lignes qui contiennent les 
règles du système. Les signes « * »signifient n’importe quel mot contenu dans les cellules 
du tableau. Le signe « = » renvoie automatiquement à une fonction traitée par le moteur 
(Parsing). Le moteur appelle la fonction Equivalence qui à son tour appelle par exemple les 
fonctions (=Déterminant), (=Relatif), et autres mentionnées dans le tableau de règles. 
N° :  La première colonne contient le nombre de règles, nous en avons autour 
de la trentaine, dans les textes n° correspond aux nombres de phrases à 
traiter. 
CG3, 2,1 :  Contexte Gauche ces trois colonnes contiennent le contexte qui se trouve 
à gauche du mot grammatical proposé par ordre décroissant. 
Mots_Gram : La quatrième colonne contient les mots grammaticaux selon la table de 
règles on trouve trois catégories de noyau : déterminants pour définir les 
groupes nominaux, pronoms personnels pour définir les groupes verbaux 
et la troisième table contient l’article défini ou pronom personnel afin de 
désambiguïser leur fonction selon le contexte. 
CD1,2,3,4,5,6 Contexte Droit, il s’étend du premier mot après le mot grammatical et 
juste au sixième mot. 
Num : Le numéro de la règle appliquée. Outil qui nous permet de valider et 
mesurer les règles définies. 
Chapitre IV : START  147 
Anna PAPPA, Université PARIS VIII, Labo d’I.A., Programmation Holistique, groupe CSAR 
Décision :   Dans la colonne Décision nous trouvons les frontières des groupes 
syntaxiques, ou les groupes mêmes délimités dans leurs frontières (voir 
exemples au chapitre suivant). 
Cas :  Dans la colonne Cas nous expliquons la Décision sur l’étendue des 
groupes syntaxiques ou les lexèmes étiquetés suivant le traitement, par 
exemple <V>faire ou <N>chose. 
Priorité L’avant dernière colonne est un flag qui sert pour le classement et 
l’application des règles selon le contexte. 
Vérité La dernière colonne est un indice d’erreur possible selon la règle 
appliquée. Les valeurs de cette colonne vont de 1 à 7. Nous avons défini 
ces valeurs suite à une vérification manuelle effectuée sur une partie du 
corpus traité (voir chapitre V). 
Ensuite nous présentons l’image de notre application, où l’utilisateur n’a qu’à appuyer sur 
le bouton de Traitement. Il y a une boîte de dialogue qui apparaît où il faut donner le nom 
du texte à traiter, ensuite on valide le nom de la table choisie en appuyant sur ‘OK’ et la 
procédure commence. 
 
Figure 17 :   Le clic sur le bouton exécute le programme de la reconnaissance des 
groupes verbaux 
 
148  Chapitre IV : START 
START 2003 
La figure qui suit montre la boite de dialogue qui s’ouvre lorsqu’on clique sur le bouton de 
reconnaissance des GV. 
 
Figure 18 : La boite de dialogue pour le traitement des textes du corpus, ici « Candide » 
L’analyse se fait en plusieurs niveaux : 
- la première analyse détermine les groupes syntaxiques dans leurs frontières 
- la deuxième analyse extrait les groupes syntaxiques détectés 
- la troisième analyse consiste en la désambiguïsation de cas ambigus, ici le cas de 
l’article défini et du pronom personnel. 
- Toutes les analyses peuvent aboutir à l’ajout des nouveaux mots dans le 
dictionnaire. 
Avant d’exposer le fonctionnement du dictionnaire nous détaillons la procédure de la 
désambiguïsation. Ici aussi il y a 3 analyses (three-pass parsing, par rapport au multiple-
pass parsing) :  
Chapitre IV : START  149 
Anna PAPPA, Université PARIS VIII, Labo d’I.A., Programmation Holistique, groupe CSAR 
- la première est la correspondance du cas avec une règle définie, 
- la deuxième analyse procède à la vérification des cas non résolus par rapport au 
contexte droit du mot ambigu. Si le même cas est déjà résolu dans le texte alors on 
applique le même résultat à cette phrase, et 
- la troisième consiste en la comparaison entre les cas non résolus et les entrées 
lexicales. Nous vérifions si le mot du contexte droit est présent dans le dictionnaire 
et on copie le résultat. Cette application dépasse le 99% de résolution. 
4.6. Dictionnaire 
Après avoir approfondi notre étude sur le fonctionnement des groupes syntaxiques, nous 
avons élaboré un système à base de règles qui reconnaît les syntagmes nominaux et verbaux 
à leur étendue en les identifiant dans leur contexte et reconnaît les substantifs et des verbes 
qui font partie de ces groupes. Le tableau de règles codées comme des données présente une 
facilité d’emploi. Le moteur du traitement (parsing) qui appelle les fonctions est une 
approche ergonomique efficace pour le temps de traitement. 
Figure 19 :   La boite de dialogue permettant d’ajouter des nouveaux mots dans le 
dictionnaire 
 
150  Chapitre IV : START 
START 2003 
 
A l’issue du traitement, le programme crée un dictionnaire avec des mots reconnus 
précédemment en donnant comme information leur catégorie grammatical. Dans le 
dictionnaire nous pouvons ajouter les mots taggés (se trouvent dans ‘Cas’), après l’analyse 
syntaxique. Nous utilisons le dictionnaire pour la troisième étape du processus de 
désambiguïsation. Il ajoute le mot trouvé aux cas qui n’ont pas été répondus. Le 
dictionnaire est utilisé en récursif. 
 
 
 
 
 
 
 
 
 
 
 
Chapitre V 
 
 
RESULTATS ET EXPERIMENTATIONS 
 
 
152  Chapitre V : Résultats et expérimentations  
START 2003 
Sommaire du chapitre V 
RESULTATS ET EXPERIMENTATIONS 
5.1. Reconnaissance de différents groupes syntaxiques 
5.2. Vérification et évaluation des résultats 
5.3. Création du lexique 
 
Chapitre V : Résultats et expérimentations  153 
Anna PAPPA, Université PARIS VIII, Labo d’I.A., Programmation Holistique, groupe CSAR 
 
Nous présentons ici les résultats obtenus par notre système en exposant des tables de 
phrases avec la reconnaissance (décision) du groupe syntaxique ainsi que le cas pour lequel 
est attribué une étiquette à un mot de ce groupe. Le choix du mot pour l’étiqueteur se fait 
par rapport au cas le plus sûr, c'est-à-dire que dans le groupe il y a un mot pour lequel nous 
pouvons dire qu’il appartient à telle ou telle catégorie grammaticale (par exemple nom) et 
même dire sa fonction syntaxique dans la phrase (par exemple sujet)1. Les résultats sont 
répartis de la façon suivante : d’abord nous donnons un extrait de la reconnaissance des 
groupes dans leurs limites, c'est-à-dire les syntagmes en leur étendue avec marques d’arrêt. 
Ensuite nous présentons des résultats avec reconnaissance et extraction des groupes 
nominaux, et dans une autre tables avec des groupes verbaux. La dernière table donne un 
extrait du traitement de la désambiguïsation entre article et pronom. A la fin nous 
présentons un extrait du lexique construit au fur et à mesure des traitements. 
5.1. Reconnaissance de différents groupes syntaxiques 
Les règles respectent la linéarité des phrases. Il y a une trentaine de règles par table environ. 
La présentation en tableau est un concept ergonomique qui nous permet facilement 
d’enlever ou d’ajouter une règle dans le système. Nous avons choisi d’élaborer des règles à 
partir des contextes gauche (CG) et droit (CD) du noyau (mots grammaticaux). La première 
ligne du tableau donne la fonction de chaque colonne. La première colonne correspond au 
numéro de chaque règle2. Les trois colonnes qui suivent contiennent le contexte gauche du 
noyau (noté CG). La colonne intitulée Mot_Gram contient le noyau (mots grammaticaux), 
                                                   
1. La prédication de la fonction syntaxique est en train de se développer et nous en parlerons dans les perspectives 
car nous n’avons pas effectué des analyses sur la totalité du corpus. 
2. L’étoile signifie n’importe quel mot, le « = » renvoie automatiquement à une fonction (subroutine) traitée par le 
moteur (parsing). Le moteur appelle la fonction (=Verbal) ou (=Relatif) ou autre (il y en a une dizaine environ) 
qui renvoie vrai si le cas est vérifié, et la règle s’applique. 
154  Chapitre V : Résultats et expérimentations  
START 2003 
ensuite nous avons six colonnes1 qui contiennent le contexte droit du noyau. La colonne 
nommée “num” contient le n° de la règle appliquée, celle intitulée “décision” contient le 
groupe syntaxique à ses frontières, la colonne “cas” justifie la décision et donne l’étiquette 
aux composants du groupe, et les deux dernières colonnes “priorité” “vérité” donnent 
respectivement la priorité pour l’application des règles et le taux d’erreur qui nous permet 
de construire notre dictionnaire en fin de traitement. 
Nous présentons quelques exemples extraits du corpus qui montrent l’application des 
règles, les phrases ont été choisies en fonction de la colonne décision afin de mieux illustrer 
le tableau des règles présenté plus haut. Nous ne montrons ici qu’une partie de la phrase 
correspondant à un syntagme substantif ou verbal. 
 
 
 
 
 
 
 
                                                   
1. Les statistiques ont montré qu’il est extrèmement rare de rencontrer un syntagme substantif –encore  moins un 
syntagme verbal – qui s’étende au-delà de 7 mots dans son contexte droit après le déterminant. 
Chapitre V : Résultats et expérimentations   155 
Anna PAPPA, Université PARIS VIII, Labo d’I.A., Programmation Holistique, groupe CSAR 
Tableau 20 :  Extrait des résultats de détection de groupes nominaux  
Nu CG3 CG2 CG1 Mot_Gra CD1 CD2 CD3 CD4 CD5 CD6 N Décision Cas Priori Vérit
22 la fenêtre montrait un étroit morceau de ciel coupé de 11 /GN/un étroit morceau/ <S>étroit 2 1 
23 de tôle , des lignes de toits , et au 12 /GN/des lignes de toits/ <S>lignes 2 1 
24 toits , et au loin , entre deux maisons qui 13 /GN/au loin/ <S>loin 2 1 
25 touchaie presque , la branche sans feuilles d' un arbre 13 /GN/la branche/ <S>branche 2 1 
26 sans feuilles d' un arbre qu' on ne voyait pas 22 /GP/d' /GN/ un arbre/ <S>arbre 1 1 
27 pas . Dans la chambre , sur la cheminé , 22 /GP/Dans /GN/ la chambre/ <S>chambre 1 1 
28 chambre , sur la cheminée , posait dans une boîte 22 /GP/sur /GN/ la cheminée/ <S>cheminée 1 1 
29 , posait dans une boîte d' acajou carrée une pendule 16 /GP/dans /GN/ une boîte/ <S>boîte 1 1 
30 d' acajou carrée une pendule au large cadran , aux 13 /GN/une pendule/ <S>pendule 2 1 
31 carrée une pendule au large cadran , aux gros chiffres 24 /GN/au large cadran/ <S>large 5 1 
32 large cadran , aux gros chiffres , aux heures lourdes 24 /GN/aux gros chiffres/ <S>gros 5 1 
33 gros chiffres , aux heures lourdes . A côté deux 24 /GN/aux heures lourdes/ <S>heures 5 1 
34 cygnes argentés tendant leur col autour d' un carquois doré   non résolu 10  
35 col autour d' un carquois doré , étaient sous verre 21 /GP/d'/GN/ un carquois doré/ <S>carquois 2 1 
36 . Près de la cheminée un fauteuil à la Voltaire 25 /GP/Près de/GN/la cheminée/ <S>cheminée 2 1 
37 de la cheminée un fauteuil à la Voltaire , recouvert 24 /GN/un fauteil/ <S>fauteuil 5 1 
38 un fauteuil à la Voltaire , recouvert d' une de 22 /GP/à /GN/ la Voltaire/ <S>Voltaire 1 1 
39 , recouvert d' une de ces tapisseries à dessin de   non résolu 10  
40 d' une de ces tapisseries à dessin de damier que 14 /GN/une de ces tapisseries/ <S>tapisserie 2 1 
41 damier que font les petites filles et les vieilles femmes 24 /GN/les petites filles/ <S>petites 5 1 
42 petites filles et les vieilles femmes , étendai ses bras 24 /GN/les vieilles femmes/ <S>vieilles 5 1 
43 femmes , étendait ses bras vides . Deux petits paysages 24 /GN/ses bras vides/ <S>bras 5 1 
44 Italie , dans le goût de Bertin , une aquarelle 15 /GP/dans /GN/le goût de Bertin/ <S>goût 1 1 
45 de Bertin , une aquarelle de fleurs avec une date 12 /GN/une aquarelle de fleurs/ <S>aquarelle 2 1 
 
156   Chapitre V : Résultats et expérimentations 
START 2003 
Tableau 21 :  Extrait de résultats de reconnaissance des groupes verbaux 
Nu CG3 CG2 CG1 Mot CD1 CD2 CD3 CD4 CD5 CD6 Nu Décision Cas Pri Véri
23 la douleur que nous éprouvons à ne pouvoir les faire 2 /GN/nous éprouvons /GPà <V>éprouvons 1 1 
24 faire connaîtr . Je ne savais pas que , même 13 /GV/ Je ne savais pas/ <V>savais 1 1 
25 m' interdire , il me quittait les yeux mouillés de 20 GV/il me quittait/ <V>quittait 1 1 
26 de ce que je ne l' aimais pas . Ma 8 /GV/que je ne l'aimais pas/ <V>aimais 1 1 
27 , parce que j' étais plus jeune , je m' 8 /GV/que j' étais plus/ <V>étais 1 1 
28 plus jeune , je m' accoutumai à renfermer en moi 20 GV/je m' accoutumai/ <V>accoutumai 1 1 
29 tout ce que j' éprouvais , à ne former que 8 /GV/que j' éprouvais ,/ <V>éprouvais 1 1 
30 un obstacle . Je contractai l' habitude de ne jamais 26 /GV/Je contractai/ <V>contractai 2 2 
31 causer sérieuse que j' ai toujours peine à surmonte . 8 /GV/que j' ai toujours/ <V>ai 1 1 
32 à surmont . Il en résulta en même temps un 20 GV/Il en résulta/ <V>résulta 1 1 
33 des liens dont j' étais environné , une terreur invincible 17 /GV/j' étais environné / <V>étais 2 2 
34 de nouveau . Je ne me trouvais à mon aise 10 /GV/Je ne me trouvais/ <V>trouvais 2 2 
35 important , quand je dois choisir entre deux partis , 29 /GP/je dois choisir/ <V>dois<V>choi 2 2 
36 en paix . Je n' avais point cependant la profondeur 13 /GV/ Je n' avais point/ <V>avais 1 1 
37 à moi , je m' intéressais faiblement à moi - 30 /GV/je m' intéressais/ <V>intéressais 3 3 
38 - même . Je portais au fond de mon coeur 26 /GV/Je portais/ <V>portais 2 2 
39 de sensibilit dont je ne m' apercevais pas , mais 10 /GV/je ne m' apercevais/ <V>apercevais 2 2 
40 et sur laquelle je n' ai jamais conçu que les 13 /GV/ je n' ai jamais/ <V>ai 1 1 
41 monde , qu' elle ne connaissait pas , avec le 13 /GV/ elle ne connaissait pas/ <V>connaissait 1 1 
42 mais nécessai , elle avait vu ses espérance trompées , 15 /GV/elle avait vu/ <PP>vu 1 1 
43 la soumettr . Elle vivait dans un château voisin d' 26 /GV/Elle vivait/ <V>vivait 2 2 
44 conversat inépuisa , nous avions envisagé la vie sous toutes 15 /GV/nous avions envisagé/ <PP>envisagé 1 1 
45 la mort avec elle , j' avais vu la mort 7 /GP/avec elle/ <Prep + Pron> 1 1 
46 avec elle , j' avais vu la mort la frapper 15 /GV/j' avais vu/ <PP>vu 1 1 
47 abandon pas . Je lisais de préférence dans les poètes 26 /GV/Je lisais/ <V>lisais 2 2 
48 vie humaine . Je trouvais qu' aucun but ne valait 26 /GV/Je trouvais/ <V>trouvais 2 2 
49 aucun effort . Il est assez singulier que cette impression 16 /GV/Il est assez/ <S>assez 2 2 
50 ce parce qu' il y a dans l' espéranc quelque 5 /GV/il y a /dans/ <V>a 1 1 
51 que , lorsqu' elle se retire de la carrière de 20 GV/elle se retire/ <V>retire 1 1 
52 se dissipent ? Je me rendis , en quittant Gottingue 20 GV/Je me rendis/ <V>rendis 1 1 
53 ou médiocre . Je fus accueilli dans cette cour avec 28 /GV/Je fus accueilli/ <PP>accueilli 2 2 
54 Pendant quelques mois je ne remarquai rien qui put captiver 13 /GV/je ne remarquai rien/ <V>remarquai 1 1 
55 l' obligean qu' on me témoignait ; mais tantôt ma 20 GV/on me témoignait/ <V>témoignait 1 1 
56 insipides que l' on m' invitait à partager . Je 20 GV/on m' invitait/ <V>invitait 1 1 
 
Chapitre V : Résultats et expérimentations   157 
Anna PAPPA, Université PARIS VIII, Labo d’I.A., Programmation Holistique, groupe CSAR 
 
Tableau 22 :  Extrait des résultats après désambiguïsation entre l’article défini et le pronom personnel 
N° CG3 CG2 CG1 Mot_G CD1 CD2 CD3 Num Décision Cas Priorit Vérit
88 , de toutes les raisons qui sont 28 pluriel article 3 1 
89 . Ce sont les gens scrupuleux , 28 pluriel article 3 1 
90 par rapport à la religion , à 9 suffixe article 3 1 
91 ailleurs que sur la Terre . Je 20 nom propre article 1 1 
92 délicatesses excessives que l' on a faites 10 l'on l'on 1 2 
93 a faites sur le fait de la 11 imparfait pronom 3 1 
94 le fait de la religion , et 9 suffixe article 3 1 
95 même que je l' aurais respectée au  Equiv enr n° 1525 pronom 3 2 
96 point de ne la vouloir pas choquer  Dico n° 1558 pronom 2 1 
97 vous dit que la Lune est habitée 20 nom propre article 1 1 
98 de difficultés . La postérité d' Adam 19 début de phrase article 1 1 
99 étendre jusque dans la Lune , ni 20 nom propre article 1 1 
100 - là . Les hommes qui sont 19 début de phrase article 1 1 
101 qui sont dans la Lune ne sont 20 nom propre article 1 1 
102 embarrassant , dans la théologie , qu' 8 prep+substantif article 1 1 
103 davantage , toutes les difficultés imaginables se 17 suffixes accordées pluriel article 2 1 
104 cela , et les termes qu' il 28 pluriel article 3 1 
105 - ci . L' objection roule donc 19 début de phrase article 1 1 
106 tout entière sur les hommes de la 28 pluriel article 3 1 
107 les hommes de la Lune , mais 20 nom propre article 1 1 
108 sont ceux qui la font , à 25 pronom relatif pronom 3 1 
109 des hommes dans la Lune ; moi 20 nom propre article 1 1 
110 ? je ne les ai point vus  Dico n° 1446 pronom 1 1 
111 est pas pour les avoir vus que  Equiv enr n° 2649 pronom 3 2 
112 d' hommes dans la Lune , vous 20 nom propre article 1 1 
113 en ait selon l' idée que j' 16 suffixe article 2 1 
114 j' ai de la diversité infinie que 15 suffixe article 2 1 
115 diversité infinie que la nature doit avoir  Equiv enr n° 1996 article 1 1 
 
158  Chapitre V : Résultats et expérimentations 
START 2003 
5.2. Vérification et évaluation des résultats 
La colonne « Vérité » est un indice d’erreur allant de 1 à 7. Cet indice a été défini après 
avoir vérifié manuellement une partie du corpus. Nous avons récupéré 32559 phrases que 
nous avons traité manuellement de la façon suivante : 
- nous avons trouvé et défini les groupes verbaux, les groupes nominaux ainsi que les 
groupes prépositionnels et les subordonnées relatives en leur totalité (acceptant 
toujours un très faible pourcentage d’erreur ou d’oubli humain). 
- nous avons effectué l’analyse de reconnaissance sur cette partie sans aucune 
information supplémentaire et nous avons mesuré le pourcentage d’erreur en 
comparant le résultat aux résultats donnés manuellement. 
- chaque règle est vérifiée par rapport aux résultats correspondants, et nous calculons 
le nombre de cas qui n’ont pas été correctement reconnus. Nous avons trouvé 230 
phrases pour lesquelles les cas étaient mal définis, ceci représente 0,70 % d’erreur 
par rapport à la totalité des phrases. Chaque règle a été vérifiée séparément et nous 
avons défini l’indice selon le pourcentage d’erreur trouvé pour chaque règle 
appliquée. 
La signification des indices est la suivante : 1 pour les cas sans erreur, les cas trouvés sont 
candidats pour entrer dans le dictionnaire. 2 pour les cas où l’erreur est de l’ordre de 0,2 % 
par exemple pour une règle appliqué 950 fois nous n’avons trouvé que deux (2) erreurs. 3 
pour les cas où l’erreur est de l’ordre de 0,3 % et ainsi de suite. 
Il est souvent difficile de comparer les résultats que les auteurs rapportent de différents 
systèmes d’analyse. Une très grande partie de corpus est utilisée, soit homogène extraite du 
même corpus avec les mêmes notations soit d’un corpus hétérogène venu de sources 
diverses (journaux, romans, transcription de dialogues, etc.), dans l’effort de représenter la 
grande diversité du langage. La comparaison est difficile même quand il s’agit d’un seul 
corpus spécifique mais sur lequel chacun a porté ses propres marques de test ou de pré-
traitement tout simplement, et par conséquent les marques d’évaluation ne sont plus les 
Chapitre V : Résultats et expérimentations  159 
Anna PAPPA, Université PARIS VIII, Labo d’I.A., Programmation Holistique, groupe CSAR 
mêmes [Goodman 1996]. Plusieurs schémas sont utilisés pour évaluer la performance de 
systèmes : incluant des mathématiques exactes, ou mesurant des corrections de l’application 
des règles, nous trouvons parmi les plus connus le schéma PARSEVAL [Grishman et al. 
1992], qui mesure la performance et la consistance des analyses en respectant un standard 
manuellement annoté. Mais selon E. Briscoe et J. Carroll même ce schéma présente des 
problèmes quand il évalue des systèmes incorporant des grammaires créées à la main avec 
des « treebanks » existants qui souvent emploient des conventions d’analyse différentes 
[Briscoe et Carroll 1995]. 
CORPUS non annoté Précision 
en % 
Rappel 
(calculé 
manuellement
en % 
F-mesure 
en % 
Erreur 
en % 
Reconnaissance des GN 91,8 98,76 95,15 0,73 
Reconnaissance des GV 92,6 99,01 95,69 0,51 
Désambiguïsation 99,1 99,99 99,54 0,86 
Tableau 23 :  Résultats du système START 
160  Chapitre V : Résultats et expérimentations 
START 2003 
Nu
m 
CG2 CG1 Noyau CD1 CD2 CD3 CD4 CD5 CD6 Décision Cas Flag 
385 , et aucun ne va de droit fil , 
Syntagme 
Verbal 
Négation 
ou type 
verbal 
1 
155 ! je les 
comma
nderai 
! - Oui , vous 
Syntagme 
Verbal 
CD2 :m.a 
Pronom + 
Pronom 
1 
123 baisa 
innoce
ment 
la main de la jeune 
demois
elle 
avec 
Synt 
Substantif 
CD5/CD6 : 
m.a 
Dét+Subs
t+prep+d
ét+subst 
2 
166 bleus , les 
person
nes 
de votre figure qui 
semble
nt 
Synt 
Substantif 
CD4 : m.a 
Dét+Subs
t+prep+su
bst+relatif 
4 
134 et voyant cette cause et cet effet , chassa 
Synt 
Substantif 
CD2 : m.a 
Dét+Subs
t+Conjonc
tion 
8 
160 Candide avec une 
modest
ie 
charma
nte 
, vous me faites 
Synt 
Substantif 
CD3 :m.a. 
Dét+EG/E
D+subst+
ponctuati
on 
3 
172 argent ; les 
homme
s 
ne sont faits que pour 
Synt 
Substantif 
CD2 : m.a 
Dét+subst
+négation 
2 
Tableau 24 :  Extrait des résultats 
Ensuite nous avons appliqué le même type de règles à notre corpus grec (composé 
principalement d’articles des journaux quotidiens en Grèce). Le tableau qui suit montre 
quelques extraits. Nous avons laissé les trois dernières colonnes en français pour faciliter la 
lisibilité des phrases. 
Chapitre V : Résultats et expérimentations  161 
Anna PAPPA, Université PARIS VIII, Labo d’I.A., Programmation Holistique, groupe CSAR 
Nu
m 
CG2 CG1 Noyau CD1 CD2 CD3 CD4 CD5 CD6 Décision Cas Flag 
16 τους 
Ευρωπ
αίους  
ο 
πλουρ
αλισµό
ς 
δεν είναι η 
µοναδ
ικότητ
α 
και 
Syntagme 
subst CD : 
m.a 
Négation 1 
412 . Όµως οι 
γόνιµε
ς 
επιρρο
ές 
και οι 
αλληλ
επιδρά
σεις 
είναι 
Syntagme 
subst CD3 : 
m.a 
Dét+EG/E
D+Subst+
Conjoncti
on+Dét 
2 
423 , που η ανάσα της 
απο
πνέε
ι 
πνευ
µατι
κότη
τα 
, 
δηµιου
ργικό 
Sub rel avec 
Syntagme 
subst CD3 : 
m.a 
Relatif+D
ét+Subst
+possessi
f 
2 
426 . Είναι µια πόλη µε 
ελλη
νιστι
κές 
και 
βυζαν
τινές 
ρίζες 
Syntagme 
subst CD2 : 
m.a 
Dét+Subs
t+prep 
4 
134 γι΄ αυτό τον 
προστ
ατεύο
υµε 
, τον 
προβ
άλλο
υµε 
και τον 
Syntagme 
verbal CD2 : 
m.a 
Pronom+
Pronom 
1 
Tableau 25 :  Extrait des résultats en grec 
5.3. Création du lexique 
Nous avons présenté le système qui reconnaît les syntagmes substantifs à leur étendue dans 
le chapitre précédent. Nous avons également introduit la procédure qui crée un dictionnaire 
à partir du contexte droit des déterminants en précisant le type grammatical nom ou verbe. 
Cette expérimentation, dont les résultats ne sont pas utilisés pour l’instant, pourrait s’avérer 
précieuse pour un traitement postérieur dans lequel le système chercherait des informations 
supplémentaires dans les entrées lexicales dont le type grammatical est déjà connu.  
La procédure qui crée ce dictionnaire est basée sur l’idée suivante : il y a des déterminants 
qui ne peuvent être suivis que par un nom soit substantif soit épithète, comme les possessifs 
par exemple. Pour les cas comme ceux-ci où il n’y a pas de possibilité d’erreur nous avons 
développé une procédure qui « récupère » les mots qui suivent le déterminant dans un 
162  Chapitre V : Résultats et expérimentations 
START 2003 
dictionnaire et qui marque le type grammatical (après les possessifs c’est nominal) de 
chaque entrée lexicale. 
De même dans les cas où il n’y a pas d’ambiguïté possible quant aux verbes, le programme 
« récupère » les lexèmes et les stocke dans le dictionnaire avec la notion de type verbal. Les 
entrées lexicales sont des formes fléchies.  
Nous donnons un extrait de notre lexique (qui compte plus de 49000 entrées pour l’instant), 
dans les pages suivantes. Le dictionnaire contient les mots1 qui se trouvent immédiatement à 
droite des mots grammaticaux : par exemple certains déterminants ne peuvent être suivis 
que par un nom (soit substantif soit épithète) pour la plupart des cas, comme les possessifs 
(sa maison). Pour des cas où l’ambiguïté est peu probable ou inexistante (flag 1), nous 
avons développé une procédure qui enregistre les mots de la colonne CD1. Les mots sont 
étiquetés en catégories grammaticales : verbale, participe passé, nominale. 
La figure qui suit montre un extrait du dictionnaire en français : 
N° CD1 Type Texte d’origine 
156 affamés nominal Luc 
62 armée nominal Pin_Up 
272 bourgeoisie nominal Paresse 
58 censure nominal Pin_Up 
73 doutes nominal Rêveries 
577 aggraver verbal Rêveries 
4519 attachait verbal Domi 
4430 blessaient verbal Domi 
Tableau 26 :  Extrait du tableau du dictionnaire 
                                                   
1. En leur forme fléchie. 
Chapitre V : Résultats et expérimentations  163 
Anna PAPPA, Université PARIS VIII, Labo d’I.A., Programmation Holistique, groupe CSAR 
Et voici quelques entrées du dictionnaire avec des mots grecs tirés des exemples dans le 
tableau qui suit : 
N° CD1 Type Texte d’origine 
412 αλληλεπιδράσεις nominal Eleftherotypia_Thessaloniki 
423 ανάσα nominal Eleftherotypia_Thessaloniki 
412 γόνιµες nominal Eleftherotypia_Thessaloniki 
16 µοναδικότητα nominal Kathimerini_Europe 
16 πλουραλισµός nominal Kathimerini_Europe 
426 πόλη nominal Eleftherotypia_Thessaloniki 
134 προβάλλουµε verbal Eleftherotypia_Thessaloniki 
134 προστατεύουµε verbal Eleftherotypia_Thessaloniki 
Tableau 27 :  Extrait du dictionnaire avec des mots grecs 
 
 

 
 
 
 
 
 
 
 
CONCLUSIONS ET PERSPECTIVES 
166  Conclusion 
START 2003 
The problem of natural language 
analysis is somewhat like counting 
from one to infinity, whereas in 
language generation you are 
counting from infinity to one 
Yorick Wilks 
Nous avons commencé cette étude en nous fixant comme but de réaliser un système qui 
reconnaisse les syntagmes syntaxiques à leur étendue, avec le minimum de règles possibles 
et sans dictionnaire préalable ni connaissance morphologique. Le système a été testé sur un 
grand corpus de textes non annotés. 
Nous avons créé un système robuste qui procède à une analyse des marques (mots 
grammaticaux principalement) sans connaissances préalables sur leur nature et leur 
fonctionnement. Le taux de réussite atteint presque 93% de cas résolus (reconnaissance des 
syntagmes substantifs, des syntagmes verbaux des syntagmes prépositionnels et 
reconnaissance des subordonnées relatives), dont le taux d’erreur est inférieur à 1% (les cas 
non résolus autour de 7 %, ceci correspond principalement à des contextes ambigus). 
L’algorithme peut être utilisé pour la résolution des cas ambigus (entre l’article défini et le 
pronom personnel par exemple) et cette analyse peut s’effectuer pour d’autres langues de 
même structure syntaxique que le français comme le montrent les résultats de l’analyse sur 
le corpus grec. Nous aimerions préciser que notre système START offre une 
désambiguïsation entre le pronom personnel et l’article avec un succès de l’ordre de 99,6 % 
et un taux d’erreur à 0,72%. 
Les résultats du traitement sont très satisfaisants. Nous avons eu l’occasion d’aborder 
plusieurs aspects du traitement automatique du langage naturel, telles que la disposition 
contextuelle, la distribution quantitative des marques grammaticales et les caractéristiques 
sémantiques dont sont dotés les désinences, les suffixes et les préfixes des lexèmes qui 
forment le contexte des mots grammaticaux.  
Conclusion  167 
Anna PAPPA, Université PARIS VIII, Labo d’I.A., Programmation Holistique, groupe CSAR 
La création du dictionnaire à partir du contexte droit des mots grammaticaux peut s’avérer 
précieuse pour un traitement où l’on chercherait des informations supplémentaires dans les 
entrées lexicales dont le type grammatical est déjà connu. Pour les cas non résolus aussi 
pouvons-nous envisager une utilisation des désinences des verbes ou même des verbes 
auxiliaires qui pourrait résoudre quelques cas ambigus. 
La procédure de découpage en phrases constitue un pré-traitement pour toute analyse du 
langage naturel. Nous avons développé un système robuste qui reconnaît les frontières 
d’une phrase et qui s’adapte à différentes langues. Il a été testé avec succès sur des corpus 
des langues naturelles comme le français et le grec. Nous n’utilisons aucune connaissance 
préalable (dictionnaire, liste d’abréviations, etc.), et les corpus ne sont pas annotés. Le taux 
de découpage sans faute atteint en moyenne pour les trois corpus 99,5%. La 
désambiguïsation des signes de ponctuation tels que le point, s’effectue grâce à un moteur 
de règles simples extraites de statistiques basées sur l’analyse distributionnelle des segments 
différents. Les balises produites par le système au cours du traitement offrent un outil 
précieux pour toute analyse syntaxique postérieure. Car bien que les humains semblent 
reconnaître immédiatement la bonne structure et les sens corrects des mots, plusieurs 
aspects du langage montrent que ce n’est pas toujours le cas. En particulier les phrases 
labyrinthes (garden path en anglais) conduisent à adopter une analyse qui est remise en 
cause par certains mots suivants. Dans ces cas-là la ponctuation, présence des virgules par 
exemple, peut être le facteur de désambiguïsation, donc les balises de la ponctuation en 
combinaison avec des balises des mots étiquetés comme les verbes les noms etc., peuvent 
aider à la désambiguïsation de l’interprétation d’une phrase. Ce postulat sémantique est 
prévu dans la suite du traitement. Nous allons illustrer ce cas d’ambiguïté avec un exemple 
emprunté à [Sabah 1989] : 
Le lac que l’écrivain décrit dans ce livre contemple est le Lac de Côme, 
Arrivé à contemple nous devons reconsidérer la structure de la phrase afin de pouvoir 
intégrer le verbe : on suppose alors que décrit est un participe passé et non pas un présent 
comme nous l’avons supposé au départ. Normalement la présence de virgules faciliterait 
notre première interprétation, il en serait de même pour le système. 
168  Conclusion 
START 2003 
 
Travaux testés sur le même corpus 
(par ordre d’année d’apparition) 
Précision
en % 
Rappel 
en % 
F-mesure 
en % 
[Kudo et Matsumoto 2001] 94,15 94,29 94,22 
[Tjong Kim Sang et al. 2000] 94,18 93,55 93,86 
[Tjong Kim Sang 2000] 93,63 92,89 93,26 
[Tjong Kim Sang et Veenstra 1999] 92,50 92,25 92,37 
[Muñoz et al. 1999] 92,40 93,10 92,80 
[Cardie et Pierce 1999] 89,00 90,90 89,90 
[Argamon et al. 1999] 91,60 91,60 91,60 
[XTAG Research Group 1998] 91,80 93,00 92,40 
[Veenstra 1998] 89,00 94,30 91,60 
[Cardie et Pierce 1998] 90,70 91,10 90,90 
[Ramshaw et Marcus 1995] 91,80 92,27 92,03 
Tableau 28 :  résultats publiés pour la reconnaissance des GN 
 
CORPUS non annoté 
(sur une totalité de 
122559 phrases) 
Précision 
en % 
Rappel (calculé manuellement 
sur un corpus de  
12255 phrases) 
F-mesure 
en % 
Erreur 
en % 
Reconnaissance des GN 92,8 99,71 96,13 0,73 
Reconnaissance des GV 92,6 99,84 96,08 0,51 
Désambiguïsation 99,1 99,98 99,53 0,86 
Tableau 29 :  Résultats du système START 
Notre système donne des résultats similaires mais la différence se trouve dans le fait que le 
parseur analyse des données qui n’ont pas été préalablement étiquetées (tagging) par un 
étiqueteur (tagger). Nous donnons le taux des résultats obtenus mais le pourcentage du 
rappel a été calculé manuellement car nous travaillons sur un corpus où rien n’est défini, 
aucun groupe et aucune étiquette. Il faut pourtant préciser que trouver et identifier tous les 
Conclusion  169 
Anna PAPPA, Université PARIS VIII, Labo d’I.A., Programmation Holistique, groupe CSAR 
groupes nominaux de notre corpus manuellement est une rude tâche qui ne peut aboutir à 
une reconnaissance totale et sans erreur. Nous prenons donc comme mesure non pas la 
perfection absolue car nous sommes sujets à l’erreur ou à l’omission, nous avons calculé ce 
taux avec un deuxième control qui a donné les cas qui ont souvent été omis, le taux d’erreur 
reste très faible. 
Le tableau ci-dessus nous donne également le pourcentage d’erreur pour chaque groupe 
reconnu. Nous avons déjà mentionné qu’à partir des cas sûrs nous étiquetons un mot du 
groupe reconnu, ce mot correspond à une catégorie grammaticale et le pourcentage d’erreur 
de cet étiquetage est presque nul. 
Cette procédure d’étiquetage peut s’avérer utile quant à la construction d’un corpus annoté 
sans erreur. Il est très facile aujourd’hui de compiler une collection de textes d’une langue 
par exemple le français, et d’y apporter toutes sorte d’informations internes comme la 
lemmatisation, l’étiquetage morpho-syntaxique ou différents types d’analyses de surface. 
Toutes ces opérations d’annotation étant entièrement automatisables, on peut construire à 
faible coût un corpus de plusieurs centaines de millions de mots annotés sans aucune 
révision manuelle. Bien sûr, un tel corpus contient un taux d’erreurs correspondant à ce 
qu’affichent les différents outils utilisés (tagger, lemmatiseurs, shallow-parsers, etc.). Les 
étiqueteurs et lemmatiseurs affichent un taux d’erreur proche de 95 % par mot avec un jeu 
relativement réduit d’étiquettes, les shallow-parsers et chunkers obtiennent des taux 
variables mais aux alentours de 90% [Clément 2001]. 
En revanche la correction d’un corpus annoté est très coûteuse puisque les erreurs des 
systèmes automatiques ne sont généralement pas prédictibles et il faut une inspection 
longitudinale de tout le corpus pour les identifier. La correction d’un million de mots en 
morpho-syntaxe s’estime à quelques 4 hommes – années, sa correction en syntagmes 
environ à la même quantité de travail. 
Notre étiqueteur peut s’avérer utile pour annoter un corpus avec des connaissances 
grammaticales actuelles mais aussi pouvons-nous ajouter des traits morphologiques, tels 
170  Conclusion 
START 2003 
que le genre, le nombre ou la personne pour les verbes, et donc, créer un étiqueteur plus 
complet et avec un taux d’erreur quasi-nul. 
Pour améliorer le taux de reconnaissance (actuellement légèrement supérieur à 92%), nous 
devrions procéder à une étude plus élaborée sur les cas non résolus. Nous pourrions traiter 
dans une analyse postérieure plus approfondie le taux des cas non résolus qui est dû au fait 
d’absence de marques grammaticales dans le contexte voisinant des mots grammaticaux. 
Soit, il faudra trouver des marques de type différent, soit utiliser les réponses obtenues pour 
l’apprentissage du système et ré-évaluer les résultats après un deuxième traitement.  
Nous savons qu’un programme d’analyse peut être décrit comme un mécanisme de 
décision. Une analyse déterministe se réfère à un mécanisme capable de prendre 
directement la bonne décision quand il se trouve devant une multitude de choix. Dans un 
avenir proche nous pourrons envisager de générer automatiquement les règles de notre 
grammaire, puisque le système est déterministe. Ceci engendre deux étapes séparées : la 
syntaxe, traitée de façon déterministe et la sémantique permettant l’attachement des groupes 
construits par la syntaxe à l’aide d’une grammaire éventuellement (par exemple une 
grammaire des cas). Le traitement syntaxique sert à identifier les groupes élémentaires 
d’une phrase sans vouloir déterminer les relations qu’ils entretiennent entre eux. Les 
ambiguïtés présentes seraient levées grâce aux connaissances lexicales que le système 
apporterait avec un dictionnaire comprenant pratiquement tous les verbes, tous les mots 
grammaticaux, ainsi que les mots qui font partie des concepts les plus courants. Aussi 
compliqué que cela puisse paraître nous pensons que le système STAR peut intégrer des 
modules qui aideraient à la création d’un tel dictionnaire ainsi qu’à la désambiguïsation. 
 
 
 
 
TERMINOLOGIE 
Sont présentés ici les principaux termes techniques et linguistiques employés cette étude. 
Nous utilisons le mot terme quand il s’agit d’un contenu notionnel. 
Chunking : procédure de découpage, identification et classification de groupes 
syntaxiques d'une phrase. 
Chunk(s) : identificateur-classificateur de type grammatical pour l'identification – 
classification des groupes syntaxiques, par exemple [GN Les enfants] [GV 
sont partis]. 
Corpus : pour assurer la validité des statistiques que nous avons effectuées sur le 
contexte des termes grammaticaux, il nous faut un corpus qui fournisse à la 
fois un nombre d’occurrences suffisant et une diversité importante d’emploi 
des termes analysés. Le corpus doit être représentatif de la langue étudiée. 
Nous employons le mot corpus dans une acceptation restreinte empruntée à J. 
Sinclair: 
« Un corpus est une collection de données langagières qui sont sélectionnées et 
organisées selon des critères linguistiques explicites pour servir d’échantillon du 
langage ». (p. 4). [Sinclair 1996]  
Parsing : désigne l’analyse syntaxique automatique, 
Parser : désigne le programme qui effectue cette opération. Notre système est un 
shallow parser qui parcourt la phrase et procède à l’analyse syntaxique et 
l'étiquetage. 
Précision : Ensuite, nous allons employer le terme de recherche documentaire précision 
qui représente la proportion de réponses pertinentes données par rapport au 
total des réponses extraites [Habert et al. 1997]. A la fin de cette étude nous 
172  Terminologie 
START 2003 
parlerons des résultats de cette étude et nous utiliserons la précision pour leur 
évaluation. 
Tagging, étiquetage, marquage :  désigne l’étiquetage ou marquage de chaque "mot" d'un 
texte par une catégorie grammaticale. 
Tagger :  désigne le programme qui effectue cette tâche, dans les différents travaux 
actuels sur l’analyse syntaxique. 
Token :  Item lexical. Dans le même contexte nous utilisons le mot token qui est une 
étiquette de niveau supérieur susceptible de regrouper plusieurs étiquettes. La 
liste des tokens est produite à partir de ressources lexicales considérées 
comme exhaustives et les tokens sont dotés d’une ou plusieurs étiquettes. 
Tokenizer: Outil qui permet la distribution des tokens aux différentes unités du texte. 
Pour le traitement linguistique [Bernard 1990] les mots clés qui seront employés dans cette 
étude sont donnés ci-dessous : 
  « comprendre, c’est partager les connaissances préalables sur le monde, à partir de 
connaissances et d’un calcul syntaxique-sémantique sur les énoncés. L’aboutissement 
de la compréhension, c’est essentiellement une réorganisation de ces connaissances ». 
Singularité : Le langage est le moyen de faire partager au travers d’une certaine 
forme l’expérience de compréhension. Cette expérience est singulière, 
personnelle : expérience singulière d’une situation singulière. 
Typique : Dans une situation singulière, il se passe des chose diverses, elle a tant 
d’aspects que l’on ne peut la faire partager en totalité. Pour la faire 
partager, il faut la rapprocher d’une situation (arché-)typique, générique, 
abstraite, pour laquelle on a un nom, connu de ceux à qui l’on parle. Par 
exemple, écrire, qui évoque une situation générique, impliquant un 
écriveur générique, de l’écrivable, un instrument à écrire ... 
Terminologie  173 
Anna PAPPA, Université PARIS VIII, Labo d’I.A., Programmation Holistique, groupe CSAR 
Détermination : Une singularité se définit par la détermination, qui est une opération par 
laquelle nous donnons les éléments nécessaires. 
Répérage : Nous déterminons la singularité à l’aide du repérage, où il faut donner 
des coordonnées spatiales pour trouver un objet (il s’agit d’une pointe 
au sens propre) et, 
Spécification : à l’aide de la spécification où nous répondons à des questions du type à 
quoi ressemble ou de quel espèce est l’objet en question. 
La détermination nous intéresse dans la mesure où nous représentons les connaissances de 
façon logique en les séparant en parties du discours; par exemple syntagmes substantifs, 
syntagmes verbaux. Le syntagme substantif est composé d’un déterminant et d’un 
substantif, qui peut être tantôt substance tantôt adjectif, le déterminant joue le rôle du 
repérage et le substantif celui de la spécification. En effet, nous pourrions reconnaître la 
fonction grammaticale ou syntaxique d’un élément dans une phrase en donnant une liste 
exhaustive de règles qui spécifient la place de chaque élément dans une phrase 
grammaticalement correcte, (le sens de la phrase importe peu à ce genre de traitement). 
174  Terminologie 
START 2003 
 
Liste des abréviations 
EM : Entropy Model 
GN / NP : Nominal Phrase, Groupe Nominal 
GP / PP : Prepositional Phrase, Groupe Prépositionnel 
GV / VP : Verbal Phrase, Groupe Verbal 
HMM : Hidden Markov Model 
MEM : Maximum Entropy Model 
NLP : Natural Language Processing 
SVMs : Support Vector Machines 
TALN : Traitement Automatique du Langage Naturel 
VMM : Variable Memory Markov model 
ED : Epithète droit 
CD : Contexte Droit 
CG : Contexte Gauche 
EG : Epithète Gauche 
 
 
 
BIBLIOGRAPHIE 
[Abeillé et Blache 2000] 
Abeillé A. et Blache Ph. Grammaires et analyseurs syntaxiques. Dans la collection 
Ingénierie des Langues éd. Hermès Sciences, Paris, pp. 51-76, 2000. 
[Abney 1991] 
Abney S. Parsing by chunks. In Robert Berwick and Steven Abney and Carol Teny, 
“Principle-Based Parsing”, Kluwer Academic Publishers, 1991. 
[Argamon et al. 1999] 
Argamon S., Dagan I., Krymolowski Y. A memory-based Approach to Learning 
Shallow Natural Language Patterns. In Journal of Experimental and Theoretical 
Artificial Intelligence (JETAI), vol 11 (3), 1999. 
[Assadi et Bourigault 1995] 
Assadi H. et Bourigault D. Classification d’adjectifs extraits d’un corpus pour l’aide à 
la modélisation des connaissances. In Actes des 3èmes Journées Internationales 
d’analyse des données textuelles (JADT’95), Rome, 1995. 
[Auroux 1989] 
Auroux S. Histoire des idées linguistiques, Liège Mardaga, 1989. 
[Auroux 1994] 
Auroux S. La révolution technologique de la grammatisation, Liège, Mardaga, 1994. 
[Baldwin et al. 1997] 
Baldwin B., Doran C., Reynar J., Niv M., Srinivas B. Et Wasson M. EAGLE: An 
Extensible Architecture for General Linguistic Engineering. In Proceedings of RIAO 
’97, Montreal, June 1997. 
176  Bibliographie 
START 2003 
[Bally 1950] 
Bally C. Linguistique Générale et Linguistique Française, 3e édition, A. Francke, S.A, 
Berne, 1950. 
[Bar-Hillel 1964] 
Bar-Hillel Y. Language and Information, Reading Mass., Addison-Wesley, 1964. 
[Benveniste 1966] 
Benveniste E. Problèmes de linguistique générale (I – II), Gallimard, Paris, 1966. 
[Bernard 1988] 
Bernard G. Arabia felix – felix Austria, Etude sur l’ordre des mots, Groupe Relpred, 
Collection ERA 642 (UA 04 1028), Université Paris 7, 1988. 
[Bernard 1990] 
Bernard G. La liaison dynamique, Les Chemins du Texte, Bernard et Poswick (éd. Sc), 
Slatkine Champion, Genève, Paris, 1990. 
[Bernard 1994] 
Bernard G. Typologie neuromimétique des substantifs, rapport de recherche 94-06-17-
1, laboratoire d’Intelligence Artificielle de l’Université Paris 8, 1994.. 
[Bernard 1998] 
Bernard G. L’épithète et l’ordre des mots dans le syntagme substantif, 22e Congrès 
International de Linguistique et Philologie romanes, Université Libre de Bruxelles, 
1998. 
[Bernard 2003] 
Bernard G. Détection automatique de structures syntaxiques. In  ACTAS of the 8th 
International Symposium of Social Communication and Applied Linguistics, vol. 1, pp. 
575-579, Santiago de Cuba, janvier 2003. 
Bibliographie  177 
Anna PAPPA, Université PARIS VIII, Labo d’I.A., Programmation Holistique, groupe CSAR 
[Blaheta et Charniak 2000] 
Blaheta D., Charniak E. Assigning function tags to parsed text. . Proceedings of the 1st 
Annual Meeting of the North American Chapter of the Association for Computational 
Linguistics, 2000, pp. 234—240. 2000 
[Blanche-Benveniste 1984] 
Blanche-Benveniste C. Pronom et Syntaxe, l’approche nominale et son application en 
français, SELAF – CNRS, Paris, 1984. 
[Blanche-Benveniste et Chervel 1966] 
Blanche-Benveniste C., Chervel A. Recherches sur le syntagme substantif, Cahiers de 
Lexicologie 9-II, Didier Larousse, Paris, 1966. 
[Bloomfield 1933] 
Bloomfield L. Le langage. Payot, Paris, trad. en 1970. 
[Boisson et al. 1994] 
Boisson C., Basset L., Kirtchuk P. Problématique des parties du discours. Les Classes 
des Mots, Traditions et Perspectives, (ouvrage collectif) éd. Presses Universitaires de 
Lyon, pp. 9-45, 1994. 
[Bouaud et al. 1997] 
Bouaud J., Habert B., Nazarenko A., Zweigenbaum P. Regroupements issus de 
dépendances syntaxiques en corpus : catégorisation et confrontation avec deux 
modélisations conceptuelles. In Actes du Colloque « Ingénierie de la Connaissance », 
Roscoff, 1997. 
[Bourigault 1992] 
Bourigault D. Surface Grammatical Analysis for the Extraction of Terminological Noun 
Phrases. In Proceedings of the 15th International Conference on Computational 
Linguistics, 3, pp. 977-981, 1992. 
178  Bibliographie 
START 2003 
[Bourigault 2002] 
Bourigault D. « Upery » : un outil d’analyse distributionnelle étendue pour la 
construction d’ontologie à partir de corpus. Actes de la 9ème conférence annuelle sur le 
traitement automatique des langues, Nancy, 2002. 
[Bourigault et Fabre 2000] 
Bourigault D. et Fabre C. Approche linguistique pour l’analyse syntaxique de corpus. 
Cahiers de grammaire, Université Toulouse-Le Mirail, n° 25, pp. 131-151, 2000. 
[Breasted 1930] 
Breasted J. H. The Edwin Smith Surgical Papyrus. In Chicago University Press, 1930. 
[Brants 1999] 
Brants T. Cascaded Markov Models. In Proceedings of the 9th Conference of the 6th 
Applied Natural Language Processing Conference, Seattle, Washington, USA, 1999. 
[Bresnan 1982] 
Bresnan J. The mental representation of Grammatical Relations, Cambridge, Mass. : 
MIT Press, 1982. 
[Brill 1992] 
Brill E. A simple Rule-Based part of speech tagger. In Proceedings of the Third 
conference on Applied Natural Language Processing, Trento, Italy, ACL, 1992. 
[Brill 1993] 
Brill E. Automatic grammar induction and parsing free text : A transformation-based 
approach. In Proceedings of the DARPA Speech and Natural Language Workshop, pp. 
237-242, 1993. 
[Brill 1995] 
Brill E. Transformation-Based Error-Driven Learning and Natural Language Parsing : 
Bibliographie  179 
Anna PAPPA, Université PARIS VIII, Labo d’I.A., Programmation Holistique, groupe CSAR 
A case Study in Part of Speech Tagging. In Computational Linguistics 21(4), pp. 543-
565, MIT Press, 1995. 
[Brill 1997] 
Brill E. Unsupervised learning of Disambiguation Rules for Part of Speech Tagging. In 
Natural Language Processing Using Very Large Corpora. Kluwer Academic Press, 
1997. 
[Brill et Marcus 1994] 
Brill E., Marcus M. Tagging an Unfamiliar Text With Minimal Human Supervision, 
(www.cs.jhu.edu/~brill/acadpubs.html). 
[Briscoe 1994] 
Briscoe E. Parsing (with) Punctuation. Technical Report, Rank Xerox Research Centre, 
France, 1994. 
[Briscoe 1994a] 
Briscoe E. Prospects for practical parsing: robust statistical techniques. In P. De Haan 
& N. Oostdijk eds. Corpus-based Research into Language: A Feschrift for Jan Aarts. 
Rodopi, Amsterdam, pp. 67-95, 1994. 
[Briscoe et Carroll 1995] 
Briscoe E. et Carroll J. Developing and evaluating a probabilistic LR parserof part-of-
speech and punctuation labels. In Proceedings of the 4th ACL/SIGPARSE International 
Workshop on Parsing Technologies, Prague, Czech Republic, pp. 48-58, 1995. 
[Buchholz et al. 1999] 
Buchholz S., Veenstra J., Daelemans W. Cascaded Grammatical Relation Assignment. 
In Proceedings of EMNLP/VLC-99, University of Maryland, U.S.A. 1999. 
180  Bibliographie 
START 2003 
[Buyssens 1975] 
Buyssens E. Les catégories grammaticales du français, Editions de l’Université, 
Bruxelles. 1975 
[Cardie et Pierce 1998] 
Cardie C. Et Pierce D. Error-driven Pruning of Treebank Grammars for Base Noun 
Phrase Identification. In Proceedings of COLING-ACL’98, Montreal , Canada. 1998. 
[Cardie et Pierce 1999] 
Cardie C. Et Pierce D. The role of Lexicalization and Pruning for Base Noun 
Grammars. In Proceedings of the 16th National Conference on Artificial Intelligence, 
1999. 
[Carlson et al. 2001] 
Carlson A. J., Cumby C. M., Rosen J. L., Roth D. SnoW User’s Guide. http :// 
l2r.cs.uiuc.edu/~danr/snow.html. 2001 
[Charniak 1993] 
Charniak E. Statistical language learning. Cambridge MA: MIT Press, 1993. 
[Charniak 1996] 
Charniak E. Tree-bank grammars. In Proceedings of the Thirteenth National 
Conference on Artificial Intelligence, (AAAI – 96), pages 1031-1036, MIT Press, 
August 1996. 
[Charniak 1997] 
Charniak E. Statistical parsing with a context free grammar and word statistics. In 
Proceedings of the Fourteenth National Conference on Artificial Intelligence, AAAI 
Press / MIT Press, Menlo Park. 1997 
[Charniak et al. 1993] 
Charniak E., Hendrickson C., Jacobson N., Perkowitz M. Equations for Part-of-Speech 
Bibliographie  181 
Anna PAPPA, Université PARIS VIII, Labo d’I.A., Programmation Holistique, groupe CSAR 
Tagging. In Proceedings of the Eleventh National Conference  on Artificial 
Intelligence, pp. 784-789, 1993. 
[Chatzivasiliou 1995] 
Chatzivasiliou G. Synoptiki Neoelliniki Grammatiki kai Syntaxi éd. GRIGORIS, 
Athènes, Grèce. 1995 
[Cherry et al. 1991] 
Cherry L.L. et Vesterman W. Writing tools – the STYLE and DICTION programs. In 
4.3. BSD Unix System Documentation. University of California, Berkeley, 1991. 
[Chevalier et al. 1964] 
Chevalier J.-Cl., Blanche-Benveniste Cl., Arrivé M., Peytard J. Grammaire, Librairie 
Larousse, Paris, 1964. 
[Chomsky 1969] 
Chomsky N. Structures syntaxiques, Le Seuil, Paris, 1969. 
[Chomsky 1971] 
Chomsky N. Aspects de la théorie syntaxique. Editions du Seuil, Paris, 1971. 
[Church 1988] 
Church K. A stochastic parts program and noun phrase parser for unrestricted text. In 
Proceedings of the Second Conference on Applied Natural Language Processing, ACL 
pages 136 – 143, Austin, Texas, 1988. 
[Clément 2001] 
Clément L. Construction et exploitation d’un corpus syntaxiquement annoté pour le 
français. Thèse soutenue publiquement à l’Université Paris 7, juin 2001.  
182  Bibliographie 
START 2003 
[Collins 1996] 
Collins M. A new statistical parser based on bigram lexical dependencies. In 
Proceedings of the 34th Annual Meeting of the ACL. 1996 
[Cortes et Vapnik 1995] 
Cortes C. et Vapnik V. Support Vector Networks. In Machine Learning, n° 20, pp. 273-
297, 1995. 
[Cowie et lehnert 1996] 
Cowie J., Lehnert W. Information Extraction. In Communications of the ACM, 39(1), 
pp. 84-91. 1996 
[Crevier 1997] 
Crevier D. A la recherche de l’Intelligence Artificielle. Tr. Par Nathalie Bucsek, éd. 
Champs Flammarion, 1997. 
[Culioli 1990] 
Culioli A. Pour une linguistique de l’énonciation, Opérations et représentations, vol. 1, 
Ophrys, 1990. 
[Cutting et al. 1992] 
Cutting D., Kupiec J., Pedersen J., Sibun P. A practical of part of speech tagger. In 
Proceedings of the 3rd Conference on Applied Language Processing, pp. 133-140, 
Trento, Italy, 1992. 
[Dale 1991] 
Dale R. The role of Punctuation in Discourse Structure. In Working Notes of the AAAI 
Fall Symposium on Discourse Structure in Natural Language Understanding and 
Generation, Asilomar, pages 13-14. 1991 
[Denis et Sancier-France 1994] 
Denis D., Sancier-France A.-S. Grammaire du français. Ed. Le livre de Poche série Les 
Usuels de Poche, Librairie Générale Française, 1994. 
Bibliographie  183 
Anna PAPPA, Université PARIS VIII, Labo d’I.A., Programmation Holistique, groupe CSAR 
[Dermatas et al. 1995] 
Dermatas E. Et Kokkinakis G. Automatic Stochastic Tagging of Natural Language 
Texts. In Computational LInguistics, 21 (2), pp. 137-164, 1995. 
[Dewitte 1998] 
Dewitte f. Contribution a l’etiquetage syntaxique et semantique automatique d’un 
corpus, memoire de dea en intelligence artificielle, universites paris 8 – paris13, 1998 
[Dubois 1973] 
Dubois J. Dictionnaire de la Linguistique, Paris, Larousse, 1973. 
[Ducrot et Todorov 1972] 
Ducrot O., Todorov T. Dictionnaire encyclopédique des sciences du langage, éditions 
du Seuil, Points, Paris, 1972. 
[Eineborg et Gambäck 1994] 
Eineborg M. Et Gambäck B. Tagging experiment using neural networks. In Eklund 
(ed.), pp. 71-81, 1994. 
[Elworthy 1994] 
Elworthy D. Does Baum-Welch re-estimation help taggers ? In Proceedings of the 4th 
Conference on Applied Natural Language Processing, ACL. Stuttgart, 1994. 
[Fillmore 1968] 
Fillmore C. A case for case, in Universals in Linguistic Theory, ed. E. Bach et R. 
Harms, Holt, Rinehart and Winston, pp. 1-90, 1968. 
[Forsgren 1978] 
Forsgren M. La place de l’adjectif épithète en français contemporain. Etude 
quantitative et sémantique, Stockholm, Almqvist & Wiksell, 1978. 
184  Bibliographie 
START 2003 
[Freud et Schapire 1996] 
Freud Y. Et Schapire R. Experiments with a new boosting algorithm. In Internaional 
Conference on Machine Learning (ICML), pp. 148-156, 1996. 
[Fuchs et Victorri 1993] 
Fuchs C., Victorri B. Syntaxe, dans Linguistique et Traitements automatiques des 
langues, Hachette Université, chapitre 4, 1993. 
[Garside 1987] 
Garside R. The CLAWS word-tagging system. In Garside, Leech and Sampson (eds.), 
The Computational Analysis of English : the IBM/Lancaster Approach, Rodopi 
Amsterdam, 1987. 
[Gazdar et al. 1985] 
Gazdar et al. Generalized phrase structure grammar, Oxford, Blackwell, 1985. 
[Giguet et Vergne 1997] 
Giguet E. Vergne J. From Part-of-Speech tagging to memory-based deep syntactic 
analysis. In Proceedings of the International Workshop on Parsing Technologies, 
Boston, 1997. 
[Görz et Henrieder 1995] 
Görz G. et Henrieder G. Robust parsing of Spoken Dialogue Using Contextual 
Knowledge and Recognition Probabilities. (www.citeseer.nj.nec.com/170777.html) 
[Grefenstette 1994] 
Grefenstette G. Exploration in Automatic Thesaurus Discovery. Londres, Kluwer 
Academic Publishers, 1994. 
[Grefenstette et Tapanainen 1994] 
Grefenstette G. Et Tapanainen P. What is a word, What is a sentence? Problems of 
Bibliographie  185 
Anna PAPPA, Université PARIS VIII, Labo d’I.A., Programmation Holistique, groupe CSAR 
tokenization. In Proceedings of 3d Inter. Conference In Computer Lexicography, pp. 
79-87, 1994. 
[Grevisse 1975] 
Grevisse M. Le Bon Usage, Grammaire Française avec des remarques sur la langue 
française d’aujourd’hui. 10e éd. J. Duculot, S.A. Gemloux, France. 1975 
[Grevisse 1980] 
Grevisse M. Le bon usage, (11e édition), 1980. 
[Gross 1975] 
Gross M. Méthodes en syntaxes. Hermann (éd.), Paris, 1975. 
[Gross 1997] 
Gross M. La traduction automatique, article paru dans « Pour la Science », Dossier 
Spécial « Les langues du monde », octobre, 1997. 
[Guillaume 1961] 
Guillaume G. Langage et Science du Langage, 4e édition 1994, Librairie A.-G. Nizet, 
Paris 1e éd en 1961. 
[Guillaume 1975] 
Guillaume G. Le problème de l’article et sa solution dans la langue française, réédition, 
Librairie A.G. Nizet, Paris, 1975. 
[Habert et al. 1997] 
Habert B., Nazarenko A., Salem A. Les linguistiques de corpus, Armand Colin, Paris, 
1997. 
[Habert et Nazarenko 1996] 
Habert B. et Nazarenko A. La syntaxe comme marche-pied de l’acquisition des 
186  Bibliographie 
START 2003 
connaissances : bilan critique d’une expérience. In Actes des 7èmes Journées 
d’acquistion des connaissances (JAC’96), Sète. 
[Hagège 1985] 
Hagège Cl. L’hommes de paroles, Contribution linguistique aux sciences humaines, 
Fayard, Paris, 1985. 
[Harris 1954] 
Harris Z. S. Distributional structure, Word, Chicago Press, pp. 146 –162, 1954. (réédité 
sous le titre Structural Linguistics). 
[Harris 1962] 
Harris Z. S. String analysis of sentence structure, Mouton and Co., La Hague, 1962. 
[Harris 1968] 
Harris Z. Mathematical Structures of Language. New York, John Wiley & Sons 1968. 
[Harris et al. 1989] 
Harris Z., Gottfried M., Ryckman T., Mattick P., Daladier A., Harris T.N., Harris S. 
The form of Information in Science; Analysis of Immunology Sublanguage. Dordrecht: 
Kluwer Academic Publishers, Dordrecht, 1989. 
[Henderson et Lane 1998] 
Lane P.C.R. et Henderson J.B. A connectionist architecture for learning to parse. In 
Proceedings of the 17th International Conference on Computational Linguistics and the 
36th Annual Meeting of the Association for Computational Linguistics (COLING-
ACL’98), University of Montreal, Canada, 1998. 
[Hendrix et al. 1978] 
Hendrix G., Sacerdoti E., Sagalowicz D., Slocum J. Developing a natural language 
interface to complex data, ACM Transactions on Database Systems, vol. 3, pp. 105-
147, 1978. 
Bibliographie  187 
Anna PAPPA, Université PARIS VIII, Labo d’I.A., Programmation Holistique, groupe CSAR 
[Hindle 1990] 
Hindle D. Noun Classification form Predicate-Argument Structures. In Proceedings of 
the Association for Computational Linguistics Conference (ACL’90), pp. 268-275, 
1990. 
[Hirshman et al. 1975] 
Hirshman L., Grishman R. Et Sager N. Grammaticaly-based automatic word class 
formation. In Information Processing and Management 11, pp. 39-57, 1975. 
[Hobbs et al. 1996] 
Hobbs J., Appelt D., Bear J., Israel D., Kameyama M., Stickel M. Et Tyson M. 
FACTUS : a Cascaded Finite-State Transducer for Extracting Information from 
Natural Language Text. In E. Roche et Y. Schabes (eds) Finite State Devices for 
Natural Language Processing. Cambridge MA : MIT Press, 1996. 
[Jacobs 1990] 
Jacobs P. To parse or not to parse : relation-driven text skimming. In Proceedings of 
13th COLING, Helsinki, pp. 194-198, 1990. 
[Joachims 1998] 
Joachims T. Text Categorization with Support Vector Machines : Learning with Many 
Relevant Features. In European Conference on Machine Learning (ECML), 1998. 
[Karlsson et al. 1994] 
Karlsson F., Voutilainen A., Heikkilä J., Anttila A., editors. Constraint Grammar : A 
Language – Indépendant Formalism for Parsing Unrestricted Text. Mouton de Gruyter, 
Berlin, New York, 1994. 
[Karlsson et al. 1995] 
F., Voutilainen A., Heikkila J. Antilla A. A Language Independent System for Parsing 
Unrestricted Text. Mouton de Gruyter. 1995 
188  Bibliographie 
START 2003 
[Kay 1973] 
Kay M. The MIND system, in Natural Language Processing, Rustin, Algorithmic Press, 
New York, pp. 155-188, 1973. 
[Kouloughli 1994] 
Kouloughli D.E. Grammaire de l’arabe d’aujourd’hui. Edition Pocket Collection 
Langues pour tous. 1994 
[Krotov et al.1998] 
Krotov A., Hepple M., Gaizauskas R., Wilks Y. Compacting the Penn Treebank 
Grammar. In Proceedings of the COLING-ACL ’98, August 1998, Montreal. 
[Kučera et Francis 1967] 
Kucera H. et Francis W. Computational analysis of present-day American english., 
Providence, Brown university press, 1967. 
[Kudo et Matsumoto 2000] 
Kudo T., Matsumoto Y. Japanese Dependency Structure Analysis Based on Support 
Vector Machines. In Empirical Methods in Natural Language Processing and Very 
Large Corpora, pp. 18-25, 2000. 
[Kudo et Matsumoto 2001] 
Kudo T., Matsumoto Y. Chunking with Support Vector Machines. In Proceedings of 
NAACL Pittsburgh, PA, USA, 2001. 
[Lane et Henderson 2001] 
Lane P.C.R. et Henderson J.B. Incremental Syntactic Parsing of Natural Language 
Corpora with Simple Synchrony Networks. In Special Issue on Connectionist Models 
for Learning in Structured Domains, IEEE Transactions on Knowledge and Data 
Engineering, 2001. 
Bibliographie  189 
Anna PAPPA, Université PARIS VIII, Labo d’I.A., Programmation Holistique, groupe CSAR 
[Lemaréchal 1989] 
Lemaréchal A. Les parties du discours, Sémantique et Syntaxe, PUF, Linguistique 
Nouvelle, Paris, 1989. 
[Lewis et Spärk 1996] 
Lewis D., Spärk J. Natural Language Processing for Information Retrieval. In 
Communications of the ACM, 39(1), pp. 92-101. 1996 
[Losee 1996] 
Losee R. M Learning Syntactic Rules and Tags with Genetic Algorithms for 
Information Retrieval and Filtering: An Empirical Basis for Grammatical Rules _ 
Information Processing & Management 32 (2), pp. 185-197, 1996 
[Lutinen et Gershman 1986] 
Lutinen S., Gershman A. ATRANS automatic processing of money transfer messages. 
In fifth National Conference on Artificial Intelligence, Philadelphia, 1986. 
[Mahmoudian 1970] 
Mahmoudian M. Les modalités nominales en français, PUF, Paris, 1970. 
[Megyesi 2001] 
Megyesi B. Phrasal parsing by using Data-Driven PoS Taggers. In Proceedings of 
Recent Advances in Natural Language Processing (EuroConference RANLP-
2001),Tzigov Chark, Bulgaria, September 2001. 
Marcus et al. 1993] 
Marcus M., Marcinkiewicz M.A., Santorini B. Building a large annotated corpus of 
English : the Penn Treebank. Computational Linguistics, 19(2), 313-330. 1993. 
[Merialdo 1994] 
Merialdo B. Tagging English with a probabilistic model. In Computational Linguistics, 
Vol. 20, 1994. 
190  Bibliographie 
START 2003 
[Mikheev 1994] 
Mikheev A. Periods, Capitalized Words, etc. Association for Computational 
Linguistics, Vol. 16, n° 1, 1994. 
[Mikheev 1997] 
Mikheev A. Automatic Rule Induction for Unknown Word Guessing. In Computational 
Linguistics 23 (3), pp. 405-423. 
[Montague 1974] 
Montague R. English as a formal language, papier de 1970 repris par Thomason 
Richmond H. Dition Formal Philosophy : selected papers of Richard Montague, Yale 
University Press, 1974. 
[Mounin 1967] 
Mounin G. Histoire de la linguistique, des origines au XXe siècle, Paris, P.U.F., 1967. 
[Muller et al. 1980] 
Muller H., Amerl V., Natalis G. Worterkennungsverfahren als Grundlage einer 
Universalmethode zur automatischen Segmentierung von Texten in Satze. Ein 
Verfahren zur maschinellen Satzgrenzen-Bestimmung im Englischen In Sprache und 
Datenverarbeitung, 1. 1980 
[Muñoz et al. 1999] 
Muňoz M., Punyakanok V., Roth D., Zimak D. A learning Approach to Shallow 
Parsing. In Proceedings of EMNLP/WVLC-99, University of Maryland, MD, USA, 
1999. 
[Noailly 1990] 
Noailly M. Le substantif épithète, PUF, Linguistique Nouvelle, 1990. 
[Nunberg 1990] 
Nunberg G. The Linguistics of punctuation. Technical Report Lecture Notes n° 19, 
CSLI, Stanford, California. 1990 
Bibliographie  191 
Anna PAPPA, Université PARIS VIII, Labo d’I.A., Programmation Holistique, groupe CSAR 
[Palmer et Hearst 1997] 
Palmer D., Hearst M Adaptive Multilingual Sentence Boundary Disambiguation. 
Computational Linguistics, pp. 241-267(2). 1997 
[Pappa et al. 2003] 
Pappa A., Bernard G., Ouekeradi H. Détection automatique de frontières des phrases – 
Un système adaptatif multi-langues. (à paraître) MAJECSTIC ‘03, Marseille, France, 
octobre 2003. 
[Pereira et Warren 1980] 
Pereira F., Warren D. Definite clause grammars for natural language analysis – A 
survey of the formalism and a comparison with augmented transition networks, 
Artificial Intelligence 13, pp. 231-278,. 
[Pollard et Sag 1988] 
Pollard C., Sag I. An Information Based Approach to Syntax and Semantics, Part I, 
Stanford, Cal., CSLI, Chicago University Press, 1988. 
[Quillian 1968] 
Quillian R. Semantic Memory, dans Semantic Information Processing, Minsky MIT 
Press, Cambridge Mass., pp. 227-270, 1968. 
[Ramshaw et Marcus 1995] 
Ramshaw L.A., Marcus M.P. Text Chunking Using Transformation-Based Learning. In 
Proceedings of the third ACL Workshop on Very Large Corpora. Cambridge, MA, 
U.S.A. pp. 82-94. 1995. 
[Rastier 1991] 
Rastier F. Sémantique et recherches cognitives, Formes Sémiotiques, PUF, Paris, 1991. 
[Ratnaparkhi 1996] 
Ratnaparkhi A. A maximum entropy model for part-of-speech tagging. In Proceedings 
192  Bibliographie 
START 2003 
of Conference on Empirical Methods in Natural Language Processing, pp. 133-142, 
1996. 
[Reynar et Ratnaparkhi 1997] 
Reynar J., Ratnaparkhi A. A maximum Entropy Approach to Identifying Sentence 
Boundaries. In Proc. Of the 5th Applied Natural Language Processing Conference. 1997 
[Riley 1989] 
Riley M. Some Applications of Tree-based Modeling, to Speech and Language 
Indexing. In Proc. Of the DARPA Speech and Natural Language Workshop, pages 339-
352. 1989 
[Sabah 1988] 
Sabah G. L’intelligence artificielle et le langage, représentations de connaissances, Vol 
1, 2, 2ème édition, Hermès, Paris, 1988. 
[Sabah 1989]  
Sabah G. L’intelligence artificielle et le langage, processus de compréhension (vol II), 
éd. Hermès, Paris, 1989. 
[Sager et al. 1987] 
Sager N. Friedman C. Et Lyman M. (eds). Medical Language Processing: Computer 
Management of Narrative Data. Massachussetts, Addison Wesley, Reading, 1987. 
[Saint Dizier et Vazquez] 
Saint Dizier P. et Vazquez G. A Compositional Framework for Prepositions. In  
IWCS4, Tilburg, Springer, lecture notes, janvier 2001. 
[Sandfelf 1970] 
Sandfeld K. Syntaxe du Français Contemporain, vol. 1, Librairie Honoré Champion, 
Paris, 1970. 
[Santos 2001] 
Santos D. Punctuation and Multilinguality some reflections from a language 
Bibliographie  193 
Anna PAPPA, Université PARIS VIII, Labo d’I.A., Programmation Holistique, groupe CSAR 
engineering perspective.  – 
(www.oslo.sintef.no/portug/Diana/download/ponctuacao.ps) 2001 
[Sassano et Utsuro 2000] 
Sassano M. Et Utsuro T. Named Entity Chunking Techniques in Supervised Learning 
for Japanese Named Entity Recognition. In Proceedings of COLING 2000, pp. 705-
711, 2000. 
[Saussure 1960] 
Saussure F. Cours de Linguistique Générale, Payothèque Payot, Paris, 1983. 
[Say et Akman 1997] 
Say B. Et Akman V. Current Approaches to Punctuation in Computational Linguistics. 
In Computers and the Humanities. 30(6) pp. 457-469. 1997 
[Schank 1986] 
Schank R. Explanation patterns, Hillsdale, N.J. Lawrence Erlbaum, 1986. 
[Schieber 1990] 
Schieber S. Les grammaires basées sur l’unification, dans Formalismes syntaxiques 
pour le traitement automatique du langage naturel, présenté par P. Miller et T. Torris, 
Hermès, chapitre 1,. 
[Schmid 1994] 
Schmid H. Part-of-Speech Tagging withe Neural Networks. In Proceedings of 
COLING-94, Kyoto, Japan, 1994. 
[Schütze 1995] 
Schütze H. Distributional Part-of-Speech Taggingrt. In EACL 7, pp. 141-148, 1995. 
[Scut et Brants 1998] 
Scut W. et Brants T. Chunk Tagger Statistical Recognition of Noun Phrases. In 
194  Bibliographie 
START 2003 
ESSLLI-98 Workshop on Automated Acquisition of Syntax and Parsing (ESSLLI-98), 
Saarbrücken, Germany, 1998. 
[Siamak 2001] 
Siamak R Tokenizing an Arabic Script Language. In Arabic NLP Workshop at 
ACL/EACL, France. 2001 
[Silberztein 1993] 
Silberztein M. Dictionnaires électroniques et analyse automatique de textes. Le système 
INTEX. Collection ‘Informatique Linguistique’, éd. Masson, Paris, 1993. 
[Sinclair 1996] 
Sinclair J. Preliminary recommendations on Corpus Typology, rapport technique, 
EAGLES (Expert Advisory Group on Language Engineering Standards), CEE, mai 
1996. 
[Srinivas 1997] 
Srinivas B. Performance Evaluation of Supertagging for Partial Parsing. In 
Proceedings of the 5th International Workshop on Parsing Technologies, 1997. 
[Stamatatos 2000] 
Stamatatos E. Statistical Identification of Genre and Author in Urestricted Modern 
Greek Text. Ph.D Thesis, Dept. Of Electrical and Computer Engineering, University of 
Patras, Greece, 2000. 
[Stamatatos et al. 2000] 
Stamatatos E., Fakotakis N., Kokkinakis G. A practical chunker for Unrestricted Text. 
In Proceedings of the 2nd International Conference of Natural Language Processing 
(NLP 2000), pp. 139-150, 2000. 
[Stévenin-Barbier 1996] 
Stévenin-Barbier A. Réseaux connexionnistes et traitement symbolique-numérique : 
Bibliographie  195 
Anna PAPPA, Université PARIS VIII, Labo d’I.A., Programmation Holistique, groupe CSAR 
une application en compréhension du langage, Thèse de Doctorat, Université Paris 6, 
1996. 
[Taira et Haruno 1999] 
Taira H. Et Haruno M. Feature Selection in SVM Text Categorization. In AAAI-1999. 
[Tesnière 1959] 
Tesnière L. Eléments de syntaxe structurale, Klincksieck, Paris, 1959. 
[Tjong Kim Sang 2000] 
Tjong Kim Sang E. Noun phrase recognition by system combination. In Proceedings of 
ANLP-NAACL’2000, Seattle, WA, USA, pp.50-55, 2000. 
[Tjong Kim Sang et al. 2000] 
Tjong Kim Sang E., Daelemans W., Déjean H., Koeling R., Krymolowski Y., 
Punyakanok V. et Roth Dan. Applying system combination to base noun phrase 
identification. In Proceedings of COLING 2000, Saarbrücken, Germany, pp. 857-863, 
2000. 
[Tjong Kim Sang et Buchholz 2000] 
Tjong Kim Sang E. Et Buchholz S. Introduction to the CoNLL-2000 Shared Task : 
Chunking. In Proceedings of CoNLL-2000 and LLL-2000, Lisbon, Portugal, 2000. 
[Tjong Kim Sang et Veenstra 1999] 
Tjong Kim Sang E. et Veenstra J. Representing Text Chunks. In Proceedings of 
EACL’99, Bergen, Norway, 1999. 
[Van Halteren 2000] 
Van Halteren H. Chunking with WPDV models. In Proceedings of CoNLL-2000 et 
LLL-2000, pp. 154-156, 2000. 
196  Bibliographie 
START 2003 
[Van Rijsbergen 1979] 
Van Rijsbergen C. J. Information Retrieval. Buttersworth, 1979. 
[Veenstra 1998] 
Veenstra J. Fast NP chunking using memory-based learning techniques. In F. 
Verdenius et W. van den Broek (eds), Proceedings of BENELEARN-98, Wageningen, 
The Netherlands, 1998. 
[Veenstra 1999] 
Veenstra J. Memory-Based Text Chunking. In Nikos Fakotakis (éd), “Machine learning 
in human language technology”, Workshop de ACAI 99, Chania, Greece, 1999. 
[Vergne et Giguet 1998] 
Vergne J., Giguet E., Regards théoriques sur le tagging. In Proceedings of the fifth 
annual conference TALN 1998, Paris June 10-12. 
[Voutilainen 1993] 
Voutilainen A. NPTool, a Detector of English Noun Phrases. In proc.of the Workshop 
on Very Large Corpora Academic and Industrial Perspectives, Ohio State University, 
pp. 48-57, 1993 
[Voutilainen 1995] 
Voutilainen A. A syntax-based part-of-speech analyser. In Proceedings of the 7th 
Conference of the European Chapter of the Association for Computational Linguistics, 
Dublin, 1995. 
[Voutilainen 1998] 
Voutilainen A. Does tagging help parsing ? A case study on finite state parsing. In 
International Workshop on Finite State Methods in Natural Language Processing, 
pp.25-26, 1998. 
Bibliographie  197 
Anna PAPPA, Université PARIS VIII, Labo d’I.A., Programmation Holistique, groupe CSAR 
[Voutilainen et al. 1992] 
Voutilainen A., Heikkilä J., Antila A. Constraint Grammar of English. A Performance-
Oriented Introduction. Publications 21, Department of General Linguistics, University 
of Helsinki, 1992. 
[Weaver 1955] 
Weaver W. Translation, dans Machine Translation of Languages, Locke et Booth, 
Technology Press of MIT and Wiley and Sons, New York, pp. 15-23, 1955. 
[Weischedel et al. 1993] 
Weischedel R., Meteer M., Schwartz R., Ramshaw L., Palmucci J. Coping with 
ambiguity and unknown words through probabilistic models. Computational 
Linguistics 19, 359-382. 1993 
[Wells 1947] 
Wells R. S. Immediate Constituents, Language, 1947. 
[White 1995] 
White M. Presenting Punctuation. In Proceedings of the 5th European Workshop on 
Natural Language Generation, Leiden, Netherlands, pp. 107-125, 1995. 
[Wilks 1973] 
Wilks Y. An artificial intelligence approach to machine translation. In Computer 
models of thought and language, Schank & Colby, Freeman, San Fransisco, pp. 114-
151, 1973. 
[Wilmet 1986] 
Wilmet M. La détermination nominale, PUF, Linguistique Nouvelle, 1986. 
[Winograd 1983] 
Winograd T. Language as a cognitive process vol 1 Syntax, Reading Mass., Addison-
Wesley, chapitre 5, 1983. 
198  Bibliographie 
START 2003 
[Woods 1970] 
Woods W. Transition network grammars for natural language analysis, 
Communication of the ACM, 3.10, pp. 591-606, 1970. 
[Woods 1973] 
Woods W. Progress in Natural Language Understanding : An application to tunar 
geology, National Computer Conference, pp. 44-450, 1973. 
[XTAG Research Group 1998] 
The XTAG Research Group. A lexicalised Tree Adjoining Grammar for English. In 
IRCS Tech Report 98-18, University of Pennsylvania, PA, USA, 1998. 
 
Index  199 
Anna PAPPA, Université PARIS VIII, Labo d’I.A., Programmation Holistique, groupe CSAR 
INDEX DES FIGURES 
Figure 1 : Visualisation des connexions et des nœuds dans la phrase. 29 
Figure 2 : A parse tree. 63 
Figure 3 : Diagramme d’un système de compréhension. 86 
Figure 4 : La répartition des mots grammaticaux dans le texte 98 
Figure 5 : Schéma général de l’algorithme 107 
Figure 6 : Représentation schématique du système START 113 
Figure 7 : Transformations textuelles avant l’analyse linguistique 115 
Figure 8 : Un programme flex qui filtre le code SGML. 116 
Figure 9 : Extrait du code SGML présent au début du fichier texte 118 
Figure 10 : Extrait du fichier texte « Aurélien ». 119 
Figure 11 : Exemple des segments utilisés 126 
Figure 12 : Procédure de désambiguïsation 129 
Figure 13 : Extrait du tableau avec les déterminants comme noyau. 139 
Figure 14 : Présence des relatifs, prépositions et conjonctions dans le contexte des 
pronoms  140 
200  Index 
START 2003 
Figure 15 : Proportion d’apparition de certaines catégories grammaticales 141 
Figure 16 : Le clic sur le bouton exécute le programme de la reconnaissance des groupes 
verbaux  147 
Figure 17 : La boite de dialogue pour le traitement des textes du corpus, ici « Candide » 
  148 
Figure 18 : La boite de dialogue permettant d’ajouter des nouveaux mots dans le 
dictionnaire 149 
 
Index  201 
Anna PAPPA, Université PARIS VIII, Labo d’I.A., Programmation Holistique, groupe CSAR 
INDEX DES TABLEAUX 
Tableau 1 : Les parties de la phrase définies par Denys de Thrace 31 
Tableau 2 : Exemples des Groupes Nominaux, utilisation de « de ». 32 
Tableau 3 : Les déterminants 37 
Tableau 4 : Résultats publiés obtenus par la méthode de l’apprentissage 74 
Tableau 5 : Résultats obtenus par notre système 74 
Tableau 6 : structures avec ce 88 
Tableau 7 : structures avec ce 89 
Tableau 8 : présence de signes de ponctuation dans le contexte gauche et droit des 
déterminants 96 
Tableau 9 : présence de signes de ponctuation dans le contexte gauche et droit des pronoms 
  96 
Tableau 10 : Les mots grammaticaux utilisés pour définir les règles de la reconnaissance 
automatique des parties du discours 103 
Tableau 11 : Extrait du corpus français : 123 
Tableau 12 : Extrait du corpus grec. 124 
202  Index 
START 2003 
Tableau 13 : Informations statistiques sur les caractères finaux en français et en grec 
  125 
Tableau 14 : Explicatif des segments utilisés. 126 
Tableau 15 : Exemple du contexte 128 
Tableau 16 : Résultats avec l’erreur. 131 
Tableau 17 : Table des règles du système pour la reconnaissance de l’étendue de GN 
  143 
Tableau 18 : Table des règles définissant les GV 144 
Tableau 19 : Table des règles de désambiguïsation entre l’article défini et le pronom 
personnel  145 
Tableau 20 :  Extrait des résultats de détection de groupes nominaux 155 
Tableau 21 :  Extrait de résultats de reconnaissance des groupes verbaux 156 
Tableau 22 : Extrait des résultats après désambiguïsation entre l’article défini et le 
pronom personnel 157 
Tableau 23 : Résultats du système START 159 
Tableau 24 : Extrait des résultats 160 
Tableau 25 : Extrait des résultats en grec 161 
Tableau 26 : Extrait du tableau du dictionnaire 162 
Index  203 
Anna PAPPA, Université PARIS VIII, Labo d’I.A., Programmation Holistique, groupe CSAR 
Tableau 27 : Extrait du dictionnaire avec des mots grecs 163 
Tableau 28 : résultats publiés pour la reconnaissance des GN 168 
Tableau 29 : Résultats du système START 168 

Table des Matières  205 
Anna PAPPA, Université PARIS VIII, Labo d’I.A., Programmation Holistique, groupe CSAR 
TABLE DES MATIERES  
THESE................................................................................................................................1 
DOCTEUR DE L'UNIVERSITE PARIS 8 .......................................................................1 
Anna PAPPA ...................................................................................................................1 
START : analyse syntaxique automatique de surface sur grand corpus en français ......1 
Remerciements ..................................................................................................................3 
Sommaire ...........................................................................................................................5 
Abstract ..............................................................................................................................7 
Guide de lecture.................................................................................................................9 
INTRODUCTION............................................................................................ 11 
PROBLEMATIQUE ........................................................................................ 21 
1.1 La grammaire ............................................................................................................24 
1.1.1 Au fil de l’histoire.................................................................................................24 
1.2. La syntaxe .................................................................................................................28 
1.3. Les parties du discours ............................................................................................30 
1.3.1. Définition et détermination des GN et GV ..........................................................32 
1.3.1.1. Le nom et le verbe ..............................................................................................32 
1.3.1.2. Distinction entre nom et substantif .....................................................................33 
1.3.2. Les adjectifs (épithètes) .......................................................................................35 
1.4. Les mots grammaticaux.............................................................................................1 
1.4.1. Les déterminants....................................................................................................1 
1.4.2. Les pronoms ........................................................................................................46 
1.4.3. Les relatifs ...........................................................................................................47 
1.4.4. Les prépositions...................................................................................................48 
1.4.5. Les conjonctions ..................................................................................................48 
1.4.6. Les adverbes ........................................................................................................49 
206  Index 
START 2003 
1.5. Relation entre forme et sens .................................................................................... 50 
ETAT DE L’ART...........................................................................................51 
2.1. Bref historique.......................................................................................................... 53 
2.1.1. Le premier exemple des règles ............................................................................ 56 
2.2. Méthodes et travaux informatiques pour le langage naturel ............................... 57 
2.2.1. La composante grammaire.................................................................................. 57 
2.2.2. La composante syntaxe........................................................................................ 62 
2.2.3. L’étiquetage......................................................................................................... 63 
2.2.3.1. Les étiqueteurs ................................................................................................... 64 
2.2.4. La division du texte (text chunking) .................................................................... 68 
2.2.4.1. Divers systèmes et applications ......................................................................... 70 
2.2.4.2. Analyse robuste.................................................................................................. 77 
2.2.5. Le découpage en phrases et la ponctuation ........................................................ 78 
2.3. Situation de START dans ce contexte .................................................................... 82 
METHODOLOGIE .........................................................................................83 
3.1. Principes pour la création d’un système ................................................................ 85 
3.2. Lignes théoriques ..................................................................................................... 87 
3.2.1. Définition des parties du discours....................................................................... 89 
3.2.2. Analyse distributionnelle..................................................................................... 90 
3.3. Les outils ................................................................................................................... 93 
3.3.1. Le corpus............................................................................................................. 93 
3.3.2. Méthodes statistiques .......................................................................................... 95 
3.2.3. Vers une méthode ................................................................................................ 99 
3.4. De la méthode vers l’algorithme ........................................................................... 105 
LE SYSTEME « START » ..........................................................................109 
4.1. Introduction............................................................................................................ 114 
4.2. Pré-traitement des données textuelles .................................................................. 114 
Table des Matières  207 
Anna PAPPA, Université PARIS VIII, Labo d’I.A., Programmation Holistique, groupe CSAR 
4.3. Découpage en phrases ............................................................................................119 
4.3.1. Le rôle de la ponctuation...................................................................................120 
4.3.2. Désambiguïsation du point (.) ...........................................................................122 
4.3.2.1. Particularités des langues naturelles traitées.....................................................123 
4.3.2.2. Les paramètres et les règles ..............................................................................124 
4.3.3. Evaluation du découpage ..................................................................................131 
4.4. Le colonage..............................................................................................................132 
4.5. Le système des règles..............................................................................................139 
4.5.1. Elaboration des règles.......................................................................................139 
4.5.1.1. Notation des tableaux de règles ........................................................................146 
4.6. Dictionnaire.............................................................................................................149 
RESULTATS ET EXPERIMENTATIONS .......................................................151 
5.1. Reconnaissance de différents groupes syntaxiques .............................................153 
5.2. Vérification et évaluation des résultats ................................................................158 
5.3. Création du lexique ................................................................................................161 
CONCLUSIONS ET PERSPECTIVES..............................................................165 
TERMINOLOGIE.........................................................................................171 
Liste des abréviations....................................................................................................174 
BIBLIOGRAPHIE.........................................................................................175 
INDEX DES FIGURES ..................................................................................199 
INDEX DES TABLEAUX...............................................................................201 
TABLE DES MATIERES..............................................................................205 
ANNEXES................................................................................................208 
208  Annexes 
START 2003 
 
 
 
 
 
 
 
ANNEXES 
