On the Relevance of Search Space Reduction in
Automatic Plagiarism Detection ∗
Sobre la importancia de la reducción del espacio de búsqueda
en la detección automática de plagio
Alberto Barrón-Cedeño and Paolo Rosso
Natural Language Engineering Lab. - ELiRF
Dpto. Sistemas Informáticos y Computación
Universidad Politécnica de Valencia
DSIC, edificio 1F Campus de Vera
Camino de Vera s/n, 46022 Valencia, Spain
[lbarron | prosso]@dsic.upv.es
Resumen: En la detección automática de plagio con referencia, los fragmentos
de texto de un documento sospechoso son buscados de manera exhaustiva en un
conjunto de documentos originales (de referencia) con el objetivo de determinar si
han sido plagiados o no. Uno de los factores más importantes para el éxito de este
tipo de aplicaciones es el tamaño del corpus de referencia el cual, al mismo tiempo,
puede representar un problema al considerar el desempeño y la precisión. En este
art́ıculo, abordamos la detección automática de plagio con referencia analizando el
impacto de una etapa previa de reducción del espacio de búsqueda (conformado por
los documentos originales en el corpus de referencia). Nuestros experimentos sobre el
corpus METER muestran una mejora en la Precisión y Cobertura de los resultados
obtenidos cuando la reducción del espacio de búsqueda es realizada al principio del
proceso de detección de plagio.
Palabras clave: detección de plagio, reducción del espacio de búsqueda, similitud
de texto
Abstract: In automatic plagiarism detection with reference, the text fragments
in a suspicious document are exhaustively searched in a set of original (reference)
documents in order to determine whether they have been plagiarised or not. One of
the most important factors for the success of this kind of applications is the size of
the reference corpus that, at the same time, may represent a problem when we con-
sider performance and precision. In this paper, we approach automatic plagiarism
detection analysing the impact of a preliminary search space reduction (composed
of the original documents in the reference corpus). Our experiments over the ME-
TER corpus show that the Precision and Recall of the obtained results are improved
when a search space reduction is applied at the beginning of a plagiarism detection
process.
Keywords: plagiarism detection, search space reduction, text similarity
1 Introduction
Plagiarism is a current problem in many sci-
entific and cultural fields.1 It is not uncom-
mon to find documents that have not been
originally written (be partially or completely)
∗ We would like to thank Paul Clough for providing
us the METER corpus and Germán Rigau for sharing
with us the Les Luthiers’s plagiarism sketch. This
work was partially funded by the MCyT TIN2006-
15265-C06-04 research project and the CONACyT-
MEXICO 192021/302009 grant.
1See for instance
http://www.youtube.com/watch?v=bYLWTxNgY6o
by their claimed authors. These cases of pla-
giarism arise from the facility of electroni-
cally accessing texts written by other people
as well as retrieving documents directly from
Internet Web pages. The amount of informa-
tion reachable through a browser may be of
great benefit, but when it is simply copied
without any “rational” processing, plagia-
rism is committed. Fortunately, the problem
that the information technology has caused
can be approached by itself.
Automatic Plagiarism Detection, a closed
Procesamiento del Lenguaje Natural, núm. 43 (2009), pp. 141-149 recibido 1-05-2009; aceptado 5-06-2009
ISSN: 1135-5948 © 2009 Sociedad Española para el Procesamiento del Lenguaje Natural
task to Authorship Attribution (Stein, Kop-
pel, and Stamatatos, 2007), can be classified
into two main approaches: plagiarism detec-
tion with reference and intrinsic plagiarism
analysis. In the former approach a suspicious
document is compared to a set of potential
source documents in order to discover a possi-
ble case of plagiarism. In the latter approach
stylometric and other text inherent features
are considered in order to detect fragments
of the suspicious document that could be pla-
giarised. This research work is focused on the
former approach.
A key factor in plagiarism detection with
reference is the size of the set of potential
source documents considered (hereinafter ref-
erence corpus). The larger the reference cor-
pus, the higher the probability of including
the source of a plagiarised text fragment. The
size of the reference corpus represents also
a lack for any text comparison process due
to the fact that it often composes a large
search space. In this work we emphasise the
relevance of reducing the search space be-
fore carrying out any text comparison strat-
egy. The search space reduction is based
on the Kullback-Leibler distance, which has
been previously applied to documents clus-
tering (Bigi, 2003) among other tasks. This
research is mainly oriented to improve the
quality of the obtained results (in terms of
Precision and Recall) of automatic plagiarism
detection.
The rest of the paper is structured as fol-
lows. Section 2 gives a brief overview of pla-
giarism detection and includes a description
of some of the state of the art methods. Sec-
tion 3 is intended to outline the corpus used
in the research work. Section 4 describes the
proposed reduction method as well as an ex-
haustive text comparison method. In Sec-
tion 5 the results obtained by the different
experiments carried out are discussed. Fi-
nally, Section 6 draws some conclusions and
future work.
2 Plagiarism Detection Overview
Among the most frequent plagiarism cases,
which are feasible to be automatically de-
tected are: direct copy of text and text re-
wording (changing words by synonyms or
changing the order of the text).2 Maurer,
2Due to the unclear text dependency between the
plagiarism and its source, plagiarism of citations and
ideas are not considered automatically detectable.
Kappe, and Zaka (2006) have organised the
automatic detection methods into three main
categories including those which:
• Try to detect suspicious text fragments
on the basis of stylometric analysis;
• Make an exhaustive comparison of sus-
picious versus reference texts in order to
find the source of a potentially plagia-
rised text; and
• Select one characteristic text fragment
of the suspicious document in order to
search for it on the Web.
This simple classification entails to dis-
criminate the plagiarism detection meth-
ods into the two main approaches afore-
mentioned. Intrinsic plagiarism analysis is
mainly inspired by the fact that humans can
detect plagiarism cases by simply reading a
text (without comparing it to any other doc-
ument). The idea is to capture the writing
style across the suspicious text in order to
find fragments which are candidates of being
plagiarised.
The main parameter considered by Meyer
zu Eißen and Stein (2006) is known as Aver-
aged Word Frequency Class (AWFC), where
each word w is assigned to a class c(w). Given
a suspicious document s, the frequency of
each word w ∈ s (fs(w)) is calculated. Af-
ter this, the words are sorted by their fre-
quency in decreasing order. The word with
the maximum frequency is named w∗ and is
assigned to the class c0. Then, any other
word w ∈ s is assigned to the class given by
log2(fs(w∗)/fs(w)). The classes distribu-
tion reflects style and complexity as well as
the vocabulary size. When analysing a doc-
ument written by a single author (an origi-
nal text), AWFC shows a small variance no
matter the size of the analysed text. AWFC
as well as other stylometric features are cal-
culated for the entire document as well as
for each paragraph in order to look for un-
expected variations in the obtained values.
This approach avoids the high cost of a text
comparison process as well as the difficulty
of compiling a good reference corpus. How-
ever, due to the method philosophy, no hint
is obtained about the potential source of a
presumably plagiarised text fragment.
Plagiarism detection with reference is
based on the comparison of suspicious and
reference texts. Once a suspicious text is
found to be similar enough to an original
Alberto Barrón-Cedeño and Paolo Rosso
142
Procesamiento del Lenguaje Natural, núm. 43 (2009)
one, it is considered a plagiarism candidate.
Consider that one of the main difficulties in
this approach (after having compiled a good
enough reference corpus, which is by itself a
hard task), is how to compare the text frag-
ments considering the big size that a refer-
ence corpus should have. Following, we give
some different approaches to this task.
The CHECK system approaches plagia-
rism detection on the basis of the documents
structure (Si, Leong, and Lau, 1997). In
CHECK the reference as well as the suspi-
cious documents must be LATEXfiles. The
documents, whose structures are represented
in a tree format, are compared with a depth
first search strategy. In those cases where
a leaf (composed of a pair of paragraphs)
is reached, the similarity between suspicious
and reference paragraphs is calculated on the
basis of the dot plot technique. The weakness
of this approach is that it is only able to pro-
cess LATEX files.
The PPChecker system carries out an
exhaustive text comparison at the sentence
level (Kang, Gelbukh, and Han, 2006). In
this approach the sentences vocabularies are
expanded considering Wordnet synonymic
relationships. The method considers the vo-
cabulary intersection and complement be-
tween suspicious and reference sentences in
order to discriminate real plagiarism cases
from casual vocabulary intersections. It
is able to differentiate among exact copy
of sentences, word insertion, word removal
and rewording instead of simply determining
whether there is a case of plagiarism or not.
Text splitting (considering sentences,
paragraphs or any other text chunk) is not
always necessary. The Ferret system (Lyon,
Barrett, and Malcolm, 2004) bases the pla-
giarism analysis process on a word-level tri-
grams comparison. In this case, the trigrams
in the suspicious text are obtained in order
to after compare them to a set of reference
texts (also codified as trigrams). The method
defines whether or not the suspicious and ref-
erence documents become a potential case of
plagiarism depending on the amount of com-
mon trigrams between both texts.
When plagiarism detection with reference
is carried out in “real life”, a big drawback
is the big size that a good reference corpus
should reach. Precisely, this size (the number
of documents in the reference corpus) rep-
resents the search space for every suspicious
document to be analysed. Some efforts, such
as fingerprinting techniques (Stein, 2007),
have been made in the direction of improving
the search speed. Instead of the original text
fragments, a numerical value is assigned to
each text chunk. The numerical values (fin-
gerprints) of the reference and suspicious doc-
uments are compared in order to determine
a possible case of plagiarism.
These approaches to plagiarism detection
with reference share a common idea: a sus-
picious document must be exhaustively com-
pared to all the documents contained in a ref-
erence corpus. As it will be shown across the
following sections, assuming this behaviour
can affect the quality of the obtained results.
In this research work we describe our pro-
posed solution to this problem: a previous
selection of good source candidates of a sus-
picious text.
3 The METER Corpus
In order to experiment we have opted for con-
sidering a standard corpus. In this way, we
offer results that could be after compared
to those obtained by other methods. The
METER corpus (Clough, Gaizauskas, and
Piao, 2002) was created inside of the METER
(MEasuring TExt Reuse) Project3. The ob-
jective of this project was working on “de-
tecting and measuring text reuse”.
This corpus, which is not a real plagiarism
corpus, can be divided into two subcorpora.
The first one is composed of a set of news
reported by the Press Association (PA), the
major UK news agency. The news reported
by the PA are distributed to nine British
newspapers (The Times, The Guardian, The
Independent, The Telegraph, etc.) for their
publication. This is precisely the second part
of the corpus, which contains notes about
the same news written in any of the differ-
ent newspapers.
The notes in the newspaper subcorpus
have been tagged by an expert journalist con-
sidering three main levels of derivation from
the corresponding PA note: wholly derived,
partially derived and non derived. These tags
mean that the PA version of the note was
the only source, one of the sources, or none
of the sources of the newspaper note, respec-
tively (Clough, Gaizauskas, and Piao, 2002).
Additionally, a good part of the notes text
3http://www.dcs.shef.ac.uk/nlp/meter/
On the Relevance of Search Space Reduction in Automatic Plagiarism Detection
143
Procesamiento del Lenguaje Natural, núm. 43 (2009)
Feature Entire PA Papers
|tokens| 526,427 226,427 299,767
|tokens| (avg) 306.12 293.68 318.56
|types| 40,336 25,728 30,173
|typess| 28,990 18,643 22,204
Table 1: METER Corpus statistics. Tokens
in the entire subcorpora and per document;
types before and after stemming.
fragments have been identified as:
verbatim if the text fragment is an exact
copy of the PA version,
rewrite if it has been modified from the PA
version, or
new if it has nothing to do with the PA ver-
sion.
The entire METER corpus is composed of
around 1,700 texts from July 1999 to June
2000. Table 1 shows some statistics about it
including the number of tokens and types in
the entire corpus as well as in the PA and
newspapers notes.
For our purposes, the entire set of PA
notes, 771 documents, are considered as
source documents (i.e., the reference corpus).
Those newspaper notes which text fragments
are tagged (as verbatim, rewrite or new), 444
documents, compose the corpus of suspicious
samples.
In order to illustrate the corpus samples,
Figure 1 shows a story fragment written by
the PA followed by the annotated version of
the same story as published in The Telegraph.
For an easier identification, the PA version
contains those fragments that The Telegraph
copied verbatim and rewrote highlighted (in
bold and italic respectively). It can be noted
from this example that the sentences in the
“potentially plagiarised” documents are com-
posed of a mix of verbatim, rewritten and
new text fragments.
The experiments carried out in this re-
search work are based on the search of po-
tentially plagiarised sentences. A sentence is
considered plagiarised if a high percentage
of its words have been copied verbatim or
rewritten from the original PA source note.
In order to avoid considering incidental com-
mon fragments (such as named entities) as
plagiarism cases, a sentence must fulfil the
following inequality to be considered as pla-
giarised:
Press Association version
Celebrity chef Marco Pierre White today won
the battle of the Titanic and Atlantic restau-
rants. Oliver Peyton, owner of the Atlantic
Bar and Grill, had tried to sink Marco’s new Ti-
tanic restaurant housed in the same West End
hotel in London by seeking damages against
landlords Forte Hotels and an injunction in the
High Court. But today the Atlantic announced in
court it had reached a confidential agreement with the
landlords and was discontinuing the whole action.
The Telegraph version
<R> THE </R>
<V> chef Marco Pierre White </V>
<R> yesterday </R>
<V> won </V>
<R> a dispute over </R>
<V> the Titanic and Atlantic restaurants.
</V>
<V> Oliver Peyton, owner of the Atlantic,
had tried to </V>
<R> close White’s </R>
<V> new Titanic restaurant, housed in the
same West End hotel in London, by
seeking damages against </V>
<R> the </R>
<V> landlords, Forte Hotels, and </V>
<R> a </R>
<V> High Court injunction.</V>
<R> He </R>
<V> claimed that the Titanic was a
replica of the Atlantic and should
not be allowed to trade in competition
at the Regent Palace Hotel. </V>
Figure 1: PA and The Telegraph notes of the
news item “Titanic restaurant case discontin-
ued”. <R> = rewrite, <V> = verbatim
|wV ∪ wR| > 0.4|w| , (1)
where |w| is the number of words in the entire
sentence, whereas |wV ∪wR| is the number of
words in verbatim and rewritten fragments in
the sentence.
The corpus preprocessing includes punc-
tuation marks and words splitting as well
as lowercasing and stemming. For stem-
ming the Porter stemmer has been applied
(Porter, 1980).4 Note that splitting punctu-
ations marks and words implies that given
the text fragment “here we are, born” the re-
sulting bigrams are {here we}, {we are}, {are
,} and {, born}.
4The Vivake Gupta implementation of the Porter
stemmer has been used in this research. It is available
at http://tartarus.org/∼martin/PorterStemmer/.
Alberto Barrón-Cedeño and Paolo Rosso
144
Procesamiento del Lenguaje Natural, núm. 43 (2009)
4 Method Definition
Due to the nature of the corpus, composed of
short texts (around 300 words per document
in average), we consider that the plagiarism
detection task is solved if given a plagiarised
sentence si ∈ s, its source document d is ac-
curately retrieved from the reference corpus.
The common schema of automatic pla-
giarism detection methods with reference is
an exhaustive comparison of sentences, para-
graphs or any other text chunk si ∈ s to the
text in d ∈ D. The processing cost of mak-
ing all the necessary comparisons is O(n ·m),
being n and m the length of s and D in
fragments, respectively. If D contains sev-
eral hundreds of documents with thousands
of words, the output could be affected as well
as the time invested in order to obtain it. Due
to this reason D must be short enough to ob-
tain the wished results in a reasonable time.
Given s and D, our propose is carrying out
a preliminary selection of those documents
d ∈ D with the highest probabilities of being
the source of the potentially plagiarised frag-
ments si ∈ s. The selected documents com-
pose the set D′ ⊂ D, such that |D′|  |D|.
After D′ has been obtained, an exhaustive
comparison method can be applied in order
to relate a fragment si ∈ s to its potential
source document d ∈ D′.
The proposed method for the selec-
tion of reference documents, which implies
the search space reduction, is based on
the Kullback-Leibler distance (Kullback and
Leibler, 1951) (Subsection 4.1). For the ex-
haustive text comparison we have opted for
the containment measure (Lyon, Malcolm,
and Dickerson, 2001), over word-level bi-
grams, which have previously shown good re-
sults in this task (Barrón-Cedeño and Rosso,
2009) (Subsection 4.2).
4.1 Search Space Reduction
Different methods to relate a potentially pla-
giarised text to its source have shown good
results (Si, Leong, and Lau, 1997; Kang, Gel-
bukh, and Han, 2006; Lyon, Malcolm, and
Dickerson, 2001). However, a difficult which
has not been considered is the size that a ref-
erence corpus can reach. As it can be seen
in the following section, the large size of the
reference corpus (the search space) can affect
the quality of the obtained results in this kind
of analysis. In order to solve this problem,
we propose a method for reducing the search
space of the plagiarism detection task.
The method is based on the Kullback-
Leibler distance (KLδ) between two prob-
ability distributions which characterise the
reference as well as the suspicious docu-
ments. KLδ is a symmetric version of the
Kullback-Leibler divergence (Kullback and
Leibler, 1951). It measures how different (or
equal) two probability distributions P and Q,
over a feature vector X , are. In agreement
with Bigi (2003) we define KLδ as:
KLδ(P ||Q) =
∑
x∈X
(P (x)−Q(x))logP (x)
Q(x)
.
(2)
Pd and Qs are the probability distribu-
tions characterising the documents d and s,
respectively. The feature selection technique
considered in order to compose Pd is the well
known tfidf (Salton, Fox, and Wu, 1983).
The tfidf value of a given term x in a doc-
ument d is defined as:
tfidfx,d = tfx,d · idfx , (3)
where
tfx,d =
nx,d∑
k nk,d
, (4)
(n·,d is the frequency of · in d), and
idfx = log
|D|
|{d | x ∈ d}| . (5)
Equation 3 is used to define the terms
composing the vector X of Pd (i.e. the proba-
bility distribution corresponding to each ref-
erence document). Once X is defined, the
probability of each considered term x ∈ X
is calculated as in Equation 4, i.e., P (x |
d) = tfx,d. Considering distributions com-
posed only of the top 20% of the terms in
d, ranked by their tfidf value, gives a good
result comparable to the one obtained by
considering the entire set of terms (Barrón-
Cedeño, Rosso, and Bened́ı, 2009).
The probability distributions Pd have to
be re-calculated only when a new document
is added to the reference corpus. This pro-
cess can be carried out off-line before any
suspicious document is analysed. After ob-
taining the distributions Pd for each docu-
ment d ∈ D, the set D′ ⊂ D related to a
suspicious document s can be obtained.
On the Relevance of Search Space Reduction in Automatic Plagiarism Detection
145
Procesamiento del Lenguaje Natural, núm. 43 (2009)
Given a document s, a preliminary distri-
bution Q′ is obtained on the basis of Equa-
tion 4, i.e., Q′(x | s) = tfx,s. However,
when comparing it to each probability distri-
bution Pd, Q′s must be adapted to it. The
reason is that when analysing a document
s with respect to each document d ∈ D,
the vocabulary composing the corresponding
distributions will be different in most cases.
Calculating the distance between two distri-
butions composed of different terms obtains
KLδ(Pd||Q′s) = ∞ when ∃x ∈ d ∧ x /∈ s and
KLδ(Pd||Q′s) = 0 vice versa. The distribu-
tion Qs depends on the distribution Pd and it
must be composed of the same terms (i.e. the
same vocabulary). If x ∈ (Pd∩Q′s), Q(x, s) is
smoothed from Q′(x, s), otherwise Q(x, s) =
. This is simply a back-off smoothing of Qs
and, in agreement with Bigi (2003), the final
probability Q(x, s) is calculated as:
Q(x, s) =
{
γ · tfx,s if x ∈ d ∩ s
 it x ∈ d \ s , (6)
where γ is a normalisation coefficient esti-
mated by:
γ = 1−
∑
x∈d\s
 , (7)
respecting the condition:
∑
x∈s
γ ·Q(x, s) +
∑
x∈d\s
 = 1 . (8)
As it is expected,  is smaller than the
minimum probability of a term x in a docu-
ment d. The search space reduction process
is resumed in Figure 2.
Algorithm 1: Search space reduction.
Given s:
Q′s = {[x, tfx,s]∀x ∈ s}
for all d ∈ D
Qs = (Q
′
s | Pd)
Calculate KLδ(Pd||Qs)
LD = Ranked list of d ∈ D based on KLδ
D′ = [top 10 documents in LD]
Figure 2: Search space reduction process.
Calculating KLδ(Pd||Qs)∀d ∈ D the sub-
set of possible source documents of the pla-
giarised fragments in s is obtained. The
length of the reference corpus subset D′ ⊂ D
is only |D′| = 10. After obtaining D′, an
exhaustive text comparison strategy can be
applied in order to detect plagiarism can-
didates. The exhaustive text comparison
method we have opted for is based on word-
level n-grams.
4.2 Exhaustive Text Comparison
For the n-gram based text comparison, the
entire documents in the reference corpus are
codified as word-level n-grams. However, the
document s is first split into sentences and
thereafter each sentence si ∈ s is codified as
n-grams. In this way an asymmetric com-
parison (sentence versus document) is car-
ried out. The length of the set of n-grams
of each si ∈ s and d are different; in gen-
eral, |N(si)|  |N(d)|, where N(·) is the set
of n-grams in ·. Due to this fact, we con-
sider the containment measure (Lyon, Mal-
colm, and Dickerson, 2001), a value in the
range of [0, 1], to determine if a fragment si
is plagiarised from d:
C(si, d) =
|N(si) ∩N(d)|
|N(si)| (9)
If the maximum C(si, d), after considering
every d ∈ D′, is greater than a given thresh-
old, si is considered a candidate of plagiarism
from d. The exhaustive text comparison pro-
cess is resumed in Figure 3. Both, suspicious
sentence and reference document, are repre-
sented as a bag of n-grams.
Algorithm 2: Exhaustive text comparison.
Given s and D′:
for each sentence si ∈ s
N(si) = [n-grams in si]
for each d ∈ D′
N(d) = [n-grams in d]
Calculate C(N(si)N(d))
if (M = maxd∈D(C(N(si), N(d)))) ≥ thresh
si is plagiarised from arg maxd∈D(M)
Figure 3: Exhaustive text comparison pro-
cess.
5 Experiments Description
The aim of our experiments is to investi-
gate the impact of applying a preliminary
search space reduction to a plagiarism detec-
tion method. In order to analyse this im-
pact, given s and D, we have carried out two
experiments considering different stages: (a)
Alberto Barrón-Cedeño and Paolo Rosso
146
Procesamiento del Lenguaje Natural, núm. 43 (2009)
exhaustive text comparison; and (b) search
space reduction+ exhaustive text compari-
son. The exhaustive text comparison is based
on the containment measure, while the search
space reduction is based on the Kullback-
Leibler distance.
The main purpose of these experiments
is to compare how the quality of the ob-
tained output is influenced by the reduction
stage. As it has been pointed out (Section 3),
the reference corpus is composed of 771 PA
notes while the suspicious corpus contains
444 newspaper notes.
Different probability distributions have
been considered in order to characterise the
suspicious document s as well as the refer-
ence documents d ∈ D. We have consid-
ered multi-word terms with a length of n in
the range [1, . . . , 5]. As it is expected, the
best result for the search space reduction has
been obtained by considering n = 1. Higher
n-gram levels produce distributions where a
good part of the terms have a probability
close to 1. These distributions (where almost
all the terms have the same probability), do
not allow KLδ to effectively determine how
close two documents are.
For the exhaustive text comparison, it
has been previously shown that considering
n = 2 gives the best results in terms of Preci-
sion and Recall (Barrón-Cedeño and Rosso,
2009). Comparable results have been re-
ported by considering n = 3 (Lyon, Mal-
colm, and Dickerson, 2001; Barrón-Cedeño
and Rosso, 2009). However, due to the fact
that bigrams comparisons are simpler, we
have opted for considering this n-gram level.
By using a bag of words (n = 1), relevant
factors for plagiarism detection such as pla-
giarism detection and writing style are elimi-
nated. Additionally, the probability of a sin-
gle word of appearing in an entire document
is too high. Considering n > 3 would make
the search strategy too rigid and a plagia-
rised sentence with just small changes would
be more difficult to be detected.
Figure 4 compares the final detection re-
sults with and without search space reduc-
tion. The evaluation is carried out on the ba-
sis of the standard measures Precision, Recall
and F -measure. The figure shows the evolu-
tion of the three measures while the detection
threshold is varied. As it is evident, Precision
and Recall show a normal behaviour as the
threshold increases: Precision increases while
 0.2
 0.3
 0.4
 0.5
 0.6
 0.7
 0.8
 0.9
 1
 0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9  1
M
ea
su
re
Threshold (containment)
Precision
Recall
F−measure
(a) Searching a text fragment in the original search space
 0.2
 0.3
 0.4
 0.5
 0.6
 0.7
 0.8
 0.9
 1
 0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9  1
M
ea
su
re
Threshold (containment)
Precision
Recall
F−measure
(b) Searching a text fragment in the reduced search space
Figure 4: Evaluation of searching results
combining different options
Exp. thresh P R F
s, D ∗ 0.34 0.74 0.62 0.68
s, D 0.34 0.73 0.63 0.68
s, D′ 0.25 0.77 0.74 0.75
Table 2: P, R and F -measure obtained by the
different experiments (results considering the
best F -measure). The first row corresponds
to the same experiment of the second one but
without carrying out a stemming process.
Recall decreases (both in a soft way). It can
be seen that in general the curves correspond-
ing to those experiments including the search
space reduction stage evolve across higher
values of P, R and hence F -measure. The
best combinations of values obtained for this
metrics are resumed in Table 2.
In the first experiment (Figure 4(a), sec-
ond row of Table 2), an exhaustive compar-
On the Relevance of Search Space Reduction in Automatic Plagiarism Detection
147
Procesamiento del Lenguaje Natural, núm. 43 (2009)
ison of si ∈ s is carried out by considering
the entire set of documents in the reference
corpus D. The containment-based compar-
ison technique obtains good results by it-
self (F -measure = 0.68 with threshold =
0.34). However, considering too many ref-
erence documents which are unrelated to the
suspicious one, produces noise in the output,
affecting P as well as R.
In the second experiment (Figure 4(b),
third row of Table 2) the best F -measure is
higher than in the previous one, which is ob-
tained by considering a lower threshold. This
behaviour is due to the fact that when s is
compared to the entire corpus D, each si is
compared to too many documents that are
not even related to the topic of s (and that
cannot be possible sources of it). However,
common n-grams are found in documents of
D which are not related at all with s. By re-
ducing the set of potential sources in the ref-
erence corpus, less noisy comparisons are car-
ried out, improving the Precision. Addition-
ally, as the actual source documents of the
plagiarism sentences are correctly retrieved
during the reduction, the Recall is not af-
fected. On the contrary, it is improved due
to the fact that lower thresholds can be con-
sidered.
An additional experiment without stem-
ming nor search space reduction is also re-
ported (first row of the Table 2). Compar-
ing the results to those obtained after stem-
ming is quite interesting. There is no sig-
nificant difference between the obtained re-
sults. The stemming process, that frequently
improves the output of other information re-
trieval tasks, does not affect the results in this
case. However, the search space reduction
causes an important increase in the quality
of the plagiarism analysis output.
The results displayed in Figure 4 corre-
spond to the estimation stage of the experi-
ment (variation of the threshold). However in
a further experiment, based on a 5-fold cross-
validation, the results obtained with the cor-
responding test sets did not present any vari-
ation with respect to those obtained during
the estimation. This fact reflects the stability
of the method.
A secondary aspect to consider is the pro-
cessing time. Carrying out a search space
reduction before the exhaustive search pro-
cess causes an important decrease in the pro-
cessing time. This is due to three main rea-
sons: (1) the probability distribution Pd is
pre-calculated for every reference document;
(2) the probability distribution Q′s is calcu-
lated only once and simply adapted to define
the probability distribution Qs given each Pd;
and (3) s is compared to the reduced set D′,
which only contains the 10 of the original set
of documents D with the highest probabil-
ities of being the source of the potentially
plagiarised sentences in s. The average time
needed to analyse a suspicious document in-
cluding search space reduction and exhaus-
tive search over the minimised reference cor-
pus is 10 times lower than carrying out an
exhaustive text comparison of a suspicious
document in the entire reference corpus.
6 Conclusions and Further Work
In this paper we have investigated the impact
that the search space reduction may have
on the task of automatic plagiarism detec-
tion with reference. The search space reduc-
tion method, based on the Kullback-Leibler
symmetric distance, measures how close two
probability distributions are. The probabil-
ity distributions are composed of a set of uni-
gram terms from the reference and suspicious
documents.
In the experiments we carried out, a com-
parison of the obtained results was made
(also in terms of time performance) employ-
ing a method that exhaustively searches for
bigrams of the suspicious document in the
reference corpus. When the search space re-
duction is applied, the entire reference corpus
(composed of approximately 700 documents)
is reduced to only 10 reference documents. In
these optimised conditions, the quality of the
obtained output in terms of Precision, Re-
call and therefore F -measure is importantly
increased (particularly, F -measure increases
from 0.68 to 0.75).
As future work, we would like to investi-
gate the impact of the search space reduc-
tion in automatic plagiarism detection with
larger documents and reference corpora in-
cluding other registers such as scholar and
literary.
References
Barrón-Cedeño, A. and P. Rosso. 2009. On
Automatic Plagiarism Detection based on
n-grams Comparison. In M. Boughanem,
C. Berrut, J. Mothe, and C. Soule-Dupuy,
editors, Proceedings of the 31st Euro-
Alberto Barrón-Cedeño and Paolo Rosso
148
Procesamiento del Lenguaje Natural, núm. 43 (2009)
pean Conference on IR Research, volume
5478 of Lecture Notes in Computer Sci-
ence, pages 696–700, Toulouse, France.
Springer.
Barrón-Cedeño, A., P. Rosso, and J.M.
Bened́ı. 2009. Reducing the Plagiarism
Detection Search Space on the Basis of
the Kullback-Leibler Distance. In A. Gel-
bukh, editor, Proceedings of the CICLing
2009, volume 5449 of Lecture Notes in
Computer Science, pages 523–534, Mexico
city, Mexico. Springer.
Bigi, B. 2003. Using Kullback-Leibler Dis-
tance for Text Categorization. In Pro-
ceedings of the 25th European Conference
on IR Research, volume 2633 of Lecture
Notes in Computer Science, pages 305–
319, Pisa, Italy. Springer.
Clough, P., R. Gaizauskas, and S. Piao. 2002.
Building and annotating a corpus for the
study of journalistic text reuse. In Pro-
ceedings of the 3rd International Confer-
ence on Language Resources and Evalu-
ation (LREC-02), volume V, pages 1678–
1691, Las Palmas de Gran Canaria, Spain.
Kang, N., A. Gelbukh, and S. Han. 2006.
PPChecker: Plagiarism Pattern Checker
in Document Copy Detection. In Proceed-
ings of the TSD-2006: Text, Speech and
Dialogue, volume 4188 of Lecture Notes
in Artificial Intelligence, pages 661–667,
Brno, Czech Republic.
Kullback, S. and R. Leibler. 1951. On infor-
mation and sufficiency. Annals of Mathe-
matical Statistics, 22(1):79–86.
Lyon, C., R. Barrett, and J. Malcolm. 2004.
A theoretical basis to the automated de-
tection of copying between texts, and
its practical implementation in the Ferret
plagiarism and collusion detector. In Pro-
ceedings of Plagiarism: Prevention, Prac-
tice and Policies Conference, Newcastle,
UK.
Lyon, C., J. Malcolm, and B. Dickerson.
2001. Detecting short passages of simi-
lar text in large document collections. In
Proceedings of the Conference on Empiri-
cal Methods in Natural Language Process-
ing, pages 118–125, Pennsylvania, USA.
Maurer, H., F. Kappe, and B. Zaka. 2006.
Plagiarism - A Survey. Journal of Univer-
sal Computer Science, 12(8):1050–1084.
Meyer zu Eißen, S. and B. Stein. 2006.
Intrinsic Plagiarism Detection. In
M. Lalmas, A. MacFarlane, S. Rüger,
A. Tombros, T. Tsikrika, and A. Yavlin-
sky, editors, Proceedings of the 28th Eu-
ropean Conference on IR Research, vol-
ume 3936 of Lecture Notes in Computer
Science, pages 565–569, London, UK.
Springer.
Porter, M.F. 1980. An algorithm for suffix
stripping. Program, 14(3):130–137.
Salton, G., E.A. Fox, and H. Wu.
1983. Extended Boolean Information Re-
trieval. Communications of the ACM,
26(11):1022–1036.
Si, A., H.V. Leong, and R.W.H. Lau. 1997.
CHECK: a document plagiarism detection
system. In Proceedings of the 1997 ACM
Symposium on Applied Computing, pages
70–77, San Jose, CA.
Stein, B. 2007. Principles of Hash-based
Text Retrieval. In Proceedings of the
30th Annual International ACM SIGIR
Conference, pages 527–534, Amsterdam,
Netherlands.
Stein, B., M. Koppel, and E. Stamatatos.
2007. Plagiarism Analysis, Authorship
Identification, and Near-Duplicate Detec-
tion (PAN’ 07). SIGIR Forum, 41(2):68–
71.
On the Relevance of Search Space Reduction in Automatic Plagiarism Detection
149
Procesamiento del Lenguaje Natural, núm. 43 (2009)
