.
Atribuci√≥n de Autor√≠a utilizando distintos tipos
de caracter√≠sticas a trav√©s de una nueva
representaci√≥n
Por
Adri√°n Pastor L√≥pez Monroy
Tesis sometida como requisito parcial para obtener
el grado de
MAESTRO EN CIENCIAS EN LA ESPECIALIDAD DE
CIENCIAS COMPUTACIONALES
en el
Instituto Nacional de Astrof√≠sica, √ìptica y Electr√≥nica
Tonantzintla, Puebla
Supervisada por:
Dr. Manuel Montes y G√≥mez
Investigador del INAOE
Dr. Luis Villase√±or Pineda
Investigador del INAOE
c¬©INAOE 2012
Derechos reservados
El autor otorga al INAOE el permiso de
reproducir y distribuir copias de esta tesis
en su totalidad o en partes
x
Resumen
Hoy en d√≠a la inmensa cantidad de informaci√≥n disponible a trav√©s de inter-
net se encuentra en constante crecimiento. Gran parte de √©sta es texto escrito
por usuarios bajo distintos contextos, por ejemplo: redes sociales, foros, bit√°co-
ras, correos electr√≥nicos, etc. En este sentido, surge la necesidad de contar con
mecanismos autom√°ticos para facilitar el an√°lisis de dicha informaci√≥n. Una de
las situaciones que en recientes a√±os ha estado ganando inter√©s es la Atribuci√≥n
de Autor√≠a (AA). De forma general, la AA consiste en lograr identicar autom√°-
ticamente los documentos de uno o m√°s autores. Por ejemplo, existe inter√©s en
el desarrollo de m√©todos para hacer frente a situaciones de: vericaci√≥n de men-
sajes terroristas, ltrado de spam, disputas por derechos de autor, etc. Hoy en
d√≠a se han propuesto diferentes algoritmos y estrategias para llevar a cabo la AA;
en especial enfoques de aprendizaje autom√°tico. Con este enfoque se pretende
construir clasicadores utilizando un conjunto de documentos de entrenamiento.
Desafortunadamente, no siempre se tiene disponible un conjunto de documentos
ideal, es decir existen escenarios donde los datos son escasos o desbalanceados.
Considerando las situaciones anteriores, los atributos textuales que mejor repre-
senten el estilo de cada autor as√≠ como la representaci√≥n de los documentos, juegan
un papel fundamental para el buen desempe√±o de los algoritmos de aprendizaje.
En esta tesis se propone un m√©todo alternativo para AA que aproveche el uso de
i
ii
distintos tipos de atributos, por medio de una nueva representaci√≥n. Se sigue la
idea de que distintos tipos de atributos (e.g., n-gramas de caracteres, signos de
puntuaci√≥n) proporcionan distintas perspectivas del estilo de los documentos y
por consiguiente de los autores. En particular, proponemos: i) utilizar conjuntos
de atributos que puedan retener el estilo de los autores, ii) caracterizarlos con
una representaci√≥n que considere las relaciones entre documentos y autores, y iii)
proponer alternativas para la integraci√≥n de la representaci√≥n de distintos tipos
de atributos en un modelo de clasicaci√≥n. La evaluaci√≥n se realiza sobre el corpus
c50, el cual ha sido utilizado en distintos trabajos de AA. Durante la evaluaci√≥n
utilizamos la exactitud para medir la clasicaci√≥n, considerando escenarios con
pocos datos de entrenamiento y desbalanceados. Los resultados experimentales
demostraron que la representaci√≥n y el m√©todo propuesto en esta tesis son una
buena alternativa para AA, incluso en los escenarios dif√≠ciles.
Palabras clave: Atribuci√≥n de Autor√≠a, Clasicaci√≥n no-tem√°tica, Estilome-
tr√≠a, Aprendizaje Autom√°tico, Ensambles
Abstract
Nowadays, the huge amount of information available in the Web is constantly
growing. Much of this information is in plain text written by users under dierent
contexts, for example: social networks, forums, blogs, emails, etc. In this regard, it
is important to have automated tools in order to assist the analysis of such infor-
mation. One situation that has gained interest in recent years is the Authorship
Attribution (AA) task. In general the main goal of AA is to identify automatically
documents belonging to one or more authors. For example, building methods to
deal with situations such as: terrorist message verication, spam ltering, copy-
right disputes, etc. Currently, dierent algorithms and strategies for addressing
AA have been proposed; especially machine learning approaches. The idea of this
approach is to build classiers using a set of training documents. Unfortunately,
the available document set is not always ideal, the latter is because there are sce-
narios where the instances are few, imbalanced, or both. Considering the above
situations, textual features that best represent the style of each author and do-
cuments representation, play a key role in the performance of machine learning
algorithms. This thesis proposes an alternative method for AA that takes advan-
tage of using dierent types of attributes, through a new representation. It follows
the idea that dierent types of attributes (e.g., character n-grams, punctuation
marks) provide dierent perspectives of the style of documents and therefore of
iii
iv
authors. In particular, we propose: i) using sets of attributes that can retain the
style of the authors, ii) characterizing textual features with a representation that
considers the relationships between documents and authors, and iii) proposing
alternatives to integrate representations of dierent types of attributes in a clas-
sication model. The evaluation is performed on the c50 corpus, which has been
used in dierent AA works. In our experiments we measure the classication ac-
curacy, considering scenarios with few training data and imbalanced clases for a
set of authors. The experimental results showed that the proposed method and
our representation is a good alternative to AA, even in settings where the training
data is limited or imbalanced.
Keywords: Authorship Attribution, Non-thematic Classication, Stylistic Fea-
tures, Machine Learning, Ensembles
Agradecimientos
Al Consejo Nacional de Ciencia y Tecnolog√≠a (CONACYT), por el apoyo otorga-
do a trav√©s de la beca no. 243957. As√≠ como al INAOE por todas las facilidades
prestadas durante mi estancia acad√©mica.
A mis asesores, Dr. Manuel Montes y G√≥mez y Dr. Luis Villase√±or Pineda quienes
con su conocimiento, experiencia y buen car√°cter me acompa√±aron a lo largo de
mis estudios.
A mis sinodales, Dr. Jes√∫s Ariel Carrasco Ochoa, Dr. Aurelio L√≥pez L√≥pez y Dr.
Sa√∫l Eduardo Pomares Hern√°ndez, por sus observaciones y comentarios. En espe-
cial, expreso mi gratitud al Dr. Ariel por su apoyo, consejos y el seguimiento que
me brind√≥.
A mis compa√±eros de la maestr√≠a, en especial a Aar√≥n, Adri√°n y Ale, gracias por
su amistad, por las discusiones sin sentido y por todos los momentos de alegr√≠a.
A mi familia, por su apoyo constante e incondicional, en especial a mi pap√°, por
siempre creer en m√≠ apoy√°ndome, anim√°ndome, escuch√°ndome, gracias pap√° eres
mi h√©roe.
v
vi
Dedicatoria
Para Dios,
porque siempre est√° conmigo
brind√°ndome fortaleza y entendimiento.
Para mis padres, Jos√© Pastor y Ma. Guadalupe,
por su amor y sus palabras de aliento
para alcanzar mis sue√±os.
Para mis hermanos, Marco y Lupita,
por su apoyo incondicional.
Para Clau,
por su cari√±o, apoyo, comprensi√≥n y motivaci√≥n.
Para todos los que creen en m√≠.
vii

√çndice general
Resumen i
Agradecimientos v
√çndice de guras xiii
√çndice de tablas xv
1. Introducci√≥n 1
1.1. Planteamiento del problema . . . . . . . . . . . . . . . . . . . . . 3
1.2. Objetivos . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4
1.3. Organizaci√≥n de la tesis . . . . . . . . . . . . . . . . . . . . . . . 5
2. Fundamento te√≥rico 7
2.1. Atribuci√≥n de Autor√≠a . . . . . . . . . . . . . . . . . . . . . . . . 7
2.1.1. Tareas principales . . . . . . . . . . . . . . . . . . . . . . . 8
2.1.2. Familias de caracter√≠sticas textuales . . . . . . . . . . . . . 9
2.1.3. M√©todos convencionales . . . . . . . . . . . . . . . . . . . 15
2.2. Algoritmos de Ensambles . . . . . . . . . . . . . . . . . . . . . . . 16
2.2.1. M√©todos de ensambles . . . . . . . . . . . . . . . . . . . . 16
ix
x √çndice general
2.2.2. M√©todos de combinaci√≥n . . . . . . . . . . . . . . . . . . . 21
2.2.3. Generaci√≥n de diversidad . . . . . . . . . . . . . . . . . . . 23
3. Trabajo relacionado 25
3.1. Representaciones tradicionales . . . . . . . . . . . . . . . . . . . . 25
3.2. Utilizaci√≥n de m√∫ltiples tipos de atributos . . . . . . . . . . . . . 27
3.3. Enfoques para identicaci√≥n de autores . . . . . . . . . . . . . . . 29
3.4. Otras representaciones y enfoques en AA . . . . . . . . . . . . . . 32
4. M√©todo propuesto 35
4.1. Representaci√≥n de atributos . . . . . . . . . . . . . . . . . . . . . 35
4.1.1. Representaci√≥n Documento Autor (RDA) . . . . . . . . . . 36
4.2. Enfoques para la identicaci√≥n de autor . . . . . . . . . . . . . . . 41
4.3. Espacios de atributos . . . . . . . . . . . . . . . . . . . . . . . . . 41
4.3.1. Enfoque de Vista General . . . . . . . . . . . . . . . . . . 43
4.3.2. Enfoque de Vista Individual . . . . . . . . . . . . . . . . . 46
5. Experimentos y Resultados 51
5.1. Metodolog√≠a experimental . . . . . . . . . . . . . . . . . . . . . . 51
5.2. Evaluaci√≥n de la Representaci√≥n Documento Autor . . . . . . . . 53
5.2.1. Experimentos . . . . . . . . . . . . . . . . . . . . . . . . . 54
5.2.2. Discusi√≥n de los resultados . . . . . . . . . . . . . . . . . . 57
5.3. Evaluaci√≥n del m√©todo de ensambles . . . . . . . . . . . . . . . . 58
5.3.1. Espacios de atributos utilizados . . . . . . . . . . . . . . . 58
5.3.2. Experimentos . . . . . . . . . . . . . . . . . . . . . . . . . 60
5.3.3. Discusi√≥n de los resultados . . . . . . . . . . . . . . . . . . 64
5.4. Consideraciones adicionales . . . . . . . . . . . . . . . . . . . . . 65
√çndice general xi
6. Conclusiones y trabajo futuro 69
6.1. Conclusiones . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 70
6.2. Trabajo futuro . . . . . . . . . . . . . . . . . . . . . . . . . . . . 72
Ap√©ndices 72
A. Espacios de atributos 75
B. Criterios para formar espacios de atributos 77
C. Art√≠culo publicado 79
D. Experimentos adicionales 81
Referencias 85

√çndice de guras
4.1. Enfoque de Vista General. . . . . . . . . . . . . . . . . . . . . . . 43
4.2. Enfoque de Vista Individual. . . . . . . . . . . . . . . . . . . . . . 46
5.1. RDA con diferentes umbrales de frecuencia en los datos balancea-
dos. Cada barra representa la exactitud de un experimento y una
conguraci√≥n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 56
5.2. RDA con diferentes umbrales de frecuencia en los datos desbalan-
ceados. Cada barra representa la exactitud de un experimento y
una conguraci√≥n. . . . . . . . . . . . . . . . . . . . . . . . . . . . 57
xiii

√çndice de tablas
2.1. Algunos tipos de caracter√≠sticas l√©xicas que pueden aportar infor-
maci√≥n de estilo y contenido √∫til para Atribuci√≥n de Autor√≠a. . . 11
2.2. Elementos normalmente utilizados para la construcci√≥n de ensam-
bles de clasicadores. . . . . . . . . . . . . . . . . . . . . . . . . 17
2.3. Matriz de votaci√≥n Condorcet de un votante con lista: A, B, C, D. 23
3.1. Algunos trabajos relevantes para esta tesis en AA. . . . . . . . . 29
3.2. M√°xima exactitud alcanzada de algunos trabajos relevantes para
esta tesis. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30
5.1. RDA contra SVM utilizando las 2500 palabras m√°s frecuentes. . . 54
5.2. Se compara RDA contra BoT y MET utilizando los 2500 3-gramas
m√°s frecuentes. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 55
5.3. Principales espacios de atributos considerados, cada uno contenien-
do los Œ≤ = 2500 t√©rminos m√°s frecuentes . . . . . . . . . . . . . . 59
5.4. Utilizaci√≥n individual y conjunta de atributos utilizando BoT como
representaci√≥n base. . . . . . . . . . . . . . . . . . . . . . . . . . . 61
5.5. Utilizaci√≥n individual y conjunta de atributos utilizando RDA como
representaci√≥n base. . . . . . . . . . . . . . . . . . . . . . . . . . . 62
xv
xvi √çndice de tablas
5.6. Utilizaci√≥n individual y conjunta de atributos utilizando BoT y
RDA como representaci√≥n base. . . . . . . . . . . . . . . . . . . . 64
5.7. Resultados generales. . . . . . . . . . . . . . . . . . . . . . . . . . 65
5.8. Resultados sin pruebas de signicancia estad√≠stica de BoT+RDA
contra los resultados reportados para LOWBOW . . . . . . . . . 67
D.1. Algunos experimentos con uso individual y conjunta de atributos
utilizando BoT y RDA como representaci√≥n base y Random Forest
como clasicador. . . . . . . . . . . . . . . . . . . . . . . . . . . . 82
D.2. Algunos experimentos con uso individual y conjunta de atributos
utilizando BoT y RDA como representaci√≥n base y Na√Øve Bayes
como clasicador. . . . . . . . . . . . . . . . . . . . . . . . . . . . 83
Cap√≠tulo 1
Introducci√≥n
Hoy en d√≠a existe una enorme cantidad de informaci√≥n disponible a trav√©s de
internet, gran parte de √©sta se encuentra en formato de texto dentro de redes
sociales, correo electr√≥nico, bit√°coras, foros, diarios, c√≥digos fuente, etc. Dado
este contexto, en muchas situaciones toda esta informaci√≥n es poco √∫til si no
se cuenta con herramientas apropiadas para su an√°lisis. Por ejemplo, una de las
tareas que ha despertado m√°s inter√©s en recientes a√±os es la Atribuci√≥n de Autor√≠a
(AA). En la AA se pretende construir un algoritmo capaz de aprender el estilo
de escritura de uno o m√°s autores, para identicar autom√°ticamente sus futuros
documentos (Stamatatos, 2009). Algunas de las problem√°ticas relacionadas con
AA involucran: identicaci√≥n de acoso sexual, atribuci√≥n de mensajes terroristas,
vericaci√≥n de autenticidad de notas suicidas, disputas por derechos de autor,
identicaci√≥n de autores de c√≥digo fuente malicioso, detecci√≥n de spam, detecci√≥n
de plagio, y la atribuci√≥n an√≥nima o disputas de trabajos literarios para autores
conocidos (Stamatatos, 2009).
Para hacer frente a las necesidades en AA, distintos enfoques han sido propues-
tos. Por ejemplo, algunos trabajos abordan el problema utilizando clasicaci√≥n
1
2 Cap√≠tulo 1. Introducci√≥n
supervisada (de Vel et al., 2001; Pavelec et al., 2008), sobre todo cuando existen
unas cuantas decenas de autores. Otros enfoques se encaminan por el lado de la
recuperaci√≥n de informaci√≥n, en especial cuando se tienen miles de autores (Schler
et al., 2009) . De manera general, la mayor√≠a de los enfoques involucran dos tareas
elementales; la extracci√≥n de caracter√≠sticas y la representaci√≥n de documentos.
En cuanto a estas dos tareas cabe a√±adir que, aunque algunos procedimientos
en AA son similares a los de otras tareas como la clasicaci√≥n tem√°tica, existen
algunas diferencias a considerar. Por ejemplo, las caracter√≠sticas textuales m√°s im-
portantes en AA son no-tem√°ticas (Stamatatos, 2009), debido a que el principal
objetivo es modelar el estilo de escritura de cada autor (Schler et al., 2009); para
luego determinar la autor√≠a de documentos incluso en el mismo contexto tem√°tico.
Por otro lado, para la representaci√≥n de documentos es com√∫n utilizar m√©todos
basados en el modelo vectorial; pero variando aspectos en los atributos tales como
el pesado y los valores que toman.
Algunos trabajos (Stamatatos, 2009; Solorio et al., 2011) en AA han proporcio-
nado pistas de que la combinaci√≥n adecuada de algunos tipos de atributos podr√≠an
ayudar en la identicaci√≥n de los documentos del autor. Por lo tanto, es com√∫n
que algunos trabajos consideren dos o tres tipos de caracter√≠sticas textuales. Sin
embargo, para explotar esta idea y obtener el m√°ximo benecio es necesario ex-
plorar m√°s a detalle los atributos que pueden retener el estilo, formas nuevas de
caracterizarlos para ayudar a las representaciones tradicionales y la forma de in-
tegrar lo anterior en un contexto de clasicaci√≥n. Esto es precisamente la idea
general de esta tesis.
1.1. Planteamiento del problema 3
1.1. Planteamiento del problema
De acuerdo con el estado del arte, gran parte de las investigaciones en AA se
abordan utilizando:
Representaciones convencionales de clasicaci√≥n tem√°tica (Abbasi
y Chen, 2008): La mayor√≠a de los trabajos abordan AA utilizando alg√∫n
tipo de Bolsa de T√©rminos (BoT, Bag of Terms1, por sus siglas en ingl√©s),
en donde se extrae un conjunto de caracter√≠sticas textuales y luego se llevan
al modelo vectorial. No obstante, en algunas situaciones este enfoque no es
suciente, ya que cuenta con el problema de la alta dimensionalidad y alta
dispersi√≥n en la representaci√≥n. Estos inconvenientes afectan la calidad de la
representaci√≥n y dicultan la tarea de los algoritmos de aprendizaje autom√°-
tico. Otro de los inconvenientes de BoT es que, al obtener la representaci√≥n
vectorial se pierde cualquier informaci√≥n de orden o relaci√≥n que exista entre
los t√©rminos y clases. Estas desventajas hacen dif√≠cil la utilizaci√≥n de BoT
en escenarios realistas y distintos dominios (foros, correo electr√≥nico, etc.),
donde surgen algunas situaciones importantes tales como: escasos datos de
entrenamiento, clases altamente desbalanceadas o textos de entrenamiento
cortos (Frantzeskou et al., 2007). Dado este contexto, estamos interesados
en una representaci√≥n alternativa para AA, en d√≥nde se mejore la represen-
taci√≥n de los documentos y se minimizen los problemas cl√°sicos de BoT.
Pocos tipos de atributos: Existen pocos trabajos que se dediquen a ex-
plorar la forma de utilizar distintos tipos de atributos para la identicaci√≥n
1Utilizamos las siglas BoT para referirnos a una Bolsa de Palabras (BoW, Bag of Words, por
sus siglas en ingl√©s), el que los atributos adem√°s de palabras pueden ser: n-gramas de caracter,
signos de puntuaci√≥n, una etiqueta que represente la longitud de la palabra, etc.
4 Cap√≠tulo 1. Introducci√≥n
de autores. Entre los atributos que m√°s han sido utilizados se encuentran;
las palabras y los n-gramas a nivel de caracter (Argamon y Juola, 2011).
No obstante, existen otros tipos de atributos de estilo que al ser considera-
dos conjuntamente podr√≠an mejorar las tasas de clasicaci√≥n. Por ejemplo,
considere AA sobre correos electr√≥nicos usando como atributos los errores
gramaticales y las palabras vac√≠as. En esta situaci√≥n, podr√≠amos decir que
ambos atributos son de diferente tipo (e.g., de idiosincrasia y de contenido).
En el presente trabajo se propone explorar estrategias con ensambles de
clasicadores para explotar diferentes tipos de caracter√≠sticas textuales en
AA; esto tiene la idea de que, al utilizar distintos tipos de atributos, √©stos
se complementen entre s√≠ para mejorar la identicaci√≥n del autor.
1.2. Objetivos
Objetivo general:
Dise√±ar e implementar un m√©todo de Atribuci√≥n de Autor√≠a basado en el uso
conjunto de distintos tipos de atributos, caracteriz√°ndolos a trav√©s de una nueva
representaci√≥n.
Objetivos espec√≠cos:
Determinar tipos de atributos que conjuntamente puedan ayudar a retener
el estilo de escritura de los autores.
Denir una representaci√≥n especial para documentos en AA, con baja di-
mensionalidad y dispersi√≥n.
Proponer un m√©todo para AA que aproveche la combinaci√≥n de distintos
conjuntos de atributos, caracterizados a trav√©s de alguna representaci√≥n.
1.3. Organizaci√≥n de la tesis 5
1.3. Organizaci√≥n de la tesis
A continuaci√≥n se presenta la forma en la que se estructur√≥ esta tesis. Dentro
del Cap√≠tulo 2 se presentan los conceptos relacionados con AA y ensambles de
clasicadores que son utilizados a lo largo del presente trabajo. Posteriormente,
en el Cap√≠tulo 3 se realiza una revisi√≥n del trabajo relacionado con la presente tesis;
entre ellos m√©todos en AA y tipos de representaciones empleadas. El Cap√≠tulo 4
explica detalladamente el m√©todo de representaci√≥n y clasicaci√≥n utilizado. En
el Cap√≠tulo 5 se muestra la evaluaci√≥n del m√©todo, experimentos relevantes y sus
resultados. Por √∫ltimo, en el Cap√≠tulo 6 se exponen las conclusiones obtenidas y
el trabajo futuro.

Cap√≠tulo 2
Fundamento te√≥rico
En este cap√≠tulo se introducen los conceptos b√°sicos que fundamentan el pre-
sente trabajo. Principalmente se explican dos temas: i) Atribuci√≥n de Autor√≠a
(AA) y ii) Ensambles de clasicadores. La Secci√≥n 2.1 presenta la AA exponiendo
sus tareas principales, familias de caracter√≠sticas textuales y algunos de los m√©-
todos convencionales. Por otro lado, la Secci√≥n 2.2 introduce algunos conceptos
de los ensambles de clasicadores tal como los m√©todos convencionales, formas
de combinar predicciones y la importancia de la generaci√≥n de diversidad. Cabe
a√±adir que, la relevancia de los algoritmos de ensambles de clasicadores para esta
tesis, radica en que la combinaci√≥n de espacios de atributos se aborda tomando
en cuenta varios clasicadores en un sistema de votaci√≥n.
2.1. Atribuci√≥n de Autor√≠a
En este trabajo nos enfocamos en la Atribuci√≥n de Autor√≠a basada en m√©todos
estad√≠sticos y computacionales. Esto consiste en estudiar caracter√≠sticas textuales
que al medirlas nos permitan discriminar entre documentos escritos por distintos
7
8 Cap√≠tulo 2. Fundamento te√≥rico
autores (Stamatatos, 2009). La AA comparte procesos similares con otras tareas
relacionadas con el tratamiento autom√°tico de texto (e.g., la clasicaci√≥n tem√°ti-
ca). Sin embargo, existen importantes diferencias entre la AA y otros problemas
de clasicaci√≥n de documentos, sobre todo en el tipo de caracter√≠sticas textuales
que se extraen de los documentos; por ejemplo, en AA son m√°s relevantes los
atributos de estilo de escritura que los de contenido.
2.1.1. Tareas principales
En general la AA comprende dos enfoques principales, ambos con el objetivo
de conocer la autor√≠a de un cierto documento, pero en contextos un tanto distintos.
A continuaci√≥n se explica cada uno de estos enfoques:
Identicaci√≥n de Autor√≠a (IA): Consiste en predecir el autor de un do-
cumento, dado un conjunto de autores candidatos para los cuales se tienen
disponibles textos de su autor√≠a (Stamatatos, 2009). En este contexto, la IA
se puede establecer como un problema de clasicaci√≥n multiclase de una eti-
queta; donde cada documento pertenece a un autor, y los autores representan
las clases a discriminar. Dentro de este enfoque existen dos situaciones:
‚Ä¢ Clase Cerrada: Se puede asumir que el documento a predecir perte-
nece a alguno de los autores candidatos.
‚Ä¢ Clase Abierta: En esta subtarea el documento a predecir puede no
pertenecer a ninguno de los autores candidatos.
Vericaci√≥n de Autor√≠a (VA): En este enfoque s√≥lo se cuenta con un
autor y sus documentos, el objetivo es determinar si los documentos de
prueba pertenecen o no a dicho autor (Argamon y Juola, 2011). En este
2.1. Atribuci√≥n de Autor√≠a 9
sentido, este caso se puede abordar como un problema de clasicaci√≥n de
una clase (Koppel y Schler, 2004).
2.1.2. Familias de caracter√≠sticas textuales
De acuerdo a recientes foros de AA (Argamon y Juola, 2011), entre los atri-
butos m√°s √∫tiles se encuentran la selecci√≥n de ciertas palabras y los n-gramas a
nivel de caracter. Por ejemplo, tomar en cuenta la frecuencia y distribuci√≥n de
las palabras vac√≠as (e.g., el, de y sobre) a trav√©s del texto, podr√≠a contribuir a
identicar al autor. Por otro lado, n-gramas a nivel de caracter podr√≠an descu-
brir ciertas preferencias de estilo. Para ilustrar lo anterior, considere un espacio
de caracter√≠sticas de 3-gramas, en el que una alta frecuencia de los t√©rminos ing
y ed_ podr√≠an revelar la identidad de autores que tienden a escribir en tiempo
progresivo o pasado respectivamente.
Adem√°s de las palabras vac√≠as y los n-gramas, existen otros atributos de estilo
que pueden hacer m√°s efectiva la AA, por ejemplo algunos de ellos son: marcadores
l√©xicos (e.g. riqueza del vocabulario y longitud de las oraciones), secuenciales (e.g.,
n-gramas de palabras), estructurales (e.g., organizaci√≥n del texto), de contenido,
y de idiosincrasia (e.g., errores gramaticales) (Abbasi y Chen, 2008). A continua-
ci√≥n se describen de manera general algunas de las caracter√≠sticas textuales m√°s
relevantes para la AA.
Caracter√≠sticas l√©xicas
Este tipo de caracter√≠sticas toman en cuenta al texto como una secuencia de
tokens. Los tokens podr√≠an ser palabras, n√∫meros, signos de puntuaci√≥n o abrevia-
turas. En este contexto, es posible denir distintas caracter√≠sticas l√©xicas basadas
10 Cap√≠tulo 2. Fundamento te√≥rico
en estas secuencias de tokens. Por ejemplo, medir la longitud de las oraciones,
las palabras o los p√°rrafos. Tambi√©n existen medidas para calcular la riqueza del
vocabulario o el √≠ndice de repetitividad l√©xica de los documentos basados en el n√∫-
mero de tokens (Miranda-Garc√≠a y Calle-Mart√≠n, 2005). Incluso extraer, palabras,
puntuaci√≥n, o cualquier otro tipo de token l√©xico que sea frecuente. La Tabla 2.1
detalla algunos de los atributos l√©xicos m√°s importantes en AA.
Las caracter√≠sticas l√©xicas tienen la ventaja de que muchas de ellas pueden ser
extra√≠das de igual forma para distintos idiomas, con un nivel de an√°lisis relativa-
mente sencillo utilizando herramientas existentes, como los Tokenizers, salvo algu-
nas excepciones como en el Chino, donde esta tarea es un tanto m√°s complicada
(Stamatatos, 2009). No obstante, como ya se mencion√≥, algunas otras caracter√≠s-
ticas l√©xicas, requieren de algoritmos m√°s espec√≠cos para el idioma, tales como
Lematizadores, divisores de oraciones, diccionarios o correctores ortogr√°cos.
Caracter√≠sticas basadas en caracteres
Desde un punto de vista general, este tipo de caracter√≠stica considera al texto
como una secuencia de caracteres. En este sentido, es posible denir caracter√≠sticas
textuales que se basen en estad√≠sticas de los caracteres o en secuencias selectas de
estos en el texto.
Utilizar los N m√°s frecuentes n-gramas a nivel de caracter, ha resultado ser
de los atributos m√°s efectivos para AA (Houvardas y Stamatatos, 2006). Los n-
gramas a nivel de caracter son meras secuencias de caracteres de tama√±o n. √âstos
son una caracter√≠stica textual con las que es posible mantener informaci√≥n de
contenido, al mismo tiempo que informaci√≥n contextual (Stamatatos, 2009). Los
n-gramas suelen ser un tanto m√°s tolerantes a errores gramaticales y de puntua-
ci√≥n, que un simple enfoque l√©xico de obtener palabras como tokens. Por ejemplo,
2.1. Atribuci√≥n de Autor√≠a 11
Atributos l√©xicos en AA
Atributo Descripci√≥n
Palabras Son conjuntos de palabras (e.g., art√≠culos, preposiciones, adjetivos o adverbios)
o simplemente extraer las n palabras m√°s frecuentes (Pavelec et al., 2008). En
general, este tipo de caracter√≠sticas son llevadas a una representaci√≥n tradicio-
nal tal como la BoT, para despu√©s clasicar con alg√∫n algoritmo de aprendizaje
autom√°tico.
n-gramas de
palabra
Son secuencias de palabras de tama√±o n. √âstas mantienen m√°s informaci√≥n
contextual que los tokens aislados. Sin embargo, su sola utilizaci√≥n no siempre
han resultado ser un buen atributo. Se ha demostrado que su exactitud en la
clasicaci√≥n no siempre es mejor que simplemente palabras aisladas. Lo anterior
debido a que la dimensionalidad puede incrementar con el tama√±o de n y
diculta el aprendizaje. Adem√°s, la representaci√≥n vectorial suele resultar con
alta dispersi√≥n, debido a que la combinaci√≥n de tokens de tama√±o n no siempre
es encontrada en cada uno de los documentos a clasicar. Otro inconveniente,
es que es bastante probable quedarse con n-gramas que representan contenido
espec√≠co en lugar de informaci√≥n de estilo (Gamon, 2004).
Errores de
escritura
Consiste en tomar en cuenta los errores de escritura con el objetivo de captu-
rar cuestiones de idiosincrasia del autor (Koppel y Schler, 2003). Sin embargo,
no siempre resulta ser un buen atributo sobre todo si se trata de documentos
revisados (e.g., noticias, libros, art√≠culos, etc.), adem√°s de que suelen ser de-
pendientes del lenguaje y no siempre es posible conseguir un buen corrector
ortogr√°co.
Tabla 2.1: Algunos tipos de caracter√≠sticas l√©xicas que pueden aportar informaci√≥n de
estilo y contenido √∫til para Atribuci√≥n de Autor√≠a.
considere un documento con las palabras Brasil y Brazil ; un enfoque de pala-
bras los considerar√° como dos atributos distintos, cuando en realidad representan
el mismo concepto, adem√°s de un error ortogr√°co o cierta idiosincrasia del au-
tor. Por otro lado, con el enfoque basado en 3-gramas de car√°cter obtendremos
12 Cap√≠tulo 2. Fundamento te√≥rico
los siguiente atributos; Bra, ras, raz, asi, azi, sil y zil. Lo anterior signica que
mantenemos la informaci√≥n de contenido en atributos como Bra, mientras por
otro lado mantenemos esos sutiles errores gramaticales o preferencias en atributos
como sil y zil. A pesar de los puntos a favor que tiene utilizar atributos basa-
dos en caracteres tales como los n-gramas, existen desventajas en comparaci√≥n a
un enfoque l√©xico basado en palabras. Una es el aumento en la dimensionalidad
y dispersi√≥n en la representaci√≥n. Por ejemplo, al obtener los N n-gramas m√°s
frecuentes puede ocasionar que para representar una palabra se necesiten varios
n-gramas (e.g., de_, _de). Otro inconveniente en los n-gramas, consiste en c√≥mo
determinar el mejor valor para n, una n grande podr√≠a capturar informaci√≥n l√©-
xica y contextual, pero tambi√©n informaci√≥n tem√°tica (Houvardas y Stamatatos,
2006). En relaci√≥n a esto √∫ltimo, existen trabajos para elegir la mejor n o utilizar
distintos tama√±os de n (Sanderson y Guenter, 2006).
Caracter√≠sticas sint√°cticas
Obtener estas caracter√≠sticas tiene la idea de detectar elementos sint√°cticos
comunes en la escritura del autor. En este sentido, este tipo de atributo es una
idea m√°s natural para capturar el estilo. Dos ejemplos de este tipo de caracter√≠stica
son:
Etiquetas de partes de la oraci√≥n (POS, por sus siglas en ingl√©s de Part of
Speech). Por ejemplo, para enfocarnos en c√≥mo el autor utiliza palabras que
pueden ser empleadas como sustantivos o como adjetivos.
√Årboles sint√°cticos de las oraciones. Por ejemplo, para enfocarnos en la
complejidad de las oraciones del autor (e.g., midiendo la profundidad del
√°rbol sint√°ctico).
2.1. Atribuci√≥n de Autor√≠a 13
Es importante mencionar que, para extraer caracter√≠sticas sint√°cticas normal-
mente se requiere la utilizaci√≥n de herramientas de Procesamiento de Lenguaje
Natural (PLN) m√°s elaboradas, robustas y precisas, las cuales pudiesen no estar
disponibles, ya que por lo regular son espec√≠cas para cada idioma. Otro incon-
veniente de estas caracter√≠sticas es que, siempre existen errores cometidos por las
herramientas (no son precisas al 100%), obteniendo inevitablemente cierto ruido
del conjunto de datos.
La utilizaci√≥n de estos atributos en el estado del arte ha obtenido buenos re-
sultados, aunque no tan buenos como la utilizaci√≥n de solo caracter√≠sticas l√©xicas
(Stamatatos, 2009). Sin embargo, la combinaci√≥n de ambas caracter√≠sticas ha me-
jorado los resultados (Gamon, 2004). Algunas de las herramientas para obtener
este tipo de atributos son: etiquetadores de partes de la oraci√≥n, analizadores
sint√°cticos y algunos correctores ortogr√°cos.
Caracter√≠sticas sem√°nticas
Las caracter√≠sticas sem√°nticas hacen referencia al signicado, sentido, interpre-
taci√≥n o coherencia de los diferentes elementos textuales. Extraer caracter√≠sticas
sem√°nticas del texto libre de restricciones quiz√° sea una de las tareas m√°s com-
plicadas del procesamiento autom√°tico de texto. En este tipo de texto no se tiene
certeza acerca de la calidad de la escritura (sem√°ntica, sint√°ctica, ortogr√°ca).
Adem√°s, normalmente se carece de etiquetas o marcadores que proporcionen in-
formaci√≥n acerca de los elementos textuales; por ejemplo, en e-mails, el saludo,
contenido, rma, tipo de palabras, etc.
Extraer caracter√≠sticas sem√°nticas puede requerir de un nivel profundo de an√°-
lisis en el texto, que puede llegar a ser bastante impreciso. En general, las actuales
herramientas para Procesamiento de Lenguaje Natural (PLN) no han logrado ma-
14 Cap√≠tulo 2. Fundamento te√≥rico
nipular apropiadamente tareas complejas como el an√°lisis sint√°ctico de documen-
tos enteros o el an√°lisis sem√°ntico (Stamatatos, 2009). Adem√°s, las herramientas
que realizan an√°lisis de texto en este nivel suelen ser dependientes del idioma
y muy sensibles a los errores gramaticales. Debido a todos estos inconvenientes,
existen pocos trabajos que estudien caracter√≠sticas sem√°nticas con prop√≥sitos de
extraer elementos de estilo. Uno de los trabajos que se enfoca en estas caracte-
r√≠sticas es el de Argamon et al. (2007). En este trabajo se dene un conjunto de
caracter√≠sticas que se asocian a palabras o frases, para identicar qu√© papel juegan
los elementos textuales (e.g., palabras, frases) seg√∫n su contexto. De esta forma,
seg√∫n el contexto anterior, identicar si se tiene una aclaraci√≥n, un complemento
de informaci√≥n o un contraste.
Caracter√≠sticas espec√≠cas de la aplicaci√≥n
Estas caracter√≠sticas textuales, a diferencia de todas las anteriores, son de-
pendientes del dominio y tipo de documentos (e.g., emails, foros, chats). En este
sentido, podemos decir que al no ser tan generales, no pueden ser extra√≠das de
cualquier conjunto de datos. Un ejemplo de lo anterior son los emails, d√≥nde se
pueden extraer caracter√≠sticas estructurales relacionadas con el estilo; por ejem-
plo, centrar la atenci√≥n en la parte del saludo, indentado del contenido o rma.
Otro ejemplo es en p√°ginas en lenguaje HTML donde se cuenta con etiquetas de la
estructura del documento (de Vel et al., 2001). Sin embargo, como ya se ha men-
cionado, para generalizar el uso en las caracter√≠sticas textuales que representan el
estilo, es importante evitar la dependencia del dominio de los datos.
2.1. Atribuci√≥n de Autor√≠a 15
2.1.3. M√©todos convencionales
Una de las clasicaciones m√°s conocidas de los m√©todos en AA ha sido pro-
puesta en (Stamatatos, 2009). En general los m√©todos para obtener un modelo de
atribuci√≥n son tres:
1. Basados en el perl: Fue de los primeros m√©todos en utilizarse (Mosteller
y Wallace, 1964). La idea consiste en modelar el estilo de escritura bas√°ndose
en una cantidad de texto representativa del autor. √âste pod√≠a ser obtenido
a partir de la concatenaci√≥n de todos sus documentos. La idea principal es
ignorar las peque√±as diferencias entre sus documentos, y extraer caracter√≠s-
ticas del estilo general (perl) de escritura.
2. Basados en instancias: Se basan en la utilizaci√≥n de m√∫ltiples instancias
de texto del autor. La idea es extraer caracter√≠sticas de estilo comunes a
nivel documento. Los textos se representan como vectores de atributos, para
luego utilizar alg√∫n algoritmo de clasicaci√≥n. Los m√©todos m√°s modernos
normalmente utilizan este enfoque (Solorio et al., 2011; de Vel et al., 2001;
Abbasi y Chen, 2008; Plakias y Stamatatos, 2008).
3. H√≠bridos: √âstos combinan caracter√≠sticas de los dos anteriores. Por ejem-
plo, representar de manera individual cada documento, pero utilizando ca-
racter√≠sticas obtenidas a nivel clase. Es decir, se aplica alg√∫n algoritmo de
clasicaci√≥n tal como en los m√©todos basados en instancias, pero sobre vec-
tores de documentos cuyas caracter√≠sticas textuales fueron extra√≠das a partir
del perl de escritura de cada autor, tal como en los m√©todos basados en
perl.
16 Cap√≠tulo 2. Fundamento te√≥rico
2.2. Algoritmos de Ensambles
La idea principal detr√°s de estos algoritmos consiste en construir un esquema
de predicci√≥n integrando m√∫ltiples modelos de clasicaci√≥n. El objetivo es que el
modelo de clasicaci√≥n del ensamble sea mejor que cada uno de sus clasicadores
individuales (Rokach, 2009). Una de las preguntas m√°s importantes en el estudio
de aprendizaje por Ensambles es, ¬æRealmente un conjunto de clasicadores pueden
crear uno m√°s fuerte? En este sentido, la respuesta depende de las condiciones del
problema y de c√≥mo se sigan las condiciones para construir el ensamble.
De acuerdo al estado del arte relacionado con los m√©todos de ensambles, la
idea de combinar clasicadores no ha sido una tarea sencilla (Rokach, 2009); es
por ello que existen criterios importantes a considerar. Un ejemplo es que, entre
los miembros del ensamble es importante que exista diversidad en las predicciones.
Otro consideraci√≥n es que exista independencia, es decir que cada uno pueda espe-
cializarse y establecer sus propias opiniones basadas en su conocimiento privado.
As√≠ tambi√©n, es necesario alg√∫n mecanismo que convierta todas estas opiniones
privadas en una decisi√≥n colectiva.
2.2.1. M√©todos de ensambles
En cuanto a m√©todos de ensambles se reere, existen dos grandes categor√≠as
(Rokach, 2009) i) los m√©todos dependientes, en los que cada nuevo clasicador se
enfoca en aprender los errores del clasicador anterior, y ii) los independientes,
que no se ven inuenciados por el desempe√±o de otros clasicadores. En las si-
guientes secciones explicaremos las ventajas y desventajas de cada m√©todo. As√≠
como su esquema de trabajo, el cual puede ser un factor importante seg√∫n el pro-
blema a resolver. Sin embargo, antes de describirlos cabe mencionar que, existen
2.2. Algoritmos de Ensambles 17
4 elementos fundamentales en la construcci√≥n de un ensamble (Rokach, 2009), los
cuales son mostrados a detalle en la Tabla 2.2.
Elementos para ensambles
Elemento Descripci√≥n
Conjunto de datos de en-
trenamiento
Normalmente un conjunto de instancias representadas como vectores
de n atributos, con un atributo objetivo llamado clase.
Constructor del modelo
de clasicaci√≥n
Es un algoritmo I que a partir de un conjunto de entrenamiento S,
obtiene un clasicador M , es decir M=I(S).
Generador de diversidad
Es el componente encargado generar diversidad entre los clasicado-
res creados. Normalmente, selecciona las instancias o atributos con
las que se construye cada clasicador.
Combinador
Es el encargado de combinar las predicciones, con el objetivo de
convertirlas en una decisi√≥n comunitaria.
Tabla 2.2: Elementos normalmente utilizados para la construcci√≥n de ensambles de
clasicadores.
M√©todos Dependientes
En estos m√©todos se construyen los miembros del ensamble utilizando informa-
ci√≥n de los clasicadores construidos en iteraciones anteriores (Provost y Kolluri,
1999). La idea principal es que los clasicadores construidos, en iteraciones pos-
teriores logren ser m√°s especializados en elementos denidos como importantes
seg√∫n el problema.
Un ejemplo de este tipo de m√©todo son los guiados por selecci√≥n de instancias,
tambi√©n conocidos como Boosting. En este enfoque cada clasicador entrena con el
conjunto de instancias que su predecesor clasic√≥ incorrectamente. En este sentido,
18 Cap√≠tulo 2. Fundamento te√≥rico
cada nuevo clasicador se va especializando en aquellas instancias dif√≠ciles. Como
ejemplo est√° el algoritmo AdaBoost (Adaptive Boosting), √©ste fue presentado por
primera vez por Freund y Schapire en (Freund y Schapire, 1996).
Algoritmo 2.1 El algoritmo AdaBoost
Entrada: I (constructor del modelo de clasicaci√≥n), T (n√∫mero de iteraciones), S =
{x1, x2, . . . , xm} (conjunto de ejemplos etiquetados)
Salida: Mt, Œ±t; t = 1, . . . , T
1: t = 1
2: D1(i) = 1/m; i = 1, . . . ,m
3: Repite
4: Construir el clasicador Mt utilizando I y la distribuci√≥n de instancias Dt
5: Œµt =
‚àë
i:Mi(xi)6=yi
Dt(i)
6: Si Œµ > .5 entonces
7: T = t‚àí 1
8: salir del ciclo.
9: Fin Si
10: Œ±t =
1
2 ln
(
1‚àíŒµt
Œµt
)
11: Dt+1(i) = Dt(i) ¬∑ e‚àíŒ±tytMt(xi)
12: Normaliza Dt+1
13: t++
14: Hasta t < T
El Algoritmo 2.1 muestra una versi√≥n del AdaBoost para un conjunto de m
instancias, etiquetadas como ‚àí1 y +1. La idea central es asignar un peso a cada
instancia y cada clasicador. Para esto, en un inicio todas las instancias y clasi-
cadores son igual de importantes (l√≠nea 2). En seguida, cada nuevo clasicador
realiza una prueba de clasicaci√≥n que registra su desempe√±o (l√≠nea 5). Posterior-
mente, seg√∫n cierto umbral, si el desempe√±o es bueno se continua la construcci√≥n
de clasicadores (l√≠nea 6), para luego ajustar el peso del clasicador (l√≠nea 10) y
de las instancias en las que se equivoc√≥ (l√≠nea 11). Posteriormente, el clasicador
de la siguiente iteraci√≥n se enfoca en aprender las instancias con m√°s peso, es
2.2. Algoritmos de Ensambles 19
decir las m√°s dif√≠ciles (l√≠nea 4). Para la clasicaci√≥n de instancias de prueba, cada
clasicador vota con su peso Œ±, la ecuaci√≥n 2.1 muestra la idea de la predicci√≥n.
En pocas palabras, se pretende que el proceso iterativo logre obtener una serie de
clasicadores que se complementen entre s√≠.
H(x) = signo
(
T‚àë
t=1
Œ±t ¬∑Mt(x)
)
(2.1)
M√©todos Independientes
En este enfoque los datos de entrenamiento son transformados en varios sub-
conjuntos, a partir de los cuales los clasicadores son entrenados (Rokach, 2009).
Estos subconjuntos de datos pueden ser disjuntos o no. En cuanto a la predicci√≥n
nal se utiliza alg√∫n m√©todo de combinaci√≥n (e.g., voto mayoritario). Una de las
ventajas de este tipo de sistemas es que pueden ser f√°cilmente paralelizados, o
utilizar f√°cilmente distintos tipos de clasicadores.
Uno de los m√©todos m√°s conocidos es el Bagging (por sus siglas en ingl√©s
de bootstrap aggregating). √âste es mostrado en el Algoritmo 2.2, d√≥nde la idea
central es obtener un clasicador compuesto I‚àó, que para obtener buena diversidad
entrena cada miembro del ensamble con una submuestra St de un tama√±o ¬µ con
reemplazo (l√≠nea 3). La predicci√≥n del clasicador compuesto I‚àó se obtiene con la
clase m√°s veces obtenida (m√©todo de votaci√≥n simple).
Una caracter√≠stica importante de los clasicadores Bagging, es que a menudo
obtienen un clasicador compuesto mejor que cualquiera de sus miembros cons-
truido con el conjunto de datos original. La cual es especialmente cierta para los
algoritmos que al construir el modelo obtienen clasicadores con cambios signi-
cativos si el conjunto de datos fue alterado (Breiman, 1996). Por ejemplo, en
20 Cap√≠tulo 2. Fundamento te√≥rico
los √°rboles de decisi√≥n, modelos espec√≠cos sin poda, construidos sobre distintos
subconjuntos de datos, dieren signicativamente (Rokach, 2009).
Algoritmo 2.2 El algoritmo Bagging
Entrada: I (constructor del modelo de clasicaci√≥n), T (n√∫mero de iteraciones), S =
{x1, x2, . . . , xm} (conjunto de ejemplos etiquetados), ¬µ (tama√±o de la submuestra)
Salida: Mt; t = 1, . . . , T
1: t = 1
2: Repite
3: St= Muestra de ¬µ instancias de S con reemplazo.
4: Construir clasicador Mt utilizando I(St)
5: t++
6: Hasta t > T
Otro de los algoritmos Bagging m√°s conocidos es el Random Forest (ver Al-
goritmo 2.3), el cual emplea un gran n√∫mero de √°rboles de decisi√≥n sin poda
(Breiman, 2001). √âste utiliza N atributos aleatorios y sobre ellos, seg√∫n su crite-
rio, determina el que mejor discrimine (l√≠nea 4).
Algoritmo 2.3 El algoritmo Random Forest
Entrada: IDT (constructor de √°rboles de decisi√≥n), T (n√∫mero de iteraciones), S =
{x1, x2, . . . , xm} (conjunto de ejemplos etiquetados) y N (n√∫mero de atributos uti-
lizados en cada nodo)
Salida: Mt; t = 1, . . . , T
1: t = 1
2: Repite
3: St = Muestra de ¬µ instancias de S con reemplazo.
4: Construir un clasicador Mt utilizando IDT (St, N).
5: t++
6: Hasta t > T
2.2. Algoritmos de Ensambles 21
2.2.2. M√©todos de combinaci√≥n
La combinaci√≥n de predicciones es uno de los pasos m√°s importantes para el
√©xito de un ensamble. Dentro de la literatura, podemos clasicar en dos ramas
los m√©todos de combinaci√≥n de decisiones: m√©todos de pesado y m√©todos de meta
aprendizaje. Las siguientes Secciones introducen la idea principal acerca de cada
m√©todo de combinaci√≥n.
M√©todos de pesado
Son muy utilizados cuando los clasicadores tienen un rendimiento comparable
al realizar la misma tarea (Rokach, 2009). Un ejemplo de m√©todo de pesado es el
voto mayoritario, tambi√©n conocido como el m√©todo b√°sico de ensambles (BEM,
basic ensemble method, por sus siglas en ingl√©s) que simplemente obtiene la clase
m√°s elegida por los clasicadores. Muy a menudo √©ste es utilizado como baseline
a nuevos m√©todos de votaci√≥n. La Expresi√≥n 2.2 es una aproximaci√≥n de (Rokach,
2009) a las ideas anteriores.
clase(x) = argmaxcidom(y)
(‚àë
k
g(yk(x), ci)
)
(2.2)
donde yk(x) es la clasicaci√≥n del k-√©simo clasicador y g(y, c) es un indicador de
funci√≥n denido como:
g(y, c) =
Ô£±Ô£¥Ô£≤Ô£¥Ô£≥1 y = c0 y 6= c (2.3)
Algunos m√©todos de votaci√≥n consideran otros aspectos de la elecci√≥n, tal como
los votos para los otros candidatos. Por ejemplo, en la votaci√≥n de Condorcet
22 Cap√≠tulo 2. Fundamento te√≥rico
gana el candidato m√°s preferido ante el resto de los candidatos al compararse
de uno en uno (Montague y Aslam, 2002). En el sistema de votaci√≥n Condorcet
b√°sico cada votante ordena a los candidatos en funci√≥n de sus preferencias, es
decir del candidato favorito hasta el menos preferido. En el momento de votar,
se compara por parejas a cada candidato contra el resto de los candidatos. Es
decir, enfrentar a los candidatos uno a uno en muchas elecciones. Para conocer al
ganador entre dos candidatos A y B se cuenta el n√∫mero de votantes que preeren
a A sobre B y viceversa. El ganador de la elecci√≥n es el que gan√≥ la mayor√≠a de
los enfrentamientos por parejas. En caso de empate, se utiliza un mecanismo
alternativo; por ejemplo, votaci√≥n mayoritaria entre los empatados, o un voto
simple para todos los candidatos. En caso de presentar nuevamente empate, otro
criterio de selecci√≥n (e.g., una selecci√≥n aleatoria) se emplea hasta encontrar un
ganador.
Una forma sencilla de hacer la votaci√≥n Condorcet se explica a continuaci√≥n.
Considere una elecci√≥n entre 4 candidatos; A, B, C yD. En este contexto, suponga
que un votante tiene su lista de candidatos como:B, C, A, D. En esta lista B es el
candidato favorito y D es el menos preferido. En seguida, cada lista de votaci√≥n
se convierte en una matriz de voto, donde un 1 signica preferencia al candidato
que se est√° comparando contra todos, y 0 signica que preere al candidato rival.
As√≠ pues, para el resultado nal de la elecci√≥n, solo hay que sumar las matrices de
cada votante. A continuaci√≥n la Tabla 2.3 muestra la matriz de voto para la lista
anterior.
2.2. Algoritmos de Ensambles 23
A B C D
A - 0 0 1
B 1 - 1 1
C 1 0 - 1
D 0 0 0 -
Tabla 2.3: Matriz de votaci√≥n Condorcet de un votante con lista: A, B, C, D.
M√©todos de meta aprendizaje
Suelen ser empleados cuando los clasicadores muestran un patr√≥n de aciertos
o errores en la clasicaci√≥n de ciertas instancias.
En cuanto a los m√©todos de meta aprendizaje, el Stacking es uno de los me-
jor conocidos. El Stacking es una t√©cnica para obtener la mayor generalizaci√≥n a
partir de la exactitud de los modelos (Wolpert, 1992). Normalmente es utilizado
en ensambles a base de distintos tipos de clasicadores (e.g., SVM, Na√Øve Bayes).
La idea es centrar la atenci√≥n en el patr√≥n de las decisiones que toman los dis-
tintos clasicadores. En este contexto, la decisi√≥n nal es tomada por un meta
clasicador, llamado as√≠ debido a que tuvo una fase de entrenamiento en la que
las instancias tienen como atributos las decisiones de los clasicadores miembros.
2.2.3. Generaci√≥n de diversidad
La generaci√≥n de diversidad es uno de los elementos m√°s importantes a la hora
de construir ensambles con buen desempe√±o (Tumer y Ghosh, 1996; Krogh y Ve-
delsby, 1995; Kuncheva, 2005; Maimon y Rokach, 2002). Es interesante mencionar
que, aunque es uno de los aspectos fundamentales en casi todos los m√©todos de
24 Cap√≠tulo 2. Fundamento te√≥rico
ensambles de la actualidad, en el contexto de clasicaci√≥n no existe una teor√≠a
ampliamente aceptada y denitiva que explique c√≥mo y por qu√© la diversidad en-
tre distintos modelos contribuye positivamente en el desempe√±o del clasicador
(Brown et al., 2005) . En este sentido, Rokach (2009) clasica las distintas formas
de obtener esta diversidad que son utilizadas en el estudio de ensambles, las cuales
son:
Manipulaci√≥n del conjunto de entrenamiento: cada miembro del en-
samble entrena con diferentes muestras o proyecciones del conjunto de datos.
Manipulaci√≥n del constructor del modelo de clasicaci√≥n: por ejem-
plo, ajustar los par√°metros con los que se construye el clasicador.
Cambiar la representaci√≥n del atributo objetivo (clase): cada clasi-
cador resolver√° un concepto distinto. Normalmente se remplaza el atributo
clase con una funci√≥n, tal que el dominio del nuevo atributo clase es m√°s
peque√±o que el original.
Particionar el espacio de b√∫squeda: La idea es que cada miembro ex-
plore en un subespacio distinto, del espacio de b√∫squeda total. Un ejemplo
de ello es entrenar los clasicadores utilizando solo ciertos subcojuntos de
caracter√≠sticas de las instancias. En este sentido, cada clasicador contar√°
con distintas vistas del conjunto de datos.
H√≠bridos: la idea es obtener diversidad combinando cualquiera de las es-
trategias anteriores. Por ejemplo, utilizando varios tipos de clasicadores en
conjunto con la manipulaci√≥n del conjunto de entrenamiento.
Cap√≠tulo 3
Trabajo relacionado
En este cap√≠tulo se presenta el trabajo relacionado m√°s relevante para esta
tesis. La Secci√≥n 3.1 inicia con una descripci√≥n de las representaciones tradiciona-
les en AA, posteriormente en la Secci√≥n 3.2 presenta trabajos que han utilizado
distintos tipos de atributos, luego la Secci√≥n 3.3 presenta algunos enfoques de AA
relevantes para este trabajo, y nalmente la Secci√≥n 3.4 presenta otros enfoques
no tan convencionales en AA y termina por introducir algo de la idea de nuestro
trabajo.
3.1. Representaciones tradicionales
Una manera de abordar la AA es considerarla como un problema est√°ndar de
clasicaci√≥n. De esta forma, se puede establecer como un problema multiclase de
una etiqueta, donde los autores representan la clase a discriminar. Por lo tanto,
distintos enfoques tradicionales pueden ser utilizados para hacer frente a la iden-
25
26 Cap√≠tulo 3. Trabajo relacionado
ticaci√≥n de autores. Por ejemplo, la Bolsa de T√©rminos (BoT, Bag of Terms1,
por sus siglas en ingl√©s) clasicando con M√°quinas de Vectores de Soporte (SVM,
Support Vector Machines, por sus siglas en ingl√©s) ha sido un enfoque ampliamente
utilizado para AA (Houvardas y Stamatatos, 2006). Las representaciones del tipo
BoT construyen vectores utilizando caracter√≠sticas textuales; por ejemplo, tomar
cada palabra del vocabulario como atributo. De esta manera, la BoT representa
documentos con vectores de caracter√≠sticas, asignando un valor a cada una de ellas
(Pavelec et al., 2008). Este valor podr√≠a ser desde valores Booleanos (e.g., 1 o 0)
hasta complejos valores calculados a partir del an√°lisis del corpus.
Las representaciones BoT han sido muy utilizadas para identicar autores de
correos electr√≥nicos, ltraci√≥n de spam y detecci√≥n de plagio (Stamatatos, 2009).
Sin embargo, uno de los principales problemas de las representaciones BoT es
que no mantienen ning√∫n orden o relaci√≥n entre los t√©rminos o clases; lo cual
podr√≠a proporcionar informaci√≥n valiosa para mejorar la representatividad de los
documentos. Un segundo problema con las representaciones del tipo BoT ocurre en
escenarios realistas de AA donde existen grandes vocabularios, pero pocos datos de
entrenamiento y clases desbalanceadas para los autores candidatos (Stamatatos,
2008). En consecuencia, las representaciones BoT tienden a favorecer las clases
mayoritarias, cuando de hecho cada documento puede pertenecer a cualquiera
de los autores. (e.g., en c√≥mputo forense donde se requiere discriminar entre un
conjunto de presuntos culpables) (Stamatatos, 2008). Un tercer problema con las
representaciones BoT es que normalmente tienen alta dimensionalidad, lo que
requiere de un gran n√∫mero de recursos computacionales para llevar a cabo la
1Utilizamos las siglas BoT para referirnos a una Bolsa de Palabras (BoW, Bag of Words, por
sus siglas en ingl√©s), el que los atributos adem√°s de palabras pueden ser: n-gramas de caracter,
signos de puntuaci√≥n, una etiqueta que represente la longitud de la palabra, etc.
3.2. Utilizaci√≥n de m√∫ltiples tipos de atributos 27
clasicaci√≥n de grandes conjuntos de documentos, lo cual podr√≠a ser poco pr√°ctico
en algunas situaciones (e.g. AA en foros, donde se pueden llegar a tener cientos
de documentos para algunos autores) (Solorio et al., 2011).
3.2. Utilizaci√≥n de m√∫ltiples tipos de atributos
En AA realizar una selecci√≥n de qu√© atributos representan el estilo y c√≥mo
combinarlos no ha resultado ser una tarea trivial. Existen algunos trabajos en los
que se combinan dos o m√°s conjuntos de atributos textuales distintos. Sin em-
bargo, esto implica que normalmente se tiene que considerar el problema de la
dimensionalidad; el cual afecta la calidad de la representaci√≥n, y diculta la tarea
de los algoritmos de aprendizaje. Para afrontar esta situaci√≥n, algunos trabajos
han utilizado algoritmos de selecci√≥n de caracter√≠sticas (Forman, 2003). Desafortu-
nadamente, el uso de este tipo de algoritmos puede obtener demasiados atributos
de contenido tem√°tico, en lugar de atributos que representen el estilo del autor
(Stamatatos, 2009) . Por lo tanto, la alternativa m√°s com√∫n ha sido seleccionar
conjuntos de caracter√≠sticas textuales enfocados a retener mayor informaci√≥n de
estilo. En este sentido, la selecci√≥n de caracter√≠sticas en AA suele diferir con la
de otras tareas tales como la Clasicaci√≥n Tem√°tica. Por ejemplo, distintos tra-
bajos en AA han demostrado que uno de los criterios m√°s importantes consiste
en seleccionar aquellos elementos m√°s frecuentes (Koppel, Akiva, y Dagan, 2006)
(Forman, 2003) (√©stos normalmente se eliminan en otras tareas). Es decir, a partir
de un conjunto de atributos denido, seleccionar los que m√°s ocurrencias tengan
dentro del conjunto de documentos. Lo anterior, con la idea de que entre m√°s
frecuente sea el atributo a trav√©s del corpus, m√°s variaci√≥n de estilo podr√≠a ser
capturada. Otro punto importante est√° en la combinaci√≥n de atributos. Por ejem-
28 Cap√≠tulo 3. Trabajo relacionado
plo, en muchas ocasiones las caracter√≠sticas textuales que parecen ser irrelevantes
de manera individual, pueden llegar a ser √∫tiles en conjunto con otras (Gamon,
2004).
Desde hace algunos a√±os se han realizado distintos trabajos en AA que contem-
plan la utilizaci√≥n de conjuntos diferentes de atributos con enfoques de aprendizaje
autom√°tico. Por ejemplo, en (de Vel et al., 2001) tomaron distintos marcadores
de estilo (e.g., total de palabras cortas, total de l√≠neas en blanco, palabras vac√≠as,
etc.), y representaron correos electr√≥nicos como vectores de 170 atributos; poste-
riormente, clasicaron con SVM. En otro trabajo, Pavelec et al. en (Pavelec et al.,
2008) utilizaron adverbios y adjetivos para identicar a los autores de documen-
tos cortos en Portugu√©s a trav√©s de SVM. Por otra parte, algunas investigaciones
proponen un uso m√°s extenso de tipos de atributos, por ejemplo Abbasi y Chen
en (Abbasi y Chen, 2008) proponen una t√©cnica para identicaci√≥n de autores y
perles empleando un conjunto de cinco distintos tipos atributos con m√©todos de
An√°lisis de Componentes Principales (PCA, Principal Component Analisys por
sus siglas en ingl√©s). Otros trabajos proponen el uso de clasicadores ensambla-
dos que utilicen distintos tipos de atributos. Por ejemplo, Stamatatos y Widmer
(Stamatatos y Widmer, 2005) utilizaron un ensamble basado en SVM donde cada
clasicador es entrenado con un conjunto diferente de atributos. De manera simi-
lar, Cherkauer utiliz√≥ un ensamble de redes neuronales entrenadas sobre distintos
conjuntos de atributos (Abbasi y Chen, 2008). La idea principal detr√°s del uso
de ensambles es obtener un conjunto de clasicadores que, mediante una decisi√≥n
colectiva, mejoren la predicci√≥n de autores en la clasicaci√≥n nal (Stamatatos y
Widmer, 2005)
3.3. Enfoques para identicaci√≥n de autores 29
3.3. Enfoques para identicaci√≥n de autores
La Tabla 3.1 muestra un peque√±o historial de algunos de los trabajos en AA
relevantes para esta tesis.
Trabajo
M√∫ltiples
atributos
Ensambles
Represen-
taci√≥n
especial
para
atributos
Pondera-
ci√≥n
por
atributos
(Stamatatos y Widmer, 2005) S√≠ S√≠ No No
(Pavelec et al., 2008) S√≠ No No No
(Plakias y Stamatatos, 2008) S√≠ No No No
(Koppel, Schler, et al., 2006) S√≠ No No No
(Abbasi y Chen, 2008) S√≠ No S√≠ No
(Escalante et al., 2011) No S√≠ No S√≠
(de Vel et al., 2001) S√≠ No No No
(Frantzeskou et al., 2007) S√≠ No No No
(Solorio et al., 2011) S√≠ No S√≠ No
(Kern et al., 2011) S√≠ S√≠ No S√≠
Propuesta S√≠ S√≠ S√≠ S√≠
Tabla 3.1: Algunos trabajos relevantes para esta tesis en AA.
En la Tabla 3.1 se considera si el trabajo utiliz√≥ los siguientes criterios para
llevar a cabo la AA:
M√∫ltiples tipos de atributos: considera si utilizaron m√°s de un tipo
atributo para hacer la identicaci√≥n de autor.
Ensambles: considera si de alguna forma emplearon ensambles de clasi-
cadores que tomaran en cuenta los tipos de atributos.
30 Cap√≠tulo 3. Trabajo relacionado
Representaci√≥n individual por atributo: es decir, si se realiz√≥ alg√∫n tipo
de consideraci√≥n para representar por separado a cada tipo de atributo.
Ponderaci√≥n por atributo: es decir, si se tom√≥ en cuenta alg√∫n tipo de
ponderaci√≥n de estilo para intentar beneciar a la AA.
Por otro lado, la Tabla 3.2 complementa la informaci√≥n presentada en la Ta-
bla 3.1. La primer columna muestra el m√°ximo n√∫mero de autores y la segunda
columna la m√°xima exactitud alcanzada en la clasicaci√≥n.
Trabajo
N√∫mero
de autores
Exactitud
alcanzada
(Stamatatos y Widmer, 2005) 22 70%
(Pavelec et al., 2008) 20 83.2%
(Plakias y Stamatatos, 2008) 10 78%
(Koppel, Schler, et al., 2006) 10000 88.2%
(Abbasi y Chen, 2008) 100 91.3%
(Escalante et al., 2011) 10 86.4%
(de Vel et al., 2001) 3 92.5%
(Frantzeskou et al., 2007) 8 100%
(Solorio et al., 2011) 100 62.1%
(Kern et al., 2011) 66 67.3%%
Tabla 3.2: M√°xima exactitud alcanzada de algunos trabajos relevantes para esta tesis.
Es importante se√±alar que la Tabla 3.2 es solo para tener una idea muy general
de los resultados alcanzados por el estado del arte relacionado con esta tesis. Esto
principalmente porque la mayor√≠a de los trabajos utilizan un conjunto de datos
distinto. Es decir, los experimentos son en dominios diferentes (e-mails, blogs,
foros, noticias, etc.), con documentos de distinta longitud o utilizando un n√∫mero
3.3. Enfoques para identicaci√≥n de autores 31
de autores tan grande que puede requerir abordar la AA con otro enfoque (e.g.,
con recuperaci√≥n de informaci√≥n).
Algunos de los trabajos de la Tabla 3.1 fueron mencionados en secciones pre-
vias de este cap√≠tulo. Sin embargo, el trabajo de Kern et al. (2011) sobresale
debido que cumple m√°s caracter√≠sticas (ver columnas de la Tabla 3.1) con respec-
to a la propuesta de esta tesis. En el trabajo de Kern et al. (2011) se realiza AA
utilizando un amplio n√∫mero de atributos textuales y ensambles de clasicado-
res. √âste trabajo tiene valor para AA por el lado de su m√©todo de votaci√≥n en
los ensambles. En la votaci√≥n se propone un esquema de voto/veto pesado (vea
explicaci√≥n de m√©todos de pesado en Secci√≥n 2.2.2). La idea b√°sica es que cada
clasicador adem√°s de votar positivamente, tambi√©n puede votar negativamente
de acuerdo a ciertos umbrales alcanzados en una etapa previa de entrenamiento.
Sin embargo, aunque se utilizaron ensambles, √©stos son utilizados en su forma tra-
dicional tomando un vector de caracter√≠sticas como si todas fueran de un mismo
tipo (clasicando con Random Forest). Es decir no aprovechan el uso de los cla-
sicadores ensamblados para sacar ventaja de aspectos importantes en AA. Por
ejemplo, Plakias y Stamatatos (2008) utilizan ensambles de SVM para especializar
el aprendizaje en cada tipo de atributo. En otro ejemplo de la Tabla 3.1, Escalante
et al. (2011) utiliza ensambles SVM para aprender vectores de caracter√≠sticas que
son locales a ciertas partes del texto. Por ejemplo, vectores de caracter√≠sticas de la
parte inicial o nal de los documentos, con la idea de mantener el estilo de c√≥mo
cada autor inicia o termina de escribir.
A√∫n cuando distintas investigaciones han proporcionado pistas de que utili-
zar m√°s de un tipo de atributo benecia la tasa de clasicaci√≥n, a√∫n no existen
investigaciones que den respuestas concisas de c√≥mo combinar distintos tipos de
atributos en AA. Es por ello que en esta tesis proponemos un par de alternativas
32 Cap√≠tulo 3. Trabajo relacionado
utilizando algoritmos de ensambles y el uso de distintos espacios de atributos para
llevar a cabo la identicaci√≥n de autores.
3.4. Otras representaciones y enfoques en AA
Existen otros tipos de representaciones no tan convencionales en AA. Por
ejemplo, Plakias y Stamatatos (2008) propusieron el uso de Tensores de Segundo
Orden para representar las propiedades de estilo de los textos. La idea principal
detr√°s de esta representaci√≥n consiste en ubicar a las caracter√≠sticas relevantes to-
mando en cuenta el contexto de cada t√©rmino y su frecuencia. Lo √∫ltimo se logra
debido a que el modelo basado en tensores toma en cuenta las asociaciones entre
caracter√≠sticas que se encuentran en la misma vecindad (Plakias y Stamatatos,
2008). De esta forma, cada caracter√≠stica es asociada con otras dentro del mismo
rengl√≥n y columna. Para manejar tensores en vez de vectores utilizan una gene-
ralizaci√≥n de SVM llamada Support Tensor Machines (STM) (Cai et al., 2006).
Para la evaluaci√≥n utilizaron los 2500 n-gramas m√°s frecuentes, y utilizaron la
exactitud para medir la clasicaci√≥n. Esta representaci√≥n con tensores toma en
cuenta cierta relaci√≥n entre los t√©rminos. No obstante, √©sta no garantiza resolver
el problema de la dispersi√≥n de la informaci√≥n y la alta dimensionalidad.
En otras √°reas del tratamiento autom√°tico de textos, existen algunas t√©cnicas
para construir relaciones sem√°nticas produciendo vectores de baja dimensionali-
dad. Por ejemplo, el An√°lisis Sem√°ntico Latente (LSA, Latent Semantic Analysis,
por sus siglas en ingl√©s) (Deerwester, 1990) y el An√°lisis Sem√°ntico Explicito
(ESA, Explicit Semantic Analysis, por sus siglas en ingl√©s ) (Gabrilovich y Mar-
kovitch, 2009) que interpretan elementos del texto y sus relaciones en un conjunto
predenido de conceptos. Este tipo de t√©cnicas hacen frente al problema de la
3.4. Otras representaciones y enfoques en AA 33
dimensionalidad, debido a que √©sta es limitada por el n√∫mero de elementos se-
m√°nticos (conceptos). Sin embargo, el problema con estas t√©cnicas es que usual-
mente es necesario interpretar los t√©rminos en un complejo espacio de conceptos
(Zhixing et al., 2010), lo cual resulta en un alto costo computacional; adem√°s, tal
como ya se mencion√≥ estas t√©cnicas fueron pensadas para tareas de recuperaci√≥n
de informaci√≥n o clasicaci√≥n tem√°tica (Zhixing et al., 2010).
Considerando las situaciones anteriores y dado que la representaci√≥n de do-
cumentos es un procedimiento clave; nuestro inter√©s radica en un m√©todo para
llevar a cabo un simple pero efectivo an√°lisis sem√°ntico enfocado en la tarea de
AA. En nuestra propuesta seguimos algunas de las idea del An√°lisis Sem√°ntico
Conciso (CSA, Concise Semantic Analysis (Zhixing et al., 2010), por sus siglas
en ingl√©s), la cual es una t√©cnica independiente del lenguaje dise√±ada para clasi-
caci√≥n tem√°tica que extrae algunos conceptos de las etiquetas de las clases del
corpus. CSA ha sido exitosamente utilizada en clasicaci√≥n tem√°tica (Zhixing et
al., 2010) empleando solamente las palabras como t√©rminos, sin embargo no ha
sido utilizada para la tarea de AA. En nuestra propuesta seguimos algunas de las
ideas de CSA con el objetivo de obtener relaciones entre t√©rminos, documentos
y autores. Sin embargo, se han introducido funciones diferentes para pesar los
vectores de t√©rminos y documentos con el objetivo de favorecer la tarea de AA.
Nuestra idea es conseguir una representaci√≥n especial para AA que ayude a ha-
cer frente a los principales problemas de la representaci√≥n convencional BoT. A
continuaci√≥n presentamos concretamente las desventajas a las que nos referimos:
No preservan ning√∫n tipo de relaci√≥n entre los t√©rminos y las cla-
ses: En este contexto, informaci√≥n valiosa est√° siendo ignorada, principal-
mente porque creemos que, para caracter√≠sticas de estilo, podr√≠a ser √∫til
tomar en cuenta las relaciones entre los autores y sus vocabularios m√°s all√°
34 Cap√≠tulo 3. Trabajo relacionado
de frecuencias de palabras aisladas.
Producen alta dimensionalidad y una alta dispersi√≥n de la infor-
maci√≥n: Ambas afectan la calidad de la representaci√≥n y el rendimiento
de la mayor√≠a de los algoritmos de Aprendizaje Autom√°tico; especialmente
cuando existen vocabularios grandes, pero datos de entrenamiento escasos
y desbalanceados.
En este documento introducimos la Representaci√≥n Documento Autor para
caracterizar documentos, con el objetivo de superar esas desventajas en AA y
ayudar a nuestro m√©todo de combinaci√≥n de atributos con ensambles. Con relaci√≥n
a la primera desventaja de BoT, proponemos utilizar la riqueza l√©xica de los
documentos y relaciones entre los t√©rminos, documentos y autores para mejorar
la representatividad. De esta forma, nos interesamos en las relaciones que los
autores mantienen con sus t√©rminos, para despu√©s denir c√≥mo un documento
est√° relacionado con su autor. En este contexto, a estos atributos de relaciones
les llamaremos atributos de segundo orden, debido a que son calculados a partir
de los atributos que fueron extra√≠dos para BoT. Estos atributos de segundo orden
son pocos, pero tambi√©n son ricos en representatividad; lo cual hace frente a la
segunda desventaja.
Cap√≠tulo 4
M√©todo propuesto
En este cap√≠tulo se presenta un m√©todo alternativo para la representaci√≥n de
textos en AA; la idea principal es obtener un nuevo conjunto de atributos que
relacionan a los documentos con cada autor. Adem√°s, proponemos el uso de la
riqueza del vocabulario; siguiendo la idea de que los autores tienden a escribir sus
documentos con tasas similares de repetici√≥n para sus t√©rminos. Por otro lado,
para probar la idea de que la combinaci√≥n de atributos benecia a la AA se
presenta: i) una combinaci√≥n sencilla de atributos a la que nos referiremos como
Vista General y ii) una combinaci√≥n que los considere por separado a la cual
llamamos Vista Individual. Para la explicaci√≥n de estos m√©todos se inicia por una
descripci√≥n general del m√©todo cuyos elementos espec√≠cos se presentan a trav√©s
de las siguientes secciones.
4.1. Representaci√≥n de atributos
En el Cap√≠tulo 3 ya se ha mencionado que la representaci√≥n BoT es el enfoque
tradicional para representar los documentos en AA. As√≠ tambi√©n se han expuesto
35
36 Cap√≠tulo 4. M√©todo propuesto
sus desventajas tales como su alta dimensionalidad y dispersi√≥n, las cuales dicul-
tan la tarea de los algoritmos de aprendizaje. En este contexto, proponemos el uso
de una nueva representaci√≥n que aborde los principales problemas de BoT y que
ayude en la tarea de AA. Se pretende obtener un nuevo conjunto de atributos (a
los cuales nos referimos como de segundo orden) que puedan ser utilizados por si
solos o en complemento con los atributos de las representaciones convencionales.
4.1.1. Representaci√≥n Documento Autor (RDA)
La Representaci√≥n Documento Autor (RDA) est√° motivada por algunas de las
ideas del An√°lisis Sem√°ntico Conciso (Zhixing et al., 2010), pero transport√°ndolas
al contexto de la AA. En este sentido, hacemos un pesado de los t√©rminos conside-
rando la riqueza del vocabulario y frecuencias de los t√©rminos, lo que nos permite
obtener de manera sencilla un an√°lisis sem√°ntico para AA. La RDA almacena
caracter√≠sticas textuales de los documentos en un vector, donde el problema de la
dimensionalidad est√° limitado por el n√∫mero de autores a clasicar. Para lograr
esto, la RDA es construida en dos pasos; primero se construyen vectores de t√©rmi-
nos en un espacio de autores, y luego se construyen vectores de documentos en un
espacio de autores. Las siguentes dos secciones explican estos pasos con detalle.
Representaci√≥n de los T√©rminos
La representaci√≥n de los t√©rminos es el primer paso para obtener la RDA. Para
esta etapa, es necesario construir una representaci√≥n en el modelo vectorial para
cada t√©rmino. Recuerde que, los t√©rminos son cualquier unidad textual utiliza-
da como caracter√≠stica del documento, por ejemplo: palabras, n-gramas, frases,
puntuaci√≥n, etc.
4.1. Representaci√≥n de atributos 37
La idea principal detr√°s de este primer paso es capturar la relaci√≥n que ca-
da t√©rmino mantiene con cada autor. En otras palabras, la intenci√≥n es calcular
valores que muestren c√≥mo un t√©rmino tj es utilizado por cada autor ai. En este
contexto, sea {t1, . . . , tm} el vocabulario en la colecci√≥n y {a1, . . . , an} el conjunto
de autores a ser identicados. Para cada t√©rmino tj en el vocabulario, construi-
mos un vector tj = „Äàta1j, . . . , tanj„Äâ, donde taij es un valor real que representa la
relaci√≥n del t√©rmino tj con el autor ai. Para calcular taij solo tomamos en cuenta
aquellos documentos que pertenecen al autor ai, es decir obtenemos un valor a
nivel clase. La relaci√≥n de un t√©rmino con un autor toma en cuenta la frecuencia
del t√©rmino en los documentos de ese autor. De esta forma, frecuencias altas de-
notan cierta preferencia por el t√©rmino. La Expresi√≥n 4.1 expresa la idea anterior
calculando un peso relativo.
wij =
‚àë
k:dk‚ààAi
log2
(
1 +
tf kj
len(dk)
)
(4.1)
Donde Ai es el conjunto de documentos que pertenecen al autor ai, tfkj es el
n√∫mero de ocurrencias del t√©rmino tj en el documento dk, y len(dk) es la longitud
del documento dk. El objetivo de la funci√≥n logar√≠tmica en la Expresi√≥n 4.1 es
suavizar las frecuencias altas de los t√©rminos.
Como se puede observar, debido a la sumatoria de estas frecuencias, los pesos
pueden variar demasiado entre los t√©rminos. Por lo tanto, es conveniente aplicar la
normalizaci√≥n de la Expresi√≥n 4.2 para obtener el valor nal de taij. Note que, esta
normalizaci√≥n toma en cuenta los pesos que fueron calculados para otros autores,
consiguiendo que cada peso sea relativo a todos los autores.
38 Cap√≠tulo 4. M√©todo propuesto
taij =
wij‚àë
i=1
wij
(4.2)
De las expresiones anteriores se puede observar que el m√©todo obtiene infor-
maci√≥n a nivel clase. Es decir, a partir de los documentos conocidos de cada
autor. En este sentido, los vectores de t√©rmino se calculan solamente a partir del
conjunto de entrenamiento. De tal forma que al hacer la representaci√≥n para el
conjunto de prueba, se utilizan los vectores de t√©rmino calculados en el conjunto
de entrenamiento.
Representaci√≥n de los Documentos
En el paso previo calculamos los vectores de t√©rminos que representan las
relaciones entre los t√©rminos y los autores. La idea principal en este segundo paso
es construir relaciones entre los documentos y los autores; √©stos son, en cierto modo
nuestros atributos de segundo orden. Estos los calculamos a partir de los vectores
de los t√©rminos contenidos en el documento. Para ello, obtenemos los t√©rminos de
cada documento y sumamos sus vectores. De esta forma, tendremos documentos
representados como dk = „Äàda1k, . . . , dank„Äâ, donde n es el n√∫mero total de autores,
y daik es un valor real que representa la relaci√≥n entre el documento dk con el
autor ai. Cabe se√±alar que, cada vector t√©rmino ~tj antes de ser sumado, es pesado
por la frecuencia del t√©rmino tj en el documento dk, normalizado por la longitud
de dk. Finalmente, con el objetivo de tomar en cuenta la tasa de repetitividad del
contexto, multiplicamos por la riqueza l√©xica del documento dk (ver explicaci√≥n
de la Expresi√≥n 4.4). La Expresi√≥n 4.3 muestra las ideas anteriores.
4.1. Representaci√≥n de atributos 39
~dk = riqueza(dk)
‚àë
tjDk
tfkj
len(dk)
√ó ~tj (4.3)
donde Dk es el conjunto de t√©rminos que pertenecen al documento dk. Adicional-
mente denimos:
riqueza(dk) =
1
repetitividad(dk)
(4.4)
La Expresi√≥n 4.4 intenta capturar mas informaci√≥n acerca de la riqueza l√©xica;
siguiendo la idea de que los autores tienden a mantener tasas de repetitividad
similares de sus t√©rminos a trav√©s de sus documentos. Adem√°s, la riqueza l√©xica nos
permite hacer frente a la siguiente situaci√≥n; documentos con alta riqueza l√©xica
normalmente tienen muchos t√©rminos con frecuencias bajas (esto es relativo a la
longitud del documento). De ello intuimos que, estas bajas frecuencias no reejan
la importancia adecuada de los t√©rminos del autor. Lo anterior se basa en la
hip√≥tesis de que, un autor con documentos l√©xicamente ricos presta m√°s atenci√≥n
en seleccionar sus t√©rminos para transmitir el mensaje; esto quiere decir que a
trav√©s del texto existen t√©rminos muy importantes con una tasa de repetici√≥n
relativamente baja. Por lo tanto, para la relevancia de los t√©rminos, consideramos
la riqueza l√©xica de el documento que los contiene. De esta forma, si el contexto
es rico, entonces los t√©rminos fueron cuidadosamente seleccionados y por lo tanto
su relevancia ser√° mayor aunque su frecuencia sea baja.
Para calcular la repetitividad de un documento necesitamos una medida inde-
pendiente de la longitud del texto. Por esta raz√≥n, hemos utilizado la K de Yule,
calculada tal como sugiere (Miranda-Garc√≠a y Calle-Mart√≠n, 2005). La Expresi√≥n
4.5 muestra c√≥mo la K de Yule es calculada para cada documento:
40 Cap√≠tulo 4. M√©todo propuesto
repetitividad(dk) = 10
4
(
N‚àë
i=1
i2V (i, N)
N2
)
‚àí 1
N
(4.5)
donde la N representa la longitud del documento y V (i, N) es el n√∫mero de
palabras que ocurren i veces en el documento.
Por √∫ltimo, cabe a√±adir que este tipo de representaci√≥n sem√°ntica favorece
a los algoritmos de aprendizaje autom√°tico basados en prototipos (Zhixing et
al., 2010), debido a que produce vectores densos (pr√°cticamente sin ceros) y con
baja dimensionalidad. As√≠ pues, la clasicaci√≥n es llevada a cabo de forma muy
r√°pida comparada con la tradicional BoT. Para realizar la clasicaci√≥n, optamos
por hacerlo buscando el vector m√°s parecido. Por esta raz√≥n, hemos escogido el
algoritmo de 1 vecino m√°s cercano (1NN, 1 Nearest Neighbor, por sus siglas en
ingl√©s) utilizando la distancia Euclideana.
An√°lisis de complejidad de RDA
La construcci√≥n de los vectores de t√©rminos en la Secci√≥n 4.1.1 es una sumatoria
de las frecuencias del t√©rmino en cada documento, con respecto a cada autor. De
esta forma, su complejidad es O(dta) donde d es el n√∫mero de total de documentos,
t es el m√°ximo n√∫mero de t√©rminos diferentes en un documento y a es el n√∫mero
de autores. Para la representaci√≥n de un documento, cada vector de t√©rmino es
sumado. Debido a que cada t√©rmino es representado por a autores, la complejidad
de representar un documento est√° dada por O(at). De esta forma O(dta) es la
complejidad de representar todos los documentos en el conjunto de datos. En
conclusi√≥n, la complejidad total de la representaci√≥n RDA esta dada por O(2dta),
la cual queda como O(dta) d√≥nde por lo regular tendremos que a < 100.
4.2. Enfoques para la identicaci√≥n de autor 41
4.2. Enfoques para la identicaci√≥n de autor
En esta secci√≥n se explican los dos enfoques para llevar a cabo la combina-
ci√≥n de atributos. El primer enfoque es referido como Vista General, en √©ste la
representaci√≥n es un vector por documento utilizando todos los atributos textua-
les que contienen los espacios. El segundo enfoque es el de Vista Individual, en
√©ste se tienen distintas perspectivas (vectores) del documento para cada espacio
de atributos. Las siguientes secciones muestran los detalles espec√≠cos de cada
enfoque.
La idea fundamental es construir distintas perspectivas para un conjunto de
documentos. Es decir, cada instancia se representa utilizando distintos espacios
de atributos (e.g., n-gramas a nivel de caracter, palabras vac√≠as, y signos de pun-
tuaci√≥n). Intuitivamente, se persigue la idea de que al tener m√°s vistas de los
documentos, exista al menos un espacio (o alguna combinaci√≥n de espacios) en el
que la discriminaci√≥n entre autores sea mejor. Por ejemplo, en el conjunto de n-
gramas de caracter, el estilo de un autor a1 podr√≠a ser muy similar al del autor a2,
sin embargo su estilo podr√≠a variar en el espacio de palabras vac√≠as. Las siguientes
secciones muestran dos alternativas para desarrollar las ideas anteriores.
4.3. Espacios de atributos
Para facilitar la explicaci√≥n del resto de este cap√≠tulo, primeramente esta-
blecemos lo que queremos decir con el t√©rmino espacio de atributos. Cuando se
menciona espacio de atributos, nos referimos a un conjunto de tipos de caracter√≠s-
ticas textuales que tienen algo en com√∫n. Por ejemplo, el espacio l√©xico podr√≠a
contener un subconjuntos de palabras vac√≠as, bigramas de palabras y signos de
42 Cap√≠tulo 4. M√©todo propuesto
puntuaci√≥n (comunes porque pertenecen a la misma familia de caracter√≠sticas). La
idea central es utilizar un esquema de distintos espacios en donde internamente,
cada espacio contenga conjuntos de atributos similares entre s√≠, pero distintos con
respecto a los conjuntos de atributos de otros espacios; esto es para seguir la idea
de complementarlos entre s√≠ al representar los documentos.
Para determinar si dos conjuntos de atributos A y B comparten algo o son
similares en cierta forma, proponemos hacerlo sobre la base del Ap√©ndice B, el
cual explica algunos criterios √∫tiles para usar en conjunto dos o m√°s tipos de
atributos. Con estos criterios intentamos beneciar el esquema de clasicaci√≥n, a
trav√©s de espacios de atributos que se complementen entre s√≠.
4.3. Espacios de atributos 43
4.3.1. Enfoque de Vista General
Consiste en representar cada instancia como un solo vector. En este enfoque
los atributos son la uni√≥n de los distintos vocabularios (conjuntos de atributos)
contenidos en cada espacio. La idea principal de este enfoque es comprobar de la
forma m√°s simple que, usar distintos tipos de atributos es mejor que utilizarlos
de forma individual. De esta forma, se cuenta con un solo vector que contiene los
distintos tipos de atributos y se entrena un clasicador. La Figura 4.1 muestra las
ideas anteriores.
Figura 4.1: Enfoque de Vista General.
44 Cap√≠tulo 4. M√©todo propuesto
El Algoritmo 4.1 presenta el enfoque sencillo para construir un clasicador cg
empleando Vista General de atributos. En este enfoque, sea D = {d1, . . . , dk} el
universo de documentos del problema y P(D) el conjunto potencia, considere los
siguientes elementos:
Sea Dm el conjunto de documentos etiquetados disponibles para entrenar,
tal que Dm ‚äÇ D.
El conjunto de distintos vocabularios Am = {V1, . . . , Vn} que se utilizar√°n
para representar Dm.
La funci√≥n constructor de alguna representaci√≥n CDR : P(D)√ó V ‚Üí S. La
cual con CDR
(
Dm,
‚ãÉ
Vj‚ààAm
Vj
)
= Sm, donde Sm es la representaci√≥n corres-
pondiente a los documentos Dm utilizando como atributos los elementos de
los vocabularios de Am.
La funci√≥n constructor de alg√∫n clasicador CDC : S ‚Üí C. La cual con
CDC(Sm) = cm, d√≥nde cm es un clasicador construido a partir de las
instancias Sm.
En el Algoritmo 4.1, la funci√≥n CDR se utiliza para obtener una representaci√≥n
general Sm (l√≠nea 1). Posteriormente, CDC utiliza Sm para obtener un clasicador
cg (l√≠nea 2).
Algoritmo 4.1 Algoritmo simple de Vista General
Entrada: CDC, Vm =
‚ãÉ
Vj‚ààAm
Vj , CDR, Dm
Salida: cg
1: Sm = CDR(Dm, Vm)
2: Construir un clasicador general cg utilizando CDC(Sm).
4.3. Espacios de atributos 45
En este algoritmo, para un conjunto de prueba, las instancias son representadas
de la misma forma que las de entrenamiento y el clasicador cg es el encargado
de predecir la clase.
46 Cap√≠tulo 4. M√©todo propuesto
4.3.2. Enfoque de Vista Individual
Consiste en representar cada instancia como un conjunto de m vectores, donde
cada vector representa una perspectiva del documento en un espacio de atributos
espec√≠co. Posteriormente, se entrena un clasicador por cada vector i, la idea es
que √©ste se especialice en ese tipo de caracter√≠sticas. La Figura 4.2 muestra las
ideas del enfoque individual.
Figura 4.2: Enfoque de Vista Individual.
4.3. Espacios de atributos 47
El Algoritmo 4.2 presenta el enfoque de ensambles considerando Vista Indivi-
dual por tipo de atributo. En este enfoque, sea D = {d1, . . . , dk} el universo de
documentos del problema y P(D) el conjunto potencia, considere los siguientes
elementos:
Sea Dm el conjunto de documentos etiquetados disponibles para entrenar,
tal que Dm ‚äÇ D.
El conjunto de distintos vocabularios Am = {V1, . . . , Vn} que se utilizar√°n
para representar Dm.
Un conjunto de distintos vocabularios Am
‚Ä≤ = {V1‚Ä≤, . . . , Vn‚Ä≤} para incrementar
diversidad, d√≥nde:
‚àÄ(Vi‚Ä≤ ‚àà Am‚Ä≤),‚àÉ(Vi ‚àà Am)
Ô£ÆÔ£∞(|Vi‚Ä≤| = |Vi|)
‚àß
Ô£´Ô£≠Vi‚Ä≤ =
Ô£±Ô£≤Ô£≥(X ‚à™ Y ) : (X ‚äÇ Vi) ‚àß
Ô£´Ô£≠Y ‚äÇ ‚ãÉ
Vj‚àà(Am‚àíVi)
Vj
Ô£∂Ô£∏Ô£ºÔ£ΩÔ£æ
Ô£∂Ô£∏Ô£πÔ£ª (4.6)
La funci√≥n Constructor de Representaci√≥n CDR : P(D) √ó A ‚Üí S. La cual
con CDR(Dm, Vi) = Smi, d√≥nde Smi es la representaci√≥n correspondiente a
los documentos Dm utilizando como atributos los elementos de Vi.
La funci√≥n Constructor de Clasicador CDC : S ‚Üí C. La cual con
CDC(Smi) = cmi, donde cmi es un clasicador construido a partir de las
instancias Smi.
De forma simple, en el Algoritmo 4.2 el CDR se utiliza para obtener dos
representaciones de Dm por cada tipo de atributo i: Smi y Smi
‚Ä≤ (l√≠nea 3 y 4). La
48 Cap√≠tulo 4. M√©todo propuesto
Algoritmo 4.2 Algoritmo Propuesto de Vista Individual
Entrada: CDC, Am,Am‚Ä≤, CDR, Dm
Salida: {cmi, cmi‚Ä≤|i = 1, . . . , n}
1: Para i = 1 hasta n hacer
2: Smi = CDR(Sm, Vi)
3: Smi
‚Ä≤ = CDR(Sm, Vi
‚Ä≤)
4: Construir cmi y cmi‚Ä≤ utilizando CDC(Smi) y CDC(Smi‚Ä≤) respectivamente.
5: i++
6: Fin Para
representaci√≥n Smi es construida con base en el vocabulario Vi. Mientras tanto, la
representaci√≥n Smi
‚Ä≤ es construida utilizando el vocabulario Vi
‚Ä≤. Por √∫ltimo, CMD
construye un clasicador cmi para Smi y otro cmi‚Ä≤ para Smi
‚Ä≤.
Combinaci√≥n de predicciones
Para llevar a cabo la clasicaci√≥n se utiliza un m√©todo de votaci√≥n Condorcet
(vea explicaci√≥n en Secci√≥n 2.2.2). La raz√≥n de utilizar una votaci√≥n Condorcet
radica en la forma de construir los clasicadores en el Algoritmo 4.2. En √©ste se
puede observar que un clasicador cmi es entrenado con las instancias represen-
tadas con el 100% de los atributos del espacio, mientras otro clasicador cmi‚Ä≤ es
entrenado con las instancias representadas solo asegurando un cierto porcentaje
del total de los atributos (60% para nuestros experimentos), y el resto es tomado
aleatoriamente de los otros espacios. Dada esta situaci√≥n tenemos dos clasicado-
res especializados en un espacio de atributos ligeramente distinto. En este sentido,
es m√°s evidente que, en distintas predicciones emitan como candidato favorito al
mismo autor. Dado este contexto, nos interesa no solo el candidato favorito, sino
tambi√©n la forma en que posicion√≥ al resto de los candidatos. Esto tambi√©n es
importante para las instancias que para un cierto espacio suelen confundirse entre
dos o m√°s autores. Principalmente, debido a que es probable que dos clasicadores
4.3. Espacios de atributos 49
emitan como candidato favorito a un cierto autor incorrecto, pero es m√°s dif√≠cil
que se hayan equivocado exactamente en toda una lista de predicciones.
Dada la situaci√≥n anterior, es necesario adaptar al clasicador para propor-
cionar la lista de preferencias, para despu√©s construir la matriz de votaci√≥n. La
adaptaci√≥n depende del clasicador, por ejemplo en un clasicador binario como
SVM bajo un esquema de uno-contra-todos la matriz de voto puede ser obtenida
de forma pr√°cticamente directa (vea matriz Condorcet en Secci√≥n 2.2.2). Sin em-
bargo, en un clasicador multi-clase como Na√Øve Bayes, la matriz de voto se podr√≠a
construir a partir de una lista de autores ordenada en funci√≥n de la probabilidad
de pertenecer a cada clase. Para prop√≥sitos de esta tesis, utilizamos Weka (Hall et
al., 2009), que proporciona la funcionalidad anterior para todos sus clasicadores.

Cap√≠tulo 5
Experimentos y Resultados
En este cap√≠tulo presentamos la evaluaci√≥n de los m√©todos propuestos. La
Secci√≥n 5.1 explica el conjunto de datos utilizado y las pruebas de evaluaci√≥n
que se llevaron a cabo. Posteriormente, en las Secciones 5.2 y 5.3, mostramos
a detalle la evaluaci√≥n para la representaci√≥n RDA y los m√©todos de ensambles
respectivamente.
5.1. Metodolog√≠a experimental
Para evaluar los m√©todos propuestos, hemos utilizado un subconjunto de 10
autores del corpus c50. Los autores utilizados son: Alan Crosby, Alexander Smith,
Benjamin KangLim, David Lawder, Jane Macartney, Jim Gilchrist, Marcel Mi-
chelson, Mure Dickie, Robin Sidel y Todd Nissen. Este subconjunto de autores del
corpus fue originalmente utilizado por Plakias y Stamatatos (2008) en (Plakias y
Stamatatos, 2008). El corpus c50 est√° conformado por textos del Corpus Reuters
Volumen 1 (Lewis et al., 2004). El corpus c50 consta de 50 autores con documentos
que pertenecen a la categor√≠a CCAT (la cual trata noticias acerca de la industria).
51
52 Cap√≠tulo 5. Experimentos y Resultados
Se utiliza la misma categor√≠a en aras de reducir el factor tem√°tico, y centrar la
evaluaci√≥n en AA. Por √∫ltimo, cada autor tiene 50 documentos para entrenar y
50 documentos para probar.
Los experimentos que se han realizado son similares a los reportados en (Plakias
y Stamatatos, 2008). Primeramente y con el prop√≥sito de simular escenarios realis-
tas (Stamatatos, 2009), hemos construido diferentes conjuntos de entrenamiento.
Tres de ellos est√°n balanceados, tomando aleatoriamente 50, 20 y 10 documen-
tos de entrenamiento por autor, y los otros tres est√°n desbalanceados tomando
aleatoriamente 2:10, 5:10 y 10:20 (donde a : b signica, m√≠nimo a y m√°ximo b
documentos por autor). De este modo, el desempe√±o de cada m√©todo es medido
por la exactitud en la clasicaci√≥n en todo el conjunto de prueba.
La representaci√≥n RDA y los algoritmos de ensambles fueron construidos tal
como se describe en el Cap√≠tulo 5. Adem√°s, cada experimento es el promedio
de diez corridas, con el objetivo de tener sucientes datos para llevar a cabo
pruebas estad√≠sticas. Con respecto a esto √∫ltimo, hemos aplicado la prueba de
los signos de Wilcoxon para cada resultado, obteniendo un 95% de conanza
estad√≠stica para los resultados de nuestros experimentos. En nuestras pruebas
denotamos en negritas los resultados signicativamente mejores. Cabe a√±adir que
se han seleccionado los experimentos m√°s relevantes que muestran las propiedades
interesantes de los m√©todos propuestos. No obstante, en el Ap√©ndice D est√°n
algunos otros experimentos que contribuyeron con la investigaci√≥n.
5.2. Evaluaci√≥n de la Representaci√≥n Documento Autor 53
5.2. Evaluaci√≥n de la Representaci√≥n Documento
Autor
Para la evaluaci√≥n de RDA se han llevado a cabo tres diferentes experimentos
mostrados en la Secci√≥n 5.2.1. En el primero y en el segundo comparamos RDA
contra BoT, el cual es un enfoque tradicional. Para ello utilizamos dos de los
tipos de t√©rminos m√°s efectivos en AA; palabras y n-gramas a nivel de caracter
(Stamatatos, 2009). Cabe a√±adir que tambi√©n comparamos RDA contra el Modelo
de Espacio de Tensores (MET) (Plakias y Stamatatos, 2008), el cual ha sido
evaluado utilizando el corpus c50. Por √∫ltimo, en el tercer experimento RDA es
construido basado en una simple selecci√≥n de atributos, para conseguir mejores
resultados. En resumen, comparamos RDA contra los siguientes m√©todos:
Bolsa de T√©rminos (utilizando palabras y n-gramas de caracteres) clasi-
cando con SVM y 1NN. Hemos utilizado SVM debido a que se ha mostrado
que es efectivo para AA (Pavelec et al., 2008) (Plakias y Stamatatos, 2008).
Tambi√©n utilizamos 1NN debido a que nos permite mostrar c√≥mo mejora su
rendimiento cuando RDA es utilizado (ver argumento al nal de la Secci√≥n
4.1.1).
Modelo de Espacio de Tensores (utilizando n-gramas de caracteres), clasi-
cando con M√°quinas de Tensores de Soporte (MTS) (Plakias y Stamatatos,
2008). Nos comparamos contra este m√©todo por dos razones. La primera es
que es un m√©todo que se centra en evaluar c√≥mo la sola representaci√≥n de
tensores benecia la AA. La segunda raz√≥n es que la evaluaci√≥n la tiene bien
establecida desde trabajos anteriores (Stamatatos, 2008) que se enfocan en
el desbalance de los datos.
54 Cap√≠tulo 5. Experimentos y Resultados
5.2.1. Experimentos
Experimento 1. RDA utilizando palabras
La Tabla 5.1 muestra los resultados del primer experimento utilizando 2500
palabras, truncadas con el algoritmo de M. F. Porter (Porter, 1980) (e.g., playing,
played, plays son tomadas como play). Es importante mencionar que las palabras
vac√≠as se mantienen, con la idea de capturar informaci√≥n de estilo acerca de c√≥mo
los autores las distribuyen en sus documentos. Se puede observar que RDA su-
pera la representaci√≥n BoT cuando los datos est√°n desbalanceados (un escenario
realista). Creemos que esto es gracias a las relaciones capturadas en RDA, las
cuales est√°n representando a los documentos desde una perspectiva m√°s all√° de
las palabras independientes.
Instancias por autor
Modelo Balanceado Desbalanceado
50 10 5 10:20 5:10 2:10
BoT - SVM 79.6 71.6 65.8 55.2 56.4 42.8
RDA - SVM 70.0 62.3 57.7 61.2 59.6 46.1
BoT - 1NN 37.0 49.6 36.6 30.8 39.4 34.2
RDA - 1NN 70.8 65.5 61.1 66.2 62.0 53.3
Tabla 5.1: RDA contra SVM utilizando las 2500 palabras m√°s frecuentes.
Experimento 2. RDA utilizando n-gramas a nivel de caracter
La Tabla 5.2 muestra los resultados del segundo experimento, en este experi-
mento comparamos BoT y RDA utilizando los 2500 3-gramas m√°s frecuentes a
5.2. Evaluaci√≥n de la Representaci√≥n Documento Autor 55
nivel de caracter. Adem√°s, comparamos RDA contra MTS utilizando la misma
metodolog√≠a que los autores de (Plakias y Stamatatos, 2008) siguieron en sus ex-
perimentos (igual desbalance de datos y mismo tipo y cantidad de t√©rminos); por
ello, podemos decir que los resultados son directamente comparables.
Los resultados en Tabla 5.2 muestran como RDA supera a BoT en la mayo-
r√≠a de los conjuntos de datos desbalanceados. Tambi√©n puede observarse que al
utilizar 3-gramas se mejora la exactitud respecto al experimento anterior, esto es
debido a que los 3-gramas de caracter son caracter√≠sticas que pueden retener m√°s
informaci√≥n de estilo. Este experimento tambi√©n nos permite mostrar que en la
mayor√≠a de los conjuntos de datos, RDA (especialmente RDA-1NN) es mejor que
BoT-SVM y MET-MTS cuando se ejecutan bajo las mismas condiciones.
Instancias por autor
Modelo Balanceado Desbalanceado
50 10 5 10:20 5:10 2:10
BoT - SVM 80.8 64.4 48.8 64.2 62.4 51.0
RDA - SVM 72.1 63.1 56.6 62.1 63.9 53.2
BoT - 1NN 36.4 50.3 38.6 33.8 41.4 36.2
RDA - 1NN 76.0 67.3 62.7 66.9 65.6 55.1
MET - MTS 78.0 67.8 53.4 63.0 62.6 50.0
Tabla 5.2: Se compara RDA contra BoT y MET utilizando los 2500 3-gramas m√°s
frecuentes.
56 Cap√≠tulo 5. Experimentos y Resultados
Experimento 3. RDA utilizando un umbral de frecuencia
Las Figuras 5.1 y 5.2 muestran los resultados del tercer experimento, as√≠ como
una propiedad interesante de RDA; la cantidad de t√©rminos con la que se cons-
truye. En este experimento podemos observar que RDA puede ser mejorada con
una sencilla selecci√≥n de atributos.
En estos experimentos seleccionamos aquellos atributos con frecuencia igual
o mayor que 3, 5, 7 y 10, en el conjunto de entrenamiento de cada experimento.
La idea principal es explorar el comportamiento de RDA cuando se incrementa
o se reduce la cantidad de t√©rminos, con el objetivo de mejorar la calidad de la
representaci√≥n. La Figura 5.1 y 5.2 muestra qu√© RDA puede ser notablemente
mejorada por esta simple selecci√≥n. En general, la mejor conguraci√≥n de RDA
fue con un umbral de frecuencia de 5.
Figura 5.1: RDA con diferentes umbrales de frecuencia en los datos balanceados. Cada
barra representa la exactitud de un experimento y una conguraci√≥n.
5.2. Evaluaci√≥n de la Representaci√≥n Documento Autor 57
Figura 5.2: RDA con diferentes umbrales de frecuencia en los datos desbalanceados.
Cada barra representa la exactitud de un experimento y una conguraci√≥n.
5.2.2. Discusi√≥n de los resultados
Estos resultados muestran el buen desempe√±o de nuestra propuesta. Note que,
especialmente cuando el corpus est√° desbalanceado o con pocos datos de entre-
namiento, RDA supera a los dem√°s m√©todos. Tambi√©n se ha mostrado que RDA
proporciona un mejor rendimiento que los enfoques tradicionales y la represen-
taci√≥n MET, cuyos resultados est√°n reportados en el estado del arte. Tambi√©n,
analizando las Tablas 5.1 y 5.2 podemos observar como BoT reduce sus tasas de
exactitud cuando los datos son escasos o cuando las clases son desbalanceadas;
por otro lado, RDA parece ser menos sensible a conjuntos de datos peque√±os y
desbalanceados. Adem√°s, en contraste con un n√∫mero jo de t√©rminos para los ex-
perimentos, hemos mostrado como denir un umbral de frecuencia puede mejorar
notablemente el rendimiento de RDA.
58 Cap√≠tulo 5. Experimentos y Resultados
5.3. Evaluaci√≥n del m√©todo de ensambles
En esta Secci√≥n presentamos una serie de experimentos utilizando la represen-
taci√≥n y los m√©todos de ensambles propuestos. Esto con el objetivo de mostrar
que la combinaci√≥n de distintos tipos de atributos es mejor que utilizarlos de ma-
nera individual. Para ello consideramos los espacios de atributos denidos en la
Secci√≥n 5.3.1, y los utilizamos en los experimentos de la Secci√≥n 5.3.2 ; adem√°s, al
igual que en la secci√≥n anterior, realizamos experimentos con 2500 atributos para
cada espacio, primero de forma individual, y luego de forma conjunta mediante
los algoritmos propuestos.
La Secci√≥n 5.3.2 presenta tres experimentos para evaluar los m√©todos de en-
sambles. En el primer experimento, se utilizan los algoritmos propuestos utilizando
como base una representaci√≥n de atributos convencional (BoT); esto para probar
la idea de la combinaci√≥n de atributos en la forma m√°s simple y tradicional. En el
segundo experimento, probamos los m√©todos utilizando la representaci√≥n propues-
ta RDA; para apreciar el desempe√±o cuando se proporciona ayuda en la parte de
la representaci√≥n. Por √∫ltimo, el tercer experimento muestra la integraci√≥n de la
representaci√≥n BoT y RDA; con el objetivo de proporcionarle a cada instancia dos
tipos de perspectivas por atributo (una convencional y una de segundo orden).
5.3.1. Espacios de atributos utilizados
Motivados por el primer criterio del Ap√©ndice B proponemos el uso conjunto
de cuatro distintos espacios de atributos: palabras, n-gramas a nivel de car√°cter,
n-gramas a nivel de palabra, y estilo. Cabe mencionar que debido a su efectividad,
los 3-gramas y las palabras son muy utilizados individualmente en trabajos de la
literatura (Stamatatos y Widmer, 2005; Rokach, 2009; de Vel et al., 2001). Es por
5.3. Evaluaci√≥n del m√©todo de ensambles 59
ello que tambi√©n los hemos incluido dentro de los espacios, para complementarlos
con otros tipos de atributos y mejorar la clasicaci√≥n.
Cada uno de los espacios utilizados est√° constituido por los Œ≤ elementos m√°s
frecuentes en los datos de entrenamiento. Lo √∫ltimo, para seguir la idea de que, en-
tre m√°s frecuente un elemento m√°s variaci√≥n de estilo puede capturar (Stamatatos,
2009). Cabe se√±alar que la mayor√≠a de estos tipos de atributos no requieren de
herramientas cr√≠ticamente dependientes del lenguaje. En consecuencia, los atribu-
tos se extraen f√°cilmente para muchos tipos de documentos, dominios y lenguajes
(salvo algunas excepciones como el Chino).
A continuaci√≥n se presenta cada uno de los espacios utilizados, y los conjuntos
de atributos que consideran (para una descripci√≥n a detalle vea el Ap√©ndice A):
Espacios de caracter√≠sticas textuales utilizados
Espacio Conjuntos de atributos que incluye
Palabras
palabras, contracciones, abreviaturas, y palabras compuestas a
trav√©s de guiones.
n-gramas nivel de
caracter
3-gramas y 5-gramas
n-gramas nivel de
palabra
2-gramas y 3-gramas considerando al texto como una secuencia
de: palabras, contracciones, abreviaturas, y palabras compues-
tas a trav√©s de guiones.
Estilo
Signos de puntuaci√≥n, longitud de palabras, colocaciones, pala-
bras con m√°s de una etiqueta POS y longitud de las oraciones
seg√∫n la cantidad de: elementos l√©xicos, palabras vac√≠as, pala-
bras no vac√≠as y puntuaci√≥n.
Tabla 5.3: Principales espacios de atributos considerados, cada uno conteniendo los
Œ≤ = 2500 t√©rminos m√°s frecuentes
60 Cap√≠tulo 5. Experimentos y Resultados
Tenga en cuenta que para elegir los atributos de cada espacio, adem√°s del
criterio 1 se utiliz√≥ el criterio 3 (ver Ap√©ndice B). Por ejemplo, para determi-
nar los atributos del espacio de n-gramas de caracter se realizaron pruebas con
n = 1...15. Con esto, se tomaron decisiones tales como: no usar 4-gramas debido
a que discriminan de forma muy similar a los 3-gramas, o no usar 10-gramas por
que ya no aportan informaci√≥n relevante.
5.3.2. Experimentos
Experimento 1. M√©todo utilizando BoT
La Tabla 5.4 muestra los resultados del primer experimento, en √©ste nuestro
objetivo es observar una situaci√≥n particular; explorar si utilizar conjuntamente
espacios de atributos ayuda en la identicaci√≥n de autor. De la Tabla 5.4 se puede
observar que los algoritmos propuestos obtienen resultados superiores en casi todos
los casos.
El experimento Vista-General-1 utiliza como vocabulario los 2500 elementos
m√°s frecuentes por espacio. Este muestra resultados superiores a utilizar cualquier
espacio de atributos de forma individual, aun cuando la dimensionalidad y la
dispersi√≥n en la representaci√≥n son mayores.
En el experimento de Vista-General-2 se emplea como vocabulario los 625 ele-
mentos m√°s frecuentes por espacio (un total de 2500 atributos). Esto para evaluar
utilizando vectores con la misma dimesionalidad que los utilizados por los otros
espacios individuales. Note que, no se utiliza ning√∫n algoritmo de selecci√≥n de
caracter√≠sticas debido a lo expuesto en la Secci√≥n 3.2. Cabe a√±adir que, seleccio-
nar los N atributos m√°s frecuentes no signica seleccionar a los mejores, o que
todos est√©n capturando el estilo (Stamatatos, 2009). Por lo tanto, el enfoque de
5.3. Evaluaci√≥n del m√©todo de ensambles 61
Vista-General-2 con un vocabulario de 2500 elementos, muestra que una combi-
naci√≥n simple de los espacios de atributos es mejor que utilizar cada uno de forma
individual.
El experimento de Vista-Individual muestra tambi√©n mejora notable con res-
pecto a utilizar cualquier espacio de atributos de forma individual. √âste esperi-
mento utiliza como vocabulario los 2500 t√©rminos m√°s frecuentes por espacio. Sin
embargo, el entrenar un clasicador para cada espacio de atributos ayuda a reducir
el problema de la dimensionalidad. Adem√°s, pensamos que este experimento sigue
obteniendo buenos resultados debido a que la mayor√≠a de sus clasicadores son
competitivos entre s√≠ y cuentan con diversidad en sus predicciones individuales,
lo cual mejora la predicci√≥n conjunta.
Experimentos con diferentes atributos
Modelo Balanceado Desbalanceado
50 10 5 10:20 5:10 2:10
Exp 1. Usando SVM a 10 iteraciones
Palabras 78.2 69.1 63.2 68.0 64.0 48.0
n-gramas de caracter 78.3 69.1 62.0 68.3 62.1 49.0
n-gramas de palabra 77.1 69.3 61.1 68.2 64.1 50.4
Estilo 47.2 34.1 27.2 36.4 32.5 30.1
Vista-General-1 81.2 71.3 64.3 72.1 66.2 50.3
Vista-General-2 80.8 71.1 63.9 72.2 66.8 52.1
Vista-Individual 83.1 73.2 67.4 73.1 67.2 53.3
Tabla 5.4: Utilizaci√≥n individual y conjunta de atributos utilizando BoT como repre-
sentaci√≥n base.
62 Cap√≠tulo 5. Experimentos y Resultados
Experimento 2. M√©todo utilizando RDA
La Tabla 5.5 muestra los resultados del segundo experimento. En este experi-
mento se explora la combinaci√≥n de espacios de atributos representados con RDA.
Experimentos con diferentes atributos
Modelo Balanceado Desbalanceado
50 10 5 10:20 5:10 2:10
Exp 2. Usando 1NN a 10 iteraciones
Palabras 76.0 70.1 65.7 69.6 65.9 54.8
n-gramas de caracter 76.0 67.3 62.7 69.0 65.6 55.1
n-grams de palabra 74.0 69.1 59.4 68.0 65.0 52.0
Estilo 51.6 42.1 36.7 41.8 37.6 34.8
Vista-General 75.8 66.2 56.6 69.0 58.9 50.7
Vista-Individual 78.0 72.0 66.9 73.4 68.0 56.1
Tabla 5.5: Utilizaci√≥n individual y conjunta de atributos utilizando RDA como repre-
sentaci√≥n base.
De la Tabla 5.5 se puede observar que para el algoritmo de Vista-General los
resultados no son estad√≠sticamente superiores que utilizar individualmente cada
uno de los espacios. Esto es debido a que en RDA los vectores, que representan
la relaci√≥n de t√©rminos con autores, son construidos bajo un espacio de atributos
espec√≠co. Es decir, estos vectores utilizan informaci√≥n a nivel clase (ver ecuaci√≥n
4.1 de la Secci√≥n 4.1.1), para luego ser normalizados con respecto a los dem√°s
atributos (ver ecuaci√≥n 4.2 de la Secci√≥n 4.1.1). Por lo tanto, los vectores RDA
ya vienen muy concretos para un espacio espec√≠co, con escalas de valores muy
diferentes de un espacio a otro. Adem√°s, la representaci√≥n RDA comprime la
5.3. Evaluaci√≥n del m√©todo de ensambles 63
informaci√≥n de miles de atributos textuales en unos pocos atributos de relaci√≥n, en
este sentido una vez que son obtenidos, son muy sensibles a cualquier manipulaci√≥n
que se les aplique (e.g., normalizaciones), perjudicando la clasicaci√≥n.
Por otro lado, en el experimento anterior el algoritmo Vista-General funcion√≥
con BoT debido a que no existe ninguna compresi√≥n de atributos, es decir los
valores de cada atributo est√°n expl√≠citos. Si bien es cierto que tambi√©n algunos
atributos est√°n fuera de escala, cada uno representa una y solo una caracter√≠stica
textual.
En cuanto al experimento de Vista-Individual, √©ste mantiene un buen desem-
pe√±o frente a la utilizaci√≥n individual de cada espacio de atributos. Esto es debido
a que las representaciones RDA no son mezcladas para un mismo clasicador. Sino
m√°s bien tenemos un clasicador especializado en cada espacio representado por
RDA. Esto evita problemas de escala en los valores de un espacio a otro, y cada
clasicador puede enfocarse mejor en su problema.
Experimento 3. M√©todo utilizando BoT + RDA
La Tabla 5.6 muestra los resultados del tercer experimento, en el que se utiliza
una combinaci√≥n de ambas representaciones: BoT y RDA. El objetivo es explorar
si proporcionarle a cada documento perspectivas de atributos espec√≠cos (BoT)
y atributos de relaciones (RDA) ayuda en la identicaci√≥n de autores. A partir
de la Tabla 5.6 podemos observar que ambos enfoques de combinaci√≥n ayudan
en la identicaci√≥n de autor. En particular el algoritmo de Vista-Individual ob-
tiene resultados mejores que utilizar individualmente cada espacio. Parte de la
explicaci√≥n es similar a la del Experimento 2 (clasicadores especializados). Sin
embargo, en este caso la inclusi√≥n de la representaci√≥n BoT benecio a√∫n m√°s.
Esto es debido a que, utilizar BoT y RDA incrementa la diversidad al tener los
64 Cap√≠tulo 5. Experimentos y Resultados
espacios representados de distinta forma, y adem√°s se mejora la diversidad de
opini√≥n al incrementar el n√∫mero de clasicadores totales.
Experimentos con diferentes atributos
Modelo Balanceado Desbalanceado
50 10 5 10:20 5:10 2:10
Exp 3. Usando SVM-1NN a 10 iteraciones
Palabras 78.6 68.6 62.8 70.9 63.0 49.4
n-gramas de caracter 78.8 69.0 63.8 70.2 61.9 48.3
n-gramas de palabra 77.2 68.7 62.6 71.5 63.4 51.0
Estilo 47.6 36.9 32.2 38.6 34.4 30.8
Vista-General 81.6 72.0 65.9 72.2 66.3 53.9
Vista-Individual 83.4 72.9 67.6 72.9 68.5 56.6
Tabla 5.6: Utilizaci√≥n individual y conjunta de atributos utilizando BoT y RDA como
representaci√≥n base.
5.3.3. Discusi√≥n de los resultados
La Tabla 5.7 muestra los resultados de los enfoques utilizados para la combi-
naci√≥n de atributos. En √©sta se puede apreciar que en general combinar atributos
benecia a la AA. No obstante, con respecto a la exactitud, los enfoques propues-
tos para combinarlos siguen una tendencia similar que su representaci√≥n base. Es
decir, con una representaci√≥n BoT tiene buen rendimiento sobre datos balancea-
dos. Mientras que con una representaci√≥n RDA se consigue mejorar al tener datos
desbalanceados. En este contexto, el experimento BoT +RDA obtiene resultados
5.4. Consideraciones adicionales 65
que muestran que combinar ambas representaciones es mejor que utilizarlas indi-
vidualmente; no en el sentido de obtener resultados superiores, sino en el sentido
de conseguir un m√©todo que logra juntar las buenas propiedades de cada represen-
taci√≥n y no es muy afectado por las malas. Es decir, un m√©todo con un desempe√±o
similar a BoT en la parte balanceada, y similar a RDA en la parte desbalanceada.
Por √∫ltimo, concluimos que se incrementa la exactitud en BoT + RDA debido a
que la diversidad en el Ensamble 4.2 se incrementa con la manipulaci√≥n de m√°s
espacios de atributos y m√°s votos de los clasicadores.
Experimentos con diferentes atributos
Representaci√≥n Modelo Balanceado Desbalanceado
50 10 5 10:20 5:10 2:10
Vista-General 81.2 71.3 64.3 72.1 66.2 50.3
BoT Vista-General-2 80.8 71.1 63.9 72.2 66.8 52.1
Vista-Individual 83.1 73.2 67.4 73.1 67.2 53.3
RDA Vista-General 75.8 66.2 56.6 69.0 58.9 50.7
Vista-Individual 78.0 72.0 66.9 73.4 68.0 56.1
BoT + RDA Vista-General 81.6 72.0 65.9 72.2 66.3 53.9
Vista-Individual 83.4 72.9 67.6 72.9 68.5 56.6
Tabla 5.7: Resultados generales.
5.4. Consideraciones adicionales
Durante la evaluaci√≥n encontramos que es posible congurar par√°metros de
cada representaci√≥n y cada sistema de clasicaci√≥n para producir mejores resul-
66 Cap√≠tulo 5. Experimentos y Resultados
tados. Sin embargo, en aras de probar y exponer claramente las ideas presentadas
en esta tesis decidimos utilizar un conjunto de par√°metros jos para construir las
representaciones y clasicadores. Con esto logramos i) evitar presentar resultados
demasiado sobreajustados a los datos, y ii) mantener tan simple como sea posible,
un sistema ya de por si complejo.
En esta tesis comparamos RDA contra la representaci√≥n MET del trabajo
(Plakias y Stamatatos, 2008). Se utiliz√≥ a MET y solo el corpus c50 como referencia
debido a que, la forma de evaluarse en AA se tiene bien denida desde trabajos
anteriores (Stamatatos, 2008). Posterioremente, probamos dos alternativas para
explorar la idea de la combinaci√≥n de atributos; esto es, evaluando espacios de
forma individual y conjunta.
Existe otro trabajo en AA (Escalante et al., 2011), el cual se eval√∫a sobre el
mismo corpus. Con respecto a este trabajo, algunos de nuestros resultados llegan
a ser similares (ver Tabla 5.8). No obstante, no lo consideramos como referencia en
nuestras tablas anteriores debido a dos inconvenientes: i) su alto coste computacio-
nal y la falta pruebas estad√≠sticas que respalden los resultados, y ii) para alcanzar
buenos resultados el trabajo ajusta una serie de par√°metros dependientes de su
sistema (Lebanon et al., 2007). Con respecto al punto (i), obtener las corridas ne-
cesarias es uno de los problemas m√°s importantes, ya que una ejecuci√≥n requiere
de varias horas y considerables recursos computacionales. Lo anterior, implica que
para tener el promedio de 10 corridas con palabras y 10 corridas con n-gramas
en cada conjunto de entrenamiento, se necesita programar una plataforma para
ejecutar consecutivamente varias instancias del m√©todo de Escalante et al. (2011),
adem√°s de meses de experimentaci√≥n con dicha plataforma. En este contexto, rea-
lizar los experimentos para compararnos directamente est√° fuera de los alcances
de esta tesis. Con respecto al punto (ii), se necesitan experimentos adicionales
5.4. Consideraciones adicionales 67
dedicados solo a explorar los par√°metros de BoT + RDA para encontrar ajus-
tes √≥ptimos de: umbrales de frecuencia para cada representaci√≥n, par√°metros de
clasicadores con distintos kernels para SVM, y distintos valores de k para el algo-
ritmo kNN. En este sentido, pensamos que esto sobre ajustar√≠a demasiado nuestro
m√©todo a los datos (distanci√°ndonos del objetivo de la tesis). Es por ello que nos
parece m√°s interesante explorar el benecio de utilizar RDA como representaci√≥n
base del m√©todo de (Escalante et al., 2011), lo cual es considerado a realizarse
para trabajo futuro.
Experimentos con diferentes atributos
Representaci√≥n Modelo Balanceado Desbalanceado
50 10 5 10:20 5:10 2:10
Exp 3. Usando SVM (1 corrida)
LOWBOW Palabras 82.0 72.8 69.2 74.1 70.7 66.6
(Escalante et al., 2011) n-gramas 86.4 82.2 80.6 82.2 80.5 77.8
Exp 3. Usando nuestros ensambles (1 corrida)
BoT + RDA Vista-General 87.6 81.7 75.9 78.2 75.8 70.9
Vista-Individual 87.2 78.9 79.1 73.4 78.3 74.1
Tabla 5.8: Resultados sin pruebas de signicancia estad√≠stica de BoT+RDA contra los
resultados reportados para LOWBOW

Cap√≠tulo 6
Conclusiones y trabajo futuro
En la tarea de AA la selecci√≥n de los atributos de estilo y la representaci√≥n de
los documentos son dos procedimientos fundamentales que inuyen en el desarro-
llo y desempe√±o de los m√©todos. Sin embargo, la tarea de seleccionar y representar
los atributos no ha sido una tarea sencilla. En este sentido, diversas soluciones se
han planteado, una de las m√°s comunes es la utilizacion de los N t√©rminos m√°s
frecuentes. En cuanto a la representaci√≥n, la mayor√≠a utiliza BoT (o variantes),
para despu√©s clasicar con SVM. Algunos otros, van m√°s all√° de la BoT y utilizan
representaciones para capturar relaciones entre los t√©rminos (Plakias y Stamata-
tos, 2008). Dado este contexto, en esta tesis presentamos una soluci√≥n alternativa
al problema de la AA.
En este Cap√≠tulo se expone un resumen de las ideas presentadas, las con-
clusiones obtenidas, las principales aportaciones, y algunas ideas que pudieran
desarrollarse en el trabajo futuro.
69
70 Cap√≠tulo 6. Conclusiones y trabajo futuro
6.1. Conclusiones
En la presente tesis se desarroll√≥ una investigaci√≥n para AA en la que destaca
lo siguiente: la representaci√≥n RDA, la combinaci√≥n de distintos tipos de atributos
y su integraci√≥n en un sistema de clasicaci√≥n.
En cuanto a la representaci√≥n RDA, hemos explorado una nueva alternativa
para caracterizar documentos en AA. √âsta representa a los documentos con un
vector de atributos de segundo orden, para determinar c√≥mo un texto est√° relacio-
nado con los autores bajo un cierto espacio de caracter√≠sticas textuales. Al menos
en lo que conocemos, √©sta es la primera vez que una t√©cnica similar a RDA es ex-
plorada para la tarea de AA. En este sentido, encontramos que representaciones
como RDA pueden conservar informaci√≥n relevante para AA. Esto ayuda a man-
tener buenas tasas de clasicaci√≥n, incluso cuando el corpus est√° desbalanceado,
lo cual es un escenario realista. Pensamos que esto es debido a que, las relaciones
entre t√©rminos, autores y la riqueza del vocabulario del contexto, logra preservar el
estilo de escritura en la representaci√≥n nal. Tambi√©n reportamos mejores resulta-
dos que los enfoques convencionales en datos desbalanceados, as√≠ como resultados
superiores contra el m√©todo MTS (Plakias y Stamatatos, 2008). De esta forma, he-
mos demostrado la alta calidad que RDA puede conseguir en la representaci√≥n de
los documentos. Con todo ello, concluimos que RDA es una representaci√≥n factible
y afectada en menor medida por el desbalance de los datos. Adem√°s, RDA puede
ser utilizada en AA para descubrir un nuevo conjunto de atributos (atributos de
segundo orden) que representan relaciones entre documentos y autores.
En cuanto a los espacios de atributos, utilizamos algunos que han sido emplea-
dos individualmente (e.g., 3-gramas de caracter y palabras). Adem√°s, denimos
otro espacio de atributos de estilo, d√≥nde incluimos algunos atributos cl√°sicos
6.1. Conclusiones 71
(e.g., longitud de las palabras) y denimos algunos otros tales como medir la lon-
gitud de las oraciones bas√°ndose en diferentes criterios (e.g., signos de puntuaci√≥n,
palabras vac√≠as, etc.). Para integrar esto en un sistema identicaci√≥n de autores,
construimos representaciones de documentos que consideren los distintos tipos
de atributos. En cuanto a la representaci√≥n de los documentos utilizamos BoT y
RDA, individual y conjuntamente. Posteriormente, para probar la mejora en la
identicaci√≥n presentamos dos alternativas. La primera es Vista-General, la cual
consiste en mezclar los vocabularios de los espacios para construir una represen-
taci√≥n sencilla. La segunda alternativa es Vista-Individual, √©sta tiene la idea de
construir un ensamble con un clasicador para cada espacio de atributos. Presen-
tamos experimentos con ambos enfoques y encontramos que en general combinar
los espacios de atributos adecuados ayuda en la AA. Pensamos que esto se debe
principalmente a que las diferentes perspectivas de los documentos y clasicadores
especializados logran capturar con m√°s detalle el estilo de los documentos de los
autores.
En conclusi√≥n, hemos estudiado una representaci√≥n exitosa para AA que tiene
el potencial de ser utilizada en diferentes maneras, especialmente porque produce
atributos con un alto nivel de representatividad en vectores densos con baja di-
mensionalidad y un bajo coste computacional. Tambi√©n encontramos que ir m√°s
all√° de la sola selecci√≥n de n-gramas de caracter y palabras benecia la AA, ya
que se pueden conseguir conjuntos de atributos que se complementen entre s√≠.
De esta forma, los documentos pueden ser discriminados en uno o m√°s espacios
de atributos. Adem√°s, incrementar los espacios de atributos, las representaciones
utilizadas y el n√∫mero de clasicadores, benecia la diversidad en el aprendizaje
y la votaci√≥n de los ensambles.
72 Cap√≠tulo 6. Conclusiones y trabajo futuro
6.2. Trabajo futuro
A continuaci√≥n se plantean las siguientes ideas como trabajo futuro, con el
n de que se pueda continuar investigando aspectos relacionados con la presente
tesis.
Explorar la utilizaci√≥n de RDA como representaci√≥n base de otros m√©todos
de clasicaci√≥n de AA. As√≠ como probar los atributos construidos por RDA
en conjunto con otras representaciones del estado del arte.
Explorar el uso de RDA y los m√©todos de combinaci√≥n de atributos bajo
otras condiciones; por ejemplo, evaluar RDA incrementando el n√∫mero de
autores, utilizando documentos de distintas longitudes (e.g., con documentos
cortos), o en dominios distintos (e.g., AA en blogs, foros, etc.)
Explorar el uso de estos atributos de segundo orden en la AA crossling√ºe. En
este contexto, ser√≠a interesante estudiar si la RDA produce vectores similares
para los documentos pertenecientes a un mismo autor en distintos idiomas.
Ap√©ndices
73

Ap√©ndice A
Espacios de atributos
A continuaci√≥n se presentan los espacios de atributos utilizados para la cons-
trucci√≥n de los ensambles de clasicadores. En la siguiente lista, el * indica que el
atributo puede ser extra√≠do f√°cilmente en textos de distintos idiomas.
1. Conjunto de palabras*: palabras, contracciones, abreviaturas, y palabras
compuestas a trav√©s de guiones
2. n-gramas nivel de caracter*: 3-gramas y 5-gramas
3. n-gramas nivel de palabra*: bi-gramas y tri-gramas
4. Atributos de estilo:
Signos de puntuaci√≥n*
Longitud de palabras*: consiste en extraer como atributos etique-
tas que representen la longitud de las palabras. Por ejemplo, el texto
La investigaci√≥n es muy divertida!!, produce la cadena token_len{2}
token_len{13} token_len{2} token_len{3} token_len{9}.
Longitud de oraciones: consiste en extraer etiquetas que representen
la longitud de las oraciones. En donde para cada oraci√≥n se extrae su
longitud en t√©rminos de cada uno de los siguientes elementos:
75
76 Ap√©ndice A. Espacios de atributos
‚Ä¢ elementos l√©xicos*: palabras, puntuaci√≥n, o abreviaturas.
‚Ä¢ palabras vac√≠as*: art√≠culos, preposiciones, adverbios, etc.
‚Ä¢ palabras no vac√≠as
‚Ä¢ puntuaci√≥n*: puntos, comas, signos de interrogaci√≥n, comillas,
etc.
Colocaciones de (Bigramas y Trigramas)*: consiste en extraer
pares y tercias de colocaciones utilizando como elemento base cada
uno de los siguientes atributos.
‚Ä¢ palabras*
‚Ä¢ palabras vac√≠as*
‚Ä¢ puntuaci√≥n*
Palabras con m√°s de una etiqueta POS: todas aquellas palabras
que pueden ser utilizadas en m√°s de una forma al escribir. Por ejemplo,
la palabra en ingl√©s lay puede ser utilizada al menos como adjetivo, o
verbo.
Ap√©ndice B
Criterios para formar espacios de
atributos
Para efectos de esta tesis proponemos los siguientes tres:
1. Criterio de familias de caracter√≠sticas textuales: Es decir, usar los
elementos de A y B en un mismo espacio, s√≥lo si A y B pertenecen a la
misma familia de caracter√≠sticas textuales. Por ejemplo, agrupar los con-
juntos de 1-gramas y 3-gramas en un mismo espacio llamado Conjunto de
caracter√≠sticas basadas en caracteres.
2. Criterio espec√≠co del dominio: Es decir, agrupar las caracter√≠sticas
de acuerdo a una caracter√≠stica espec√≠ca del dominio de documentos. Por
ejemplo, los errores de escritura pueden ser muy valiosos en un dominio
de mensajes de correo electr√≥nico, foros, o redes sociales. En este contexto,
un Conjunto de errores gramaticales agrupar√≠a los conjuntos de atribu-
tos denoten uso incorrecto de may√∫sculas, errores ortogr√°cos, o errores de
estructura, por mencionar algunos.
77
78 Ap√©ndice B. Criterios para formar espacios de atributos
3. Criterio cuanticable: Este consiste en denir un m√©todo, o prueba que
proporcione valores espec√≠cos para determinar si un conjunto de atributos
A es similar a un conjunto de atributos B. Por ejemplo una prueba simple
es que, sobre el conjunto de entrenamiento, se eval√∫en dos pruebas de clasi-
caci√≥n. La primera y segunda prueba utilizan como atributos (vocabulario)
los elementos de A y B respectivamente. Si a partir de las pruebas de cla-
sicaci√≥n al menos un Œ± porcentaje de los aciertos son id√©nticos, entonces
se determina que los conjuntos de atributos A y B son similares, y por lo
tanto se agrupan en un mismo espacio. Note que, en este ejemplo el valor Œ±
sirve para controlar que tan similares deben ser los atributos, de tal forma
que continuen contribuyendo a la diversidad.
Ap√©ndice C
Art√≠culo publicado
El siguiente es un art√≠culo derivado de esta tesis:
A New Document Author Representation for Authorship Attribution. Adri√°n
Pastor L√≥pez-Monroy, Manuel Montes-y-G√≥mez, Luis Villase√±or-Pineda, J.
Ariel Carrasco-Ochoa and Jos√© Fco. Mart√≠nez-Trinidad Lecture Notes in
Computer Science, Volume 7329, pp. 283-292, 2012.
79

Ap√©ndice D
Experimentos adicionales
A continuaci√≥n se presentan algunos experimentos con BoT y RDA utilizando
los clasicadores Na√Øve Bayes y Random Forest. La evaluaci√≥n se realiz√≥ igual que
en (Plakias y Stamatatos, 2008) utilizando el corpus c50, los 2500 t√©rminos m√°s
frecuentes por espacio, y utilizando la exactitud como medida de clasicaci√≥n.
Note que la tendencia de combinar atributos se mantiene en casi todos los casos
de los algoritmos Vista General y Vista Individual.
81
82 Ap√©ndice D. Experimentos adicionales
Experimentos con diferentes atributos
Modelo Balanceado Desbalanceado
50 10 5 10:20 5:10 2:10
Exp 1. Usando Random Forest-BoT
Palabras 71.6 65.5 57.8 62.6 55.6 41.3
n-gramas de palabra 74.0 62.5 51.5 60.8 54.8 41.7
n-gramas de caracter 74.4 61.8 51.9 65.0 56.5 41.3
Estilo 50.8 39.2 34.0 41.0 35.1 30.8
Vista-General 76.6 67.8 60.0 66.1 55.2 41.9
Vista-Individual 77.8 69.5 61.7 67.9 56.4 42.4
Exp 2. Random Forest-RDA
Palabras 72.4 51.9 29.1 59.3 39.4 33.2
n-gramas de palabra 73.6 53.4 30.1 59.2 42.1 31.7
n-gramas de caracter 74.6 55.4 31.1 60.2 43.1 31.7
Estilo 53.2 41.7 33.5 43.5 38.5 35.0
Vista-General 75.6 56.2 29.5 62.0 42.0 33.9
Vista-Individual 76.9 60.1 36.5 64.7 46.3 38.7
Exp 3. Usando Random Forest-BoT+RDA
Palabras 70.4 64.3 58.0 65.5 59.3 42.5
n-gramas de palabra 74.2 61.9 52.3 65.0 52.1 40.1
n-gramas de caracter 73.8 62.5 53.3 64.8 53.8 41.5
Estilo 54.6 44.9 34.2 44.8 40.2 32.2
Vista-General 76.8 66.3 60.0 68.1 63.5 45.1
Vista-Individual 78.6 68.7 62.9 69.4 65.1 47.8
Tabla D.1: Algunos experimentos con uso individual y conjunta de atributos utilizando
BoT y RDA como representaci√≥n base y Random Forest como clasicador.
83
Experimentos con diferentes atributos
Modelo Balanceado Desbalanceado
50 10 5 10:20 5:10 2:10
Exp 1. Usando Na√Øve Bayes-BoT
Palabras 72.0 62.0 49.5 57.5 50.9 39.1
n-gramas de palabra 72.4 57.4 46.4 54.8 44.3 32.3
n-gramas de caracter 72.2 59.8 47.9 56.4 48.6 40.0
Estilo 45.2 29.8 22.6 34.0 26.0 22.8
Vista-General 74.4 64.6 55.5 59.5 52.9 35.9
Vista-Individual 75.6 56.4 55.0 61.4 55.0 40.4
Exp 2. Usando Na√Øve-Bayes-RDA
Palabras 71.0 64.2 49.4 66.7 55.9 46.1
n-gramas de palabra 70.2 64.4 48.1 65.5 57.7 43.9
n-gramas de caracter 72.6 63.0 49.0 66.1 56.6 46.3
Estilo 52.2 42.7 32.6 46.8 39.0 31.6
Vista-General 72.6 63.5 43.8 68.9 59.2 49.5
Vista-Individual 74.8 66.5 50.6 68.4 61.2 51.7
Exp 3. Usando Na√Øve-Bayes-BoT+RDA
Palabras 72.0 61.4 51.2 58.2 51.3 38.1
n-gramas de palabra 72.4 55.7 46.1 52.6 43.5 32.2
n-gramas de caracter 72.2 56.3 47.1 56.9 50.4 40.4
Estilo 48.0 29.7 22.6 34.5 25.6 24.9
Vista-General 73.4 63.9 53.6 61.7 55.4 44.3
Vista-Individual 76.0 65.2 54.8 63.1 56.1 44.4
Tabla D.2: Algunos experimentos con uso individual y conjunta de atributos utilizando
BoT y RDA como representaci√≥n base y Na√Øve Bayes como clasicador.

Referencias
Abbasi, A., y Chen, H. (2008). Writeprints: a stylometric approach to identity-
level identication and similarity detection in cyberspace. ACM Transac-
tions on Information Systems , 26 , Article 7, 29p.
Argamon, S., y Juola, P. (2011). Overview of the international authorship iden-
tication competition at pan-2011. Notebook for PAN at CLEF .
Argamon, S., Whitelaw, C., Chase, P., Hota, S. R., Garg, N., y Levitan, S. (2007).
Stylistic text classication using functional lexical features. Journal of the
American Society for Information Science and Technology , 58 , 802822.
Breiman, L. (1996). Bagging predictors. Mach Learn, 24 , 123140.
Breiman, L. (2001). Random forests. Mach Learn, 45 , 532.
Brown, G., Wyatt, J., Harris, R., y Yao, X. (2005). Diversity creation methods:
a survey and categorisation. Inf. Fusion, 6 , 520.
Cai, D., He, X., Wen, J., Han, J., y Ma, W. (2006). Support tensor machines for
text categorization. Technical report, UIUCDCS-R-2006-2714, University
of Illinois at Urbana-Champaign.
de Vel, O., Anderson, A., Corney, M., y Mohay, G. (2001). Mining e-mail content
for author identication forensics. ACM SIGMOD Record , 30 , 5564.
Deerwester, S. (1990). Indexing by latent semantic analysis. Journal of the
American Society for Information Science, 41 , 391407.
85
86 Referencias
Escalante, H. J., Solorio, T., y G√≥mez, M. Montes-y. (2011). Local histograms of
character n-grams for authorship attribution. Proceedings of the 49th Annual
Meeting of the Association for Computational Linguistics , 288298.
Forman, G. (2003). An extensive empirical study of feature selection metrics for
text classication. Journal of Machine Learning Research, 3 , 12891305.
Frantzeskou, G., Stamatatos, E., Gritzalis, S., Chaski, C. E., y Howald, B. (2007).
Identifying authorship by byte-level n-grams: the source code author prole
(scap). Int. Journal of Digital Evidence, 6 , 18p.
Freund, Y., y Schapire, R. E. (1996). Experiments with a new boosting algo-
rithm. Machine learning: proceedings of the thirteenth international confe-
rence, 325332.
Gabrilovich, E., y Markovitch, S. (2009). Wikipedia-based semantic interpretation
for natural language processing. Journal of Articial Intelligence Research,
34 , 443498.
Gamon, M. (2004). Linguistic correlates of style: Authorship classication with
deep linguistic analysis features. Proceedings of the 20th International Con-
ference on Computational Linguistics , 611617.
Hall, M., Frank, E., Holmes, G., Pfahringer, B., Reutemann, P., y Witten, I. H.
(2009). The weka data mining software: An update. ACM SIGKDD Explo-
rations , 11 , 1018.
Houvardas, J., y Stamatatos, E. (2006). N-gram feature selection for author iden-
tication. In Proceedings of the 12th International Conference on Articial
Intelligence. LNCS , 4183 , 7786.
Kern, R., Seifert, C., Zechner, M., y Granitzer, M. (2011). Vote/veto meta-
classier for authorship identication. Notebook for PAN at CLEF 2011 .
Koppel, M., Akiva, N., y Dagan, I. (2006). Feature instability as a criterion
Referencias 87
for selecting potential style markers. Journal of the American Society for
Information Science and Technology , 57 , 15191525.
Koppel, M., y Schler, J. (2003). Exploiting stylistic idiosyncrasies for authorship
attribution. Proceedings of IJCAI'03 Workshop on Computational Approa-
ches to Style Analysis and Synthesis , 6972.
Koppel, M., y Schler, J. (2004). Authorship verication as a one-class classca-
tion problem. Proceedings of the 21st International Conference on Machine
Learning , 7p.
Koppel, M., Schler, J., Argamon, S., y Messeri, E. (2006). Authorship attribution
with thousands of candidate authors. SIGIR '06 Proceedings of the 29th
annual international ACM SIGIR conference on Research and development
in information retrieval , 659660.
Krogh, A., y Vedelsby, J. (1995). Neural network ensembles, cross validation and
active learning. Adv. Neural Inf. Process Syst., 7 , 231238.
Kuncheva, L. (2005). Combining pattern classiers. Wiley Press, New York ,
241259.
Lebanon, G., Mao, Y., y Dillon, J. (2007). The locally wighted bag of words frame-
work for document representation. Journal of Machine Learning Research,
8 , 24052441.
Lewis, D., Yang, Y., Rose, T., y Li., F. (2004). Rcv1: a new benchmark collection
for text categorization research. Journal of Machine Learning Research, 5 ,
361397.
Maimon, O., y Rokach, L. (2002). Improving supervised learning by feature
decomposition. Proceedings of foundations of information and knowledge
systems, Salzan Castle, Germany , 178196.
Miranda-Garc√≠a, A., y Calle-Mart√≠n, J. (2005). Yule's k characteristic k revisited.
88 Referencias
Language Resources and Evaluation, 39 , 287294.
Montague, M., y Aslam, J. A. (2002). Condorcet fusion for improved retrie-
val. Proceedings of the eleventh international conference on Information
and knowledge management, ACM , 538548.
Mosteller, F., y Wallace, D. L. (1964). Inference and disputed authorship: The
federalist. Addison-Wesley .
Pavelec, D., Justino, E., Batista, L. V., y Oliveira, L. S. (2008). Author identi-
cation using writer-dependent and writer-independent strategies. In Procee-
dings of the 2008 ACM Symposium on Applied Computing - SAC08 , 414
418.
Plakias, S., y Stamatatos, E. (2008). Tensor space models for authorship attri-
bution. In Proc. of the 5th Hellenic Conference on Articial Intelligence
(SETN'08), LNCS , 5138 , 239249.
Porter, M. F. (1980). An algorithm for sux stripping. Program, 14 , 130137.
Provost, F. J., y Kolluri, V. (1999). A survey of methods for scaling up inductive
learning algorithms. Proceeding of 3rd international conference on knowledge
discovery and data mining , 3 , 131139.
Rokach, L. (2009). Ensemble-based classiers. Articial Intelligence Review , 33 ,
139.
Sanderson, C., y Guenter, S. (2006). Short text authorship attribution via se-
quence kernels, markov chains and author unmasking: An investigation. Pro-
ceedings of the International Conference on Empirical Methods in Natural
Language Engineering , 482491.
Schler, J., Koppel, M., y Argamon, S. (2009). Computational methods in authors-
hip attribution. Journal of the American Society for Information Science,
60 , 926.
Referencias 89
Solorio, T., Pillay, S., Raghavan, S., y G√≥mez, M. Montes-y. (2011). Modality
specic meta features for authorship attribution in web forum posts. In
Proceedings of the 5th International Joint Conference on Natural Language
Processing , 156164.
Stamatatos, E. (2008). Author identication: Using text sampling to handle
the class imbalance problem. Information Processing and Management , 44 ,
790799.
Stamatatos, E. (2009). A survey on modern authorship attribution methods.
Journal of the American Society for Information Science and Technology ,
60 , 538556.
Stamatatos, E., y Widmer, W. (2005). Automatic identication of music perfor-
mers with learning ensembles. Articial Intelligence, 165 , 3756.
Tumer, K., y Ghosh, J. (1996). Error correlation and error reduction in ensemble
classiers. Connection science, special issue on combining articial neural
networks: ensemble approaches , 8 , 385404.
Wolpert, D. H. (1992). Stacked generalization. Neural Networks , 5 , 241259.
Zhixing, L., Zhongyang, X., Yufang, Z., Chunyong, L., y Kuan, L. (2010). Fast
text categorization using concise semantic analysis. Pattern Recognition
Letters , 32 , 441448.
90 Referencias
