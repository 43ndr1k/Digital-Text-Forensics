Automatic Annotation of Learning Materials 
for E-learning 
 
 
A thesis submitted in fulfillment of the requirements 
for the award of the degree of 
 
 
Doctor of Philosophy 
 
 
by 
 
 
Devshri  Roy 
 
 
 
Under the guidance of 
 
Prof. Sujoy Ghose 
Dr. Sudeshna Sarkar 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Department of Computer Science and Engineering 
Indian Institute of Technology, Kharagpur 
August 2006 
 
 
 
 
 
 
 
 
 
 
 
Dedicated  
to 
My Parents 


 
Abstract 
 
One of the most important components of an e-learning system is the learning 
material or the learning content. The popularity of e-learning has led to the 
development of many learning object repositories that store learning materials 
specifically created for e-learning. Besides, the world wide web contains many 
articles and good quality learning materials. High quality learning materials are 
expensive to create. So it is very important to ensure reuse of learning content. 
Reuse is made possible by annotating learning content with metadata. Manual 
annotation is a time consuming and expensive process. It is also liable to human 
errors. 
 
In this thesis, we have worked on the automatic annotation of learning materials. We 
have identified a set of metadata attributes that describe some important pedagogic 
characteristics of learning materials. We have developed an automatic annotation 
tool, which annotates given learning materials and thus facilitates the creation of a 
learning object repository. To make the best use of the learning repository one needs 
to be able to retrieve learning materials that are most relevant to the learner’s 
requirements. The metadata associated with a learning object are chosen so as to 
make this possible. We use as metadata pedagogic attributes like document type, 
topic, difficulty level, coverage of concepts, and for each concept the significance 
and the role. A number of methods like standard classification algorithms, parsing 
and analysis of documents have been used for automatic extraction of the above 
metadata attributes. The automatic extraction of some of the metadata makes use of 
the domain ontology. The domain knowledge of the subject is captured using a 
structural ontology of the domain and this ontology has been manually developed 
for a few domains. 
 
Further, a learning system should be able to deliver personalized learning materials 
to a learner. To deliver personalized learning materials to a learner, we have 
developed a search tool. The personalized retrieval is based on the user profile. The 
user profile includes what the learner already knows (the learner’s knowledge state) 
and what the learner is required to know (the learner’s curriculum requirements).  
 
The major contribution of the thesis can be outlined as follows: 
• Identification of some important pedagogic metadata attributes of learning 
materials to facilitate e-learning.  
• Development of different algorithms for automatic extraction of the metadata 
attributes from the learning content. 
• Development of an automatic annotation tool to facilitate the creation of a 
learning repository. 
• Development of a search tool for personalized retrieval of learning materials. 
 
Automatic extraction of pedagogic metadata is a sub problem of natural language 
processing and shares the latter’s difficulties. However, because of its limited scope 
and the availability of the contextual knowledge in the form of ontology allows 
comparatively superficial analysis to give encouraging results.  
 
Contents 
 
  
Chapter – 1: Automatic Annotation of Learning Materials for  
    E-learning 
1.1  Introduction ……………………………………………...………………1 
 1.1.1 Learning Object Repositories ..…………………………………2 
 1.1.2 Metadata for Learning Objects………………………………….4  
 1.1.3 Difficulties with Manual Annotation of Learning Objects……...7 
 1.1.4 Automatic Tagging ….………………………………………….8 
1.2 Objective ……………………..…………………………………………11 
1.3  Overview of our work  ……….………………………………………….12 
 1.3.1 Identification of Attributes from the Standard  
   Metadata  Specification ….……………………………………12 
 1.3.2  Overview of the System ……………………………………….15 
 1.3.3  Algorithm Design for Automatic Extraction of the Attributes...16 
 1.3.4  Information Retrieval from the Repository…………………....18 
1.4   Organization of the Thesis…………………………………………….. 19 
 
Chapter – 2: Related Work on Metadata Standards, Learning  
    Object Repositories & Automatic Metadata   
    Generation 
2.1 Introduction…………………...…………………………………………21 
2.2  The Meta-Data Standards…….………………………………………….22 
2.3  Learning Object Metadata Based Repositories…….……………………25 
2.4  Metadata Generation ……………………………………………………30 
 2.4.1  Manual Metadata generation…………………………………..30 
 2.4.2  Automatic Metadata generation….………………….…………31 
2.5  Summary …………………………………………………………….36 
 
Chapter – 3: Related Work on Ontology, Student Modeling &  
    Personalized  Information Retrieval 
3.1  Introduction …………………………………………………………….40 
3.2  Ontology  ……………………………………………………………….42 
Contents 
   
 
 II
3.3 Student Modeling ……………………………………………………….45 
3.4  Personalized Information Retrieval Systems   ………………………….48 
3.5  Adaptive Learning Systems  ……………………………………………50 
3.6  Summary………………………..……………………………………….54 
 
Chapter – 4: System Architecture 
4.1  Introduction……………………..……………………………………….55 
4.2  Overview of the System………………………………………………... 56 
4.3  Domain Knowledge Representation   …………………………………..58 
 4.3.1  Ontological Structure   ………………………………………..60 
4.4  Metadata Based Repository & Document Analyzer   …………………..67 
 4.4.1  Requirements of a Metadata Based Repository   ……………...67 
 4.4.2  Architecture of the Metadata Based Repository……………….69 
4.5  User Profile Representation……………………………………………..71 
4.6  Personalized Retrieval Module………………………………………….72 
4.7  User Interface & Query Handler……………………………………..….73 
4.8  Summary  ……………………………………………………………….77 
 
Chapter – 5: Metadata Schema 
5.1  Introduction …………………………………………………………….78 
5.2  Identification of Attributes from the Standard  Metadata Specification...79 
 5.2.1  General and Technical Category Metadata….…………………88 
 5.2.2  Educational Category Metadata...……………………………...88 
 5.2.3  Classification Category Metadata...……………………………93 
 5.2.4  Local Extension………………………………………………..93 
5.3   Metadata Schema……………….……………………………………….95 
5.4  Summary………………………..……………………………………….96 
 
Chapter – 6: Automatic Metadata Extraction 
6.1  Introduction……………………………………………………………...98 
6.2  Types of Metadata Annotation…………………………………………..98 
6.3  Automatic Extraction of Metadata……………………………………..100 
 6.3.1  List of Terms………………………………………………….101 
Contents 
   
 
 III
 6.3.2  List of Concepts and their Significance...…………………….101 
 6.3.3  Concept Type Identification………………………………….109 
   6.3.3.1 Identification of Defined Concept and  
     Used Concept……………………………………….110     
   6.3.3.2   Extraction of Outcome and Prerequisite  
     Concepts from the Document……………………….118 
 6.3.4  Topic Identification………………………………………..….120 
   6.3.4.1  Example Based Classifier…………………….……..123 
   6.3.4.2  Topic Identification using Ontology………….…….131 
 6.3.5  Learning Resource Type Identification………………………137 
   6.3.5.1  Feature Set used for Automatic Classification……...139 
   6.3.5.2  Feedforward Backpropagation Neural Network……141 
   6.3.5.3  Generalised Regression Neural Network (GRNN) ...149 
 6.3.6  Grade Level Identification……………………………………150 
6.4 Automatic Annotation Tool……………………………………………154 
6.5 Summary……………………………………………………………….154 
 
Chapter – 7:  Personalized Information Retrieval for E-learning 
7.1  Introduction…………………………………………………………….156 
7.2  Retrieval Requirement for E-learning……………………………….…158 
7.3  Search Tool for E-learning……………………………………………..160 
7.4  Query module…………………………………………………………..162 
 7.4.1 Types of Queries……………………………………………...163 
 7.4.2 Query Processing……………………………………………..164 
 7.4.3  Domain Specific Retrieval……………………………………164 
   7.4.3.1  Query Enhancement Approach……………………..166    
   7.4.3.2  Domain Specific Filtering Approach……………….168 
 7.4.4  Relevance Finding and Re-ranking…………………………..169    
 7.4.5  Snippet………………………………………. ………………177    
7.5  Implementation of the Retrieval System………………………………180 
 7.5.1  Simple Search………………………………………………...180 
   7.5.1.1  Evaluation of the Retrieval Module  
     for Simple Search…………………………………...181 
 7.5.2  Advanced Search………………………………………….….184 
Contents 
   
 
 IV
   7.5.2.1 Evaluation of the Retrieval Module for  
     Advance Search……………………………………..185 
 7.5.3  Hierarchy Browsing for Navigation on Topics……………….190 
7.6  Summary……………………………………………………………….192 
 
 
Chapter – 8:  Conclusion & Future Work 
 8.1  Conclusion…………………………………………………………….193 
 8.2  Future Work…………………………………………………………...195 
  8.2.1 Extension of the Metadata Schema…………………………..195 
  8.2.2   Ontology……………………………………………………...196 
  8.2.3 User Model…………………………………………………...197 
 
 
References…………………………………………………………………….198
                   
Appendix – A…………………………………………………………………211 
 
Appendix – B…………………………………………………………………213 
 
List of Publications 
 
List of Figures 
 
1.1  Overview of the System…………………………………………... 15 
3.1  A typical personalized retrieval system…………………………... 40 
4.1  Overall architecture of the system……………………………….. 57 
4.2  Ontology: three level hierarchical structures……………………... 62 
4.3  A small section of the ontology…………………………………... 63 
4.4  Example of a specific domain…………………………………….. 66 
4.5  Metadata collection, extraction and load process………………… 69 
4.6  Input interface for collecting documents…………………………. 70 
4.7  User interface……………………………………………………... 74 
4.8  User profile creation interface…………………………………….. 75 
6.1  
 
First few results returned by Google search engine  
for the query reflection……………………………………………. 
 
102 
6.2 The page returned by the Google search engine in response  
to the query reflection…………………………………………….. 
 
103 
6.3  Relation among concepts…………………………………………. 104 
6.4  Precision and recall measure……………………………………… 107 
6.5  Performance evaluation of the algorithm in terms of precision….. 109 
6.6  Constituent Tree…………………………………………………... 111 
6.7  Linkage detail……………………………………………………... 111 
6.8  Semantic relations between words………………………………... 114 
6.9  Linkage detail……………………………………………………... 115 
6.10  A portion of a document………………………………………….. 118 
6.11  Probabilistic neural network architecture…………………………. 124 
6.12  A part of a topic tree………………………………………………. 126 
List of Figures 
   
 
 II
6.13 features distribution in documents belonging to the  
topics lens and mirror……………………………………………... 
128 
6.14  Distribution of features in document sets…………………………. 128 
6.15  
 
features distribution in documents belonging to the  
topics lens and velocity…………………………………………… 
 
129 
6.16  A part of a topic tree……………………………………… 132 
6.17  Distribution of features in few sets of documents………………… 141 
6.18  Feed forward network structure…………………………………... 142 
6.19  Parser output for a sentence “what is a rainbow?”……………….. 146 
6.20  Link detail obtained from parser output…………………………... 146 
6.21  linkage detail……………………………………………………… 147 
6.22  Architecture of GRNN……………………………………………. 149 
6.23  A portion of syllabus of grade seven and grade ten………………. 151 
6.24  Snapshot of a document…………………………………………... 152 
7.1  Query module of the system……………………………………… 163 
7.2   Consideration of related concepts of the query  
concept for domain specific filtering……………………………... 
 
170 
7.3  Relevance calculation mechanism………………………………... 176 
7.4  Some example snippets…………………………………………... 179 
7.5  The user interface…………………………………………………. 180 
7.6  User interface for advanced search……………………………….. 185 
7.7  Documents on chapter mirror and reflection of light……………... 191 
 
List of Tables  
 
 
1.1 Comparative study of learning object repositories……………... 37 
5.1  LOMv1.0 Base Schema………………………………………… 80 
5.2  Six levels of Bloom’s Taxonomy………………………………. 89 
5.3  Phases of expository teaching according to Ausubel…………... 90 
5.4  Definition of document types with examples…………………... 92 
5.5  A subset of the IEEE LOM…………………………………….. 95 
5.6  Local extension of the IEEE LOM…………………………….. 96 
6.1  Performance evaluation in terms of precision and recall………. 108 
6.2  Link type labeling………………………………………………. 112 
6.3 Interpretation of the link types between words………………… 113 
6.4  Performance of the algorithm output…………………………... 117 
6.5  Performance of the classifier…………………………………… 127 
6.6  Classifier output for identification of topics belonging  
to same parents…………………………………………………. 
 
129 
6.7  Classifier output for identification of topics belonging to  
different parents………………………………………………… 
 
130 
6.8  Performance of the algorithm 6.4………………………………. 132 
6.9  Performance of the algorithm 6.3………………………………. 136 
6.10  Performance of the topic identification algorithm 6.5…………. 137 
6 .11  Document type and the sample verb list……………………….. 140 
6.12  Classification performance of the document type classifier…… 143 
6 .13  Classification performance of the document type classifier…… 148 
6.14  Classification performance of the document type classifier…… 150 
7.1  Improvement in relevance with enhanced query……………….. 167 
List of Tables 
   
 
 II
 7.2  
 
The top 10 output results shown to a student with  
User Id CS2 for query reflection……………………………….. 
182 
 7.3  
 
The top 10 output results shown to a student with  
User Id CS4 for query reflection……………………………...... 
 
183 
 7.4  Advanced search results for the experiment type documents….. 186 
 7.5  Advanced search results for the exercise type documents……... 187 
 7.6  Advanced search results for the application type documents….. 188 
 7.7  Advanced search results for the explanation type documents….. 188 
 7.8  Evaluation of advanced search…………………………………. 189 
 
 
 
Chapter – 1  
 
Automatic Annotation of Learning 
Materials for E-learning 
 
1.1  Introduction 
The wide availability of content in the electronic media has given rise to new 
paradigms of learning and knowledge delivery. E-learning has emerged as a 
promising approach to facilitate and enhance learning through computer and 
communication technology. E-learning makes asynchronous and flexible learning 
possible and the courses can be tailored to the specific needs of the learner. The 
definition of e-learning given by Khan (Khan, 2005) is as follows: 
 
“E-learning can be viewed as an innovative approach for delivering learner-
centered, interactive, and facilitated learning environment to anyone, anyplace, 
anytime by utilizing the attributes and resources of various digital technologies 
along with other forms of learning materials suited for open, flexible, and 
distributed learning environment”. 
 
The web is a gigantic digital library. It contains structured and unstructured 
information from all areas, be it general, educational, commercial so on and so 
forth. Search engines are used to access content from the web. Popular general-
purpose search engines like Google, MSN and Yahoo! search index many billion 
pages of the Web. A user makes a query to a search engine, typically by giving key 
words. The search engine looks up the index and provides a listing of the best-
matching web pages according to some ranking criteria, usually with snippet which 
Chapter – 1 
   
 
 - 2 -
is a short summary containing the document's title and sometimes parts of the text. 
The search engine may index several thousands or even millions of documents that 
match the query words, and it returns a ranked list of pages. The effectiveness of a 
search engine depends on the relevance of the top few results returned in response 
to the query.  If the user does not find the information he wants from the top few 
pages, then he has to sift through a large number of pages to find documents of his 
interest. He may get bored without finding the information he needs.  
 
Besides the world wide web, specific learning materials are created often for the 
purpose of computer aided learning or e-learning. Creating high quality learning 
content requires a great deal of effort, and the wisdom today is to create high 
quality learning objects, which are reusable units of instruction. Learning objects 
are defined as being educational resources that can be employed in technology-
supported learning (McGreal, 2004). 
 
The popularity of e-learning has led to the development of many learning object 
repositories that store learning materials specifically created for e-learning. 
1.1.1 Learning Object Repositories 
In order to make learning resources readily accessible to learners and educators, 
several initiatives to build learning object repositories have been undertaken. 
Learning object repositories are essentially storage and retrieval systems for 
learning objects where the learning objects are organized so as to be easily 
searchable. These repositories enable share and reuse of learning materials by 
different users. Different learners have different requirements and therefore require 
different learning contents. A learner may be looking for learning materials 
explaining a given topic or exercises on the topic. Learning materials like 
explanation, exercises, assignments, simulations, tutorials and other kinds are 
easier to find from within a contained collection. One of the key issues in using 
learning objects is their identification by search engines. This is usually facilitated 
by assigning descriptive metadata to the learning object.  
Chapter – 1 
   
 
 - 3 -
 
Many organisations develop lessons, modules and courses for educational 
purposes. By housing the learning objects in a repository and allowing multiple 
and simultaneous access via internet, instructional designers and course developers 
can access the objects and incorporate them into different courses and modules. 
 
E-learners use learning object repositories for searching and browsing learning 
materials. In recent years, many learning object repositories have been developed, 
which support searching as well as browsing. Learners need to search specific 
learning material in e-learning. Some repositories have different advanced search 
features that allow the user to refine the kind of objects they wish to find. In 
advanced search, it is possible to enter different extra fields along with keywords 
for more specific retrieval. There are several online repositories or collections of 
learning objects. Some of the well-known learning object repositories are 
mentioned below.  
 
1. "Multimedia Educational Resource for Learning and Online Teaching" 
(MERLOT, http://www.merlot.org) is one of the most popular repositories 
of learning objects. It is a free and open resource designed primarily for 
faculty and students of higher education. MERLOT includes links to online 
learning materials along with annotations such as peer reviews and 
assignments.  
2. ARIADNE (ARIADNE, http://www.ariadne-eu.org), the European digital 
library project, was initiated in 1996 by European commission’s telematics 
for education and training program. It is actively used in both academic and 
corporate contexts. 
3. Maricopa Center for Learning and Instruction (MCLI, 
http://www.mcli.dist.maricopa.edu/) links to a number of discrete 
searchable repositories. The Maricopa Learning Exchange (MLX, 
http://www.mcli.dist.maricopa.edu/mlx/index.php) facilitates teaching 
/learning on web.  
Chapter – 1 
   
 
 - 4 -
4. The Campus Alberta Repository of Educational Objects (CAREO, 
http://www.careo.org/ ) is an ongoing research prototype supported by 
Alberta Learning and CANARIE. It’s primary goal is the creation of a 
searchable, web-based collection of multidisciplinary teaching materials for 
educators and learners. It provides the additional facility of creating 
workspace apart from searching and browsing. In workspace, user can 
organize the contents from the repository to suit their individual needs. 
5. iLumina (iLumina, http://www.ilumina-dlib.org/ ) is a digital library of 
sharable undergraduate teaching materials for chemistry, biology, physics, 
mathematics, and computer science. It is designed to quickly and accurately 
connect users with the educational resources they need. These resources 
range in type from highly granular objects such as individual images and 
video clips to entire courses. Resources in iLumina are cataloged in the 
MARC and NSDL metadata formats.  
6. National Science, Mathematics, Engineering, and Technology Education 
digital library (SMETE, http://www.smete.org) provides the facility of 
searching and browsing through the extensive collection of learning 
resources.   
 
All above discussed repositories are searchable. In addition to the simple search, 
these repositories offer certain advanced search features such as type of learning 
resource, title, subject, grade, author, primary audience etc. These repositories 
make use of different metadata for organizing learning objects. 
1.1.2 Metadata for Learning Objects 
A learning object repository has many uses. One can retrieve learning objects from 
the repository. Meaningful retrieval is possible only when the learning objects are 
properly tagged. More ambitiously, one may like to develop an adaptive tutoring 
system which has to identify the most appropriate learning material for a given 
learner, and that can take advantage of the learning objects stored in the repository. 
In order to achieve this, it is important to annotate the learning objects in the 
Chapter – 1 
   
 
 - 5 -
repository appropriately. We must carefully select the set of most relevant 
attributes that will be used as metadata for the learning objects.  
 
However, in order to facilitate the sharing and reuse of learning objects across 
different information repositories or learning management systems, it is 
recommended that the learning objects should be associated with some common 
metadata standard.  
 
Several metadata standards have emerged for the description of learning resources. 
The Dublin Core metadata initiative (DCMI, http://dublincore.org/) is an open 
forum engaged in the development of interoperable online metadata standards that 
supports a broad range of purposes and business models. Although Dublin Core 
attributes that contains metadata such as authors, title or granularity, are definitely 
useful for describing educational resource content, but Dublin Core does not 
contain attributes describing the pedagogical perspective of a document. In order to 
cope with the educational concerns, various metadata standards were defined such 
as IMS Metadata (IMS, http://www.imsglobal.org/), SCORM Metadata (SCORM, 
http://www.adlnet.gov/scorm/index.cfm), CanCore (http://www.cancore.ca/) and 
IEEE Learning Object Metadata (IEEE LOM,http://ltsc.ieee.org/wg12/index.html). 
The IMS Global Learning Consortium develops and promotes the adoption of open 
technical specifications for interoperable learning technology.  The Advance 
Distributed Learning Initiative (ADL, http://www.adlnet.org) aims to establish a 
distributed learning environment that facilitates the interoperability of e-Learning 
tools and course content on a global scale. The Sharable Content Object Reference 
Model (SCORM) is a set of specifications by ADL concerning developing, 
packaging and delivering learning objects. SCORM-compliant courses are 
reusable, accessible, interoperable and durable. IEEE LOM aims to develop 
accredited technical standards, recommended practices, and guidelines for learning 
technology. 
 
Chapter – 1 
   
 
 - 6 -
Most of the learning object repository such as SMETE, MERLOT, HEAL, 
LearnAlberta, CAREO etc has adapted IEEE LOM metadata specification schema. 
Although IEEE LOM is considered as a standard reference, sometimes it does not 
meet all the requirements of the learning management systems and requires local 
extensions and modifications. Many researchers have suggested the extension of 
LOM specifications. Mohan et al. (Mohan, 2003) investigated instructional 
planning processes in e-learning environments and recommended extensions to the 
current specifications. Brooks et al., Mccalla (Brooks, 2005; McCalla, 2004) are 
working on implementing an alternative theory of metadata, called the ecological 
approach. In the ecological approach, the e-learning system keeps a learner model 
for each learner, tracking characteristics of the learner and information about the 
learner’s interaction with the learning objects. Liu et al. (Liu, 2004) have suggested 
adding the learning object usage history, which can be gathered from prior 
experience with the learning object by learners.  
 
From instructional design perspective it is important to know the pedagogic 
category of the learning resource. It is important to identify the pedagogical 
category of a document to assess its relevance for learning in a given situation. 
Different learners require different learning content depending on their learning 
style (Papanikolaou, 2002). A learning system decides whether a document is 
relevant to the learner based on the learner’s learning style and the characteristics 
of the learning materials. The learning system should be able to reuse the content 
in different instructional strategies. In the context of instructional design, the 
learning resource type (IEEE LOM’s property 5.3) such as exercise, simulation, 
narrative text, exam and experiment cover the instructional type. Few more values 
have been proposed as an extension to LOM resource type, which will describe 
learning resource from the instructional perspective (Ullrich, 2004). 
 
The learning resources should be associated with a set of metadata, which 
effectively facilitates the retrieval of learning materials. In order to filter the 
learning material according to the learner’s requirement from the repository, there 
is a need to identify a set of attributes from the learning content, which describes 
Chapter – 1 
   
 
 - 7 -
the learning material. Further, different learners require different learning content 
depending on their current state of knowledge and learning style preferences. 
Which learning material is relevant to the learner depends on the learner’s profile 
and requirements that have to be matched with the characteristics of the learning 
materials. The learning system should be able to reuse the same learning content in 
different situations. For this purpose it is important to know the topic of the 
learning material, the extent of coverage in terms of different concepts referred in 
the material. A document contains a set of concepts. In order to distinguish the 
learning material understandable to the user, we need to know the concepts and 
their role in the document. In a document, there are sets of concepts, which are 
prerequisite for studying and understanding that document. Some concepts are 
defined/explained in the document. Some of explained concepts are outcome 
concepts, which are learned after going through the documents. We need to know 
few more attributes like frequency and significance of concepts. All the concepts 
mentioned in a document are not equally important. A concept and the concepts 
related to it in a document can be used to estimate the significance of the concept 
in the document. The attribute significance helps in identifying and discriminating 
the domain specific documents. 
1.1.3 Difficulties with Manual Annotation of Learning Objects 
Most of the available online repositories have been developed manually. The 
authors, contributors and developers of the open repositories have the 
responsibility of manually attributing meta information to the learning objects. In 
the Health Education Assets Library (HEAL, http://www.healcentral.org), iLumina 
and Campus Alberta repository of educational objects (CAREO), the contributors 
are required to follow strict guidelines and fill up many forms to carefully ensure 
that the learning objects associated to the repository are according to their 
requirements. Similarly, while developing learning materials for LearnAlberta 
online repository (LearnAlberta, http://www.learnalberta.ca/login.aspx), the 
developer has to follow the specifications of resource development guideline such 
Chapter – 1 
   
 
 - 8 -
as learning object development guideline, metadata guidelines, instructional design 
guidelines etc.  
 
Associating meta information to learning objects by humans is a labour intensive 
activity. Many contributors find the task of manual annotation and assigning of 
meta-tags uninteresting, and sometimes the tagging is not done satisfactorily. The 
development of a repository with manually annotated learning materials is 
expensive in terms of the time and effort required. Many people feel (cite (Ochoa, 
2005, http://www.cs.kuleuven.ac.be/~hmdb/amg/publicationsFiles/paperAMG2.doc) that 
unless the process of annotating learning objects can be automated, it is difficult to 
create a critical mass of reusable learning objects.   
1.1.4 Automatic Tagging 
Automating part of the process of building repositories will facilitate the building 
of large learning object repositories with little effort. It will be useful if the 
contributors/ developers can be relieved from filling up many forms while 
submitting the learning material into the repository. This can be made possible by 
automating the tagging of the learning objects. Further, the process of collection of 
learning objects can be made easier by building a system that will be able to select 
learning objects from existing materials present in various sources like the internet, 
as well as learning objects present in the other repositories.  
 
Automatic indexing is especially important if we wish to harness the large number 
of documents available in the Web. The Internet includes a huge storehouse of 
information on various topics. In order to be able to make use of such materials in 
e-learning systems, one will have to search and filter the learning materials from 
this storehouse and use these for building learning object repository.  These 
materials are often not tagged. The challenge is to make such materials usable by 
learning management systems by incorporating appropriate meta tags 
automatically.  
 
Chapter – 1 
   
 
 - 9 -
As discussed above, meta information for learning object is created by humans is a 
labour intensive activity. A recent survey about metadata (Friesen, 2004) confirms 
that metadata instantiation is a difficult task. The correct instantiation of metadata 
for learning object requires educational and technical skill. It requires too much 
time. It is costly to create metadata, and impractical, if we consider a large set of 
potential materials obtained from the world wide web and other sources. Therefore, 
metadata creation needs to be simplified. Being able to create metadata 
automatically has significant value and researchers are working on automatic 
creation of learning object metadata (Downes, 2004; Duval, 2004; Simon, 2004). 
The Bibliographic Control of Web Resources: A Library of Congress Action Plan 
(LC Action Plan, http://lcweb.loc.gov/catdir/bibcontrol/actionplan.pdf) recognizes 
this need and highlights automatic metadata generation tool development as a 
“near-term/high” priority. LC Action Plan Section 4.0 targets the development of 
“automatic tools…to improve bibliographic control of selected Web resources,” 
and Section 4.2 specifically identifies the need for a master specification to guide 
development of such applications. According to automatic indexing developments 
(Anderson, 2001), automatic metadata generation is more efficient, less costly, and 
more consistent than human-oriented processing. In fact, research indicates that 
automatic metadata generation can produce acceptable results (Han, 2003; Liddy, 
2002). Automatic metadata generation solely depends on machine processing and 
therefore is a difficult task. Certain attributes of the learning material can come 
from the application (like format, date of creation, and date of modification).  
More interesting and useful metadata relating to the content of the learning 
material can be obtained by analyzing the learning materials. Current progress in 
natural language processing, machine learning and data mining is making this task 
possible.  
 
Some work has been done on automatic generation of Dublin Core metadata. UK 
Office for Library and Information Networking (UKOLN) has developed 
automatic metadata generator tool DC-dot (DC-dot, 
http://www.ukoln.ac.uk/metadata/dcdot/). The set of Dublin Core metadata, which 
is generated by DC-dot are identifier, subject, title, description, type, and format. 
Chapter – 1 
   
 
 - 10 -
Metadata creation with DC-dot is initiated by submitting a URL. DC-dot, copies 
resource identifier metadata from the web browser’s address prompt, and harvests 
title, keywords, description and type metadata from resource meta tags. DC-dot 
automatically generates type, format and date metadata by reading the source code 
programming. If meta tags are absent, it automatically generates keywords by 
analyzing anchors (hyperlinked concepts) and by using the presentation encoding. 
Similarly, the work done by Jenkins (Jenkins, 2000), a set of metadata like title, 
date, and format are harvested from html documents and the metadata keywords 
are extracted from the actual content of the documents.  
 
Hui Han et al (Han, 2003) proposes a machine learning method using support 
vector machine for automatic extraction of Dublin Core metadata. They have 
extended the Dublin Core metadata. The additional metadata included are author’s 
affiliation, author’s address, author’s email, publication number and thesis type. 
Another work by Li y., Zhu Q., and Cao Y. (Li, 2004) also generates the Dublin 
Core metadata of 10 elements from web pages automatically. 
 
Most of the learning object repositories provide the facility of advanced search. 
Advanced search allows the user to refine the kind of object they wish to find. In 
advanced search, it is possible to enter different kinds of criterion such as subject, 
subcategories (topics), learning resource types, content URL, primary audience etc 
so that the repository returns most relevant materials. Therefore it is important to 
know all these metadata information of a document. The framework of automatic 
generation given by Cardinaels (Cardinaels, 2005) generates subject (main 
discipline) and keyword for documents. The top-level classification gives the main 
discipline and the lowest level classification gives the keyword for the document. 
For example, XML is one of topic of course Multimedia. The documents on the 
topic XML are structured in folders like Multimedia/XML and the keyword of the 
documents are identified from this taxonomic path. Challenge is to identify the 
topic of document automatically by analyzing the content of the document. 
 
Chapter – 1 
   
 
 - 11 -
Li et al. (Li, 2004) classify webPages into ten major classes: news, entertainment, 
community, sports, health, finance and economics, living information, science and 
technology, people and shopping. The classification is done using a neural 
network. However, in this case, the taxonomy is flat and the classes have few 
overlapping features or common terms.  
 
Jovanovic et al. (Jovanovic, 2006a) present an ontology-based approach for 
automatic annotation of the components of learning objects based on IEEE LOM. 
The metadata for the learning object (LO) is provided by the author. They generate 
the metadata elements title, description, unique identifier, subject and pedagogic 
role automatically for the different components of the LO. They focus on smaller 
units for reusability on a finer scale. The subject annotation is based on a domain 
ontology and derived from the subject metadata provided by the author for the LO. 
They use ontology of pedagogical rules like definition, illustration, reference, etc. 
They mainly use the author provided annotation of the entire LO, content mining 
algorithms and certain heuristics for extraction of these metadata elements.  
 
The aim of our work is to take forward the process of automatic metadata 
generation by developing algorithms for extraction of some metadata with 
acceptable level of performance. 
1.2 Objective 
The objective of our work is to simplify the process of creating learning repository 
so that the documents from various sources can be incorporated into the repository 
with very little manual effort. Each learning object of the repository is to be tagged 
with appropriate metadata for the ease of e-learner and also for use by the tutoring 
systems.  To achieve it we need  
 
• To identify important pedagogic metadata from the existing metadata 
standards, which give the description of the attributes of the learning 
Chapter – 1 
   
 
 - 12 -
material to facilitate e-learning and can automatically be extracted from the 
learning content.  
 
• To develop a tool to facilitate construction of a learning repository. To 
collect learning materials from different resources, the input interface is to 
be very simple where authors/contributors are not required to do any kind 
of manual tagging while submitting the document and the web documents 
can be submitted simply by submitting their URL. 
 
• To develop algorithms for automatic extraction of the metadata. The 
metadata such as the topic, difficulty level, the pedagogic category of the 
document, concepts describing the content of the document and its 
significance need to be extracted automatically from the document. 
 
• To develop a search tool for personalized retrieval of learning materials, 
which presents different search results to different learners considering the 
learner’s characteristics such as his background, his current state of 
knowledge and his preferences from the repository and also from the web. 
1.3  Overview of our work 
1.3.1 Identification of Attributes from the Standard Metadata 
 Specification 
We have adapted IEEE LOM standard and designed a metadata schema. The IEEE 
LOM specification contains 9 categories, which includes almost 60 attributes. 
These categories cover various aspects of the learning material including general, 
life cycle, meta-metadata, technical, educational, right, relation, annotation and 
classification.  
 
We have identified a set of attributes from the IEEE LOM specification, which are 
deemed to be the most useful for learning purposes and can automatically be 
Chapter – 1 
   
 
 - 13 -
extracted from learning contents. It includes metadata such as identifier, format, 
size and location, which gives general and technical information about the 
document. In order to meet the learner’s requirement, it includes attributes 
describing the pedagogic characteristics of the learning object like learning 
resource type, grade level and the topic of the document.  
 
To identify the learning resource type from instructional design perspective, we 
have consulted the Bloom’s classification (Bloom, 1956) of educational objectives, 
the learning theory suggested by Ausubel (Ausubel, 1968) and the instructional 
models of problem based learning (Merrill, 2002). In 1956, educational 
psychologist Benjamin S Bloom developed a classification of educational goals 
and objectives. The major idea of the Bloom’s taxonomy is to arrange the 
educational objective in a hierarchy from less complex to more complex. He 
identified six levels in the cognitive domain, namely, knowledge, comprehension, 
application, analysis, synthesis and evaluation. The knowledge level of Bloom’s 
taxonomy includes the basic knowledge and recall of information, the 
comprehension level includes understanding and grasping the meaning of the 
information and the application level includes the use of the information in new 
and practical situations. The evaluation level of Bloom’s taxonomy evaluates of 
the value of the information, which is learned. The learning phases suggested by 
Ausubel are advance organizer, progressive differentiation, practice, and 
integrating and connecting. The learning phase advance organizer includes the 
presentation of introductory material. The learning phase progressive 
differentiation includes the details of the material in progressive manner. The 
learning phase integrating and connecting integrate and link new knowledge to 
other fields of knowledge. Based on the above levels, we have categorized 
documents into four types namely explanation, application, exercise and 
experiment type. A document that deals with the comprehension level of Bloom’s 
taxonomy and the progressive differentiation of Ausubel’s learning theory is 
classified as belonging to the explanation type. Considering the evaluation level of 
Bloom’s taxonomy, we classify documents into the category exercise type. The 
Problem based learning gives more emphasis on demonstration and 
Chapter – 1 
   
 
 - 14 -
experimentation; therefore we have included experiment type learning resources. 
We can map the explanation type document to the narrative text, the exercise type 
document to quaternaries, exercise and the experiment type to the experiment type 
of IEEE LOM 5.2 learning resource type metadata.  
 
The learners from different grade levels need learning materials at different 
difficulty levels. One needs to find out the difficulty level of the document. The 
attribute grade level of the document indicates the grade or class for which the 
document is suitable and helps in filtering the documents specific to the learner’s 
grade. This attribute can be mapped to the attribute 5.6 context of the IEEE LOM.  
 
We have added a few extra attributes into the metadata schema, which are not there 
in the IEEE LOM. The attributes are list of concept, its frequency, its significance 
and role of the concepts with respect to the document. The repository is a pool of 
learning materials. To incorporate the facility of retrieval of learning materials, a 
set of document terms is extracted from the document. A term can be polysemous. 
It may have different meaning in different domains. If the documents are searched 
on terms, the search result will contain documents of various domains.  To retrieve 
documents specific to the interest of the user’s query, the search on concepts 
returns better search results (Aitken, 2000). Concept-based search gives higher 
precision for domain specific retrieval. The attribute concept list provides a list of 
concepts, which describe the content of the document. But all concepts that occur 
in a document are not equally useful for characterizing the document. Some 
concepts are more significant and useful for describing the document. We keep a 
separate attribute for representing the significance of the concept in the document. 
The concepts mentioned in a document can have two major roles with respect to 
the content. A concept may be used to define or explain other concepts, or a 
concept may be defined or explained in the document. In the first case they act as 
pre-requisites, and in the second case they act as learning outcomes.  
Chapter – 1 
   
 
 - 15 -
1.3.2  Overview of the System 
The system is designed to accept documents from various sources, analyze them 
and assign metadata automatically. The annotated documents are stored in the 
repository so that users can access relevant learning material from it. The system 
stores the domain knowledge of various subject domains in the form of ontologies. 
The relevance of a document depends on the user’s knowledge state and his 
requirement. In order to effectively identify the documents that are most relevant to 
a user, the system needs to keep track of the user’s requirements and his interest, 
and also the knowledge state of the user.  
 
The success of any e-learning system depends on the organization of learning 
objects with specific knowledge and the retrieval of relevant learning material. We 
have developed an information retrieval system, which tries to provide learning 
materials according to the learner’s requirement. In Figure 1.1, we show the 
overview of our system. The query module handles the query given by a learner. A 
learner can search learning materials from the repository of the system.  The 
system also provides the facility of search of learning materials directly from the 
web. The personalized retrieval module is responsible for extracting relevant items 
Figure 1.1 Overview of the System 
Chapter – 1 
   
 
 - 16 -
for the learner by looking at the domain knowledge or ontology and the user 
profile.  
 
The repository management tool builds and manages the learning object repository 
of the system. It collects documents from various resources such as web or 
documents submitted by different authors. It searches and filters the domain 
specific learning material referring the domain knowledge maintained in the 
system. To filter the documents it looks into the domain specific concepts and their 
significance with respect to the document. It analyzes the filtered documents, 
automatically extracts the set of attributes discussed in Section 1.3.1 from it and 
annotates documents with those attributes before storing them into the repository. 
For automatic extraction of the attributes, it uses different approaches such as 
natural language processing of the text, machine learning etc. It also refers the 
domain knowledge of various subject domains maintained in our system for 
automatic extraction of the attributes. 
 
The personalized retrieval module takes the metadata-annotated documents, the 
user profile and the domain knowledge as the input. It checks whether the 
documents are relevant to the user’s requirement and understandable to the user. It 
finds, whether the user will gain some new knowledge from documents. This 
module provides content-based score to each document and this score reflects the 
relevance of the document to the user. It computes two scores for each of the 
documents, the relevance scores and the understandability score. The relevance 
score represents the relevance of the document to the input query. The 
understandability score gives the degree of understandability of a specific user for 
the document. Based on the relevance score and the understandability score, 
documents are ranked. The ranked results are presented to the user. 
1.3.3  Algorithm Design for Automatic Extraction of the Attributes  
We have developed different algorithms to extract the set of attributes from 
documents. All attributes of the metadata schema discussed in section 1.3.1 are 
Chapter – 1 
   
 
 - 17 -
extracted automatically. Few attributes like format, size, and date are extracted 
automatically from the system properties.  
 
The type of learning resource is generated by textual content analysis. The analysis 
is based on the surface level features of the text. Our approach uses various 
features like verb, cue phrases, special characters, and a set of patterns for 
automatic extraction of the type of learning resource. The classifiers using neural 
network are designed to automatically extract the type of learning resource. They 
use the above-mentioned features of the text for identification of the type of the 
document. The presence of a set of verbs like illustrate, define, describe, discuss 
etc in a document are important features for identification of the explanation type 
of documents, but sometimes the same set of verbs may occur in the exercise type 
of documents. The declarative sentences containing these verbs are part of the 
explanation type documents. But when these verbs occur in an imperative sentence 
it might be a question sentence. If we simply consider the occurrences of the verbs, 
words and phrases without understanding the meaning of the sentences, these 
features will lead the classifier for wrong classification.  The set of verbs, cue 
words and phrases must be considered only from those sentences, which give 
correct interpretation for classification. Therefore it is necessary to know the 
semantic of sentences while considering the features from them. To know the 
semantic of sentences, they are parsed and analyzed using a link parser (Link 
Grammar, http://bobo.link.cs.cmu.edu/link/). The link parser gives the link type 
details between words of sentences. These link type details between words are 
further analyzed and based on some inference rules; the features are either 
considered or discarded. For identification of the type of learning resource, we 
have designed and experimented with two neural network classifiers. The 
classifiers are FeedForward backpropagation neural network classifier and 
Generalized regression neural network classifier. The performances of both the 
classifiers are tested. We have analyzed the misclassification errors.  
 
The algorithms are designed to extract metadata such as list of concept, its 
significance, the topic of the document and the grade level. The algorithms for 
Chapter – 1 
   
 
 - 18 -
automatic extraction of above set of metadata use the domain ontology maintained 
in our system. The domain ontology is a three level structure. The levels are topic 
level, concept level and term level. The topic level keeps the topic taxonomy. The 
topic concept relationships are kept in the domain ontology where the concepts 
covered by each of the topics of the topic taxonomy are kept separately. This 
domain ontology is used for automatic extraction of the topic and the grade level 
of the document. The second level of the ontology is the concept level. In the 
concept level, the relationships between concepts are maintained. The above 
knowledge helps in extraction of the list of concepts and their significance in the 
document. 
 
The type of concept identification algorithm uses the natural language processing 
of the text of the document. The presence of cue verbs and phrases in sentences 
with their associated semantics in conjunction with patterns are used to extract the 
type of concepts from the document. 
1.3.4  Information Retrieval from the Repository  
Learners can search documents from the repository. The search results can further 
be refined on different search parameters as required by a learner. The different 
search parameters on which the search can further be refined are the grade level 
and the type of learning materials. Learners can search learning materials like 
exercise type, experiment type, application type and explanation type of their grade 
level.  
 
We provide the facility of hierarchy browsing for navigation on topics. Learners 
can navigate through this topic-subtopic hierarchy and obtain learning materials on 
different topics.  
 
We wish to supplement the search results along with snippets. The snippet 
provides the summarization of the learning material that helps the leaner to identify 
the type of learning material according to his preferences. 
Chapter – 1 
   
 
 - 19 -
1.4    Organization of the Thesis  
The thesis has been organized into eight chapters as enumerated below. A brief 
summary of the contents of each of these eight chapters is as follows: 
 
Chapter 1 (Introduction): The first chapter discusses a general introduction to the 
problem along with the motivation and the objective of our work. The chapter also 
presents a small survey of the works that are relevant to our work. Moreover in this 
chapter the major contributions of the work have been listed. 
 
Chapter 2 (Related Work on Metadata Standards, Learning Object 
Repositories and Automatic Metadata Generation): This chapter provides the 
survey of the existing learning object repositories and the metadata standards. It 
also discusses the work done on automatic metadata extraction. 
 
Chapter 3 (Related work on Ontology, Student Modeling and Personalized 
Information Retrieval): This chapter discusses the work done on the various 
aspects of the personalized retrieval system. It provides the brief survey of the 
personalized retrieval systems, user modeling done in different systems and the 
ontology. 
 
Chapter 4 (System Architecture): This chapter provides the overall architecture 
of the system. 
 
Chapter 5 (Metadata Schema): This chapter discusses the identification of a set 
of metadata elements from the IEEE LOM specification that deemed to be the most 
useful for learning purposes. It discusses the uses and the characteristics of those 
metadata elements.  
Chapter 6 (Automatic Metadata Extraction): This chapter provides different 
algorithms for automatic extraction of metadata from documents. 
 
Chapter – 1 
   
 
 - 20 -
Chapter 7 (Personalized Information Retrieval for E-learning): This chapter 
discusses the personalized retrieval technique of our system. 
 
Chapter 8 (Conclusion and Future Work): This chapter concludes the 
achievements of the work in terms of the research goals. It also discusses the future 
work, which is to be carried out to attain the unattained goals.  
 
Chapter – 2  
 
Related Work on Metadata Standards, 
Learning Object Repositories & 
Automatic Metadata Generation 
 
2.1 Introduction 
Learning object repositories are the storage of variety of learning resources. 
Retrieving learning resources from learning object repositories to meet the 
learner’s requirement is a challenging area of research. Metadata is an important 
step towards the semantic tagging of learning materials. Using descriptive 
metadata, i.e. document attributes, associated with learning materials substantially 
improve the efficiency and the accuracy of retrieval of learning materials.  
 
Learning materials associated with metadata also facilitates the interoperability 
between learning object repositories. Interoperability between repositories depends 
on the effective sharing of the metadata. For successful sharing of learning 
materials between information repositories, they should be annotated with some 
common metadata standard.   
 
Two main alternatives exist to annotate the learning objects with metadata. It can 
be done either manually or automatically. In the first alternative, the content 
developers or the experts manually tag the metadata values. In the second 
alternative, different machine processing information extraction algorithms tries to 
deduce the value of the metadata fields from the content of the learning object. 
Chapter – 2 
 
   
 - 22 -
 
In recent years, several open metadata standards have been emerged. The different 
metadata standards are discussed in Section 2.2. A survey of some of the available 
learning object repositories is provided in Section 2.3. In section 2.4, we have 
discussed the work done on automatic metadata extraction. 
2.2  The Meta-Data Standards  
The term "meta" comes from a Greek word that denotes "alongside, with, after, 
next". Metadata can be thought of as data about other data. The metadata system 
is common in libraries. The library catalog contains a set of records with elements 
that describe a book or other library items such as the author, title, date of 
creation or publication, subject coverage, and the index number specifying the 
location of the book on the shelf. Metadata is the internet-age term for 
information that librarians traditionally have put into catalogs, and it most 
commonly refers to the descriptive information about web resources. A metadata 
record consists of a set of attributes or elements, necessary to describe the 
resource.  
Although the concept of metadata pre-exists in the web, the worldwide interest in 
metadata standards and practices has exploded with the growth of e-learning and 
digital libraries or information repositories.  
 
The Dublin Core Metadata Initiative (DCMI, http://dublincore.org/) is an open 
forum engaged in the development of interoperable online metadata standards that 
supports a broad range of purposes and business models. The Dublin Core standard 
includes two levels: Simple and Qualified. The simple Dublin Core contains fifteen 
elements. The elements are Title, Subject, Description, Type, Source, Relation, 
Coverage, Creator, Publisher, Contributor, Rights, Date, Format, Identifier and 
Language. The qualified Dublin Core includes three additional elements Audience, 
Provenance and RightsHolder, as well as a group of element refinements (also 
called qualifiers) that refine the semantics of the elements in a way that may be 
useful in resource discovery. The Dublin Core metadata contains metadata 
Chapter – 2 
 
   
 - 23 -
elements useful for general purpose applications but it does not contain attributes 
describing the pedagogical perspective of a document. In order to cope with 
educational concerns, various other metadata standards have been defined such as 
IMS Metadata, SCORM Metadata, CanCore and IEEE Learning Object Metadata.  
 
The IEEE Learning Object Metadata (IEEE LOM, 
http://ltsc.ieee.org/wg12/index.html) aims to develop accredited technical 
standards, recommended practices, and guides for learning technology. This 
standard specifies learning object metadata. It specifies a conceptual data schema 
that defines the structure of a metadata instance for a learning object. For this 
standard, a learning object is defined as any entity digital or non-digital that may 
be used for learning, education or training. For this standard, a metadata instance 
for a learning object describes relevant characteristics of the learning object to 
which it applies. Such characteristics are grouped in General, Life cycle, Meta-
metadata, Educational, Technical, Rights, Relation, Annotation, and Classification 
categories. It is intended to reference by other standards that define the 
implementation descriptions of the data schema so that a metadata instance for a 
learning object can be used by a learning technology system to manage, locate, 
evaluate or exchange learning objects. 
 
The IMS Global Learning Consortium (IMS, http://www.imsglobal.org/) develops 
and promotes the adoption of open technical specifications for interoperable 
learning technology. The IMS Content Packaging Information Model defines a 
standardized set of structure that can be used to exchange the learning content. 
These structures provide the basis for standardized data bindings that allow the 
software developers and the implementers to create instructional materials that are 
interoperable across authoring tools, learning management systems, and run time 
environments. IMS learning resource metadata information, version 1.1, final 
specification is available at http://www.imsproject.org/metadata/mdinfov1p1.html. 
  
The Advance Distributed Learning Initiative (ADL, http://www.adlnet.org) aims to 
establish a distributed learning environment that facilitates the interoperability of 
Chapter – 2 
 
   
 - 24 -
e-learning tools and course contents on a global scale. The Sharable Content 
Object Reference Model (SCORM, http://www.adlnet.org/scorm/index.cfm) is a 
collection of standards and specifications adapted from multiple sources to provide 
a comprehensive suite of e-learning capabilities that enable interoperability, 
accessibility and reusability of web-based learning content. The SCROM is often 
described as a bookshelf that houses specifications that are originated in other 
organizations like ARIADNE, AICC, IMS and IEEE. The SCROM has three parts, 
Overview, Content Aggregation Model and the Run Time Environment. The first 
part covers the overview about the model, vision and the future. The second part, 
the Content Aggregation Model (CAM) covers many specifications. The first 
specification in the CAM (from IEEE/ARIADNE/Dublin Core and IMS) is the 
"Learning Object Metadata".  This is a dictionary of tags that are used to describe 
the learning content in a variety of ways.  The second specification in the CAM is 
the XML "binding" for the metadata tags (from IMS).  This defines how to code 
the tags in XML so that they are machine (and human) readable. The third 
specification in the CAM is the IMS Content Packaging Specification.  This 
defines how to package a collection of learning objects, their metadata, and the 
information about how the content is to be delivered to the user. Packaging defines 
how learning contents of all types can be exchanged between different systems in a 
standardized way. The third part is the Run Time Environment. During the 
evolution of the SCORM suite of specifications, a standardized way is needed for 
sending the information back and forth between the learner (content) and the 
learning management system. An application program interface is defined that 
provides a standard way of communication with the learning management system, 
regardless of what tools are used to develop the content. 
 
The CanCore Learning Resource Metadata Initiative (CanCore, 
http://www.cancore.ca/) enhances the ability of educators, researchers and students 
in Canada and around the world to search and to locate materials from online 
collections of educational resources. CanCore is fully compatible with the IEEE 
Learning Object Metadata standard and with the IMS Learning Resource Meta-
data specification 
Chapter – 2 
 
   
 - 25 -
2.3  Learning Object Metadata Based Repositories 
Learning objects are the content components that are meant to be reusable in 
different contexts. These learning objects are associated with metadata, so that they 
can easily be searchable and manageable. As the international standardization in 
this area is making a fast progress, the number of learning object repositories are 
also growing rapidly. A LOM repository or learning object repository stores both 
learning objects (LOs’) and their metadata.  
 
A learning object repository allows users to search and retrieve learning materials 
from the repository. It supports simple and advanced search, as well as browsing 
through the materials. In simple search, it returns the search results against the 
given input keywords. A learner needs to search specific learning materials 
according to his requirements. The advanced search allows users to specify values 
for specific metadata elements to filter learning materials to meet the user’s 
specific need. Browsing allows users to descend in a tree of disciplines and sub-
disciplines to access learning objects available in the repository. Here, we will 
discuss the features and characteristics of some of the existing learning object 
repositories. 
 
ARIADNE (ARIADNE, http://www.ariadne-eu.org), the European digital library 
project, was initiated in 1996 by European commission’s telematics for education 
and training program. Since then, an infrastructure has been developed in Belgium 
and Switzerland for the production of reusable learning content, including its 
description, distributed storage, and discovery, as well as its exploitation in 
structured courses. The core of this infrastructure is a distributed library of digital 
reusable educational components called the Knowledge Pool System (KPS). It is 
actively used in both academic and corporate contexts. The KPS content (Duval, 
2001) is oriented more toward technical science, strongly represented by computer 
science, economics, electronics, health science, transportation and life science. The 
KPS is a reference library. The KPS includes descriptions (metadata), as well as 
the documents themselves, making it easier to replicate documents across all nodes 
Chapter – 2 
 
   
 - 26 -
of the system, ensuring convenient access without excessive download times. The 
ARIADNE includes a set of metadata from general, technical and educational 
categories. The ARIADNE includes the traditional metadata title, author and 
publication date, which are generally used in a library. It includes metadata 
describing the technical characteristics of the document i.e. uncompressed size of 
the document and the requirements with respect to the computing platform. 
Educational metadata includes document type (active or expositive), format 
(questionnaire, simulation, hypertext and others), usage remarks (explaining how  
documents can be used in a sound way in a learning environment), didactical 
context and course level (describing the kind of learners for whom the document is 
intended), difficulty level, interactivity level, semantic density and pedagogical 
duration. A user can search learning materials using a tool SILO (search and index 
learning objects). It provides the facility of simple search using keywords, 
advanced search and federated search. Advanced search can be done on the 
document title, usage right, author’s name and the main concept. Federated search 
provides the facility of searching learning materials from other repositories namely 
MERLOT, EdNA, CGIAR along with the ARIADNE. The authoring tool of 
ARIADNE allows indexing of pedagogical materials and inserting them into the 
knowledge pool system.   
 
The National Science, Mathematics, Engineering, and Technology (SMET) 
Education Digital Library (NSDL) (SMETE, http://www.smete.org) is constructed 
to meet learner’s and educator’s need. The digital library offers direct access to the 
learning resources. It promotes learning through personal ownership and 
management of the learning process while connecting the learner with the content 
and communities of learners and educators. Users can create their profile and 
submit it to the repository. It recommends learning objects based on their profile 
and past user interaction with the repository. Contents and services provided 
through the digital library includes multimedia courseware, digital problem sets 
and exercises, educational software applications, related articles, journals and 
instructional technology services for educators/students, both commercial and non-
commercial, organized and labeled for the purpose of education and instruction. To 
Chapter – 2 
 
   
 - 27 -
search and obtain more precise learning resources from this digital repository, a 
user can give input to the different search fields apart from the keyword. The 
search fields are learning resource type (applet, case study, course, demonstration, 
educational games, images/diagrams/graphs, links, laboratory/experimental 
support, lecture/presentation, lesson plan, practical problems, exercise etc), grade 
(starting from primary education to higher education), title, author/creator, 
collection and the publication year. The search results shows the URL of the 
learning object along with meta information title, author, publisher, subject, 
description, grade, format, rating. It allows users to browse through the repository 
over subject headings.  
 
Multimedia Educational Resources for Learning and Online Teaching (MERLOT, 
http://www.merlot.org) is an open repository designed primarily for faculty and 
students. Links to online learning materials are collected here along with 
annotations such as peer reviews and assignments. The learning materials are peer 
reviewed by the reviewers. The primary purpose of these reviews is to allow the 
faculty from any institution of higher education to decide that the online teaching-
learning materials that they are examining will work in their course(s). Peer 
Reviews are performed by evaluation standards that divide the review into three 
dimensions: Quality of Content, Potential Effectiveness as a Teaching Tool, and 
Ease of Use. Each of these dimensions is evaluated separately. In addition to the 
written findings (review) by the reviewers, there is a rating for each of the learning 
materials with three dimensions (1-5 stars, 5 being the highest). A review must 
average three stars (or textual equivalent) to be posted to the MERLOT site. It 
provides the facility of simple search, advanced search and browsing by discipline. 
Advanced search can be done on fields subject, sub-category (topic), material 
types, title, content URL, description, primary audience, Technical format, 
learning management system, language and author. 
 
The Health Education Assets Library (HEAL, http://www.healcentral.org) is a 
digital library that provides freely accessible learning resources that meet the needs 
of today's health sciences educators and learners. The HEAL provides the facility 
Chapter – 2 
 
   
 - 28 -
of search, either with a simple keyword or with advanced search parameters. 
Advanced search can be done on parameters like learning resource type, title, 
description, contributors, medical subject heading, and primary audience. A user 
can browse learning materials by Medical Subject Heading (MeSH). A user can 
also view the detailed cataloging information (metadata) about the resource. The 
metadata schema is based on the international IEEE LOM standard and includes 
extensions specific to the health sciences. The health science specific elements in 
the HEAL metadata schema are Specimen Type (cell, tissue, organ, organ system), 
Radiograph (radiology technology used to generate the multimedia item), 
Magnification (magnification of microscopic image), Disease Process (indicate 
disease process), and Clinical History (clinical history of patient). In addition to 
the health science specific extensions, there is a set of elements which satisfy the 
functional requirement of the HEAL system. These are Inappropriate for minors, 
annotated (indicates that the multimedia is labeled or not), Context URL (The 
context in which the item can be used such as course, a case etc.) and the Context 
URL description. 
 
The Education Network Australia (EdNA, http://www.edna.edu.au/) online 
supports and promotes the benefits of internet for learning and training in 
Australia. It provides a database of learning resources useful for teaching and 
learning. One can search 20,000 educational resources for schools and for higher 
education. It offers standard and advanced search facilities. The EdNA advanced 
search provides the facility of searching on categories like Adult and Community 
Education (ACE), Vocational Education and Training (VET), General References, 
Higher Education, Educational Organizations, School Educations or all the above 
categories. Apart from the EdNA online repository, a user can search from other 
repositories like Government Education Portal, ABC online, Cultural and 
Recreation Portal, Gateway to Educational Materials (GEM), Multimedia 
Educational Recourses for Learning and Online Teaching (MERLOT), Picture 
Australia, UNESCO/NCVER database (VOCED), VLORN (Vocational education 
and training learning object repository. The EdNA Metadata standard (Metadata 
standard V1.1, http://www.edna.edu.au/edna/go/pid/385) is particularly formulated 
Chapter – 2 
 
   
 - 29 -
to meet the needs of the educational and training community. The EdNA Metadata 
Standard is based on the Dublin Core Metadata Standard. Consistent with the 
extensibility principles of Dublin Core, the EdNA Metadata Standard V1.1 
includes additional elements and element qualifiers for specific applications to the 
Australian education domain and to support the operational requirements of EdNA 
Online. The additional metadata elements are Audience (a category of users for 
whom the resource is intended), Approver (email of a person or organization 
approving the item for inclusion in EdNA Online), Category-Code (a numerical 
code derived from the database tables which support the EdNA Online browse 
categories), Entered (data item was entered as an entry in the online item database, 
used for management purposes), Indexing (to what extent should EdNA online 
spidering software follow links from this page), Review (a third party review of the 
resource), Reviewer (name of the person and/or organization or authority affiliated 
for reviewing), Version (version of the EDNA Metadata Standard applied). 
 
The iLumina (iLumina, http://www.ilumina-dlib.org) is a digital library of sharable 
undergraduate learning materials for chemistry, biology, physics, mathematics, and 
computer science. It provides the facility of simple search, advanced search and 
browsing of learning materials. The search can be done by giving keyword, subject, 
author, title, journal title, author/title, ISBN/ISSN numbers. A user can also fill 
options like type of material, language, year, sort etc. The search results are sorted 
according to the date or the title or relevance. The learning resources in iLumina 
are cataloged in the Machine-Readable Cataloging (MARC, 
http://www.loc.gov/marc/marcdocz.html) and National science digital library 
(NSDL,http://metamanagement.comm.nsdlib.org/overview2.html#NSDL)metadata 
formats, which capture both technical and education-specific information about 
each resource. NSDL metadata standard consists of Dublin Core set of 15 basic 
elements, their associated element refinements plus the three IEEE LOM elements 
recommended by the DC Education Working Group. 
 
The goal of the LearnAlberta Online Curriculam Repository (LearnAlberta.ca, 
http://www.learnalberta.ca/ ) is to create a collection of learning object repositories 
Chapter – 2 
 
   
 - 30 -
in the field of education with access through a set of linked portals. It contains 
learning materials for students of various grade levels raninging from kindergarten 
to grade 12. A user can search learning materials by giving keywords or can 
browse learning resources using grades. 
 
Campus Alberta repository of educational objects (CAREO, 
http://careo.ucalgary.ca/cgi-bin/WebObjects/CAREO.woa/wa/Home?theme=careo) 
is a learning object repository that holds links to learning objects, as well as some 
learning objects themselves. The entry page displays the newest and most popular 
learning objects . Users can search learning materials by giving keywords or can 
perform advanced search by giving extra fields like title, discipline, technical 
format, learning resouce type etc. Users can also browse learning objects based on 
the discpline. A personal profile give access to a workspace (My Objects) with 
bookmarks. A user can access a history of objects that  had been downloaded by 
him. 
 
The LydiaLearn (LydiaLearn, http://www.lydialearn.com/) is a commercial 
network  of learning object repositories where users can search for learning 
materials after registering. The metadata for each learning object describes 
ownership and price, and users can use Lydia’s transcation basket to buy learning 
objects.  
2.4  Metadata Generation  
High quality metadata is essential for reusability and for effective retrieval of 
learning objects. Metadata can be generated in any of these ways. 
2.4.1 Manual Metadata Generation  
The maintainer of the learning object repository generates metadata manually. 
Sometimes the author of the learning material submits the metadata, which is then 
assessed and organized by the maintainers. The learning materials in most of the 
learning object repositories discussed in section 2.3 are manually annotated. 
Chapter – 2 
 
   
 - 31 -
Manual annotation often results in a very high quality metadata but is a very time 
consuming and labor intensive activity. It is advantageous to describe a set of 
constantly changing and evolving learning materials with some degree of 
automation (Downes, 2004; Duval, 2004; Simon, 2004).  
2.4.2  Automatic Metadata Generation  
Automatic metadata generation depends on machine processing. The advantage of 
automatic metadata generation is that an automated tool can discover much more 
data much more quickly than human beings. 
 
Metadata harvesting and metadata extraction has been identified as two methods 
of automatic metadata generation. Metadata harvesting is the process of 
automatically collecting resource metadata already embedded in or associated with 
a resource. The harvested metadata is originally produced by humans or by semi-
automatic processes supported by the software. Metadata extraction is the process 
of automatically pulling metadata from the resource content. The resource content 
is mined to produce the structured standard metadata.  
 
Automatic metadata generation from learning materials is an upcoming and 
challenging area of research. Some work has been done on automatic metadata 
generation, which is discussed below. 
 
DC-dot (DC-dot, http://www.ukoln.ac.uk/metadata/dcdot/) is a metadata generator 
developed by UKOLN (UK Office for Library and Information Networking) based 
at the University of Bath. The DC-dot is open source and can be redistributed or 
modified under the terms of the GNU General Public License as published by the 
Free Software Foundation. The DC-dot produces Dublin Core metadata and can 
format output according to the number of different metadata schemas like 
USMARC, RDF, and IMS etc. Metadata creation with the DC-dot is initiated by 
submitting a URL. It copies resource identifier metadata from the web browser’s 
address prompt, and harvests title, keywords, description, and type metadata from 
Chapter – 2 
 
   
 - 32 -
the resource’s META tags. If resource META tags are absent, DC-dot 
automatically generates keywords by analyzing anchors (hyperlinked concepts) and 
by using presentation encodings (font size, bold words). It also generates type, 
format and date metadata automatically.  
 
Han et al. (Han, 2003) proposes a machine learning method using support vector 
machine for automatic metadata extraction of Dublin Core Metadata. Sometimes 
the metadata standard does not meet the requirements of a particular learning 
system and requires local extensions and modifications. Han et al. have extended 
the Dublin Core metadata and included additional metadata author’s affiliation, 
author’s address, author’s email, publication number and thesis type. These 
additional metadata helps in building unified services for heterogeneous digital 
libraries, while at the same time enabling sophisticated querying of the databases 
and facilitating construction of the semantic web. The reported metadata extraction 
results are based on the experiments conducted on research papers. Most of the 
information like author’s name, affiliations, address, and the title are collected 
from the header of the research paper. The header consists of all the words from 
the beginning of the paper up to either the first section, usually the introduction, or 
to the end of the first page, whichever occurs first. They have illustrated the 
dominance of SVM based metadata extraction algorithm over Hidden Markov 
Model based systems. They have also introduced a method for extracting 
individual names from the list of authors within the same network and present a 
document extraction method using SVM classification, combining chunk 
identification. A new feature extraction method and an iterative line classification 
process using contextual information are also introduced in their work. 
 
The work by Jenkins C. and Inman D. (Jenkins, 2000) propose a technique for 
automatically generating qualified Dublin Core metadata (DCMI, 
http://dublincore.org/) on a web server using a Java Servlet. The metadata is 
structured using the Resource Description Framework (RDF, 
http://www.w3.org/RDF/) and expressed in Extensible Markup Language (XML, 
http://www.w3.org/XML/). The description covers ten out of fifteen standard 
Chapter – 2 
 
   
 - 33 -
metadata. The metadata elements are title, creator, subject, description, publisher, 
date, format, identifier, relation, and rights. When the URL of a document is 
passed to the servlet, it harvests the title, date, and format from the html tags. The 
metadata description is represented by an abstract, which are the first 25 words 
found in the body of the document. The metadata subject is represented by a series 
of keywords. The keywords are extracted by parsing the actual content. The 
metadata relation is used to represent a resource that is hyper-linked from the 
current resource. 
 
Another work by Li y., Zhu Q., and Cao Y. (Li, 2004) also automatically generates 
the qualified Dublin Core metadata from web pages. It extracts total 10 metadata 
elements from web pages. The 9 elements title, creator, description, publisher, 
date, format, identifier, relation and rights are generated by the same techniques as 
used by Jenkins C. and Inman D. The subject element is obtained using neural 
network. The subject element of a resource is a term weight vector in 
multidimensional space, which represents the whole content of the resource. In the 
vector, each word is assigned a weight, which represents its degree of importance. 
The principal component analysis (PCA) technology of neural network is used to 
select the effective terms to represent a resource. 
 
In the above few paragraphs, we have discussed the work on the automatic 
extraction of Dublin Core metadata useful in general purpose applications. There is 
a need to extract attributes describing the pedagogical perspective of a document to 
cope with educational concerns. The IEEE LOM standard contains attributes 
describing the pedagogic characteristics of the document. The work has been 
started on automatic extraction of the educational category metadata elements of 
the IEEE LOM specification. 
 
Jovanovic et al. (Jovanovic, 2006a) present an ontology-based approach for 
automatic annotation of learning objects based on IEEE LOM. In their work, the 
metadata elements title, description, unique identifier, subject and pedagogic role 
are automatically generated from the learning object.  They mainly used content 
Chapter – 2 
 
   
 - 34 -
mining algorithms and certain heuristics for determining these metadata elements 
to annotate the learning content.  They have annotated documents only in slide 
format. The whole document forms the learning object and the different slides of a 
document forms the content object. In their work, they focus on smaller units for 
reusability on a finer scale and annotated each slides (content objects) of a 
document along with the whole document (learning object). The metadata element 
title of the content objects is simply extracted from the title of the slides. If the 
slides do not have the title, then those instances of content objects do not assigned 
the title element. The subject annotation of content objects depends on the author’s 
supplied information. The subject annotation of each of the content objects (or 
slides) is based on domain ontology and derived from the subject metadata 
provided by the author during submission of the learning object. In their work, they 
automatically generate the pedagogic roles like example, summary and references. 
To infer the pedagogic role of the learning content, they opted heuristic based 
approach. To identify the pedagogic role, they observed the presence of some 
specific terms along with some patterns. If the title of the slide contains terms like 
summary, conclusion and the body of the slide is structured in the form of a list, 
the slide is annotated with pedagogic type summary. Similarly in the case of 
reference type, the learning content contains terms like references, reference list, 
bibliography etc. The description of the whole learning object is generated by 
combining the different attributes like type, title, subject creator, and date etc. 
 
Kris Cardinaels et al. (Cardinaels, 2005) developed a framework for automatic 
metadata generation of IEEE Learning Object Metadata as a web service. They 
tried to generate a metadata set that contains all the mandatory elements defined in 
the ARIADNE (ARIADNE, http://www.ariadne-eu.org) application profile. 
Metadata elements are document type, package size, publication date, creation 
date, operating system type, access right, main discipline, language, format, title, 
and author’s detail. Author’s detail includes his postal code, affiliation, city, 
telephone, department, and email. They proposed an idea of deriving metadata 
from two different sources. The first source is the learning object itself; the second 
is the context in which the learning object is used. Metadata derived from the 
Chapter – 2 
 
   
 - 35 -
object itself is obtained by the content analysis, such as keyword extraction, 
language classification and so on. The contexts typically are learning management 
systems in which the learning objects are deployed. A learning object context 
provides the extra information about the learning object that can be used to define 
the metadata. The proposed framework for automatic metadata generation consists 
of two major groups of classes, namely Context-based indexers and Object-based 
indexers. As discussed above, the Context-based indexers use a context to generate 
metadata. When an object is used in a specific context and the data about that 
specific context are available, then these data gives the information for annotation 
of the object. The Object-based indexers generate metadata based on the learning 
object itself, isolated from any other learning object or learning management 
system. A Metadata-Merger combines the results of the different indexers into one 
set of metadata. 
 
Dehors et al. (Dehors, 2005) have proposed a methodology for semi-automatic 
annotation of learning resources based on the document layout features. They 
assume that every course is based on a learning or pedagogical model, which 
includes some pedagogical strategy. So, first the author is asked to explicit the 
pedagogical strategy for his/her course.  The annotation task begins by 
interviewing the author of the document to determine the relations between the 
employed presentational model of the existing document and how this model 
supports the envisioned educational strategy. Once, this model is defined, a phase 
of content re-authoring takes place to ensure that the employed visual features are 
compliant to the established instructional model. Only then it is possible to 
automatically identify and annotate content units according to their pedagogical 
role. The employed pedagogical ontology is generated on the fly and includes 
concepts that formalize elements of a content author’s specific pedagogical 
strategy. Although this approach tends to be more precise in recognition of 
instructional roles of content units, but it requires more human effort: interviewing 
the author and content re-authoring.  
 
Work has been done on the semantic annotation of web documents with general 
metadata information. The KIM platform (Popov, 2003) provides a novel 
Chapter – 2 
 
   
 - 36 -
knowledge and information management infrastructure and services for automatic 
semantic annotation, indexing, and retrieval of documents. The KIM platform is 
based on the PROTON ontology (http://proton.semanticweb.org/) and a knowledge 
base providing extensive coverage of entities of general importance. They worked 
on the automatic semantic annotation on general type of metadata information such 
as organization, person, date, location, percent, and money.  
 
Piggy Bank (Huynh, 2005) is a tool integrated into the contemporary web browser 
that lets users to collect information from various websites, presents them in an 
ontology based format and annotate them with metadata. It invokes the 
screenscrapers to re-structure information within web pages into semantic web 
format (RDF format). Semantic Bank is a repository of RDF triples to which a 
community of PiggyBank users can contribute and share the information they have 
collected. 
2.5  Summary 
In this chapter, we have discussed open metadata standards for interoperable 
learning technologies. The discussed metadata standards are as follows. 
 
1. Dublin Core, (Dublin Core, http://dublincore.org/) 
2. IEEE Learning Object Metadata,  (LOM, 2002, 
http://ltsc.ieee.org/wg12/index.html) 
3. IMS learning resource metadata information, version 1.1, (IMS, version 
1.1, http://www.imsproject.org/metadata/mdinfov1p1.html.) 
4. The Sharable Content Object Reference Model (SCORM, 2004, 
http://www.adlnet.org/scorm/index.cfm) 
5. CanCore Learning Resource Metadata Initiative (CanCore, 2000, 
http://www.cancore.ca/) 
 
We have surveyed most of the available learning object repositories. The learning 
objects in the repositories are associated with metadata, so that they can be 
properly managed and searched. We summarize the different learning object 
Chapter – 2 
 
   
 - 37 -
repositories we surveyed, with a comparative analysis of their features and 
characteristics in Table 2.1.  
 
Table 2.1 Comparative study of learning object repositories 
Features  
Learning 
Object 
Repository 
Meta-
data 
Standard 
Metadata 
annotation 
Simple 
Search 
Advanced  
Search 
Browsing 
  
Subject  
Domain 
Peer 
Review 
Personal 
Features 
LO   
Store 
 
ARIADNE IEEE  
LOM 
Manual and 
Automatic 
Metadata 
Generation 
Keyword 
search  
Advanced search 
on 
-Document title 
-Usage right 
-Author’s name
-Main Concept 
No All Yes Metadata 
Templates 
Document 
Repository 
 
SMETE IEEE  
LOM 
Manual Keyword 
search 
Advanced search 
on 
-Keyword,  
-Learning 
resource type  
-Grade 
-Title 
-Author 
- Collection 
- Publication 
year 
Browse by 
discipline 
Science, 
Mathematics, 
Engineering, 
Technology 
No Workspace, 
Recommendat
ions 
Links  
MERLOT IEEE  
LOM 
Manual Keyword 
search 
Advanced search 
on 
- Subject 
- Subcategory 
- Material type 
- URL 
- Description 
- Primary 
Audience  
- Technical 
format 
- Language 
- Author’s name
Browse by 
discipline 
Education Yes N/A Links  
HEAL LOM  
LOM 
Manual Keyword 
search 
Advanced search 
on 
-Learning 
resource type 
-Title 
-Description 
-Contributors 
-Medical subject 
heading term 
Browse by 
Medical 
subject 
heading or 
by 
collection 
Health 
Science 
No N/A Links  
EdnA Dublin 
Core 
profile 
Manual Keyword 
search  
Advanced search 
on 
-Adult & 
community 
education 
-Vocational 
education & 
training 
-General 
references 
-Higher 
Browse by 
discipline 
Education No N/A Links  
Chapter – 2 
 
   
 - 38 -
education 
-Educational 
organizations 
-School 
education 
iLumina IEEE  
LOM 
Manual Simple 
search on 
- Keyword 
- Subject 
- Author 
-Journal 
title 
-ISBN/ 
ISSN 
number 
Advanced 
Search on  
-Type of 
material 
- Year 
- Language 
 
  
Browse   
by 
discipline, 
subject, 
topic 
Science, 
Mathematics, 
Engineering 
& 
Technology 
Plan to 
create peer 
review, 
rating and 
recommen
dation  
N/A Links  
Learn-
Alberta 
IEEE  
LOM 
Manual Keyword 
search 
N/A Browse by 
grades 
All  Yes N/A Document 
Repository 
 
CAREO IEEE  
LOM 
Manual Keyword 
search 
Advanced search 
on  
-Title 
-Description 
-Keyword 
-Discipline 
-Technical 
format 
-Learning 
resource type 
-Intended user 
role 
Browse by 
discipline 
All No Workspace, 
Download 
history 
Document 
Repository
+ 
Links 
 
Lydia IEEE  
LOM 
Profile  
(SCROM
) 
Manual Keyword 
search 
N/A N/A All No Transaction 
basket, 
Purchase, 
History 
Document 
Repository 
 
 
 
As discussed, there are two ways of generation of metadata, manual and automatic. 
In our work we emphasis on automatic generation of pedagogic metadata elements. 
As per our knowledge, too much research work has not been done in the field of 
automatic generation of pedagogic metadata elements. The summary of the related 
work done in automatic metadata generation is given below. 
  
1. DC-dot metadata generator, (http://www.ukoln.ac.uk/metadata/dcdot/) 
2. A set of Dublin core metadata generation using support vector machine, 
(Han, 2003) 
3. Qualified Dublin core metadata generation using servlet, (Jenkins, 
2000) 
4. Qualified Dublin core metadata generation, (Li, 2004) 
5. A set of IEEE LOM metadata generation, (Jovanovic, 2006) 
Chapter – 2 
 
   
 - 39 -
6. A set of IEEE LOM metadata generation, (Cardinaels, 2005) 
7. Semi-automatic annotation of learning resources with instructional roles 
based on the document layout features, (Dehors, 2005) 
8. The semantic annotation of web documents with general meta 
information (Popov, 2003) 
9. Annotation of web pages in semantic web format, (Huynh, 2005) 
 
 
 
 
 
 
 
 
 
 
Chapter – 3  
 
Related Work on  
Ontology, Student Modeling & 
Personalized Information Retrieval  
 
3.1  Introduction 
The success of any e-learning system depends on the organization of learning 
objects with specific knowledge and the retrieval of relevant learning materials. E-
learning can be truly effective when it provides a learner centric personalized 
learning experience. This leads to the development of the personalized retrieval 
system, which provides learning materials considering the requirements of the 
learner. The block diagram of a typical personalized retrieval system is shown in 
Figure 3.1 A typical personalized retrieval system 
Chapter – 3 
 
   
 - 41 -
figure 3.1. There has been research on various aspects of the personalized retrieval 
system such as domain knowledge, student model and different information 
retrieval techniques for personalized delivery of learning resources.  
 
For the development of any flexible educational system, the domain ontology plays 
a crucial role (Song, 2005; Tan, 2004). The ontological structures can be used for 
organizing, processing and visualizing subject domain knowledge, marking the 
topic and coverage of learning objects, and for building learner models in e-
learning systems. The domain ontology can be used for concept-based domain 
specific information retrieval, visualization, and navigation that help learners to get 
oriented within a subject domain and build up their own understanding and 
conceptual association (Aroyo, 2001; Hubscher, 2002).   
 
The model of the student is an integral part of any system aiming at personalized 
information delivery. Student modeling can be described as a process of building 
the personal preferences of users in terms of the student’s knowledge about the 
subject, his behavioral aspects, goals, likes and dislikes. The model of a student is 
generally represented in the form of a student profile, which captures the personal 
preferences in a machine process able format. So, the student model can be seen as 
an abstract entity and the student profile represents an instantiation of the student 
model for a particular user. The different research works differs in the way they 
represent the student profile, how they update the student model and the strategies 
they adapt for providing the personalized information. 
 
The personalized retrieval module of any information retrieval system is 
responsible for retrieving specific learning resources customized to the need of the 
student. The information retrieval techniques vary from system to system.  
 
We have developed an annotation tool for developing a repository of learning 
materials and a retrieval module for retrieving learning materials from the 
repository. We emphasize on the retrieval of learning materials with the use of 
domain knowledge and the learner’s profile to retrieve learning materials 
Chapter – 3 
 
   
 - 42 -
according to the learner’s requirements and the learner’s current state of 
knowledge. In order to annotate the learning materials automatically and to allow 
the system to remain flexible, the basic structure of our system is based on the 
domain ontology. 
 
In this chapter, we have discussed the related work on various aspects of the 
personalized retrieval systems such as the domain knowledge, the student model 
and the different information retrieval techniques for personalized delivery of 
learning resources. In Section 3.2, we discuss the use of ontology in various 
applications by different systems. Section 3.3 deals with the related work done in 
the area of student modeling. In Section 3.4, different information retrieval systems 
providing personalized information to the user in different application domains are 
discussed. Personalization and adaptive presentation is especially important in 
education domain. Some of the available adaptive learning systems are discussed 
in Section 3.5. 
3.2  Ontology 
Ontology (Guarino, 1998; Corcho, 2001) refers to the shared understanding of a 
domain of interest and is represented by a set of domain relevant concepts, the 
relationships among the concepts, functions and instances. The definition of 
ontology given by Gruber (Gruber, 1993) is as follows 
       “A ontology is a formal, explicit specification of shared conceptualization.”  
Conceptualization is the abstract representation of a real world entity with the help 
of domain relevant concepts. Ontology should be formal so that it becomes 
machine understandable and it should enable shared communication across the 
communities. Ontology can be viewed as a vocabulary containing the formal 
description of terms and a set of relationships among the domain relevant concepts. 
The basic requirements for building a ontology are 
 
• Identifying relevant domain entities to be included in the ontology.  
Chapter – 3 
 
   
 - 43 -
• Establishing formal description of the domain entities and relationships 
among the entities.  
 
Currently, ontology has emerged as a very important discipline as its usefulness 
has been demonstrated in various types of applications, which include information 
organization and extraction, personalization, natural language processing, artificial 
intelligence, knowledge representation and acquisition. As a shared and common 
understanding of the domain, the ontology can play an important role in 
applications, which require communication between the user and the system. 
According to Lee (Lee, 2001), the ontology is going to play a major role in the 
evolution process of the world wide web to the Semantic Web. The ontology can 
act as the metadata representing the semantics of a page in a machine-
understandable way.  
 
Several ontologies have been developed in various domains for various purposes. 
They differ in the way the ontology is structured, the ontology representation 
language that has been used to represent the ontology and the application domain. 
The uses of the ontologies in various applications are discussed below. 
 
Dicheva et al. (Dicheva, 2004a; Dicheva, 2004b; Dicheva, 2005) proposed a 
framework for building a concept-based digital course library where subject 
domain ontology is used for classification of course library content. To create 
adaptive and modularized courses Hoermann (Hoermann, 2003) used learning 
object metadata together with a well-defined knowledge base.  
 
In the work of ontology based automatic annotation of learning content (Jovanovic, 
2006a), ontology is used to annotate learning objects with metadata. Similarly 
Gasevic et al (Gasevic, 2005) have also used domain ontology for semantically 
marking up the content of a learning object 
 
The work by Baumann and others (Baumann, 2002) has used ontology for 
document retrieval. They have kept two types of relationships in the ontology. The 
Chapter – 3 
 
   
 - 44 -
relations are “is a” and “part-of” relation. The relation “is a” is used to indicate 
specializations of concepts while the “part-of” relation denotes the required sub-
concepts for understanding a given concept. The document retrieval technique is 
based on the vector space model. The documents and the queries are represented as 
vectors. They have used the cosine similarity measure to compute the angle 
between the document vectors to find similarity between the documents. 
 
Pretschner et al. have (Pretschner, 1999) developed an ontology based personalized 
search system. In this system, the user’s interest is incorporated into the search 
process to improve the search results. The user’s interest is inferred by analyzing 
the web pages that the user visits. The system uses an existing ontology from 
Magellan, which has 4400 nodes. Each node is associated with a set of documents. 
All documents are merged into a super document and represented as a weighed 
vector using the vector space model. To find the web pages of the user’s interest, 
the system creates keyword vector for each of the web pages visited by the user. 
These page vectors are compared with the keyword vector associated with every 
node of the ontology to calculate the similarity. The nodes with the top matching 
vectors are assumed to be the user’s interest.   
 
Aitken S. and Reid S. (Aitken, 2000) evaluated the use of domain ontology in an 
information retrieval tool and showed that the retrieval using ontology gives higher 
precision and recall as compared to the simple keyword based retrieval without 
using ontology. They store the ontology in a hierarchical structure. They use the 
ontology of a particular domain, which consists of taxonomy of domain concepts. 
It maintains two types of relations between domain concepts. The relations are “is 
a” and “part of” relation. Lexical terms, which are used to identify concepts from 
the document content, are also part of the ontology. The ontology contains 244 
concepts (classes), 264 subclass relations, 104 “part of” relations and 256 
“concept to term” relations. The lexical terms, which are associated with the 
concepts, are used to extract the ontology concepts from the document content. 
The same procedure is applied to the user’s query. The system maps the document 
Chapter – 3 
 
   
 - 45 -
and the query to the ontology concepts. The concepts present in a document and 
the concepts present in the query words are checked to calculate the relevance. 
 
The work of Chaffee (Chaffee, 2000) explores a way to use the user’s personal 
arrangement of concepts to navigate the web. They have used the existing ontology 
based informing web agent navigation (OBIWAN) system and mapped them to the 
user’s personal ontology. OBIWAN allows the users to explore multiple sites via 
their own personal browsing hierarchy. The mapping of the reference ontology to 
the personal ontology is shown to have a promising level of correctness and 
precision. 
3.3 Student Modeling  
The knowledge about personal traits, skill levels, and learning material access 
patterns of students is the most important aspect of learner centric adaptive 
systems. A key requisite for intelligence and adaptation in a learning environment 
is student modeling. Looking to their own models and reflecting upon the content 
can benefit students themselves. Considering students as an active and integral part 
of a learning process, the student models become powerful tools that offer 
important opportunities to engage students in meaningful learning experiences.  
 
IMS has defined a standard model for learners called IMS learner information 
packaging (LIP) model. IMS LIP is based on a data model that describes the 
characteristics of a learner needed for learner modeling. The characteristics are  
 
• Recording and managing learning-related history, goals, and 
accomplishments 
• Engaging a leaner in a learning experience 
• Discovering learning opportunities for the learner 
 
In this section, we discuss how the characteristics of a learner can be modeled in 
different adaptive learning systems.  
Chapter – 3 
 
   
 - 46 -
 
Han B. et al (Han, 2003) have developed student model for web based intelligent 
educational system. The student knowledge is represented by an overlay model, in 
which the current state of the student’s knowledge level is described as a subset of 
the domain model. The domain independent part of individual student model 
includes the student’s personal information, background and preferences of 
learning style. The domain specific part contains the student’s competence level 
for each concept node, each unit in the content tree and his overall subject 
competence level. A group student model is constructed by averaging 
corresponding values in the models of all individual students within a group. The 
student model is initialized by simple but carefully designed questionnaires, which 
is presented to the student in the first session. 
 
In AHAM (Bra, 1999), the student model is also based on overlay model. The 
concepts known to the user and the user’s knowledge about each concept are stored 
in the student model. The user’s knowledge is a vector in a high dimensional 
space.  It maintains a log of visited (concepts covered by those pages) pages. The 
user’s model is updated by the system each time the user visits a page.  
 
In many learning systems, learners are allowed to interact and update their own 
learning model. In NetCoach (Weber, 2001a) student’s state is updated either on 
the basis of test performance or a student can himself update by marking concepts 
known to him. Similarly Dimitrova et al. (Dimitrova, 1999) explored a 
collaborative construction of student models promoting student's reflection and 
knowledge awareness. 
 
The student model generally includes the student's knowledge about the concepts 
in some particular domain, learning preferences (e.g. learning style), and various 
aspects that affect the learning performance and skill level. The learning style of a 
learner is not expected to change too dynamically, but the learning performance or 
skill level changes in short time durations. The work by Shi H. et al. (Shi, 2002) 
consider the above assumption and the learner modeling is done on two different 
Chapter – 3 
 
   
 - 47 -
time scales: long term and short term modeling. The long term modeling attempts 
to model those aspects of a learner that are not expected to change too 
dynamically. In their work, the short-term modeling is also being performed in two 
ways: indirectly and directly. Indirect short term modeling includes counting the 
number of times a learner reviews a learning object, measuring the total time taken 
to complete the topic. Direct short-term modeling is carried out by assessment on 
questionnaires that evaluates the learner performance as a skill level. The skill 
levels are Beginner, Novice, Intermediate, Advanced and Expert. 
 
In the IRIS Shell (Arruarte, 1997), the learner characteristics are separated into two 
groups: curriculum and learner profile. The former refers to the general and 
professional aspects of the learner and the latter refers to the characteristics that 
influence the learning process. The learner’s goal is selected directly by the 
instructor from a predefined set. The learner model is organized in two parts 
permanent model and dynamic model. The permanent model is updated at the end 
of each session and is divided into three sections: learner characterization, learner 
knowledge and learner history. The learner characterization consists of the 
curriculum-vitae and the learner profile. The learner knowledge records the 
domain contents acquired by the learner during the learning process. Finally  the 
learner history consists of information about the evaluation process of the last 
session and the collection of the most important events of the whole course. The 
dynamic model exists just during the current session and is used for updating the 
permanent model. It is divided into two components: session characteristics, i.e. 
events occurring up to the current moment in the session, and learner performance, 
which contains interaction information about the learner such as texts presented, 
requests made and so forth. 
 
 
Most of the modeling approaches mentioned above are relatively simple. The 
models are slots and values, feature vectors or simple overlays. More complicated 
representational formalisms, such as Bayesian belief networks can be effectively 
used to construct student models. Several researchers in different areas have 
Chapter – 3 
 
   
 - 48 -
explored the use of Bayesian belief networks to represent student models (Henze, 
1999; Conati, 2002; Zapata- Rivera, 2004b).  
3.4  Personalized Information Retrieval Systems 
Many publicly available filtering systems, personalized search and personalized 
web navigation agents are available. Some of them are discussed below. We 
mainly discuss the how the user profile is represented and used for personalized 
retrieval.  
 
The Stanford Information Filtering Tool (SIFT), developed by Yan at Stanford 
University (Yan, 1995), includes two selective dissemination services, one for 
computer science technical reports and other for USENET news articles. It 
provides the users with personalized information by looking at the aspect of user 
interest modeling. The user profile is represented by a weighted vector of 
keywords and specified during the subscription procedure. No idea of adaptation is 
apparent here.  
 
The Krakatoa Chronicle (Kamba, 1995) is a personalized newspaper on the World 
Wide Web. To obtain personalized news item, it maintains user profile, which 
reflects the personal interest of the user.  
 
The SmartPush (Kuki, 1999) is a personalized news delivery system, which 
depends on a special type of content authoring. Each document is augmented with 
metadata in an ontological form that describes the content. User profile is 
represented by the hierarchy of concepts or ontology and is created explicitly by 
the user or by choosing from, a set of default profiles. The user profile and the 
metadata in each document are matched to decide on the relevance of the 
document. 
 
In the above few paragraphs, we have discussed some of the available personalized 
information filtering systems. A lot of work has been done on the development of 
Chapter – 3 
 
   
 - 49 -
personalized web navigation agents and a few of them are discussed here. SiteIF 
(Stefani, 1998) and ifWeb (Asnicar, 1997) aim to provide personalized search and 
navigation support. IfWeb is a user model based intelligent agent that provides the 
support for navigation of world wide web and also for document search according 
to the need of a user.  The user profiles are represented as weighted semantic 
networks of nodes and the relations between nodes are derived from the co-
occurrence criteria of related terms in some documents. The user profile is updated 
by relevance feedback. The system keeps the measure of disinterest and the idea of 
temporal decay of interesting terms.  
 
A lot of work has been done of the development of collaborative filtering systems. 
Collaborative filtering attempts to address information overload by forming 
recommendations based on the opinions of other people who have seen 
information items. The GroupLens project (Konstan, 1997) provides personalized 
collaborative filtering for Usenet news.  
 
The WebWatcher (Armstrong, 1995; Joachims, 1997) is a collaborative system 
that assists the user as he or she browses the Web. When a user browses the world 
wide web, it provides important suggestions in choosing relevant hyperlinks by 
analyzing the past experiences. The user profile is represented as a list of keywords 
and is provided by the user in the beginning of the tour. If the interest of other 
users matches sufficiently with the list of keywords in a link, that link is suggested. 
WebWatcher is a hybrid model of individual and collaborative system. Personal 
WebWatcher (Mladenic, 1998) is an individual system that is based on 
WebWatcher (Joachims, 1997), but it avoids involving the user in its learning 
process because it does not ask the user for keywords or opinions about pages.  
 
Syskill & Webert (Pazzani, 1996) also recommends interesting web pages using 
explicit feedback. If the user rates some links on a page, Syskill & Webert can 
recommend other links on the page in which they might be interested. Starting 
from a manually constructed index pages for a particular topic, the user can rate the 
hyperlinks of these pages. The system uses the rating to learn a user specific topic 
Chapter – 3 
 
   
 - 50 -
profile that can be used to suggest unexplored hyperlinks on the page. It uses 
Lycos to retrieve pages by turning the topic profile into a query. Search process is 
carried out, by simply annotating the search results returned by Lycos with proper 
ratings and the recommendation is done by annotating links in the index page for a 
topic. 
 
In this section, we have discussed various personalized information retrieval 
systems helpful in various applications like retrieving personalized news items, 
providing support for navigation of world wide web, searching documents from the 
web according to the need of the user. Personalized and adaptive retrieval is 
equally important in retrieving learning materials according to the need of a learner 
and researchers have developed many adaptive learning systems to support 
learners. In the next section, some of the available adaptive learning systems are 
discussed. 
3.5  Adaptive Learning Systems  
Recent years witnessed a growing interest in development of adaptive learning 
systems where learning materials are selected and presented in adaptive manner, so 
as to fit each single user as much as possible.  
 
In 1996, Brusilovsky et al. have developed ELE-PE (Brusilovsky, 1996), which 
provides an educational example based programming environment for learning 
LISP. The knowledge based programming environment ELE-PE was designed to 
support novices who learn the programming language LISP. They have used the 
collaborative approach where the user and the system collaborate in the process of 
example selection. For several years, ELE-PE was used in introductory LISP 
courses at the university of Trier. But the limitation of ELE-PE is that it is platform 
dependent and requires powerful computers for its implementation. This limitation 
obstructed a wider distribution and usage of the system. To overcome the above 
limitations, work has been done on the development of web based learning systems 
Chapter – 3 
 
   
 - 51 -
and a number of web based adaptive learning systems have been developed. Some 
of the web-based learning systems are discussed below. 
 
In 1998, Hockemeyer et al. (Hockemeyer, 1998) developed adaptive tutoring 
software (RATH), which combines a mathematical model for the structure of 
hypertext document with the theory of knowledge space. In the knowledge base, it 
maintains prerequisite relation between learning objects. Using this prerequisite 
relation between learning objects and the student model, it presents only those 
links in a hypertext document to the student for which he knows the entire 
prerequisites.  
 
KBS hyperbook (Henze, 1999) is implemented for an introductory course on 
computer science. The adaptation techniques used for this course are based on a 
goal driven approach. This allows students to choose their own learning goal and 
get suggestions for suitable information units required to reach the learning goal. 
The elementary unit of the hyerbook model is knowledge item. A knowledge item 
denotes a knowledge concept of the application domain. All knowledge items are 
connected in a dependency graph. These knowledge items are used for indexing the 
contents of the information units and for describing the range of goals. The 
information units are semantically related to other information units. The semantic 
relationships between the information units generate the navigational structure. 
The navigational structure is annotated as “already known”, “suggested” and “too 
difficult” according to the current knowledge of the reader.  
 
ELM adaptive remote tutor (Weber, 2001b) is the WWW based version of ELE-PE 
(Brusilovsky, 1996). It removes the limitations of ELE-PE and provides learning 
materials online in the form of an adaptive interactive textbook. It provides 
adaptive navigation support, course sequencing and problem solving support. The 
adaptation component of ELM_ART uses the information about prerequisite and 
outcome knowledge, which is available with the hypermedia documents. Course 
sequencing obtains the best next step to continue with the course. The algorithm 
which selects the best next step for a particular user works as follows: starting from 
Chapter – 3 
 
   
 - 52 -
the current learning goal, the system recursively computes all prerequisites that are 
necessary to fulfill the goal. The first concept belonging to the set of prerequisites 
that are not learned by the learner is selected and offered to the learner. The learner 
completes one course successfully when he learns all the prerequisites to the 
current goal. 
 
In ELM_ART, each document is annotated with metadata information, which 
gives the information about the prerequisite and outcome of that document. 
NetCoach (Weber, 2001a), the successor of ELM_ART maintains a knowledge 
base. The knowledge base consists of concepts and these concepts are the internal 
representations of the pages. The concepts are interdependent. NetCoach can be 
used via the web and offers templates to describe pages, to add exercises and test 
items, to adjust the interface and to set parameters that influence different features 
of the courses. With NetCoach, authors can create fully adaptive and interactive 
web based courses. The author creates content specific relations like prerequisite 
and inferences for every concept.  The system guides the user to learn the 
prerequisite pages before suggesting the current concept. The knowledge base 
delivers information for adaptation by giving predecessors and successors for each 
document in the document space.  
 
The work by Shang Yi et. al  (Shang, 2001) present an intelligent agent for active 
learning. A student’s learning related profile such as his learning style, background 
knowledge and the competence level are used in selecting and presenting the 
learning materials.  
 
Metalinks (Murray, 2003) is an authoring tool and also a web server for adaptive 
hypermedia. The pages visited by the user are kept track of by the system. On the 
main page, a mark appears indicating whether the user has previously seen that 
page. It uses tree structure (parent, child and sibling) to organize the content. A 
parent page is the summary, or the overview, or the introduction of all of its 
children pages. Child nodes of any page cover the material in greater depth while 
the sibling pages contain the material at the same level. The next page that a user 
Chapter – 3 
 
   
 - 53 -
can access is calculated by finding the siblings of the pages he has visited. Thus the 
sequencing is breadth first rather than depth first and is called as horizontal 
reading. A pop-out menu "Related links exist for this page" is provided to 
encourage the users to inspect the pages that have links to the related learning 
materials.   
 
The majority of the adaptive systems discussed above have focused on closed 
corpus adaptation. Normally, adaptive hypermedia systems works on a closed set 
of materials are often described by proprietary metadata and those adaptation 
functionalities are tailored to their applications. The shift towards adaptation for 
open learning repositories requires the interpretation of the standardized metadata 
of the learning objects and to find generalizations of adaptation functionalities. 
Henze N. (Henze, 2002) proposed a knowledge modeling approach for adaptive 
open corpus hypermedia system. Their approach towards adaptation is based on 
interpreting metadata of learning objects. The documents of the hypermedia system 
are annotated by a short metadata description (IEEE LOM, category General, data 
element 1.6 keywords), which contains a set of keywords describing the content of 
each document. The documents are identified with this short metadata description 
(keywords) during retrieval. But this short metadata description is not sufficient to 
meet all the requirements of any e-learning system from the instructional 
perspective. There is a need to annotate the documents with metadata, which 
describe the pedagogical characteristics of the document.  
 
The web is a large open corpus containing a variety of learning materials and can 
be used to enhance and personalize the learning experience in e-learning scenarios. 
Dolog et al. (Dolog, 2004) show in their work that personalized e-learning can be 
realized in the semantic web. They integrate the closed corpus adaptation and 
global context provision in a personal reader environment. The primary goal of 
their work is to support the learners in their learning in two ways. The two ways 
are local context provision and global context provision. The local context 
provision provides the learner with references to summaries, general information, 
detailed information, examples, and quizzes from the closed corpus. Global context 
Chapter – 3 
 
   
 - 54 -
provision provides the learner with references to additional resources from the 
semantic web, which is not available in the closed corpus but might further help to 
improve his background on the topics that they want to learn. The additional 
resources of a particular type are retrieved from the semantic web using metadata. 
They assume that external resources are semantically annotated with semantic web 
technology (embedded or external RDF annotations). The generation of this 
annotation is outside the scope of their system. The resources outside of the closed 
corpus are accessible through defined interfaces by connecting Edutella (Nejdl, 
2002), TAP semantic web search (Guha, 2003), or Lixto (Baumgartner, 2001) 
through which they can get RDF annotated metadata.  
3.6  Summary 
In this chapter, we have discussed the work done on different components of a 
personalized information retrieval system such as domain knowledge, student 
model, different strategies for adaptive retrieval etc. A few personalized 
information retrieval systems, which help in retrieving personalized information 
from the web, are also discussed in this chapter. We have also presented a brief 
survey of adaptive learning systems.  
Chapter – 4  
 
System Architecture 
 
4.1  Introduction 
The objective of our work is to develop a tool for building learning object 
repository for learning purposes, where documents from diverse sources can be 
incorporated with minimum effort. The repository is a collection of various types 
of learning materials. To build the repository, documents can be collected from 
various sources such as the web or documents submitted by authors etc. Web 
documents are not structured documents and therefore cannot be stored directly 
into the repository. For efficient retrieval of documents from the repository, 
documents should be annotated with metadata information before incorporating 
them into the repository. 
 
In Chapter 1, we have discussed the disadvantages of manual annotation. An 
alternative to manual annotation is to have the annotation of documents done 
automatically. Some of the domain specific metadata can be extracted using 
domain knowledge of a specific subject domain.  
 
A good learning object repository should provide learners with a search tool that 
allows them to efficiently access good quality learning materials from it. We have 
implemented a system, which facilitates the searching of learning materials from 
the repository. In addition to the internal repository search, our system also 
retrieves learning materials from the internet using a driver to a standard search 
engine. For testing purpose, we have evaluated the system by judging its 
effectiveness in providing learning materials relevant to school students. In order 
to do so, we have incorporated the domain ontology of various school subjects into 
Chapter – 4 
   
 
 - 56 -
the system and created a repository by incorporating the learning materials on 
various topics of those subjects. In this chapter, we present an overview of the 
system. 
4.2  Overview of the System 
The system is designed to accept documents from various sources, and annotate 
them automatically with metadata. The annotated documents are stored in a 
repository, and users are provided a retrieval facility to access relevant learning 
materials from the repository. In order that the retrieval system is able to identify 
the documents that are relevant to the user’s requirements, the system needs to 
store domain knowledge of various subject domains of relevance to the user. The 
relevance of a document is dependent on the user’s knowledge and his 
requirements. Different users giving the same query should get different 
documents as their requirements may differ. In order to effectively filter 
documents, the system needs to store a model of the requirements, interest and 
knowledge level of each user. Our system maintains the user profile for each user, 
which provides the user’s current state of knowledge.  
 
The system also has a local repository of annotated documents. It provides two 
types of search facilities: Local search and Internet search. In Local search, the 
user can access documents from the local repository. In Internet search, the user 
gets personalized search results from the web.  
 
The overall architecture of the system is shown in Figure 4.1. The system consists 
of different modules. The different modules are query handler, content retriever, 
metadata extractor module, personalized retrieval module, domain knowledge, 
user profile and input interface. These modules are discussed below: 
 
• The query handler module handles the user’s given query. In the case of Local 
search, it sends the query to the local repository of the system. In the case of 
Internet search, the query is forwarded to a general-purpose search engine.  
Chapter – 4 
   
 
 - 57 -
Figure 4.1 Overall architecture of the system 
 
• In case of Internet search, the content retrieval module retrieves the first 
few documents from the results returned by the search engine. The 
retrieved documents are forwarded to the metadata extractor module of the 
system.  
• The metadata extractor module analyzes the retrieved documents and 
extracts metadata. For automatic extraction of some of the metadata, this 
module makes use of the domain knowledge of various subjects that are 
maintained in the system.  
• The job of the personalized retrieval module is to filter documents relevant 
to the user. This module takes as input a list of metadata annotated 
documents, and the user profile. It makes use of the domain ontology. It 
filters the document list according to the relevance of the documents to the 
user. For this it checks whether a document is relevant to the user’s 
curriculum requirement and whether it is understandable to the user. It also 
Chapter – 4 
   
 
 - 58 -
checks whether the user is likely to gain some new knowledge from the 
documents. This module provides a content-based score to each document 
and this score reflects the relevance of the document to the user. It 
computes two scores for each of the documents, the relevance score and the 
understandability score. The relevance score represents the relevance of 
the document to the user for a given query. The understandability score 
gives the degree of understandability of a specific user for the document. 
Based on the relevance score and the understandability score, documents 
are ranked.  
• The user interface accepts scored documents from the personalized 
retrieval module and presents the ranked results to the user. 
 
The different modules of the system are discussed in detail in the following 
sections. In Section 4.3, we discuss the structure of the ontology used to store 
domain knowledge. The Section 4.4 presents the metadata-based repository of the 
system. The user profile representation is discussed in Section 4.5. In section 4.6, 
we discuss the personalized retrieval module. The user interface and the query 
handler are discussed in Section 4.7. 
4.3  Domain Knowledge Representation 
Many researchers (Song, 2005; Tan, 2004) believe that the domain ontology plays 
a crucial role for the development of a flexible educational system. In order to 
generate metadata automatically and to allow the repository to remain dynamic and 
flexible, the basic structure of our system is based on the domain ontology of the 
subject being taught.  
 
The domain ontology is an ontological structure of the topics and concepts in a 
particular subject domain together with the relationships between those concepts. 
Thus the subject ontology can be used for the automatic extraction of some of the 
pedagogic metadata such as concepts, the role of each concept and the topic of the 
document etc. The development of the domain ontology incurs cost in terms of 
both time and manual effort. But once it is developed, the presence of the domain 
Chapter – 4 
   
 
 - 59 -
knowledge and efficient use of the knowledge base help in automatic generation of 
metadata and achieving higher precision level in the retrieval process. The model 
of user’s interest can be indicated against various topics and concepts in the 
domain ontology.  
 
The benefits of educational use of ontologies have been identified by many 
researchers (Mitrovic, 2002; Dicheva, 2002). A framework for building a concept-
based digital course library is proposed by Dicheva et al. (Dicheva, 2004a; 
Dicheva, 2004b; Dicheva, 2005), where the subject domain ontology is used for 
the classification of course library content. They proposed a layered architecture of 
the repository consisting of three layers. These layers are semantic layer, resource 
layer and contextual layer. Each layer captures different aspects of the information 
space that are conceptual, resource related and contextual. The semantic layer 
contains a conceptual model of the domain knowledge. In this layer it stores the 
key domain terms (subject of resources) of the domain and relationships among 
them. The resource layer contains a collection of learning resources. The different 
layers support different functionalities in the library. The domain conceptualization 
provided by semantic layer supports findability of learning resources whereas the 
resource layer ontologies supports reusability of learning resources. 
 
Hoermann et al. (Hoermann, 2003) proposed an approach of using learning object 
metadata together with a well-defined knowledge base in order to create adaptive 
and modularized courses. Basically the system consists of a knowledge base where 
multimedia resources are stored. The knowledge base consists of the ConceptSpace 
and the MediaBrickSpace. The ConceptSpace stores the keywords of the domain 
and semantic relations between these keywords. In the second part of the 
knowledge base, which is called MediaBrickSpace, learning resources are stored. 
Every learning resource is described by a set of metadata to provide mechanisms 
for finding and reusing of existing learning resource in the knowledge base.  
 
As discussed above, in the work of Hoermann et al., the ConceptSpace stores the 
keywords of the domain and the semantic layer of the concept-based digital course 
Chapter – 4 
   
 
 - 60 -
library of Dicheva et al. provides the declarative description of domain in terms of 
subjects of resources. These layers explore the domain conceptual map and used 
for efficient retrieval of learning resources. To provide the description of concepts 
of the content of the learning resources, it is needed to include an additional 
information space or layer in the ontology. This layer should store the concepts of 
the learning content and relations among concepts. These concepts can be used for 
the textual content analysis of the learning resource, which may be useful for 
automatic extraction of metadata from the learning content. In the work of Gasevic 
et al. (Gasevic, 2005), they have included this space in their ontology. They use 
two kinds of ontology, the content structure ontology and the domain ontology. 
The domain ontology describes concepts of the content and their relationship. The 
domain ontology is used to semantically mark up the content of a learning object. 
Similarly in the work of ontology based automatic annotation of learning content, 
Jovanovic et al. (Jovanovic, 2006a; Jovanovic, 2006b) store concepts describing 
the documents and their relationship in the ontology. They have used this ontology 
to annotate the learning objects and thus facilitate reusability of learning objects. 
 
Aitken S. and Reid S. (Aitken, 2000) have used the domain ontology in an 
information retrieval tool. The ontology consists of taxonomy of domain concepts. 
In the ontology they stores a list of lexical terms, which are used to identify the 
domain concepts from the document content. 
 
In the above few paragraphs, we have discussed the use of ontology and their 
ontological structure in various systems. The domain knowledge in our system is 
also represented in an ontological structure consisting of different layers. The 
ontological structure of the domain knowledge in our system is discussed below. 
4.3.1  Ontological Structure 
There are some basic requirements for representing the domain knowledge. The 
requirements are as follows: 
 
Chapter – 4 
   
 
 - 61 -
• The representation should consist of distinct layers for different entities in the 
domain. For example, the ontological structure used by Dicheva, Hoermann, 
Gasevic, Jovanovic, Aitken (Dicheva, 2005; Hoermann, 2003; Gasevic, 2005, 
Jovanovic, 2006a, Aitken, 2000) for representing the domain knowledge 
consists of different layers.  
• The representation should provide an efficient means to map the entities of one 
layer to the other layer.  
• The ontology should include relationships between concepts. These 
relationships provide a means to infer possible semantic content of the textual 
documents. If a concept is of significance in a document, it is usually the case 
that the document contains a number of references to related concepts. In fact 
the occurrence of related concepts is taken as a very strong indication of the 
relevance of the document. Pages that do not contain related concepts are 
suspected to be spurious. For example, if a document contains material relevant 
to the concept reflection in optics, it will have references to some of the related 
concepts like light, ray, mirror, lens, angle of incidence etc. These relations 
make it possible to find the concepts that are close to a particular concept in a 
document.  
• Different types of relationships may be used differently in systems that make 
use of the domain knowledge. This information can be used in many ways in 
automatic extraction of metadata from documents. They are useful for better 
matching of documents to the user’s query and retrieving relevant documents 
to fulfill the learner’s requirement from instructional perspective. 
• Finding information at the concept level is important to reduce the confusion 
occurring due to the synonymous ambiguity between terms.  
 
To meet the above-mentioned requirements, the domain knowledge is represented 
in an ontological structure in our system. The knowledge representation database 
or ontology is organized into a three level hierarchical structure. Gasevic et al. 
(Gasevic, 2005) and Jovanovic et al. (Jovanovic, 2006a) have included a concept 
layer in their ontology. The ontology used by Aitken S. (Aitken, 2000) stores 
lexical terms, which are used to identify the domain concepts. In our ontology both 
these layers the concept layer and the term layer are present. The term layer stores 
lexical terms. Lexical terms are the raw terms or representative keywords that 
occur in documents. A lexical term can be polysemous and it may have different 
meanings in different contexts. For example the term charge can have different 
Chapter – 4 
   
 
 - 62 -
meaning in different contexts. The different meanings of the term charge are the 
price charged for an article, a special assignment that is given to a group, an 
assertion that someone is guilty, electric charge etc. A term can have different 
meanings but the domain specific concept is unambiguous and can be useful for 
retrieving domain specific documents.  The concept layer of our ontology contains 
domain specific concepts of various subject domains. In addition to the above two 
layers, we have added a layer in the top, which consists of the set of topics. The 
motivation for adding topics to the ontology is that in a subject, materials are 
organized according to topics denoting the chapter and section names. A topic may 
introduce or discuss a single concept, but it is not always synonymous with a single 
concept. Often a topic discusses several concepts. To make this distinction, we 
have added a different layer called topic layer, which is a prototype-based layer 
whose categories are distinguished by a prototype (Biemann, 2005). The topics are 
the categories of the prototype-based ontology that are formed by collecting the 
concepts (instances) of the topics.  
 
The three-level hierarchical structure of the ontology used by our system is as 
shown in Figure 4.2.  
Figure 4.2 Ontology: three level hierarchical structures
Chapter – 4 
   
 
 - 63 -
We now discuss these layers in detail. 
 
Topic Level: The topic level contains topics from the subject domain. A subject 
domain contains a number of topics and some of the topics are subtopics of these 
topics and they share a parent child relationship. This provides a way of 
generalization from a specific to a more general topic. A subtopic may be placed 
under one or more topics. The hierarchy of topics is stored as an acyclic digraph 
with a single source.  The top most level in Figure 4.3 represents the topic level. 
Examples of some topics in Physics are kinematics, force, geometric optics and so 
on. The topic Geometric Optics has many child topics for example mirror, lens etc.  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Physics 
Mirror 
Geometric 
optics
Force Kinematics 
Lens 
Concave 
mirror 
Convex 
mirror
Pole Reflection 
Angle of 
incidence
Incident 
angle 
Angle of 
incident 
Topic 
Concept 
Law’s of 
reflection
Term Level 
Normal 
Figure 4.3 A small section of the ontology 
Chapter – 4 
   
 
 - 64 -
 
Concept level: Concepts form the next level of the ontology. A set of empirical 
relations can be defined among the concepts in a domain.   
 
Concepts are the nodes of the graph. The edges between the nodes denote 
relationship between concepts. In order to keep the system simple, relation 
between concepts must be broad and general. The types of relations used by our 
system are discussed below. 
 
• Has Prerequisite & Prerequisite For: Sometimes, to understand and grasp 
the idea about a concept, one needs to know some other concepts. These two 
categories of concepts are connected via Has Prerequisite and Prerequisite 
for relations. For example, to learn the concept laws of reflection one should 
have the idea about the concepts like angle of incidence, angle of reflection and 
normal etc. We maintain both forward and backward relations between 
concepts. The concept laws of reflection maintain forward relation of has 
prerequisite with concepts angle of incidence, angle of reflection and normal 
vice versa the concept angle of reflection is prerequisite for the concept laws 
of reflection. 
 
• Inherited from & Parent of: The hypernym and hyponym relations are 
reflected in these relationships. For example, the concept concave mirror 
inherits some properties from the more generalized concept spherical mirror.  
 
• Functionally Related: In some cases, the relationships between concepts do 
not fall into the above-mentioned categories. In such cases, a relation 
Functionally Related relates the concepts. For example, to derive the concept 
Radius of curvature, we need to derive the concept Focal length and vice versa. 
In these cases, the reverse relation has the same label as the forward relation. 
 
Term Level: Documents contain lexical terms. Users usually give their query as a 
set of lexical terms. At this level, we keep a set of lexical terms that occur in 
documents. 
Chapter – 4 
   
 
 - 65 -
 
In our ontology, we map the entities of one layer to other layer by keeping 
relationships between entities of different layers. We keep relationship between 
topics and concepts and also between concepts and keywords. 
 
Topic-Concept Relationships: The documents on a topic contain several 
concepts. For example, a document on the topic spherical mirror may contain 
several of the following set of concepts.  
 
{Reflection, pole, concave surface, convex surface, focus, normal, focal plane, 
principal axis, focal length, concave mirror, convex mirror…………} 
 
A topic can explain more than one concept. A concept can belong to more than one 
topic. We keep the topic concept relationships where the concepts covered by each 
of the topics of the topic taxonomy are kept separately.  
 
We notice that, each concept is not of the same significance for a topic. For 
example, if we take two topics “mirror” and “lens”, the concept mirror is very 
specific or significant to the topic “mirror” whereas the concept lens is very 
specific or significant to the topic “lens”. We give different weights to the topic 
concept relationships. We give more weights to the significance concepts as 
compared to the other concepts in the topic. The significant concepts of each topic 
are associated with specificity index (SI) of value 1 and the other concepts are 
associated with value 0.5. 
 
Term-Concept Mapping: Due to the polysamy, the same term may map to 
multiple concepts. Therefore, each term is linked to the possible set of concepts 
that the term may refer to. These terms are used to extract concepts from 
documents and queries. The association of the terms to the concepts has several 
advantages. The different terms having the same meaning are mapped to a 
common concept removing the synonymous ambiguity of terms. Users are free to 
give query in free text terms. It is not needed them to have knowledge of domain 
specific concepts. 
Chapter – 4 
   
 
 - 66 -
 
Let us take an example of a specific domain namely Physics at the school level. 
Generally the syllabus for any subject is structured in a way shown in figure 4.4.  
 
Figure 4.4 Example of a specific domain 
 
This can be represented in the ontological structure as discussed above. 
• Generally, in the school syllabus there are several subjects like Physics, 
 Chemistry, Biology, History etc. 
• Each subject consists of several chapters. Each chapter may again be 
 divided into several subchapters or subtopics.  
 Example: The subject Physics consists of many chapters like Geometric 
 Optics, Mechanics, Electricity, Magnetism, Waves, etc. These chapters in 
 turn consist of many subtopics. As shown in Figure 4.4, the chapter 
 Geometric Optics contains many subtopics like Spherical mirror, Lens etc. 
 This hierarchical structure can be mapped to the top level of the ontology 
 and can be represented by the topic taxonomy.  
Chapter – 4 
   
 
 - 67 -
• Each chapter or subchapter contains materials that include discussions on 
 various concepts.  
 Example: The chapter Spherical mirror contains the concepts mirror, 
 reflection, concave mirror, convex mirror etc. The concepts describing the 
 topic can be kept in the second level i. e. the concept level of the ontology. 
• The concepts are related to each other through different relationships.  
 Example: The concept mirror is related to the concepts focus, principal 
 axis, center of curvature etc. with the relation has Prerequisite.  
• The same concept may be dealt with in two or more topics.  
 Example: The concepts like focal length, principal axis are included in the 
 topic mirror as well as in the topic lens. The concepts covered by each of 
 the topic can be found from the topic-concept relationships. 
• The same concept may be referred to by different synonymous terms.  
 Example: The terms angle of incidence and incidence angle refer to the 
 same concept.  
4.4  Metadata Based Repository & Document Analyzer 
We wish to develop a repository management tool that will provide an effective 
means to manage the creation and maintenance of a metadata based open 
repository through a user-friendly interface. In Section 4.4.1 we specify the 
requirements of a metadata-based repository. In Section 4.4.2, we provide the 
descriptions of the various modules required for automatic creation of the 
repository.  
4.4.1  Requirements of a Metadata Based Repository 
The key requirements of a metadata-based repository are listed below. 
• The input interface for incorporating documents into the repository should be 
very simple. Most contributors/authors do not like to learn the complicated 
tools. They are usually reluctant to submit documents with complicated 
interfaces. So it is always best to design a simple front end. Documents are 
Chapter – 4 
   
 
 - 68 -
available in various formats for example in pdf, html, txt format etc. The 
contributor should be able to add documents in any format. 
• The Internet is a huge resource of learning materials. The repository should be 
able to incorporate learning materials from the web.  
• The process of loading and maintaining the metadata repository should be as 
automated as possible. The task of manually assigning metadata is a very time 
consuming job and usually slows down the repository initiative. This manual 
process can be automated with careful analysis of documents and with some 
development efforts.  
• The repository should be open and interoperable. It should be accessible by 
other learning management systems and by users. 
• A metadata based learning object repository needs to be able to integrate 
different categories of metadata. The categories may be general, technical, 
educational category and so on. It should keep general information about the 
documents such as identifier, contributors/authors detail, date of creation of 
documents etc. It is also essential to keep information about technical details 
such as the format (pdf, txt, html) and the size of the resource. This information 
tells us about the softwares to be incorporated in a learning management 
system to view the resource. The educational category metadata describes the 
pedagogic characteristics of documents help in retrieval of the documents from 
instructional perspective.  
• Learning management systems should be able to share and reuse metadata. 
Therefore syntax and semantics of metadata elements should be represented 
and designed according to a particular metadata standard.  
 
In Section 2.3, we have discussed about some of the available learning object 
repositories. Most of the learning object metadata based repositories (HEAL, 
EdNA, SMETE, ilumina, CAREO, LearnAlberta, MERLOT) have been built using 
a manual process. As metadata is assigned manually, these repositories cannot take 
advantage of the variety of documents available in the web. These repositories are 
not able to incorporate documents directly from the web.  
 
Chapter – 4 
   
 
 - 69 -
In this work, our aim is to develop a metadata-based repository with an automatic 
metadata extraction tool. 
4.4.2  Architecture of the Metadata Based Repository 
The process for developing the metadata-based repository of our system can be 
explained as a combination of three processes namely collection, extraction and 
load. This is illustrated in Figure 4.5. These three processes are discussed below. 
 
Collection Layer: The primary activity of the collection layer in the metadata-
based repository is to insert documents from various sources with minimum effort. 
It provides the input interface through which the documents can be inserted. Figure 
4.6 provides the screenshot of the input interface of the repository builder of our 
system. It has been divided into two sections: Author Based Submission and Web 
Based Submission. The input interface is very simple. Authors/contributors can 
submit documents through the Author based submission. They are not required to 
fill any kind of form while submitting the documents. The Web based submission 
Figure 4.5 Metadata collection, extraction and load process 
Chapter – 4 
   
 
 - 70 -
provides the facility of accepting documents directly from the web. It accepts the 
global address (URL) of the web document. 
 
Figure 4.6 Input interface for collecting documents 
 
Extraction layer: In the extraction layer, an inserted document is analyzed and the 
available metadata are extracted automatically from the document. The document 
is sent to the automatic metadata extractor module of the system. It extracts all 
types of metadata information such as general, technical, educational etc. from the 
document. The technical category metadata such as the size of the document, 
format, date etc. are extracted automatically from the system properties. The 
educational category metadata, which provides the pedagogic attributes of the 
documents, are extracted by content analysis. The extracted metadata are stored in 
a file with rdf binding. The details of the algorithms for automatic extraction of 
metadata from documents are discussed in Chapter 6.  
 
Load Layer: The load layer takes the metadata file, which is generated in the 
extraction layer and stores them into the metadata repository. Documents are 
stored in the document repository of the system.  
Chapter – 4 
   
 
 - 71 -
4.5  User Profile Representation 
In Section 4.3, we have discussed the different aspects of representation of the 
domain knowledge for effective domain specific retrieval. But the knowledge of 
the domain alone is not enough to collect information specific to the need of a 
particular user. The system should have a profile of the user’s interest to meet the 
user’s need.  
 
The student model is an essential part of intelligent learning systems aiming 
tutoring or adaptive retrieval. The student modeling involves creation of an 
individual model for every user, which records the user’s personal preferences, 
learning history, goal, his current state of knowledge and adapt the curriculum 
sequencing to provide the next best document. We have not developed a tutoring 
system, but we have implemented a module for retrieval of learning materials to 
satisfy the need of a student. As mentioned in Section 4.1, we have implemented 
our system for school students and we aim at providing study materials to the 
school students according to their curricular requirement.  
 
The system keeps a profile of the user’s interest to meet the user’s need. Firstly, the 
system keeps track of the user’s requirement including the user’s interests. This is 
referred to as the user requirement. Secondly, the system keeps track of the 
concepts already learned by the user or known to the user. This is referred to as the 
user state. 
 
The students belonging to the same class have a common set of requirement that is 
defined by the curriculum and this common set is a part of the total domain 
knowledge, which reflects the knowledge requirement for a specific user group. 
We represent this requirement of knowledge for a specific group in a Group 
Profile. This is a representation of the syllabus of a class for a particular subject. 
Individual interest of a user can vary from the predefined Group Profiles. Again, 
different students have different state of knowledge levels. System maintains an 
Chapter – 4 
   
 
 - 72 -
individual user profile for an individual student. The student’s current state of 
knowledge is captured in the individual user profile. 
 
Each user profile is stored in two levels, the topic level and the concept level. A 
profile includes a set of topics. For each topic, it includes the concepts known to 
the user. 
 
In a study, Bull and Pain (Bull, 1995) found that students seem to understand 
textually presented models.  Dimitrova et al. (Dimitrova, 1999) explored a 
collaborative construction of student models promoting student's reflection and 
knowledge awareness. Zapata-Rivera (Zapata-Rivera, 2004a) focuses on the idea 
of letting students (and teachers) interact with the representation of the student 
profile. With this interaction, both student and system can be benefited.  
 
Presently in our system, the student himself interacts with the system to update his 
user profile for personalized retrieval of documents. The user profile updating is 
not dynamic. The system does not update the user profile automatically. 
4.6  Personalized Retrieval Module 
The personalized retrieval module retrieves documents suitable to the learner. It 
finds the suitability of a document to a particular learner by comparing it with his 
user profile. The user profile includes what the learner already knows (the learner’s 
knowledge state) and what the learner is required to know (the learner’s curricular 
requirements).  
 
This module takes as input a list of annotated documents and uses the user profile 
and the domain knowledge for retrieving relevant documents. It computes two 
types of scores namely relevance score and understandability score for each of the 
documents in the list.  
 
Chapter – 4 
   
 
 - 73 -
• It checks the relevance of the document to the input query consulting the 
domain knowledge and the metadata available with the document. Based on 
the relevance of the content of document to the given query, it provides a 
content based score namely relevance score. 
• It checks the suitability of the document to the user consulting the user’s 
profile. It provides a score namely understandability score to the document 
based on the user’s current state of knowledge. 
 
The total score is the summation of the relevance score and the understandability 
score. Based on the total score, documents are ranked and presented to the user 
through the user interface. 
4.7  User Interface & Query Handler 
The user interface is the front end of the system through which users can search 
learning materials on the given input query and also can navigate through the topic 
hierarchy for accessing learning materials on different topics. They can create and 
update their own user profile through this front end.  
 
The simple search button shown in Figure 4.7 enables the user to perform search of 
learning materials. On selecting the simple search button, a new window pane 
appears with options user specific local search and user specific web search. The 
user specific local search enables the user to search learning materials from the 
repository of the system. The user specific web search provides the facility of 
searching learning materials personalized to the user from the web.  
 
The advanced search button enables the user to filter the search results by 
providing extra input such as learning resource type and grade level along with the 
keyword. The advanced search allows the students to filter the search results for a 
particular learning resource type such as experiment type, exercise type, 
application type and explanation type.   
 
Chapter – 4 
   
 
 - 74 -
 
 
Figure 4.7 User interface 
 
The query handler of the system takes the user’s query. In the case of the user 
specific local search, it forwards the query to the repository of the system whereas 
for the user specific web search, the query is forwarded to the driver of a general-
purpose search engine. 
 
The user can navigate through the topic subtopic hierarchy to access documents on 
topics using navigation button provided in the user interface. Generally the 
syllabus of a subject consists of many topics and again the topics are divided into 
many subtopics. The topics and subtopics of a subject of the curriculum 
requirement are kept in the system in hierarchical structure. The user can navigate 
the topic hierarchy for accessing documents on different topics. 
 
Chapter – 4 
   
 
 - 75 -
A learner can add his profile to the system using Add Student button. The students 
can provide their initial profiles during the registration procedure and can make 
changes to the initially created profiles. We have provided an easy user interface 
(Figure 4.8) that helps the student to create the profile.  
 
 
 
 
 
 
 
Figure 4.8 User profile creation interface  
 
 
The students can acquire one or more group profiles and can customize the group 
profiles to produce the personal user profiles. The interface provides the following 
facilities:  
 
• Acquiring Group Profiles: This panel helps the user to select and acquire 
group profiles from a pool of previously created groups. The name of a 
group is constructed by the class name and the subject name.  
 Group   <Class name, Subject Name>  
Choosing Group 
Concept Selection 
Group Viewer 
Chapter – 4 
   
 
 - 76 -
• Group Viewer: When a user selects a group, the topics belonging to the 
selected group are displayed in an expandable tree structure in this panel as 
shown in Figure 4.8. The topics that are already selected by a user from a 
particular group are marked to distinguish them from the topics that have 
not been included yet into the user profile. The users can perform the 
following operations in this panel.  
 
A. Deselect Topic: Any previously selected topic can be deselected and in 
effect the deselected topic will be deleted from the user profile. The 
concepts belonging to the deleted topics will also be deleted from the user 
profile.  
 
B. Select Topic: The topics can be added as a whole or a subset of 
concepts under the selected topic. 
 
• Concept Selection Panel: When a user clicks on a topic in the group 
viewer panel, the concepts belonging to the topic in the selected group are 
displayed in a list in this panel. The marked concepts in the list indicate that 
they already exist in the user profile. The users are provided with the 
following operation in this panel.  
 
A. Select Concept: The concepts can be added to the user profile by 
selecting them. The concepts in the user profile indicate that the user knows 
the concepts. 
 
B. Deselect Concept: The users can exclude one or more than one concepts 
from their profiles by deselecting the selected (marked) concepts.  
Chapter – 4 
   
 
 - 77 -
4.8  Summary  
In this Chapter, we have discussed an overview of the system. The basic structure 
of the system depends upon the ontology of the subject domain, the user’s 
requirements and the metadata-based system’s repository. In Section 4.3, the 
domain ontology is discussed. The domain knowledge is structured into an 
ontological structure consisting of three different layers: topic layer, concept layer 
and the keyword layer. The system builds the user profile of each user and keeps 
track of his current state of knowledge. The system provides the personalized 
search results to the user by reasoning with the ontology, his requirement and the 
user’s current state of knowledge.  
 
Chapter – 5 
 
Metadata Schema 
 
5.1  Introduction 
Metadata is often called “information about information” or “data about data”. The 
information captured on the traditional library catalogue card (title, author etc) is 
an example of metadata. By capturing the essence of information items in the 
metadata description of documents, a repository makes documents easier to search, 
to reuse and to share. The advantages of annotating documents with metadata are 
as follows.  
 
• It makes search, acquisition, and use of learning objects easier by the 
learner. 
• It enables the retrieval module of a retrieval system to retrieve personalized 
learning objects for an individual learner. It helps the tutoring module of a 
tutoring system in the tutoring processes. 
• It facilitates reusability of learning objects i.e. the learning objects can be 
reused in different instructional contexts. 
• It facilitates interoperability of learning objects i.e. the sharing and the 
exchange of learning objects across any technology supported learning 
system. 
 
To facilitate the reusability and the interoperability of documents, the metadata 
schema should follow some standard. Several metadata standards are available, 
which have been discussed in Chapter 2. The Dublin Core Metadata Initiative 
(DCMI, http://dublincore.org/) provides a standard of fifteen elements to facilitate 
Chapter – 5 
   
 
 - 79 -
the management of information in general purpose applications. The elements are 
Title, Subject, Description, Type, Source, Relation, Coverage, Creator, Publisher, 
Contributor, Rights, Date, Format, Identifier and Language. The IEEE learning 
object metadata (IEEE LOM, http://ltsc.ieee.org/wg12/index.html) provides a 
more comprehensive description of learning resources. In the IEEE LOM, an 
elaborate hierarchical scheme has been developed that includes the following 
categories:  general, lifecycle, meta-metadata, technical, educational, rights, 
relations, annotation, and classification. 
 
In our system, a metadata-based repository is developed in conjunction with a 
personalized retrieval system for e-learners. We are interested to have a set of 
metadata, which provides the adequate description of attributes of learning 
materials to facilitate personalized retrieval of documents for e-learning and can 
automatically be extracted from learning materials. We are specifically interested 
in finding the pedagogical attributes, which would be useful for an e-learner. We 
have identified a subset of metadata from the IEEE LOM standard to design the 
metadata schema for our system. We also suggest some minor enhancement to the 
set of metadata, which appears to be useful. Specifically, as discussed in Chapter 4, 
the concepts seem to be more useful notion than the lexical terms. The significance 
and the type of concept seem to be the important attributes.  
 
Section 5.2 provides the overview of the standard metadata IEEE LOM 
specification and the discussion for identification of a set of attributes from this 
specification to design the metadata schema required by our system. Section 5.3 
provides the overview of the metadata schema used by our system. Section 5.4 
gives the summary of this chapter.  
5.2  Identification of Attributes from the Standard 
 Metadata Specification 
As mentioned in Section 5.1, the IEEE LOM standard specification 
(http://ltsc.ieee.org/wg12/files/LOM_1484_12_1_v1_Final_Draft.pdf) specifies a 
Chapter – 5 
   
 
 - 80 -
standard for learning object metadata. It specifies a conceptual data schema that 
defines the structure of a metadata instance for a learning object. The IEEE LOM 
specification consists of nine categories, which includes 60 data elements. Table 
5.1 gives the LOMv1.0 Base Schema structure.  
 
Table 5.1 LOMv1.0 Base Schema 
Nr Name Explanation 
1 General This category groups the general information that 
describes the learning object as a whole. 
1.1 Identifier A globally unique label that identifies the learning 
object. 
 
1.1.1 Catalog The name or designator of the identification or 
cataloging scheme for this entry. A namespace scheme. 
1.1.2 Entry The value of the identifier within the identification or 
cataloging scheme that designates or identifies the 
learning object. A namespace specific string. 
1.2 Title Name given to the learning object. 
1.3 Language The primary human language or languages used within 
the learning object to communicate to the intended user. 
1.4 Description A textual description of the content of the learning 
object. 
1.5 Keyword A keyword or phrase describing the topic of the 
learning object. 
1.6  Coverage The time, culture, geography or region to which the 
learning object applies. 
1.7 Structure Underlying organizational structure of the learning 
object. 
1.8 Aggregation 
Level 
The functional granularity of the learning object. 
2 Life Cycle This category describes the history and current state of 
Chapter – 5 
   
 
 - 81 -
the learning object and those entities that have affected 
the learning object during its evolution. 
2.1 Version The edition of the learning object. 
2.2 Status The completion status or condition of the learning 
object. 
2.3 Contribute Those entities (i.e., people, organizations) that have 
contributed to the state of the learning object during its 
life cycle (e.g., creation, edits, publication). 
2.3.1 Role Kind of contribution. 
 
2.3.2 Entity The identification of and information about entities (i.e., 
people, organizations) contributing to the learning 
object. 
2.3.3 Date The date of the contribution 
3 Meta-
Metadata 
This category describes the metadata record itself 
(rather than the learning object that the record 
describes). This category describes how the metadata 
instance can be identified, who created the metadata 
instance, how, when, and with what references. 
3.1  Identifier A globally unique label that identifies the metadata 
record. 
3.1.1 Catalog The name or designator of the identification or 
cataloging scheme for this entry. A namespace scheme. 
3.1.2 Entry The value of the identifier within the identification or 
cataloging scheme that designates or identifies the 
metadata record. A namespace specific string. 
3.2 Contribute Those entities (i.e., people or organizations) that have 
affected the state of the metadata instance during its life 
cycle (e.g., creation, validation). 
3.2.1 Role Kind of contribution. Exactly one instance of the data 
element with value "creator" should exist. 
Chapter – 5 
   
 
 - 82 -
3.2.2 Entity The identification of and information about entities (i.e., 
people, organizations) contributing to the metadata 
instance. 
3.2.3 Date The date of the contribution.  
 
3.3 Metadata 
Schema 
The name and version of the authoritative specification 
used to create the metadata instance. 
3.4 Language 
 
Language of the metadata instance. 
4 Technical This category describes the technical requirements and 
characteristics of the learning object. 
4.1 Format Technical data type of the learning object. This data 
element shall be used to identify the software needed to 
access the learning object. 
4.2 Size The size of the digital learning object in bytes 
4.3 Location A string that is used to access the learning object. It may 
be a location (e.g., Universal Resource Locator), or a 
method that resolves to a location (e.g., Universal 
Resource Identifier). 
4.4 Requirement The technical capabilities necessary for using this 
learning object. 
4.4.1 OrComposite Grouping of multiple requirements. The composite 
requirement is satisfied when one of the component 
requirements is satisfied, i.e., the logical connector is 
OR. 
4.4.1.1 Type The technology required to use the learning object, e.g., 
hardware, software, network, etc. 
4.4.1.2 Name Name of the required technology to use the learning 
object. 
4.4.1.3 Minimum 
Version 
Lowest possible version of the required technology to 
use the learning object. 
Chapter – 5 
   
 
 - 83 -
4.4.1.4 Maximum 
Version 
Highest possible version of the required technology to 
use the learning object. 
4.5 
 
Installation 
Remarks 
Description about installation 
4.6 Other 
Platform 
Requirements 
Information about other software and hardware 
requirements. 
4.7 Duration Time a continuous learning object takes when played at 
intended speed. 
5 Educational This category describes the key educational or 
pedagogic characteristics of the learning object. 
5.1 Interactivity 
Type 
Predominant mode of learning supported by the 
learning object. 
• "Active" learning (e.g., learning by doing) is 
supported by content that directly induces 
productive action by the learner.  
• "Expositive" learning (e.g., passive learning) 
occurs when the learner's job mainly consists of 
absorbing the content exposed to him (generally 
through text, images or sound). 
5.2 Learning 
Resource 
Type 
 
Specific kind of learning object.  
• exercise 
• simulation 
• questionnaire 
• diagram 
• figure 
• graph 
• index 
• slide 
• table 
• narrative text 
Chapter – 5 
   
 
 - 84 -
• exam 
• experiment 
• problem statement 
• self assessment 
• lecture 
5.3 Interactivity 
Level 
 
The degree of interactivity characterizing the learning 
object. Interactivity in this context refers to the degree 
to which the learner can influence the aspect or 
behavior of the learning object. 
5.4 Semantic 
Density 
 
The degree of conciseness of a learning object. The 
semantic density of a learning object may be estimated 
in terms of its size, span, or in the case of self-timed 
resources such as audio or video, its duration. The 
semantic density of a learning object is independent of 
its difficulty. It is best illustrated with examples of 
expositive material, although it can be used with active 
resources as well. 
5.5 Intended End 
User Role 
Principal user(s) for which the learning object was 
designed 
5.6 Context The principal environment within which the learning 
and use of the learning object is intended to take place. 
5.7 Typical Age 
Range 
Age of the typical intended user. 
5.8 Difficulty How hard it is to work with or through the learning 
object for the typical intended target audience. 
5.9 Typical 
Learning 
Time 
Approximate or typical time it takes to work with or 
through the learning object for the typical intended 
target audience. 
5.10 Description Comments on how the learning object is to be used. 
 
5.11 Language The human language used by the typical intended user 
Chapter – 5 
   
 
 - 85 -
of the learning object. 
6 Rights This category describes the intellectual property rights 
and conditions of use for the learning object. 
6.1 Cost Whether use of the learning object requires payment. 
6.2 Copyright and 
Other 
Restrictions 
Whether copyright or other restrictions apply to the use 
of the learning object. 
 
6.3 Description Comments on the conditions of use of the learning 
object. 
7 Relation This category defines the relationship between learning 
objects. To define multiple relationships, there may be 
multiple instances of this category. If there is more than 
one target-learning object, then each target shall have a 
new relationship instance. 
7.1 Kind Nature of the relationship between the learning object 
and the target-learning object, identified by 
7.2:Relation.Resource. 
7.2 Resource The target learning object that this relationship 
references. 
7.2.1 Identifier A globally unique label that identifies the target-
learning object. 
7.2.1.1 Catalog The name or designator of the identification or 
cataloging scheme for this entry.  
7.2.1.2 Entry The value of the identifier within the identification or 
cataloging scheme that designates or identifies the 
target-learning object.  
7.2.2 Description Description of the target learning object 
8 Annotation This category provides comments on the educational 
use of the learning object, and information on when and 
by whom the comments were created. This category 
enables educators to share their assessments of learning 
Chapter – 5 
   
 
 - 86 -
objects, suggestions for use, etc. 
8.1 Entity Entity (i.e., people, organization) that created this 
annotation. 
8.2 Date Date that this annotation was created.  
8.3 Description The content of this annotation.  
9 Classification This category describes where the learning object falls 
within a particular classification system. 
9.1 Purpose The purpose of classifying the learning object. 
• discipline 
• idea 
• prerequisite 
• educational objective 
• accessibility 
• restrictions 
• educational level 
• skill level 
• security level 
• competency 
9.2 Taxon Path A taxonomic path in a specific classification system. 
Each succeeding level is a refinement in the definition 
of the preceding level. There may be different paths, in 
the same or different classifications, which describe the 
same characteristic. 
9.2.1 Source The name of the classification system. This data 
element may use any recognized "official" taxonomy or 
any user-defined taxonomy. 
9.2.2 Taxon A particular term within a taxonomy. A taxon is a node 
that has a defined label or term. A taxon may also have 
an alphanumeric designation or identifier for 
standardized reference. Either or both the label and the 
entry may be used to designate a particular taxon. An 
Chapter – 5 
   
 
 - 87 -
ordered list of taxons creates a taxonomic path, i.e., 
"taxonomic stairway": this is a path from a more 
general to more specific entry in a classification. 
9.2.2.1 Id The identifier of the taxon, such as a number or letter 
combination provided by the source of the taxonomy. 
9.2.2.2 Entry The textual label of the taxon. 
9.3 Description Description of the learning object relative to the stated 
9.1:Classification.Purpose of this specific classification, 
such as discipline, idea, skill level, educational 
objective, etc. 
9.4 Keyword Keywords and phrases descriptive of the learning object 
relative to the stated 9.1:Classification. Purpose of this 
specific classification, such as accessibility, security 
level, etc. 
 
To design the metadata schema, we have followed the IEEE LOM standard. As 
shown in the above table, it consists of nearly 60 data elements including general, 
technical, educational etc. We have identified a subset of metadata from the IEEE 
LOM specification, which are relevant for finding the suitability of a document to 
a particular e-learner and can automatically be extracted from learning materials. 
Even though we would like to include many of the attributes from the IEEE LOM 
that are important from instructional design perspective, currently our system deals 
with a small subset of the IEEE LOM attributes from general, technical, 
educational and classification category. We have added a few more additional 
attributes, which are not there in the IEEE LOM, but seem to be useful for the 
learning management and retrieval systems. We are mainly interested on a set of 
pedagogic metadata attributes, which can automatically be extract from learning 
materials. 
Chapter – 5 
   
 
 - 88 -
5.2.1  General and Technical Category Metadata 
The repository is a collection of documents. In order to identify the documents, it 
is required that each document should have a global unique label. The general 
category metadata 1.1 of the IEEE LOM defines this attribute and is included in 
our metadata schema. The set of metadata, which describe the document, is stored 
in a metadata record. Each metadata record should also have some unique label, 
which is defined in data element 3.1 of Meta Metadata category and is included in 
our metadata schema. In order to retrieve documents from the repository, it is 
required to store the location of documents, where they reside.  
 
We are interested to keep some technical characteristics of documents. The 
technical data type format of the document is included in the metadata schema. 
This data type is used to identify the software needed by any learning system to 
access the document. The metadata schema also includes technical attributes like 
size of the document and date.  
5.2.2  Educational Category Metadata 
The educational category metadata are the most important and useful metadata for 
e-learners. We are interested to provide documents to meet the learner’s 
requirement. The different learners may have different learning requirements. A 
retrieval system decides whether a document is relevant to the learner based on the 
curriculum requirement, the learner profile and the type of the learning resource. 
Therefore it is important to identify the pedagogical category or the type of  
learning resource to assess its relevance for learning in a given situation. In order 
to identify the pedagogical attributes of relevance, we have consulted different 
learning theories given by different educational psychologist.  
 
In 1956, the educational psychologist Benjamin S Bloom (Bloom, 1956) developed 
a classification of educational goals and objectives. The major idea of the Bloom’s 
taxonomy is to arrange the educational objectives in a hierarchy from less complex 
to more complex. He identified six levels in the cognitive domain, namely, 
Chapter – 5 
   
 
 - 89 -
knowledge, comprehension, application, analysis, synthesis and evaluation. The 
six levels of Bloom’s taxonomy are discussed in Table 5.2. 
 
Table 5.2 Six levels of Bloom’s Taxonomy  
 
Level Explanation 
Knowledge • Observation and recall of information  
• Knowledge of major ideas  
• Mastery of subject matter  
Comprehension • Understanding information  
• Grasp meaning  
• Translate knowledge into new context  
• Interpret facts  
• Infer causes  
• Predict consequences  
Application • Use information  
• Use methods, concepts, theories in new situations  
• Solve problems using required skills or 
knowledge  
Analysis • Seeing patterns  
• Organization of parts  
• Recognition of hidden meanings  
• Identification of components  
Synthesis • Use old ideas to create new ones  
• Generalize from given facts  
• Relate knowledge from several areas  
• Predict, draw conclusions  
Evaluation • Evaluate the value of the material which is 
learned 
 
In 1968, Ausubel (Ausubel, 1968) has proposed a learning sequence consisting of 
four learning phases. The learning phases are advance organizer, progressive 
Chapter – 5 
   
 
 - 90 -
differentiation, practice, and integrating. The above learning phases are discussed 
in Table 5.3 
 
Table 5.3 Phases of expository teaching according to Ausubel 
 
Phase Instructional purpose 
Advance organizer Present introductory materials that help the 
students to relate new information to the 
existing knowledge schemes. 
Progressive differentiation The most general ideas of a subject should be 
given first and then progressively 
differentiated in terms of details. 
Practice Practice and apply 
Integrating and connecting Integrate and link new knowledge to the other 
fields of knowledge. 
 
Different educational psychologists have proposed many instructional models. 
Merrill (Merrill, 2002) identified the common phases that exist in many models. 
These phases are (1) activation of prior experience, (2) demonstration of skills, (3) 
application of skills, and (4) integration of these skills into real world activities. 
 
In the context of instructional design, the learning resource type (IEEE LOM’s 
property 5.3) such as exercise, simulation, narrative text, exam and experiment 
cover the instructional type. Few more values have been proposed as an extension 
to LOM resource type, which will describe the learning resource from instructional 
design perspective (Ullrich, 2004). RDN/LTSN resource type vocabulary 
(http://www.rdn.ac.uk/publications/rdn-ltsn/types/) is very common in learning and 
teaching community of UK. It specifies a set of additional learning resource types 
like worked example, glossary, case study and many more, which are expected to 
be use with 5.2 learning resource type LOM elements. The different learning 
resource type vocabularies used by the community of UK and Europe is available 
Chapter – 5 
   
 
 - 91 -
in the appendix 2, learning resource type vocabularies of UKLOM core 
(http://www.cetis.ac.uk/profiles/uklomcore).  
 
Considering the IEEE LOM standard and the above discussed learning theories, we 
classify learning resources (documents) into different categories or types. We want 
to identify the type of the document automatically. Presently, we have worked on 
the automatic identification of four types of documents. The types are as follows. 
 
Explanation Type: A document that deals with the knowledge and the 
comprehension level of the Bloom’s Taxonomy is classified as belonging to the 
explanation type. These types of documents provide definitions, facts and the 
explanation about concepts. The 5.2 learning resource type metadata of IEEE 
LOM includes narrative text type of learning resource. The narrative text type 
documents generally contain definitions, statement of laws or facts about concepts. 
The definition and uses of narrative text type documents are discussed in the 
CanCore guidelines (http://www.cancore.ca/en/help/44.html). We can map the 
explanation type documents to the narrative text type documents (5.2, learning 
resource metadata) of the IEEE LOM. 
 
Application Type: The third level of Bloom’s taxonomy is application. According 
to Bloom (Bloom, 1956), “application is the use of abstractions in particular and 
concrete situations”. We categorize a document as belonging to the application 
type, when it contains applications of the theories, laws, rules, methods or 
principles.  
 
Exercise Type: In Bloom’s classification the last level is the evaluation. 
Evaluation is concerned with the ability to evaluate the value of the material, 
which is learned by a learner. The third phase of the learning sequence given by 
the Ausubel’s theory is practice. We have classified documents into a category 
named exercise. The category exercise includes the documents containing 
exercises, numerical problems, questions etc. We can map the exercise type 
documents to the exercise and questionnaire type of learning resources (5.2, 
learning resource type) of the IEEE LOM specification.  
Chapter – 5 
   
 
 - 92 -
 
Experiment Type: For the better understanding of any theory, law or principle, 
students perform experiments. Different instructional models (Merrill, 2002) also 
give emphasis on demonstrations and experimentations. We classify the learning 
resources into a category named experiment type. The experiment type documents 
contain instructions and discussion on experiments. We can map experiment type 
documents to the experiment type learning resources (5.2, learning resource type) 
of the IEEE LOM specification.   
 
The type of the documents and their characteristics are summarized in the Table 
5.4. 
Table 5.4 Definition of document types with examples 
  
Document 
type 
Definition Example 
Explanation Documents, which 
contain definitions and 
explanation of concepts 
A document explaining Newton’s 
law of motion 
Application Documents, which give 
applications of any 
concept or principle in 
practical situations 
A document which gives application 
of Newton’s law in aircraft 
Experiment Documents, which give 
experiment instructions 
and discussions.  
A document containing experiment 
on Newton’s law of motion 
Exercise  Documents containing 
questions, numerical 
problems, exercises etc. 
Documents containing questions, 
numerical problems and exercises on 
Newton’s law of motion 
 
Automatically deducing the type of learning resource (document) requires deep 
content analysis of the document. However, considering the importance of the 
learning resource types in e-learning, we have attempted for the automatic 
extraction of the above-discussed four types of learning resources. However, it is 
also important to identify the other types such as simulation, example etc. by a 
learning system and in future we will work on it.  
 
Chapter – 5 
   
 
 - 93 -
The students belonging to different grade levels have different levels of 
knowledge. Even in the same grade level, the students’ knowledge level differs 
from one student to other. Therefore, it is required to find out the difficulty level of 
the document. To provide the documents according to the learner’s knowledge 
level, it is important to know the grade for which the document is suitable. The 
attribute 5.6 context of the IEEE LOM specification is a useful attribute and fulfills 
the above requirement. This attribute provides the environment in which the 
learning and the use of the learning objects are intentioned to take place. In 
MERLOT and HEAL, users can perform advanced search on this attribute. Here, 
this attribute is named as primary audience. Using this attribute, a user can filter 
the search results of his grade level. In our metadata schema, the context attribute 
is named as grade level, which indicates the grade or class for which the document 
is suitable.  
5.2.3  Classification Category Metadata 
A learning system may need to identify documents belonging to a topic, so it helps 
if documents in the repository are labeled with the topic information. The attribute 
taxon path (9.2, IEEE LOM specification) indicates the taxonomic path with 
respect to the topic tree in the domain ontology and gives the topic of the 
document. A learner can browse this topic tree to access documents on topics. 
 
The curriculum is a set of topics. Corresponding to each topic, from our domain 
ontology we can retrieve the taxonomy path, which we specify as the metadata.  
5.2.4  Local Extension 
Although the IEEE LOM contains almost 60 metadata elements, sometimes it does 
not meet all the requirements of learning systems and therefore requires extension. 
Many researchers (Mohan, 2003; Brooks, 2005; McCalla, 2003; Ullrich, 2004) 
have recommended and suggested extensions to the IEEE LOM. We have added 
few attributes that play a vital role in the retrieval of relevant materials from the 
repository. The use and importance of this minor enhancement is discussed below. 
Chapter – 5 
   
 
 - 94 -
 
The repository is a pool of learning materials. To incorporate the facility of 
retrieval of the learning materials, the set of terms occurring in the document is 
extracted from the document. We have a domain ontology from which we can map 
each term to its corresponding concept and can identify the concepts present in the 
document. Concept based search gives higher precision for retrieval (Aitken, 
2000). We are interested in finding the list of concepts present in the document. 
But all the concepts that occur in a document are not equally useful for 
characterizing the document. The concepts are associated with some attributes, 
which help in identifying the importance of a concept with respect to the 
document. The attributes are frequency, significance and type. 
 
We use the frequency of the domain term indicating the concept frequency in a 
document as one attribute of the concept. While searching documents from a huge 
pool of documents, the frequency of each concept is used to compute the degree of 
similarity between the documents and the user’s requirements. For content 
identification and discrimination, consideration of the frequency of the concept is 
not enough. We have to take into account other factors such as the significance of 
each concept with respect to the document. Further, a concept may be defined or 
explained in a document, or it may be used to explain some other concepts. In the 
former case, the concept can be learned from the document; in the latter case 
knowledge of the concept is a prerequisite for studying the document. We have 
considered labeling each concept as prerequisite or outcome based on this 
distinction. An outcome concept is a concept, which is learned from the document. 
The concepts, which are used for studying and understanding the outcome 
concepts, are called the prerequisite concepts.  
 
The metadata schema also includes the list of document terms associated with the 
term frequency. The term frequency is the number of occurrences of each term in a 
document. 
Chapter – 5 
   
 
 - 95 -
5.3   Metadata Schema 
As discussed in Section 5.2, the metadata schema is grouped into five categories. 
The Metadata schema, which is a subset of the IEEE LOM is shown in Table 5.5. 
It defines the name by which the data element is referenced and the definition or 
explanation of each element.  
 
Table 5.5 A subset of the IEEE LOM  
Name Explanation 
1. General category  // General information describing the learning object 
     1.1 Identifier  // A globally unique label that identifies the learning 
object.  
2. Life Cycle // This category describes the history of the learning 
object. 
     2.3.3 Date // Date of contribution. 
3.  Meta Metadata category  // This category describes the metadata record itself. 
      3.1 Identifier  // Unique label that identifies the metadata record. 
4. Technical category  //Describes the technical requirements and characteristics 
of the learning object. 
      4.1 Format // Technical data type(s) of the learning object. 
 
      4.2 Size  // The size of the digital learning object in bytes. 
 
      4.3 Location  // A string that is used to access the document.  
 
5. Educational category  // This category describes the key educational or pedagogic 
characteristics of the learning object. 
     5.2 Learning Resource 
Type  
// Specific type of learning material. The types considered 
are  
// Explanation, application, exercise, and experiment 
     5.6 Grade level (Context) // Difficulty level or the grade level for which the learning 
object is suitable 
9. Classification category  // This category describes where this learning object falls 
within a particular classification system. 
      9.2 Topic (Taxonomic 
Path ) 
// Topic of a document (Taxonomic path with respect to 
the topic tree in the domain ontology ) 
 
Chapter – 5 
   
 
 - 96 -
The metadata elements given in Table 5.6 are the local extensions to the IEEE 
LOM specification and included in our metadata schema. 
 
Table 5.6 Local extension of the IEEE LOM  
 
     List of concepts  // List of concepts mentioned that belong to the 
domain ontology along with certain attributes for each 
concept 
  For each concept we 
specify 
    
              Name // Name of the concept 
              Significance  // Significance of the concept 
              Type  // A concept can be one of these 2 types: outcome or 
prerequisite. 
     List of domain terms // List of domain terms in the learning material along 
with their frequency 
   For each term we 
specify 
 
               Name   // Name of the term 
               Frequency // Its frequency of occurrence in the document 
 
5.4 Summary  
In this chapter, we have discussed about the metadata schema used in our system. 
To make our system interoperable, we have designed the metadata schema by 
identifying the important general, technical, classification and educational category 
attributes from the standard IEEE LOM, which can automatically be extracted 
from a document. Our metadata schema is a small subset of the IEEE LOM 
specification.  
 
We have included the metadata element list of concepts, which is not there in the 
IEEE LOM specification. Each concept in the concept list is associated with 
attributes frequency, significance and type. The attribute type includes two types of 
concepts: the outcome concept and the prerequisite concept.  
 
The metadata learning resource types are categorized into four types namely 
explanation, application, exercise, and experiment. Presently in our system, we 
Chapter – 5 
   
 
 - 97 -
have worked with the above four types of documents. Other document types like 
simulation type, example type are also important from instructional design 
perspective and required to be included into the metadata schema. 
 
Although, the metadata schema contains the metadata grade level that gives the 
difficulty level of a learning object. The metadata attributes semantic density, 
which gives the degree of conciseness of a learning object is also an impoatant 
attribute and should be included into the metadata schema. 
 
We have worked on the automatic extraction of the metadata elements mentioned 
in Table 5.5 and 5.6. Chapter 6 gives the details of different algorithms for 
automatic extraction of the metadata elements. 
 
 
Chapter – 6 
 
Automatic Metadata Extraction 
 
6.1  Introduction 
In Chapter 5, we have discussed the advantages of annotation of documents with 
metadata before incorporating them into the repository. Most existing learning 
object repositories contain learning materials annotated with metadata. One of the 
main difficulties in developing a large repository lies in the labor-intensive nature 
of activity of manual annotation of metadata. The process of metadata generation 
can be simplified by capturing metadata attributes automatically from documents 
 
In this Chapter, we discuss the automatic extraction of metadata from documents. 
In Section 6.2, we discuss the different types of metadata annotation. Different 
algorithms used to extract metadata automatically from documents are discussed in 
Section 6.3. Section 6.4 discusses about the automatic annotation tool developed 
by us.                                                                                                                                                        
6.2  Types of Metadata Annotation 
Documents can be annotated in two ways, manual and automatic. Manual 
annotation requires an expert/developer who generates the metadata values after 
reviewing the documents. In automatic annotation, some kind of information 
extraction process tries to deduce the values of the metadata fields based on the 
information available in documents. In this Section, we compare the advantages 
and disadvantages of these two ways of metadata generation. 
 
Chapter – 6 
   
 
 - 99 -
Manual annotation of documents can be done in two ways. The author/developer 
may generate the metadata for learning objects or a group of experts may generate 
the metadata values for all the objects present in the repository. The first approach 
where the developer generates metadata scales because the average number of 
learning objects that an individual developer generates is relatively small. But, this 
approach does not work in real life (Duval, 2004). It requires more work from the 
developer. This process is relatively slow. In the second approach, the annotation is 
done using a group of dedicated experts. The solution is neither scalable nor 
consistent.  
 
The web has emerged as a gigantic digital library and can act as one of the major 
source of documents for e-learning. But documents available in the web are not 
structured as required by learning object repositories and cannot be indexed 
directly into repositories. Automatic metadata generation seems to be the only 
feasible way for the task of the rapid build up of indexed repositories.   
 
Researchers (Greenberg, 2004b) have identified two methods of automatic 
metadata generation. These methods are metadata harvesting and metadata 
extraction. In metadata harvesting, metadata is automatically collected from 
META tags found in the source code of HTML resources or by encoding from 
resources in other formats (e.g., Microsoft WORD documents). The harvesting 
process relies on the metadata produced by humans or by semi-automatic processes 
supported by softwares. In metadata extraction method, the resource content is 
mined and different algorithms are implemented to produce metadata. Metadata 
extraction methods may employ different sophisticated machine learning methods 
and classification algorithms to improve the metadata quality. As discussed in 
Section 2.4.2, Han et al. have (Han, 2003) used SVM based metadata extraction 
algorithm for automatically extracting the author’s detail from documents. 
Similarly, Li et al. (Li, 2004) have applied the principal component analysis (PCA) 
technology of neural network for generating the subject of the document 
automatically. 
 
Chapter – 6 
   
 
 - 100 -
In Section 6.3, we present some algorithms for automatic extraction of different 
types of metadata that we have worked on.  
6.3  Automatic Extraction of Metadata  
We explore the automatic metadata extraction methods for semantic tagging of 
documents in our system. All elements of the metadata schema given in Tables 5.5 
and 5.6 are extracted automatically. The metadata schema consists of six 
categories, which tries to capture the information in all dimensions including 
general, life cycle, meta metadata, technical, educational and classification. A few 
metadata such as date_created, size and format are derived automatically from the 
system properties. Educational category metadata are generated by textual content 
analysis.  
 
To identify the educational category metadata learning resource type, we have 
identified some of the surface level features of the text similar to the work of 
automatic detection of text genre by Kessler et al. and Rauber et al.(Kessler, 1997; 
Rauber, 2001) and used these features to classify documents using a neural 
network. The features are the occurrences of a set of specific verbs or other words, 
phrases and special characters in a document. It also uses the natural language 
processing of the text of the document to understand the semantic of sentences.  
 
Some of the algorithms for automatic extraction of metadata from documents use 
the domain ontology maintained in our system. As discussed in Section 4.3.1, the 
ontology is a three level structure: topic level, concept level and term level. In the 
topic level, hierarchy of topics is stored as an acyclic digraph with a single source. 
The concept level stores concepts of the subject domain and relationships among 
them. The concepts are the nodes of the graph and the edges between the nodes 
give the relationships between the concepts. The above knowledge helps in the 
extraction of some of the metadata information from documents. 
 
Chapter – 6 
   
 
 - 101 -
The different methods used for automatic extraction of the educational category 
metadata are discussed below. 
6.3.1  List of Terms 
In the classical models of information retrieval, each document is described by a 
set of representative keywords called terms. These terms are used to index the 
document contents. The number of occurrences of each term in a document is an 
attribute. This attribute helps in identifying the relevance of the document to the 
user’s query. 
 
The ontology of our system maintains a dictionary of lexical terms. The text of 
each document is tokenized and each token is compared with this dictionary. The 
matched words are extracted from the document and added into the list of terms. 
The number of occurrences of each term is found and is associated with the term.  
6.3.2  List of Concepts and their Significance 
As stated above, a document contains a set of terms.  A term can be polysemous, 
that is, in different contexts it may have different meanings. For example, the term 
reflection has different meanings in different contexts. If we search the documents 
for the term reflection, a general-purpose search engine returns documents of 
various domains. For example, the first few documents returned by the Google 
search engine for the query reflection is shown in Figure 6.1.  The search returns 
documents from entirely different domains altogether. We find that few documents 
talk about the concepts of java tutorial, some documents deal with the reflection of 
light while there are documents, which talk about reflections of people on various 
aspects of life.   
 
 
 
 
Chapter – 6 
   
 
 - 102 -
 
 
The Reflection API  
You'll want to use the reflection API if you are writing development tools such ... Don't use 
the reflection API when other tools more natural to the Java ... 
java.sun.com/docs/books/tutorial/reflect/index.html - 7k - Cached - Similar pages 
Reflection  
Reflection. Documentation Contents. Reflection enables Java code to discover 
information about the fields, methods and constructors of loaded classes, ... 
java.sun.com/j2se/1.3/docs/guide/reflection/ - 4k - Cached - Similar pages 
[ More results from java.sun.com ] 
Terminal Emulator and Application Integration Software: WRQ  
AttachmateWRQ Reflection provides a complete range of terminal emulation, ... In 
addition to supporting all the essential hosts, Reflection is loaded with ... 
www.wrq.com/ - 16k - Cached - Similar pages 
WRQ Reflection and VeraStream for IBM zSeries  
With a terminal emulator, PC X server and an FTP client, all available in a secure 
framework, Reflection can meet all of your terminal emulation needs. 
www.wrq.com/products/reflection/ - 15k - Cached - Similar pages 
[ More results from www.wrq.com ] 
Reflection and Mirrors Table of Contents  
Lesson 1: Reflection and its Importance. The Role of Light to Sight · The Line of Sight ... 
Reflection of Light and Image Formation for Convex Mirrors ... 
www.glenbrook.k12.il.us/ gbssci/phys/Class/refln/reflntoc.html - 7k - Cached - Similar pages
NTNU JAVA :: View topic - Reflection and Refraction  
Post Posted: Thu Jan 29, 2004 10:55 am Post subject: Reflection and Refraction. The 
Transmission of Wave through Dense media -- Reflection and Refraction ... 
www.phy.ntnu.edu.tw/java/propagation/propagation.html - 55k - Cached - Similar pages 
Daily Reflection Calendar  
University Ministry Division of Creighton University. 
www.creighton.edu/CollaborativeMinistry/daily.html - 26k - Cached - Similar pages  
 
Figure 6.1 First few results returned by Google search  
engine for the query reflection 
 
Chapter – 6 
   
 
 - 103 -
As an example, consider the snap shot of the document 
(http://www.uvm.edu/~dewey/reflection_manual/understanding.html) shown in 
Figure 6.2. This document is returned by Google in response to the query 
reflection.  It is in the top few documents of the search result because the term 
reflection occurs many times in the document. Although, the term reflection occurs 
many times, the document is not relevant for a learner who is interested to learn the 
concept reflection of subject physics.  
 
 
Figure 6.2 The page returned by the Google search engine in response  
to the query reflection 
 
 
A term or phrase may have multiple meanings, while a domain specific concept is 
unambiguous. It is more useful to use the domain specific concepts present in 
documents than the terms for retrieving documents belonging to a particular 
domain. Therefore, we extract the list of concepts present in documents and 
Chapter – 6 
   
 
 - 104 -
annotate them with the list of concepts. For this, we need to disambiguate the 
meaning of a term and identify the concept it refers to. In some cases more than 
one term may refer to the same concept. In such cases the frequency of a concept 
will include the frequencies of all synonymous terms for the concept in the 
document.  
 
We note that concepts rarely occur in isolation. If a concept is significant for a 
document, the document usually contains other concepts related to it. For example 
the word charge has at least two distinct meanings: electric charge and financial 
charge. If a document talks about electric charge, the document usually contains 
other terms like current, electricity, etc. while in the case of financial charge; the 
document may contain terms like payment, amount, etc. Our idea is to score a 
concept by looking at that concept as well as references to its related concepts.  
 
We have a list of terms and their frequencies for each document (discussed in 
Section 6.3.1). We will now discuss how we map each term in the list to its 
corresponding concept and how we estimate the significance of each concept with 
respect to the current document. For each term, the associated set of concepts is 
Figure 6.3 Relation among concepts 
Chapter – 6 
   
 
 - 105 -
obtained from the ontology. A term can map to one or more number of concepts. 
As mentioned in the above paragraph, the term charge can map to electric charge, 
financial charge or criminal charge. Out of these mapped concepts, we want to 
find the most appropriate concept for a particular domain. To identify the correct 
concept, we look at the occurrences of the related concepts. We use the inter 
concept relationship which is captured in our ontology. Figure 6.3 shows a part of 
the concept graph for the physics domain from our ontology. A concept is more 
significant if more number of related concepts of that term occur in the document.  
The proposed algorithm takes a list of terms from the document along with their 
frequency as input, and returns a list of concepts along with their significance with 
respect to the document.  
 
The algorithm works as follows. For each term ti in the term list of a document D, 
the associated concepts cij are obtained from the ontology. Let the significance of 
each associated concept cij be cij.significance. The significance cij.significance is 
initially taken as the normalized frequency of the term ti i.e. ti.frequency. For each 
associated concept cij, we look at the presence of the related concepts rcp in the 
document. We then increment the significance of the associated concept cij by α* 
normalized term frequency for the occurrences of the terms tp corresponding to the 
concept rcp. 
 
 
Significance cij  = ti.frequency + α * tp.frequency  
 
 
Where α is the weight given to the related concepts. In our experiment, we have 
taken α = ½.  
 
For a particular term, we choose a concept with maximum significance value. 
 
 
 
 
Chapter – 6 
   
 
 - 106 -
 
The algorithm is outlined below: 
Algorithm 6.1: Identification of Concept and its significance 
 
Input:  t1, t2, .. ,tn is the list of domain terms in the document D;  
 ti.frequency is the normalized frequency of domain term ti ;  
 num is the total number of tokens in the document D 
Output: list of concepts c1, c2, … cm and their significance ci.significance 
 
(1)  for i ← 1 to n   
 { 
     // Normalize the frequency counts 
     ti.frequency  ← ti.frequency / num 
 } 
 
(2)  for i ← 1 to n   
 { 
      ti.concepts  ←{ci1 .. cij ..cik}  
     // where {ci1 .. cij ..cik} be the list of associated concepts of ti  
             cij.significance  ← ti.frequency 
 } 
 
(3)  for i ← 1 to n  
     { 
        for j ← 1 to k  
          {  
  find the related concepts rcp.of cij  (rcp.’s corresponding term tp) in D  
       if tp occurs in D 
              cij.significance  ← cij.significance  + α × tp.frequency  // we take α = 1/2 
 } 
     } 
 
(4)  // Select the final concept 
   for i ← 1 to n   
     { 
    // find the concept x in ti.concepts which has the highest significance score. 
       if x.significance > threshold  
          return x 
       else 
          return null 
      } 
 
The algorithm returns the list of concepts and their significance scores. 
Chapter – 6 
   
 
 - 107 -
Performance Evaluation of the algorithm 6.1:  To evaluate the performance 
of the above algorithm, we have given different queries to a general purpose search 
engine (Google search engine) and collected first 20 documents in response to the 
each given query. Out of those documents, the documents relevant to the physics 
domain are detected by manual observation and the precision is calculated.  
 
The same sets of 20 documents are given as input to the above algorithm. We have 
used the list of concepts and their signinficance value to filter out the domain 
specific documents from the total documents inputed. We have experimented to 
filter out the documents belonging to the physics domain. Each document dj is 
represented as a vector of concepts C = {c1, c2,…,cm}.  A concept ci has 
siginificance value v i > 0 , if and only if the related concepts of ci are present in 
the document. For a given query word q, let the corrosponding concept in the 
physics domain is cq. A document dj is selected if the concept cq  has significance 
value vq > 0 in the document. The filtered output returned by the above algorithm 
is manually verified and the performance of the algorithm is evaluated in terms of 
precision and recall. 
 
Let the set C contains the first 20 documents returned by the search engine for a 
given query Q. From the set C, the documents relevant to the query Q are marked. 
Let the set R contains the 
relevant documents. Let |R| be 
the number of documents in the 
set R. The same documents 
belonging to the set C are 
further processed for filtering 
using domain specific concepts 
and its significance value as 
discussed above. After filtering, 
let it generates a document 
answer set A. Let |A| be  the Figure 6.4 Precision and recall measure
Chapter – 6 
   
 
 - 108 -
number of documents in this answer set. Further, let |Ra| be the number of 
documents in the intersection of the sets R and A. Figure 6.4 illustrates these sets. 
The precision and recall measures are defined as follows: 
Precision is the fraction of the retrieved documents, which is relevant. 
Precision = |Ra| / |A| 
Recall is the fraction of the relevant documents, which has been retrieved. 
Recall = |Ra| / |R| 
Table 6.1 gives experimental results.  
 
Table 6.1 Performance evaluation in terms of precision and recall 
 
S.
 N
o.
 
 In
pu
t  
qu
er
y 
 
N
o.
 o
f  
re
le
va
nt
 d
oc
um
en
ts
 
ou
t o
f  
20
 d
oc
um
en
ts
 
(w
ith
ou
t u
si
ng
 c
on
ce
pt
 
id
en
tif
ic
at
io
n)
 
Pr
ec
isi
on
 in
 p
er
ce
nt
ag
e 
(w
ith
ou
t u
si
ng
 c
on
ce
pt
 
id
en
tif
ic
at
io
n)
 
N
o.
 o
f  
fil
te
re
d 
do
cu
m
en
ts
 
(u
sin
g 
co
nc
ep
t i
de
nt
ifi
ca
tio
n)
 
N
o.
 o
f  
re
le
va
nt
 d
oc
um
en
ts
 
ou
t o
f f
ilt
er
ed
 d
oc
um
en
ts
 
(u
sin
g 
co
nc
ep
t i
de
nt
ifi
ca
tio
n)
 
Pr
ec
isi
on
 in
 p
er
ce
nt
ag
e 
(u
sin
g 
co
nc
ep
t i
de
nt
ifi
ca
tio
n)
 
R
ec
al
l i
n 
pe
rc
en
ta
ge
 
(u
sin
g 
co
nc
ep
t i
de
nt
ifi
ca
tio
n)
 
1 Gravity 4 20 4 4 100 100 
2 Motion 2 10 2 2 100 100 
3 Reflection 5 25 4 4 100 80 
4 Acceleration 8 40 8 5 62.5 62.5 
5 Torque 3 15 4 2 50 66.6 
6 Force 1 5 1 1 100 100 
7 Charge 3 15 3 3 100 100 
8 Lever 6 30 6 4 66.66 66.6 
9 Friction 18 90 16 16 100 88.88 
10 Pulley 8 40 6 4 66.6 50 
11 Conductor 3 15 4 3 75 100 
12 Velocity 2 10 2 2 100 100 
 
Chapter – 6 
   
 
 - 109 -
Improvement in Precision using Concept 
Identification
0
20
40
60
80
100
120
1 2 3 4 5 6 7 8 9 10 11 12
Query
Pr
ec
is
io
n without concept
identification
Google + concept
idetification
 
Figure 6.5 Performance evaluation of the algorithm in terms of precision 
 
The improvement in the precison using concept identification and using its 
significance for document search is shown in the Figure 6.5. The x axis represents 
the input query and the y axis represents the precision obtained in percentage for 
the given query set given in Table 6.1. We find that there is an improvement in 
precision for filtering the domain specific documents using concepts and its 
siginficance value. 
6.3.3  Concept Type Identification  
Psychologist David Ausubel (Ausubel, 1963; 1968) formulated a learning theory 
that is of practical use in educational systems. The primary idea of Ausubel’s 
theory is that the learning of the new knowledge is dependent on what is already 
known. In Ausubel’s view the most important thing a learner could bring to a 
learning situation is what s/he already knows. According to him, meaningful 
learning results when the learner explicitly ties new knowledge to the known 
concepts within her/his current state of knowledge. The objective of any learning 
system or tutoring system is to provide meaningful learning to the learner. 
Therefore a learning system or a tutoring system needs to know whether a concept 
mentioned in a document is a pre-requisite for studying that document, or it can be 
Chapter – 6 
   
 
 - 110 -
learned from the document. The learned concepts are the outcome concepts. 
Generally, the outcome concept is defined or explained in a document using a set 
of concepts, some of which may be prerequisite for understanding the document.  
 
To identify the outcome and the prerequisite concepts for the document, we further 
consider two types of concepts: defined concepts and used concepts. A concept ci 
is known as a defined concept, if it is defined/explained in a sentence. Each 
concept ck from the set of concepts {c1, c2,.. ,ck, .. ,cj}, which is used to 
define/explain the concept ci is referred as the used concept. 
6.3.3.1 Identification of Defined Concept and Used Concept  
The identification of the type of concept is a complex problem. To extract the type 
of concepts from a sentence, our approach uses the features such as verbs, phrases 
with their associated semantics in conjunction with patterns. We observed that the 
sentences, which state definitions usually, contain verbs like defined, derived, 
called, known, states and follow some pattern. Sentences involving explanation of 
concepts generally contain occurrences of the verbs like deal, described, discussed, 
explained or phrases like “deal with”, “described as”, “known as”. Sentences that 
contain one of these trigger words/phrases are further analyzed to find the type of 
concepts from them. 
 
We analyze the sentences using a shallow parsing approach. Sentences with these 
trigger words/phrases are parsed using a publicly available parser called the link 
parser (Link Grammar, http://bobo.link.cs.cmu.edu/link/). The parser outputs link 
type detail between the words through labels. Labels associated with the links 
represent the type of dependency. The type of dependency between the trigger-
words and the other noun words in a sentence helps in finding the semantic 
relationship between those words, which in turn helps in determination of the type 
of concepts. 
 
Let us take a sentence “Work is defined as a force acting upon an object to cause a 
displacement”, which contains the trigger word defined. If we parse this sentence 
Chapter – 6 
   
 
 - 111 -
using the link parser, the constituent tree and link type detail retuned by the link 
parser is shown in Figure 6.6 and Figure 6.7 respectively.  
 
 
The Constituent tree 
 
S (NP Work) 
   (VP is 
       (VP defined 
           (PP as 
               (NP (NP a force) 
                   (VP acting 
                       (PP upon 
                           (NP an object)) 
                       (S (VP to 
                             (VP cause 
                       (NP a displacement)))))))))) 
 
 
Figure 6.6 Constituent Tree 
 
 
 
 
 
 
 
 
 
 
 
 
   +---------------------------------------------Xp---------------------- 
    |                                            +----------MVp---------+  
    |                                            |      +----Js---+     +- 
    +---Wd---+--Ss-+--Pv--+--MVp--+--Jp--+---Mg---+--MVp-+   +--Ds-+    |  
    |        |     |      |       | +-Dsu+   |        |      |   |     |       
LEFT-WALL work.n is.v defined.v as.p a force.n acting.v upon an object.n to  
 
 
-----------------------+ 
                       | 
------Jp-------+       | 
   +-----AN----+       | 
   |           |       | 
cause.n displacement.n.RIGHT-WALL 
 
 
Figure 6.7 Linkage detail 
 
 
Chapter – 6 
   
 
 - 112 -
 
In Figure 6.7, the words are followed by one of .n, .v, .a, or .e, depending on 
whether the word is being interpreted as a noun, verb, adjective, or adverb in the 
sentence. For example, the word work.n indicates that it is a noun. The artificial 
words LEFT-WALL and RIGHT-WALL are inserted at the beginning and the end 
of every sentence respectively. The link type labeling between words for the above 
sentence is shown in tabular form in the Table 6.2. 
 
 
Table 6.2 Link type labeling 
 
Word Link type Word 
LEFT-WALL Xp . 
LEFT-WALL Wd work.n 
work.n Ss is.v 
is.v Pv defined.v 
defined.v MVp as.p 
as.p Jp force.n 
a Dsu force.n 
force.n Mg acting.v 
acting.v MVi to 
acting.v MVp upon 
upon Js object.n 
an Ds object.n 
to I cause.v 
cause.v Os displacement.n 
a Dsu displacement.n 
. RW RIGHT-WALL 
 
The interpretation of the link types between words is shown in Table 6.2 is given 
in Table 6.3. 
 
Chapter – 6 
   
 
 - 113 -
Table 6.3 Interpretation of the link types between words 
 
Link Type Interpretation 
Xp X is used to connect punctuation symbols to words. Xp connects 
LEFT-WALL to the end of the sentence. 
Wd W is used to attach main clauses to the left-wall. Almost all kinds 
of main clauses - declaratives, most questions (object-type, subject-
type, where/when/why, and prepositional), and imperatives - use a 
W of some kind to attach to the wall. Wd is used in ordinary 
declarative sentences, to connect the main clause “work” back to 
the wall (or to a previous coordinating conjunction). 
Ss S connects subject-nouns to the finite verbs. Ss connects singular 
noun words to singular verb forms. Sp connects plural nouns to 
plural verb forms. 
Pv Pv is used to connect forms of "be" to passive participles: for 
example “Work is defined.” Pv connects is and defined. 
MVp MV connects verbs (and adjectives) to modifying phrases like 
adverbs, prepositional phrases, time expressions, certain 
conjunctions, "than"-phrases, and other things. 
J J connects prepositions to their objects. 
Mg M connects nouns to various kinds of post-nominal modifiers 
without commas, such as prepositional phrases, participle 
modifiers, prepositional relatives, and possessive relatives. Mg 
connects noun “force” with present participles “acting”. 
Mvi Mvi is used to connect infinitival phrases to verbs and adjectives 
when they mean "in order to". For example "force acting upon an 
object to cause a displacement". 
Ds D connects determiners to nouns. 
I I connect certain verbs with infinitives. 
Os O connects transitive verbs to direct or indirect objects. 
Dsu D connects determiners to nouns. 
RW Right Wall (Sentence ending) 
  
As discussed above, the link between two words represents a direct semantic 
relationship. A path is extracted from each sentence using link labels, which give 
Chapter – 6 
   
 
 - 114 -
the semantic relationship between words. We are mainly interested in extracting 
noun words (concepts) and the semantic relationship of noun words with other 
words. The path extracted from the above sentence is shown in Figure 6.8. 
 
Figure 6.8 Semantic relations between words 
 
In this diagram, the slots are filled with nouns (concepts). The noun words are 
connected by verbs. From the linkage diagram, we find that the noun (concept) 
work is the subject of the sentence and it is connected with the verb “is defined”. In 
this sentence, the subject work precedes the trigger phrase is defined is the concept 
to be defined, while the other concepts in the sentence such as force, object and 
displacement are used for defining the concept work. An inference rule that is 
derived from the above discussion is as follows. 
 
Inference Rule 1: When the trigger word/trigger phrase is connected with the 
subject and the subject is a noun (concept), then that subject is the defined concept 
and the other concepts in the sentence are used concepts. 
 
Chapter – 6 
   
 
 - 115 -
However, the inference rule 1 is not applicable in all situations. There are many 
ways to write the same sentence. For example the above sentence can also be 
written in following ways.  
1. Force acting upon an object to cause a displacement is called work. 
2. Force acting upon an object to cause a displacement is known as work. 
 
The inference rule 1 is not valid for sentences 1 and 2. In above sentences, the 
defined concept is the object of the sentence whereas subject of the sentence 
contains the used concepts. 
 
+-------------------------------------------Xp--------------------------- 
    |        +-----------------------------Ss-----------------------------+   
    |        |        +----------MVi---------+                            |   
    |        |        |      +----Js---+     |    +------Os-----+         |   
    +---Wd---+---Mg---+--MVp-+   +--Ds-+     +--I-+    +---Dsu--+         +-- 
    |        |        |      |   |     |     |    |    |        |         |   
LEFT-WALL force.n acting.v upon an object.n to cause.v a displacement.n is.v  
 
 
----------------+ 
                | 
                | 
                | 
Pv--+---Os--+   | 
    |       |   | 
called.v work.n .RIGHT-WALL  
 
 
 
 
Figure 6.9 Linkage detail 
 
Let us take sentence 1. The linkage diagram for sentence 1 is shown in the Figure 
6.9. In this sentence the noun (concept) work, which succeeds the trigger phrase “is 
called” is the defined concept. Here work is the object of the sentence. It is 
connected with the RIGHT-WALL in the linkage diagram. In such cases, the noun 
words (concepts) present in the subject (Ss) of the sentence are the used concepts 
while the object is the defined concept. In sentence 1, the concepts force and 
displacement are the used concepts. 
 
Inference rule 2: If the trigger word/trigger phrase is connected with the object, 
the object is a noun (concept) and it is connected with the RIGHT-WALL (link 
label), then the object is the defined concept and the concepts present in the 
subject are the used concepts. 
 
 
Chapter – 6 
   
 
 - 116 -
Let us consider a few more examples.  
• “The law of reflection states that the angle of incidence equals the angle of 
reflection”. In this case, the subject “law of reflection” is connected with 
the trigger word states. Subject “law of reflection” is a defined concept 
while “angle of incidence” and “angle of reflection” are the used concepts.  
• “Law of motion is illustrated in section one”. Here the defined concept law 
of motion is the subject of the sentence and is connected to the trigger 
phrase “is illustrated”.  
• “In this section, we deal with virtual images”.  In this sentence the defined 
concept virtual image is connected with the trigger phrase “deal with”.  
 
Algorithm for identification of defined concept and used concept is outlined below. 
 
Algorithm 6.2: Identification of defined concepts and used concepts 
Input : document D 
Output: defined concepts and used concepts for D 
// document D 
// D contains m sentences S1 ,… Sj ,… Sm. 
// C is the concept list of D containing p concepts, C ← {c1 ,…, ck ,…, cp } 
// T is the list of trigger words and trigger phrases, T ← {t1 ,…, ti ,…, tn} 
 
(1) select  Sj from D that contains a trigger word/ phrase ti  
(2) parse Sj using a link parser and obtain the link detail output. 
(3) L← { c1 ,…,ck , …,cq } //where L is the list of concepts present in Sj 
(4)  if  ti is connected to the subject of Sj and the subject is a concept ck  
return ck as a defined concept and other concepts in L as the used 
concepts. 
      else if ti  is connected to the object of Sj and the object is a concept ck 
return ck as a defined concept and the other concepts in L present in the 
subject as the used concepts.  
 
Performance Evaluation of the algorithm 6.2 : 
The algorithm for concept type identification was tested on 50 documents. Each 
document was read manually and the concepts were differentiated. Separate lists of 
Chapter – 6 
   
 
 - 117 -
the defined concepts and the used concepts were made for each document. This list 
was compared with the algorithm output. The performance of the algorithm 6.2 is 
shown in Table 6.4. 
 
 
 
Table 6.4 Performance of the algorithm output  
 
Manual Observation Algorithm Output 
 
Used Concepts 
 
 
Defined Concepts 
 
Total 
Docu-
ments 
 
  Total 
concepts 
 
  Total 
Used 
concepts 
 
Total 
Defined 
concepts  
    
Correct 
  
   
False    
posi- 
 tive 
 
 
 
   
False    
nega- 
 tive 
 
 
 
    
Correct 
 
False 
posi - 
tive 
 
False  
nega -
tive 
 
50 
 
987 
 
836 
 
151 
 
836 
 
14 
 
0 
 
137 
 
0 
 
14 
 
 
It is observed from Table 6.4, that algorithm misclassified 14 defined concepts as 
used concepts.  
 
Let us discuss the limitations of the above discussed concept type identification 
algorithm. There are sentences, which define some concepts, but are not 
considered for further analysis. For example: 
 
• The principal axis is the line that joins the centers of curvature of its surfaces.  
• The focal point is the point where a beam of light parallel to the principal axis 
converges. 
• The focal length is the distance from the center of the lens to the focal point.  
 
In the above sentences, principal axis, focal point and focal length all are the 
defined concepts, but the parser is not able to identify them as defined concepts. 
Presently, the algorithm is incapable of handling sentences following the pattern of 
the example sentences mentioned above. To improve the performance of the 
algorithm, inference rules for such type of sentences have to be discovered and all 
those sentences have to be taken into account. 
Chapter – 6 
   
 
 - 118 -
6.3.3.2  Extraction of Outcome and Prerequisite Concepts from the 
     Document 
Algorithm 6.2 returns separate lists of defined concepts and used concepts. The 
outcome concepts and the prerequisite concepts for the document are extracted 
from these lists. The outcome concept is the concept, which a learner learns from 
the document. As discussed above, the defined concepts are defined or explained in 
a document. A learner learns defined concepts from the document. Therefore the 
defined concepts are the outcome concepts. The prerequisite concepts for the 
document are the concepts, which are used to explain the outcome concept and 
required to be known by a learner to understand the document. Therefore the list of 
used concepts gives the list of prerequisite concepts for the document. But all the 
concepts present in the used concept list in a document may not be the prerequisite 
for the document. For example, if a concept x is defined in the first paragraph of a 
document and in the second paragraph, the same concept x is used to define some 
other concept y, although, the concept x is a used concept for defining the concept 
y, but it is not the prerequisite for the document. Because the concept x is 
explained in the first paragraph of the document and the learner can learn it from 
this document itself. Let us take a portion of a document shown in the figure 6.10.  
 
1). Laws of Reflection  
Key Concepts 
An interface is boundary region between two media. A light ray is a stream of light with the 
smallest possible cross-sectional area. (Rays are theoretical constructs.)  
The incident ray is defined as a ray approaching a surface.  
The point of incidence is where the incident ray strikes a surface.  
A line drawn perpendicular to the surface at the point of incidence is called normal.  
The reflected ray is the portion of the incident ray that leaves the surface at the point of incidence.  
The angle between the incident ray and the normal is known as angle of incidence. The angle 
between the normal and the reflected ray is known as angle of reflection.  
Laws of reflection states that  
• The angle of incidence is equal to the angle of reflection.  
• The incident ray, the normal, and the reflected ray are coplanar.  
 
Figure 6.10 A portion of a document  
Chapter – 6 
   
 
 - 119 -
 
For this document, the list of defined concepts and used concepts are as follows: 
  
Defined concept list = (angle of incidence, angle of reflection, incident ray, laws of 
reflection, light ray, normal, point of incidence, ray, reflected ray) 
 
Used concept list = (angle, area, angle of incidence, angle of reflection, coplanar, 
incident ray, light, line, ray, normal, point of incidence, reflected ray, surface) 
 
The concepts incident ray, reflected ray, normal, angle of incidence and angle of 
reflection are defined in first few paragraphs of this document (Figure 6.10). These 
defined concepts are used to explain the other concept laws of reflection. In this 
document, a learner first learns the defined concepts incident ray, reflected ray, 
normal, angle of incidence and angle of reflection and then uses these concepts to 
understand the concept laws of reflection. Therefore the concepts incident ray, 
reflected ray, normal, angle of incidence and angle of reflection are not the 
prerequisite for the document. The list of outcome concepts and the prerequisite 
concepts for the document shown in Figure 6.10 is as follows:  
 
Outcome concept list = (angle of incidence, angle of reflection, incident ray, laws 
of reflection, light ray, normal, point of incidence, ray, reflected ray) 
 
Prerequisite concept list = (angle, area, coplanar, light, line, surface) 
 
The outcome concepts and the prerequisites concepts for the document are 
extracted from the list of the defined concepts and the used concepts. The defined 
concepts list gives the outcome concepts of the document. To find the prerequisite 
concepts list, the used concepts list is compared with the defined concepts list. The 
defined concept, which also exists in the used concepts list are removed from the 
used concepts list. The new used concepts list gives the prerequisite concepts for 
the document.  
 
 
 
Chapter – 6 
   
 
 - 120 -
Algorithm 6.3: Identification of outcome and prerequisite concepts 
 
Input: List of defined concepts DL ← { c1 ,c2 ,……, cn} 
      List of used concepts UL ← { c1 ,c2 ,……, cm}  
Output: List of outcome concepts OL ← { c1 ,c2 ,……, cn} 
        List of prerequisite concepts PL ← { c1 ,c2 ,……, cp} 
 
(1) Get DL and UL 
(2) OL ← DL 
Return OL 
(3) PL ← UL – DL 
Return PL 
 
The performance of the algorithm 6.3 depends upon the algorithm 6.2 i.e. how 
accurately the algorithm 6.2 extracts the list of defined concepts and the list of used 
concepts from the document.  The performance evaluation of the algorithm 6.2 is 
shown in Table 6.4. 
 
The limitation of the algorithm 6.3 is that we are blindly removing the defined 
concepts from the list of used concepts to obtain the prerequisite concepts for the 
document.  There are cases, where some concepts are very difficult and students 
should learn it properly beforehand to understand the document. Those difficult 
concepts should be prerequisite for the document. But if those concepts are defined 
somehow somewhere in the document and present in both the defined concept list 
and the used concept list, the algorithm 6.3 does not consider them as prerequisite 
for the document. 
6.3.4  Topic Identification 
The e-learners’ requirement is generally given in terms of topics in a curriculum 
requirement. The syllabus of any subject consists of several topics. Different 
learners will have different requirements and hence may be interested in different 
topics. If the documents are annotated with the metadata topic, then it becomes 
Chapter – 6 
   
 
 - 121 -
easier to search and identify documents according to the learner’s interest. We 
want to classify documents into different topics as given in the syllabus, so that a 
learner can search and navigate documents on topics according to the curriculum 
requirement.  
 
Researchers have carried out the work on automatic generation of topics from web 
documents in the past. Machine learning based document classification is now a 
prevalent approach. The work of automatic generation of the subject of a document 
by Li et al. (Li, 2004) is based on a neural network. In their approach, they have 
used the term-weight vector of the documents as feature vector. To reduce the 
original term-weight vectors with high dimensionality to a small number of 
relevant features, they have used principal component analysis technology. 
Common terms may appear in more than one category, which in turn reduces the 
classification performance.  
 
To reduce the consideration of common or overlapping concepts in more than one 
category, Bot et al. (Bot, 2004) remove the terms that are too broad in the 
document. Their approach for the web document classification is based on the 
vector space model with cosine similarity. They have chosen the maximum of 6 as 
the maximum category frequency for a term to qualify in the final list. Category 
frequency is the number of categories in which a term occurs. The final list for 
each category is used to build a representative weighted category vector.  
 
Haruechaiyasak et al. (Haruechaiyasak, 2002) proposed a method of automatically 
classifying web documents into a set of categories using the fuzzy association. The 
fuzzy association is used to capture the relationships among different index terms 
or keywords in the document. Each pair of words has an associated value to 
distinguish itself from the others. Therefore, the ambiguity in the word usage is 
avoided. They showed that the result with this approach is better than the result 
obtained with the vector space model. 
 
Chapter – 6 
   
 
 - 122 -
Gelbukh et al. (Gelbukh, 1999) have given a method of document classification on 
a hierarchical dictionary of topics. The hierarchical links in the dictionary are 
supplied with the weights that are used for detecting the main topics of a 
document. The dictionary consists of two major parts, the vocabulary and the 
hierarchical structure. The vocabulary contains keywords. The hierarchical 
structure represents the topics. The links in the hierarchy have different weights. 
These weights give the strength of the relationship of the keywords to the given 
topics. For example, the word Italy belongs to the topic Europe, thus, the weight of 
this link is 1. On the other hand, the word London can refer to a city in England but 
with much less probability, in Canada, consequently the weight for the link 
between London and Canada is very less. To obtain the topics of documents, the 
keywords in a document are compared with hierarchical dictionary of topics. 
 
There are some research works, where ontology of the domain has been used for 
automatic topic identification. In the work of ontology based automatic annotation 
of learning content (Jovanovic, 2006a), Jovanovic et al. annotate the documents 
with subject (topic) using the domain ontology. They annotate the documents, 
which are available in slide format. The whole document is the learning object and 
the different slides of the document form the content object. Initially, the author 
provides the subject (topic) of the learning object during submission. They 
generate the metadata elements of the content objects based on the subject (topic) 
of the learning object provided by the author. The annotation of the different 
content objects (or slides) is done by looking at the related concepts of the subject 
of the learning object. The annotation of the content objects depends on the subject 
of learning object. This method fails to annotate the content objects, if the subject 
of the learning object is not available. A major limitation of their work of subject 
identification is that it needs author’s supplied information.  
 
We have used two approaches to identify the topic of a document. As discussed 
above machine learning methods is a dominant approach in example-based 
classification and is used by many researchers (Li, 2004; Bot, 2004; 
Haruechaiyasak, 2002) for topic identification of web documents. The first 
Chapter – 6 
   
 
 - 123 -
approach used in our work is example based where a classifier is trained with a set 
of example documents and then the classifier is used to identify the topic of a 
document based on the examples. We have used probabilistic neural network 
(PNN) to obtain the topic of a document belonging to a particular class. The 
classifier performance is fairly good for identifying topics of the documents, which 
do not have overlapping concepts. The documents belonging to the topics of the 
same chapter may have many common concepts. In such cases, the accuracy of the 
classifier is less. A syllabus consists of many topics and we want to classify the 
documents into the different topics given in the syllabus. Documents of each topic 
of the syllabus have to be collected to train the classifier. This process of document 
collection is a very tedious task. To avoid this, we have used the second approach 
of topic identification using ontology. 
 
The second approach uses the ontology of the system for automatic topic 
identification. Jovanovic et al. (Jovanovic, 2006a) also use ontology for topic 
identification. However, the limitation of the Jovanovic’s work is that the 
automatic identification of the topic of the different content objects depends on the 
subject of the learning object given by the author. It will not work for documents 
where this information is not available. We want to identify the topic of a 
document automatically using the ontology only without depending upon the 
author’s supplied information. 
  
The example based classifier and the ontology based topic identification algorithm 
are discussed in Section 6.3.4.1 and Section 6.3.4.2 respectively.  
6.3.4.1 Example Based Classifier 
Many classification algorithms have been developed. The neural network has been 
successfully used in many classification tasks. We have used the probabilistic 
neural network (PNN) to obtain the topic of a document. Probabilistic Neural 
Networks (PNN) with Gaussian functions has been used to design the modular 
network structure. The architecture of a typical PNN is shown in Figure 6.11. The 
Chapter – 6 
   
 
 - 124 -
PNN architecture is composed of many interconnected neurons organized in 
successive layers. The PNN has a 3-layer feed-forward structure.  
 
Pattern layer: When an input is presented, the first layer computes distances from 
the input vector to the training vectors, and produces a vector whose elements 
indicate how close the input is to a training vector. This layer assigns one node for 
each of the training pattern. There are two parameters associated with each pattern 
node. 
the centres with dimension 1
the covariance matrix 
where, 
is the dimension of the input vector or the number of features
i
i
N
N N
N
→ ×
→ ×
→
w
Σ
 
The output of each of the pattern nodes is given as: 
    
( ) ( ){ }1exp , 1, 2, ,
the number of training patterns
T
i iv i M
M
−= − − − =
→
i ix w Σ x w L  
 
Figure 6.11 Probabilistic neural network architecture 
 
Chapter – 6 
   
 
 - 125 -
Summation layer: The second layer sums these contributions for each class of 
inputs to produce as its net output a vector of probabilities. The number of nodes in 
this layer is the number of classes. Each of these nodes receives an input from each 
of the pattern nodes through a set of weights. The output of this layer is given as: 
( )
( )
1
, 1, 2, ,
the number of classes
the weight associated with the  pattern node to  summation node
is the output of the  summation node
M
s
j jk k
k
s th th
jk
th
j
o v j L
L
k j
o j
=
= =
→
→
→
∑w
w
L
 
 
Decision layer: Finally, a complete transfer function on the output of the second 
layer picks up the maximum of these probabilities and produces a 1 for that class 
and a 0 for the other classes.  
 
We have used the MATLAB neural network toolbox to create a probabilistic 
neural network. The feature set used for the automatic identification of the topic of 
the document is discussed below. 
 
Feature Set: Each document can be represented by a set of concepts. The concepts 
are domain specific and therefore unambiguous. The feature set contains the 
concepts present in the document. The input feature vector is a concept-weight 
vector, which represents the content of the document. In the input feature vector, 
we consider the number of occurrences i.e. the frequency of each concept in a 
document. The frequency is normalized with respect to the number of words 
present in the document. Specifically, the importance of a concept is proportional 
to the normalized frequency of the concept in each document. 
 
Identification of the topic of the document using PNN classifier: Let us 
consider a part of a topic tree shown in Figure 6.12. The root node of the tree is the 
subject physics. The child nodes of the root of the tree are the chapters of physics 
such as kinematics, optics, electricity etc. Each chapter node has many child nodes, 
which represent the topics of that chapter in the topic tree. A document can belong 
to one or more topics that are to be identified using the classifier. 
Chapter – 6 
   
 
 - 126 -
 
 
Figure 6.12 A part of a topic tree 
 
 
 
The experiment for topic identification has been carried out to test the performance 
of the classifier. For experimentation, we have collected documents on different 
topics namely lens, mirror, optical image, prism, telescope, refraction. For each 
topic, 40 documents are collected. We have collected a total of 240 documents and 
feature vectors are created for all 240 documents. Out of total 240 vectors, 120 
vectors are used for training and the rest 120 vectors are used for testing the 
classifier. The experimental results are given in Table 6.5. The column input shows 
the number of documents along with its topic name given to the trained classifier 
for classification. The column output shows the classifier output.  
 
 
 
 
physics
kinematics optics electricity
displacement velocity
lens prism Optical imagemirror
conductors
charge
level 1
level 2
Chapter – 6 
   
 
 - 127 -
Table 6.5 Performance of the classifier  
 
Input to the 
Classifier 
Classifier Output  
(Number of documents) 
T
op
ic
 
N
um
be
r 
of
 
do
cu
m
en
ts
 
L
en
s 
M
ir
ro
r 
O
pt
ic
al
 im
ag
e 
T
el
es
co
pe
 
L
aw
 o
f  
re
fr
ac
tio
n  
Pr
ism
 
Pr
ec
is
io
n 
(%
) 
R
ec
al
l (
%
) 
Lens 20 12 2 4  4  40 60 
Mirror 
20  10 6   4 76.9 50 
Optical 
image 
20 5 1 12   2 52.1 60 
Telescope 20 7  3 10   100 50 
Law of 
refraction 
20     10 10 55 50 
Prism 20 6    4 12 42.8 60 
 
The average precision obtained is 61% and is very poor. We tried to find out the 
reason of the poor performance of the classifier. For that we have tested the 
classifier   performances for two different cases with less number of classes.  
 
Case 1: In the first case, only two topics are taken. The topics are belonging to the 
same parent or the sibling nodes in the topic tree. For example, we are looking at 
the classification task to classify the documents into the topic lens and the mirror 
from the chapter optics as shown in Figure 6.12. Feature distribution in documents 
of the topic mirror and lens are shown in Figure 6.13 and 6.14. We find that there 
are many common concepts such as principal axis, focus, center of curvature etc. 
present in the documents belonging to the topics lens and mirror. These common 
concepts mislead the classifier and leads to incorrect classification. Precision of the 
classifier is 82%. Experimental results are given in the Table 6.6.  
 
Chapter – 6 
   
 
 - 128 -
 
Figure 6.14 Distribution of features in document sets 
Figure 6.13 features distribution in documents belonging to the topics lens and mirror 
Chapter – 6 
   
 
 - 129 -
Table 6.6 Classifier output for identification of topics belonging to same parents 
 
Input to the Classifier Classifier output 
Lens Mirror Lens Mirror A
vg
. 
Pr
ec
isi
on
 
N
o.
 o
f 
do
cu
m
en
ts
 
N
o.
 o
f 
do
cu
m
en
ts
 
C
or
re
ct
 
Fa
ls
e 
Po
si
tiv
e 
Fa
ls
e 
N
eg
at
iv
e 
C
or
re
ct
 
Fa
ls
e 
Po
si
tiv
e 
Fa
ls
e 
N
eg
at
iv
e 
25 25 20 4 5 21 5 4 
82%  
 
Case 2: In the second case, the classifier is used to identify the topic of those 
documents, which are not the sibling nodes (do not belong to the same parent) in 
the topic tree. For example, the documents of the topic lens (parent node optics) 
and the topic velocity (parent node kinematics) as shown in Figure 6.12 are 
considered for classification. The x-axis represents the feature set and the y-axis 
represents the frequency of occurrences of the features in a document. The feature 
distribution in a few documents of the topic lens and the topic velocity are shown 
in Figure 6.15. Since the topics are chosen from different chapters, the documents 
have very few concepts in common.  
Figure 6.15 features distribution in documents belonging to the topics lens and velocity 
Chapter – 6 
   
 
 - 130 -
The experiment is carried out on 100 documents. We have categorized 50 
documents into the topic velocity and 50 documents into the topic lens by manual 
observation. Out of 100 documents, 50 documents (25 documents from the topic 
velocity and 25 documents from the topic lens) are used to train the classifier and 
the rest 50 documents are used to test the classifier performance. The observation 
is mentioned in Table 6.7. The precision of the classifier is 90 %. 
 
Table 6.7 Classifier output for identification of topics belonging to  
different parents 
 
Input to the Classifier Classifier output 
Velocity Lens Velocity Lens A
vg
. 
Pr
ec
is
io
n 
N
o.
 o
f 
do
cu
m
en
ts
 
N
o.
 o
f 
do
cu
m
en
ts
 
C
or
re
ct
 
Fa
ls
e 
Po
si
tiv
e 
Fa
ls
e 
N
eg
at
iv
e 
C
or
re
ct
 
Fa
ls
e 
Po
si
tiv
e 
Fa
ls
e 
N
eg
at
iv
e 
25 25 25 5 0 20 0 5 
90% 
 
From the observations of the above two cases, we find that classifier accuracy 
reduces due to the presence of the overlapping concepts. For example, the concepts 
used to explain optical image are “magnification”, “image formation by lens”, 
“image formation by mirror” etc. So a document explaining “image formation by 
lens” can also belong to the topic lens. Similarly a document which deals with 
“telescope” can also belongs to the topic lens and image. We find that a document 
can belong to more than one topic. 
 
To get a fairly good classifier performance, the classifier should be trained with a 
large set of documents. In the school curriculum, there are many subjects and each 
subject consists of many topics. It is a difficult task to collect sufficient number of 
documents on each of the topics. Again if new topics are added into the 
curriculum, then documents on new topics have to be collected to train the 
Chapter – 6 
   
 
 - 131 -
classifier. In view of the above difficulty, we have used another approach namely 
ontology based classification for topic identification. 
6.3.4.2 Topic Identification using Ontology 
Our system stores the domain knowledge for the curriculum related topics as 
mentioned in Section 4.3 of Chapter 4. The top level of the domain knowledge is 
the topic level, which keeps the topic taxonomy. The topic-concept relationships 
are kept in the domain knowledge where the concepts covered by each topics of 
the topic taxonomy are kept separately.  
  
The topic is identified on the basis of the concepts that occur in the document. We 
have a list of concepts for each document. A concept may belong to one or more 
topics. For example, as shown in Figure 6.16, the concepts like “focus”, “angle of 
incidence”, “principal axis” etc. belong to the topic mirror as well as to the topic 
lens. For each concept, we find the set of topics that include that concept from the 
domain knowledge. From these we find out the possible sets of topics for the 
document. When we consider a concept, the counters corresponding to each topic 
that includes the concept is incremented by 1. The topic with the maximum score is 
returned as the topic of the document. If more than one topic have the same 
maximum score, the list of such topics are returned. The algorithm is outlined 
below. 
 
Algorithm 6.4: Topic Identification 
Input: document D 
Output:  topic/list of topics 
(1) get list of concepts C from the document D 
(2) get set of topics T that include one or more concepts ci ∈  C where i = 1…m 
(3) ∀  Tj ∈T, initialize score(Tj )← 0 
(4) for each ci 
         { 
 ∀  Tj s. t. ci is part of Tj       
score(Tj)  ← score(Tj )+ 1 
                   } 
(5)  return topic/topics tj with maximum score(Tj)   
Chapter – 6 
   
 
 - 132 -
 
To test the algorithm 6.4, we have used the same set of documents, which have 
been used for testing the classifier performance. The experimental results of the 
algorithm 6.4 are given in Table 6.8.  
 
Table 6.8 Performance of the algorithm 6.4 
 
Input Algorithm Output (Number of documents) 
Topic 
N
um
be
r 
of
 
do
cu
m
en
ts
 
L
en
s 
M
ir
ro
r 
O
pt
ic
al
 im
ag
e 
Te
le
sc
op
e 
L
aw
 o
f 
re
fr
ac
tio
n 
Pr
ism
 
O
th
er
s 
Pr
ec
is
io
n 
(%
) 
R
ec
al
l (
%
) 
Lens 20 14 4     2 50 70 
Mirror 20 4 12     4 60 60 
Optical 
image 20 10 4 0    6 
0 0 
Telescope 20    16   4 100 80 
Law of 
refraction 20     16  4 
100 80 
Prism 20      15 5 100 75 
Physics
Optics
Mirror Lens
Focal point
Angle of 
incidence
Principal axis
focus
Kinematics Electricity
Image
refraction
Figure 6.16 Figure 6.16 Topic Concept Relationships 
Chapter – 6 
   
 
 - 133 -
The results obtained with the algorithm 6.4 are not satisfactory. The accuracy 
obtained with the algorithm 6.4 is 68%. The various reasons for this dissatisfactory 
performance are discussed here. 
 
1. A concept can belong to more than one topic. In other words two topics can 
have common concepts. Generally, the documents belonging to sibling 
nodes have many common concepts. Therefore in some cases, the 
algorithm identifies a document as belonging to a sibling topic. 
 
2. In some cases, documents are dealt with a large set of inter related concepts 
for its explanation. Due to the presence of too many inter related concepts, 
the algorithm returns more than one topic.  
 
3. On the other hand, it is also difficult to judge the main topics of a 
document, if the numbers of concepts present in the document are very less.  
 
4. There are some concepts, which are very ambiguous in nature and occur in 
many documents. For example, the concepts “distance”, “angle”, 
“motion”, “normal” etc. These concepts belong to various topics such as 
mirror, lens, Newton’s law of motion, angle, triangle etc. All these topics 
are from different chapters. The topics mirror and lens are from the chapter 
optics; the topic Newton’s law of motion is from the chapter kinematics 
whereas the topic triangle belongs to geometry. The occurrences of these 
concepts lead for the incorrect identification of the topic. 
 
To improve the performance of the above algorithm 6.4, the score function should 
consider a few more parameters. As discussed above, documents may contain 
ambiguous concepts. Also they may have many concepts in common. For example, 
if we take documents of the topics concave mirror and convex mirror, we find that 
they have many concepts in common. We notice that, each concept is not of the 
same significance for a topic. The concept “concave mirror” is very specific to the 
first topic whereas the concept “convex mirror” is very specific for the second 
Chapter – 6 
   
 
 - 134 -
topic. If we give more weights to these significance concepts while scoring, then 
the algorithm accuracy will improve. For this reason, the significance concepts of 
each topic are given more weights than the other concepts. In the ontology, the 
significant concepts of each topic are associated with specificity index (SI) of 
value 1 and the other concepts are associated with value 0.5. The same hypothesis 
is also used by Gelbukh et al (Gelbukh, 1999) for detecting the main topics of the 
document. The method of topic identification is based on a hierarchical dictionary 
of topics, where the hierarchical links in the dictionary are supplied with weights. 
 
In the algorithm 6.4, we have not considered the number of occurrences 
(frequency) of concepts in the document. We augment the above algorithm by 
using the frequency values of the concepts in the score function, which also helps 
in the correct identification of the main topics of the document. 
 
We also notice that in html documents, the concepts occur in the head tags are 
indicative of the topic of the document. Therefore, the concepts that occur in the 
title tags or in the head tags are given more weights.  
 
The modified algorithm is as follows. For each concept, we find the topic name 
and the SI value with respect to the topic from the ontology. If the concept present 
in head or title tag, the score for a topic is incremented by α*normalized concept 
frequency * (SI value) else the score is incremented by the normalized concept 
frequency * (SI value). The topic name with the maximum score gives the main 
topic for the document. In our experiment, we have considered α = 2. 
 
 
 
 
 
 
 
 
Chapter – 6 
   
 
 - 135 -
The algorithm is outlined below. 
 
Algorithm 6.5: Topic identification using specificity index 
 
Input: document D 
Output: topic TN 
 
(1) get concept list C ← { c1 ,…, ci ,…,cm } from the document D 
(2) get frequency Fi ← ci.frequency  of each concept ci ∈ C 
(3) find the normalized frequency NFi (ci) 
 
   NFi (ci)← num
Fi   // num is the total number of tokens in D 
 
(4) get set of topics T that include one or more concepts ci along with its specificity 
index SI(ci,Tj)  from the ontology. 
 
 (5) ∀  Tj ∈T, initialize score(Tj)← 0 
 for each ci  
            {     
      for each Tj ∈T s. t. ci ∈C 
              {               
      if  ci occurs in the head tag or title tag 
                            score(Tj) ← score(Tj)  +  α* SI(ci, Tj) * NFi (ci)   //we take α = 2 
                       else 
                            score(Tj) ← score(Tj) + SI(ci, Tj) * NFi (ci)  
             } 
   } 
      (6) return TN← arg 
Tj
max score(Tj)  
 
Chapter – 6 
   
 
 - 136 -
To test the algorithm 6.5, we have used the same set of documents, which have 
been used for testing the algorithm 6.4 and also the classifier performance. The 
experimental results of the algorithm 6.5 are given in Table 6.9. The average 
precision obtained with the algorithm 6.5 is 95%.  
 
Table 6.9 Performance of the algorithm 6.3 
 
Input Algorithm Output (Number of documents) 
T
op
ic
 
N
um
be
r 
of
 
do
cu
m
en
t 
L
en
s 
M
ir
ro
r 
O
pt
ic
al
 im
ag
e 
T
el
es
co
pe
 
L
aw
 o
f  
re
fr
ac
tio
n 
Pr
is
m
 
O
th
er
s 
 P
re
ci
sio
n 
(%
) 
R
ec
al
l (
%
) 
Lens 20 20       86.95 100 
Mirror 20  14 2    4 100 70 
Optical 
image 20 3  17     
89.47 85 
Telescope 20    16   4 100 80 
Law of 
refraction 20     19  1 
95 95 
Prism 20     1 19  100 95 
 
On comparing the output results of the example based classifier and the ontology 
based topic identification; we find that the algorithm 6.5 of ontology-based 
approach gives fairly good results.  
 
The performance of the algorithm 6.5 is tested on documents belonging to different 
topics. Table 6.10 shows some of the selected topics from subjects physics, biology 
and geography, on which the algorithm has been tested. The test has been done on 
Chapter – 6 
   
 
 - 137 -
a total of 770 documents and the output of the algorithm is verified against 
manually labeled topics. The performance evaluation of the algorithm in terms of 
recall and precision is shown in the Table 6.10. 
 
 Table 6.10 Performance of the topic identification algorithm 6.5  
 
Topic Recall (%) Precision(%) 
Photosynthesis 91.66 84.61 
Human circulatory system 80 83.33 
Respiration 64.28 90 
Human eye 78.94 88.23 
Human ear 70 93.33 
Chromosome 61.33 88.88 
Lens 97.88 84.21 
Mirror 88.66 92.85 
Newton’s law of motion 93 86.66 
Soil 86.95 78.57 
Rock 90 64.28 
 
Identification of a topic of a document for an e-learner in the context of formal 
school curriculum is a difficult problem. Some of the difficulties are indicated 
before. Ontology based classification seems to perform somewhat better than 
example based classification. However the performance of both falls short to the 
acceptable level, especially while dealing with closely related subtopics. Use of 
specificity index improves the results of the ontology-based classification. 
However this index may not be available in many ontologies.  
6.3.5  Learning Resource Type Identification 
As discussed in Chapter 5, the pedagogic type of a learning resource is an 
important metadata to fulfill the educational objective of a student.  Following the 
learning theories given by Ausubel (Ausual, 1968) and Bloom’s taxonomy 
Chapter – 6 
   
 
 - 138 -
(Bloom, 1956), we have categorized documents into four classes namely 
explanation type, application type, exercise type and experiment type. Documents 
are to be classified into these categories based on their contents. This is a 
classification problem, which we have solved using artificial neural networks.  
 
Rauber et al. (Rauber, 2001) present a way to provide automatic analysis of the 
structure of the text documents for content- based organization of documents into a 
digital library. The analysis is based on a combination of various surface level 
features of the text, such as word statistics, punctuation information, the 
occurrences of special characters and keywords, equation, hyperlink and similar 
information. Based on these structural descriptions of documents, the self-
organizing map (SOM) is used for clustering documents according to their 
structural similarities. Stamatatos et al. (Stamatatos, 2000) present an approach for 
text categorization in terms of genre and author. Text genre detection concerns the 
identification of the kind of the text. According to Kesseler et al.(Kessler, 1997) 
generic cues such as structural cues, lexical cues, character level cues and 
derivative cues can easily be detected from the text, which can be used for text 
categorization. 
 
We have also identified some of the surface level features of the text (similar to the 
above discussed work of Rauber et al., Stamatatos et al. and Kesseler et al.) and 
used those features to classify the documents into different categories using 
artificial neural networks. The features are the occurrence of a set of specific verbs, 
words, phrases, and special characters in a document. First, we have experimented 
with a FeedForward Backpropagation Neural Network to classify the documents. 
The FeedForawrd Backpropagation classifier takes number of iterations to 
converge to the desired solution. The Generalized Regression Neural Networks 
(GRNN) involve one-pass learning. Therefore, we have also experimented with the 
Generalized Regression Neural Network to classify the documents using the same 
feature set as used by FeedForawrd Backpropagation classifier. Section 6.3.5.1 
gives the details of the feature set, which we have used for classification of 
Chapter – 6 
   
 
 - 139 -
documents. In Section 6.3.5.2, we discuss the Feedforward Backpropagation 
classifier. The Generalized Regression classifier is discussed in Section 6.3.5.3.  
6.3.5.1 Feature Set used for Automatic Classification 
This section discusses the observable properties of the text of the documents that 
are used for automatic classification of documents into different document 
categories. 
 
Verb: The set of verbs in a document can be viewed as part of conceptual map of 
the events and actions in a document. The verb is an important factor in providing 
an event profile, which in turn can be used in categorizing the documents (Klavans, 
1998). The work done by Klavans et al. focus on the role of verbs for 
discriminating documents by types. They have classified verbs into different 
categories such as communication class, agreement class, argument class etc. Some 
of the sample verbs which are used for classification belonging to communication 
class are say, announce etc. Similarly, the sample verbs which belongs to 
agreement class are agree, accept and the verbs belongs to argument class are 
argue, debate etc. Their research works show that articles in which communication 
verbs predominates tend to be of type announcements, editorials, or opinion pieces, 
whereas the articles with a high percentage of agreement and argument verbs tend 
to be of type legal cases.  
 
We also observed that different set of verbs predominately occur in different types 
of documents. The explanation type documents generally contain definition, 
statements of laws and explanation about concepts. Therefore the verbs like define, 
known,called, state, described, explained, discussed, illustrated etc. predominantly 
occur in the explanation type documents. We observed that the lab experiment type 
of documents generally contain verbs like study, observe, design, measure etc. The 
exercise type documents usually contain verbs like evaluate, find etc. Table 6.11 
gives a list of sample verbs that predominantly occur in different type of 
documents.  
Chapter – 6 
   
 
 - 140 -
 
Table 6.11 Document type and the sample verb list 
 
Document type Verb list 
Explanation type Describe, discuss, explain, define, known, 
derive, … 
Application  Applied, used, … 
Experiment Study, observe, design, … 
Exercise Evaluate, find, calculate, … 
 
Words and Phrases: Apart from the verb, occurrences of certain words and 
phrases play an important role in describing documents. Documents belonging to 
the Documents belonging to the category experiment usually contain words like 
introduction, objective, results, goal etc. The exercise type documents usually 
contain phrases like “describe how”, “give reason”, “how can” etc. The 
application type document usually contains phrases like “application of”, “used 
for”, “applied for” etc. Documents belonging to the category explanation type 
usually contain phrases like “known as”, “defined as”, “described as”, “deal with” 
etc. 
 
Special Characters: The presence of some of the special characters and symbols 
in documents also play an important role in document classification. In case of 
exercise type documents, many sentences are interrogative sentences and contain 
the punctuation symbol question mark. The explanation type documents contain 
many special symbols to derive or explain different concepts. These character level 
features are important and used for classification. 
 
Distribution of features in few sets of documents for four classes explanation, 
application, experiment and exercise are shown in Figure 6.17. The x-axis 
represents the feature set and the y-axis represents the frequency of occurrences of 
different features in a set of documents. Since distribution of features is not linear, 
Chapter – 6 
   
 
 - 141 -
the linear discriminate analysis does not work well. We have used the feed forward 
back-propagation neural network to classify the documents. 
 
 
Figure 6.17 Distribution of features in few sets of documents 
6.3.5.2 Feedforward Backpropagation Neural Network 
The structure of a feed forward neural network is shown in Figure 6.18. It consists 
of three layers: input layer, hidden layer and output layer. The number of hidden 
neurons has been chosen by trial and error. Too many neurons lead to the problem 
of over-fitting and too less may not be able to generalize the classification. 
However in this problem the number of hidden Neurons has been fixed by trial and 
error over a number of training and test sets.  
 
Design: 
 
Number of input nodes [same as number of features] = 60 
Number of hidden Neurons = 6 with tan-hyperbolic activation function 
Number of output [same as number of classes] = 4 with tan-hyperbolic activation 
function Structure 
 
 
Chapter – 6 
   
 
 - 142 -
 
Figure 6.18 Feed forward network structure 
 
The distribution of input features suggests pre-processing because of the range 
mismatch. We have used the following normalization procedure . 
 
Let x be the input feature, then  
xj normalized =   j
xjxj
σ
−
 
Where xj  = mean of the jth component  
                                     σj = standard deviation of the jth component 
  
xj  and σ j are kept constant for testing with new features. 
 
The output classes are rendered into vectors as: 
 
Class 1   + 0.5, - 0.5, - 0.5, - 0.5 
Class 2   - 0.5, + 0.5, - 0.5, - 0.5 
 Class 3   - 0.5, - 0.5, + 0.5, - 0.5 
 Class 4   - 0.5, - 0.5, - 0.5, + 0.5 
Chapter – 6 
   
 
 - 143 -
 
The positive values at the output are taken as the output class.  
 
To test the above classifier, we have collected documents and manually 
categorized them into four classes namely explanation, application, experiment 
and exercise. A total of 240 documents were taken. Out of 240 documents, 170 
documents were randomly chosen and used to train the classifier. Remaining 70 
documents were tested with the trained classifier. The above process was repeated 
10 times with different sets of documents randomly chosen from the data set. The 
performance of the classifier is shown in Table 6.12. 
 
Table 6.12 Classification performance of the document type classifier 
 
Type of Document Avg. Accuracy in 
Percentage 
Explanation type 68.20 
Experiment type 85.83 
Application type 47.74 
Exercise Type 74.53 
 
The average accuracy obtained with the feedforward backpropagation network for 
Explanation, Experiment, Application and exercise type documents are 68.20%, 
85.83%, 67.74% and 74.53% respectively. The incorrectly classified documents 
were analyzed and the observations are discussed below. 
 
• Some of the explanation type documents are incorrectly classified as exercise 
type documents and vice versa. The presence of some of the cue words in 
documents is considered as an important feature for classification. The words 
like what, why, where, when, who etc. generally occur in questions and hence 
presence of these words are indicative of exercise type documents. But if we 
consider the occurrences of these words without understanding the meaning of 
the sentence, theses features will lead the classifier for wrong classification. 
The exercise type documents contain questions, numerical problems and 
exercises. The sentences that contain questions are generally interrogative 
Chapter – 6 
   
 
 - 144 -
sentences. When words like what, who, why etc. occur in interrogative 
sentences form questions. But these words may also occur in the declarative 
and the complex sentences to convey or explain something. Those declarative 
sentences may belong to explanation type of documents. Some example 
sentences extracted from the exercise type and the explanation type of 
documents with the same cue word are mentioned here. 
 
Exercise type: What is a rainbow? 
Explanation type: We will take a look at what happens when light reflects from 
a spherical mirror. 
 
Exercise type: Where is the sun, if there is a rainbow in the sky? 
Explanation type: It is very helpful to draw a ray diagram to determine where 
the image is. 
 
Exercise type: Which substance should be dissolved in water to form carbonic 
acid? 
Explanation type: The substance charcoal, which is a form of carbon, gives 
carbon dioxide after burning. 
 
• Some of the cue verbs predominantly occur in explanation type documents are 
illustrate, define, describe, discuss etc. These verbs are important features for 
discriminating explanation type documents from other categories. But again 
considering the occurrences of these verbs in the text without understanding the 
meaning of the sentences lead the classifier for wrong classification. The 
declarative sentences with these verbs are indicative of explanation type 
documents. But when these verbs occur in imperative sentences may form 
questions. Some of the example sentences are mentioned below. 
 
Exercise type: Describe the principle by which optical fiber works? 
Explanation type: The principle by which the optical fiber works is described 
below. 
Chapter – 6 
   
 
 - 145 -
Exercise type: State Newton’s second law of motion? 
Explanation type: Newton’s second law states that acceleration is directly 
proportional to force and inversely proportional to mass of an object. 
 
Exercise type: Explain how an object will change velocity if it pushed or 
pulled upon? 
Explanation type: Newton’s second law of motion explains how an object will 
change if it is pushed or pulled upon. 
  
• A few explanation type documents are incorrectly classified as application type 
documents. In application type documents, the predominantly occurring words 
are application, practical application, use etc. Let us take a sentence “the most 
common use of such a lens is as a magnifying glass,” reveals about the 
practical use of lens. Whereas the sentence “use the data collected above to 
determine the focal length of the lens” belongs to a document discussing about 
the determination of focal length. It is not necessary that word use is always 
associated with practical applications.  
 
• Some exercise documents contain multiple-choice questions and fill in blanks. 
These documents are misclassified as explanation type documents. 
 
From above discussion, it is clear that it is necessary to understand the semantic of 
a sentence while considering features from the sentence. The set of words and 
verbs must be considered only from those sentences, which give correct 
interpretation for the classification.  
 
To know the semantic of sentence with cue verbs, words and phrases, each 
sentence is parsed and analyzed using a link parser (Link Grammar, 
http://bobo.link.cs.cmu.edu/link/ ). The link parser gives the link type details 
between words of a sentence (discussed in section 6.3.3). These link type details 
between words are further analyzed and based on some inference rules; the cue 
words are either considered or discarded. Let us take some example sentences and 
derive inference rules. 
Chapter – 6 
   
 
 - 146 -
 
1. Let us take the example sentences with question words. The link detail obtained 
from the parser for sentence “what is a rainbow?” is shown in Figure 6.19. 
 
+-------------Xp------------+ 
|            +---Ost--+     | 
+---Ws--+Ss*w+  +--Ds-+     | 
|       |    |  |     |     | 
LEFT-WALL what is.v a rainbow.n ? 
 
Figure 6.19 Parser output for a sentence “what is a rainbow?” 
 
The link parser output for sentence “We will take a look at what happens when 
light reflects from a spherical mirror.” is shown in figure 6.20. 
 
+--------------------------------------------------Xp--------------------- 
    |                  +-----MVp-----+                                         
    |                  +---Os---+    |                                         
    +--Wd--+-Sp-+--If--+   +-Ds-+    +-Js+-Ss*d-+--MVs--+--Cs-+----Ss---+--MVp 
    |      |    |      |   |    |    |   |      |       |     |         |      
LEFT-WALL we will.v take.v a look.n at what happens.v when light.n reflects.v  
 
 
----------------------------+ 
  +---------Js---------+    | 
  |  +--------Ds-------+    | 
--+  |      +-----A----+    | 
  |  |      |          |    | 
from a spherical.a mirror.n .RIGHT-WALL  
 
Figure 6.20 Link detail obtained from parser output 
 
Figure 6.19 gives the link type details between the words of sentence “what is a 
rainbow?” The horizontal dashed lines represents links between words. The parser 
insert word LEFT WALL at the beginning of every sentence. There is a Ws link 
between the LEFT WALL and the word what. The letter W is used to attach main 
clauses to the wall. The letters Wq, Ws and Wj are used to connect many types of 
questions such as subject questions (Ws), object questions (Wq), where/when/why 
questions (Wq), adjectival questions (Wq), and prepositional questions (Wj) to the 
Chapter – 6 
   
 
 - 147 -
LEFT WALL. When a question word begins a sentence, it must make a Wq or Ws 
connection to the LEFT WALL. The sentence shown in Figure 6.20 is not an 
interrogative sentence. Therefore the word what is not connected to the LEFT 
WALL. 
 
From above discussion we can derive an inference that whenever the cue words 
like what, when, why in a parsed sentence are connected to the LEFT WALL with 
linkage Wq, Ws, Wj, the sentence begins with a question word and form a 
question.  
 
Inference Rule1: If the linkage between the question word and the left-wall of a 
parsed sentence is Wq, Ws and Wj, increment the count of the question words in 
the feature vector. 
 
2. Let us take an example sentence with cue verb describe. The link detail for the 
sentence “Describe the principle by which optical fiber works?” is shown in figure 
6.21. 
 
   +---------------------------------Xp--------------------------------+ 
    |          +------Os------+       +---------Cs---------+            | 
    +----Wi----+      +--D*u--+---Mj--+-Jw+       +----A---+---Ss--+    | 
    |          |      |       |       |   |       |        |       |    | 
LEFT-WALL describe.v the principle.n by which optical.a fiber.n works.v ?  
 
Figure 6.21 linkage detail 
  
In Figure 6.21, the verb describe is connected to the LEFT-WALL with link Wi. 
The letter Wi is used to connect imperative to the LEFT-WALL. When a set of 
verbs like describe, discuss, state, explain are connected to the LEFT-WALL with 
link Wi indicates that some question has been asked in that sentence. To 
differentiate question sentences from declarative sentences, we assign higher 
weight to the verbs present in imperative sentences.   
 
Rule 2: If a linkage between the verb and the left-wall is Wi, then increment the 
count of that verb by 10. 
Chapter 6 
________________________________________________________________________ 
 148
 
3. The presence of some of the cue words like application, use etc. in the heading of a 
paragraph is very important to distinguish application type documents from other 
documents. Similarly words like objective, aim, apparatus required, experimental results, 
conclusion generally occur in the heading of different paragraphs in experiment type 
documents. We assign higher weights to these words, if it occurs in the heading of a 
document.   
 
Rule 3: If a cue word belonging to the set T = {objective, aim, apparatus required, 
experimental results, result, conclusion, application, use} occurs in headings of a 
paragraph, then increment the count for that word by 10.  
 
New feature vectors are created for the same set of 240 documents by applying above 
rules. The classifier is trained with the feature vectors of 170 documents and the 
remaining 70 documents are tested with the trained classifier. The above process is 
repeated 5 times with different sets of documents randomly chosen from the data set. The 
performance of the classifier is shown in Table 6.13. 
 
Table 6.13 Classification performance of the document type classifier 
 
Type of learning resource type Precision Recall 
Explanation type 85.23 87.61 
Experiment 80.36 82.41 
Application 62.89 60.87 
Exercise Type 74.28 73.52 
 
The Performance of the classifier is fairly good. But one disadvantage of Feedforward 
Backpropagation is that it takes a large number of iterations to converge to the desired 
solution. An alternative to the Feedforward Backpropagation is the Generalized 
Regression Neural Networks (GRNN), which involves one-pass learning and can be 
implemented directly in the neural network. In the next section, classification of 
documents using Generalized Regression Neural Networks (GRNN) is discussed. 
Chapter – 6 
   
 
 - 149 -
6.3.5.3 Generalized Regression Neural Network (GRNN) 
Figure 6.22 gives the overall network topology implementing the GRNN. As it can 
be seen from the figure, the GRNN consists of three layers of nodes: the input 
layer, where the inputs are applied, the hidden layer, where a nonlinear 
transformation is applied on the data from the input space to the hidden space, and 
the linear output layer, where the outputs are produced.  
Figure 6.22 Architecture of GRNN 
 
The learning process is equivalent to finding a surface in a multidimensional space 
that provides a best fit to the training data. The generalization is equivalent to the 
use of this multidimensional surface to interpolate the test data.  
 
We have chosen multivariate Gaussian function with an appropriate mean and 
autocovariance matrix. We have used Matlab functions to design the above 
classifier.  
 
The classifier is tested with the same set of feature vectors, which are used to test 
the Feedforward Backpropagation Neural Network classifier. The average 
classifier performance is shown in Table 6.14. 
Chapter 6 
_______________________________________________________________________ 
 150
 
Table 6.14 Classification performance of the document type classifier 
 
Type of learning resource type Precision Recall 
Explanation type 83.81 79.63 
Experiment 90.51 89.23 
Application 63.89 64.87 
Exercise Type 70.14 75.82 
 
We find that the performance of Feedforward Backpropagation Neural Network 
classifier and Generalized Regression Neural Network classifier are fairly good for 
classifying documents into the categories of explanation, experiment and exercise. 
But the classification performance is poor for application type of documents. The 
deeper analysis of application type of documents is required and also the feature set 
for this type of document needs to be improved.  
 
The principal advantage of GRNN is fast learning and convergence to optimal 
regression surface. Therefore it is particularly advantageous to use this method. 
6.3.6 Grade Level Identification 
The metadata grade level gives the difficulty level of the document. It helps the 
retrieval module for retrieving documents for learners according to their grade level.  
 
Flesch-Kincaid ( http://en.wikipedia.org/wiki/Flesch-Kincaid_Readability_Test ) has 
given a formula for finding the grade level for which a document is suitable. Flesch-
Kincaid grade level formula is designed to indicate how difficult a reading passage is 
to understand. The formula is as follows: 0.39*( sentences  Total
 wordsTotal ) + 
11.8*(   wordsTotal
syllables  Total ) . This formula calculates a score for the text of the document. 
The score is a number that corresponds to a grade level. For example a score of 6.1 
would indicate that the text is understandable by an average student of 6th  grade. 
Chapter – 6 
   
 
 - 151 -
grade. This formula give the complexity of the text and hence is more suitable for 
finding the grade level in domains where langauge complexity plays an important 
role. But in science domains like physics, biology, the difficulty level of a 
document can not only be decided by finding the complexity of the sentences in 
the text. We feel that the difficulty level or the grade level of a document can be 
better estimated by finding the extent of match between the concepts coverage by a 
document and the concepts present in the syllabus of any grade level. 
The syllabus content, the number of topics and the topic coverage in terms of 
concepts are more for higher grade level as compared to the lower grade level. A 
portion of the syllabus of grade seven and grade ten is shown in Figure 6.23. The 
Chapter optics of the grade seven syllabus contains topics like light, shadow, 
mirror, reflection and image, whereas the Chapter optics of grade ten syllabus 
contains many more topics like lens, refraction, prism etc along with topics light, 
shadow, mirror, reflection etc. 
 
 
Figure 6.24 shows a snap shot of a document, which gives discussion of various 
concepts like reflection, refraction and total internal reflection.  A grade seven 
student can understand the concept reflection but it is difficult for him to 
Figure 6.23 A portion of syllabus of grade seven and grade 
Chapter – 6 
   
 
 - 152 -
understand the concepts refraction and total internal reflection. Because of the 
presence of a few higher-level concepts, this document is more suitable for the 
grade ten students than the grade seven students.  
 
As discussed in Chapter 4, the curriculum requirements of different grade levels 
are kept in the group-profile. The curriculum requirement or syllabus of a grade 
level is used to identify the grade for which the document is suitable.  The 
curriculum of any grade level consists of several subjects. Again the subjects 
contain many chapters and subchapters (topics). The lists of concepts used to 
explain each topic in the syllabus are kept as topic concepts relationships in the 
group profile. The concepts present in the group profile are used to score a 
document for identification of the grade level. This score reflects the extent of 
match between the concepts present in the document and the concepts present in 
the group profile of a class.  
 
Figure 6.24 Snapshot of a document 
Chapter – 6 
   
 
 - 153 -
A concept may present in more than one group profile. For example the concepts 
reflection, mirror, law of reflection etc. belong to grade level seven as well as 
grade level ten syllabus as shown in Figure 6.24. For each concept ci, we obtain a 
grade level list G = { G1, .., Gj, ..,Gn } that includes the concept ci in its group 
profile. The grade level score score(Gj ) corresponding to the lowest grade level Gj 
that includes the concept ci is incremented by 1. A list GN is created which 
contains all the grade levels with the maximum score. The minimum grade level Gi 
is retuned from this list. A grade level Gi∈ GN  is minimum if i<k ∀  Gk∈ GN.  
 
The algorithm for the grade level identification is outlined below. 
 
Algorithm 6.6: Grade level identification 
 
Input: document D 
Output: grade level Gmin 
 
// C = {c1,…,ci ,…,cm } be the concept list of the document D 
// grade level is Gj and Gi  <  Gk   if i<k 
 
  
1. get ci  from the document D 
2. for i ← 1 to m  
 find the lowest grade level Gj that includes ci   
score(Gj ) ← score(Gj )  + 1 
3. GN← arg 
Gj
max score(Gj) //hence GN contains all the grade levels with 
maximum score 
4. return  Gmin∈ GN with minimum grade level  
 
The algorithm 6.6 uses the group profile of the system for grade level 
identification. Therefore the accuracy of the algorithm depends on the group 
profile. It is required to build the group profile very carefully.  
Chapter – 6 
   
 
 - 154 -
6.4 Automatic Annotation Tool  
We have developed an automatic annotation tool. The input interface of the tool is 
very simple. The contributors are not required to fill any kind of form while 
submitting documents instead they can simply add documents through this input. 
Web documents can also be submitted by providing the global address URL of the 
web document. The submitted document is sent to the automatic metadata 
extractor module of the system, which extracts the metadata automatically. 
 
The metadata annotation is done in a machine comprehensible format. The 
metadata annotation is expressed in a semantic web language. All IEEE metadata 
elements are compliant with IEEE LOM RDF binding specification (Nilsson, 
2002) except the metadata attributes, which are extended by us. An example of the 
metadata annotated file format for a document is shown in Appendix B. 
6.5  Summary 
The automatic extraction of metadata from documents is discussed in this Chapter. 
We have discussed the extraction of concepts and its significance with respect to 
the document. We categorized concepts into two types. The types are the outcome 
concepts and the prerequisite concepts. Identification of the type of concept is a 
complex problem. However, we have attempted it by analyzing the documents 
with a shallow parsing approach and by using some inference rules. But to improve 
the performance it is required to do the deeper analysis and also to incorporate few 
more inference rules. 
 
Knowing the topic of a document helps in document retrieval and in navigation. 
We have discussed two approaches for automatic identification of the main topics 
of documents. The two approaches are the example-based classifier and the 
ontology based topic identification. We have designed a classifier using 
probabilistic neural network to obtain the topics of documents. The classifier 
performance for different sets of documents is shown.  To obtain good 
performance from the classifier, it needs to be trained with a large set of 
Chapter – 6 
   
 
 - 155 -
documents. Document collection for different grade levels according to the 
curriculum requirements is a very tedious job. Therefore we have opted the 
identification of topics of documents using ontology. However, the performance of 
both the example based classifier and the ontology based classification are not up 
to the acceptable levels for the topics, which are closely related to each other and 
having many common concepts.   
 
The document type attribute plays a vital role in adaptive presentation of learning 
materials. The documents are categorized into four types namely explanation type, 
experiment type, application type, exercise type. To identify the document type, we 
have identified some of the surface level features of the text and used this set of 
features to classify documents into different types using feedforward 
backpropagation neural network and generalized regression neural network. The 
classification performance for application type document is poor. To improve the 
performance, the feature set is required to be enhanced.   
 
In section 6.3.6, we have discussed the identification of metadata grade level, 
which gives the difficulty level of the document. The algorithm for grade level 
uses the group profile, which is a part of the ontology. The group profile is built 
manually. It is required to build it very carefully to get fairly good results. 
 
Chapter – 7 
 
Personalized Information Retrieval 
for E-learning 
 
7.1  Introduction 
E-learning is a learning using computer and internet technology. For e-learning an 
e-learner can retrieve learning materials by providing search queries to the 
available learning object repositories. Apart from the learning object repositories e-
learner can retrieve learning materials from the web by querying the available 
search engines.  
 
Many tutoring systems are also available to support e-learners. The tutoring system 
uses the learner’s profile, his learning style, his current state of knowledge and the 
learning goal to select and present the most appropriate learning materials. It 
attempts to provide the learner with the most suitable individually planned 
sequence of knowledge units such as a set of concepts or topics to learn. Different 
learners have different knowledge levels. It tries to provide the most appropriate 
learning materials understandable to the learner considering the learner’s current 
state of knowledge. Again, the learning style of different learners can never be 
same. They may be interested in different types of learning materials. The tutoring 
system tries to provide different types of learning materials as required by the 
learner.  
 
In order to decide the relevance of a learning material to a given learner, the 
learning material should have metadata associated with them. The attributes of 
Chapter – 7 
   
 
 - 157 -
learning materials such as the topic, the concept covered, difficulty level etc. are 
useful in determining the appropriateness of the learning material for a given 
learner. To know the learner’s current state of knowledge, a key requisite for the 
system is to maintain the learner’s profile. To provide the documents as required 
by a learner, the system should know about the type of the learning resources. 
 
We have not developed a complete tutoring system but we have implemented an 
information retrieval module for retrieving learning materials to satisfy the need of 
a learner. The information retrieval module of the system is discussed in this 
Chapter. The retrieval can be done in two ways either by giving input search query 
to the repository of the system or to the web.  
 
The system’s repository is a collection of high quality learning materials. It is 
easier to search the learning materials from within a contained collection. But the 
amount of learning materials indexed in them is very small as compared to the 
world wide web. The web contains a large variety of learning resources and has 
opened up new possibilities in area of education, general and scientific information 
dissemination and retrieval.  
 
World wide web is a large collection and is continuously growing. As of January 
2006, the largest search engine has indexed 9.7 billion web pages, 1.3 billion 
images, and over one billion usenet messages, in total, approximately 12 billion 
items (http://en.wikipedia.org/wiki/Google_(search_engine)). With the increase in 
the number of webpages, the search on a given query often returns a very large 
number of documents. The difficulties in search of world wide web is captured by 
the remarks made by Steve Borsch who raises general awarenees for next 
geneartion internet through connecting the dots 
(http://borsch.typepad.com/ctd/2006/03/97_billion_web_.html).“As of January 
2006, Google has indexed 9.7 billion web pages. When I search on a string that is 
even somewhat popular, I often get back hundreds of thousands or millions of 
results. In addition, I find it very difficult to obtain the most recent results unless 
Chapter – 7 
   
 
 - 158 -
I'm very, very careful about how I enter my search string. Why is it so hard to find 
really useful data?” 
 
The sheer volume of information available on the web, itself poses a major 
challenge for a user who is trying to obtain very specific forms of relevant 
documents. The other major drawback is that the search results for a given query 
are independent of the context in which the user made the request. For the same 
query different users have different preferences on the items depending upon their 
area of interest. For example, for the query light, a solar technologist may be 
interested in the study of solar light where a student’s interest may be the study 
materials of the chapter light. But the search engine selects the same information 
and presents it to users without considering the users’ interest and their 
requirements. To find a solution to all of the above problems, efforts have been 
started to customize the view of the web in a user specific personalized way and 
many personalized information retrieval systems have been developed. 
7.2  Retrieval Requirement for E-learning  
Personalized systems are useful for filtering, recommendation, navigation and for 
many other applications. Personalized information filtering systems are designed to 
help users to quickly find the needed information. Many projects have been 
working on building personalized web navigation agents. Web navigation agents 
assist and provide guidance to the user for browsing the web. A survey on 
personalized information retrieval is provided in Chapter 3.  
 
Personalization is especially important in e-learning.  The knowledge level and 
understanding of different learners differ from each other. For any topic, the 
information needed by a sixth grade and a tenth grade student differs in terms of 
the concepts that the learner is expected to understand, the topic he is familiar with 
and the scope and extent of his curriculum requirement as well as his individual 
interest and grasp of a particular subject. For the same query, different learners 
want different information according to their requirement. If we consider a topic 
Chapter – 7 
   
 
 - 159 -
such as “reflection and refraction of light”, which is of interest to students 
belonging to different grade levels, a high school student may be interested in 
documents illustrating the use of Snell’s law to determine the index of refraction, a 
middle school student may be interested in the phenomenon of the total internal 
reflection in binocular, whereas a college student may want to learn about the 
applications of total internal reflection in optical fiber. Even at the same grade 
level, there are students with different knowledge levels. Since different learners 
with different knowledge levels have different interpretation about what is 
relevant, the only way to improve the quality of search results will be to show 
different search results to different learners considering the learners’ characteristics 
such as their current state of knowledge, learning and cognitive style etc.  
 
The learning style of different learners is usually not the same. A comprehensive 
review of research in cognitive psychology has indicated that learners exhibit 
significant individual differences in the cognitive and learning styles (Robertson, 
1985). Different learners may be interested in different type of learning materials 
for a single topic. For the same topic there are different types of learning materials. 
For example, there are some documents, which explain the topic whereas some 
documents give exercises or numerical problems on the topic. Some documents 
give laboratory experiments. Because the preferences and current requirement can 
vary greatly across individuals, a personalized system must be tailored so that it 
should be able to provide a learner with learning materials of a particular type that 
he requires. 
 
In web search, text queries are generally provided to a search engine. Because of 
the enormous size of the web, text alone is usually not selective enough to limit the 
number of query results to a manageable size. Therefore the search engines apply 
ranking algorithm to sort the search results. The ranking algorithm finds the 
relative importance of web pages within the set. To encompass different notions of 
importance for different learners and queries, the search results returned by the 
search engine should be filtered and re-ranked to create a personalized view of the 
web, redefining importance according to the learner’s interest and requirements. 
Chapter – 7 
   
 
 - 160 -
For example, suppose a student belongs to the standard 10 wants to learn a topic 
refraction of light, the documents belonging to the topic should be filtered and re-
ranked considering the student’s knowledge level. 
 
To take a better decision in selecting the web pages from the large pool of results 
returned by a search engine, the search results are generally supplemented with 
snippets. The snippet contains the title and fragment of sentences extracted from 
the document, which give match with the input query word. The snippet shown by 
the Google search engine is the text extracted from the web page, which gives the 
best match for the search query. Yahoo is more likely to use the text from the 
description tag (when it contains the search keyword). Sometimes Google uses the 
description for a site from Open Directory (http://www.dmoz.org/). As mentioned 
earlier, the learner’s preferences for learning material is usually not same. Some 
may be interested for learning materials that explains a topic, whereas other may 
be interested for the documents, which provide exercises on the topic. In order to 
help the learner to take better decision for selecting documents of their preferences 
from large pool of returned links, the snippets should contain the fragment of 
sentences, which gives general idea about the type of the learning material. It 
should not only contain the title and the sentences with search query but it should 
also give the summarization of the web pages that helps a learner to identify the 
content of the page. 
7.3  Search Tool for E-learning 
We wish to develop a search tool, which retrieves most appropriate learning 
materials for a given learner based on his learning profile, his learning style 
preferences, his requirement, and his current state of knowledge. A learner can 
search learning materials from the system’s repository or from the web. We want 
to provide the facility of personalized search and navigation of learning materials 
to learners. For testing the developed tool, we have implemented it for school 
students. The students can search and navigate the learning materials according to 
their curriculum requirements. To retrieve the personalized search results, the 
Chapter – 7 
   
 
 - 161 -
system looks into the user profile, the group profile and the domain knowledge. As 
mentioned in Section 4.5, for each learner, a separate user profile is maintained in 
our system, which provides the learner’s interest, his grade level and his current 
state of knowledge. The learner’s curriculum requirement is kept in the group 
profile.  
 
As discussed in Section 4.4, the system maintains a repository. Learners can search 
documents from the system’s repository. Documents from various sources are 
collected, automatically annotated with metadata and kept into the system’s 
repository. The metadata available with the documents helps in the retrieval of 
learning materials from the repository to suit the learner’s requirement.  
 
As the web is a large source of learning materials, therefore we wish to provide the 
facility of search of learning materials directly from the web. In case of the web 
search, the learner’s search requests are sent to a general-purpose search engine. 
The system maintains the domain ontology of the subject being taught. The domain 
specific documents are filtered out from the documents returned by the search 
engine using the domain ontology. The domain specific documents are processed 
for the automatic extraction of various metadata information and the documents are 
tagged with the extracted metadata information. The documents are chosen 
according to the learner’s requirements using these tags, re-ranked and presented to 
the user.   
 
The search provides personalized search results for the given input query. The 
search results can further be filtered on different search parameters as required by a 
learner. The different search parameters on which the search can further be filtered 
are the grade level and the type of learning materials.  
 
We wish to supplement the returned documents along with the snippets. The 
snippet contains the fragment of those sentences of the document, which helps a 
learner to identify the type of learning materials according to his preference. 
Chapter – 7 
   
 
 - 162 -
The query module of the developed system is discussed in Section 7.4. 
7.4  Query Module 
The query module of our system is shown in Figure 7.1. It takes the input query 
given by a learner. The query processor processes the given input query. A learner 
can search learning materials from the system’s repository or from the web. In case 
of the repository search, the search requests are forwarded to the repository. For 
web search, the query is forwarded to a general-purpose search engine. The 
domain specific documents are filtered from the document set returned by the 
search engine using the domain knowledge of the system. The metadata annotator 
module automatically annotates the filtered documents with a set of metadata 
attributes. The metadata-annotated documents are forwarded to the relevance 
calculator module. The relevance calculator module takes the metadata-annotated 
documents, the user profile and the domain knowledge as input and finds the 
relevance of each of the documents. The idea is to identify the relevance of each of 
the retrieved documents with respect to the domain knowledge and the user profile, 
to determine how much a user is likely to be interested in the document and 
whether the document is understandable to the user. It computes two types of 
scores for each of the documents: relevance scores and understandability score. 
The relevance score represents the relevance of the document to the user for the 
given query, and the understandability score reflects the extent to which the 
document is understandable to the user, given the user knowledge state and on the 
basis of the pre-requisites computed from the document. The documents are re-
ranked based on these scores, and the re-ranked results are presented to the user. 
The search results are supplemented with snippets. The snippet gives short 
description about the type of the document, which helps the learner to take better 
decision for selecting documents.  
 
Chapter – 7 
   
 
 - 163 -
 
Figure 7.1 Query module of the system 
7.4.1 Types of Queries 
The query module accepts different types of queries from a learner. A learner can 
perform search by giving a term or a set of terms as input to the query module of 
the system. A learner can also form queries by combining additional search 
parameters along with the input query term to filter more specific documents of his 
preference. The additional search parameters are as follows: 
 
• Type of the learning material: By providing this search parameter along 
with the input query term, a learner can search a particular type of learning 
materials. The types of learning materials are exercise type, experiment 
type, application type and explanation type.  
• Grade Level: For a given input query term, a learner can search documents 
of his grade level. 
Chapter – 7 
   
 
 - 164 -
7.4.2 Query Processing 
The query processor module first processes the input query given by a learner and 
then sends it to the content retrieval module. As discussed above, the input query is 
a term or a list of terms. To perform the concept based search, each term in the 
input query list is mapped to its corresponding concepts.  
 
A term can map to a single concept or multiple concepts. When a term has multiple 
meanings in different domains; it can map to multiple concepts. The ontology 
maintains a dictionary of terms and the list of associated concepts for each term.  
 
For each term in the input query list, the list of associated concepts is obtained 
from the ontology. If a term in the input query list corresponds to a single concept, 
that single concept is selected. If a term maps to more than one concept of different 
domains, then the learner’s feedback is taken to select the concept of the particular 
domain for which he is interested. The concept list is forwarded to the content 
retrieval module for document retrieval. In case of repository search, it is 
forwarded to the repository content retrieval module. For web search, it is 
forwarded to the driver of a general-purpose search engine. Documents of learner’s 
interested domain are filtered out from the document set returned by the search 
engine. The domain specific retrieval of documents is discussed in the next section. 
7.4.3 Domain Specific Retrieval 
The web is a large digital repository containing documents of various domains. 
Learners give search queries to the search engines for searching documents of their 
interest. In fact, keyword length study by iProspect.com ( 
http://www.iprospect.com/premiumPDFs/keyword_length_study.pdf ) shows that searchers 
routinely use a very small number of keywords (one or two) to express their search 
interests. According to this study 88% of search engine referrals are based on only 
one or two keywords. NEC Research Institute study (Butler, 2000) shows that up 
to 70% of searchers use only a single keyword as a search term. Because the web 
contains various types of web pages on various topics, naive queries by students 
Chapter – 7 
   
 
 - 165 -
find matches to many relevant as well as irrelevant pages. This problem can greatly 
be reduced by different approaches like enhancing the user’s query with contextual 
information or domain specific filtering.  
 
The contextual search tries to capture the user’s information need by augmenting 
the user’s query with contextual information. The context information helps in 
refining the meaning of the user’s query and narrowing the returned results. Y!Q 
(Kraft, 2005) is a contextual search application integrated with  yahoo search 
engine (http://search.yahoo.com).  
 
For eliminating the irrelevant documents from the retuned pages, work has been 
done on domain specific filtering. Domain specific filtering eliminates the 
irrelevant documents and presents the relevant documents of a particular domain to 
the student. Work has been done on domain specific filtering and many domain 
specific web search engines are available. Cora (McCallum, 1999), SPIRAL 
(Cohen, 1998), WebKB (Craven, 1998) are the domain specific search engines, 
which use web crawler to collect domain specific documents. There are domain 
specific search engines like MetaCrawler Softbot (Selberg, 1997), Ahoy! (Shakes, 
1997), which forwards the user’s query to one or more search engines and 
eliminates the irrelevant documents from the returned web pages by domain 
specific filtering.  
 
As discussed above, we find that there are two approaches for retrieving domain 
specific documents. The first approach is to enhance the input search query by 
associating related concepts of the input query concepts and forward the enhanced 
query to the general-purpose search engine (Kraft, 2005). The second approach is 
to forward the original query to the search engine and eliminate the irrelevant 
documents from the returned ones (Selberg, 1997; Shakes, 1997). 
 
To select any one of the above-discussed two approaches for domain specific 
retrieval, we have experimented with the query enhancement approach and also 
Chapter – 7 
   
 
 - 166 -
with the domain specific filtering approach. The query enhancement approach 
with experimental results and its drawbacks are discussed first. 
7.4.3.1 Query Enhancement Approach 
 In this approach, the given input query is first enhanced. To enhance the input 
query, the related concepts of the input query concepts are obtained from the 
ontology and are associated with the input query concepts.  The enhanced query is 
forwarded to the search engine (we have used the Goggle search engine). The 
algorithm for the enhancing the query is outlined below. 
Algorithm 7.1 Enhanced Query Generation 
// Q is the concept list of the input query containing k concepts, Q ← { q1 … qk  } 
 
// EQ is the enhanced concept list to be returned  
Input: Concept list Q 
Output: Enhanced concept list EQ 
EQ ← Q 
for i ← 1 to k 
find the related concept list R← { r1 ….rm} of qi∈Q  from the ontology  
      for j ← 1 to m  
 if rj ∉  EQ 
 EQ ← EQ ∪  rj 
         return EQ 
 
Table 7.1 shows the improvement in precision of the search result with the 
enhanced query. The number of relevant documents for the input query without 
enhancement and with enhancement is compared in Table 7.1. Column 2 gives the 
Chapter – 7 
   
 
 - 167 -
original input query. Column 3 shows the number of manually identified relevant 
documents out of first 20 documents returned by the search engine for the query 
given in column 1. Column 4 contains the enhanced query. Column 5 shows the 
number of manually identified relevant documents out of the first 20 documents 
returned by the search engine for the enhanced query given in the column 4. 
Table 7.1 Improvement in relevance with enhanced query 
 
Sl. 
No. Query 
Manually identified 
relevant documents 
out of first 20 
documents returned 
by Google for 
query given in 
column 2 
Enhanced Query 
Manually identified 
relevant documents 
out of first 20 
documents returned 
by Google for 
enhanced query given 
in column 3 
1 gravity 4 
gravity, 
force,mass,gravitatio
nal 
force,gravitational 
constant 
20 
2 motion 2 
motion, 
displacement,speed, 
velocity, 
20 
3 reflection 5 
reflection, light, 
mirror, laws of 
reflection 
20 
4 acceleration 8 acceleration,mass, force 20 
5 torque 3 
torque, force, 
moment of inertia, 
time, displacement 
20 
6 force 1 
force, momentum, 
mass, torque, 
acceleration, gravity, 
gravitational force,  
nuclear force 
 
7 friction 18 
friction, kinetic 
friction, static 
friction, rolling 
friction, force, 
coefficient of friction
20 
8 kinetic energy 20 
Kinetic energy, 
mass, velocity, 
energy 
20 
 
 
Chapter – 7 
   
 
 - 168 -
We observe that with the query enhancement approach the precision is very high. 
There are some drawbacks with this approach, which are discussed below. 
 
• As discussed above, the enhanced query is obtained by associating the 
related concepts of the input query concepts and the related concepts are 
obtained from the concept graph of our domain ontology. For a given 
concepts, there may be many related concepts. For example, if we take a 
search query force. For the concept force, the related concepts obtained 
from the ontology are force, momentum, mass, torque, acceleration, 
gravity, gravitational force, nuclear force. Again, if the input search query 
contains more than one query concepts and if the related concepts of all the 
concepts are added, then the enhanced query may lose the essence of the 
input query. The query enhancement improves the search result only when 
it is enhanced properly. 
• If the query is enhanced with the specific contextual information, it may 
restrict the returned results to a very specific context and reject many of the 
useful documents. It is always advantageous to select documents from a 
diversified set retuned by the search engine rather than a specific set.  
 
Due to the above-discussed drawbacks, we have used the filtering approach for 
retrieving domain specific documents. The domain specific filtering approach is 
discussed below. 
7.4.3.2 Domain Specific Filtering Approach 
The original query is forwarded to the search engine and the domain specific 
relevant documents are filtered from the documents returned by the search engine. 
For filtering the domain specific documents, the concepts present in the document 
are extracted from the document. The significance of each of the concepts present 
in the document is computed. Our hypothesis is that if a concept is of significance 
in a document, it is usually the case that the document contains a number of 
references to the related concepts. We use the concept significance for filtering the 
Chapter – 7 
   
 
 - 169 -
documents. The computation and use of the concept significance for filtering 
domain specific documents has been discussed in Section 6.3.2 in detail.  
 
The input query concept list is matched with the metadata concept list available 
with the documents. Documents which contain the query concept with concept 
significance above threshold are filtered out from the documents returned by the 
search engine.  
 
The metadata annotator module extracts a set of metadata from the domain specific 
filtered documents. The metadata extraction algorithms are discussed in detail in 
Chapter 6. The relevance calculator module of the query module finds the 
relevancy of the each of the filtered documents with respect to a particular learner 
and re-ranks the documents. The relevance finding and re-ranking of documents is 
discussed in the next section. 
7.4.4 Relevance Finding and Re-ranking 
A document may be relevant to the domain but if a learner does not know most of 
the concepts of that document then it will be difficult for him to understand. For 
the same query input, the relevance of a document will be different for different 
learners having different knowledge levels. Therefore it is required to find the 
relevance of a document with respect to a particular learner.  
 
Each of the filtered documents is given two types of scores: the relevance score 
and the understandability score. The document score is the summation of the 
above two scores. The documents are re-ranked using the document score and then 
presented to the learner.  
1. Relevance Score: Relevance of a document to the given query 
The relevance score represents the relevance of the document to the given query. 
The relevance score of a document is computed considering the occurrences of the 
query concept as well as the occurrences of the related concepts of the query 
Chapter – 7 
   
 
 - 170 -
concepts present in the document (shown in Figure 7.2). To compute the relevance 
score, we use the metadata attribute concept significance available with the 
document. The computation of the attribute concept significance is discussed in 
Section 6.3.2. 
  
Let a document D contains a list of concept C = { C1 ,…, Ci ,..., Cn }. The relevance 
score ( R ) for the document  D is computed as follows: 
 
Relevance Score (R) = ∑
=
n
i 1
canceCi.Signifi  
Where Ci.Significance = Number of occurrence of the domain terms indicative of 
query concept Ci in the document + α * Number of occurrence of the domain terms 
indicative of concepts related to the query concept Ci. 
 
Figure 7.2  Consideration of related concepts of the query concept for 
domain specific filtering 
current, charge
electric current
electric charge
electric charge
ohm’s law
resistance
ampere
voltage
electric current
coulomb’s law
electric field
coulomb
electron
proton
Input Query (list of terms)
Term to concept 
mapping
Related concepts present in 
a document
conductor
Chapter – 7 
   
 
 - 171 -
α is the weight given to the concepts. In our experiment, we have taken α = 1/2. 
Ci.Significance is normalized with respect to the total number words present in a 
document. 
 
The relevance score increases with the presence of the number of occurrence of the 
query concepts as well as the number of occurrences of the related concepts of the 
query concepts.  
 
This is illustrated in the example given below. 
 
Example: Let the given input query is reflection. Let us take two documents D1 
and D2, which were retrieved for the given input query. 
 
Input Query term = reflection 
Input Query concept = reflection 
Related concepts to query concepts reflection =  {mirror, angle of reflection, angle 
of incidence, reflected ray, incident ray, law’s of reflection} 
 
Document D1  
(http://www.glenbrook.k12.il.us/gbssci/phys/Class/refln/u13l1c.html) 
Concept list D1 with their frequency = {angle of incidence (6), angle of reflection 
(5), curved mirror (1), eye (9), incident ray (3), law of reflection (13), mirror (5), 
normal (4), reflected ray (3), reflection (26), sun (1)} 
Total number of words present in document D1 = 948 
 
 
Relevance Score (R) of D1 for the input query =  
948
1 *(26 + 
2
1 *6 + 
2
1 *5 +  
       
2
1 *3 + 
2
1 *13 + 
2
1 *5 + 
2
1 *3)  
        =  0.0458 
 
 
 
Chapter – 7 
   
 
 - 172 -
Document D2 (http://floti.bell.ac.uk/MathsPhysics/1total.htm) 
 
Concept list D2 with their frequency = {angle of incidence (2), critical angle (2), 
energy (1), reflection (2), refraction (9), refractive index (9), speed  (4), total 
internal reflection (3)}  
 
Total number of words present in document D1 = 412 
 
Relevance Score (R) of D2 for the input query =  
412
1 *(2 +
2
1 *2+
2
1 *2+
2
1 * 3) 
                                    =  0.0133 
The relevance score of the document D1, which has comparatively more number of 
related concepts of the query concept reflection, is more than the document D2. 
 
2. Understandability Score: Relevance of a document with respect to the user  
The idea behind calculating the relevance of a document to a given learner is to 
determine  
 
• Whether the learner is interested in the document. 
• Whether the learner can understand the document.  
• Whether the learner will gain new knowledge from the document. 
 
A document may be relevant to a query but it may not be understandable to the 
learner. This can happen if for example the document contains many concepts that 
are unknown to the learner. If a document contains too many concepts that are 
unknown or outside the scope of the learner’s curriculum then the document may 
not be understandable to the learner. For the same query input the relevance of a 
document will be different for different learners having different knowledge levels.  
 
A learner should gain new knowledge from the document. For meaningful 
expository learning D. Ausubel has proposed subsumption theory 
(http://tip.psychology.org/ausubel.html). According to Ausubel, a primary process 
in learning is subsumption in which new material is related to relevant ideas in the 
Chapter – 7 
   
 
 - 173 -
existing cognitive structure on a substantive basis. Cognitive structures represent 
the residue of all learning experiences. A major instructional mechanism proposed 
by Ausubel is the use of advance organizers. According to him (Ausubel, 1963, pp. 
81) "These organizers are introduced in advance of learning itself, and are also 
presented at a higher level of abstraction, generality, and inclusiveness; and since 
the substantive content of a given organizer or series of organizers is selected on 
the basis of its suitability for explaining, integrating, and interrelating the material 
they precede, this strategy simultaneously satisfies the substantive as well as the 
programming criteria for enhancing the organization strength of cognitive 
structure,”  
 
Ausubel emphasizes that advance organizers act as a subsuming bridge between 
the new learning material and existing related ideas. To provide documents, which 
add new knowledge to the learner, we have identified outcome concepts and 
prerequisite concepts for the document (discussed in Section 6.3.3). The presence 
of a set of known concepts in the document provides the existing knowledge. The 
outcome concepts of the document will give new knowledge to the learner. The 
prerequisite concepts of the document act as a subsuming bridge between the new 
knowledge and existing knowledge.  
 
A document may be too easy or difficult for a specific learner depending upon the 
presence of a set of known concepts in the document. This information is captured 
in the user profile of the learner. As discussed in Section 4.5, the user profile gives 
the learner’s current state of knowledge. It contains a list of concepts, which are 
known to the learner. We define a score called the understandability score (U), 
which reflects the extent of match between the concepts present in the document 
and the known concepts present in the learner’s state. We compute this score only 
for those documents that are relevant to the given query. 
 
To compute this score, we look at the concepts present in the document and the 
concepts present in the learner state. We find the proportion of the concepts of the 
document, which are known to the learner. We extract the list of unknown 
Chapter – 7 
   
 
 - 174 -
concepts. An unknown concept is easier to grasp, if the learner knows most of the 
prerequisite concepts of that concept. So we look at the prerequisite concepts of the 
unknown concepts. The meta tag prerequisite concepts available with the 
document gives the prerequisite concepts present in the document. But all the 
prerequisite concepts of unknown concepts may not present in the document. 
Therefore, we also look into the ontology to obtain all the prerequisite concepts of 
unknown concepts.  
 
To compute the understandability score of a document, we compute two scores: 
us1 and us2. The score us1 is computed using the meta tag prerequisite concepts 
available with the document. The score us2 is computed by obtaining all the 
prerequisite concepts of unknown concepts from the ontology.  
 
Computation of the score us1 using the meta tag prerequisite concepts: To 
compute the score us1, we use the meta tag prerequisite concepts available with 
the document. Let P be the set of prerequisite concepts present in the document. 
Let A be the subset of P containing the prerequisite concepts that are known to the 
learner. Let the size(A) be the total number of concepts present in set A and size(P) 
be the total number of concepts present in set P. The score us1 is computed as 
follows: 
us1 = 
size(P)
size(A)   
The value of us1 varies between 0 and 1.    
 
Computation of the score us2 using the ontology: Let C = {C1, C2…. Cn} be the 
concepts present in the document D. The concepts in set C  be divided into two 
categories i. e. known concepts and unknown concepts. The known concepts are 
those that are known to the user. Similarly, the unknown concepts are those that 
are not known to the user. 
 
Chapter – 7 
   
 
 - 175 -
Let the set K contains the known concepts and the set U contains the unknown 
concepts. We obtain all the prerequisite concepts for each of the unknown 
concepts∈U from the ontology. Next, we check whether the obtained prerequisite 
concepts are known to the learner consulting the user profile. We partition set U 
into two subsets U1 and U2. The subset U1 contains the concepts, whose all 
prerequisites are known to the user. U2 = U-U1 is the subset of U, which contains 
the concepts, whose at least one prerequisite is unknown to the user.  
Let the size(K), size(U1), size(U2) give the total number of concepts present in the 
set K, U1, U2 respectively. The us2 is computed as follows: 
us2 =  
size(C)
U2sizeU1)sizeKsize )(*(*)(* γβα ++  
    We take α =1, β=1/2, γ = 0 
us2 varies between 0 and 1. 
Computation of the understandability score of the document: The 
understandability score (U) of the document D is taken as the summation of the 
score us1 and the score us2. 
Understandability Score (U) = us1 + us2 
 
3. Document Score 
 
The document score is an estimate of the relevance of the document with respect to 
a query and the learner state. We compute the document score by combining the 
relevance score (R) and the understandability score (U). Only those documents are 
chosen, which have understandability score above threshold value. For the chosen 
documents, the document score is given by   
 
Document score = α1 * Relevance score (R) + α2 * Understandability score (U) 
 
For our experimentation, we have taken values α1 = α2 = 1. 
 
Chapter – 7 
   
 
 - 176 -
The documents are ranked using the document score and presented to the user. The 
above discussed relevance calculation mechanism is illustrated in the flow chart 
shown in Figure 7.3. 
 
 
 
 
Document does not 
 belong to  
the domain 
Document, query, 
domain knowledge,
user profile 
Query concept
 significance 
> threshold 
Relevance 
score ( R ) 
Understandabili
ty score ( U ) > 
threshold 
Document 
score 
= R + U 
Ranked  
document 
to the user 
Document does not 
understandable to  
the user 
Yes 
No Yes 
No 
Figure 7.3 Relevance calculation mechanism 
Chapter – 7 
   
 
 - 177 -
7.4.5 Snippet  
The snippet is a fragment of a web page returned by a general-purpose search 
engine in the search results along with the url of the web page. It helps the searcher 
to take better decision for selecting documents of their interest from the large pool 
of links retuned by the search engine. 
 
The documents returned by our system are also supplemented by snippets. The 
snippet of the document is generated dynamically for the given query. It contains 
fragment of sentences extracted from the document. The system provides different 
types of learning materials such as explanation, exercise, application and 
experiment type according to the learner’s interest. To generate a snippet from a 
document, our idea is to extract sentences which not only contain the query 
concept but also should reflect the type of the learning material. For example, it 
contains fragment of those sentences, which provides definitions of concepts, 
questions, the objective of experiments etc.  
 
The occurrences of the cue verbs, words and phrases play an important role in 
describing a document.  As discussed in Section 6.3.3, the sentences that provide 
definitions/explanations contain trigger words/phrases like defined, derived, called, 
known, states, deal with, describe, described, illustrated. Generally, the questions 
are interrogative sentences which contain interrogative pronouns which are trigger 
words such as what, why, how etc. The experiment type of document contains the 
trigger words like aim, obj:, objective, purpose etc.  
 
Hence any sentence that contains the trigger words and the query concepts or the 
trigger words or query concepts are extracted from the document and stored in a 
list, which is used to create the snippet. The snippet is created by extracting the 
first 70 words from this list of sentences, where sentences containing both the 
trigger words and the query concepts are given higher priority than sentences 
containing only the trigger words or query concepts. The snippet is shown to the 
Chapter – 7 
   
 
 - 178 -
learner along with the URL of the document. The snippet generation algorithm is 
outlined below. 
 
 
Algorithm 7.2 Snippet Generation 
 
Input : document D 
Output: snippet SN 
 
// document D 
// D contains m sentences S1 ,…, Sj ,…, Sm 
// Q is the concept list of the given input query containing k concepts, Q ← { q1   
,…,qi ,…, qk  } 
// T is the list of trigger words/ phrases ti, T ← { t1 ,… ,ti ,…,tn) 
// A is a list of sentences, A←{} 
// B is a list of sentences, B←{} 
 
(1) for each sentence Si  in the document D 
 if Si  contains tj  and qk   // tj is an element of T and qk is an element of Q 
         A←A ∪ Si 
                 if Si  contains tj   
     B←B ∪ Si 
                 if Si  contains qk  
     B←B ∪ Si 
(2) if number of words in A < 70 
            A←A ∪ B 
(3) return SN←the first 70 words from A 
 
 
 
Chapter – 7 
   
 
 - 179 -
Some of the example snippets generated by the Algorithm 7.2 is shown in Figure 
7.4.  
 
Figure 7.4 Some example snippets  
 
In Figure 7.4, the document no. 1 discusses about the working of Galilean 
telescope and contains questions on the Galilean telescope. The questions from the 
document are picked up and shown in the snippet. The document no. 2 and 
document no. 3 discuss about lab experiments. The snippet of these documents 
contains the objective of the experiment. The snippet of the document 5 contains 
definition and some questions.  
 
 (1)  http://galileo.rice.edu/lib/student_work/astronomy96/mtelescope.html 
What is a Galilean telescope, What are the disadvantages of a Galilean telescope, How does a Galilean telescope work, 
How do you make a Galilean telescope  
(2)  http://www.frontiernet.net/~jlkeefer/converging_and_diverging_lenses_.htm 
Obj: To examine the features of convex lens and use the lens equation, What is astigmatism, Describe the image of any 
object at close and long range. Analysis 1. Describe the conditions when a convex lens acts as a magnifying glass 
 (3)  http://umbc7.umbc.edu/~gmorris/physics112/labs/lab18.htm 
Purpose: 1) To study the relationship between the object distance and the image distance for a concave mirror and for a 
converging lens; 2) to find the relative heights of object and image; 3) to find the focal length of mirrors and lenses; 4) to 
study the behavior of a system of two converging lenses. 
(4) http://en.wikipedia.org/wiki/Lens_(optics) 
If the lens is biconvex or plano-convex, a collimated or parallel beam of light travelling parallel to the lens axis and 
passing through the lens will be converged (or focused) to a spot on axis, at a certain distance behind the lens (known as 
the focal length). In this case, the lens is called a positive or converging lens, meniscus lens can refer to any lens of the 
convex-concave type  
(5)  http://ganymede.nmsu.edu/astro/a110labs/labmanual/node9.html 
n = line which is always perpendicular to the surface; also called the normal light ray and the normal, Optics: Mirrors 
How do mirrors work, What do you conclude about how light is reflected from a mirror, How does the magnification 
depend on the distance of the lens from the object, Describe the properties of the different types of lenses and mirrors 
discussed in this lab, What are some of the differences between mirrors and lenses  
(6)  http://www.glenbrook.k12.il.us/GBSSCI/PHYS/CLASS/refrn/u14l5da.html 
The goal of a ray diagram is to determine the location, size, orientation, and type of image which is formed by the double 
convex lens, The method of drawing ray diagrams for double convex lens is described below, Each diagram yields 
specific information about the image 
Chapter – 7 
   
 
 - 180 -
7.5 Implementation of the Retrieval System  
7.5.1 Simple Search 
The user interface for simple search is shown in Figure 7.5. For performing simple 
search, two buttons are provided. These buttons are user specific local search and 
user specific web search. The user specific local search enables the user to search 
learning materials from the repository of the system. The user specific web search 
provides the facility of searching learning materials personalized to the user from 
the web.  
 
To perform user specific search, user needs to provide his user identification 
number. A user can give his user identification number through User ID text field. 
Figure 7.5 The user interface 
Input query Simple  Search
Local Repository 
Search Web Search User ID
Chapter – 7 
   
 
 - 181 -
For the given query, the relevant documents are filtered and ranked consulting the 
user profile and the domain knowledge of the system. The result pane presents the 
search results to the user.  
7.5.1.1 Evaluation of the Retrieval Module for Simple Search 
We have contacted students of grade 7 and grade 10 from different schools of 
Kharagpur (DAV Model School, IIT Kharagpur and Hijli School, IIT Kharagpur). 
We have created user profiles for the students. We have asked the students to 
provide queries of their interest in the subject of Physics, biology and geography. 
We have collected nearly 60 queries belonging to these domains from 20 students. 
We observed that many students, especially from grade 7 have given single word 
query. The set of queries given by grade 10 students mostly contain one or two 
keywords. These queries are processed by our system. The system filters the 
relevant documents and the ranked them considering the student’s current state of 
knowledge before presenting them to the learner.  
 
To evaluate the performance of our system, many queries from the collected set 
were processed out by our system. For the same given query, the ranking of the 
documents varies according to the learner’s knowledge level. Here, we show the 
results obtained by our system for the query reflection for two students whose 
knowledge level differs from each other. 
 
The query reflection was forwarded to the Google search engine and first 100 
documents were further processed by our system. The system first filtered out the 
domain specific documents and the filtered documents were re-ranked using 
documents score (discussed in Section 7.4.4). The Table 7.2 and Table 7.3 show 
the first ten documents presented by our system to two different students with User 
Id CS2 and CS4 for the same query reflection. In Table 7.2 and 7.3, the first 
column shows the document ranking given by our system. We have manually 
checked the ranking of the same document in the search results returned by the 
Google search engine. The second column gives the Google page ranking. The 
Chapter – 7 
   
 
 - 182 -
third column gives the document score and the fourth column gives the URL of the 
document. 
 
Table 7.2 the top 10 output results shown to a student with  
User Id CS2 for query reflection 
 
System 
Ranking 
Google 
Ranking 
Document 
Score URL 
1 21 1.1419 http://www.physicsclassroom.com/Class/refln/reflntoc.html 
2 98 1.1408 http://www.geom.uiuc.edu/education/calc-init/rainbow/reflection.html 
3 12 1.0524 http://id.mind.net/~zona/mstm/physics/light/rayOptics/reflection/reflection1.html 
4 35 1.00960 http://hyperphysics.phy-astr.gsu.edu/hbase/phyopt/reflectcon.html 
5 15 0.9872 http://www.glenbrook.k12.il.us/gbssci/phys/Class/refln/u13l1c.html 
6 17 0.94902 http://www.bbc.co.uk/schools/gcsebitesize/maths/shape/symmetryrev2.shtml 
7 54 0.91724 http://www.gcse.com/waves/reflection.htm 
8 66 0.90999 http://acept.asu.edu/PiN/mod/light/reflection/pattLight1.html 
9 19 0.83404 http://physics.bu.edu/~duffy/PY106/Reflection.html 
10 45 0.83341 http://acept.asu.edu/PiN/rdg/reflection/reflection.shtml 
 
 
 
 
 
Chapter – 7 
   
 
 - 183 -
Table 7.3 The top 10 output results shown to a student with  
User Id CS4 for query reflection 
 
System 
Ranking 
Google 
Ranking 
Document 
Score URL 
1 66 1.4584 http://acept.asu.edu/PiN/mod/light/reflection/pattLight1.html 
2 35 1.3205 http://hyperphysics.phy-astr.gsu.edu/hbase/phyopt/reflectcon.html 
3 17 1.1419 http://www.bbc.co.uk/schools/gcsebitesize/maths/shape/symmetryrev2.shtml 
4 21 1.1408 http://www.physicsclassroom.com/Class/refln/reflntoc.html 
5 98 1.0096 http://www.geom.uiuc.edu/education/calc-init/rainbow/reflection.html 
6 19 0.8385 http://physics.bu.edu/~duffy/PY106/Reflection.html 
7 54 0.8340 http://www.gcse.com/waves/reflection.htm 
8 15 0.8061 http://www.glenbrook.k12.il.us/gbssci/phys/Class/refln/u13l1c.html 
9 85 0.7912 http://www.spin.gr/static/sections/applets/kiselev/javapm/java/totintrefl/index.html 
10 67 0.7661 http://theory.uwinnipeg.ca/physics/light/node4.html 
 
For the same query, the ranking of documents in the output results varies for 
students with User ID cs2 and cs4 according to their knowledge levels. The known 
concept space of student cs4 is more as compared to the student cs2. If we go 
through the documents shown to students, we find that the top ranked document 
shown to student cs4 includes discussion of the concept reflection along with other 
concepts refraction and total internal reflection, whereas the document score for 
the same document for student cs2 is less and is ranked at 8th position in the 
returned result set. 
Chapter – 7 
   
 
 - 184 -
7.5.2 Advanced Search 
The system provides the facility of advanced search. To learn a topic as a whole, a 
student may look for the different types of documents that contain applications or 
exercises, or experiments on the same topic. The advanced search allows students 
to filter the search results and retrieve documents of a particular type like 
experiment type, exercise type, application type or explanation type. It also allows 
students to retrieve documents of their grade level.  
 
The general-purpose search engine returns thousands of documents for any query 
input. Generally, this large set contains all the above types of documents but not in 
any orderly manner. For example, a student is interested in the documents that 
contain exercises or questions on convex lens. The exercise type documents on 
convex lens are available in the output results of a search engine but they are 
arbitrarily distributed in the search results. The ranking of the exercise type 
documents in the search result returned by the Goggle search engine for the query 
convex lens is 34, 52, 88, 125, 151 etc. Similarly, we find that the ranking of the 
experiment type documents in search result retuned by the Goggle search engine 
for the query convex lens is 109, 119,122, 128, 135, 177, 180, 418 etc. These 
documents are ranked at a greater depth and students find it very difficult and 
waste of time to retrieve a particular type of documents from this large pool.  
 
In our system, the advanced search assists users by filtering documents and 
delivering a particular type of document. It selects the document of user’s interest 
and eliminates the rest.  
 
The user interface for performing the advanced search is shown in Figure 7.6. The 
advanced search button enables the user to perform advanced search. Users can 
provide the grade level and the type of document of their interest through Grade 
and Type of learning resource text fields. The result pane presents the advanced 
search results to the user.   
 
Chapter – 7 
   
 
 - 185 -
7.5.2.1 Evaluation of the Retrieval Module for Advanced Search 
To assess the performance of the advanced search of our system, first 200 
documents returned by the Google search engine for the query convex lens are 
collected and advanced search is done on these 200 documents. The advanced 
search filters documents as per the given learning resource type. The advanced 
search results for different learning resource types are shown below. 
 
Input for advanced search 
Learning Resource Type = Experiment 
Keyword = convex lens 
 
Grade Type of learning 
Resource 
Submit Avd. 
Search 
Key-
word 
Figure 7.6 User interface for advanced search
Chapter – 7 
   
 
 - 186 -
Output results obtained by our system for the above input search parameters are 
shown in Table 7.4. The column 3 gives the ranking of the documents obtained by 
our system for the above input search parameters. The column 4 gives the URL of 
the document. The column 2 gives the ranking of the same document obtained by 
the Google search engine for the input query convex lens. 
 
Table 7.4 Advanced search results for the experiment type documents 
 
S. 
No. 
Goggle 
Page 
Ranking 
System  
Ran-
king 
URL 
1 180 1 http://www.saburchill.com/physics/practicals/030.html 
2 119 2 http://www.hsphys.com/light_and_optics.html 
3 30 3 http://www.school-for-champions.com/science/experiments/simopticslens.htm  
4 43 4 http://faculty.virginia.edu/teach-present-bio/LightRefraction.html  
5 72 5 http://www.rit.edu/~vjrnts/courses/OFT/labs/lens_identification/  
6 109 6 http://acept.la.asu.edu/PiN/rdg/lenses/lenses2.shtml  
7 198 7 http://acad.erskine.edu/facultyweb/wjunkin/Demo/opticslab3.htm  
8 9 8 http://www.lessonplanspage.com/ScienceConvexConcaveLenses69.htm  
9 109 9 http://acept.la.asu.edu/PiN/rdg/lenses/lenses2.shtml  
10 85 10 http://galileo.rice.edu/lib/student_work/astronomy96/mtelescope.html  
11 122 11 
http://amazing-
space.stsci.edu/resources/explorations/groundup/teacher/scienc
ebackground.html   
12 53 12 http://www.frontiernet.net/~jlkeefer/lenses.doc  
13 54 13 http://www.dartmouth.edu/~physics/labs/descriptions/lenses.html  
14 128 14 http://www.hazelwood.k12.mo.us/~grichert/sciweb/opticsl1.htm  
15 135 15 http://physics.indiana.edu/~demos/demos/F5-1.htm  
16 177 16 http://cosmos.phy.tufts.edu/~zirbel/laboratories/Telescope.pdf  
Chapter – 7 
   
 
 - 187 -
Input for advanced search 
Learning Resource Type = Exercise 
Keyword = convex lens 
 
Output results obtained by our system for the above input search parameters are 
shown in Table 7.5. 
 
 
Table 7.5 Advanced search results for the exercise type documents 
 
S. 
No. 
Goggle 
Page 
Ranking 
System 
Ranking URL 
1 34 1 http://www.glenbrook.k12.il.us/gbssci/phys/CLass/refrn/u14l5f.html  
2 52 2 http://acept.la.asu.edu/PiN/mod/light/lenses/pattLight2Obj2.html  
3 151 3 http://www.ewart.org.uk/science/waves/wav7.htm  
4 125 4 http://www.frontiernet.net/~jlkeefer/converging_and_diverging_lenses_.htm  
5 162 5 http://faculty.virginia.edu/teach-present-bio/LightWorksheet.html  
6 88 6 http://www.iit.edu/~smile/ph9523.html  
 
 
Input for advanced search 
Learning Resource Type = Application 
Keyword = convex lens 
 
Output results obtained by our system for the above input search parameters are 
shown in Table 7.6. 
 
 
 
 
Chapter – 7 
   
 
 - 188 -
Table 7.6 Advanced search results for the application type documents 
 
S. 
No. 
Goggle 
Page 
Ranking 
System  
Ranking URL 
1 45 1 http://homepage.mac.com/cbakken/obookshelf /cvfocal.html   
2 31 2 http://www.jbvoptical.com/s-lenses.html  
 
Input for advanced search 
Learning Resource Type = Explanation type 
Keyword = convex lens 
 
Our system retrieves total 44 documents for the above input search parameters. 
First 10 results are shown in Table 7.7 
 
Table 7.7 Advanced search results for the explanation type documents 
 
S. 
No. 
Goggle 
Page 
Ranking 
System  
Ranking 
URL 
1 18 1 http://en.wikipedia.org/wiki/Lens_(optics)  
2 46 2 http://hyperphysics.phy-astr.gsu.edu/Hbase/geoopt/raydiag.html  
3 3 3 http://en.wikipedia.org/wiki/Convex_lens  
4 2 4 http://www.physicsclassroom.com/Class/refrn/U14L5a.html  
5 1 5 http://www.play-hookey.com/optics/lens_convex.html  
6 7 6 http://www.lessonplanspage.com/ScienceConvexConcaveLenses69.htm  
7 157 7 http://www.colorado.edu/physics/phys1230/phys1230_fa
01/topic22.html  
8 109 8 http://acept.la.asu.edu/PiN/rdg/lenses/lenses2.shtml  
9 110 9 http://www.shokabo.co.jp/sp_e/optical/labo/lens/lens.htm 
10 9 10 http://www.answers.com/topic/convex-lens-1  
Chapter – 7 
   
 
 - 189 -
To evaluate the performance of the advanced search of our system in terms of 
precision and recall, we have taken the first 200 documents returned by the Google 
search engine for the query convex lens. These 200 documents were given as input 
to our system. Using the advance search facility, we have filtered the documents 
into four different types of documents. The four types of documents are experiment 
type, exercise type, application type and explanation type. The first 200 documents 
returned by the Google are manually categorized into above four types of 
documents. The advanced search results for a particular type of documents 
returned by our system were compared with the manual observation.  
 
The experimental results of the advanced search of our system for different types 
of documents are shown in Table 7.8. The precision and recall of the advanced 
search is calculated and presented in this table. 
 
Table 7.8 Evaluation of advanced search 
 
Manual observation of first 
200 documents obtained 
from Google search engine 
for query “convex lens” 
System output 
Document 
type 
Number of 
documents Correct 
False 
positive 
False 
negative 
Pr
ec
is
io
n 
 in
 
pe
rc
en
ta
ge
 
R
ec
al
l  
in
 
pe
rc
en
ta
ge
 
Experiment 
type 23 16 2 7 88.88 69.56 
Exercise 
type 10 5 1 5 83.33 50 
Application 
type 3 2 0 1 100 66.66 
Explanation 
type 43 38 6 5 86.36 88.83 
 
Chapter – 7 
   
 
 - 190 -
The precision of the advanced search for the experiment type document is 88.88% 
and the recall is 69.56%. On closer look at false negative documents of the 
experiment type, we find that in some documents, headings of paragraph are 
different than usual headings of any experimental type documents. For example 
heading topic is used in place of objective or aim or purpose of the experiment. 
Similarly Materials is used in place of equipment or apparatus required. Since 
these words are not included the trigger word list of the experiment type 
documents as a result these documents are not selected.  It is required to extend the 
trigger word list with careful inspection. 
 
The precision and recall for exercise documents is 83.33% and 50%. Documents 
containing multiple choice questions and fill in blanks type question are eliminated 
out by the system, as they do not contain interrogative sentences. In some cases, 
these documents are recognized as the explanation type documents. 
 
The precision of explanation type documents is 86.36%. There are some exercise 
documents, which contain questions as well answers for the questions. As long 
answers are also present in the document, system categorizes them as explanation 
type documents. A few experiment type documents are also recognized as 
explanation type documents. 
7.5.3  Hierarchy Browsing for Navigation on Topics 
The learner can navigate through the topic hierarchy of the syllabus of any class or 
grade level to access documents on topics. In every grade level, there is a 
predefined syllabus. The syllabus of a subject consists of chapters. The chapters 
are again divided into topics. It is expected that a student’s interest is to learn the 
topics of the syllabus of his grade level. Our system provides the facility of 
navigation on topics of his syllabus or curriculum requirement.  
 
Each document in the repository of the system is tagged with the metadata topic of 
the document. The algorithm for identification of the topic of the document is 
Chapter – 7 
   
 
 - 191 -
discussed in Section 6.3.4. This metadata topic helps the retrieval module of the 
system to retrieve documents on the topics of student’s interest.   
 
The curriculum requirement or the syllabus of different subjects for different grade 
levels is maintained in the group-profile. The user interface for the topic navigator 
enables the student to access the topic hierarchy of his grade level. In Figure 7.7, 
the left pane shows the topic hierarchy of the grade level 7 for the subject physics. 
It contains chapters like electric charge at rest, energy, heat, matter, mirror and 
reflection of light, sound.  Each chapter contains a set of topics. A student can 
select either a topic from a chapter or a full chapter. When a chapter is selected, 
then the system provides the documents on each of the topics of that chapter. For 
example, suppose the chapter mirror and reflection of light is selected in the topic 
hierarchy. This Chapter consists of topics mirror, reflection and law of reflection. 
The system retrieves documents on each of the above topics. In Figure 7.7, the 
Figure 7.7 Documents on chapter mirror and reflection of light 
Chapter – 7 
   
 
 - 192 -
right pane shows the documents on the topics law of reflection, mirror and 
reflection. When a topic from a chapter is selected, it provides documents only on 
that topic.  
 
The topic hierarchy browsing enables the learner to navigate through the different 
topics of the syllabus of his grade level.  A Learner can navigate through the topics 
and can obtain learning materials on different topics of his/her curriculum 
requirement.  
7.6  Summary  
In this chapter, we have discussed the personalized information retrieval of our 
system in the domain of school curriculum related topics. Users can perform 
personalized search from the system’s repository as well as directly from the web. 
The system provides the facility of the simple search, the advanced search and the 
topic hierarchy navigation for document extraction on topics. The search results 
are supplemented with snippet, which helps the learner to take better decision for 
selecting documents.  
 
The simple search filters the domain specific documents and provides the 
personalized search results to a user based on his requirement and current state of 
knowledge. In the case of searching documents directly from the web, the post 
processing of documents for domain specific filtering increases the precision of 
search results. But the post processing of documents take time and respond slowly 
to the user’s query.  
 
The advanced search further refines the search results on different search 
parameters as required by the user. The advanced search can be done on the grade 
level and on the learning resource type. A user can navigate though the topic 
hierarchy of his/her curriculum requirement to access documents on topics.  
Chapter – 8  
 
Conclusion and Future Work 
 
8.1 Conclusion 
 
Standard metadata schemes like Dublin Core and IEEE LOM have been developed 
to represent learning objects and courses with an eye towards reusability. A 
learning system needs to use pedagogic attributes including document type, topic, 
difficulty level, coverage of concepts, and for each concept the significance and the 
role. Moreover, in order to have a flexible and reusable repository of e-learning 
materials, it is necessary that the annotation of the documents with such metadata 
be done in an automatic fashion as far as possible. 
 
Automatic annotation of learning materials is a difficult task. However, the 
progress in natural language processing, machine learning and data mining is 
making this difficult task possible.  
 
To reduce the overhead of the manual annotation, we have explored the feasibility 
of automatic annotation of learning materials with metadata. This facilitates the 
creation of an e-Learning repository for storing these annotated learning materials, 
which can be used by different learning management systems or tutoring systems. 
The idea is to make use of learning materials from various sources such as from the 
web, from other repositories or from authors for developing high quality learning 
materials with specific metadata information. The learning materials are reusable 
and interoperable between different learning management systems. The automatic 
annotation is based on the domain ontology and a number of algorithms like 
Chapter – 8 
   
   
 - 194 -
standard classification algorithms, parsing and analysis of documents have been 
used for this purpose. 
 
We have developed an automatic annotation tool for annotating documents with 
metadata such as concepts, their significance and type, topic, difficulty level and the 
learning resource type. The domain ontology has been used to extract the list of 
concepts from the document. The concept attributes significance and types are also 
extracted automatically from the document. Identification of the type of concept is 
a complex problem. However, we have attempted it by analyzing the documents 
with a shallow parsing approach and by using some inference rules. But to improve 
the performance it is required to do a deeper analysis and also to incorporate a few 
more inference rules. 
 
We use the domain ontology for automatic identification of the topic of a 
document. In some cases, it classified the document into some of its related topics, 
which shares many common concepts. Use of specificity index (concepts are 
associated with specificity index in the ontology) improves the results of the 
ontology-based classification. For this the ontology must be edited to incorporate 
this feature.   
 
The document type attribute plays a vital role in the adaptive presentation of 
learning materials. The documents are categorized into four types namely 
explanation type, experiment type, application type, exercise type. To identify the 
document type, we have identified some of the surface level features of the text 
and used these sets of features to classify the documents into different types using 
feedforward backpropagation neural network and generalized regression neural 
network. The classification performance is poor for application type of documents. 
We feel that a more thorough and deeper semantic analysis of the learning 
materials and enhanced feature set would be required for improving the 
classification performance. 
 
Chapter – 8 
   
   
 - 195 -
We have worked on the automatic identification of the metadata grade level, which 
gives the difficulty level of the document. The algorithm for grade level uses the 
group profile, which is a part of the ontology. The group profile is built manually. 
It is required to build it very carefully to get fairly good results. 
 
We have developed a search tool for retrieval of the appropriate learning materials 
to meet the learner’s requirements from the repository and also from the web. In 
order to find the relevance of a document for a particular learner, the retrieval 
module looks into the domain ontology and the learner’s requirements. 
 
In our system, the facility of hierarchical browsing for navigation on topics has 
been provided to the learner. The system maintains the curriculum requirement or 
syllabus of different grade levels. The learners can navigate through the topic-
subtopic hierarchy and obtain learning materials on different topics.  
 
We have also generated snippets that provide the learner with a useful summary of 
the page. The snippets are designed to help a learner to identify the essence of the 
learning material. It provides snapshot of the different concepts that have been 
defined and explained in the document. It also provides the fragment of sentences 
containing questions on different concepts, objective of experiment etc. 
8.2 Future Work 
There are several future research directions on which one can focus from our current 
status.  
 
8.2.1 Extension of the Metadata Schema 
 
We have worked on a small subset of pedagogic metadata from the IEEE LOM 
standard. As discussed in Chapter 5, the pedagogic metadata attributes of our 
metadata schema presently consists of document type, topic, difficulty level, 
coverage of concepts, and for each concept the significance and the role.  
 
Chapter – 8 
   
   
 - 196 -
It will be useful to be able to annotate automatically more metadata attributes. This 
will help in improving a learning system or a tutoring system to provide learning 
materials to fulfill the learning goal of a learner. Presently, we have considered 
four types of documents: explanation, application, exercise and experiment and 
worked on the automatic extraction of the above four type of the document. Other 
document types like simulation type, example type etc. are also important from 
instructional design perspective and are required to be included into the metadata 
schema for automatic extraction. We have automatically identified the difficulty 
level of a learning object, the metadata attributes semantic density, which gives the 
degree of conciseness of a learning object and independent of its difficulty, needs 
to be identified automatically from the document. 
8.2.2  Ontology 
The ontology used for this work is purely manually populated. There are some 
drawbacks in manual population of ontologies. First of all, the efforts needed to 
build ontology for a domain requires a great effort from the ontology builder. 
Again the quality of the created ontology largely depends on the expertise of the 
domain expert who builds the ontology. These drawbacks can be eliminated by 
automatic acquisition of ontology [Gomez-Perez, 2003]. This has got several 
advantages over manual authoring of ontology. Effort needed to build the ontology 
will be lower than that with manual population. Moreover, the quality of the 
ontology will depend only on the acquisition data and acquisition algorithm, which 
can be tuned to obtain a desired quality.  
 
The ontology builder stores the ontology in two form: relational database and in 
XML format. We haven’t yet provided the facility of importing ontologies created in 
other formats and exporting our ontology to other well-known formats like OWL, 
OML, OIL, SHOE etc. Ontology storage in the above formats is important because 
they provide facilities for sharing ontology easily.  
Chapter – 8 
   
   
 - 197 -
8.2.3 User Model 
The intelligence of an intelligent educational system depends on its ability to adapt 
to a specific learner’s requirement. It involves choosing and presenting learning 
materials considering the student’s knowledge, which are in turn maintained in a 
student model.  
 
Presently, in our system the student himself performs user profile acquisition and 
update. The user profile updating is not dynamic. The system does not update the 
user profile automatically. One may work on automatic updating of the user profile. 
Again, the acquisition of user profile is completely ontology based. This restricts the 
system to acquire concepts that occurs only in the domain. The system fails to draw 
inference for other domains for which the ontology is not available to the system. To 
make the system more general, the user profile should include concepts outside the 
defined ontology. 
 
 
 
 
 
 
 
 
References 
 
ADL, Advance Distributed Learning Initiative, http://www.adlnet.org 
Aitken, S., Reid, S. (2000). Evaluation of an Ontology-Based Information 
Retrieval Tool. Proceedings of 14th European Conference on Artificial 
Intelligence, ECAI 2000, Aug 20-25, Berlin, Germany. 
Anderson, J. D., Perez-Carballo, J. (2001). The nature of indexing: how humans 
and machines analyze messages and texts for retrieval. part I: research, and 
the nature of human indexing. Information Processing Management, vol. 
37, pp. 231-254. 
ARIADNE, European Knowledge Pool, http://www.ariadne-eu.org 
Armstrong, R., Freitag, D., Joachims, T., Mitchell, T.  (1995). WebWatcher: A 
Learning Apprentice for the World Wide Web. Proceedings of the AAAI 
Spring Symposium on Information Gathering, pp 6-12. 
Aroyo, L., Dicheva, D. (2001). AIMS: Learning and Teaching Support for WWW-
based Education. International Journal of Continuing Engineering 
Education and Life-Long Learning, vol. 11, pp. 152-164. 
Arruarte, A., Fernández-Castro, I., Ferrero, B., Greer, J. (1997). The IRIS Shell: 
"How to Build ITSs from Pedagogical and Design Requisites". 
International Journal of Artificial Intelligence in Education, vol. 8, pp. 
341-381. 
Asnicar F. A., Tasso C. (1997). ifWeb: a Prototype of User Model-Based 
Intelligent Agent for Document Filtering and Navigation in the World 
Wide Web. Sixth International Conference on User Modeling, 2-5 June, 
Chia Laguna, Sardinia.  
Ausubel, D. P. (1963). The Psychology of Meaningful Verbal Learning. New York 
Grune and Stratton. 
References 
   
 
 
 - 199 -
Ausubel, D. P. (1968). Educational psychology: A cognitive view. New York, 
Holt, Rinehart and Winston. 
Baumann, S., Dengel, A., Junker, M., Kieninger, T. (2002). Combining Ontologies 
and Document Retrieval Techniques: A case study for an E-Learning 
scenario. Proceedings of 13th International Workshop on Database and 
Expert Systems Applications, DEXA Workshops: 2002, pp. 133-137. 
Baumgartner, R., Flesca, S., Gottlob, G.(2001). Declarative information extraction, 
web crawling, and recursive wrapping with lixto. Proceedings of 6th 
International Conference on Logic Programming and Nonmonotonic 
Reasoning, Vienna, Austria. 
Biemann, C. (2005). Ontology Learning from Text: S Survey of Methods. LDV-
Forum, vol. 20(2), pp.75-93. 
Bloom, B. S. (1956). Taxonomy of Educational Objectives. The Classification of 
Educational Goals, Handbook 1: The Cognitive Domain, New York: 
Longman, Green and Co, vol. 1. 
Bot, R. S., Wu Y. B., Chen, X., Li Q. (2004). A Hybrid Classifier Approach for 
Web Retrieved Documents Classification. Proceedings of the International 
Conference on Information Technology: Coding and Computing (ITCC’ 
04), pp. 326-330. 
Bra Paul De, Houben G.J., Wu H. (1999). AHAM: A Dexter based Reference 
Model to support Adaptive Hypermedia Authoring. Proceedings of the 
ACM Conference on Hypertext and Hypermedia, Darmstadt, Germany, pp. 
147-156.     
Brooks, C., McCalla, G., Winter M. (2005). Flexible Learning Object Metadata. 
Workshop on Applications of Semantic Web Technologies for E-learning, 
July 18, Amsterdam,The Netherlands.  
Brusilovsky, P., Weber, G. (1996). Collaborative Example Selection in an 
Intelligent Example-based Programming Environment. In D. C. Edelson, & 
References 
   
 
 
 - 200 -
E. A. Domeshek (Eds.), Proceedings of International Conference on 
Learning Sciences, ICLS'96, Evanston, IL, USA, AACE, pp. 357-362. 
Bull, S., Pain, H. (1995). "Did I say what I think I said, and do you agree with 
me?”: Inspecting and questioning the student model, Proceedings of AI-
ED'95 - 7th World Conference on Artificial Intelligence in Education, 
AACE, pp. 501-508. 
Butler, D. (2000). Souped-Up Search Engines. Nature, vol. 405. pp. 112-115. 
CanCore guidelines, http://www.cancore.ca/en/help/44.html 
CanCore, http://www.cancore.ca/ 
Cardinaels, K., Meire, M., Duval, E., (2005). Automating Metadata Generation: 
the Simple Indexing Interface, Proceedings of the 14th International 
Conference on World Wide Web Committee (IW3C2), WWW 2005, may 
10-14, Chiba, Japan. 
CAREO, Campus Alberta Repository of Educational Objects, 
http://careo.ucalgary.ca/cgibin/WebObjects/CAREO.woa/wa/Home?theme
=careo 
Chaffee, J., Gauch, S. (2000). Personal Ontologies for Web Navigation. 
Proceedings of 9th International Conference on Information and 
Knowledge Management (CIKM,00) , Mclean VA, November, pp 227-234. 
Cohen, W. W. (1998). A Web-Based Information System that Reasons with 
Structured Collections of Text. Proceedings of Second International 
Conference on Autonomous Agents (Agents-98), pp. 116-123. 
Conati, C., Gertner, A.S., VanLehn, K. (2002). Using Bayesian Networks to 
Manage Uncertainty in Student Modeling. User Modeling and User-
Adapted Interaction, vol. 12, pp. 371-417. 
Corcho, O., Frnandez-Lopez, M., Gomez-Perez, A. OntoWeb. D1.1. Technical 
roadmap. www.ontoweb.org/deliverable.htm   
References 
   
 
 
 - 201 -
Craven, M., DiPasquo, D., Freitag, D., McCallum, A., Mitchell, T., Nigam, K., 
Slattery, S. (1998). Learning to Extract Symbolic Knowledge from the 
World Wide Web. Proceedings 15th National Conference Artificial 
Intelligence (AAAI-98), pp. 509-516. 
DC-dot, http://www.ukoln.ac.uk/metadata/dcdot/ 
DCMI, Dublin Core Metadata Initiative, http://dublincore.org/ 
Dehors, S., Faron-Zucker, C., Stromboni, J., Giboin, A. (2005). Semi-automated 
Semantic Annotation of Learning Resources by Identifying Layout 
Features. Workshop on Applications of Semantic Web Technologies for E-
learni, July 18, Amsterdam, The Netherlands.   
Dicheva, D., & Dichev, C. (2004a). A Framework for Concept-Based Digital 
Course Libraries. Journal of Interactive Learning Research, vol. 15(4), pp. 
347-364. 
Dicheva, D., Aroyo (2002). Concept and Ontologies in WBES. Proceedings 
Workshop Concepts & Ontologies in Web-based Education Systems, 
Auckland, New Zealand.  
Dicheva, D., Dichev, C., Sun, Y., Nao S., (2004b). Authoring Topic Maps-based 
Digital Course Libraries. Workshop on Applications of Semantic Web 
Technologies for Adaptive Educational Hypermedia, in conjunction with 
AH 2004, August 23-26, Eindhoven, The Netherlands, pp. 331-337. 
Dicheva, D., Sosnovsky S., Gavrilova T., Brusilovsky P. (2005). Ontological Web 
Portal for Educational Ontologies. Workshop on Applications of Semantic 
Web Technologies for E-learning, July 18, Amsterdam, The Netherlands. 
Dimitrova, V., Self, J., Brna, P. (1999). The Interactive Maintenance of Open 
Student Models. In S. P.Lajoie & M.  Vivet (Eds.) Artificial Intelligence in 
Education, Amsterdam: IOS Press, pp. 405-412. 
Dolog, P., Henze, N., Nejdl, W., Sintek, M. (2004).  The Personal Reader: 
Personalizing and Enriching Learning Resources using Semantic Web 
Technologies. International Conference on Adaptive Hypermedia and 
References 
   
 
 
 - 202 -
Adaptive Web-Based Systems (AH 2004), Eindhoven, The Netherlands, vol. 
3137 of LNCS, Springer. 
Downes, S. (2004). Resource Profiles. Journal of Interactive Media in Education, 
Special Issue on the Educational Semantic Web, vol. 5. 
Duval, E., Forte, E., Cardinaels, K., Verhoeven, B., Durm, R. V., Hendrikx, K., 
Forte, M. W., Ebel, N., Macowicz, M., Warkentyne, K., Haenni, F. (2001). 
The ARIADNE Knowledge Pool System. Communications of the ACM 
(CACM), vol. 44 (5). 
Duval, E., Hodgins, W. (2004). Metadata matters. Proceedings of International 
Conference on Metadata and Dublin Core Specification, DC-2004, 
Shanghai, China. 
EdNA, http://www.edna.edu.au/edna/page1.html 
EdNA, The Education Network Australia, http://www.edna.edu.au/ 
Friesen, N. (2004), International LOM survey: Report. ISO/IEC JTCI/SC36 sub-
committee, http://mdlet.jtc1sc36.org/doc/SC36_WG4_N0109.pdf 
Gasevic, D., Jovanovic, J., Devedzic, V., Boskovic, M. (2005). Ontologies for 
Reusing Learning Object Content. 5th IEEE International Conference on 
Advanced Learning Technologies (3rd Workshop on Applications of 
Semantic Web Technologies for E-learning ), July 5-8, Kaohsiung, Taiwan, 
pp. 944-945.  
Gelbukh, A. F., Sidorov, G., Guzman-Arenas, A. (1999). Document Comparison 
with a Weighted Topic Hierarchy, 10th International Workshop on 
Database & Expert Systems Applications ( Proceedings IEEE Computer 
Society), Florence, Italy, 1-3 September, pp. 566-570. 
Gomez-Perez, A., Manzano-Macho, D. (2003). Deliverable 1.5: A Survey of 
Ontology Learning Methods and Techniques. Ontoweb: Ontology-Based 
Information Exchange for Knowledge Management and Electronic 
Commerce,IST-2000-29243, 
http://www.deri.at/fileadmin/documents/deliverables/Ontoweb/D1.5.pdf 
References 
   
 
 
 - 203 -
Greenberg, J. (2004). Metadata extraction and harvesting: A comparison of two 
automatic metadata generation applications. Journal of Internet 
Cataloging, vol. 6(4), pp. 59-82. 
Gruber. T. R. (1993). A translation approach to portable ontology specifications. 
Knowledge Acquisition, vol. 5, pp.199-220. 
Guarino, N. (1998). Formal Ontology and Information Systems, IOS Press, 
Frontiers in Artificial Intelligence and Applications, vol. 46, pp. 347.  
Guha, R., McCool, R., Miller, E. (2003). Semantic Search. Proceedings of the 12th 
international conference on World Wide Web (WWW2003 ), ACM Press, 
pp. 700–709. 
Han, H. C., Giles, L., Manavoglu, E., Zha, H., Zhang, Z., Fox, E.A. (2003). 
Automatic document metadata extraction using support vector machines. 
Proceedings of the third ACM/IEEE-CS Joint Conference on Digital 
Libraries, pp. 37 - 48. 
Haruechaiyasak C., Shyu M., Chen S., Li X. (2002). Web Document Classification 
Based on Fuzzy Association, Proceedings of the 26th annual international 
computer software and applications conference (COMPSAC’02), pp. 487-
492. 
HEAL, Health education assets library, http://www.healcentral.org 
Henze N., Nejdi, W. (2002). Knowledge Modeling for Open Adaptive 
hypermedia, Proceedings of 2nd International Conference on Adaptive 
Hypermedia and Adaptive Web Based Systems, Malaga, Spain. 
Henze N., Nejdl W. (1999). Adaptivity in the KBS Hyperbook System. 2nd 
Workshop on adaptive systems and User Modeling on the WWW, may 11th , 
Tornto. 
Hockemeyer, C., Held, T., Albert, D. (1998). RATH – A Relational Adaptive 
Tutoring Hypertext WWW-Environment based on Knowledge Space 
Theory. Proceedings of the fourth International Conference on Computer 
References 
   
 
 
 - 204 -
Aided Learning in Science and Engineering, Goteborg, Sweden , Chalmers 
University of Technology, pp 417–423.  
Hoermann, S., Seeberg, C., Divac-Krnic, L., Merkel, O., Faatz, A., Steinmetz, R. 
(2003). Building Structures of Reusable Educational Content Based on 
LOM. Workshop on Semantic Web for Web-based Learning (SW-WL'03), 
June 16-20, Klagenfurt/Velden, Austria. 
Hubscher, R., Puntambekar, S. (2002). Adaptive Navigation for Learners in 
Hypermedia is Scaffolded Navigation. Second International Conference on 
Adaptive Hypermedia and Adaptive Web-Based Systems (AH 2002), May 
29-31, Malaga, Spain, pp. 184-192.  
Huynh, D., Mazzocchi, S., Karger, D. (2005). PiggyBank: Experience the 
Semantic Web inside your Web browser. Proceedings of the 4th 
International Semantic Web Conference, Galway, Ireland, pp. 413-430. 
IEEE LOM, IEEE learning Object Metadata, http://ltsc.ieee.org/wg12/index.html 
iLumina , http://www.ilumina-dlib.org 
IMS, Standard for Learning Objects. http://www.imsglobal.org/ 
iProspect Natural SEO keyword length study, iProspect.com, Inc., November 
2004, http://www.iprospect.com/premiumPDFs/keyword_length_study.pdf 
Jenkins, C., Inman, D. (2000). Server-Side Automatic Metadata Generation using 
Qualified Dublin Core and RDF. Kyoto, International conference on 
digital libraries: research and practice, pp. 262 – 269. 
Joachims, T., Freitag, D., Mitchell, T. (1997). WebWatcher: A Tour Guide for the 
World Wide Web. Proceedings  IJCAI’97. 
Jovanovic, J., Gasevic, D., Devedzic, V. (2006a), Ontology-Based Automatic 
Annotation of Learning Content. International Journal on Semantic Web 
and Information Systems, April-June, vol. 2(2), pp. 91-119. 
Jovanovic, J., Gasevic, D., Devedzic, V. (2006b). Automating Semantic 
Annotation to Enable Learning Content Adaptation. International 
References 
   
 
 
 - 205 -
Conference on Adaptive Hypermedia and Adaptive Web-Based Systems 
(AH 2006), June 21-23, Dublin, Ireland, pp. 151-160. 
Kamba, T., Bharat, K., Albers, M. C. (1995). The Krakatoa Chronicle- An 
Interactive Personalized Newspaper on Web, Proceedings of 4th 
international WWW conference, pp. 159–170. 
Kessler, B., Nunberg G., Schütze H.(1997). Automatic Detection of Text Genre. 
Proceedings of the Thirty-Fifth Annual Meeting of the Association for 
Computational Linguistics and, Eighth Conference of the European 
chapter of the Association for Computational Linguistics, pp. 32-38. 
Khan, B. H. (2005). Managing E-Learning: Design, Delivery, Implementation and 
Evaluation, Idea Group Inc, ISBN- 159140634X. 
Klavans J., Kan M.Y. (1998). Role of Verbs in Document Analysis, Proceeding of 
the 36th Annual Meeting of the ACL and Proceedings of the 17th 
International Conference on Computational Linguistic (COLING-ACL 
'98), Montreal, Canada. pp. 680-686. 
Konstan, J., Miller, B., Maltz, D., Herlocker, J., Gordon, L., Riedl, J. (1997). 
GroupLens: Collaborative Filtering for Usenet News, Communications of 
the ACM, special issue on collaborative filtering, March 97.  
Kraft, R., Maghoul, F., Chang, C.C. (2005). Y!Q: Contextual Search at the Point 
of Inspiration. Proceedings of the 14th Conference on Information and 
Knowledge Management (CIKM), pp 816-823. 
Kuki, T., Jokela, S., Sulonen, R. Turpeinen, M. (1999). Agents in Delivering 
Personalized Content Based on Semantic Metadata. Proceedings of 1999 
AAAI Spring Symposium, Workshop on Intelligent Agents in Cyberspace, 
Stanford, USA. pp. 84-93.  
LC Action Plan, http://lcweb.loc.gov/catdir/bibcontrol/actionplan.pdf 
 
References 
   
 
 
 - 206 -
LearnAlberta, LearnAlberta Online Curriculam Repository, 
http://www.learnalberta.ca/  
Lee, T. B., Hendler, J., Lassila, O. (2001). The Semantic Web. Magazine Scientific 
American.com. issue may 2001.  
Li, Y., Zhu, Q., Cao, Y. (2004). Automatic metadata generation based on Neural 
Network. Proceedings of the 13th International Conference on Information 
Security, ACM International Conference Proceeding Series, vol. 185, 
pp.192 –197. 
Liddy, E. D., Allen, E., Harwell, S., Corieri, S., Yilmazel, O., Ozgencil, N. E., 
Diekema, A.,McCracken, N. J., Silverstein, J., & Sutton, S. A. (2002). 
Automatic Metadata Generation & Evaluation. Proceedings of the 25th 
Annual International ACM SIGIR Conference on Research and 
Development in Information Retrieval, August 11-15, Tampere, Finland 
New York: ACM Press, pp. 401– 402. 
Link Grammar, http://bobo.link.cs.cmu.edu/link/ 
Liu, J., Greer, J. (2004). Individualized Selection of Learning Object, Workshop on 
Applications of Semantic Web Technologies for e-Learning, 30 August-03 
September, Maceió, Brazil.  
LydiaLearn, http://www.lydialearn.com/ 
MARC, Machine-readable cataloging, http://www.loc.gov/marc/marcdocz.html 
McCalla, G.(2004). The Ecological Approach to the Design of E-learning 
Environments: Purpose-based Capture and Use of Information about 
Learners. Journal of Interactive Media in Education (Special issue on the 
Educational Semantic Web), vol. 7.  
McCallum, A., Nigam, K., Rennie, J., Seymore, K. (1999). A Machine Learning 
Approach to Building Domain-Specific Search Engines. Proceedings 16th 
International Joint Conference Artificial Intelligence (IJCAI -99), pp 662-
667. 
References 
   
 
 
 - 207 -
McGreal, R. (2004). Learning objects: A practical definition. International journal 
of instructional technology and distance learning, September, vol. 1(9). 
MCLI, Maricopa Center for Learning and Instruction. 
http://www.mcli.dist.maricopa.edu/ 
MERLOT, Multimedia Educational Resources for Learning and Online Teaching, 
http://www.merlot.org 
Merrill, M. D. (2002). First Principles of Instruction. Educational Technology 
Research and Development, vol. 50(3), pp. 43-59. 
Mitrovic A., Devedzic, V. (2002). A model of MultiTutor Ontology-based 
Learning Environments, Proceedings Workshop Concepts & Ontologies in 
WBES, Auckland, New Zealand. 
Mladenic, D., Personal WebWatcher: Design and Implementation. Technical 
Report IJS-DP-7472, J. Stefan Institute, Department for Intelligent 
Systems, Ljubljana, Slovenia, 1998.  
MLX, Maricopa Learning Exchange, 
http://www.mcli.dist.maricopa.edu/mlx/index.php 
Mohan, P., Greer, J. (2003). E-Learning Specification in the Context of 
Instructional Planning.  International Conference on Artificial Intelligence 
in Education (AIED 2003), Sydney, Australia, pp 307-314. 
Murray Tom. (2003). Metalink: Authoring and Affordances for Conceptual and 
Narrative Flow in Adaptive Hyperbooks. International Journal of Artificial 
Intelligence in Education, special issue on Adaptive and Intelligent in 
Education, vol 13., pp. 199–233. 
Nejdl, W., Wolf, B., Qu, C., Decker, S., Sintek, M., Naeve, A., Nilsson, M., 
Palm´er, M., Risch, T. (2002). EDUTELLA: a P2P Networking 
Infrastructure based on RDF.  Proceedings of 11th World Wide Web 
Conference, May, Hawaii, USA.  
References 
   
 
 
 - 208 -
Nilsson, M.(Ed.). (2002). IEEE Learning Object Metadata RDF binding. 
http://kmr.nada.kth.se/el/ims/md-lomrdf.html 
NSDL, National Science Digital Library, 
http://metamanagement.comm.nsdlib.org/overview2.html#NSDL 
Ochoa, X., Cardinaels, K., Meire, M., & Duval, E. (2005). Frameworks for the 
Automatic Indexation of Learning Management Systems Content into 
Learning Object Repositories. World Conference on Educational 
Multimedia, Hypermedia & Telecommunications, EDMEDIA 2005, 
Montreal, Canada, pp. 1407-1414. 
Papanikolaou, K. A., Grigoriadou, M., Magoulas, G. D., Kornilakis, H. (2002). 
Towards New Forms of Knowledge Communication: the Adaptive 
Dimensions of a Web-based Learning Environment. Computer and 
Education, vol.39, page 333-360.  
Pazzani, M., Muramatsu, J., Billsus, D. (1996). Syskill & Webert: Identifying 
Interesting Web Sites. Proceedings of 19th National Conference on 
Artificial Intelligence (AAAI96). 
Popov, B., Kiryakov, A., Kirilov, A., Manov, D.,Ognyanoff, D., Goranov, M. 
(2003). KIM- Semantic annotation platform. Proceedings of the 2nd 
International Semantic Web Conference, Florida, pp. 834-849. 
Pretschner, A., Gauch, S. (1999). Ontology based personalized search. 
Proceedings of 11th IEEE International Conference on tools with Artificial 
Intelligence, Chicago, November 1999, pp 391-398.  
Rauber, A., Muller-Kogler, A. (2001). Integrating Automatic Genre Analysis into   
Digital Libraries, First ACM/IEEE-CS Joint Conference on Digital 
Libraries (JCDL’01), June 24-28, Roanoke, Virginia, USA, pp. 1-10. 
RDF, Resource Description Framework,http://www.w3.org/RDF/ 
RDN/LTSN resource type vocabulary, http://www.rdn.ac.uk/publications/rdn-
ltsn/types/ 
References 
   
 
 
 - 209 -
Robertson, I. T. (1985). Human Information-Processing Strategies and Style. 
Behavior and Information Technology, vol. 4 (1), pp.19-29. 
SCORM, Sharable Content Object Reference Model, 
http://www.adlnet.org/scorm/index.cfm 
Selberg, E., Etzioni, O. (1997). The MetaCrawler Architecture for Resource 
Aggregation on the Web. IEEE Expert, vol. 12(1), pp. 11-14. 
Shakes, J., Langheinrich, M., Etzioni, O. (1997). Dynamic Reference Sifting: A 
Case Study in the Homepage Domain. Proceedings of Sixth International 
World Wide Conference. (WWW 6), pp. 189-200. 
Shang, Y., Shi, H., Chan, S. (2001). An Intelligent Distributed Environment for 
Active Learning, ACM – 1-58113-348-0/01/0005, May. 
Shi, H., Rodriguez, O., Shang, Y., Chen, S. (2002). Integrating Adaptive and 
Intelligent Techniques into a Web-Based Environment for Active Learning. 
Intelligent Systems: Technology and Applications, CRC Press, Boca Raton, 
FL, vol. 4, Chapter 10, pp 229-260. 
Simon, B., Dolog, P., Miklos, Z., Olmedilla, D., Michael, S. (2004). 
Conceptualizing Smart Spaces for Learning. Journal of Interactive Media 
in Education, Special Issue on the Educational Semantic Web, Vol. 3(03), 
pp. 22-26. 
SMETE, The National Science, Mathematics, Engineering, and Technology 
Education Digital Library, http://www.smete.org 
Song, H., Zhong, L., Wang, H., Li R., Xia, H. (2005). Constructing an Ontology 
for Web-based Learning Resource Repository. Workshop on Applications 
of Semantic Web Technologies for e-Learning, October 2-5, Banff, Canada.  
Stamatos, E., Fakotakis, N., Kokkinakis, G. (2000).  Automatic Text 
Categorization in Terms of Genre and Author, Computational Linguistics, 
vol. 26(4), pp 471-95. 
References 
   
 
 
 - 210 -
Stefani, A., Strappavara, C. (1998). Personalizing Access to Web Sites: The SiteIF 
Project. Proceedings of the 2nd Workshop on Adaptive Hypertext and 
Hypermedia. 
Tan, M., Goh, A.(2004). The Use of Ontologies in Web-based Learning, 
Workshop on Applications of Semantic Web Technologies for e-Learning, 
November 8, Hiroshima, Japan.  
UKLOM core, http://www.cetis.ac.uk/profiles/uklomcore 
Ullrich C. (2004). Description of an Instructional Ontology and its Application in 
Web Services for Education. Workshop on Applications of Semantic Web 
Technologies for e-Learning, November 8, Hiroshima, Japan.  
Weber G., Kuhl H. C., Weibelzahl S. (2001a). Developing Adaptive Internet 
Based Courses with the Authoring System, NetCoach. Proceedings of the 
third workshop on adaptive hypermedia AH 2001. 
Weber, G., Brusilovsky, P. (2001b). ELM-ART: An Adaptive Versatile System for 
Web-based Instruction, International journal of Artificial Intelligence in 
education, vol. 12, pp. 351-384. 
XML, Extensible Markup Language, http://www.w3.org/XML/ 
Yan Tak W., Garcia-Molina, H. (1995). SIFT: A Tool for Wide-Area Information 
Dissemination. Proceedings of the 1995 USENIX Technical Conference, 
pp. 177-86. 
Zapata- Rivera, J. D., Greer, J.E. (2004b). Inspectable Bayesian Student Modeling 
Servers in Multi-Agent Tutoring Systems. International Journal of 
Human-Computer Studies, vol. 61 (4), pp. 535-563. 
Zapata-Rivera J. D., Greer, J. E. (2004a). Interacting with Inspectable Bayesian 
Student Models, International Journal of Artificial Intelligence in 
Education, Vol. 14(2), pp.127-163. 
Appendix A 
 
Ontology Format  
The ontology is built and stored in XML format. Later the ontology in XML 
format is transferred and stored in a relation database. The database is implemented 
in MySql. Java Open Database connectivity is used to establish connection 
between the database and the Java programs.  
 
XML Format 
A1. Concept File Format 
A concept file contains 
1. The concept itself 
2. The list of related concepts with relations 
3. The list of topics with specificity index (to which the concept belongs) 
 
An example of a concept file is shown below. 
<?xml version="1.0" ?> 
<!DOCTYPE concept-list SYSTEM  “concept.dtd”> 
- <concept-list> 
- <concept> 
  <name>angle of incidence</name>  
  <keyword>incidence angle</keyword>  
  <keyword>angle of incidence</keyword>  
  <topic>prism,0.5</topic>  
  <topic>law of reflection,1</topic>  
  <topic>mirror,0.5</topic>  
  <topic>lens,0.5</topic>  
  <prerequisite-for>mirror</prerequisite-for>  
  <prerequisite-for>prism</prerequisite-for>  
  <prerequisite-for>law of reflection</prerequisite-for>  
  <prerequisite-for>lens</prerequisite-for>  
  <inherited-from>angle</inherited-from>  
  <fun-related-to>angle of reflection</fun-related-to>  
</concept> 
  </concept-list> 
 
 - 212 -
A 2. Keyword File Format 
A keyword file contains: 
1. The keyword itself, 
2. List of associated concepts  
A portion of the keyword file is shown below. 
<?xml version="1.0" ?>  
<!DOCTYPE keyword-list SYSTEM  “keyword.dtd”> 
- <keyword-list> 
- <keyword> 
  <keyword>incidence angle</keyword>  
  <concept>angle of incidence</concept>  
  </keyword> 
- <keyword> 
  <keyword>angle of incidence</keyword>  
  <concept>angle of incidence</concept>  
  </keyword> 
- <keyword> 
  <keyword>charge</keyword>  
  <concept>electric charge</concept>  
  <concept>criminal charge</concept>  
  <concept> charge </concept>  
  </keyword> 
- <keyword> 
  <keyword>mirror</keyword>  
  <concept>mirror</concept>  
  </keyword> 
- <keyword> 
  <keyword>virtual image</keyword>  
  <concept> virtual image </concept>  
  </keyword> 
- <keyword> 
  <keyword> real image </keyword>  
  <concept> real image </concept>  
  </keyword> 
- <keyword> 
  <keyword>optical image</keyword>  
  <concept> image </concept>  
  </keyword> 
- <keyword> 
  <keyword>image</keyword>  
  <concept> image </concept>  
  </keyword> 
  </keyword-list> 
 
 
 - 213 -
Appendix B 
 
Metadata File Format 
 
The metadata annotation is expressed in a semantic web language. All IEEE 
metadata elements are compliant with IEEE LOM RDF binding specification 
(Nilsson, 2002) except the metadata attributes, which are extended by us. An 
example metadata file is shown below. 
 
 <?xml version="1.0" ?>  
- <rdf:RDF xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-
ns#" xmlns:rdfs="http://www.w3.org/2000/01/rdf-schema#" 
xmlns:dcterms="http://purl.org/dc/terms/" 
xmlns:dc="http://purl.org/dc/elements/1.1/" 
xmlns:lom="http://ltsc.ieee.org/2002/09/lom-base#" xmlns:lom-
gen="http://ltsc.ieee.org/2002/09/lom-general#" xmlns:lom-
life="http://ltsc.ieee.org/2002/09/lom-lifecycle#" xmlns:lom-
meta="http://ltsc.ieee.org/2002/09/lom-metametadata#" 
xmlns:lom-tech="http://ltsc.ieee.org/2002/09/lom-technical#" 
xmlns:lom-edu="http://ltsc.ieee.org/2002/09/lom-educational#" 
xmlns:lom-cls="http://ltsc.ieee.org/2002/09/lom-classification#" 
xmlns:myVoc="http://www.myVocbulary.com/someVocab#"> 
- <rdf:Description> 
  rdf:about=http://en.wikipedia.org/wiki/Law_of_Refraction/>  
- <dc:format> 
- <dcterms:IMT> 
  <rdf:value>html</rdf:value>  
  </dcterms:IMT> 
  </dc:format> 
- <dc:date> 
  <rdf:value>Thu Jun 15 10:02:30 GMT+05:30 2006</rdf:value>  
  </dc:date> 
- <dcterms:extent> 
- <lom-tech:ByteSize> 
  <rdf:value>23436</rdf:value>  
  </lom-tech:ByteSize> 
  </dcterms:extent> 
  <lom-tech:location 
rdf:resource="http://en.wikipedia.org/wiki/Law_of_Refraction" />  
  <dc:subject>refraction</dc:subject>  
  <rdf:type rdf:resource="http://ltsc.ieee.org/2002/09/lom-
educational/narrative text" />  
  <lom-edu:context rdf:resource="myVoc;grade 10" />  
- <myVoc:keyword-list> 
- <keyword> 
  <name>vector</name>  
 - 214 -
  <frequency>2</frequency>  
  </keyword> 
- <keyword> 
  <name>refractive index</name>  
  <frequency>3</frequency>  
  </keyword> 
- <keyword> 
  <name>reflection</name>  
  <frequency>2</frequency>  
  </keyword> 
- <keyword> 
  <name>refraction</name>  
  <frequency>2</frequency>  
  </keyword> 
- <keyword> 
  <name>solution</name>  
  <frequency>2</frequency>  
  </keyword> 
- <keyword> 
  <name>optical path</name>  
  <frequency>1</frequency>  
  </keyword> 
- <keyword> 
  <name>angle</name>  
  <frequency>4</frequency>  
  </keyword> 
- <keyword> 
  <name>energy</name>  
  <frequency>3</frequency>  
  </keyword> 
- <keyword> 
  <name>velocity</name>  
  <frequency>1</frequency>  
  </keyword> 
- <keyword> 
  <name>time</name>  
  <frequency>1</frequency>  
  </keyword> 
- <keyword> 
  <name>area</name>  
  <frequency>2</frequency>  
  </keyword> 
- <keyword> 
  <name>total internal reflection</name>  
  <frequency>2</frequency>  
  </keyword> 
- <keyword> 
  <name>normal</name>  
  <frequency>5</frequency>  
  </keyword> 
- <keyword> 
 - 215 -
  <name>direction</name>  
  <frequency>3</frequency>  
  </keyword> 
- <keyword> 
  <name>interference</name>  
  <frequency>3</frequency>  
  </keyword> 
- <keyword> 
  <name>incident ray</name>  
  <frequency>2</frequency>  
  </keyword> 
  </myVoc:keyword-list> 
- <myVoc:concept-list> 
- <concept> 
  <name>vector</name>  
  <significance>0.5</significance>  
  <type> concept</type>  
  </concept> 
- <concept> 
  <name>refractive index</name>  
  <significance>0.5</significance>  
  <type>used concept</type>  
  </concept> 
- <concept> 
  <name>reflection</name>  
  <significance>0.4</significance>  
  <type>used concept</type>  
  </concept> 
- <concept> 
  <name>refraction</name>  
  <significance>0.4</significance>  
  <type>defined concept</type>  
  </concept> 
- <concept> 
  <name>solution</name>  
  <significance>0.0</significance>  
  <type>used concept</type>  
  </concept> 
- <concept> 
  <name>optical path</name>  
  <significance>0.0</significance>  
  <type>concept</type>  
  </concept> 
- <concept> 
  <name>angle</name>  
  <significance>0.7</significance>  
  <type>used concept</type>  
  </concept> 
- <concept> 
  <name>energy</name>  
  <significance>0.4</significance>  
 - 216 -
  <type>used concept</type>  
  </concept> 
- <concept> 
  <name>velocity</name>  
  <significance>0.4</significance>  
  <type>concept</type>  
  </concept> 
- <concept> 
  <name>time</name>  
  <significance>0.2</significance>  
  <type> concept</type>  
  </concept> 
- <concept> 
  <name>area</name>  
  <significance>0.4</significance>  
  <type>used concept</type>  
  </concept> 
- <concept> 
  <name>total internal reflection</name>  
  <significance>0.4</significance>  
  <type>defined concept</type>  
  </concept> 
- <concept> 
  <name>normal</name>  
  <significance>0.0</significance>  
  <type>used concept</type>  
  </concept> 
- <concept> 
  <name>direction</name>  
  <significance>0.7</significance>  
  <type>concept</type>  
  </concept> 
- <concept> 
  <name>interference</name>  
  <significance>0.0</significance>  
  <type>used concept</type>  
  </concept> 
- <concept> 
  <name>incident ray</name>  
  <significance>0.0</significance>  
  <type>used concept</type>  
  </concept> 
  </myVoc:concept-list> 
  <myVoc:identifier>34</myVoc:identifier>  
  <myVoc:outcome>[refraction, critical angle]</myVoc:outcome>  
  <myVoc:Prerequisite>[angle, incident ray, light, normal, 
reflection, refractive index, solution]</myVoc:Prerequisite>  
  <myVoc:location-metadata rdf:resource="D:\expt\expt_repo\http -
-en_wikipedia_org-wiki-Law_of_Refraction.rdf" />  
  </rdf:Description> 
  </rdf:RDF> 
List of Publications 
 
Journal Papers 
1. Devshri Roy, Sudeshna Sarkar, Sujoy Ghose. “Learning Material Annotation for 
Flexible Tutoring System” accepted for publication in the Journal of Intelligent 
Systems. 
 
2. Devshri Roy, Sudeshna Sarkar, Sujoy Ghose. “Automatic Extraction of 
Pedagogic Metadata form Learning Content” is being revised after receiving 
review reports from the International Journal of Artificial Intelligence in 
Education.  
 
Conference Papers 
1. Devshri Roy, Sudeshna Sarkar, Sujoy Ghose (2005). Document Type 
Identification for use with Intelligent Tutoring System. International conference on 
open and distance learning education (ICDE) 2005, New Delhi, November 19-23. 
 
2. Devshri Roy, Sudeshna Sarkar, Sujoy Ghose (2005). A Personalized Query 
Module for Online Learning”. International conference on cognitive systems 
(ICCS), New Delhi, December 14-15.  
 
3. Devshri Roy, Sudeshna Sarkar, Sujoy Ghose (2005). Automatic Annotation of 
Documents with Metadata for use with Tutoring Systems. Indian international 
conference on artificial intelligence (IICAI), Pune, December 20-22, pp. 3576-
3592. 
 
4. Devshri Roy, Sudeshna Sarkar, Sujoy Ghose (2004). Concept Based Query 
Search in a Personalized Tutoring System. International conference on controls, 
automation & communication systems, ICCACS-2004, Bhubaneswar, December 
22-24, pp. 202-208. 
 
5. Samiran Srakar, Plaban Bhowmik, Devshri Roy, Sudeshna Sarkar, Anupam 
Basu, Sujoy Ghose (2004). A System for Personalized Information Retrieval Based 
on Domain Knowledge. National conference on recent trends in computational 
mathematics, NCRTCM 2004, Gandhigram, Narosa Publisher, March 18 –19. 
 
6. Devshri Roy, Sudeshna Sarkar, Sujoy Ghose (2002). Automatic Query 
Refinement for Online Learning. International Conference on Online Learning, 
Vidyakash 2002, National Centre for Software Technology, December 20-22, Navi 
Mumbai, pp. 137-145. 
