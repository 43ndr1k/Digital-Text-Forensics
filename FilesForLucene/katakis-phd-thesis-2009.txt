ΑΡΙΣΤΟΤΕΛΕΙΟ ΠΑΝΕΠΙΣΤΗΜΙΟ ΘΕΣΣΑΛΟΝΙΚΗΣ
Τµήµα Πληροφορικής
Μέθοδοι Μηχανικής Μάθησης για
Αυτόµατη Ταξινόµηση Κειµένων
∆Ι∆ΑΚΤΟΡΙΚΗ ∆ΙΑΤΡΙΒΗ
Ιωάννης Κατάκης
ΘΕΣΣΑΛΟΝΙΚΗ 2009
Ιωάννης Γ. Κατάκης
Μέθοδοι Μηχανικής Μάθησης για
Αυτόµατη Ταξινόµηση Κειµένων
Υποβλήθηκε στο Τµήµα Πληροφορικής
του Αριστοτελείου Πανεπιστηµίου Θεσσαλονίκης
Ηµεροµηνία προφορικής εξέτασης : 26/06/2009
Συµβουλευτική Επιτροπή:
Ιωάννης Βλαχάβας - Καθηγητής (επιβλέπων)
Νικόλαος Βασιλειάδης - Επίκουρος Καθηγητής
Ιωάννης Μανωλόπουλος - Καθηγητής
Εξεταστική Επιτροπή:
Νικόλαος Βασιλειάδης - Επίκουρος Καθηγητής
Ιωάννης Βλαχάβας - Καθηγητής
Θεόδωρος Καλαµπούκης - Καθηγητής
Ιωάννης Μανωλόπουλος - Καθηγητής
Γεώργιος Παλιούρας - Ερευνητής Β΄
Απόστολος Παπαδόπουλος - Επίκουρος Καθηγητής
Γρηγόριος Τσουµάκας - Λέκτορας
Στη µητέρα µου Σοφία
Ευχαριστίες
Η διατριβή αυτή εκπονήθηκε στο πλαίσιο του Μέτρου 8.3 του Ε.Π. Ανταγωνιστικότητα
Γ΄ Κοινοτικό Πλαίσιο Στήριξης και συγχρηµατοδοτείται κατά :
− 75% της ∆ηµόσιας ∆απάνης από την Ευρωπαϊκή ΄Ενωση - Ευρωπαϊκό Κοινωνικό
Ταµείο
− 25% της ∆ηµόσιας ∆απάνης από το Ελληνικό ∆ηµόσιο - Υπουργείο Ανάπτυξης -
Γενική Γραµµατεία ΄Ερευνας και Τεχνολογίας.
Θα ήθελα να εκφράσω τις ϑερµές ειλικρινείς ευχαριστίες µου στον επιβλέποντα της
διατριβής µου, Καθηγητή κ. Ιωάννη Βλαχάβα, για την εµπιστοσύνη που µου έδειξε από
τα χρόνια των προπτυχιακών µου σπουδών και τον απεριόριστο χρόνο που αφιέρωσε
στην καθοδήγηση µου κατά τη διάρκεια εκπόνησης της διατριβής τόσο σε επιστηµονικά
ϑέµατα όσο και σε ϑέµατα χαρακτήρα και ήθους. Θα ήθελα επίσης να τον ευχαριστήσω
γιατί µου έδωσε τη δυνατότητα να συµµετάσχω σε διάφορα ερευνητικά και αναπτυξιακά
έργα, τα οποία αποτέλεσαν πηγή σηµαντικής επαγγελµατικής εµπειρίας αλλά και
πολύτιµης οικονοµικής ϐοήθειας.
Κατά την εκπόνηση της διατριβής καθοριστική ήταν η συµβολή του Λέκτορα κ.
Γρηγορίου Τσουµάκα τόσο σε επίπεδο συµβουλών και καθοδήγησης στα πρώτα ϐή-
µατα όσο και σε επίπεδο ερευνητικής συνεργασίας. Πολύτιµη επίσης ήταν η ηθική
συµπαράσταση και η ενθάρρυνσή του όλα αυτά τα χρόνια.
Θα ήθελα επίσης ϑερµά να ευχαριστήσω:
− τον Επίκουρο Καθηγητή κ. Νικόλαο Βασιλειάδη, για την ερευνητική του συνερ-
γασία, την καθοδήγηση και υποστήριξή του καθ΄ όλη τη διάρκεια εκπόνησης της
διατριβής.
− τον Καθηγητή κ. Ιωάννη Μανωλόπουλο, για τη συµµετοχή του στην τριµελή
συµβουλευτική επιτροπή και άψογη συνεργασία.
− τον ∆ρ. Γεώργιο Παλιούρα για τα εύστοχα σχόλια και τις σηµαντικές διορθώσεις
του στο κείµενο της διατριβής.
− Τους συνοδοιπόρους µου, υποψήφιους διδάκτορες του Εργαστηρίου Γλωσσών
Προγραµµατισµού, Γιάννη Παρτάλα, Στράτο Κοντόπουλο, Γιώργο Τζανή και
Γιώργο Μεδίτσκο για τη συµπαράστασή τους και τη ϕιλία τους.
− Τα µέλη της οµάδας Λογικού Προγραµµατισµού και Ευφυών Συστηµάτων, Λέ-
κτορα κ. ∆ηµήτρη Βράκα, κ. Χρήστο Μπερµπερίδη και κ. Φώτη Κόκκορα για
την άψογη συνεργασία και τις συµβουλές τους.
Τέλος, ϑα ήθελα να εκφράσω τη ϐαθιά µου ευγνωµοσύνη στα µέλη της οικογένειάς
µου, και ειδικότερα στη µητέρα µου Σοφία, στον αδερφό µου Θοδωρή και στο ϑείο
µου Κυριάκο για την αγάπη, τη συµπαράσταση και την ανεξάντλητη υποµονή τους.
Περίληψη
Οι εφαρµογές µεθόδων µηχανικής µάθησης σε δεδοµένα κειµένου παρουσιάζουν ι-
διαίτερο ερευνητικό και εµπορικό ενδιαφέρον εξαιτίας της µεγάλης διαθεσιµότητας
πληροφορίας σε µορφή κειµένου. Με τη χρήση της µηχανικής µάθησης είναι εφικτή
η ανάλυση µεγάλου αριθµού κειµένων και η αυτόµατη διαχείρισή τους. Σηµαντικό
ενδιαφέρον συγκεντρώνει η διεργασία της ταξινόµησης κειµένων την οποία πραγµα-
τεύεται και η παρούσα διατριβή. Συγκεκριµένα, αντιµετωπίζονται τρία σηµαντικά προ-
ϐλήµατα της ταξινόµησης κειµένων : α) η ταξινόµηση ϱοών κειµένων, ϐ) η ταξινόµηση
κειµένων πολλαπλών ετικετών και γ) η ταξινόµηση κειµένων του παγκόσµιου ιστού.
Αρχικά, η διατριβή επικεντρώνεται σε ένα πρόβληµα της ταξινόµησης ϱοών κειµέ-
νων, την εννοιολογική απόκλιση, και ειδικότερα στην εµφάνιση νέων χαρακτηριστικών
µε το πέρασµα του χρόνου. Παρουσιάζεται ένα πλαίσιο µάθησης το οποίο συνδυάζει
µία επαυξητική µέθοδο επιλογής χαρακτηριστικών µε έναν ταξινοµητή που µπορεί
να λειτουργήσει σε δυναµικούς χώρους χαρακτηριστικών µε στόχο την αντιµετώπιση
αυτού του προβλήµατος. Το προτεινόµενο πλαίσιο εφαρµόζεται σε ένα προσαρµοστικό
σύστηµα ανάγνωσης ειδήσεων.
Επίσης, προτείνεται µία µέθοδος οµάδας ταξινοµητών κατά την οποία χρησιµο-
ποιείται ένα νέο µοντέλο αναπαράστασης κατάλληλο για προβλήµατα ταξινόµησης ϱο-
ών δεδοµένων που εµπεριέχουν επανεµφανιζόµενες έννοιες. Συγκεκριµένα, η ϱοή
διαχωρίζεται σε δέσµες δεδοµένων οι οποίες µετασχηµατίζονται σε διανύσµατα που
περιγράφουν τις έννοιες που εµπεριέχονται σε αυτά. Στην προκύπτουσα ϱοή των
διανυσµάτων αυτών εφαρµόζεται ένας αλγόριθµος οµαδοποίησης ϱοών µε στόχο την
οργάνωσή τους σε οµάδες όπου επικρατούν οι ίδιες ή παρόµοιες έννοιες. Απώτερος
σκοπός είναι η διατήρηση ενός ταξινοµητή για κάθε έννοια της ϱοής.
Επιπλέον, προτείνονται δύο µέθοδοι για το πρόβληµα της ταξινόµησης πολλαπλών
ετικετών µε ιδιαίτερη έµφαση σε προβλήµατα µε µεγάλο αριθµό ετικετών. Η πρώτη,
αντιµετωπίζει το πρόβληµα οργανώνοντας τις ετικέτες σε µία ιεραρχία µε κύριο πλεονέ-
κτηµα τους µικρούς χρόνους ταξινόµησης αλλά και την ποιότητα πρόβλεψης. Για την
οργάνωση των ετικετών στην ιεραρχία προτάθηκε ένας νέος αλγόριθµος ισορροπηµέ-
νης οµαδοποίησης. Στη δεύτερη µέθοδο, διασπάται τυχαία το αρχικό σύνολο ετικετών
σε υποσύνολα. Σε κάθε ένα από αυτά εφαρµόζεται ένας ξεχωριστός ταξινοµητής πολ-
λαπλών ετικετών.
Τέλος, παρουσιάζονται δύο µέθοδοι ταξινόµησης κειµένων στον παγκόσµιο ιστό.
Η πρώτη χρησιµοποιεί έναν ταξινοµητή πολλαπλών ετικετών για τη σύσταση λέξεων
επισήµανσης σε σύστηµα διαµοιρασµού ϐιβλιογραφικών αναφορών και σελιδοδεικτών
ιστού. Η δεύτερη αφορά στην αυτόµατη ταξινόµηση σηµασιολογικών υπηρεσιών ιστού.
Προτείνονται µέθοδοι για την αναπαράσταση των περιγραφών των υπηρεσιών ως δια-
νύσµατα χαρακτηριστικών στα οποία εφαρµόζονται αλγόριθµοι µηχανικής µάθησης.
Παρουσιάζονται επίσης δύο µέθοδοι συνδυασµού αυτών των αναπαραστάσεων.
Abstract
Applications of machine learning methods to text data present great commercial
and research interest due to the high availability of information in unstructured
text format. The utilization of machine learning enables the analysis and automated
management of large amounts of text. The contribution of this thesis regards three
challenging text classification problems: a) text stream classification, b) multilabel
text classification and c) text classification in the world wide web.
Concerning text stream classification, the problem of the appearance of new
predictive features (words) over time is discussed. A computationally efficient ap-
proach is presented that combines an incremental feature selection method with
a learning algorithm that can operate in a dynamic feature space. The proposed
method is incorporated into a personalized news reader. Additionally, the problem
of recurring contexts is confronted by exploiting stream clustering in order to dyna-
mically build and update an ensemble of incremental classifiers. To achieve this,
a transformation function that maps batches of examples into a new conceptual
representation model is proposed. The clustering algorithm is then applied in order
to group batches of examples into concepts and identify recurring contexts. The en-
semble is produced by creating and maintaining an incremental classifier for every
concept discovered in the data stream.
Furthermore, two methods are proposed for multilabel text classification that
focus on the problem of large number of labels. The first one constructs a hierarchy
of multilabel classifiers, each one dealing with a much smaller set of labels and a
more balanced example distribution. The second one proposes breaking the initial
set of labels into a number of small random subsets, and employing a multilabel
classifier for each one. The set of labels can be either disjoint or overlapping, de-
pending on which of two strategies is used to construct them. Empirical evidence
indicates that both approaches manage to improve substantially over the base mul-
tilabel classifier, especially in domains with large numbers of labels. Additionally
the overlapping approach outperforms the disjoint one and exhibits competitive
performance against other high-performing multi-label learning methods.
Finally, two applications of text classification for the world wide web were stu-
died. In the first one a multilabel classification algorithm is utilized in order to build
an automated tag recommender for web bookmarks and bibliographic references.
The second one tackles the problem of automated classification of semantic web
services according to their application domain. The method represents each web
service as a feature vector based on the text and the semantic annotations of the
web service description. A number of different representations is proposed. The
classification is achieved by applying machine learning algorithms to these repre-
sentations. An increase in predictive accuracy is obtained by exploiting classifier
combination.
Περιεχόµενα
1 Εισαγωγή 13
1.1 Μηχανική Μάθηση . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13
1.2 Εξόρυξη Κειµένων . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15
1.3 Ταξινόµηση Κειµένων . . . . . . . . . . . . . . . . . . . . . . . . . . . 17
1.3.1 Ταξινόµηση Ροών Κειµένων . . . . . . . . . . . . . . . . . . . . . 17
1.3.2 Ταξινόµηση Κειµένων Πολλαπλών Ετικετών . . . . . . . . . . . . 18
1.3.3 Ταξινόµηση Κειµένων Παγκόσµιου Ιστού . . . . . . . . . . . . . . 19
1.4 Συνεισφορά και ∆οµή της ∆ιατριβής . . . . . . . . . . . . . . . . . . . . 19
2 Μηχανική Μάθηση και Ταξινόµηση Κειµένων 23
2.1 Εισαγωγή . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23
2.2 Η Ταξινόµηση Κειµένων ως Ερευνητική Περιοχή . . . . . . . . . . . . . 24
2.3 Ορισµός Προβλήµατος . . . . . . . . . . . . . . . . . . . . . . . . . . . 25
2.4 Η Προσέγγιση της Μηχανικής Μάθησης . . . . . . . . . . . . . . . . . . 26
2.5 Σύνολο εκπαίδευσης , επικύρωσης και αξιολόγησης . . . . . . . . . . . 27
2.6 ∆εικτοδότηση Κειµένων . . . . . . . . . . . . . . . . . . . . . . . . . . . 28
2.7 Μείωση ∆ιαστάσεων . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30
2.7.1 Επιλογή Χαρακτηριστικών . . . . . . . . . . . . . . . . . . . . . 31
2.7.2 Εξαγωγή Χαρακτηριστικών . . . . . . . . . . . . . . . . . . . . . 32
2.8 Ταξινοµητές Κειµένων . . . . . . . . . . . . . . . . . . . . . . . . . . . 33
2.8.1 Πιθανοτικοί Ταξινοµητές . . . . . . . . . . . . . . . . . . . . . . 33
2.8.2 ∆ένδρα απόφασης . . . . . . . . . . . . . . . . . . . . . . . . . . 34
2.8.3 Ταξινοµητές Κανόνων . . . . . . . . . . . . . . . . . . . . . . . . 35
2.8.4 Νευρωνικά ∆ίκτυα . . . . . . . . . . . . . . . . . . . . . . . . . . 36
2.8.5 Ταξινοµητές ϐάσει περιπτώσεων . . . . . . . . . . . . . . . . . . 37
2.8.6 Μηχανές ∆ιανυσµάτων Υποστήριξης . . . . . . . . . . . . . . . . 37
2.8.7 Οµάδες Ταξινοµητών . . . . . . . . . . . . . . . . . . . . . . . . 38
2.9 Αξιολόγηση µεθόδων ταξινόµησης κειµένων . . . . . . . . . . . . . . . . 38
2.10Ταξινόµηση Ροών Κειµένων . . . . . . . . . . . . . . . . . . . . . . . . 39
2.10.1Επιλογή Παραδειγµάτων . . . . . . . . . . . . . . . . . . . . . . 41
2.10.2Παραδείγµατα µε Βάρη . . . . . . . . . . . . . . . . . . . . . . . 42
2.10.3Μέθοδοι οµάδων ταξινοµητών . . . . . . . . . . . . . . . . . . . . 42
2.10.4Προσαρµοστικοί Αλγόριθµοι . . . . . . . . . . . . . . . . . . . . 43
2.11Ταξινόµηση Κειµένων Πολλαπλών Ετικετών . . . . . . . . . . . . . . . . 43
2.11.1Μέθοδοι Μετασχηµατισµού Προβλήµατος . . . . . . . . . . . . . 44
2.11.2Μέθοδοι Προσαρµογής Αλγορίθµων . . . . . . . . . . . . . . . . 45
2.11.3Ιεραρχική ταξινόµηση πολλαπλών ετικετών . . . . . . . . . . . . 47
2.11.4Αξιολόγηση ταξινόµησης πολλαπλών ετικετών . . . . . . . . . . . 48
2.12Σύνοψη . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 50
9
ΠΕΡΙΕΧΟΜΕΝΑ
3 ∆υναµικοί Χώροι και Επαυξητική Επιλογή Χαρακτηριστικών 51
3.1 Εισαγωγή . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 51
3.2 Επαυξητική Επιλογή Χαρακτηριστικών . . . . . . . . . . . . . . . . . . 52
3.2.1 Κίνητρο . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 52
3.2.2 Προτεινόµενο Πλαίσιο Ταξινόµησης . . . . . . . . . . . . . . . . 53
3.3 Πειραµατική Αξιολόγηση . . . . . . . . . . . . . . . . . . . . . . . . . . 55
3.3.1 Επιλογή Χαρακτηριστικών και Ταξινοµητής . . . . . . . . . . . . 55
3.3.2 Σύνολα ∆εδοµένων . . . . . . . . . . . . . . . . . . . . . . . . . 56
3.3.3 Μέθοδοι . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 57
3.3.4 Μεθοδολογία και Λεπτοµέρειες Αξιολόγησης . . . . . . . . . . . . 58
3.3.5 Αποτελέσµατα . . . . . . . . . . . . . . . . . . . . . . . . . . . . 58
3.4 ΄Ενα Προσαρµοστικό Σύστηµα Ανάγνωσης Ειδήσεων . . . . . . . . . . . 61
3.4.1 Υπερφόρτωση Πληροφορίας . . . . . . . . . . . . . . . . . . . . 62
3.4.2 Σχετικά Συστήµατα . . . . . . . . . . . . . . . . . . . . . . . . . 62
3.4.3 Αρχιτεκτονική του Συστήµατος PersoNews . . . . . . . . . . . . . 66
3.4.4 Λειτουργικότητα Συστήµατος . . . . . . . . . . . . . . . . . . . . 68
3.4.5 Αξιολόγηση Συστήµατος . . . . . . . . . . . . . . . . . . . . . . 72
3.5 Συµπεράσµατα . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73
4 Ταξινόµηση Ροών Κειµένων µε Επανεµφανιζόµενες ΄Εννοιες 75
4.1 Εισαγωγή . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 75
4.2 Μοντέλο Αναπαράστασης . . . . . . . . . . . . . . . . . . . . . . . . . . 76
4.2.1 Προβλήµατα Αναπαράστασης Ροών ∆εδοµένων . . . . . . . . . . . 76
4.2.2 Εννοιολογικό Μοντέλο Αναπαράστασης . . . . . . . . . . . . . . 77
4.3 Το πλαίσιο CCP . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 80
4.4 Σύνολα ∆εδοµένων . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 84
4.4.1 Σύνολο Λίστας Ηλεκτρονικού Ταχυδροµείου . . . . . . . . . . . . 84
4.4.2 Σύνολο Spam Filtering . . . . . . . . . . . . . . . . . . . . . . . 84
4.5 Αξιολόγηση . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 85
4.5.1 Αξιολόγηση Εννοιολογικού Μοντέλου Αναπαράστασης . . . . . . 85
4.5.2 Αξιολόγηση του Προτεινόµενου Πλαισίου Ταξινόµησης . . . . . . 87
4.5.3 Παρουσίαση και Σχολιασµός Αποτελεσµάτων . . . . . . . . . . . 90
4.6 Συµπεράσµατα . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 93
5 Ταξινόµηση Κειµένων Πολλαπλών Ετικετών 95
5.1 Εισαγωγή . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 95
5.2 HOMER . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 97
5.2.1 Υπολογιστική Πολυπλοκότητα . . . . . . . . . . . . . . . . . . . 99
5.2.2 Ισορροπηµένη οµαδοποίηση k-µέσων . . . . . . . . . . . . . . . 101
5.2.3 Πειραµατική Αξιολόγηση . . . . . . . . . . . . . . . . . . . . . . 102
5.2.4 Σχολιασµός Αποτελεσµάτων . . . . . . . . . . . . . . . . . . . . . 105
5.3 Η µέθοδος RAkEL . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 110
10
ΠΕΡΙΕΧΟΜΕΝΑ
5.3.1 RAkELd . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 111
5.3.2 RAkELo . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 111
5.3.3 Σύνολα ∆εδοµένων . . . . . . . . . . . . . . . . . . . . . . . . . 114
5.3.4 Αποτελέσµατα . . . . . . . . . . . . . . . . . . . . . . . . . . . . 116
5.4 Συµπεράσµατα . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 122
6 Εφαρµογές Ταξινόµησης Κειµένων στον Παγκόσµιο Ιστό 125
6.1 Εισαγωγή . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 125
6.2 Σύστηµα Συστάσεων Επισηµάνσεων . . . . . . . . . . . . . . . . . . . . 126
6.2.1 Περιγραφή ∆ιαγωνισµού Discovery Challenge . . . . . . . . . . . 127
6.2.2 Προεπεξεργασία και Ανάλυση ∆εδοµένων . . . . . . . . . . . . . 128
6.2.3 Προτεινόµενο Σύστηµα Συστάσεων . . . . . . . . . . . . . . . . . 130
6.2.4 Αξιολόγηση . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 132
6.3 Ταξινόµηση Σηµασιολογικών Υπηρεσιών Ιστού . . . . . . . . . . . . . . 133
6.3.1 Σηµασιολογικές Υπηρεσίες Ιστού . . . . . . . . . . . . . . . . . . 134
6.3.2 Η ανάγκη για αυτόµατη ταξινόµηση υπηρεσιών ιστού . . . . . . . 135
6.3.3 Σχετικές Εργασίες . . . . . . . . . . . . . . . . . . . . . . . . . . 136
6.3.4 ∆ιανυσµατική Αναπαράσταση Περιγραφών OWL-S . . . . . . . . 137
6.3.5 Συνδυασµός Κειµένου και Σηµασιολογίας . . . . . . . . . . . . . 139
6.3.6 Αξιολόγηση . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 141
6.4 Συµπεράσµατα . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 143
7 Επίλογος 145
7.1 Συµπεράσµατα . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 145
7.2 Μελλοντική Εργασία . . . . . . . . . . . . . . . . . . . . . . . . . . . . 147
Βιβλιογραφία 149
Λίστα ∆ηµοσιεύσεων 165
Λίστα Ετεροαναφορών 167
11
1
Εισαγωγή
Η παρούσα διατριβή υπάγεται στην περιοχή της εξόρυξης κειµένων η οποία πραγ-
µατεύεται εφαρµογές µεθόδων µηχανικής µάθησης σε δεδοµένα ϕυσικής γλώσσας.
Συγκεκριµένα, αντιµετωπίζεται το πρόβληµα της αυτόµατης ταξινόµησης κειµένων και
ειδικότερα της ταξινόµησης ϱοών κειµένων, της ταξινόµησης κειµένων πολλαπλών ετι-
κετών και της ταξινόµησης κειµένων του παγκόσµιου ιστού.
1.1 Μηχανική Μάθηση
Μηχανική µάθηση (machine learning) είναι η επιστηµονική περιοχή η οποία πραγ-
µατεύεται το σχεδιασµό και την ανάπτυξη αλγορίθµων µε τη χρήση των οποίων είναι
εφικτή η υλοποίηση συστηµάτων (π.χ. υπολογιστών) µε ικανότητα µάθησης. Ο ορι-
σµός της έννοιας «µάθησης» στη συγκεκριµένη περίπτωση ίσως αποδειχτεί πρόβληµα
δυσεπίλυτο. Σε άρθρο µε τίτλο «Why should Machines Learn?» στο ϐιβλίο «Machine
Learning: An Artificial Intelligence Approach» (Michalski et al., 1983), ο H. Simon
γράφει (Simon, 1983):
«Ο µόνος, µερικώς ικανοποιητικός, ορισµός που µπόρεσα να σκεφτώ
είναι ότι µάθηση είναι οποιαδήποτε αλλαγή σε ένα σύστηµα που ϑα του
επιτρέψει να είναι αποτελεσµατικότερο την επόµενη ϕορά που ϑα επανα-
λάβει την ίδια εργασία ή κάποια άλλη παρόµοια».
΄Ενας παρόµοιος αλλά πιο αυστηρός ορισµός δίνεται αργότερα από τον Tom Mi-
tchell (Mitchell, 1997).
«΄Ενα πρόγραµµα υπολογιστή ϑεωρείται ότι µαθαίνει από την εµπειρία
E σε σχέση µε µία κατηγορία εργασιών T και µία µετρική απόδοσης P αν η
απόδοση του σε εργασίες της T , όπως µετριούνται από την P ϐελτιώνονται
µε την εµπειρία E».
Ως ερευνητική περιοχή η µηχανική µάθηση ϑεωρείται ότι υπάγεται στην Τεχνητή
Νοηµοσύνη (Artificial Intelligence) αφού η µάθηση αποτελεί αναπόσπαστη ιδιότητα
ενός ευφυούς συστήµατος. Για µία αναφορά στο πεδίο της τεχνητής νοηµοσύνης ο
13
ΚΕΦΑΛΑΙΟ 1. ΕΙΣΑΓΩΓΗ
αναγνώστης µπορεί να ανατρέξει στα (Vlahavas et al., 2006; Russell and Norvig,
2003).
Η έρευνα στη µηχανική µάθηση έχει ξεκινήσει από τη δεκαετία του 1940 όταν
προτάθηκε το πρώτο µοντέλο µάθησης µε ϐάση το νευρικό σύστηµα, γνωστό και ως
perceptron (McCulloch and Pitts, 1943). Από τότε, και ειδικότερα τα τελευταία 25
χρόνια έχει σηµειωθεί µεγάλη πρόοδος. Βιβλία αναφοράς της περιοχής αποτελούν
τα (Mitchell, 1997; Alpaydin, 2004; Hastie et al., 2001; Bishop, 2006; Duda et al.,
2000). Μία δηµοφιλής οργάνωση των µεθόδων µηχανικής µάθησης είναι η οµαδοποί-
ησή τους ϐάσει του προβλήµατος που αντιµετωπίζουν. Τα ϐασικά αυτά προβλήµατα
είναι τα παρακάτω (Tsoumakas, 2005):
1. Η προσέγγιση µιας συνάρτησης από δεδοµένα µε παρατηρήσεις τιµών εισόδου
και εξόδου της. Αν η συνάρτηση έχει ως έξοδο διακριτές τιµές, τότε το πρόβληµα
ονοµάζεται ταξινόµηση ή κατηγοριοποίηση (classification), ενώ αν έχει συνεχείς
τιµές ονοµάζεται παλινδρόµηση (regression).
2. Η εύρεση ϕυσικών οργανώσεων των δεδοµένων σε οµάδες, έτσι ώστε δεδοµένα
της ίδιας οµάδας να µοιάζουν όσο το δυνατόν περισσότερο και δεδοµένα διαφο-
ϱετικών οµάδων να διαφέρουν όσο το δυνατόν περισσότερο. Το πρόβληµα αυτό
ονοµάζεται οµαδοποίηση (clustering).
3. Η εύρεση κανόνων συσχέτισης µεταξύ αντικειµένων σε συναλλακτικές (transa-
ctional) ϐάσεις δεδοµένων. Το πρόβληµα αυτό ονοµάζεται εξόρυξη κανόνων
συσχέτισης (association rule mining) και προέκυψε τη δεκαετία του ‘90 από τον
τοµέα της ανάλυσης καλαθιών αγορών.
4. Η εύρεση της ϐέλτιστης συµπεριφοράς ενός πράκτορα µε ϐάση την ανταµοιβή
που παίρνει σε µια τελική κατάσταση σε κάποιο περιβάλλον έχοντας ξεκινήσει
από µια αρχική κατάσταση στο ίδιο περιβάλλον και ακολουθώντας µια σειρά από
ενέργειες και ενδιάµεσες καταστάσεις. Το πρόβληµα αυτό ονοµάζεται ενισχυτική
µάθηση (reinforcement learning).
Στη µηχανική µάθηση υπήρχαν παραδοσιακά οι όροι µάθηση µε επίβλεψη (supe-
rvised learning) και µάθηση χωρίς επίβλεψη (unsupervised learning). Η µάθηση µε
επίβλεψη ταυτίζεται µε την πρώτη κατηγορία προβληµάτων, δηλαδή της ταξινόµησης
και παλινδρόµησης. Το όνοµα προέρχεται από το γεγονός ότι σε αυτά τα προβλήµατα
υπάρχει κάποιος «επιβλέπων» ο οποίος µας παρέχει την τιµή εξόδου της συνάρτησης
για τα δεδοµένα που εξετάζουµε. Η µάθηση χωρίς επίβλεψη ταυτιζόταν παραδοσιακά
µε το πρόβληµα της οµαδοποίησης. Ο λόγος είναι ότι στην οµαδοποίηση δεν υπάρχει
κάποιος «επιβλέπων» αφού δε γνωρίζουµε πόσες, ποιες και αν υπάρχουν οµάδες.
Η εξόρυξη κανόνων συσχέτισης εµφανίστηκε αρκετά αργότερα από την µηχανι-
κή µάθηση, και έχει περισσότερες επιρροές από την ερευνητική περιοχή των ϐάσεων
δεδοµένων. Ωστόσο ϑα µπορούσαµε να την εντάξουµε στη µάθηση χωρίς επίβλεψη,
14
1.2. ΕΞΟΡΥΞΗ ΚΕΙΜΕΝΩΝ
αφού και πάλι δε γνωρίζουµε εκ των προτέρων αν υπάρχουν κάποιες συσχετίσεις στα
δεδοµένα και ποιες είναι αυτές.
Τέλος, η ενισχυτική µάθηση έχει επιρροές και από τα δύο είδη µάθησης, όπως
στη µάθηση µε επίβλεψη όπου υπάρχει κάποιος εξωτερικός παράγων (το περιβάλλον)
που δίνει µια αριθµητική ανταµοιβή στον πράκτορα για κάθε ενέργεια του. Ωστόσο
η συµπεριφορά του περιβάλλοντος είναι άγνωστη στον πράκτορα και πρέπει να την
ανακαλύψει µέσω δοκιµής και αποτυχίας, κάτι που παραπέµπει στη µάθηση χωρίς
επίβλεψη.
Η εξόρυξη δεδοµένων (data mining) είναι µία περιοχή που έχει σηµαντική επικά-
λυψη µε τη µηχανική µάθηση και προέρχεται από το πεδίο των ϐάσεων δεδοµένων.
Πραγµατεύεται παρόµοιες µεθόδους αλλά ϐασικός άξονας είναι οι εφαρµογές σε µεγά-
λες ϐάσεις δεδοµένων. Γενικότερα η εξόρυξη δεδοµένων ϑεωρείται το κεντρικό στοιχείο
της διαδικασίας Ανακάλυψης Γνώσης από Βάσεις ∆εδοµένων (Knowledge discovery
from Databases - KDD).
Οι µέθοδοι της µηχανικής µάθησης έχουν ϐρει εφαρµογές σε διάφορες περιοχές
όπως η µηχανική όραση, η επεξεργασία ϕυσικής γλώσσας, οι µηχανές αναζήτησης
παγκόσµιου ιστού, η ιατρική διάγνωση, η οικονοµική ανάλυση, η ταξινόµηση αλ-
ληλουχιών DNA, η αναγνώριση ϕωνής και η αναγνώριση οπτικών χαρακτήρων, η α-
νάπτυξη ευφυών συστηµάτων συµµετοχής σε παιχνίδια, η ανάπτυξη λογισµικού, η
αναγνώριση αστρονοµικών αντικειµένων, η ϱοµποτική, κτλ.
Μία ενδιαφέρουσα περιοχή εφαρµογής µεθόδων µηχανικής µάθησης, στην οποία
κατατάσσεται και η παρούσα διατριβή, αποτελεί η Εξόρυξη Κειµένων (Text Mining).
1.2 Εξόρυξη Κειµένων
Στόχος της εξόρυξης κειµένων1, αποτελεί η ανακάλυψη χρήσιµης γνώσης από δε-
δοµένα ϕυσικής γλώσσας αλλά και η ανάπτυξη συστηµάτων αυτόµατης διαχείρισης
κειµένων. Η περιοχή αυτή, γνώρισε ιδιαίτερη άνθιση µε την έκρηξη του παγκόσµιου
ιστού λόγω της µεγάλης διαθεσιµότητας κειµένων σε ψηφιακή µορφή. Το γεγονός
αυτό προσέδωσε µεγάλο εµπορικό ενδιαφέρον στην εξόρυξη κειµένων.
Τα δεδοµένα κειµένου, παρουσιάζουν κάποιες ιδιαίτερες προκλήσεις. Καταρχήν,
τα κείµενα στην πρωτογενή τους µορφή, δεν είναι απευθείας επεξεργάσιµα από τους
αλγόριθµους µηχανικής µάθησης. Συνεπώς απαιτείται ένα στάδιο µετασχηµατισµού
των κειµένων σε µία κατάλληλη µορφή. ΄Ενα άλλο σηµαντικό πρόβληµα αποτελεί ο µε-
γάλος αριθµός διαστάσεων αφού συνήθως κάθε διακριτή λέξη της συλλογής κειµένων
αποτελεί και χαρακτηριστικό. Μάλιστα, τα δεδοµένα κειµένων - µετά τη δεικτοδότηση
- είναι ιδιαίτερα αραιά (sparse) αφού κάθε κείµενο περιέχει λέξεις που αποτελούν ένα
µικρό υποσύνολο σε σχέση µε το µέγεθος του λεξικού. Πρόβληµα επίσης µπορεί να
αποτελέσει το γεγονός ότι το ίδιο χαρακτηριστικό (λέξη) µπορεί να έχει πολλές έννοιες
(π.χ. πολύσηµες λέξεις) ή δύο χαρακτηριστικά να έχουν κοινή σηµασιολογία (π.χ.
1Γνωστή και ως Ανακάλυψη Γνώσης από Κείµενα (Knowledge Discovery from Text)
15
ΚΕΦΑΛΑΙΟ 1. ΕΙΣΑΓΩΓΗ
συνώνυµες λέξεις). ∆υσκολίες µπορεί να εντοπιστούν και στη διαχείριση των πολυ-
γλωσσικών δεδοµένων. Τέλος, ειδικοί τύποι κειµένων µπορεί να εµπεριέχουν επιπλέον
ιδιαιτερότητες. Για παράδειγµα στα δεδοµένα ηλεκτρονικού ταχυδροµείου το κείµενο
είναι ανεπίσηµο και έτσι υπάρχουν συντοµογραφίες και πρόχειρος τρόπος γραφής,
ϑόρυβος αλλά και µικρή ποσότητα κειµένου.
Σε αντιστοιχία µε την ανακάλυψη γνώσης από ϐάσεις δεδοµένων, τα στάδια της
ανακάλυψης γνώσης από κείµενα είναι τα ακόλουθα (Σχήµα 1.1):
− Συλλογή. Τα κείµενα µπορεί να χρειαστεί να συλλεχθούν από τον παγκόσµιο
ιστό µέσω ενός περιηγητή (crawler) ή να ψηφιοποιηθούν.
− Προεπεξεργασία. Επιλέγονται τα κείµενα ή τα τµήµατα των κειµένων που ϑα
αποτέλεσουν τη συλλογή και αφαιρούνται τα περιττά στοιχεία.
− ∆εικτοδότηση. Το στάδιο µετατροπής των κειµένων σε µορφή επεξεργάσιµη α-
πό τους αλγορίθµους µηχανικής µάθησης. Συνήθως πρόκειται για διανύσµατα
χαρακτηριστικών που αντιστοιχούν σε λέξεις.
− Μείωση διαστάσεων. Αποτελεί απαραίτητο στάδιο αφού ο αρχικός χώρος διαστά-
σεων είναι ιδιαίτερα µεγάλος.
− Εξόρυξη. Το στάδιο εφαρµογής αλγορίθµων µηχανικής µάθησης. Αποτέλεσµα
του σταδίου αυτού είναι είτε α) µία περιγραφή των δεδοµένων που ενδεχοµένως
να οδηγήσει σε χρήσιµα συµπεράσµατα είτε ϐ) ένα µοντέλο που ϑα µπορεί να
αξιοποιηθεί για την αυτόµατη διαχείριση κειµένων.
− Αξιολόγηση και Αξιοποίηση. Το στάδιο κατά το οποίο αξιολογείται το µοντέλο και
γίνεται προσπάθεια αξιοποίησης των αποτελεσµάτων της εξόρυξης.
Παρακάτω, αναφέρονται οι ϐασικότερες διεργασίες εξόρυξης κειµένων :
− Ταξινόµηση Κειµένων. Αφορά την ανάθεση µίας κατηγορίας (τάξης) σε ένα κεί-
µενο. Γνωστές εφαρµογές αποτελούν η διήθηση ανεπιθύµητης αλληλογραφίας,
η ταξινόµηση ιστοσελίδων και η αναγνώριση συγγραφέα.
− Ανάκτηση Κειµένων. Είναι το πρόβληµα στο οποίο δεδοµένων κάποιων λέξεων
κλειδιών ή ενός κειµένου Ϲητούµενο είναι η ανάκτηση σχετικών κειµένων.
− Οµαδοποίηση Κειµένων. Αφορά στην αυτόµατη οργάνωση κειµένων σε οµάδες
που ϑα έχουν κάποια κοινά χαρακτηριστικά. Γνωστές εφαρµογές αποτελούν η
ιεραρχική οργάνωση ιστοσελίδων και η οµαδοποίηση ειδησεογραφικών άρθρων.
− Εξαγωγή Πληροφορίας. Αναφέρεται στην προσπάθεια εξαγωγής συγκεκριµένης
πληροφορίας από µεγάλο αριθµό κειµένων. ΄Ενα παράδειγµα εφαρµογής είναι
η αυτόµατη εξαγωγή πληροφοριών όπως η περιοχή, το εµβαδόν και η τιµή από
αγγελίες πώλησης ακινήτων.
16
1.3. ΤΑΞΙΝΟΜΗΣΗ ΚΕΙΜΕΝΩΝ
 , 	
 	 


, 	
	 
(
		 
)  	
  	  	, 
 
,	
!, 


Σχήµα 1.1: Τα στάδια της ανακάλυψης γνώσης από κείµενα
− Περίληψη κειµένου. Είναι η παραγωγή ενός µικρού αντιπροσωπευτικού κειµέ-
νου δεδοµένου, ενός µεγαλύτερου κειµένου ή µίας συλλογής κειµένων.
Κύριο ϑέµα αυτής της διατριβής αποτελεί η ταξινόµηση κειµένου µε χρήση τεχνι-
κών µηχανικής µάθησης.
1.3 Ταξινόµηση Κειµένων
Η παρούσα διατριβή αντιµετωπίζει προβλήµατα τριών υπο-πεδίων της ταξινόµησης
κειµένων : α) ταξινόµηση ϱοών κειµένων, ϐ) ταξινόµηση κειµένων πολλαπλών ετικετών
και γ) ταξινόµηση κειµένων στον παγκόσµιο ιστό.
1.3.1 Ταξινόµηση Ροών Κειµένων
Το διαδίκτυο αποτελεί ένα ιδιαίτερα δυναµικό περιβάλλον και περιλαµβάνει µία πλη-
ϑώρα πηγών ϱοών κειµένων. Χαρακτηριστικά παραδείγµατα αποτελούν οι ιστοσελίδες,
17
ΚΕΦΑΛΑΙΟ 1. ΕΙΣΑΓΩΓΗ
οι ϱοές ειδήσεων, το ηλεκτρονικό ταχυδροµείο, οι οµάδες συζητήσεων, οι υπηρεσίες
άµεσων µηνυµάτων και τα διαδικτυακά ηµερολόγια (blogs). Τελευταία, έχουν πα-
ϱουσιαστεί πολλές ενδιαφέρουσες εφαρµογές που αφορούν στην αυτόµατη ταξινόµηση
τέτοιων ϱοών κειµένων. Η πιο διαδεδοµένη ίσως από αυτές είναι η διήθηση ανεπιθύ-
µητων µηνυµάτων ηλεκτρονικού ταχυδροµείου (spam filtering)(Katakis et al., 2006).
΄Αλλες γνωστές εφαρµογές είναι η δηµιουργία εξατοµικευµένων ϱοών ειδήσεων και η
διήθηση σελίδων πορνογραφικού περιεχοµένου για την ασφαλέστερη περιήγηση παι-
διών στο διαδίκτυο.
Οι εφαρµογές αυτές παρουσιάζουν ιδιαίτερο ενδιαφέρον για τους επιστήµονες της
µηχανικής µάθησης αφού εµπεριέχουν ένα σηµαντικό αριθµό δυσκολιών. ΄Ενα ϐα-
σικό πρόβληµα αποτελεί η εννοιολογική απόκλιση (concept drift) (Tsymbal, 2004), η
αλλαγή δηλαδή της έννοιας µίας ή περισσότερων τάξεων σε σχέση µε το χρόνο.
Μία επιπλέον ιδιαιτερότητα της ταξινόµησης ϱοών είναι η δυναµική ϕύση του
συνόλου των χαρακτηριστικών. Σε µία πραγµατική εφαρµογή ϱοών, υπάρχει πάν-
τα η πιθανότητα να εισαχθεί στο σύστηµα ένα κείµενο που ϑα περιέχει νέες λέξεις-
χαρακτηριστικά. Οι λέξεις αυτές, δεν έχουν ενσωµατωθεί στο µοντέλο µάθησης και
κατά συνέπεια δε µπορούν ληφθούν υπόψη κατά τη διαδικασία της πρόβλεψης. Τα
χαρακτηριστικά αυτά όµως µπορεί να περιέχουν σηµαντική πληροφορία για την τάξη
στόχο.
Τέλος, ένας ιδιαίτερος τύπος εννοιολογικής απόκλισης είναι αυτός των επανεµφα-
νιζόµενων εννοιών (recurring contexts) (Widmer and Kubat, 1996) και αφορά στην
εµφάνιση εννοιών που έχουν παρουσιαστεί ξανά στο ιστορικό µίας ϱοής. Παρόλο που
το ϕαινόµενο αυτό είναι αρκετά συχνό σε πραγµατικά δεδοµένα (µετεωρολογικά ϕαι-
νόµενα, συνήθειες αγοραστών, κτλ), δεν είναι παρά ελάχιστες οι µέθοδοι ταξινόµησης
που το αντιµετωπίζουν (Widmer and Kubat, 1996; Harries et al., 1998; Forman,
2006) κυρίως λόγω της έλλειψης σχετικών δεδοµένων.
Στην παρούσα διατριβή προτείνονται µέθοδοι αντιµετώπισης των παραπάνω προ-
ϐληµάτων (Katakis et al., 2009b,c).
1.3.2 Ταξινόµηση Κειµένων Πολλαπλών Ετικετών
Σε πολλές εφαρµογές, τα κείµενα σχετίζονται µε ένα σύνολο (set) από τάξεις (ετικέ-
τες). Για παράδειγµα, ένα άρθρο που αναφέρεται στις αντιδράσεις της Εκκλησίας
για την ταινία ¨Κώδικας ντα Βίντσι¨ µπορεί να ταξινοµηθεί ταυτόχρονα σε δύο τά-
ξεις : society\religion και arts\movies2. Το πρόβληµα αυτό αναφέρεται ως ταξινόµηση
πολλαπλών ετικετών (multi-label classification).
΄Ενα σηµαντικό πρόβληµα στην ταξινόµηση πολλαπλών ετικετών είναι ο µεγάλος
αριθµός ετικετών που µπορεί να εµφανιστεί σε διάφορα πεδία εφαρµογής. Στην ταξινό-
µηση κειµένων για παράδειγµα συνήθως υπάρχει ένας µεγάλος αριθµός από ϑεµατικές
κατηγορίες (Lewis et al., 2004). Επίσης, στην αυτόµατη πρόταση λέξεων επισήµανσης
2Οι κατηγορίες έχουν επιλεχθεί από το Open Directory Project (ODP) - http://www.dmoz.org/
18
1.4. ΣΥΝΕΙΣΦΟΡΑ ΚΑΙ ∆ΟΜΗ ΤΗΣ ∆ΙΑΤΡΙΒΗΣ
(automated tag suggestion) ο αριθµός των λέξεων επισήµανσης (tags) που έχουν ανα-
ϑέσει οι χρήστες στα αντικείµενα (π.χ. ιστοσελίδες στην περίπτωση συστηµάτων όπως
το del.icio.us ή το bibsonomy) µπορεί να είναι χιλιάδες. Πρόσφατα έχει παρουσια-
στεί µία συλλογή νοµικών κειµένων τα οποία είναι επισηµειωµένα µε κάποιες από τις
συνολικά 4,000 κατηγορίες (Mencia and Furnkranz, 2008).
Ο µεγάλος αριθµός ετικετών µπορεί να επηρεάσει αρνητικά τους ταξινοµητές πολ-
λαπλών ετικετών στην ποιότητα πρόβλεψης, στο χρόνο εκπαίδευσης αλλά και στο χρόνο
ταξινόµησης. Στην παρούσα διατριβή παρουσιάζονται µέθοδοι που στοχεύουν στην αν-
τιµετώπιση του προβλήµατος του µεγάλου αριθµού ετικετών (Tsoumakas, Katakis and
Vlahavas, 2008; 2009b).
1.3.3 Ταξινόµηση Κειµένων Παγκόσµιου Ιστού
Βασικό στοιχείο οργάνωσης περιεχοµένου στο σύγχρονο παγκόσµιο ιστό και κυρίως
στα κοινωνικά συστήµατα δικτύωσης είναι ο ελεύθερος χαρακτηρισµός των αντικει-
µένων από τους χρήστες µε λέξεις επισήµανσης (tags). Η ελευθερία και η απλότητα
αυτής της προσέγγισης µπορεί να οδηγήσει σε προβληµατική ανάκτηση περιεχοµένου.
Στην παρούσα διατριβή παρουσιάζεται ένα σύστηµα το οποίο υπο-ϐοηθάει το χρήστη
στην ανάθεση των λέξεων επισήµανσης έτσι ώστε να αντιµετωπιστούν τα προβλήµατα
αυτά (Katakis et al., 2008).
Το µέλλον του παγκόσµιου ιστού αναφέρεται ως Web 3.0, ϐασικό στοιχείο του οποί-
ου ϑα είναι ο σηµασιολογικός (semantic) ορισµός της πληροφορίας και των υπηρεσιών,
έτσι ώστε να είναι κατανοητές από τις µηχανές και να εξυπηρετούνται τα αιτήµατα του
χρήστη χωρίς τη δική του συµµετοχή. Το όραµα αυτό αναφέρεται ως Σηµασιολογικός
Ιστός (Semantic Web) ϐασικό στοιχείο του οποίου αποτελούν οι σηµασιολογικές υπη-
ϱεσίες ιστού (Semantic Web Services). Ο µεγάλος αριθµός όµως των διαδικτυακών
υπηρεσιών ϑέτει την ανάγκη της αυτόµατης ταξινόµησής τους. Στην παρούσα διατρι-
ϐή προτείνεται µία µέθοδος αυτόµατης ταξινόµησης σηµασιολογικών υπηρεσιών µέσω
ταξινόµησης κειµένου (Katakis et al., 2009a). Η αυτόµατη ταξινόµηση των υπηρεσιών
µπορεί να διευκολύνει άλλες κρίσιµες διαδικασίες που σχετίζονται µε αυτές όπως είναι
η ανακάλυψη (discovery), η σύνθεση (composition) και η διαχείριση (management)
υπηρεσιών.
1.4 Συνεισφορά και ∆οµή της ∆ιατριβής
Η παρούσα διατριβή πραγµατεύεται τρία σηµαντικά προβλήµατα ταξινόµησης κει-
µένων : α) την ταξινόµηση ϱοών κειµένων, ϐ) την ταξινόµηση κειµένων πολλαπλών
ετικέτων και γ) την ταξινόµηση κειµένων του παγκόσµιου ιστού.
Πιο συγκεκριµένα, στο επόµενο κεφάλαιο παρουσιάζεται µία ανασκόπηση του πε-
δίου της ταξινόµησης κειµένων µε µεθόδους µηχανικής µάθησης. Παρουσιάζονται
ϑέµατα που αφορούν στη δεικτοδότηση κειµένων και στη µείωση διαστάσεων. Επίσης,
19
ΚΕΦΑΛΑΙΟ 1. ΕΙΣΑΓΩΓΗ
αναφέρονται µέθοδοι ταξινόµησης κειµένων και µετρικές αξιολόγησης. Τέλος, παρου-
σιάζονται τα ειδικότερα προβλήµατα που αντιµετωπίζει αυτή η διατριβή που είναι η
ταξινόµηση ϱοών κειµένων και η ταξινόµηση κειµένων πολλαπλών ετικετών.
Στο τρίτο κεφάλαιο αντιµετωπίζεται το πρόβληµα της εµφάνισης νέων χαρακτηρι-
στικών στην ταξινόµηση ϱοών κειµένων (Katakis et al., 2009b). Για την αντιµετώπιση
αυτού του προβλήµατος προτείνεται η χρήση µίας ειδικής κατηγορίας ταξινοµητών
που είναι σε ϑέση να εκπαιδεύεται και να παράγει προβλέψεις σε έναν τέτοιο δυναµικό
χώρο χαρακτηριστικών (dynamic feature space). Επιπλέον, µελετάται η καταλληλότη-
τα της επαυξητικής επιλογής χαρακτηριστικών (Incremental Feature Selection - IFS)
για την αντιµετώπιση της εννοιολογικής απόκλισης σε προβλήµατα δυναµικού χώρου
χαρακτηριστικών. Επίσης, δηµιουργείται και παρέχεται διαδικτυακά ένα νέο σύνολο
ϱοών δεδοµένων µε εννοιολογική απόκλιση που ελπίζουµε ότι ϑα ϐοηθήσει άλλους
ερευνητές να αξιολογήσουν αντίστοιχες µεθόδους ταξινόµησης.
Συνολικά, προτείνεται ένα υπολογιστικά µη-απαιτητικό πλαίσιο ταξινόµησης ϱοών
κειµένων. Το προτεινόµενο πλαίσιο, περιλαµβάνει : α) έναν επαυξητικό ταξινοµητή ο
οποίος µπορεί να λειτουργήσει σε δυναµικό χώρο χαρακτηριστικών και ϐ) µία µέθοδο
επαυξητικής επιλογής χαρακτηριστικών. Λόγω της απλότητας και αποτελεσµατικότη-
τας αυτού του πλαισίου, ϑεωρούµε ότι ϑα µπορούσε να διατελέσει µέθοδος ϐάσης στην
περιοχή.
Τέλος, το προτεινόµενο πλαίσιο χρησιµοποιείται ως ϐασικό στοιχείο για την ανά-
πτυξη ενός προσαρµοστικού διαδικτυακού συστήµατος ανάγνωσης ειδήσεων. Τα κύρια
χαρακτηριστικά του είναι η εύκολη διαχείριση πολλαπλών πηγών ειδήσεων, η απόκρυ-
ψη των αδιάφορων άρθρων από το χρήστη και η δυνατότητα να παρακολουθήσει γενικά
ϑέµατα ενδιαφέροντος από µία ταξινοµία ϑεµάτων.
Στο τέταρτο κεφάλαιο προτείνεται µία µέθοδος οµάδας ταξινοµητών κατά την ο-
ποία χρησιµοποιείται ένα νέο µοντέλο αναπαράστασης κατάλληλο για προβλήµατα
ταξινόµησης ϱοών δεδοµένων που εµπεριέχουν εννοιολογική απόκλιση (Katakis et al.,
2009c). Συγκεκριµένα, η ϱοή διαχωρίζεται σε δέσµες δεδοµένων, οι οποίες µετα-
σχηµατίζονται σε διανύσµατα που ονοµάζουµε εννοιολογικά (conceptual vectors). Τα
διανύσµατα αυτά περιέχουν πληροφορία που εκφράζει τις έννοιες που εµπεριέχονται
στην αντίστοιχη δέσµη δεδοµένων. Στην προκύπτουσα ϱοή εννοιολογικών διανυσµάτων
εφαρµόζεται ένας αλγόριθµος οµαδοποίησης ϱοών. Με αυτόν τον τρόπο, τα εννοιολο-
γικά διανύσµατα (και κατά συνέπεια οι δέσµες δεδοµένων) οργανώνονται σε οµάδες
όπου επικρατούν οι ίδιες ή παρόµοιες έννοιες. Απώτερος σκοπός είναι η διατήρηση
ενός ταξινοµητή για κάθε έννοια (οµάδα) της ϱοής.
Μία υλοποίηση της προτεινόµενης µεθόδου αξιολογείται σε δύο σύνολα δεδοµένων
ηλεκτρονικού ταχυδροµείου και συγκρίνεται µε πέντε µεθοδολογίες ταξινόµησης ϱοών
της ϐιβλιογραφίας. Τα αποτελέσµατα αποδεικνύουν την καταλληλότητα της προτεινό-
µενης αναπαράστασης και την αποτελεσµατικότητα των ειδικών σε έννοιες ταξινοµητών.
Στο πέµπτο κεφάλαιο προτείνονται δύο µέθοδοι ταξινόµησης που στοχεύουν στην
αντιµετώπιση του προβλήµατος του µεγάλου αριθµού ετικετών.
Η πρώτη µέθοδος, HOMER (Hierarchy Of Multilabel classifiERs) (Tsoumakas,
20
1.4. ΣΥΝΕΙΣΦΟΡΑ ΚΑΙ ∆ΟΜΗ ΤΗΣ ∆ΙΑΤΡΙΒΗΣ
Katakis and Vlahavas, 2008), δηµιουργεί µία ιεραρχία ταξινοµητών πολλαπλών ετι-
κετών, κάθε ένας από τους οποίους αντιµετωπίζει ένα µικρότερο σύνολο ετικετών και
µία περισσότερο ισορροπηµένη κατανοµή παραδειγµάτων. Το χαρακτηριστικό αυτό
οδηγεί σε : α) ϐελτίωση της ποιότητας πρόβλεψης, ϐ) γραµµική πολυπλοκότητα εκπαί-
δευσης σε σχέση µε το συνολικό αριθµό ετικετών και γ) λογαριθµική πολυπλοκότητα
ταξινόµησης σε σχέση µε το συνολικό αριθµό ετικετών. Μία από τις σηµαντικές διαδι-
κασίες του HOMER είναι η κατανοµή ετικετών σε k ξένα και ισάριθµα υποσύνολα που
χρησιµοποιείται για τη δηµιουργία της ιεραρχίας. Τα σύνολα περιέχουν όµοιες µεταξύ
τους ετικέτες. Το πρόβληµα αυτό της οµαδοποίησης ϐάσει οµοιότητας µε τον επιπλέον
περιορισµό των ισάριθµων οµάδων είναι γνωστό στη ϐιβλιογραφία ως ισορροπηµένη
οµαδοποίηση (balanced clustering) (Banerjee and Ghosh, 2006). Για την επίλυση
αυτού του προβλήµατος προτείνεται ένας νέος αλγόριθµος οµαδοποίησης, ο balanced
k-means (ισορροπηµένη οµαδοποίηση k-µέσων).
Στη δεύτερη µέθοδο (Tsoumakas, Katakis and Vlahavas, 2009b), προτείνεται η
τυχαία διάσπαση του αρχικού συνόλου ετικετών σε υποσύνολα (labelsets). Σε κάθε ένα
από αυτά εφαρµόζεται ένας ξεχωριστός ταξινοµητής (labelset classifier). Με αυτόν τον
τρόπο, τα υποπροβλήµατα πολλαπλών ετικετών που προκύπτουν είναι υπολογιστικά
απλούστερα και η κατανοµή των τάξεων είναι περισσότερο ισορροπηµένη. Η προτεινό-
µενη µέθοδος ονοµάζεται RAkEL (RAndom k labELsets), όπου k είναι η παράµετρος
που καθορίζει το µέγεθος των τυχαίων labelsets. Μελετώνται δύο µέθοδοι κατασκευής
των labelsets. Η πρώτη οδηγεί σε ξένα υποσύνολα ενώ η δεύτερη σε επικαλυπτόµενα.
Πειραµατικά αποτελέσµατα αποδεικνύουν ότι και οι δύο µέθοδοι επιτυγχάνουν την
ϐελτίωση της ποιότητας πρόβλεψης του αλγορίθµου δυναµοσυνόλου ετικετών (labelset
powerset) ειδικά σε πεδία µε µεγάλο αριθµό ετικετών. Τα επικαλυπτόµενα labelsets
παρουσιάζουν υψηλότερη απόδοση αφού ο συγκερασµός των πολλαπλών προβλέψεων
µέσα από µία διαδικασία ψηφοφορίας επιτρέπει τη διόρθωση σφαλµάτων. Παρουσιά-
Ϲεται επίσης µία συγκριτική µελέτη µε δύο άλλες µεθόδους ταξινόµησης πολλαπλών
ετικετών υψηλής ακρίβειας όπου ο RAkEL µε επικαλυπτόµενα labelsets παρουσιάζει
ιδιαίτερα ανταγωνιστική ικανότητα πρόβλεψης.
Στο έκτο κεφάλαιο παρουσιάζονται δύο εφαρµογές ταξινόµησης κειµένων στο σύγ-
χρονο παγκόσµιο ιστό. Η πρώτη (Katakis et al., 2008) αποτελεί ένα σύστηµα συστά-
σεων λέξεων επισήµανσης για ϐιβλιογραφικές αναφορές και σελιδοδείκτες ιστού. Το
προτεινόµενο σύστηµα στηρίζεται στο ιστορικό των αντικειµένων και των χρηστών αλλά
και στο κείµενο των αντικειµένων, για την αξιοποίηση του οποίου εκπαιδεύεται ένας
ταξινοµητής πολλαπλών ετικετών.
Η δεύτερη εφαρµογή (Katakis et al., 2009a) αφορά στην αυτόµατη ταξινόµηση
σηµασιολογικών υπηρεσιών ιστού. Η µέθοδος ϐασίζεται στις περιγραφές OWL-S των
υπηρεσιών. Προτείνονται τέσσερις µέθοδοι για την µετατροπή των περιγραφών OWL-
S σε διανύσµατα χαρακτηριστικών, σε κάθε µία από τις οποίες λαµβάνεται υπόψη
διαφορετική πληροφορία της περιγραφής. Στις αναπαραστάσεις αυτές εφαρµόζονται
αλγόριθµοι µηχανικής µάθησης. Κάποια ενδιαφέροντα πορίσµατα της πειραµατικής
αξιολόγησης ήταν η ωφελιµότητα της σηµασιολογικής υπογραφής και του κειµένου πε-
21
ΚΕΦΑΛΑΙΟ 1. ΕΙΣΑΓΩΓΗ
ϱιγραφής της υπηρεσίας. Σύµφωνα µε το συµπέρασµα αυτό προτείνονται δύο µέθοδοι
συνδυασµού των δύο αυτών αναπαραστάσεων. Πειραµατικά αποτελέσµατα αποδεικνύ-
ουν ότι ο συνδυασµός αυτός έχει ϑετική επίδραση στην ορθότητα πρόβλεψης.
Τέλος, η διατριβή ολοκληρώνεται µε το έβδοµο κεφάλαιο όπου συγκεντρώνονται
τα σηµαντικότερα συµπεράσµατα που προέκυψαν αλλά και πιθανές προοπτικές για
µελλοντική έρευνα.
22
2
Μηχανική Μάθηση
και Ταξινόµηση Κειµένων
Το κεφάλαιο αυτό αποτελεί µία επισκόπηση της περιοχής της αυτόµατης ταξινόµησης
κειµένων µε χρήση τεχνικών µηχανικής µάθησης. Αρχικά, παρουσιάζονται ϑέµατα
που αφορούν στη δεικτοδότηση κειµένων και στη µείωση διαστάσεων. Στη συνέχεια
αναφέρονται µέθοδοι ταξινόµησης κειµένων και µετρικές αξιολόγησης. Τέλος, πα-
ϱουσιάζονται τα ειδικότερα προβλήµατα που αντιµετωπίζει αυτή η διατριβή που είναι η
ταξινόµηση ϱοών κειµένων και η ταξινόµηση κειµένων πολλαπλών ετικετών. Τα ϑέµατα
αυτά παρουσιάζουν ιδιαίτερο ενδιαφέρον λόγω του µεγάλου αριθµού εφαρµογών.
2.1 Εισαγωγή
Τα τελευταία δεκαπέντε χρόνια παρουσιάζεται µία έντονη προσπάθεια για την αυτοµα-
τοποίηση διαδικασιών που σχετίζονται µε τη διαχείριση κειµένων (Sebastiani, 2002).
Μία τέτοια διαδικασία, που αποτελεί και το ϐασικό ϑέµα της παρούσας διατριβής, εί-
ναι η Ταξινόµηση Κειµένων (Text Classification). ΄Εχει συγκεντρώσει σε µεγάλο ϐαθµό
το ενδιαφέρον της επιστηµονικής κοινότητας και αφορά στην αυτόµατη ανάθεση µίας
κατηγορίας (τάξης) σε δεδοµένα κειµένου.
Στην αγγλική ορολογία η ταξινόµηση κειµένων είναι ευρέως γνωστή µε τον όρο
«Text Classification» αν και πολύ συχνά χρησιµοποιείται και ο όρος «Text Categoriza-
tion». Πρέπει να σηµειωθεί, ότι και στις δύο περιπτώσεις ο χαρακτηρισµός «automa-
ted» (αυτόµατη) υπονοείται. ΄Ετσι, αντί για τον -ίσως πιο ακριβή- όρο «Automated Text
Classification», συνήθως χρησιµοποιείται απλά ο όρος «Text Classification». Αντίστοι-
χα, σε αυτήν τη διατριβή ο όρος «Αυτόµατη Ταξινόµηση Κειµένων» ϑα εµφανίζεται ως
«Ταξινόµηση Κειµένων».
Πρόσφατα, το ενδιαφέρον για την ταξινόµηση κειµένων έχει αυξηθεί σηµαντικά
κυρίως λόγω της µεγάλης διαθεσιµότητας κειµένων σε ψηφιακή µορφή. Σηµαντικό
παράγοντα σε αυτό το γεγονός αποτέλεσε η ϱαγδαία ανάπτυξη του παγκόσµιου ιστού
(world wide web). Στις ενδιαφέρουσες εφαρµογές της ταξινόµησης κειµένων περιλαµ-
ϐάνονται η διήθηση ανεπιθύµητης αλληλογραφίας (spam filtering) (Androutsopoulos
et al., 2000), η ταξινόµηση ειδήσεων (Carreira et al., 2004) και ιστοσελίδων (Qi and
23
ΚΕΦΑΛΑΙΟ 2. ΜΗΧΑΝΙΚΗ ΜΑΘΗΣΗ ΚΑΙ ΤΑΞΙΝΟΜΗΣΗ ΚΕΙΜΕΝΩΝ
Davison, 2009) και η αναγνώριση συγγραφέα (author identification) (Stamatatos,
2008).
Μέχρι τη δεκαετία του ΄80 η δηµοφιλέστερη προσέγγιση για την ταξινόµηση κει-
µένων ήταν αυτή της Τεχνολογίας Γνώσης (knowledge engineering) όπου ο µηχανικός
γνώσης (knowledge engineer) κωδικοποιεί τη γνώση του ειδικού του πεδίου (domain
expert) σε κανόνες. Στη δεκαετία του ΄90 η προσέγγιση αυτή άρχισε να χάνει έδα-
ϕος και τη ϑέση της πήρε αυτή της Μηχανικής Μάθησης (machine learning) (Mitchell,
1997). Σύµφωνα µε αυτήν, εφαρµόζεται µία επαγωγική διαδικασία (inductive process)
σε ένα σύνολο ταξινοµηµένων κειµένων για την αυτόµατη δηµιουργία ενός ταξινοµητή
(classifier). ∆εδοµένου ενός κειµένου άγνωστης τάξης, ο ταξινοµητής ϑα είναι σε ϑέση
να προβλέψει την τάξη στην οποία ανήκει το κείµενο αυτό.
Το προφανές πλεονέκτηµα της προσέγγισης µηχανικής µάθησης είναι η ευκολία
δηµιουργίας του ταξινοµητή αφού δε παρεµβαίνει ο ανθρώπινος παράγοντας. ΄Αλλα
πλεονεκτήµατα αποτελούν η εύκολη επαναχρησιµοποίηση των ταξινοµητών και η ι-
κανοποιητική ακρίβεια πρόβλεψης. Η διατριβή αυτή επικεντρώνεται στην παραγωγή
µεθόδων ταξινόµησης κειµένων µε την προσέγγιση της µηχανικής µάθησης.
2.2 Η Ταξινόµηση Κειµένων ως Ερευνητική Περιοχή
Η ταξινόµηση κειµένων ϑεωρείται υπο-περιοχή της εξόρυξης κειµένων (Text Mining)
που αφορά στην ανάλυση µεγάλου αριθµού κειµένων µε στόχο την εξαγωγή γνώσης
ή την αυτοµατοποίηση διαδικασιών διαχείρισης κειµένων. ΄Αλλες υπο-περιοχές της
εξόρυξης κειµένων είναι η οµαδοποίηση κειµένων (text clustering), η περίληψη κειµέ-
νων (text summarization) και η εξαγωγή πληροφορίας (information extraction). Μία
εκτενής ϐιβλιογραφία της περιοχής της ταξινόµησης κειµένων µπορεί να εντοπιστεί
στη διεύθυνση:
http://www.cs.technion.ac.il/gabr/resources/atc/ATCbibliography.bib
Προς το παρόν δε διοργανώνονται συνέδρια αφιερωµένα στην περιοχή της ταξι-
νόµησης κειµένων αλλά πολλές σχετικές εργασίες παρουσιάζονται σε συνέδρια που
αναφέρονται :
α) στη µηχανική µάθηση, όπως τα :
− International Conference on Machine Learning (ICML)
− European Conference on Machine Learning (ECML)
ϐ) στην εξόρυξη δεδοµένων, όπως τα :
− ACM Special Interest Group in Knowledge Discovery in Data and Data Mining
Conference (SIGKDD)
24
2.3. ΟΡΙΣΜΟΣ ΠΡΟΒΛΗΜΑΤΟΣ
− International Conference on Data Mining (ICDM)
− Principles and Practice of Knowledge Discovery in Databases (PKDD)
γ) στην ανάκτηση πληροφορίας, όπως τα :
− ACM Special Interest Group in Information Retrieval Conference (SIGIR)
− European Conference on Information Retrieval (ECIR)
Επιστηµονικά περιοδικά για την περιοχή της ταξινόµησης κειµένων προς το παρόν
δεν εκδίδονται αλλά σχετικές εργασίες µπορούν να εντοπιστούν σε περιοδικά σχετικά
µε τη µηχανική µάθηση, την εξόρυξη δεδοµένων και την ανάκτηση πληροφορίας, όπως
τα :
− Machine Learning Journal (Springer)
− Information Retrieval (Springer)
− Journal of Machine Learning Research (MIT Press)
− Journal of Intelligent Information Systems (Springer)
− Knowledge and Information Systems (Springer)
− IEEE Transactions on Data and Knowledge Engineering (IEEE)
− Data Mining and Knowledge Discovery (Springer)
Προς το παρόν δεν έχουν εκδοθεί ϐιβλία που αναφέρονται αποκλειστικά στην ταξι-
νόµηση κειµένων, αν και έχουν αρχίσει να εκδίδονται ϐιβλία που αφορούν γενικότερα
την εξόρυξη κειµένων όπως το (Weiss et al., 2004) και το (Feldman and Sanger, 2006).
Είναι σηµαντικό να σηµειωθεί ότι υπάρχει µεγάλη επικάλυψη της περιοχής της ε-
ξόρυξης κειµένων µε την περιοχή της στατιστικής επεξεργασίας ϕυσικής γλώσσας (Sta-
tistical Natural Language Processing). Συνεπώς, εργασίες που αναφέρονται στην
ταξινόµηση κειµένων µπορούν να εντοπιστούν σε σχετικά συνέδρια, περιοδικά και
ϐιβλία.
2.3 Ορισµός Προβλήµατος
Η ταξινόµηση κειµένου αναφέρεται στη διαδικασία ανάθεσης µίας τάξης cj σε ένα
κείµενο di , όπου cj ∈ C και dj ∈ ∆, µε C = {c1, . . . , c|C|} να αποτελεί το σύνολο των
τάξεων και ∆ το πεδίο των κειµένων. Πιο συγκεκριµένα, στόχος είναι η κατασκευή
µίας συνάρτησης h : ∆ → C η οποία ϑα προσεγγίζει όσο το δυνατόν καλύτερα τη
συνάρτηση στόχο h̃ : ∆ → C. Η συνάρτηση στόχος εµπεριέχει τη γνώση για τον
τρόπο µε τον οποίο πρέπει να ταξινοµούνται τα κείµενα. Η συνάρτηση h ονοµάζεται
25
ΚΕΦΑΛΑΙΟ 2. ΜΗΧΑΝΙΚΗ ΜΑΘΗΣΗ ΚΑΙ ΤΑΞΙΝΟΜΗΣΗ ΚΕΙΜΕΝΩΝ
αν ( ∃«διαιτητής» και ∃«καλάθι» και ∃«ηµίχρονο» ) ή
αν ( ∃«καλάθι» και ∃«τρίποντο» )
τότε τάξη = ΚΑΛΑΘΟΣΦΑΙΡΙΣΗ
Σχήµα 2.1: Παράδειγµα κανόνα ταξινόµησης κειµένου
ταξινοµητής (classifier) ή υπόθεση. ΄Ενας ταξινοµητής επίσης µπορεί να ϑεωρηθεί και
ως µία συνάρτηση h(d, c) → {T, F } η οποία αποφασίζει αν το κείµενο d ανήκει (T ) ή
δεν ανήκει (F ) στην τάξη c. Πολλοί ταξινοµητές µάλιστα έχουν ως έξοδο την πιθανότητα
(εµπιστοσύνη - confidence) µε την οποία ϑεωρούν ότι ένα κείµενο ανήκει στη τάξη c.
Ο ταξινοµητής δηλαδή σε αυτήν την περίπτωση είναι της µορφής h(d, c)→ [0, 1].
Ανάλογα µε τις απαιτήσεις της εφαρµογής, µπορεί να χρειαστεί να ανατεθούν πε-
ϱισσότερες από µία τάξεις σε ένα κείµενο. ΄Ετσι, Ϲητούµενο µπορεί να είναι η ανάθεση
ακριβώς k, περισσότερων από k, ή λιγότερων από k στοιχείων του C στο d. Η περίπτω-
ση όπου απαιτείται η ανάθεση ακριβώς µίας τάξης (k = 1) σε κάθε κείµενο ονοµάζεται
ταξινόµηση µονής ετικέτας (single-label classification), ειδική περίπτωση της οποίας
είναι η δυαδική ταξινόµηση (binary classification) ή διήθηση (filtering) κατα την οποία
ισχύει |C| = 2. ΄Οταν |C| > 2 το πρόβληµα αναφέρεται ως ταξινόµηση πολλαπλών τά-
ξεων (multi-class classification). Η γενική περίπτωση κατά την οποία σε ένα κείµενο
di µπορεί να ανατεθεί ένα σύνολο τάξεων Yi , µε 0 ≤ |Yi | ≤ |C| ονοµάζεται ταξινόµηση
πολλαπλών ετικετών (multi-label classification). Να σηµειωθεί ότι σε αυτήν την περί-
πτωση οι τάξεις αναφέρονται ως ετικέτες (labels). Αυτή η σύµβαση ϑα διατηρηθεί και
στην παρούσα διατριβή.
΄Ενα σχετικό πρόβληµα µε την ταξινόµηση είναι η κατάταξη (ranking). Στο πρό-
ϐληµα αυτό, δεδοµένου ενός κειµένου d, Ϲητούµενο είναι η κατάταξη των µελών του C
σύµφωνα µε την καταλληλότητά τους να χαρακτηρίσουν το d.
2.4 Η Προσέγγιση της Μηχανικής Μάθησης
΄Οπως αναφέρθηκε και στην εισαγωγή του κεφαλαίου αυτού, η αρχική λύση στο πρό-
ϐληµα της αυτόµατης ταξινόµησης κειµένων ήταν η προσέγγιση της τεχνολογίας γνώ-
σης (knowledge engineering). Σε αυτήν, δηµιουργείται ένα έµπειρο σύστηµα το οποίο
λαµβάνει αποφάσεις ταξινόµησης κειµένων. ΄Ενα τέτοιο σύστηµα συνήθως αποτελείται
από ένα σύνολο κανόνων, όπου κάθε κανόνας ελέγχει την ύπαρξη ή απουσία συγ-
κεκριµένων λέξεων για να µπορέσει να παράξει µία πρόβλεψη. Παράδειγµα τέτοιου
κανόνα ϕαίνεται στο Σχήµα 2.1.
Τέτοια συστήµατα κατασκευάζονται από τους µηχανικούς γνώσης (knowledge en-
gineers) σε συνεργασία µε τους ειδικούς του πεδίου (domain experts). Αντιπροσω-
πευτικό παράδειγµα αποτελεί το σύστηµα CONSTRUE που κατασκευάστηκε από το
Carnegie Group για τη εταιρεία Reuters (Hayes et al., 1990). Τα µειονεκτήµατα αυτής
της προσέγγισης είναι προφανή και αφορούν κυρίως στην ανθρώπινη προσπάθεια που
26
2.5. ΣΥΝΟΛΟ ΕΚΠΑΙ∆ΕΥΣΗΣ , ΕΠΙΚΥΡΩΣΗΣ ΚΑΙ ΑΞΙΟΛΟΓΗΣΗΣ
απαιτείται για την αρχική σύνταξη αυτών των κανόνων. Η εφαρµογή µάλιστα των συ-
στηµάτων αυτών περιορίζεται στα προβλήµατα για τα οποία αρχικά κατασκευάστηκαν.
Για τους λόγους αυτούς, από τις αρχές της δεκαετίας του ΄90 έγινε ιδιαίτερα δηµο-
ϕιλής η προσέγγιση της µηχανικής µάθησης. Μία επαρκής εισαγωγή στη µηχανική
µάθηση περιέχεται στο ϐιβλίο του Tom Mitchell (Mitchell, 1997). Στην περίπτωση
της µηχανικής µάθησης, αναπτύσσεται αυτόµατα ένας ταξινοµητής χρησιµοποιώντας
ένα σύνολο προ-ταξινοµηµένων κειµένων. Αναλύοντας τα παραδείγµατα, ο ταξινοµη-
τής «µαθαίνει» τα χαρακτηριστικά των κειµένων κάθε κατηγορίας. Σύµφωνα µε την
ορολογία της µηχανικής µάθησης το πρόβληµα της ταξινόµησης κειµένων είναι µία
διεργασία µάθησης υπο επίβλεψη (supervised learning) αφού η µάθηση «επιβλέπεται»
από τη γνώση των πραγµατικών τάξεων των παραδειγµάτων. Παρατηρούµε λοιπόν ότι
σηµαντικό στοιχείο στην προσέγγιση της µηχανικής µάθησης είναι η διαθεσιµότητα
των παραδειγµάτων. Αυτά, τις περισσότερες ϕορές είναι διαθέσιµα αφού υπάρχουν
οργανισµοί που συνήθως διαθέτουν ταξινοµηµένα έγγραφα αλλά επιθυµούν να αυτο-
µατοποιήσουν τη διαδικασία ταξινόµησης.
2.5 Σύνολο εκπαίδευσης, επικύρωσης και αξιολόγησης
Η προσέγγιση της µηχανικής µάθησης στηρίζεται στη διαθεσιµότητα µίας αρχικής
συλλογής D = {d1, ..., d|D|} ⊂ ∆ από κείµενα που είναι ήδη ταξινοµηµένα. Με άλλα
λόγια, οι τιµές της συνάρτησης στόχου h̃ είναι γνωστές για κάθε di ∈ D. Γενικά, ένα
κείµενο di ϑεωρείται ϑετικό παράδειγµα της τάξης cj αν h̃(di , cj) = T και αρνητικό
παράδειγµα αν h̃(di , cj) = F .
Μετά την εκπαίδευση του ταξινοµητή επιθυµητή είναι η αξιολόγηση της αποδο-
τικότητάς του στην πρόβλεψη τάξεων. Για το λόγο αυτό, πριν την εκπαίδευση του
ταξινοµητή, η αρχική συλλογή παραδειγµάτων χωρίζεται σε δύο σύνολα, όχι κατ΄ α-
νάγκη ίδιου µεγέθους :
− Το σύνολο εκπαίδευσης και επικύρωσης (Training and Validation set), TV =
{d1, . . . , d|TV |}. Χρησιµοποιώντας αυτό, αναπτύσσεται («εκπαιδεύεται»), ο ταξινο-
µητής. Μέρος αυτού του συνόλου µπορεί να χρησιµοποιηθεί για τη ϱύθµιση των
παραµέτρων του ταξινοµητή (σύνολο επικύρωσης - ϐλέπε παρακάτω).
− Το σύνολο αξιολόγησης (test set ή evaluation set), E = {d|TV |+1, ..., d|D|} χρησι-
µοποιείται για την αξιολόγηση της αποτελεσµατικότητας του ταξινοµητή. Κάθε
dj ∈ E τροφοδοτείται στον ταξινοµητή και οι αποφάσεις του (h(di)) συγκρίνονται
µε τις πραγµατικές τάξεις (h̃(di )). ΄Ενα µέτρο εποµένως για την αποτελεσµατικό-
τητα του ταξινοµητή είναι το πόσο συχνά οι τιµές h(di) συµπίπτουν µε τις h̃(di ).
Λεπτοµέρειες για µετρικές αξιολόγησης ϑα αναφερθούν στην Ενότητα 2.9.
Τα κείµενα στο E δεν πρέπει σε καµία περίπτωση να συµµετέχουν στη διαδικασία
µάθησης του ταξινοµητή. Στην αντίθετη περίπτωση τα πειραµατικά αποτελέσµατα ϑα
27
ΚΕΦΑΛΑΙΟ 2. ΜΗΧΑΝΙΚΗ ΜΑΘΗΣΗ ΚΑΙ ΤΑΞΙΝΟΜΗΣΗ ΚΕΙΜΕΝΩΝ
είναι υπερ-αισιόδοξα. Μετά την εκπαίδευση, ϱύθµιση και αξιολόγηση, ο ταξινοµη-
τής εκπαιδεύεται από ολόκληρο το σύνολο παραδειγµάτων (D) και µπορεί πλέον να
εφαρµοστεί σε νέα, άγνωστης-τάξης κείµενα. Η τελική έκδοση του ταξινοµητή ανα-
µένεται να παρουσιάσει καλύτερη απόδοση αφού έχει εκπαιδευτεί από µεγαλύτερο
αριθµό δεδοµένων. Η απλή αυτή διαδικασία ονοµάζεται εκπαίδευση-και-αξιολόγηση
(train-and-test).
Μία εναλλακτική προσέγγιση είναι η σταυρωτή επικύρωση (k-fold cross vali-
dation) όπου το αρχικό σύνολο παραδειγµάτων χωρίζεται σε k ξένα µεταξύ τους
σύνολα E1, . . . , Ek ϐάσει των οποίων δηµιουργούνται k διαφορετικοί ταξινοµητές
h1, . . . , hk. Στη συνέχεια, για κάθε ταξινοµητή εφαρµόζεται η διαδικασία εκπαίδευση-
και-αξιολόγηση στο αντίστοιχο Ϲεύγος δεδοµένων εκπαίδευης και αξιολόγησης : <
TVi = D − Ei , Ei >. Για την εκτίµηση της απόδοσης της µεθόδου υπολογίζεται ο
µέσος όρος των αποδόσεων των k ταξινοµητών.
Και στις δύο προσεγγίσεις αξιολόγησης, είναι συχνή η απαίτηση να ϱυθµιστούν οι
παράµετροι των ταξινοµητών εξετάζοντας ποιες τιµές αυτών παρέχουν την καλύτερη α-
πόδοση. Για να γίνει εφικτή µία τέτοια ϐελτιστοποίηση, το σύνολο TV = {d1, . . . , d|TV |}
χωρίζεται σε ένα σύνολο εκπαίδευσης T = {d1, . . . , d|T |} και σε ένα σύνολο επικύρωσης
(validation set), V = {d|T |+1, . . . , d|TV |} στο οποίο γίνονται επαναλαµβανόµενα πειρά-
µατα για την ϐελτιστοποίηση των παραµέτρων. Είναι σηµαντικό να αναφερθεί ότι ο
ταξινοµητής δεν πρέπει να αξιολογηθεί στα δεδοµένα επικύρωσης στα οποία ϐελτιστο-
ποιήθηκε.
2.6 ∆εικτοδότηση Κειµένων
Για την επεξεργασία των κειµένων από τους ταξινοµητές είναι απαραίτητη µία δια-
δικασία δεικτοδότησης (indexing) κατά την οποία κάθε κείµενο µετατρέπεται σε µία
συµπαγή αναπαράσταση (representation) των περιεχοµένων του, άµεσα επεξεργάσιµη
από τους αλγορίθµους µηχανικής µάθησης. Είναι απαραίτητο τα κείµενα εκπαίδευ-
σης, επικύρωσης και αξιολόγησης να έχουν κοινή αναπαράσταση.
Η απλούστερη αναπαράσταση κειµένων είναι τα λεγόµενα διανύσµατα όρων (term
vectors) της µορφής ~d = (w1, . . . , w|F |) όπου F είναι το σύνολο των όρων που εµφα-
νίζονται τουλάχιστον µία ϕορά στα κείµενα του συνόλου εκπαίδευσης και wi αντιπρο-
σωπεύει τη σηµαντικότητα (ϐάρος) του όρου fi για τη σηµασιολογία του κειµένου. Από
τον τρόπο µε τον οποίο ορίζονται οι όροι στα κείµενα αλλά και από τον τρόπο που
καθορίζονται τα ϐάρη αυτών προκύπτουν εναλλακτικές αναπαραστάσεις.
Η πιο συνηθισµένη τακτική είναι οι όροι να αποτελούν τις λέξεις των κειµένων. Η
προσέγγιση αυτή ονοµάζεται σύνολο λέξεων (set of words - ή στην περίπτωση που
χρησιµοποιούνται δυαδικά ϐάρη: «bag of words»). Πειραµατικά αποτελέσµατα (Apté
et al., 1994; Dumais et al., 1998; Lewis, 1992) έχουν δείξει ότι πιο εξεζητηµένες
προσεγγίσεις αναπαράστασης, όπως η χρήση ϕράσεων αντί για λέξεις, δε παρουσιάζουν
σηµαντικά καλύτερη απόδοση.
28
2.6. ∆ΕΙΚΤΟ∆ΟΤΗΣΗ ΚΕΙΜΕΝΩΝ
Τα ϐάρη συνήθως ορίζονται στο διάσηµα [0,1]. Εναλλακτικά, µπορούν να χρησι-
µοποιηθούν δυαδικά ϐάρη µε το 1 να δηλώνει την παρουσία και το 0 την απουσία του
όρου στο κείµενο. Η επιλογή ανάµεσα σε δυαδικά και µη δυαδικά ϐάρη γίνεται ανά-
λογα µε τον ταξινοµητή που χρησιµοποιείται. Για τον καθορισµό του (µη-δυαδικού)
ϐάρους ενός όρου tk στο κείµενο d χρησιµοποιείται συνήθως η συνάρτηση tf-idf (term
frequency - inverse document frequency) (Salton and Buckley, 1988).
tf-idf(tk , d) = ♯(tk , d) · log
|T |
♯T (tk )



2.1
όπου το ♯(tk, d) δηλώνει τον αριθµό των εµφανίσεων του tk στο d και το ♯T (tk) δηλώ-
νει την συχνότητα κειµένου (document frequency) του όρου tk, δηλαδή τον αριθµό
των κειµένων του T στα οποία εµφανίζεται το tk. Η συνάρτηση tf-idf στηρίζεται στις
παρακάτω προτάσεις :
− ΄Οσο πιο συχνά εµφανίζεται µία λέξη σε ένα κείµενο, τόσο πιο αντιπροσωπευτική
είναι για τη σηµασιολογία του
− Σε όσα περισσότερα κείµενα εµφανίζεται µία λέξη τόσο λιγότερη πληροφορία
µπορεί να περιέχει
Είναι σηµαντικό να σηµειωθεί ότι η εξίσωση αυτή όπως και οι περισσότεροι τρόποι
δεικτοδότησης µετράνε τη σηµαντικότητα ενός όρου για ένα κείµενο σε σχέση µε τη
συχνότητά της και µόνο, αγνοώντας τη σειρά εµφάνισης.
Με στόχο τον προσδιορισµό των ϐαρών στο διάστηµα [0, 1] και στην αναπαρά-
σταση των κειµένων από διανύσµατα ίσου µήκους, τα ϐάρη που προκύπτουν από τη
συνάρτηση tf-idf συχνά κανονικοποιούνται µε την κανονικοποίηση συνηµιτόνου:
wk =
tf-idf(tk, d)√∑|T |
s=1(tf-idf(ts, d))
2



2.2
Παρόλο που αυτή η διανυσµατική αναπαράσταση µε την κανονικοποιηµένη έκδο-
ση του tf-idf για τον ορισµό των ϐαρών χρησιµοποιείται ευρέως, έχουν χρησιµοποιηθεί
και άλλες τεχνικές δεικτοδότησης όπως πιθανοτικές τεχνικές (Gövert et al., 1999) ή
τεχνικές που αναφέρονται στη δεικτοδότηση δοµηµένων κειµένων (Larkey and Croft,
1996).
Συναρτήσεις διαφορετικές από την tf-idf όµως είναι απαραίτητες όταν το σύνολο
εκπαίδευσης T δεν είναι διαθέσιµο από την αρχή και κατά συνέπεια το ♯T (tk) δε µπορεί
να υπολογιστεί. Τέτοια είναι η περίπτωση των εφαρµογών ταξινόµησης ϱοών κειµένων
(ϐλέπε Ενότητα 2.10). Σε αυτήν την περίπτωση συνήθως χρησιµοποιούνται δυαδικά
ϐάρη ή γίνεται προσπάθεια για τον υπολογισµό µίας προσέγγισης του tf-idf (Dept
et al., 1997).
΄Ενα επιπλέον στάδιο προεπεξεργασίας πριν τη δεικτοδότηση είναι η αφαίρεση λέξε-
ων µε µεγάλη συχνότητα εµφάνισης και µικρό πληροφοριακό περιεχόµενο όπως είναι
29
ΚΕΦΑΛΑΙΟ 2. ΜΗΧΑΝΙΚΗ ΜΑΘΗΣΗ ΚΑΙ ΤΑΞΙΝΟΜΗΣΗ ΚΕΙΜΕΝΩΝ
οι προθέσεις, οι σύνδεσµοι και τα άρθρα. Σε εφαρµογές όµως όπως η αναγνώριση συγ-
γραφέα (author identification) είναι σηµαντικό να διατηρούνται αυτές οι λέξεις αφού
σε τέτοιες περιπτώσεις έχουν µεγάλη διακριτική ικανότητα (Manning and Schutze,
1999).
Η διαδικασία αποκοπής των καταλήξεων (stemming) των λέξεων αποσκοπεί ου-
σιαστικά σε µία οµαδοποίηση των λέξεων που τελικά ϑα οδηγήσει µειωµένο χώρο
διαστάσεων.
Ανάλογα µε την εφαρµογή, µπορεί να δεικτοδοτηθεί ολόκληρο το κείµενο ή επι-
λεγµένα τµήµατα αυτού. Αν και τις περισσότερες ϕορές χρησιµοποιείται το πλήρες
κείµενο, στην εργασία (Larkey, 1999) που αφορά ταξινόµηση διπλωµάτων ευρεσιτε-
χνίας δεικτοδοτείται µόνο ο τίτλος, η περίληψη, οι 20 πρώτες γραµµές του κειµένου
και η ενότητα που περιγράφει την πρωτοτυπία τη συγκεκριµένης ευρεσιτεχνίας. Αυτό
ϐέβαια είναι εφικτό γιατί τα συγκεκριµένα κείµενα είναι δοµηµένα. Κάτι αντίστοιχο
µπορεί να γίνει και σε κείµενα που είναι διακριτός ο τίτλος τους (Cohen and Singer,
1999). Σε αυτές τις περιπτώσεις µπορεί να δοθεί µεγαλύτερη ϐαρύτητα στις λέξεις που
περιέχονται στους τίτλους (Cohen and Singer, 1999).
2.7 Μείωση ∆ιαστάσεων
Ο µεγάλος αριθµός διαστάσεων αποτελεί σηµαντική πρόκληση για τις µεθόδους τα-
ξινόµησης κειµένων. Πολλοί ταξινοµητές αντιµετωπίζουν δυσκολίες όσον αφορά στην
κλιµάκωσή τους σε σχέση µε τον αριθµό των χαρακτηριστικών. Επίσης, ο µεγάλος α-
ϱιθµός διαστάσεων οδηγεί σε ϕαινόµενο υπερ-µοντελοποίησης (overfitting). ΄Ετσι, πριν
την εφαρµογή του ταξινοµητή απαραίτητο ϑεωρείται το στάδιο της µείωσης διαστάσεων
(dimensionality reduction).
Για τη µείωση των διαστάσεων έχουν προταθεί διάφορες τεχνικές κυρίως από τον
χώρο της ϑεωρίας της πληροφορίας και της γραµµικής άλγεβρας. Η αποτελεσµατικό-
τητα των µεθόδων αυτών διαπιστώνεται από τη σύγκριση της απόδοσης του ταξινοµητή
πριν και µετά την εφαρµογή της µείωσης διαστάσεων.
Οι µέθοδοι µείωσης του αρχικού συνόλου διαστάσεων (χαρακτηριστικών) από F σε
F ′ µε |F ′| << |F | µπορούν να οργανωθούν σε δύο οµάδες :
− Μέθοδοι επιλογής χαρακτηριστικών (feature selection), όπου επιλέγεται ένα σύ-
νολο F ′ ⊆ F .
− Μεθοδοι εξαγωγής χαρακτηριστικών (feature extraction). Τα χαρακτηριστικά
στο F ′ δεν είναι του ίδιου τύπου µε αυτά που υπάρχουν στο F (π.χ. λέξεις) αλλά
προκύπτουν από συνδυασµούς ή µετασχηµατισµούς των αρχικών χαρακτηριστι-
κών.
Οι ειδικοί όροι «επιλογή όρων» (term selection) και «εξαγωγή όρων» (term extra-
ction) χρησιµοποιούνται για την αναφορά στη µείωση διαστάσεων στην ταξινόµηση
30
2.7. ΜΕΙΩΣΗ ∆ΙΑΣΤΑΣΕΩΝ
κειµένων. Επειδή όµως οι όροι «επιλογή χαρακτηριστικών» (feature selection) και
«εξαγωγή χαρακτηριστικών» (feature extraction) είναι πιο γενικοί και πιο διαδεδοµέ-
νοι, χρησιµοποιούνται αυτοί στο υπόλοιπο της διατριβής. Στις παρακάτω δύο ενότητες
αναλύονται οι δύο αυτές οµάδες τεχνικών.
2.7.1 Επιλογή Χαρακτηριστικών
∆εδοµένου ενός ακεραίου r οι τεχνικές επιλογής χαρακτηριστικών προσπαθούν να
επιλέξουν από το αρχικό σύνολο F ένα υποσύνολο F ′ µε (|F ′| ≪ |F |) τέτοιο ώστε να
αυξηθεί η απόδοση του ταξινοµητή.
Μέθοδος Περιτυλίγµατος Στη µέθοδο περιτυλίγµατος (wrapper) αρχικά υπάρχει
ένα άδειο σύνολο χαρακτηριστικών και διαδοχικά προστίθενται όροι ελέγχοντας ταυ-
τόχρονα αν η προσθήκη του νέου χαρακτηριστικού οδήγησε σε αύξηση ή µείωση της
απόδοσης του ταξινοµητή. Στην πρώτη περίπτωση το χαρακτηριστικό διατηρείται στο
σύνολο ενώ στη δεύτερη αφαιρείται. Η διαδικασία τελειώνει µετά την αξιολόγηση όλων
των χαρακτηριστικών όπου και προκύπτει το αποδοτικότερο σύνολο. Βασικό πλεο-
νέκτηµα της µεθόδου περιτυλίγµατος είναι ότι λαµβάνεται υπόψη ο ταξινοµητής που
ϑα χρησιµοποιηθεί και έτσι το σύνολο των χαρακτηριστικών είναι ϐελτιστοποιηµένο
ως προς αυτόν. Προφανές όµως µειονέκτηµα αποτελεί το υπολογιστικό κόστος που
απαιτείται για την εξέταση καταλληλότητας των υπο-συνόλων.
Μία πιο αποδοτική προσέγγιση είναι αυτή της διήθησης (filtering) κατά την οποία
επιλέγονται να διατηρηθούν µόνο τα χαρακτηριστικά που έχουν σηµειώσει τη µεγαλύ-
τερη τιµή µίας συγκεκριµένης µετρικής αξιολόγησης. Χαρακτηριστικοί αντιπρόσωποι
αυτής της κατηγορίας είναι η διήθηση ϐάσει συχνότητας εµφάνισης και οι διήθηση
ϐάσει µετρικών αξιολόγησης πληροφορίας που περιγράφονται στις επόµενες παραγρά-
ϕους.
Συχνότητα Εµφάνισης Μία πολύ απλή και αποτελεσµατική προσέγγιση για επι-
λογή χαρακτηριστικών είναι η χρήση της συχνότητας εµφάνισης ♯T (tk) (document
frequency) ενός όρου tk στη συλλογή των κειµένων. Σύµφωνα µε αυτήν, διατηρούνται
µόνο τα χαρακτηριστικά που ξεπερνούν έναν συγκεκριµένο αριθµό από εµφανίσεις.
Σε µία σειρά πειραµάτων από τους Yang και Pedersen (Yang and Pedersen, 1997)
αποδείχτηκε ότι µε τη µέθοδο αυτή µπορεί να µειωθεί ο αριθµός των διαστάσεων µέχρι
και 10 ϕορές χωρίς να παρατηρηθεί µείωση της απόδοσης ενώ ακόµη και αν ο αριθµός
µειωθεί 100 ϕορές η µείωση της απόδοσης είναι µικρή. Το γεγονός αυτό δείχνει ότι
λέξεις οι οποίες σπάνια εµφανίζονται στη συλλογή δεν εµπεριέχουν χρήσιµη πληρο-
ϕορία για την ταξινόµηση. Πολλές ϕορές, η µέθοδος αυτή µπορεί να χρησιµοποιηθεί
πριν από κάποια άλλη τεχνική επιλογής χαρακτηριστικών (ϐλέπε παρακάτω).
Μετρικές αξιολόγησης πληροφορίας Στην προσέγγιση αυτή χρησιµοποιούνται
µετρικές από το χώρο της ϑεωρίας της πληροφορίας (information theory) όπως η µε-
31
ΚΕΦΑΛΑΙΟ 2. ΜΗΧΑΝΙΚΗ ΜΑΘΗΣΗ ΚΑΙ ΤΑΞΙΝΟΜΗΣΗ ΚΕΙΜΕΝΩΝ
τρική χ2 (chi-square) (Caropreso et al., 2001; Galavotti et al., 2000), το κέρδος πλη-
ϱοφορίας (information gain) (Caropreso et al., 2001; Larkey, 1998) και η αµοιβαία
πληροφορία (mutual information) (Dumais et al., 1998; Larkey and Croft, 1996). Οι
ορισµοί αυτών των µετρικών δίνονται παρακάτω :
IG(tk , cj) =
∑
c∈{cj,c̄j}
∑
t∈{tk ,t̄k }
P(t, c)log
P(t, c)
P(t)P(c)



2.3
χ2(tk , cj) =
|T | · {P(tk, cj)P(tk , cj) − P(tk, cj)P(tk , cj)}2
P(tk)P(tk)P(cj)P(cj)



2.4
MI(tk , cj) = log
P(tk, cj)
P(tk)P(cj)



2.5
όπου γενικά το P(t, c) εκφράζει την πιθανότητα ο όρος t να εµφανίζεται (ή να µην
εµφανίζεται - t̄) σε κείµενα της τάξης c ή της συµπληρωµατικής της (c̄). ΄Ολες οι
πιθανότητες των παραπάνω εξισώσεων µπορούν να υπολογιστούν από τις συχνότητες
εµφάνισης των όρων και των τάξεων.
Γενικά, οι συναρτήσεις αυτές δίνουν µεγάλες τιµές αξιολόγησης σε λέξεις οι οποίες
περιέχουν σηµαντική πληροφορία για το χαρακτηρισµό µίας τάξης. Για παράδειγ-
µα, µία λέξη ϑεωρείται σηµαντική αν περιέχεται πολλές ϕορές σε κείµενα µίας τάξης
αλλά όχι σε κείµενα άλλων τάξεων. ΄Εχουν γίνει διάφορες πειραµατικές αξιολογήσεις
αυτών των µετρικών (Yang and Pedersen, 1997). Σε αυτά τα πειράµατα όλες σχεδόν
οι συναρτήσεις ϑεωρίας πληροφορίας ϕαίνεται να υπερέχουν έναντι της προσέγγισης
συχνότητας εµφάνισης. Επίσης, η µετρική χ2 και το κέρδος πληροφορίας αποδεικνύ-
ονται αποτελεσµατικότερες από την αµοιβαία πληροφορία.
2.7.2 Εξαγωγή Χαρακτηριστικών
Κατά την εξαγωγή χαρακτηριστικών γίνεται µία προσπάθεια να εξαχθεί από το αρχικό
σύνολο F ένα σύνολο F ′ (|F ′| ≪ |F |) από συνθετικά χαρακτηριστικά τα οποία ϑα ϐελτιώ-
σουν την απόδοση του ταξινοµητή. Το κίνητρο πίσω από αυτές τις µεθοδολογίες είναι
η ανακάλυψη συσχετίσεων µεταξύ χαρακτηριστικών και η έκφρασή τους µέσα από νέα
χαρακτηριστικά. Σε δεδοµένα κειµένων για παράδειγµα µπορεί να υπάρξουν σχέσεις
µεταξύ των λέξεων όπως η συνωνυµία, η πολυσηµία ή σύνολα λέξεων που συνήθως
εµφανίζονται µαζί. Οι µέθοδοι της κατηγορίας αυτής αποτελούνται από δύο στοιχεία.
− Μία διαδικασία εξαγωγής των νέων χαρακτηριστικών από τα αρχικά
− Μία συνάρτηση µεταφοράς των διανυσµάτων από τον αρχικό χώρο διαστάσεων
στο νέο
Οι σηµαντικότεροι εκπρόσωποι αυτής της κατηγορίας είναι η οµαδοποίηση όρων
(term clustering) και η λανθάνουσα σηµασιολογική δεικτοδότηση (latent semantic
indexing).
32
2.8. ΤΑΞΙΝΟΜΗΤΕΣ ΚΕΙΜΕΝΩΝ
Οµαδοποίηση όρων Σε αυτήν την προσέγγιση χρησιµοποιούνται αλγόριθµοι οµα-
δοποίησης (Jain et al., 1999) µε στόχο την οργάνωση όρων µε σηµασιολογική οµοιό-
τητα σε οµάδες. Στη συνέχεια, τεχνητοί όροι που αντιστοιχούν στις οµάδες αποτελούν
τα νέα χαρακτηριστικά (Lewis, 1992; Baker and McCallum, 1998).
Λανθάνουσα σηµασιολογική δεικτοδότηση Η λανθάνουσα σηµασιολογική δει-
κτοδότηση (latent semantic indexing) (Deerwester et al., 1990) στοχεύει στην ανα-
κάλυψη και αξιοποίηση συσχετίσεων µεταξύ των όρων του αρχικού χώρου διαστάσεων.
Ο µετασχηµατισµός των αρχικών διανυσµάτων στον νέο µειωµένο χώρο γίνεται µε την
εφαρµογή της µεθόδου της αποσύνθεσης ιδιοτιµών (SVD - Singular Value Decomposi-
tion). ΄Ενα µειονέκτηµα της LSI είναι ότι σε αντίθεση µε την επιλογή χαρακτηριστικών
και την οµαδοποίηση τα χαρακτηριστικά που προκύπτουν δεν είναι ερµηνεύσιµα -
κατανοητά. Παρόλα αυτά επιτυγχάνει την αποτύπωση της σηµασιολογικής δοµής του
λεξικού των κειµένων. ΄Ενα άλλο µειονέκτηµα είναι ότι κάποιος αρχικός όρος που
είναι ιδιαίτερα χρήσιµος στην αναγνώριση µίας τάξης µπορεί να χαθεί µετά τον µετα-
σχηµατισµό.
2.8 Ταξινοµητές Κειµένων
Σε αυτήν την ενότητα περιγράφουµε τους πιο αντιπροσωπευτικούς αλγορίθµους ταξι-
νόµησης από αυτούς που έχουν χρησιµοποιηθεί στη ϐιβλιογραφία για την ταξινόµηση
κειµένων.
2.8.1 Πιθανοτικοί Ταξινοµητές
Οι πιθανοτικοί ταξινοµητές αποφασίζουν σύµφωνα µε την πιθανότητα P(cj |~di) δη-
λαδή, την πιθανότητα το κείµενο i που αναπαρίσταται από το διάνυσµα ~di =
(w(1,i), . . . , w(|F |,i)) να ανήκει στην τάξη cj. Ο υπολογισµός της πιθανότητας αποτε-
λεί εφαρµογή του ϑεωρήµατος του Bayes:
P(cj |~di ) =
P(cj)P(~di |cj)
P(~di)



2.6
΄Ενας τέτοιος ταξινοµητής εποµένως µπορεί να προβλέψει την τάξη µε τη µεγαλύ-
τερη πιθανότητα. Αν hB(~d) η πρόβλεψη του ταξινοµητή Bayes, τότε :
hB(~d) = arg max
cj∈C
P(cj |~di ) = arg max
cj∈C
(
P(cj)P(~di |cj)
P(~di )
)



2.7
Στην παραπάνω εξίσωση, P(~di) είναι η πιθανότητα ένα τυχαία επιλεγµένο κείµενο
να έχει την αναπαράσταση ~di και P(cj) είναι η πιθανότητα ένα τυχαίο κείµενο να ανήκει
στην τάξη cj. Ο όρος P(~di |cj) εκφράζει την πιθανότητα ένα αντικείµενο της τάξης cj να
33
ΚΕΦΑΛΑΙΟ 2. ΜΗΧΑΝΙΚΗ ΜΑΘΗΣΗ ΚΑΙ ΤΑΞΙΝΟΜΗΣΗ ΚΕΙΜΕΝΩΝ
έχει την αναπαράσταση του di . Ο υπολογισµός αυτής της πιθανότητας είναι ιδιαίτερα
δύσκολος αφού τα πιθανά διανύσµατα ~di είναι πάρα πολλά
1.
Για να αντιµετωπιστεί αυτό το πρόβληµα γίνεται η υπόθεση ότι οι τιµές των χα-
ϱακτηριστικών δεδοµένης µίας τάξης είναι ανεξάρτητες µεταξύ τους. Ο ταξινοµητής
που λειτουργεί σύµφωνα µε αυτήν την υπόθεση ονοµάζεται αφελής ταξινοµητής Bayes
(Naive Bayes Classifier) επειδή στην πράξη τα χαρακτηριστικά δεν είναι ανεξάρτητα
µεταξύ τους. Η υπόθεση αυτή εκφράζεται στην παρακάτω εξίσωση
P(~di |cj) =
|T |∏
k=1
P(w(k,i)|cj)



2.8
και εποµένως η απόφαση του ταξινοµητή Naive Bayes είναι :
hNB(~d) = arg max
cj∈C
P(cj)
|T |∏
k=1
P(w(k,i)|cj)




2.9
Ο παραπάνω υπολογισµός επαφίεται στον υπολογισµό των πιθανοτήτων P(cj) και
P(w(k,i)|cj). Ο όρος P(cj) µπορεί να υπολογιστεί από τη σχετική συχνότητα εµφάνι-
σης της cj. Το ίδιο µπορεί να γίνει και για τον όρο P(w(k,i)|cj) σε περίπτωση που τα
χαρακτηριστικά είναι ονοµαστικά. Σε περίπτωση που τα χαρακτηριστικά είναι αριθµη-
τικά τότε γίνεται η υπόθεση ότι τα δεδοµένα ακολουθούν µία συγκεκριµένη κατανοµή
(π.χ. Γκαουσιανή) και η πιθανότητα P(w(k,i)|cj) ισούται µε τη συνάρτηση πυκνότητας
πιθανότητας g(w(k,i), µcj , σcj), όπου µcj και σcj ο µέσος όρος και η τυπική απόκλιση του
χαρακτηριστικού k στα παραδείγµατα της τάξης cj. Ο Naive Bayes έχει παρουσιά-
σει αρκετά καλή απόδοση σε σχέση µε την απλότητά του σε εφαρµογές ταξινόµησης
κειµένου (Rennie et al., 2003; McCallum and Nigam, 1998; Kim et al., 2006).
2.8.2 ∆ένδρα απόφασης
΄Ενας ταξινοµητής δένδρου απόφασης (decision tree) αποτελεί µία δενδρική δοµή στην
οποία :
− Κάθε εσωτερικός κόµβος αντιστοιχεί σε ένα χαρακτηριστικό.
− Οι διακλαδώσεις σε κάθε κόµβο αντιστοιχούν σε δοκιµασίες ελέγχου για το αν το
ϐάρος (weight) του χαρακτηριστικού του κόµβου για ένα κείµενο ξεπερνάει ένα
κατώφλι ή όχι.
− Τα ϕύλλα του δένδρου αντιστοιχούν στις τάξεις του προβλήµατος ταξινόµησης
΄Ενας τέτοιος ταξινοµητής πραγµατοποιεί µία ταξινόµηση εκτελώντας αναδροµικά
την παρακάτω διαδικασία, ξεκινώντας από τη ϱίζα του δένδρου:
1Το ίδιο ισχύει και για τον όρο P( ~di ) αλλά επειδή είναι κοινός για όλες τις τάξεις µπορεί να απαλειφθεί.
34
2.8. ΤΑΞΙΝΟΜΗΤΕΣ ΚΕΙΜΕΝΩΝ
− Σε κάθε εσωτερικό κόµβο εξετάζεται το ϐάρος του κείµενου για το χαρακτηριστικό
του κόµβου και ακολουθείται η αντίστοιχη διακλάδωση.
− Αν ο επόµενος κόµβος είναι ϕύλλο τότε η τάξη του ϕύλλου είναι η έξοδος του
ταξινοµητή.
Στους περισσότερους από αυτούς τους ταξινοµητές χρησιµοποιείται η δυαδική α-
ναπαράσταση και κατά συνέπεια προκύπτουν δυαδικά δένδρα στα οποία οι δοκιµασίες
των διακλαδώσεων αναφέρονται στο αν ένας όρος υπάρχει ή όχι σε ένα κείµενο. Για
την εκπαίδευση του ταξινοµητή, την κατασκευή δηλαδή αυτής της δενδρικής δοµής,
ακολουθείται η παρακάτω διαδικασία :
− Αρχικά γίνεται έλεγχος για το αν όλα τα παραδείγµατα ανήκουν στην ίδια τάξη.
− Αν όχι, επιλέγεται ένας όρος tk ο οποίος ϑα αποτελεί τη δοκιµασία ελέγχου για
τα δεδοµένα αυτά. ΄Εστω ότι η δοκιµασία αφορά στην ύπαρξη ή όχι του όρου
tk στα κείµενα. Για κάθε περίπτωση δηµιουργείται µία διακλάδωση κάθε µία
από τις οποίες καταλήγει σε νέο κόµβο. ΄Ετσι τα δεδοµένα χωρίζονται στους δύο
υποκόµβους ανάλογα µε το αν περιλαµβάνουν ή όχι τον όρο tk .
− Αν στους κόµβους που προκύπτουν όλα τα παραδείγµατα ανήκουν στην ίδια
τάξη, τότε δε συνεχίζεται η διάσπαση και η τάξη αυτή αποτελεί την τάξη του
κόµβου.
Κύριο στοιχείο του αλγορίθµου είναι η επιλογή του όρου tk σύµφωνα µε τον οποίο
γίνεται η διακλάδωση. Η επιλογή αυτή γίνεται συνήθως σύµφωνα µε κριτήρια όπως το
κέρδος πληροφορίας του όρου ή την εντροπία.
Να σηµειωθεί όµως ότι ένα τέτοιο πλήρως ανεπτυγµένο δένδρο οδηγεί συνήθως σε
υπερµοντελοποίηση, αφού πολλά κλαδιά ϑα είναι εξειδικευµένα στα δεδοµένα εκπαί-
δευσης. Οι περισσότεροι λοιπόν αλγόριθµοι δένδρων απόφασης συνήθως αποτελούνται
από δύο µέρη. α) έναν αλγόριθµο για την ανάπτυξη του δένδρου και ϐ) µία µέθοδο για
το κλάδεµά του (pruning), δηλαδή την αφαίρεση των υπερ-εξειδικευµένων κλαδιών.
Στην ταξινόµηση κειµένων έχουν χρησιµοποιηθεί διάφοροι αλγόριθµοι δένδρων α-
πόφασης όπως ο ID3 (Fuhr et al., 1991), C4.5 (Cohen and Hirsh, 1998), και ο C5
(Li and Jain, 1998). Επίσης όµως τα δένδρα έχουν χρησιµοποιηθεί και ως αλγόριθ-
µοι ϐάσης (baseline) (Cohen and Singer, 1999; Joachims, 1998) αλλά και ως µέλη
οµάδων ταξινοµητών (ϐλέπε Ενότητα 2.8.7) (Li and Jain, 1998; Schapire and Singer,
2000; Weiss et al., 1999).
2.8.3 Ταξινοµητές Κανόνων
΄Ενα ταξινοµητής κανόνων (rule learning algorithm) προσπαθεί µε την ανάλυση των πα-
ϱαδειγµάτων να κατασκευάσει αυτόµατα ένα σύνολο από κανόνες της µορφής αν-τοτε
(if-then) σύµφωνα µε τους οποίος ϑα ταξινοµούνται τα κείµενα µε µεγάλη ακρίβεια.
35
ΚΕΦΑΛΑΙΟ 2. ΜΗΧΑΝΙΚΗ ΜΑΘΗΣΗ ΚΑΙ ΤΑΞΙΝΟΜΗΣΗ ΚΕΙΜΕΝΩΝ
Οι συνθήκες (if) των κανόνων συνήθως αναφέρονται στην ύπαρξη ή απουσία µίας ή
περισσότερων λέξεων στο υπο εξέταση κείµενο. Το συµπέρασµα του κανόνα (then)
προφανώς αναφέρεται στην τάξη του κειµένου.
Οι αλγόριθµοι µάθησης κανόνων προσπαθούν να επιλέξουν από όλους τους πι-
ϑανούς κανόνες τους καλύτερους µε ϐάσει κάποιο κριτήριο. Για την κατασκευή των
κανόνων αρχικά κάθε κείµενο αποτελεί και κανόνα του τύπου:
αν (f1, . . . , fn) τότε cj
όπου f1, . . . , fn οι όροι που περιέχονται στο κείµενο και cj η τάξη του κειµένου.
Αυτός ο κανόνας προφανώς ταξινοµεί σωστά το ίδιο το κείµενο αλλά ϕυσικά υπερ-
µοντελοποιεί µονο το συγκεκριµένο παράδειγµα. Οι αλγόριθµοι µάθησης κανόνων
εφαρµόζουν έπειτα µία διαδικασία γενίκευσης κατά την οποία ο κανόνας απλοποιείται
µέσα από µία σειρά αλλαγών όπως η αφαίρεση συνθηκών ή η ένωση συνθηκών. Οι
διαδικασίες αυτές κάνουν τους κανόνες πιο συµπαγείς και την ίδια στιγµή πιο γενι-
κούς. Στο τέλος της διαδικασίας εφαρµόζεται µία διαδικασία κλαδέµατος µε στόχο την
αύξηση της γενικότητας του ταξινοµητή.
΄Ενας αλγόριθµος µάθησης κανόνων που έχει εφαρµοστεί στην ταξινόµηση κειµέ-
νων είναι ο RIPPER (Repeated Incremental Prunning to Produce Error Reduction)
(Cohen, 1995; Cohen and Hirsh, 1998)
2.8.4 Νευρωνικά ∆ίκτυα
΄Ενα νευρωνικό δίκτυο (neural network) είναι ένα δίκτυο µονάδων όπου οι µονάδες
εισόδου (input units) αντιπροσωπεύουν τα χαρακτηριστικά και οι µονάδες εξόδου
(output units) τις τάξεις. Τα ϐάρη στις συνδέσεις (edges) µεταξύ των εισόδων και των
εξόδων αναπαριστούν τις συσχετίσεις µεταξύ τους. Για την ταξινόµηση ενός κειµένου,
τα ϐάρη των χαρακτηριστικών εισάγονται στις εισόδους του δικτύου. Η ενεργοποίηση
αυτών των µονάδων προωθείται µέσω του δικτύου και η τελική τιµή της µονάδας εξόδου
καθορίζει την απόφαση.
Η απλούστερη µορφή νευρωνικού δικτύου είναι ο perceptron (Dept et al., 1997;
Ng et al., 1997) που αποτελεί γραµµικό ταξινοµητή2. ΄Ενα µη-γραµµικό νευρωνικό
δίκτυο µπορεί να κατασκευαστεί έχοντας επιπλέον «κρυφά» επίπεδα µονάδων που
στην ταξινόµηση κειµένων συνήθως αντιπροσωπεύουν συσχετίσεις µεταξύ των όρων
που µπορεί να µάθει το δίκτυο (Lam and Lee, 1999; Ruiz and Srinivasan, 1999).
Απο έρευνες που έχουν γίνει τα µη γραµµικά µοντέλα δεν έχουν επιδείξει σηµαντική
ανωτερότητα απέναντι στα γραµµικά (Schütze et al., 1995; Wiener et al., 1995).
Μία τυπική µέθοδος για την εκπαίδευση νευρωνικών δικτύων είναι η ανάστροφη
µετάδοση σφάλµατος (backpropagation) όπου σε περίπτωση λάθους εξόδου (ταξινόµη-
σης) το σφάλµα επιµερίζεται στους κρυφούς συνδέσµους.
2Οι γραµµικοί ταξινοµητές ορίζουν ένα υπερ-επίπεδο στο χώρο χαρακτηριστικών που διαχωρίζει τα
δεδοµένα των διαφορετικών τάξεων. Το επίπεδο αυτό στη συνέχεια µπορεί να χρησιµοποιηθεί για την
παραγωγη ταξινοµήσεων
36
2.8. ΤΑΞΙΝΟΜΗΤΕΣ ΚΕΙΜΕΝΩΝ
2.8.5 Ταξινοµητές ϐάσει περιπτώσεων
Η ιδιαιτερότητα των ταξινοµητών ϐάσει περιπτώσεων (example based classifiers ή in-
stance based classifiers) είναι ότι δεν αναπτύσσουν ένα µοντέλο που περιγράφει τα
δεδοµένα και µπορεί να χρησιµοποιηθεί για λήψη απόφασης. Οι ταξινοµητές αυτοί δεν
περιλαµβάνουν στάδιο εκπαίδευσης, αλλά κατά την ταξινόµηση ενός κειµένου, εξετά-
Ϲονται οι τάξεις παρόµοιων παραδειγµάτων και ϐάσει αυτών παράγονται οι προβλέψεις.
Εξαιτίας αυτής τους της ιδιότητας ονοµάζονται και αλγόριθµοι οκνηρής µάθησης (lazy
learning algorithms).
Χαρακτηριστικό παράδειγµα αλγορίθµου ϐάσει περιπτώσεων αποτελεί ο ταξινοµη-
τής k κοντινότερων γειτόνων (kNN - k Nearest Neighbors)(Aha and Kibler, 1991). Για
την ταξινόµηση ενός κειµένου di , ο kΝΝ εντοπίζει πρώτα τα k πιο όµοια παραδείγµα-
τα (γείτονες) µε το di . Η τάξη που παρατηρείται στα περισσότερα παραδείγµατα της
γειτονιάς του di αποτελεί και την έξοδο του kΝΝ. Για τη µέτρηση της οµοιότητας µπο-
ϱούν να χρησιµοποιηθούν µετρικές από την ανάκτηση πληροφορίας όπως η απόσταση
συνηµιτόνου ή η ευκλείδεια απόσταση.
Το προφανές µειονέκτηµα του kΝΝ αλλά και γενικότερα των αλγορίθµων ϐάσει
περιπτώσεων είναι οι µεγάλοι χρόνοι ταξινόµησης. Πρόβληµα επίσης αποτελεί ο εν-
τοπισµός µίας κατάλληλης τιµής για το k. ∆ύο από τις εργασίες στις οποίες έχει
αξιοποιηθεί ο kΝΝ ως ταξινοµητής κειµένων είναι ο (Larkey and Croft, 1996) και
(Yang, 1999).
2.8.6 Μηχανές ∆ιανυσµάτων Υποστήριξης
Οι µηχανές διανυσµάτων υποστήριξης ή µηχανές εδραίων διανυσµάτων (Support Ve-
ctor Machines - SVM) προτάθηκαν από το Vladimir Vapnik (Vapnik, 1995) και χρη-
σιµοποιήθηκαν στην ταξινόµηση κειµένων πρώτη ϕορά από τον Thorsten Joachims
(Joachims, 1998).
Ο αλγόριθµος προσπαθεί να εντοπίσει ένα υπερ-επίπεδο στο χώρο χαρακτηριστι-
κών το οποίο να διαχωρίζει τα ϑετικά από τα αρνητικά παραδείγµατα. Το επίπεδο
αυτό επιλέγεται µε τέτοιο τρόπο ώστε να απέχει όσο το δυνατόν περισσότερο από τα
κοντινότερα ϑετικά και αρνητικά παραδείγµατα (maximum margin hyperplane). Τα
παραδείγµατα µε τη µικρότερη απόσταση από το υπερεπίπεδο αυτό ονοµάζονται δια-
νύσµατα υποστήριξης (support vectors).
Η µέθοδος που περιγράφηκε µπορεί να εφαρµοστεί και σε περιπτώσεις που τα
ϑετικά και τα αρνητικά παραδείγµατα δεν είναι γραµµικώς διαχωρίσιµα. Σε αυτές τις
περιπτώσεις χρησιµοποιούνται οι λεγόµενες συναρτήσεις πυρήνα (kernel functions) για
τον ορισµό του υπερεπιπέδου σε ένα νέο µετασχηµατισµένο χώρο χαρακτηριστικών.
Οι Yang και Liu (Yang, 1999) παρατήρησαν ότι τα αποτελέσµατα της ταξινόµησης
κειµένων είναι ελάχιστα κατώτερα αν γίνει η υπόθεση ότι τα δεδοµένα είναι γραµµικώς
διαχωρίσιµα.
΄Ενα σηµαντικό πλεονέκτηµα των µηχανών διανυσµάτων υποστήριξης ως ταξινοµη-
τές κειµένων είναι η καλή κλιµάκωση τους σε µεγάλο αριθµό χαρακτηριστικών.
37
ΚΕΦΑΛΑΙΟ 2. ΜΗΧΑΝΙΚΗ ΜΑΘΗΣΗ ΚΑΙ ΤΑΞΙΝΟΜΗΣΗ ΚΕΙΜΕΝΩΝ
2.8.7 Οµάδες Ταξινοµητών
Στις οµάδες ταξινοµητών (classifier committees ή ensemble classifiers ή multiple
classifier systems) οι αποφάσεις k διαφορετικών ταξινοµητών συνδυάζονται µε στόχο
την αύξησης της απόδοσης. ∆ύο σηµαντικοί παράγοντες για την ανάπτυξη µίας οµάδας
ταξινοµητών είναι α) η επιλογή των k ταξινοµητών που ϑα αποτελέσουν τα µέλη της
οµάδας και ϐ) ο τρόπος συνδυασµού των αποφάσεων τους.
Για το πρώτο ϑέµα, είναι γνωστό ότι για να επιτευχθεί καλή απόδοση σε µία ο-
µάδα ταξινοµητών τα µέλη της οµάδας πρέπει να έχουν όσο το δυνατόν µεγαλύτερη
ανεξαρτησία µεταξύ τους (diversity ή independency) (Tumer and Ghosh, 1996).
Για το δεύτερο ϑέµα, έχουν προταθεί διάφορες προσεγγίσεις :
− Μία απλή προσέγγιση είναι η µέθοδος πλειοψηφίας (majority voting), όπου µία
τάξη αποτελεί πρόβλεψη µόνο αν την έχουν προβλέψει («ψηφίσει») τουλάχιστον
(k + 1)/2 ταξινοµητές. Εναλλακτικά, στην ψήφο κάθε ταξινοµητή µπορεί να
προσµετράται και η εµπιστοσύνη που αυτός έχει για τη συγκεκριµένη τάξη
− Μία άλλη πολιτική είναι στην ψήφο κάθε ταξινοµητή να προσµετρηθεί η ϐα-
ϱύτητα του wj, όπου wj είναι η εκτίµηση ακρίβειας του ταξινοµητή που συνή-
ϑως προκύπτει από ένα σύνολο επικύρωσης. Η µέθοδος συνήθως αναφέρεται
ως σταθµισµένος γραµµικός συνδυασµός (weighted linear combination) (Larkey
and Croft, 1996).
− Στη µέθοδο δυναµικής επιλογής ταξινοµητή (dynamic classifier selection) ανάµε-
σα από τους ταξινοµητές h1, . . . , hk επιλέγεται ο ταξινοµητής ο οποίος αποδίδει
καλύτερα σε κείµενα που είναι όµοια µε το υπό εξέταση κείµενο di (Li and Jain,
1998).
− Στη µέθοδο στοιβάγµατος (stacking) υπάρχει ένας µέτα-ταξινοµητής ο οποίος
«µαθαίνει» να συνδυάζει τις αποφάσεις των µελών της οµάδας (Wolpert, 1992).
Μία άλλη δηµοφιλής µέθοδος οµάδων στην ταξινόµηση κειµένων είναι η µέθοδος
boosting (Schapire et al., 1998; Schapire and Singer, 2000).
2.9 Αξιολόγηση µεθόδων ταξινόµησης κειµένων
Η ακρίβεια (precision) και η ανάκληση (recall) είναι δύο δηµοφιλείς µετρικές για την
αξιολόγηση µεθόδων ταξινόµησης κειµένου δανεισµένες από το χώρο της ανάκτησης
πληροφορίας.
Η ακρίβεια σε σχέση µε µία τάξη cj είναι ουσιαστικά η πιθανότητα αν επιλέξουµε
τυχαία ένα κείµενο dx που έχει ταξινοµηθεί στην τάξη cj να είναι σωστή αυτή η τα-
ξινόµηση. Η ανάκληση σε σχέση µε µία τάξη cj αντιπροσωπεύει την πιθανότητα ένα
τυχαίο κείµενο dx της τάξης cj, όντως να ταξινοµήθηκε σε αυτήν την τάξη.
38
2.10. ΤΑΞΙΝΟΜΗΣΗ ΡΟΩΝ ΚΕΙΜΕΝΩΝ
Η ανάκληση και ακρίβεια µπορούν να εκφραστούν σε σχέση µε τον αριθµό των
αληθώς ϑετικών (True Positives), αληθώς αρνητικών (True Negatives - TN), ψευδώς
ϑετικών (False Positives - FP), και ψευδώς αρνητικών (False Negative - FN) ταξινο-
µήσεων που αφορούν την τάξη cj (όπου ϑεωρείται δηλαδή η τάξη cj ως ϑετική) ως
εξής :
Ακρίβεια ως προς cj : Pj =
TPj
TPj + FPj



2.10
Ανάκληση ως προς cj : Rj =
TPj
TPj + FNj



2.11
Η µετρική F-measure αποτελεί το συνδυασµό της ανάκλησης και της ακρίβειας
Μετρική F ως προς cj : Fj =
2 · Pj · Rj
Pj + Rj
=
2 · TPj
2 · TPj + FNj + FPj



2.12
∆ύο µετρικές που αφορούν στη συνολική απόδοση του ταξινοµητή, ανεξαρτήτου
τάξης, είναι η ορθότητα (accuracy):
Ορθότητα =
Ορθές Ταξινοµήσεις
Σύνολο Ταξινοµήσεων
=
TP + TN
TP + TN + FP + FN



2.13
και το σφάλµα (error)
Σφάλµα =
Εσφαλµένες Ταξινοµήσεις
Σύνολο Ταξινοµήσεων
=
FP + FN
TP + TN + FP + FN



2.14
Μία άλλη σηµαντική µετρική αξιολόγησης είναι το εµβαδό κάτω από την καµπύλη
ROC (Receiver Operating Characteristic). Η µετρική µπορεί να εφαρµοστεί σε ταξινο-
µητές που έχουν ως έξοδο εµπιστοσύνη (ϐλέπε Ενότητα 2.3). Σε αυτήν την περίπτωση
ο ταξινοµητής προβλέπει µία τάξη αν η εµπιστοσύνη του για αυτήν ξεπερνάει ένα
κατώφλι. Για το σχηµατισµό της καµπύλης ROC, χρησιµοποιούνται διάφορες τιµές
κατωφλίου και σηµειώνονται κάθε ϕορά τα ποσοστά True Positive Rate (TPR=TP/P)
και False Positive Rate (FPR=FP/N). Αυτά τα Ϲεύγη τιµών σηµειώνονται σε ένα γράφη-
µα όπου ο άξονας y αντιστοιχεί στα TPR και ο άξονας x στα FPR. Τα πλεονεκτήµατα
της µετρικής είναι ότι συγκεντρώνει πληροφορία για την ποιότητα πρόβλεψης του
ταξινοµητή για διάφορες τιµές του κατωφλίου και επίσης είναι ανεξάρτητη από την
ανισορροπία των τάξεων στα δεδοµένα.
2.10 Ταξινόµηση Ροών Κειµένων
΄Οπως αναφέρθηκε και στο εισαγωγικό κεφάλαιο, η ταξινόµηση ϱοών κειµένων παρου-
σιάζει ιδιαίτερο ενδιαφέρον κυρίως λόγω του µεγάλου αριθµού εφαρµογών. Επίσης,
αποτελεί ερευνητική πρόκληση αφού οι κλασικές µέθοδοι δεν είναι άµεσα εφαρµόσι-
µες στις ϱοές. Αυτό οφείλεται στο ότι είναι δυνατή µόνο µία προσπέλαση στα κείµενα
39
ΚΕΦΑΛΑΙΟ 2. ΜΗΧΑΝΙΚΗ ΜΑΘΗΣΗ ΚΑΙ ΤΑΞΙΝΟΜΗΣΗ ΚΕΙΜΕΝΩΝ
ενώ υπάρχουν σηµαντικοί περιορισµοί για τη µνήµη (Gaber et al., 2007; Barbará,
2002; Cheng et al., 2008).
Το πρόβληµα της ταξινόµησης ϱοών κειµένων είναι το ακόλουθο : Σε κάθε χρονική
στιγµή t καταφθάνει ένα κείµενο το οποίο πρέπει να ταξινοµηθεί. Η ϱοή αυτή των κει-
µένων ϑεωρείται άπειρη και εποµένως οι αλγόριθµοι ταξινόµησης δεν είναι δυνατόν να
διατηρήσουν δεδοµένα στη µνήµη. Η προσπέλαση των δεδοµένων εποµένως µπορεί να
γίνει µόνο µία ϕορά. Μετά την ταξινόµηση, η πραγµατική τάξη του κειµένου ϑεωρεί-
ται γνωστή (Kolter and Maloof, 2003, 2005; Wenerstrom and Giraud-Carrier, 2006;
Gama et al., 2004; Kolter and Maloof, 2007) και εποµένως α) µπορεί να υπολογιστεί
η απόδοση του συστήµατος και ϐ) το µοντέλο µάθησης µπορεί να ενηµερωθεί µε το
νέο παράδειγµα. Πολλές ϕορές, συνηθίζεται να γίνεται η υπόθεση ότι τα δεδοµένα
καταφθάνουν σε δέσµες (batches) (Wang et al., 2003; Martin Scholz, 2007).
Συχνό ϕαινόµενο στις ϱοές δεδοµένων είναι η εννοιολογική απόκλιση (concept
drift) κατά την οποία η έννοια µίας τάξης µπορεί να αλλάξει. Για την ταξινόµηση ϱοών
κειµένων εποµένως απαιτούνται µέθοδοι µε δυνατότητα αναγνώρισης και προσαρµο-
γής σε αυτές τις αλλαγές. Υπάρχουν δύο ϐασικά είδη εννοιολογικής απόκλισης : α) η
στιγµιαία ή απότοµη εννοιολογική απόκλιση (instant ή abrupt ή sudden concept drift)
και η σταδιακή εννοιολογική απόκλιση (gradual concept drift).
Στην περίπτωση της απότοµης εννοιολογικής απόκλισης οι έννοιες αλλάζουν ά-
µεσα. ΄Εστω ένας ταξινοµητής ηλεκτρονικού ταχυδροµείο στόχος του οποίου είναι η
αυτόµατη απόκρυψη µηνυµάτων που ϑεωρούνται αδιάφορα για το χρήστη. Ο χρήστης
ενηµερώνει το σύστηµα για τα ενδιαφέροντά του σηµειώνοντας τα µηνύµατα ως «εν-
διαφέροντα» ή «αδιάφορα». ΄Ενας χρήστης που είναι εγγεγραµµένος σε λίστα σχετική
µε υπολογιστές µπορεί άµεσα να σταµατήσει να ενδιαφέρεται για µηνύµατα που πε-
ϱιέχουν κριτικές ϕορητών υπολογιστών µετά την αγορά ενός ϕορητού υπολογιστή. Ο
ταξινοµητής πρέπει άµεσα να προσαρµοστεί σε αυτή την αλλαγή έτσι ώστε να ταξινοµεί
µε ακρίβεια τα µηνύµατα.
΄Ενα παράδειγµα σταδιακής απόκλισης µπορεί να εντοπιστεί στη διήθηση ανε-
πιθύµητης (spam) αλληλογραφίας. Τα µηνύµατα spam αλλάζουν (συνήθως γίνεται
δυσκολότερος ο εντοπισµός τους) µε ένα συγκεκριµένο ϱυθµό. Και σε αυτή την περί-
πτωση, ο ταξινοµητής πρέπει να έχει τη δυνατότητα να παρακολουθήσει τις αλλαγές
αυτές και να διατηρήσει όσο γίνεται σταθερή την απόδοση του.
Μία ενδιαφέρουσα περίπτωση που µπορεί να παρουσιαστεί και στη στιγµιαία αλλά
και στην απότοµη απόκλιση είναι η επανεµφάνιση κάποιον εννοιών σε διαφορετικές
περιόδους. Στην περίπτωση του ταξινοµητή ηλεκτρονικών µηνυµάτων για παράδειγ-
µα, ο χρήσης µπορεί να επανακτήσει το ενδιαφέρον του σε ϑέµατα που ενδιαφερόταν
στο παρελθόν. Επιπλέον, στο δεύτερο παράδειγµα, υπάρχουν κάποιες οµάδες spam
µηνυµάτων που επανεµφανίζονται συγκεκριµένες χρονικές περιόδους (π.χ. spam µη-
νύµατα που αφορούν δώρα για τη γιορτή της µητέρας ή για τα Χριστούγεννα). Αυτός
ο τύπος εννοιολογικής απόκλισης αναφέρεται στη ϐιβλιογραφία ως επανεµφανιζόµε-
νες έννοιες (Widmer and Kubat, 1996) ή επαναλαµβανόµενα ϑέµατα (recurrent the-
mes)(Forman, 2006). Σε αυτήν την περίπτωση το σύστηµα ϑα πρέπει να αναγνωρίζει
40
2.10. ΤΑΞΙΝΟΜΗΣΗ ΡΟΩΝ ΚΕΙΜΕΝΩΝ
τις επανεµφανιζόµενες έννοιες και να επαναφέρει παλιότερα µοντέλα µάθησης.
Ο Tsymbal (2004) συγκεντρώνει τα χαρακτηριστικά ενός ιδανικού συστήµατος δια-
χείρισης δεδοµένων µε εννοιολογική απόκλιση στα παρακάτω σηµεία :
− Γρήγορη προσαρµογή στην εννοιολογική απόκλιση
− Ανθεκτικότητα στο ϑόρυβο και διάκρισή του από την εννοιολογική απόκλιση
− Ικανότητα να αναγνωρίζει και να αντιδρά στις επανεµφανιζόµενες έννοιες
΄Εχει παρατηρηθεί ότι οι µεθοδολογίες που αφορούν στην αντιµετώπιση της εννοιο-
λογικής απόκλισης µπορούν να οργανωθούν σε τρεις κύριες οµάδες (Tsymbal, 2004)
που είναι η επιλογή παραδειγµάτων (instance selection), τα παραδείγµατα µε ϐάρη
(instance weighting) και οι οµάδες ταξινοµητών (ensemble methods). Επιπλέον, υ-
πάρχει µία πρόσθετη οµάδα που αποτελείται από προσαρµοστικούς αλγορίθµους. Σε
αυτήν την ενότητα παρουσιάζουµε αυτές τις οµάδες σχολιάζοντας α) τις κύριες πα-
ϱαδοχές που γίνονται σε αυτές ϐ) τα πλεονεκτήµατα και τα µειονεκτήµατα τους και
γ) τις απαιτήσεις που χρειάζεται να πληρούν οι ταξινοµητές έτσι ώστε να µπορούν να
χρησιµοποιηθούν από τις αντίστοιχες µεθόδους.
2.10.1 Επιλογή Παραδειγµάτων
Στις µεθόδους επιλογής παραδειγµάτων, τα προτεινόµενα συστήµατα προσπαθούν να
επιλέξουν τα καταλληλότερα παραδείγµατα του ιστορικού της ϱοής µε στόχο να ταξι-
νοµήσουν τα αντικείµενα που ακολουθούν. Τυπικοί αντιπρόσωποι αυτής της οµάδας
είναι τα κινούµενα παράθυρα (moving windows) (γνωστά και ως παράθυρα χρόνου -
time windows)3 όπου ο ταξινοµητής εκπαιδεύεται από ένα κινούµενο παράθυρο παρα-
δειγµάτων σταθερού ή µεταβαλλόµενου µήκους (Klinkenberg and Joachims, 2000).
Στις περισσότερες περιπτώσεις, το παράθυρο αποτελείται από τα τελευταία w παρα-
δείγµατα της ϱοής. Η υπόθεση που γίνεται σε αυτές τις µεθόδους είναι ότι τα παλιότερα
παραδείγµατα δε χρειάζονται για τις ταξινοµήσεις νέων δεδοµένων. Συνεπώς, η προ-
σαρµογή στην εννοιολογική απόκλιση σηµαίνει ουσιαστικά την αφαίρεση των παλιών
παραδειγµάτων από το µοντέλο (Widmer and Kubat, 1996; Klinkenberg, 2004). Για
την ενσωµάτωση ενός ταξινοµητή σε ένα πλαίσιο κινούµενου παραθύρου απαραίτητη
είναι η υλοποίηση δύο συναρτήσεων µε τις οποίες ϑα ενσωµατώνονται ή ϑα αφαι-
ϱούνται παραδείγµατα στο/από το µοντέλο. Το κύριο πλεονέκτηµα των κινούµενων
παραθύρων είναι το γεγονός ότι ο ταξινοµητής µοντελοποιεί συνεχώς την τελευταία δέ-
σµη παραδειγµάτων και εποµένως µπορεί να παράγει σωστές προβλέψεις ακόµη και
σε περιβάλλοντα µε εννοιολογική απόκλιση. Αν και το πρόβληµα του ορισµού του µή-
κους του παραθύρου έχει λυθεί µε τη χρήση των παραθύρων µεταβαλλόµενου µήκους
3Πολύ συχνά στην ταξινόµηση ϱοών δεδοµένων, η ϱοή µοντελοποιείται ως σειρά από παραδείγµατα
χωρίς να λαµβάνεται υπόψη η χρονική ετικέτα (time stamp) του κάθε παραδείγµατος (στιγµή άφιξης).
΄Ετσι, ϑεωρούµε τον όρο «κινούµενα παράθυρα» καταλληλότερο για αυτές τις περιπτώσεις.
41
ΚΕΦΑΛΑΙΟ 2. ΜΗΧΑΝΙΚΗ ΜΑΘΗΣΗ ΚΑΙ ΤΑΞΙΝΟΜΗΣΗ ΚΕΙΜΕΝΩΝ
(adaptive time windows) (Klinkenberg and Joachims, 2000) οι προσεγγίσεις αυτής
της οµάδας δεν αντιµετωπίζουν τις επανεµφανιζόµενες έννοιες.
΄Αλλες προσεγγίσεις που µπορούν να συµπεριληφθούν σε αυτήν την οµάδα είναι
οι µέθοδοι που διατηρούν ένα σηµαντικό αριθµό παραδειγµάτων στη µνήµη µε στόχο
τη δυναµική δηµιουργία ενός συνόλου εκπαίδευσης για τον ταξινοµητή (Klinkenberg,
2004; Fan, 2004; Sarah Jane Delany, 2005). Αν και η ιδέα της χρήσης του ιστορικού
της ϱοής είναι σωστή (ειδικά στην περίπτωση των επαναλαµβανόµενων εννοιών) οι πε-
ϱιορισµοί της µνήµης στις ϱοές δεδοµένων κάνουν τέτοιες προσεγγίσεις µη πρακτικές.
2.10.2 Παραδείγµατα µε Βάρη
Στα παραδείγµατα µε ϐάρη, η κύρια υπόθεση είναι ότι η γνώση που αποκτάται από
παλιά παραδείγµατα γίνεται λιγότερο σηµαντική µε το πέρασµα του χρόνου. ΄Ολα τα
παραδείγµατα λαµβάνονται υπόψη για την ανάπτυξη του ταξινοµητή αλλά τα νεότερα
παραδείγµατα έχουν µεγαλύτερη επίδραση. Για το σκοπό αυτό, ορίζεται µία συνάρ-
τηση απόδοσης ϐαρών (Klinkenberg, 2004). Για να ενσωµατωθεί ένας ταξινοµητής σε
αυτό το πλαίσιο µάθησης πρέπει να είναι επαυξητικός αλλά και να υποστηρίζει µάθηση
µε ϐάρη. Ο ταξινοµητής naive Bayes για παράδειγµα πληροί αυτές τις προϋποθέσεις.
Στην περίπτωση της εννοιολογικής απόκλισης η µάθηση µε ϐάρη ϐοηθάει το µοντέ-
λο να προσαρµοστεί γρήγορα αλλά στη περίπτωση των επανεµφανιζόµενων εννοιών το
σύστηµα ϑα αποτύχει να χρησιµοποιήσει αποτελεσµατικά τα παλιότερα παραδείγµατα.
2.10.3 Μέθοδοι οµάδων ταξινοµητών
Στις µεθόδους οµάδας, η κύρια στρατηγική είναι η διατήρηση ενός δυναµικού συνό-
λου ταξινοµητών. ΄Οταν παρατηρείται πτώση στην απόδοση, νέα µοντέλα προστίθενται
στην οµάδα ενώ τα παλιότερα και µη αποδοτικά µοντέλα αφαιρούνται. Για την παρα-
γωγή πρόβλεψης, οι αποφάσεις των µοντέλων της οµάδας συνήθως συνδυάζονται µε τη
µέθοδο της ψηφοφορίας (Street and Kim, 2001; Wang et al., 2003; Martin Scholz,
2007; Kolter and Maloof, 2003; Zhu et al., 2006; Kolter and Maloof, 2007). Το πλε-
ονέκτηµα των µεθόδων οµάδων σε σχέση µε τους απλούς ταξινοµητές έχει αποδειχθεί
πειραµατικά και ϑεωρητικά (Wang et al., 2003; Kolter and Maloof, 2005). Παρό-
λα αυτά, λίγες µόνο µέθοδοι σχεδιάστηκαν για να αναγνωρίζουν επανεµφανιζόµενες
έννοιες (Widmer and Kubat, 1996; Harries et al., 1998; Forman, 2006).
Συγκεκριµένα, στο πρόβληµα των επανεµφανιζόµενων εννοιών, τα µοντέλα της ο-
µάδας ϑα έπρεπε να διατηρούνται στη µνήµη ακόµη και αν δεν αποδίδουν καλά στην
τελευταία δέσµη δεδοµένων. Επιπλέον, κάθε ταξινοµητής ϑα πρέπει να εξειδικεύεται
σε µία µοναδική έννοια, να εκπαιδεύεται δηλαδή από δεδοµένα που ανήκουν σε αυτήν
την έννοια και να χρησιµοποιείται για την ταξινόµηση παρόµοιων δεδοµένων.
Στην εργασία (Harries et al., 1998) προτείνεται µία µεθοδολογία που αναγνωρίζει
τις έννοιες οµαδοποιώντας τους ταξινοµητές παρόµοιας απόδοσης. Στους ταξινοµητές
ανατίθενται ϐάρη σύµφωνα µε την απόδοσή τους στην τελευταία δέσµη δεδοµένων
και η τελική πρόβλεψη προκύπτει χρησιµοποιώντας σταθµισµένη ψηφοφορία. Αν και
42
2.11. ΤΑΞΙΝΟΜΗΣΗ ΚΕΙΜΕΝΩΝ ΠΟΛΛΑΠΛΩΝ ΕΤΙΚΕΤΩΝ
αυτή η προσέγγιση ταιριάζει αρκετά µε το πρόβληµα των επανεµφανιζόµενων εννοιών
περιλαµβάνει ένα στάδιο ανάλυσης του συνόλου εκπαίδευσης για την ανακάλυψη των
εννοιών που δεν είναι κατάλληλο για ϱοές δεδοµένων. Συγκεκριµένα, το πλαίσιο
αυτό δε ϑα αποδώσει καλά στη περίπτωση που στη ϱοή εµφανιστούν έννοιες που δεν
εµφανίζονται στο σύνολο εκπαίδευσης.
Μία ενδιαφέρουσα ιδέα παρουσιάζεται από τον Forman στην εργασία (Forman,
2006), όπου ένας µεγάλος αριθµός από «καθηµερινούς ταξινοµητές» (daily classifiers)
διατηρείται στη µνήµη. Οι προβλέψεις αυτών των ταξινοµητών για τα νέα δεδοµένα
ενσωµατώνονται ως επιπλέον χαρακτηριστικά στους πιο πρόσφατους ταξινοµητές οι ο-
ποίοι µαθαίνουν να τα χρησιµοποιούν έτσι ώστε να παράγουν καλύτερες ταξινοµήσεις.
∆υστυχώς, η µέθοδος δεν εµπεριέχει κάποιο µηχανισµός αναγνώρισης των επανεµφα-
νιζόµενων εννοιών.
Στο Κεφάλαιο 4 αυτής της διατριβής παρουσιάζεται µία µέθοδος που αναγνωρίζει
δυναµικά τις έννοιες που εµφανίζονται και διατηρεί έναν ταξινοµητή για κάθε µία από
αυτές.
2.10.4 Προσαρµοστικοί Αλγόριθµοι
Μέθοδοι όπως ο CVFDT (Hulten et al., 2001) (Concept-adapting Very Fast Decision
Tree learner) προσαρµόζονται γρήγορα στη νεότερη δέσµη δεδοµένων µε στόχο την αν-
τιµετώπιση της απόκλισης. Συγκεκριµένα, ο CVFDT αποτελεί ένα δένδρο απόφασης
το οποίο προσαρµόζεται σύµφωνα µε την τελευταία δέσµη δεδοµένων αναπτύσσοντας
ένα νέο υπο-δένδρο όταν ένα ένα παλιό υπο-δένδρο δεν αποδίδει ικανοποιητικά. ΄Οταν
το νέο αρχίσει και αποδίδει ικανοποιητικά αντικαθιστά το παλιό. Μία σχετική µέθοδος
παρουσιάζεται στην εργασία (Kalles and Morris, 1996). ∆υστυχώς, οι µέθοδοι αυ-
τής της κατηγορίας δεν έχουν σχεδιαστεί για την αναγνώριση των επανεµφανιζόµενων
εννοιών.
2.11 Ταξινόµηση Κειµένων Πολλαπλών Ετικετών
Ιδιαίτερο ενδιαφέρον παρουσιάζει η ταξινόµηση κειµένων πολλαπλών ετικετών κυρίως
λόγω του µεγάλου αριθµού εφαρµογών. Στην ενότητα αυτή αναφέρουµε τις αντι-
προσωπευτικότερες µεθόδους ταξινόµησης πολλαπλών ετικετών οι οποίες µπορούν να
οµαδοποιηθούν σε δύο κατηγορίες (Tsoumakas and Katakis, 2007)(Tsoumakas, Ka-
takis and Vlahavas, 2009a): α) µέθοδοι µετασχηµατισµού προβλήµατος (problem tran-
sformation methods) και ϐ) µέθοδοι προσαρµογής αλγορίθµου (algorithm adaptation
methods). Στην πρώτη οµάδα µετασχηµατίζεται το πρόβληµα σε ένα ή περισσότερα
προβλήµατα µονής ετικέτας για τα οποία είναι διαθέσιµος µεγάλος αριθµός αλγο-
ϱίθµων. Οι µέθοδοι της δεύτερης οµάδας, επεκτείνουν συγκεκριµένους αλγορίθµους
µάθησης έτσι ώστε να χειρίζονται απευθείας δεδοµένα πολλαπλών ετικετών.
Για την αναλυτική περιγραφή των µεθόδων αυτών ϑα χρησιµοποιήσουµε το σύνολο
L = {λj : j = 1 . . . M} για τον ορισµό ενός πεπερασµένου συνόλου ετικετών σε ένα πρό-
43
ΚΕΦΑΛΑΙΟ 2. ΜΗΧΑΝΙΚΗ ΜΑΘΗΣΗ ΚΑΙ ΤΑΞΙΝΟΜΗΣΗ ΚΕΙΜΕΝΩΝ
ϐληµα πολλαπλών ετικετών και D = {(~xi , Yi), i = 1 . . . N} το σύνολο N παραδειγµάτων
πολλαπλών ετικετών, όπου ~xi είναι το διάνυσµα χαρακτηριστικών και Yi ⊆ L το σύνολο
των ετικετών του παραδείγµατος i.
2.11.1 Μέθοδοι Μετασχηµατισµού Προβλήµατος
Οι µέθοδοι µετασχηµατισµού ϑα περιγραφούν µε τη ϐοήθεια του συνόλου παραδειγ-
µάτων πολλαπλών ετικετών που ϕαίνεται στον Πίνακα 2.1. Αποτελείται από τέσσερα
παραδείγµατα κάθε ένα από τα οποία χαρακτηρίζεται µε κάποιες από τις τέσσερις
ετικέτες : λ1, λ2, λ3, λ4.
Παράδειγµα Σύνολο Ετικετών
1 {λ1, λ4}
2 {λ3, λ4}
3 {λ1}
4 {λ2, λ3, λ4}
Πίνακας 2.1: Παράδειγµα συνόλου πολλαπλών ετικετών
Η µέθοδος δυναµοσυνόλου ετικετών Label Powerset (LP) είναι µία απλή και αποδο-
τική µέθοδος µετασχηµατισµού που λειτουργεί ως εξής : Θεωρεί κάθε σύνολο ετικετών
που υπάρχει στα δεδοµένα εκπαίδευσης ως τάξη για ένα νέο πρόβληµα ταξινόµησης
µονής ετικέτας. Ο Πίνακας 2.2 παρουσιάζει το αποτέλεσµα του µετασχηµατισµού των
δεδοµένων χρησιµοποιώντας τη µέθοδο LP.
Παράδειγµα Ετικέτα
1 λ1,4
2 λ3,4
3 λ1
4 λ2,3,4
Πίνακας 2.2: Μετασχηµατισµένα δεδοµένα µε τη µέθοδο LP
∆εδοµένου ενός νέου παραδείγµατος, ο ταξινοµητής απλής ετικέτας του LP έχει ως
έξοδο την πιο πιθανή τάξη που ουσιαστικά αντιστοιχεί σε ένα σύνολο από ετικέτες. Η
υπολογιστική πολυπλοκότητα του LP σε σχέση µε το M εξαρτάται από την πολυπλο-
κότητα του αλγορίθµου µονής ετικέτας σε σχέση µε τον αριθµό των τάξεων. Ο αριθµός
αυτός είναι ίσος µε το συνολικό αριθµό των διακριτών συνόλων ετικετών στο σύνολο
παραδειγµάτων. ΄Εχει άνω όριο την τιµή min(N, 2M ) και παρόλο που συνήθως είναι
πολύ µικρότερος, παρουσιάζει σηµαντικό πρόβληµα πολυπλοκότητας ειδικά για µε-
γάλες τιµές του N και του M. Ο µεγάλος αριθµός των τάξεων πολλές από τις οποίες
σχετίζονται µε λίγα δεδοµένα, κάνει τη διαδικασία της µάθησης ιδιαίτερα δύσκολη.
Μία επέκταση του LP αποτελεί η µέθοδος PPT (pruned problem transformation)
(Read, 2008). Η µέθοδος αυτή «κλαδεύει» τα σύνολα ετικετών που παρουσιάζουν
44
2.11. ΤΑΞΙΝΟΜΗΣΗ ΚΕΙΜΕΝΩΝ ΠΟΛΛΑΠΛΩΝ ΕΤΙΚΕΤΩΝ
λιγότερες εµφανίσεις από ένα κατώφλι (συνήθως είναι ένας µικρός αριθµός π.χ. 2 ή 3).
Τα σύνολα που απορρίφθηκαν διασπώνται σε ξένα υποσύνολα τα οποία εµφανίζονται
περισσότερες ϕορές από το κατώφλι και µε αυτόν τον τρόπο διατηρείται η πληροφορία
που περιέχουν.
Η µέθοδος δυαδικής συνάφειας (Binary Relevance - BR) είναι µία δηµοφιλής µέ-
ϑοδος µετασχηµατισµού στην οποία εκπαιδεύονται M δυαδικοί ταξινοµητές, ένας για
κάθε ετικέτα του L. Το αρχικό σύνολο δεδοµένων µετασχηµατίζεται σε M σύνολα δε-
δοµένων Dλj , j = 1 . . . M που περιέχουν παραδείγµατα του αρχικού συνόλου. ΄Ενα
παράδειγµα ϑεωρείται ϑετικό αν το αρχικό σύνολο ετικετών περιέχει την λj ή αρνητικό
στην αντίθετη περίπτωση. Για την ταξινόµηση ενός νέου αντικειµένου, ο BR έχει ως
έξοδο την ένωση των ετικετών λj που προβλέπουν οι M ταξινοµητές. Το Σχήµα 2.2
παρουσιάζει τα τέσσερα σύνολα που δηµιουργούνται από τον BR όταν εφαρµόζεται στο
αρχικό σύνολο του Πίνακα 2.1.
Παρ. Ετικέτα
1 λ1
2 ¬λ1
3 λ1
4 ¬λ1
(α΄)
Παρ. Ετικέτα
1 ¬λ2
2 ¬λ2
3 ¬λ2
4 λ2
(ϐ΄)
Παρ. Ετικέτα
1 ¬λ3
2 λ3
3 ¬λ3
4 λ3
(γ΄)
Παρ. Ετικέτα
1 λ4
2 λ4
3 ¬λ4
4 λ4
(δ΄)
Σχήµα 2.2: Σύνολα δεδοµένων που προέκυψαν µε τη µέθοδο BR
Στο Κεφάλαιο 5 παρουσιάζονται δύο µέθοδοι µετασχηµατισµού προβλήµατος που
στοχεύουν στην αντιµετώπιση προβληµάτων µε µεγάλο αριθµό ετικετών.
2.11.2 Μέθοδοι Προσαρµογής Αλγορίθµων
Σε αυτήν την ενότητα παρουσιάζονται µέθοδοι προσαρµογής αλγορίθµων οργανωµένοι
σύµφωνα µε την τεχνική µάθησης που επεκτείνουν.
∆ένδρα Απόφασης και Boosting Ο αλγόριθµος C4.5 προσαρµόστηκε από τους
Clare και King (2001) έτσι ώστε να χειρίζεται δεδοµένα πολλαπλών ετικετών. Συγκε-
κριµένα, στα ϕύλλα των δένδρων επιτρέπονται πολλαπλές ετικέτες ενώ ο υπολογισµός
της εντροπίας γίνεται όπως ϕαίνεται παρακάτω :
Entropy(D) = −
M∑
j=1
(
p(λj)logp(λj) + q(λj)logq(λj)
) 


2.15
όπου p(λj) είναι η σχετική συχνότητα της ετικέτας λj και q(λj) = 1 − p(λj).
Οι µέθοδοι AdaBoost.MH και AdaBoost.MR (Schapire and Singer, 2000) είναι
δύο προεκτάσεις της µεθόδου AdaBoost για δεδοµένα πολλαπλών ετικετών. Ενώ η
AdaBoost.MH είναι σχεδιασµένη για να ελαχιστοποιεί την απώλεια Hamming (ϐλέπε
45
ΚΕΦΑΛΑΙΟ 2. ΜΗΧΑΝΙΚΗ ΜΑΘΗΣΗ ΚΑΙ ΤΑΞΙΝΟΜΗΣΗ ΚΕΙΜΕΝΩΝ
Ενότητα 2.11.4) η AdaBoost.MR είναι σχεδιασµένη για να δηµιουργεί µία υπόθεση η
οποία παράγει µία κατάταξη ετικετών µε τις σχετικές ετικέτες για το παράδειγµα στις
κορυφαίες ϑέση αυτής.
΄Ενας συνδυασµός της AdaBoost.MH και ενός αλγορίθµου εναλλασσόµενων δέν-
δρων απόφασης (alternating decision trees) παρουσιάζεται στην εργασία (de Comite
et al., 2003). Το κύριο κίνητρο ήταν η παραγωγή µοντέλων ταξινόµησης πολλαπλών
ετικετών που να είναι εύκολα κατανοητά από ανθρώπους.
Πιθανοτικοί Μέθοδοι ΄Ενα παραγωγικό (generative) µοντέλο προτείνεται στην ερ-
γασία (McCallum, 1999) σύµφωνα µε το οποίο, κάθε ετικέτα δηµιουργεί (ή αποτελείται
από) διαφορετικές λέξεις. Βάσει αυτού του µοντέλου ένα κείµενο πολλαπλών ετικε-
τών παράγεται (δηµιουργείται) από το συνδυασµό των κατανοµών των λέξεων όλων των
ετικετών του. ΄Ενα παρόµοιο µοντέλο µικτής κατανοµής λέξεων (word based mixtu-
re model) για ταξινόµηση κειµένων πολλαπλών ετικετών παρουσιάζεται στην εργασία
(Ueda and Saito, 2003). Μία προσέγγιση αποσύνθεσης (deconvolution) προτείνεται
στην εργασία (Streich and Buhmann, 2008), µε στόχο να εντοπιστεί η συνεισφορά της
κάθε ετικέτας στο υπο εξέταση αντικείµενο.
Νευρωνικά ∆ίκτυα και Μηχανές ∆ιανυσµάτων Υποστήριξης Ο αλγόριθµος BP-
MLL (Zhang and Zhou, 2006) είναι µία προσαρµογή του δηµοφιλούς αλγορίθµου
ανάστροφης µετάδοσης σφάλµατος (error backpropagation) για δεδοµένα πολλαπλών
ετικετών. Η κύρια µετατροπή στον αλγόριθµο είναι µία νέα συνάρτηση σφάλµατος που
λαµβάνει υπόψη τις πολλαπλές ετικέτες.
Ο αλγόριθµος perceptron πολλαπλών ετικετών (multi-class multi-label perceptron
-MMP) (Crammer and Singer, 2003) αποτελεί µία οµάδα επαυξητικών µεθόδων για
κατάταξη ετικετών σε δεδοµένα πολλαπλών ετικετών. Ο MMP διατηρεί έναν perceptron
για κάθε ετικέτα αλλά τα ϐάρη ενηµερώνονται µε τέτοιο τρόπο ώστε να ϐελτιστοποιηθεί
η κατάταξη των ετικετών.
Τρεις προσεγγίσεις του BR µε χρήση µηχανών διανυσµάτων υποστήριξης προ-
τείνονται στην εργασία (Godbole and Sarawagi, 2004). Η πρώτη (SVM-HF) αφορά
την επέκταση του αρχικού συνόλου δεδοµένων µε M επιπλέον χαρακτηριστικά τα ο-
ποία περιλαµβάνουν τις προβλέψεις όλων των δυαδικών ταξινοµητών. Στη συνέχεια,
ακολουθεί ένα δεύτερο στάδιο εκπαίδευσης µε το εµπλουτισµένο πλέον σύνολο δε-
δοµένων. Για την ταξινόµηση ενός νέου παραδείγµατος αρχικά χρησιµοποιούνται οι
δυαδικοί ταξινοµητές του πρώτου ϐήµατος και η έξοδός τους προστίθεται στο υπο-
εξέταση παράδειγµα έτσι ώστε να δηµιουργηθεί τελικά ένα µετα-διάνυσµα. Αυτό το
µετα-διάνυσµα ταξινοµείται από τους δυαδικούς ταξινοµητές του δεύτερου επιπέδου.
Χρησιµοποιώντας αυτήν την επέκταση η προσέγγιση λαµβάνει υπόψη της τις πιθανές
συσχετίσεις µεταξύ των ετικετών.
Η δεύτερη προσσέγγιση (BandSVM), µετά την εκπαίδευση των δυαδικών SVMs
αφαιρεί τα αρνητικά παραδείγµατα που είναι αποµακρυσµένα από το υπερ-επίπεδο
46
2.11. ΤΑΞΙΝΟΜΗΣΗ ΚΕΙΜΕΝΩΝ ΠΟΛΛΑΠΛΩΝ ΕΤΙΚΕΤΩΝ
απόφασης και επανεκπαιδεύει τα SVMs. Η τρίτη προσέγγιση (ConfMat) αφορά την
αφαίρεση των παραδειγµάτων των «συγχεόµενων» (confusing) τάξεων.
Μέθοδοι Οκνηρής Μάθησης και Κανόνων Συσχέτισης Στη ϐιβλιογραφία έχει
παρουσιαστεί ένας σηµαντικός αριθµός από µεθόδους που στηρίζονται στους αλγορίθ-
µους οκνηρής µάθησης και στον ταξινοµητή kΝΝ που είδαµε στην Ενότητα 2.8.5 (Luo
and Zincir-Heywood, 2005; Wieczorkowska et al., 2006; Brinker and Hullermeier,
2007; Zhang and Zhou, 2007; Spyromitros et al., 2008). Το πρώτο στάδιο σε όλες
αυτές τις µεθόδους, είναι η ανάκτηση των k κοντινότερων παραδειγµάτων. Αυτό που
τις διαφοροποιεί είναι ο τρόπος µε τον οποίο χρησιµοποιούν τις ετικέτες αυτών των πα-
ϱαδειγµάτων ώστε να παράξουν µία πρόβλεψη. Χαρακτηριστικός αντιπρόσωπος αυτών
των µεθόδων είναι ο αλγόριθµος ML-kNN (Zhang and Zhou, 2007).
Η µέθοδος MMAC (Thabtah et al., 2004) εξάγει κανόνες χρησιµοποιώντας αλγο-
ϱίθµους από την περιοχή των κανόνων συσχέτισης (association rule mining) (Agrawal
et al., 1993). Στη συνέχεια αφαιρούνται τα παραδείγµατα που σχετίζονται µε αυτούς
τους κανόνες και η διαδικασία συνεχίζεται στα εναποµείναντα παραδείγµατα έως ότου
δεν εµφανίζονται άλλα συχνά σύνολα (frequent itemsets) αντικειµένων. Οι κανόνες
που προκύπτουν µπορεί να έχουν κοινές προϋποθέσεις αλλά διαφορετικά συµπερά-
σµατα (τάξεις). ΄Ετσι, µπορούν να ενωθούν µε στόχο τη δηµιουργία κανόνων πολλαπλών
ετικετών.
Τέλος µία µέθοδος που συνδυάζει οκνηρή µάθηση µε κανόνες συσχέτισης περι-
γράφεται στην εργασία (Veloso et al., 2007) όπου η διαδικασία µάθησης αναβάλλεται
µέχρι την αίτηση για ταξινόµηση ενός αντικειµένου.
2.11.3 Ιεραρχική ταξινόµηση πολλαπλών ετικετών
Στην ταξινόµηση κειµένων πολλαπλών ετικετών, πολλές ϕορές οι ετικέτες είναι ορ-
γανωµένες σε µία ιεραρχία. Παραδείγµατα τέτοιων ιεραρχιών αποτελούν η ιεραρχία
MeSH 4 που αφορά σε ιατρικά άθρα, η ταξινοµία της ACM5 που στοχεύει στην οργά-
νωση άρθρων επιστήµης υπολογιστών αλλά και ο διαδικτυακός κατάλογος dmoz6. Σε
µία τέτοια δοµή συνήθως υπονοείται ότι ένα αντικείµενο µπορεί να σχετίζεται µε µία
ετικέτα λ µόνο αν σχετίζεται και µε τη ετικέτα-γονέα του parent(λ).
∆εδοµένης µίας ιεραρχίας ετικετών, ένας απλός τρόπος να αναπτυχθεί ένας ταξι-
νοµητής πολλαπλών ετικετών είναι η εκπαίδευση ενός δυαδικού ταξινοµητή για κάθε
κόµβο-ετικέτα της ιεραρχίας (εκτός της ϱίζας) χρησιµοποιώντας ως παραδείγµατα τα
δεδοµένα που χαρακτηρίζονται από την ετικέτα parent(λ). Για την ταξινόµηση, ένα
αντικείµενο ξεκινάει από τη ϱίζα και προωθείται κάθε ϕορά στο κόµβο-παιδί για την
ετικέτα λ µόνο αν ο ταξινοµητής parent(λ) έχει δώσει ϑετική έξοδο. Η µέθοδος αυ-
τή ονοµάζεται Ιεραρχική ∆υαδική Συσχέτιση (Hierarchical Binary Relevance - HBR)
4www.nlm.nih.gov/mesh/
5www.acm.org/class/
6Open Directory Project - www.dmoz.org
47
ΚΕΦΑΛΑΙΟ 2. ΜΗΧΑΝΙΚΗ ΜΑΘΗΣΗ ΚΑΙ ΤΑΞΙΝΟΜΗΣΗ ΚΕΙΜΕΝΩΝ
(Tsoumakas et al., 2009a).
΄Ενας επαυξητικός ιεραρχικός αλγόριθµος που ακολουθεί την προσέγγιση HBR
χρησιµοποιώντας εκτιµητές ελαχίστων τετραγώνων σε κάθε κόµβο παρουσιάζεται στην
εργασία (Cesa-Bianchi et al., 2006) ενώ στην ίδια εργασία παρατηρούνται καλύτερα
αποτελέσµατα χρησιµοποιώντας perceptrons.
Η προσέγγιση HBR µπορεί εύκολα να γενικευτεί έτσι ώστε αντί του BR να χρη-
σιµοποιηθεί ένας οποιοσδήποτε ταξινοµητής πολλαπλών ετικετών σε κάθε εσωτερικό
κόµβο της ιεραρχίας. Η προσέγγιση TreeBoost.MH (Esuli et al., 2008) για παράδειγµα
χρησιµοποιεί τον ταξινοµητή AdaBoost.MH (ϐλέπε Ενότητα 2.11.2) σε κάθε εσωτερικό
κόµβο της ιεραρχίας (δηλαδη εκτός των ϕύλλων). Πειραµατικά αποτελέσµατα αποδει-
κνύουν ότι η TreeBoost.MH όχι µόνο είναι αποδοτικότερη στο χρόνο εκπαίδευσης και
ταξινόµησης αλλά παράγει και καλύτερες προβλέψεις.
΄Αλλες ιεραρχικές µέθοδοι παρουσιάζονται στις εργασίες (Blockeel et al., 2006;
Rousu et al., 2006).
2.11.4 Αξιολόγηση ταξινόµησης πολλαπλών ετικετών
Η αξιολόγηση µεθόδων µάθησης από δεδοµένα πολλαπλών ετικετών απαιτεί διαφορε-
τικές µετρικές από αυτές που χρησιµοποιούνται στα δεδοµένα µονής-ετικέτας. Στη
ϐιβλιογραφία, έχουν οριστεί µετρικές ταξινόµησης και κατάταξης πολλαπλών ετικετών.
Σε αυτήν τη διατριβή αντιµετωπίστηκε το πρόβληµα της ταξινόµησης και κατά συνέ-
πεια ϑα αναφερθούν µόνο µετρικές που αναφέρονται σε αυτήν. Για µία επισκόπηση
των µετρικών κατάταξης ο αναγνώστης µπορεί να ανατρέξει στην εργασία (Tsoumakas
et al., 2009a).
Για τον ορισµό αυτών των µετρικών ϑεωρούµε ένα σύνολο παραδειγµάτων (~xi , Yi),
i = 1 . . . N όπου Yi ⊆ L είναι το σύνολο των πραγµατικών ετικετών και L = {λj : j =
1 . . . M} είναι το σύνολο όλων των ετικετών. ∆εδοµένου ενός στιγµιότυπου ~xi , το σύνολο
των ετικετών που προβλέπει ένας ταξινοµητής πολλαπλών ετικετών δηλώνεται ως Zi .
Υπάρχουν δύο διαφορετικές προσεγγίσεις για τον υπολογισµό των µετρικών αξιο-
λόγησης. Οι µετρικές ϐάσει παραδειγµάτων (item based) στηρίζονται στον υπολογισµό
των αποστάσεων µεταξύ του συνόλου ετικετών που προβλέπεται από τον ταξινοµητή µε
το πραγµατικό σύνολο ετικετών. Στη συνέχεια υπολογίζεται ο µέσος όρος των αποστά-
σεων για όλα τα παραδείγµατα. Οι µετρικές ϐάσει ετικετών (label based) αξιολογούν
την ορθότητα πρόβλεψης για κάθε ετικέτα ξεχωριστά ώστε να υπολογιστεί ένας µέσος
όρος αυτών των αξιολογήσεων.
Μετρικές ϐάσει παραδειγµάτων
Η απώλεια Hamming (Hamming Loss) (Schapire and Singer, 2000) ορίζεται όπως
παρακάτω :
Απώλεια Hamming =
1
N
N∑
i=1
|Yi△Zi |
M



2.16
48
2.11. ΤΑΞΙΝΟΜΗΣΗ ΚΕΙΜΕΝΩΝ ΠΟΛΛΑΠΛΩΝ ΕΤΙΚΕΤΩΝ
όπου △ αντιπροσωπεύει τη συµµετρική διαφορά των δύο συνόλων, που είναι ουσιαστι-
κά ισοδύναµο µε τη συνάρτηση XOR της λογικής Bool.
Η ιεραρχική απώλεια (Hierarchical Loss) (Cesa-Bianchi et al., 2006) είναι µία
τροποποιηµένη έκδοση της απώλειας Hamming η οποία λαµβάνει υπόψη της την
ιεραρχική δοµή των ετικετών. Εξετάζει τις ετικέτες που προβλέπονται από πάνω προς
τα κάτω σύµφωνα µε την ιεραρχία και όπου η πρόβλεψη για µία ετικέτα είναι λάθος,
το υποδένδρο του κόµβου αυτού δε συµπεριλαµβάνεται στον περαιτέρω υπολογισµό
του σφάλµατος. ΄Εστω anc(λ) ένα σύνολο από προγόνους κόµβους του λ. Η ιεραρχική
απώλεια ορίζεται όπως παρακάτω.
Ιεραρχική Απώλεια =
1
N
N∑
i=1
|{λ : λ ∈ Yi△Zi , anc(λ) ∩ (Yi△Zi) = ∅}|



2.17
Η ορθότητα ταξινόµησης (classification accuracy) (Zhu et al., 2005) ή ορθότητα
υποσυνόλου (subset accuracy) (Ghamrawi and McCallum, 2005) ορίζεται ως εξής :
Ορθότητα υποσυνόλου =
1
N
N∑
i=1
I(Zi = Yi)



2.18
όπου I(true) = 1 και I(false) = 0. Αυτό είναι ένα αυστηρό µέτρο αξιολόγησης
αφού απαιτεί το προβλεπόµενο σύνολο ετικετών να είναι ακριβώς ίδιο µε το πραγµατικό
σύνολο ετικετών.
Οι ακόλουθες µετρικές ορίζονται στην εργασία (Godbole and Sarawagi, 2004):
Ακρίβεια =
1
N
N∑
i=1
|Yi ∩ Zi |
|Zi |
Ανάκληση =
1
N
N∑
i=1
|Yi ∩ Zi |
|Yi |



2.19
F1 =
1
N
N∑
i=1
2|Yi ∩ Zi |
|Zi | + |Yi |
Ορθότητα =
1
N
N∑
i=1
|Yi ∩ Zi |
|Yi ∪ Zi |



2.20
Μετρικές ϐάσει ετικετών
Σε αυτήν την κατηγορία µπορεί να χρησιµοποιηθεί ως ϐάση οποιαδήποτε µετρική
αξιολόγησης απλής ετικέτας όπως η ακρίβεια και η ανάκληση. Ο υπολογισµός των
µετρικών ϐάσει ετικετών µπορεί να πραγµατοποιηθεί µε τις τεχνικές του µακρο-µέσου
(macro averaging) και του µικρο-µέσου (micro averaging) (Yang, 1999).
΄Εστω ένα δυαδικό µέτρο αξιολόγησης B(TP, TN, FP, FN), όπως η ακρίβεια και η
ανάκληση, το οποίο υπολογίζεται ϐάσει του αριθµού των αληθώς ϑετικών (TP), αληθώς
αρνητικών (TN ), ψευδώς ϑετικών (FP), και ψευδώς αρνητικών (FN ) ταξινοµήσεων και
TPλ FPλ TNλ και FNλ είναι οι αντίστοιχες τιµές για την ετικέτα λ. Η έκδοση µικρο-
µέσου και µακρο-µέσου του µέτρου B υπολογίζονται ως εξής :
49
ΚΕΦΑΛΑΙΟ 2. ΜΗΧΑΝΙΚΗ ΜΑΘΗΣΗ ΚΑΙ ΤΑΞΙΝΟΜΗΣΗ ΚΕΙΜΕΝΩΝ
Bmacro =
1
M
M∑
λ=1
B (TPλ, FPλ, TNλ, FNλ)



2.21
Bmicro = B

M∑
λ=1
TPλ,
M∑
λ=1
FPλ,
M∑
λ=1
TNλ,
M∑
λ=1
FNλ




2.22
2.12 Σύνοψη
Σε αυτό το κεφάλαιο έγινε µία εισαγωγή στην περιοχή της αυτόµατης ταξινόµησης
κειµένων µε χρήση µεθόδων µηχανικής µάθησης. Ιδιαίτερη αναφορά έγινε στα δύο
ειδικά προβλήµατα που αντιµετωπίζονται στην παρούσα διατριβή, την ταξινόµηση ϱοών
κειµένων και την ταξινόµηση κειµένων πολλαπλών ετικετών.
50
3
∆υναµικοί Χώροι και Επαυξητική Επιλογή
Χαρακτηριστικών
Σε αυτό το κεφάλαιο, υπογραµµίζεται η αναγκαιότητα για ένα δυναµικό χώρο χαρα-
κτηριστικών αλλά και η χρησιµότητα της επαυξητικής επιλογής χαρακτηριστικών σε
εφαρµογές ταξινόµησης ϱοών κειµένων. Επιπροσθέτως, προτείνεται ένα υπολογιστικά
µη-απαιτητικό πλαίσιο επαυξητικής µάθησης που µπορεί να διατελέσει µέθοδος ϐάσης
στη σχετική ερευνητική περιοχή. Τέλος, το προτεινόµενο πλαίσιο χρησιµοποιείται ως
ϐασικό στοιχείο ενός προσαρµοστικού διαδικτυακού συστήµατος ανάγνωσης ειδήσεων.
3.1 Εισαγωγή
Το διαδίκτυο αποτελεί ένα ιδιαίτερα δυναµικό περιβάλλον και περιλαµβάνει µία πλη-
ϑώρα πηγών ϱοών κειµένων. Χαρακτηριστικά παραδείγµατα αποτελούν οι ιστοσελίδες,
οι ϱοές ειδήσεων, το ηλεκτρονικό ταχυδροµείο, οι οµάδες συζητήσεων, οι υπηρεσίες
άµεσων µηνυµάτων και τα διαδικτυακά ηµερολόγια (blogs). Τελευταία, έχουν πα-
ϱουσιαστεί πολλές ενδιαφέρουσες εφαρµογές που αφορούν στην αυτόµατη ταξινόµηση
τέτοιων ϱοών κειµένων. Η πιο διαδεδοµένη ίσως από αυτές είναι το ϕιλτράρισµα α-
νεπιθύµητων µηνυµάτων ηλεκτρονικού ταχυδροµείου (spam filtering). ΄Αλλη γνωστή
εφαρµογή είναι η δηµιουργία εξατοµικευµένων ϱοών ειδήσεων.
Οι εφαρµογές αυτές παρουσιάζουν ιδιαίτερο ενδιαφέρον για τους επιστήµονες της
µηχανικής µάθησης αφού εµπεριέχουν ένα σηµαντικό αριθµό δυσκολιών. ΄Εχουν
ήδη αναφερθεί στο εισαγωγικό κεφάλαιο κάποιες από αυτές όπως ο µεγάλος αριθµός
διαστάσεων, οι περιορισµοί που ϑέτουν οι ϱοές δεδοµένων αλλά και το ϕαινόµενο της
εννοιολογικής απόκλισης.
Σε αυτό το κεφάλαιο, αντιµετωπίζεται ένα επιπλέον πρόβληµα της ταξινόµησης
ϱοών κειµένων που είναι η δυναµική ϕύση του συνόλου των χαρακτηριστικών (Katakis
et al., 2009b). Σε µία πραγµατική εφαρµογή ταξινόµησης ϱοών κειµένων, υπάρχει
πάντα η πιθανότητα να εισαχθεί στο σύστηµα ένα κείµενο που ϑα περιέχει νέες λέξεις-
χαρακτηριστικά. Οι λέξεις αυτές, δεν έχουν ενσωµατωθεί στο µοντέλο µάθησης και
κατά συνέπεια δε µπορούν ληφθούν υπόψη κατά τη διαδικασία της πρόβλεψης. Τα
χαρακτηριστικά αυτά όµως µπορεί να περιέχουν σηµαντική πληροφορία για την τάξη
51
ΚΕΦΑΛΑΙΟ 3. ∆ΥΝΑΜΙΚΟΙ ΧΩΡΟΙ ΚΑΙ ΕΠΑΥΞΗΤΙΚΗ ΕΠΙΛΟΓΗ ΧΑΡΑΚΤΗΡΙΣΤΙΚΩΝ
στόχο.
Για την αντιµετώπιση λοιπόν αυτού του προβλήµατος προτείνεται η χρήση µίας
ειδικής κατηγορίας ταξινοµητών που ϑα είναι σε ϑέση να εκπαιδεύεται και να παράγει
προβλέψεις σε έναν τέτοιο δυναµικό χώρο χαρακτηριστικών (dynamic feature space).
Επιπλέον, ϑα µελετηθεί η καταλληλότητα της επαυξητικής επιλογής χαρακτηριστι-
κών (Incremental Feature Selection - IFS) για την αντιµετώπιση της εννοιολογικής
απόκλισης σε προβλήµατα δυναµικού χώρου χαρακτηριστικών.
∆ηµιουργείται και παρέχεται διαδικτυακά ένα νέο σύνολο ϱοών δεδοµένων µε εν-
νοιολογική απόκλιση που ελπίζουµε ότι ϑα ϐοηθήσει άλλους ερευνητές να αξιολογή-
σουν αντίστοιχες µεθόδους ταξινόµησης.
Συνολικά, προτείνεται ένα υπολογιστικά µη-απαιτητικό πλαίσιο ταξινόµησης ϱοών
κειµένων. Το προτεινόµενο πλαίσιο, περιλαµβάνει : α) έναν επαυξητικό ταξινοµητή ο
οποίος µπορεί να λειτουργήσει σε δυναµικό χώρο χαρακτηριστικών και ϐ) µία µέθοδο
επαυξητικής επιλογής χαρακτηριστικών. Λόγω της απλότητας και αποτελεσµατικότη-
τας αυτού του πλαισίου, ϑεωρούµε ότι ϑα µπορούσε να διατελέσει µέθοδος ϐάσης στην
περιοχή.
Τέλος, το προτεινόµενο πλαίσιο χρησιµοποιείται ως ϐασικό στοιχείο για την ανά-
πτυξη ενός προσαρµοστικού διαδικτυακού συστήµατος ανάγνωσης ειδήσεων.
3.2 Επαυξητική Επιλογή Χαρακτηριστικών
Σε αυτήν την ενότητα παρουσιάζονται αρχικά οι ιδιαίτερες απαιτήσεις που εµπεριέ-
χουν οι εφαρµογές ταξινόµησης ϱοών κειµένων και έπειτα προτείνεται ένα πλαίσιο
επαυξητικής µάθησης το οποίο τις ικανοποιεί.
3.2.1 Κίνητρο
Στις εφαρµογές ταξινόµησης ϱοών κειµένων υπάρχει πιθανότητα εµφάνισης ενός ιδιαί-
τερου τύπου εννοιολογικής απόκλισης που αφορά στην εµφάνιση νέων χαρακτηριστι-
κών που δεν περιλαµβάνονται στον αρχικό χώρο διαστάσεων. Πολλές ϕορές µάλιστα, τα
χαρακτηριστικά αυτά µπορούν να ϐοηθήσουν σηµαντικά στη διαδικασία της πρόβλε-
ψης. Στο spam filtering για παράδειγµα, συνεχώς εµφανίζονται νέοι τύποι µηνυµάτων
οι οποίοι περιλαµβάνουν νέες λέξεις. Επιπλέον, µία συνηθισµένη τακτική των αποστο-
λέων spam είναι να αλλοιώνουν επίτηδες τη µορφή και την ορθογραφία κάποιων λέξεων
µε σκοπό να παραπλανήσουν τους ταξινοµητές. ΄Ετσι, για παράδειγµα, η λέξη "viagra"
µπορεί να µεταµορφωθεί σε "v.i.a.g.r.a" ή "v1agra" µε σκοπό να δηµιουργηθούν λέξεις
για τις οποίες δεν έχουν εκπαιδευτεί οι ταξινοµητές.
Επιπλέον, ένα ϑέµα που δεν έχει τύχει ιδιαίτερης προσοχής αποτελεί η απουσία
συνόλου εκπαίδευσης σε εφαρµογές ταξινόµησης ϱοών δεδοµένων. Ας πάρουµε για
παράδειγµα έναν ταξινοµητή ειδησεογραφικών άρθρων. Υποθέτουµε ότι ο ϱόλος του
ταξινοµητή είναι να ξεχωρίζει για λογαριασµό του χρήστη τις ενδιαφέρουσες για αυτόν
52
3.2. ΕΠΑΥΞΗΤΙΚΗ ΕΠΙΛΟΓΗ ΧΑΡΑΚΤΗΡΙΣΤΙΚΩΝ
ειδήσεις. Ο χρήστης µπορεί να παρέχει παραδείγµατα στον ταξινοµητή υποδεικνύον-
τάς του αρχικά κάποια άρθρα που τον ενδιαφέρουν. Πριν όµως από αυτή τη διαδικασία
δεν υπάρχουν διαθέσιµα παραδείγµατα και, επιπλέον, ο χώρος χαρακτηριστικών είναι
άγνωστος.
Από τα δύο παραπάνω προβλήµατα γίνεται προφανής η ανάγκη για µεθόδους οι
οποίες ϑα κατασκευάζουν µε επαυξητικό τρόπο όχι µόνο το µοντέλο πρόβλεψης αλλά
και το χώρο χαρακτηριστικών.
΄Οπως αναφέρθηκε και στο προηγούµενο κεφάλαιο, η διαδικασία επιλογής χαρα-
κτηριστικών αποτελεί µία πολύ σηµαντική διαδικασία για την ταξινόµηση κειµένων.
Στις ϱοές δεδοµένων όµως, µε το πέρασµα του χρόνου η συσχέτιση των χαρακτηριστι-
κών µε την τάξη στόχο µπορεί να αλλάξει. Στον ταξινοµητή ειδήσεων για παράδειγµα
τα ενδιαφέροντα του χρήστη µπορεί να αλλάξουν, πράγµα που σηµαίνει ότι οι λέξεις
που χαρακτηρίζουν την τάξη ¨ενδιαφέρον άρθρο¨ ϑα είναι διαφορετικές τη χρονική
στιγµή t1 και διαφορετικές τη χρονική στιγµή t2, όπου t2 > t1. Μία δεύτερη απαίτηση
λοιπόν που αφορά στη µέθοδο επιλογής χαρακτηριστικών είναι να µπορεί να διατηρεί
ένα σύνολο επιλεγµένων χαρακτηριστικών που ϑα ανανεώνεται συνεχώς.
Τέλος, µία σηµαντική απαίτηση που συχνά παραβλέπεται είναι η ανάγκη για χα-
µηλή πολυπλοκότητα των µεθόδων έτσι ώστε να είναι εφαρµόσιµες σε πραγµατικές
εφαρµογές. Ας υποθέσουµε για παράδειγµα ότι διατηρούµε µία διαδικτυακή εξατοµι-
κευµένη εφηµερίδα. Κάθε χρήστης εγγράφεται σε συγκεκριµένα ϑέµατα ενδιαφέρον-
τος (π.χ. Αθλητικά, Τέχνες) και ένας ταξινοµητής εκπαιδεύεται λαµβάνοντας υπόψη
την ανάδραση του χρήστη έτσι ώστε να διαχωρίσει τα ενδιαφέροντα άρθρα από τα αδιά-
ϕορα σε κάθε κατηγορία. Κατά συνέπεια, απαιτείται ένας ταξινοµητής για κάθε χρήστη
και κάθε ϑεµατική κατηγορία. Ο µεγάλος αριθµός των ταξινοµητών ϑέτει σηµαντικούς
περιορισµούς για την πολυπλοκότητα τους και τη µνήµη που απαιτούν.
3.2.2 Προτεινόµενο Πλαίσιο Ταξινόµησης
Λαµβάνοντας υπόψη τις απαιτήσεις που περιγράφηκαν στην προηγούµενη ενότητα,
προτείνεται ένα πλαίσιο ταξινόµησης ϱοών κειµένων. Το πλαίσιο αυτό, το οποίο ονο-
µάζεται επαυξητική επιλογή χαρακτηριστικών (incremental feature selection), αποτε-
λείται από δύο ϐασικά στοιχεία : α) µία επαυξητική µέθοδο επιλογής χαρακτηριστικών,
και ϐ) έναν επαυξητικό αλγόριθµο µάθησης ο οποίος µπορεί λειτουργήσει σε δυναµικό
χώρο χαρακτηριστικών.
΄Οπως αναφέρθηκε και στο προηγούµενο κεφάλαιο, στην ταξινόµηση κειµένων
συνηθισµένες µέθοδοι επιλογής χαρακτηριστικών είναι η αξιολόγηση ϐάσει µετρικών
όπως η αµοιβαία πληροφορία και το χ2. Οι µετρικές αυτές εκφράζουν τη συσχέτιση
κάθε χαρακτηριστικού µε µία τιµή της τάξης-στόχου σε ένα σύνολο εκπαίδευσης. Με
ϐάση αυτήν την αξιολόγηση προκύπτει µία κατάταξη των χαρακτηριστικών ως προς τη
χρήσιµη πληροφορία που περιέχουν για το συγκεκριµένο πρόβληµα ταξινόµησης. Από
αυτήν την κατάταξη λοιπόν µπορούν να επιλεχθούν και να χρησιµοποιηθούν για την
εκπαίδευση και την ταξινόµηση µόνο τα N ποιοτικότερα (από πληροφοριακή σκοπιά)
53
ΚΕΦΑΛΑΙΟ 3. ∆ΥΝΑΜΙΚΟΙ ΧΩΡΟΙ ΚΑΙ ΕΠΑΥΞΗΤΙΚΗ ΕΠΙΛΟΓΗ ΧΑΡΑΚΤΗΡΙΣΤΙΚΩΝ
χαρακτηριστικά.
Ο υπολογισµός των µετρικών αυτών εύκολα µπορεί να πραγµατοποιηθεί επαυ-
ξητικά ενώ συνεχώς γίνονται διαθέσιµα νέα παραδείγµατα. Είναι επίσης εφικτό να
υπολογιστούν οι τιµές των µετρικών για νεοεµφανιζόµενα χαρακτηριστικά. Κατά συνέ-
πεια, τέτοιες µέθοδοι επιλογής χαρακτηριστικών µπορούν να επιλεχθούν ως το πρώτο
ϐασικό στοιχείο του προτεινόµενου πλαισίου.
Η διατήρηση όµως µίας δυναµικής λίστας χαρακτηριστικών µας οδηγεί στην ανάγ-
κη για το δεύτερο στοιχείο του πλαισίου : ΄Εναν αλγόριθµο µάθησης που ϑα µπορεί
να λειτουργεί σε ένα τέτοιο δυναµικό περιβάλλον χαρακτηριστικών. Συγκεκριµένα, ϑα
πρέπει κατά την ταξινόµηση να µπορεί να παράγει προβλέψεις λαµβάνοντας υπόψη
µόνο ένα υποσύνολο των χαρακτηριστικών. Το υποσύνολο αυτό ταυτίζεται κάθε ϕορά
µε τα N επιλεγµένα χαρακτηριστικά και αλλάζει συνεχώς. Επίσης, κατά την εκπαίδευ-
ση, ϑα πρέπει να ενηµερώνεται το µοντέλο ως προς όλα τα χαρακτηριστικά έτσι ώστε
να µπορούν να χρησιµοποιηθούν σε περίπτωση που επιλεγούν στο σύνολο των N . Υ-
πάρχει τέλος η απαίτηση ο ταξινοµητής να µπορεί να ενσωµατώσει νέα χαρακτηριστικά
στο µοντέλο του.
∆ύο επαυξητικοί ταξινοµητές που πληρούν τις παραπάνω προϋποθέσεις είναι ο Nai-
ve Bayes και ο kNN. Η ιδιαιτερότητά τους έγκειται στο ότι τα χαρακτηριστικά έχουν
ανεξάρτητη συνεισφορά στη διαδικασία της πρόβλεψης και κατά συνέπεια µπορούν να
χρησιµοποιηθούν µόνο κάποια από αυτά επιλεκτικά. Στο Naive Bayes για παράδειγ-
µα, στο γινόµενο για τον υπολογισµό της πιθανότητας (ϐλέπε ενότητα 2.8.1) µπορούν
να συµµετέχουν µόνο τα N χαρακτηριστικά. Οµοίως, στον kNN, ο υπολογισµός των
αποστάσεων µπορεί να πραγµατοποιηθεί µε τη συµµετοχή µόνο των N χαρακτηριστι-
κών. Να σηµειωθεί επίσης ότι και οι δύο ταξινοµητές µπορούν να ενσωµατώσουν νέα
χαρακτηριστικά στο µοντέλο τους. Στο Naive Bayes απαιτείται µία αρχικοποίηση των
στατιστικών που χρησιµοποιούνται για τον υπολογισµό των τελικών πιθανοτήτων ενώ
στον kNN µπορούµε απλά να επεκτείνουµε τα παλιότερα διανύσµατα µε το νέο χα-
ϱακτηριστικό τοποθετώντας την κατάλληλη τιµή αρχικοποίησης (π.χ. για το boolean
µοντέλο την τιµή 0 αφού το χαρακτηριστικό αυτό δεν είχε εµφανιστεί σε κάποιο από
τα προηγούµενα κείµενα). Στο σηµείο αυτό, πρέπει να γίνει σαφές, ότι οποιοσδήποτε
ταξινοµητής ή γενικά οποιαδήποτε µεθοδολογία µάθησης (ϐλέπε Κεφάλαιο 2 - Παρα-
δείγµατα µε Βάρη, Κινούµενα Παράθυρα, κτλ) που εµπεριέχει αυτήν την ανεξαρτησία
µεταξύ των χαρακτηριστικών µπορεί να ενσωµατωθεί στο προτεινόµενο πλαίσιο.
Το Σχήµα 3.1 παρουσιάζει τον αλγόριθµο Update που περιγράφει την επαυξητική
εκπαίδευση του προτεινόµενου πλαισίου. ΄Οταν ένα κείµενο καταφθάνει ως παράδειγ-
µα της κλάσης DocClass, τότε γίνεται ένας έλεγχος για εµφάνιση νέων λέξεων. Αν
όντως υπάρχουν νέες λέξεις, τότε αυτές προστίθενται (AddWord) στο λεξικό (Vocabu-
lary) και τα στατιστικά (WordStats) αυτής της λέξης (Word) αρχικοποιούνται. ΄Επειτα,
για κάθε λέξη του λεξικού ανανεώνονται οι µετρήσεις µε ϐάση το νέο κείµενο και υ-
πολογίζεται ξανά η µετρική αξιολόγησης της. Τέλος, ο ταξινοµητής (Classifier) πρέπει
να ανανεωθεί ϐάσει του νέου παραδείγµατος αλλά και των νέων λέξεων που µπορεί να
υπάρχουν σε αυτό.
54
3.3. ΠΕΙΡΑΜΑΤΙΚΗ ΑΞΙΟΛΟΓΗΣΗ
Για την ταξινόµηση ενός νέου κειµένου, ο αλγόριθµος επιλέγει τα κορυφαία N
χαρακτηριστικά και ϐάσει µόνο αυτών παράγει την πρόβλεψη.
Σχήµα 3.1: Αλγόριθµος Update
Είσοδος: Document, DocClass, Classes, Vocabulary
΄Εξοδος: Classifier, Vocabulary, WordStats, Evaluation
Αρχή
για κάθε Word ∈ Document κάνε
αν Word < Vocabulary τότε
AddWord(Word, Vocabulary);
για κάθε Class ∈ Classes κάνε
WordStats[Word][Class][1]← 0;
WordStats[Word][Class][0]← 0;
για κάθε Word ∈ Vocabulary κάνε
αν Word ∈ Document τότε
WordStats[Word][DocClass][1]← WordStats[Word][DocClass][1] + 1;
αλλιώς
WordStats[Word][DocClass][0]← WordStats[Word][DocClass][0] + 1;
για κάθε Word ∈ Vocabulary κάνε
Evaluation← EvaluateFeature(Word, WordStats);
Classifier← UpdateClassifier(Document, DocClass);
Τέλος
3.3 Πειραµατική Αξιολόγηση
Σε αυτήν την ενότητα παρουσιάζεται αρχικά ο αλγόριθµος ταξινόµησης και η µέθοδος
επιλογής χαρακτηριστικών που επιλέχθηκαν να χρησιµοποιηθούν στο προτεινόµενο
πλαίσιο. Στη συνέχεια, περιγράφονται τα σύνολα δεδοµένων και οι µέθοδοι που συµ-
µετέχουν στην πειραµατική αξιολόγηση. Τέλος, παρουσιάζονται και σχολιάζονται τα
πειραµατικά αποτελέσµατα.
3.3.1 Επιλογή Χαρακτηριστικών και Ταξινοµητής
Η αξιολόγηση των χαρακτηριστικών ϐάσει της µετρικής χ2 επιλέχθηκε ως µέθοδος
επιλογής χαρακτηριστικών για την προσέγγισή µας κυρίως λόγω της απλότητας και α-
ποτελεσµατικότητάς της (Yang and Pedersen, 1997). Επεκτείναµε την υλοποίηση της
µεθόδου χ2 του Weka (Witten and Frank, 1999) ώστε να δέχεται επαυξητικές ενηµε-
ϱώσεις και νέες λέξεις. ΄Οπως αναφέρθηκε και στην προηγούµενη ενότητα υπάρχουν
και άλλες παραπλήσιες µετρικές που ϑα µπορούσαν να ενσωµατωθούν µε παρόµοιο
55
ΚΕΦΑΛΑΙΟ 3. ∆ΥΝΑΜΙΚΟΙ ΧΩΡΟΙ ΚΑΙ ΕΠΑΥΞΗΤΙΚΗ ΕΠΙΛΟΓΗ ΧΑΡΑΚΤΗΡΙΣΤΙΚΩΝ
τρόπο στο πλαίσιο που προτείνουµε. Η παρούσα µελέτη όµως δε στοχεύει στην εξα-
κρίβωση της αποτελεσµατικότητας της συγκεκριµένης µετρικής αλλά στη µελέτη της
χρησιµότητας της επαυξητικής επιλογής χαρακτηριστικών κατά την ταξινόµηση ϱοών
κειµένων.
Ο αλγόριθµος ταξινόµησης που επιλέχθηκε να χρησιµοποιηθεί στο προτεινόµενο
πλαίσιο είναι ο Naive Bayes. Ο αλγόριθµος kNN δεν ενδείκνυται για ϱοές δεδοµένων
αφού απαιτεί την αποθήκευση όλων των δεδοµένων εκπαίδευσης. Ο Naive Bayes από
την άλλη αποθηκεύει µόνο τα απαραίτητα στατιστικά και επιπλέον χρησιµοποιείται
ευρέως σε εφαρµογές ταξινόµησης κειµένων λόγω της απλότητάς του. Επίσης, για
τους υπολογισµούς των πιθανοτήτων µπορεί να εκµεταλλευτεί τα στατιστικά που ήδη
αποθηκεύονται για τον υπολογισµό της αξιολόγησης χαρακτηριστικών και κατά συ-
νέπεια µπορεί να ενσωµατωθεί ευκολότερα στην προσέγγισή µας. Επεκτείναµε την
υλοποίηση του Naive Bayes του Weka έτσι ώστε να µπορεί να δέχεται ως παράµετρο
τα χαρακτηριστικά ϐάσει των οποίων ϑα γίνει η ταξινόµηση. Να σηµειωθεί και πάλι
ότι στόχος της µελέτης δεν είναι η απόδοση του συγκεκριµένου ταξινοµητή αλλά η
απόδοση του προτεινόµενου πλαισίου σε δυναµικούς χώρους χαρακτηριστικών. Υπεν-
ϑυµίζεται ότι οποιοσδήποτε αλγόριθµος ή γενικότερα µεθοδολογία µάθησης πληρεί τις
προϋποθέσεις που περιγράφονται στην Ενότητα 3.2.2 µπορεί να χρησιµοποιηθεί στο
συγκεκριµένο πλαίσιο.
3.3.2 Σύνολα ∆εδοµένων
Απαραίτητη προϋπόθεση για την αξιολόγηση του προτεινόµενου πλαισίου είναι η χρή-
ση συνόλων δεδοµένων από πραγµατικές ϱοές κειµένων, έτσι ώστε να προσοµοιωθεί
όσο το δυνατόν πιο ϱεαλιστικά το πρόβληµα ταξινόµησης. Στην παρακάτω µελέτη, µε
τα σύνολα δεδοµένων που κατασκευάζονται και χρησιµοποιούνται προσοµοιώνονται
τα προβλήµατα του ϕιλτραρίσµατος ηλεκτρονικής αλληλογραφίας (spam filtering) και
ϕιλτραρίσµατος ειδήσεων (news filtering).
Για το πρόβληµα του spam filtering απαιτείται ένα σύνολο από ανεπιθύµητα (spam)
και ϑεµιτά (ham) µηνύµατα ηλεκτρονικού ταχυδροµείου διατεταγµένα σε χρονολογι-
κή σειρά. Με αυτόν τον τρόπο, µπορεί να προσεγγιστεί η εξελικτική ϕύση του προ-
ϐλήµατος και κατά συνέπεια να αξιολογηθεί περισσότερο αποτελεσµατικά η προτει-
νόµενη προσέγγισή. Για το λόγο αυτό, χρησιµοποιήθηκε η συλλογή SpamAssasin
(http://spamassasin.apache.org/). Η συλλογή1 αυτή επιλέχθηκε για δύο κυρίως
λόγους : α) κάθε µήνυµα είναι διαθέσιµο µε τις επικεφαλίδες (headers) και κατά συ-
νέπεια µπορεί να εξαχθεί η ηµεροµηνία και ώρα αποστολής και ϐ) περιέχει spam και
ϑεµιτά µηνύµατα, µε το ποσοστό των spam µηνυµάτων να ϕθάνει το 20% του συνολι-
κού αριθµού των µηνυµάτων. Το σύνολο δεδοµένων αποτελείται από 9,324 µηνύµατα
και αρχικά 40,000 χαρακτηριστικά. ΄Οπως ϑα αναφερθεί και παρακάτω το σύνολο
αυτό αντιπροσωπεύει τη σταδιακή εννοιολογική απόκλιση (gradual concept drift).
1∆ιαθέσιµη στην αρχική της µορφή στη διεύθυνση : http://spamassassin.apache.org/publiccorpus
56
3.3. ΠΕΙΡΑΜΑΤΙΚΗ ΑΞΙΟΛΟΓΗΣΗ
Πίνακας 3.1: Ενδιαφέροντα του χρήστη σε σχέση µε το χρόνο
Ροή Παραδείγµατα
Ειδήσεων Οµάδα Συζήτησης 1-3000 3001-4500 4501-6000
Υλισµικό comp.pc.hardware Ναι Ναι -
comp.mac.hardware ΄Οχι ΄Οχι -
Μηχανοκίνηση rec.autos Ναι Ναι Ναι
rec.motorcycles ΄Οχι ΄Οχι ΄Οχι
Αθλητικά rec.sport.baseball Ναι - -
rec.sport.hockey ΄Οχι - -
Επιστήµες sci.med - ΄Οχι ΄Οχι
sci.space - Ναι Ναι
Θρησκεία soc.religion.christian - - Ναι
alt.atheism - - ΄Οχι
Για το πρόβληµα του ϕιλτραρίσµατος ειδήσεων απαιτείται µία ϱοή από ειδησεο-
γραφικά άρθρα διάφορων ϑεµατολογιών. Μία τέτοια ϱοή προσοµοιώθηκε χρησιµο-
ποιώντας αναρτήσεις (posts) σε οµάδες συζήτησης (usenet groups) από τη συλλογή
20 Newsgroups2. Το σύνολο κατασκευάστηκε έτσι ώστε να προσοµοιώνει την απότο-
µη εννοιολογική απόκλιση (sudden ή abrupt concept drift). Το σενάριο αφορά σε
έναν χρήστη ο οποίος εγγράφεται/διαγράφεται σε/από διάφορες ϱοές ειδήσεων (π.χ.
αθλητικά, επιστήµες) αλλά ενδιαφέρεται κάθε ϕορά µόνο για συγκεκριµένες ϑεµατι-
κές υποκατηγορίες αυτών των ϱοών. Ο Πίνακας 3.1 παρουσιάζει τις ϱοές που είναι
εγγεγραµένος ο χρήστης σε κάθε χρονικό διάστηµα και τις υπο-ϱοές που τον ενδιαφέ-
ϱουν. Για παράδειγµα, ο χρήστης αρχικά είναι εγγεγραµένος στις ϱοές του υλισµικού,
της µηχανοκίνησης και των αθλητικών αλλά ενδιαφέρεται µόνο για ϑέµατα που αφο-
ϱούν PC, αυτοκίνητα και baseball αντίστοιχα. Αυτό το σύνολο αποτελείται από 6,000
παραδείγµατα και αρχικά περιέχει 28,000 χαρακτηριστικά.
Και στα δύο σύνολα, έχουν αφαιρεθεί οι επικεφαλίδες και χρησιµοποιείται
το µοντέλο boolean bag-of-words για την αναπαράσταση των κειµένων. ΄Αλ-
λες µέθοδοι για επαυξητική επιλογή χαρακτηριστικών όπως η εργασία (Perkins
et al., 2003) δεν έχουν αξιολογηθεί σε δεδοµένα τόσο µεγάλων διαστάσεων. Τα
δύο σύνολα δεδοµένων είναι ελεύθερα διαθέσιµα στο διαδίκτυο στη διεύθυνση:
http://mlkd.csd.auth.gr/concept_drift.html.
3.3.3 Μέθοδοι
Για να αξιολογηθεί η αποτελεσµατικότητα της προτεινόµενης µεθοδολογίας, εφαρµό-
στηκε το προτεινόµενο πλαίσιο σε τρεις ϐασικές µεθόδους της ϐιβλιογραφίας :
− Επαυξητικός Ταξινοµητής Naive Bayes (Incremental Naive Bayes - INB): ΄Ενας
2 http://kdd.ics.uci.edu/databases/20newsgroups/20newsgroups.html
57
ΚΕΦΑΛΑΙΟ 3. ∆ΥΝΑΜΙΚΟΙ ΧΩΡΟΙ ΚΑΙ ΕΠΑΥΞΗΤΙΚΗ ΕΠΙΛΟΓΗ ΧΑΡΑΚΤΗΡΙΣΤΙΚΩΝ
αλγόριθµος ταξινόµησης Naive Bayes ο οποίος µπορεί να ενσωµατώνει επαυξη-
τικά στο µοντέλο του νέα παραδείγµατα.
− Παραδείγµατα µε Βάρη (Weighted Examples - WE): ΄Ενας επαυξητικός ταξινο-
µητής (Naive Bayes) ο οποίος όµως λαµβάνει υπόψη του ϐάρη (weights) για τα
παραδείγµατα. ΄Οσο µεγαλύτερο το ϐάρος του παραδείγµατος τόσο µεγαλύτερη
και η επιρροή του στη διαµόρφωση του µοντέλου. Στην ταξινόµηση ϱοών δε-
δοµένων, τα πιο πρόσφατα παραδείγµατα έχουν µεγαλύτερα ϐάρη έτσι ώστε το
µοντέλο να προσαρµόζεται γρήγορα στην ενδεχόµενη εννοιολογική απόκλιση.
− Χρονικά Παράθυρα (Time Windows - TW): ΄Ενας ταξινοµητής ο οποίος µοντε-
λοποιεί κάθε ϕορά τα τελευταία s παραδείγµατα, όπου s το µέγεθος του πα-
ϱαθύρου. Εκτός από την επαυξητική ενσωµάτωση ενός νέου παραδείγµατος
απαιτείται και µία συνάρτηση µε την οποία αφαιρείται ένα παράδειγµα από το
µοντέλο.
3.3.4 Μεθοδολογία και Λεπτοµέρειες Αξιολόγησης
Για την αξιολόγηση του προτεινόµενου πλαισίου συγκρίνονται οι τρείς παραπάνω µέ-
ϑοδοι µε τις ίδιες ενισχυµένες µε το προτεινόµενο πλαίσιο επαυξητική επιλογή χαρα-
κτηριστικών (Incremental Feature Selection - IFS).
΄Ολες οι µέθοδοι αξιολογήθηκαν και στα δύο σύνολα δεδοµένων (spam, news), χρη-
σιµοποιώντας τρία διαφορετικά µεγέθη συνόλων εκπαίδευσης (10%, 20%, και 30% των
κειµένων). Η διαδικασία της αξιολόγησης είναι η εξής : Με την άφιξη ενός κειµένου
κάθε µέθοδος παράγει µία πρόβλεψη. Από τη σωστή ή λανθασµένη αυτή πρόβλεψη
υπολογίζεται σταδιακά και η ορθότητα της κάθε µεθόδου. Αµέσως µετά, η πραγµατι-
κή τάξη του κειµένου ϑεωρείται γνωστή και κατά συνέπεια µπορεί να ενηµερωθεί το
µοντέλο της κάθε µεθόδου.
Ο αριθµός των επιλεγµένων χαρακτηριστικών ορίστηκε ίσος µε 500. ΄Επειτα από
µία πρόχειρη µελέτη, ϕάνηκε ότι τα 300 παραδείγµατα είναι ένα ικανοποιητικό µέ-
γεθος παραθύρου για την προσέγγιση TW ενώ ένας αποτελεσµατικός τρόπος για τον
καθορισµό των ϐαρών για τη µέθοδο WE είναι η εξίσωση w(n) = w(n − 1) + n2, όπου
w(n) είναι το ϐάρος του n-οστού παραδείγµατος. Να σηµειωθεί ότι η παρούσα πει-
ϱαµατική αξιολόγηση δε στοχεύει στη µελέτη της ορθότητας αυτών των µεθόδων αλλά
στην µελέτη της επιρροής της επαυξητητικής επιλογής χαρακτηριστικών σε αυτές.
3.3.5 Αποτελέσµατα
Ο Πίνακας 3.2 παρουσιάζει την ποιότητα πρόβλεψης των τριών µεθοδολογιών µε και
χωρίς την ενσωµάτωση του πλαισίου IFS στα δύο σύνολα δεδοµένων και για τα τρία
µεγέθη συνόλου εκπαίδευσης. Ως µετρικές αξιολόγησης της ποιότητας πρόβλεψης
χρησιµοποιείται η ορθότητα (Accuracy - acc) και η περιοχή κάτω από την καµπύλη
ROC (Area Under the ROC Curve - auc).
58
3.3. ΠΕΙΡΑΜΑΤΙΚΗ ΑΞΙΟΛΟΓΗΣΗ
Πίνακας 3.2: Ορθότητα (acc) και περιοχή κάτω από την καµπύλη ROC (acc) των
τριών µεθοδολογιών (µε και χωρίς την ενσωµάτωση του πλαισίου IFS) στα δύο σύνολα
δεδοµένων, για όλα τα µεγέθη συνόλου εκπαίδευσης.
10% 20% 30%
Σύνολο Μέθοδος acc auc acc auc acc auc
spam INB 66.06 81.64 51.44 81.53 88.55 93.23
INB+IFS 86.28 92.48 90.27 95.42 94.02 97.11
TW 89.71 93.08 90.62 93.03 91.86 92.44
TW+IFS 90.99 94.42 91.80 94.67 93.56 94.68
WE 89.76 93.67 92.35 94.60 96.00 97.08
WE+IFS 93.61 96.75 95.56 98.01 95.81 97.56
news INB 76.04 87.74 76.06 87.57 74.11 85.28
INB+IFS 84.07 93.57 84.11 93.53 83.77 93.19
TW 78.38 86.38 78.41 86.10 78.12 85.80
TW+IFS 79.27 87.50 79.54 87.55 79.59 87.42
WE 80.38 88.77 80.00 89.06 78.38 87.63
WE+IFS 84.98 93.33 85.03 93.15 85.08 93.07
΄Οπως ϕαίνεται από τα αποτελέσµατα, οι ενισχυµένες µε το πλαίσιο IFS µέθοδοι
παρουσιάζουν καλύτερη απόδοση στις µετρικές acc και auc από τις απλές µεθόδους
και στα δύο σύνολα δεδοµένων και για τα τρία µεγέθη συνόλου εκπαίδευσης. Αυτό
αποδεικνύει ότι η επαυξητική επιλογή χαρακτηριστικών επιτυγχάνει : α) να ενσωµα-
τώσει νέες λέξεις που αποδεικνύονται χρήσιµες για την ταξινόµηση, αλλά και ϐ) να
επιλέγει κάθε ϕορά το κατάλληλο σύνολο χαρακτηριστικών για την ταξινόµηση.
Στο σύνολο spam, η ενσωµάτωση περισσότερων δεδοµένων εκπαίδευσης αυξάνει
την απόδοση για όλες τις µεθοδολογίες εξαιτίας της εισαγωγής από την αρχή σηµαν-
τικών χαρακτηριστικών. Στο σύνολο news από την άλλη, η εισαγωγή περισσότερων
δεδοµένων εκπαίδευσης δεν αυξάνει ιδιαίτερα την απόδοση. Στο σύνολο αυτό έχου-
µε απότοµη εννοιολογική απόκλιση που σηµαίνει ότι πολλά από τα παραδείγµατα
πριν την εµφάνιση της απόκλισης περιέχουν λάθος πληροφορία αφού οι έννοιες έχουν
πλέον αλλάξει.
Οι εικόνες 3.2α, 3.2ϐ, και 3.2γ παρουσιάζουν το µετακινούµενο µέσο όρο (ανά
200 παραδείγµατα) της ορθότητας για όλες τις µεθόδους (µε και χωρίς IFS) χρησιµο-
ποιώντας το 20% όλων των παραδειγµάτων για εκπαίδευση στο σύνολο news3.
Και στις τρεις περιπτώσεις παρατηρούµε ότι στα πρώτα παραδείγµατα η ορθότητα
των δύο µεθόδων είναι συγκρίσιµη, αλλά από το σηµείο της πρώτης απόκλισης και
µετά η απόδοση των ενισχυµένων µε IFS µεθόδων γίνεται και παραµένει καλύτερη.
Αυτό συµβαίνει επειδή σε εκείνο το σηµείο ο χρήστης εγγράφηκε σε νέα λίστα (επι-
3Τα αντίστοιχα γραφήµατα για τη συλλογή spam είναι παρόµοια
59
ΚΕΦΑΛΑΙΟ 3. ∆ΥΝΑΜΙΚΟΙ ΧΩΡΟΙ ΚΑΙ ΕΠΑΥΞΗΤΙΚΗ ΕΠΙΛΟΓΗ ΧΑΡΑΚΤΗΡΙΣΤΙΚΩΝ
στήµες), νέες λέξεις µε µεγάλο πληροφοριακό περιεχόµενο εµφανίστηκαν αλλά και
οι συσχετίσεις των λέξεων µε την τάξη στόχο άλλαξαν λόγω της απόκλισης4. Το ίδιο
ακριβώς συµβαίνει µετά τα 4500 παραδείγµατα5 όταν ο χρήστης αλλάζει ενδιαφέροντα
και λίστες για δεύτερη ϕορά. Οι απλές µέθοδοι αποτυγχάνουν να προσαρµοστούν στα
νέα ενδιαφέροντα, ενώ οι IFS µέθοδοι καταφέρνουν να διατηρήσουν την αρχική τους
δυνατότητα πρόβλεψης.
Η µέθοδος TW είναι η µόνη που δεν επηρεάζεται σηµαντικά από το IFS και αυτό
ϕαίνεται από τον Πίνακα 3.2 (ϐλέπε ορθότητα TW σε σχέση µε ορθότητα TW+IFS και
στα δύο datasets) αλλά και στην Εικόνα 3.2γ. Η συµπεριφορά αυτή οφείλεται κυρίως
στο µικρό παραθύρου που εφαρµόζεται το IFS.
Συγκρίνοντας τις τρεις IFS µεθόδους µεταξύ τους (Πίνακας 3.2), παρατηρούµε ότι η
µέθοδος WE+IFS υπερέχει στο σύνολο spam κυρίως λόγω της ϕύσης του προβλήµατος.
Η σταδιακή εννοιολογική απόκλιση έρχεται σε συµφωνία µε τη σταδιακή αύξηση των
ϐαρών. Στο σύνολο news οι µέθοδοι WE+IFS και INB+IFS παρουσιάζουν παρόµοια
απόδοση. Συγκεκριµένα, η WE+IFS παρουσιάζει µεγαλύτερη acc ενώ η INB+IFS
µεγαλύτερη auc. Επειδή γενικότερα η auc ϑεωρείται περισσότερο αξιόπιστη µετρική
(Huang and Ling, 2005), ϑα µπορούσαµε να ισχυριστούµε ότι η INB+IFS υπερέχει σε
αυτό το σύνολο.
Οι εικόνες 3.3α και 3.3ϐ δείχνουν τον κινούµενο µέσο όρο (ανά 200 παραδείγµατα)
για τον αριθµό των λέξεων που προάγονται (ή υποβιβάζονται) στις (από τις) κορυφαίες
500 λέξεις για τα δύο σύνολα δεδοµένων για τη µέθοδο INB+IFS. Παρατηρούµε ότι
στο σύνολο news περισσότερες λέξεις προάγονται/υποβιβάζονται στις 500 καλύτερες
λόγω κυρίως των δύο απότοµων εννοιολογικών αποκλίσεων και των εγγραφών σε νέες
ϱοές ειδήσεων. Η απότοµη κορύφωση στο spam σύνολο οφείλεται σε µιά ανωµαλία
της συλλογής (ένας µεγάλος αριθµός spam µηνυµάτων καταφθάνει τη συγκεκριµένη
χρονική στιγµή).
Οι µηχανές διανυσµάτων υποστήριξης (Support Vector Machines - SVMs) είναι
γνωστοί αποδοτικοί ταξινοµητές κειµένων που εµπεριέχουν την επιλογή χαρακτηρι-
στικών. Ενδεικτικά εφαρµόσαµε SVM (Υλοποίηση Weka (SMO), µε τις εξ΄ ορισµού
παραµέτρους - γραµµικός πυρήνας, C = 1), χωρίς αρχική εκπαίδευση στο σύνολο
δεδοµένων news µε επανεκπαίδευση για κάθε 300 παραδείγµατα. Η µέση ορθότητα
που προέκυψε είναι 70.02%. Για τη µέθοδο TW+IFS (χωρίς επανεκπαίδευση), υπολο-
γίστηκε ορθότητα ίση µε 77.95%. Επιπλέον, ο χρόνος εκτέλεσης των SVM ήταν αρκετά
µεγαλύτερος (περίπου 4 ϕορές).
4Η πρώτη απόκλιση, όπως ϕαίνεται από τον Πίνακα 3.1 συµβαίνει στα 3000 παραδείγµατα. Να
σηµειωθεί όµως ότι το 20% των παραδειγµάτων (1200) έχει κρατηθεί για εκπαίδευση, και εποµένως στα
γραφήµατα της Εικόνας 3.2 η απόκλιση αντιστοιχεί στα 3000 − 1200 = 1800 παραδείγµατα.
5Με το ίδιο σκεπτικό, στα γραφήµατα του Σχήµατος 3.2 η απόκλιση ϕαίνεται στα 4500-1200=3300
παραδείγµατα.
60
3.4. ΕΝΑ ΠΡΟΣΑΡΜΟΣΤΙΚΟ ΣΥΣΤΗΜΑ ΑΝΑΓΝΩΣΗΣ ΕΙ∆ΗΣΕΩΝ
0.5
0.6
0.7
0.8
0.9
1
1 1001 2001 3001 4001
INB
INB+IFS
(α΄)
0.5
0.6
0.7
0.8
0.9
1
1 1001 2001 3001 4001
INB
WE+IFS
(ϐ΄)
0.5
0.6
0.7
0.8
0.9
1
1 1001 2001 3001 4001
TW
TW+IFS
(γ΄)
Σχήµα 3.2: Μετακινούµενος µ.ο ορθότητας (ανά 200 παραδείγµατα) στο σύνολο news
0
2
4
6
8
10
12
14
16
18
20
1 1001 2001 3001 4001
(α΄)
0
2
4
6
8
10
12
1 1001 2001 3001 4001 5001 6001 7001
(ϐ΄)
Σχήµα 3.3: Μετακινούµενος µ.ο. (ανά 200 παραδείγµατα) των λέξεων που εισάγον-
ται/εξάγονται από την λίστα των 500
3.4 ΄Ενα Προσαρµοστικό Σύστηµα Ανάγνωσης Ειδήσεων
Σε αυτήν την ενότητα περιγράφεται το σύστηµα PersoNews (Katakis et al., 2009b),
µία προσαρµοστική διαδικτυακή εφαρµογή ανάγνωσης ειδήσεων που χρησιµοποιεί το
πλαίσιο µηχανικής µάθησης που προτάθηκε προηγουµένως. Τα κύρια πλεονεκτήµα-
τα του PersoNews είναι : α) η δυνατότητα ενσωµάτωσης πολλών διαφορετικών πηγών
ειδήσεων µέσω των πρωτοκόλλων RSS και OPML, ϐ) η αυτόµατη ταξινόµηση και α-
πόκρυψη των αδιάφορων ειδήσεων για κάθε χρήστη και κάθε τροφοδοσία που αυτός
παρακολουθεί, και γ) η δυνατότητα που δίνεται στο χρήση να παρακολουθήσει γενικές
ϑεµατικές κατηγορίες ειδήσεων από µία ταξινοµία ϑεµάτων. Το σύστηµα PersoNews
είναι ελεύθερα προσβάσιµο στη διεύθυνση: http://news.csd.auth.gr.
61
ΚΕΦΑΛΑΙΟ 3. ∆ΥΝΑΜΙΚΟΙ ΧΩΡΟΙ ΚΑΙ ΕΠΑΥΞΗΤΙΚΗ ΕΠΙΛΟΓΗ ΧΑΡΑΚΤΗΡΙΣΤΙΚΩΝ
3.4.1 Υπερφόρτωση Πληροφορίας
Η εκρηκτική ανάπτυξη του παγκόσµιου ιστού τα τελευταία χρόνια είχε σηµαντική ε-
πίδραση στην ανθρώπινη καθηµερινότητα. Η σηµαντικότερη αλλαγή που έφερε το
διαδίκτυο είναι η άµεση και χωρίς ιδιαίτερο κόστος πρόσβαση σε µεγάλη ποσότητα
πληροφορίας. Τελευταία όµως ο όγκος της πληροφορίας έχει γιγαντωθεί σε ϐαθµό
τέτοιο ώστε να δηµιουργούνται σηµαντικά προβλήµατα σε διάφορους τοµείς της δια-
δικτυακής δραστηριότητας του χρήστη. Το πρόβληµα αυτό ονοµάζεται Υπερφόρτωση
Πληροφορίας (Information Overload). Κατά την ενηµέρωσή µέσω του διαδικτύου, ο
χρήστης έχει στη διάθεσή του ένα µεγάλο αριθµό πηγών των οποίων µάλιστα τις πε-
ϱισσότερες ϕορές δε γνωρίζει την αξιοπιστία και εγκυρότητα. Απαιτείται εποµένως µία
επιπλέον προσπάθεια για την ανάλυση και διασταύρωση όλων αυτών των πληροφοριών.
Το ίδιο πρόβληµα εµφανίζεται και στο ηλεκτρονικό ταχυδροµείο όπου ο ϕάκελος των
εισερχοµένων κατακλύζεται καθηµερινά από αδιάφορα µηνύµατα που µπορεί να απο-
στέλνονται από ϕίλους, συνεργάτες ή και αποστολείς spam µηνυµάτων. Το ϕαινόµενο
αυτό είναι γνωστό και ως Υπερφόρτωση Ηλεκτρονικού Ταχυδροµείου (Email Overload).
Η Μηχανική Μάθηση και ιδιαίτερα η ταξινόµηση κειµένων ϕάνηκε ότι ϑα παίξει
σηµαντικό ϱόλο στην επίλυση του προβλήµατος της υπερφόρτωση πληροφορίας. Μέχρι
σήµερα όµως, δε ϕαίνεται να έχουν καθιερωθεί εφαρµογές ή λογισµικό που κάνουν
χρήση τεχνικών µηχανικής µάθησης για αυτόν το σκοπό. Θα µπορούσε να αναφερθεί
ως εξαίρεση η εφαρµογή µεθόδων -κυρίως- Bayes σε λογισµικό ϕιλτραρίσµατος spam
µηνυµάτων (Androutsopoulos et al., 2000) καθώς συστήµατα όπως το SpamAssasin6,
το Spam Bayes 7 και ο Mozilla Thunderbird8 είναι ιδιαίτερα διαδεδοµένα. Αντίστοιχα
όµως, στον τοµέα της ανάγνωσης ειδήσεων δεν υπάρχουν σχετικά συστήµατα. Με
την ανάπτυξη του PersoNews γίνεται µία προσπάθεια µετρίασης του προβλήµατος της
υπερφόρτωσης πληροφορίας στην ανάγνωση ειδήσεων µέσω διαδικτύου.
3.4.2 Σχετικά Συστήµατα
Τα συστήµατα που σχετίζονται µε το PersoNews οµαδοποιούνται σε τέσσερις κατηγο-
ϱίες :
i Συγκεντρωτές RSS
ii Κοινωνικά δίκτυα
iii Προσαρµοστικά συστήµατα ανάγνωσης ειδήσεων
iv Προσαρµοστικοί συγκεντρωτές RSS
Τα παραπάνω συστήµατα ϐοηθούν τον χρήστη να ενηµερωθεί αποτελεσµατικότερα
µε έναν ή περισσότερους από τους παρακάτω τρόπους :
6The Apache SpamAssassin Project - http://spamassassin.apache.org/
7SpamBayes - http://spambayes.sourceforge.net/
8Mozilla Thunderbird - http://www.mozilla.com/en-US/thunderbird/
62
3.4. ΕΝΑ ΠΡΟΣΑΡΜΟΣΤΙΚΟ ΣΥΣΤΗΜΑ ΑΝΑΓΝΩΣΗΣ ΕΙ∆ΗΣΕΩΝ
Πίνακας 3.3: Σχετικά Συστήµατα
΄Ονοµα Πολ. Πηγές Προσαρµ. Ανάδραση Μέθοδος
Google Reader Ναι ΄Οχι ΄Οχι -
BlogLines Ναι ΄Οχι ΄Οχι -
SharpReader Ναι ΄Οχι ΄Οχι -
Thunderbird Ναι ΄Οχι ΄Οχι -
Digg Ναι ΄Οχι ΄Αµεση -
Newscloud Ναι ΄Οχι ΄Αµεση -
Krakatoa ΄Οχι Ναι ΄Αµεση Βάσει Περιεχ.
WebClipping2 ΄Οχι Ναι ΄Εµµεση Βάσει Περιεχ.
NewsDude ΄Οχι Ναι ΄Αµεση Βάσει Περιεχ.
Categorizor ΄Οχι Ναι ΄Αµεση Βάσει Περιεχ.
Findory Ναι Ναι ΄Εµµεση Βάσει Περιεχ/Χρ.
Spotback Ναι Ναι ΄Αµεση Βάσει Χρηστών
Reddit Ναι Ναι ΄Εµµεση Βάσει Περιεχ.
Google News Ναι Ναι ΄Εµµεση. Βάσει Χρηστών
PNS Ναι Ναι ΄Εµµεση Βάσει Χρηστών
MyFeeds Ναι Ναι ΄Αµεση Βάσει Περιεχ.
i Συγκεντρώνοντας πολλές πηγές ειδήσεων σε µία εφαρµογή
ii Φιλτράροντας τα αδιάφορα άρθα για λογαριασµό του χρήστη
iii Προτείνοντάς του ενδιαφέροντα άρθρα
Ο Πίνακας 3.3 περιλαµβάνει τα ϐασικά χαρακτηριστικά για τα συστήµατα που ϑα
αναφερθούν σε αυτήν την ενότητα. Συγκεκριµένα, για κάθε σύστηµα αναφέρεται : α)
αν διαχειρίζεται ή όχι πολλαπλές πηγές, ϐ) αν είναι ή όχι προσαρµοστικό (αν προ-
σαρµόζεται δηλαδή στα ενδιαφέροντα του χρήστη) και ποια µέθοδος χρησιµοποιείται
για το σκοπό αυτό, και γ) ο τύπος της ανάδρασης (άµεση ή έµµεση) που δέχεται το
σύστηµα.
Συγκεντρωτές RSS
Αυτή η κατηγορία αποτελείται από συστήµατα που επιτρέπουν στον χρήστη να πα-
ϱακολουθεί και να διαχειρίζεται πολλαπλές τροφοδοσίες RSS (RSS Feeds) αλλά και
blogs. Παραδείγµατα τέτοιων συστηµάτων είναι διαδικτυακές εφαρµογές όπως το Goo-
gle Reader9 και το Bloglines10, λογισµικό όπως το SharpReader11 αλλά και σύγχρονα
προγράµµατα διαχείρισης ηλεκτρονικής αλληλογραφίας όπως ο Mozilla Thunderbird.
9Google Reader - http://reader.google.com
10Bloglines - http://www.bloglines.com/
11Sharpreader RSS Aggregator - http://www.sharpreader.net/
63
ΚΕΦΑΛΑΙΟ 3. ∆ΥΝΑΜΙΚΟΙ ΧΩΡΟΙ ΚΑΙ ΕΠΑΥΞΗΤΙΚΗ ΕΠΙΛΟΓΗ ΧΑΡΑΚΤΗΡΙΣΤΙΚΩΝ
Αυτά τα συστήµατα προφανώς δεν παρέχουν εξατοµικευµένη πληροφόρηση αφού δεν
προσαρµόζονται στα ενδιαφέροντα του χρήστη.
Κοινωνικά ∆ίκτυα
Οι πηγές των άρθρων των συστηµάτων αυτών είναι ουσιαστικά οι ίδιοι οι χρήστες. Οι
χρήστες καταχωρούν, διαβάζουν και αξιολογούν τα άρθρα. Τα δηµοφιλέστερα από
αυτά (π.χ. τα άρθρα µε τις περισσότερες ϑετικές κριτικές) προτείνονται σε όλους τους
χρήστες. Παραδείγµατα τέτοιων εφαρµογών είναι διαδικτυακοί τόποι όπως το digg12
και το Newscloud13. Τα συστήµατα αυτά, ϐοηθούν τους χρήστες να εντοπίσουν ση-
µαντικά άρθρα γενικού ενδιαφέροντος αλλά το στοιχείο της εξατοµίκευσης απουσιάζει.
Προσαρµοστικά Συστήµατα Ανάγνωσης Ειδήσεων
Στο παρελθόν έχουν προταθεί συστήµατα εξατοµικευµένης ανάγνωσης ειδήσεων όπως
για παράδειγµα αυτά που περιγράφονται στις εργασίες (Bharat et al., 1998; Billsus
and Pazzani, 1999; Carreira et al., 2004). Τα συστήµατα αυτά στηρίζονται σε τεχνικές
µηχανικής µάθησης αλλά δυστυχώς παρουσιάστηκαν ως ερευνητικά προτότυπα και
δεν είναι διαθέσιµα για χρήση στο ευρύ κοινό.
Ο Bharat και οι συνεργάτες του (1998) για παράδειγµα, παρουσίασαν µία εξατοµι-
κευµένη ηλεκτρονική εφηµερίδα (The Karakatoa Chronicles) η οποία δηµιουργείται
αυτόµατα για κάθε χρήστη ϐασιζόµενη στην ανάδραση του µε το σύστηµα. Η προτει-
νόµενη προσέγγιση περιλαµβάνει την µετατροπή των άρθρων σε διανύσµατα. ΄Εχοντας
εκφράσει το προφίλ του χρήστη επίσης ως διάνυσµα, υπολογίζεται η απόσταση (οµοιό-
τητα) του κάθε άρθου µε το χρήστη. Τα άρθρα εποµένως µπορούν να παρουσιαστούν
ταξινοµηµένα ϐάσει αυτής της οµοιότητας.
΄Ενας εξειδικευµένος περιηγητής ειδήσεων ("WebClipping2") για υπολογιστές πα-
λάµης (PDA) που ϐασίζονται στο σύστηµα Palm-OS περιγράφεται στην εργασία (Car-
reira et al., 2004). Οι συγγραφείς χρησιµοποιούν έναν ταξινοµητή Bayes για να
υπολογίσουν την πιθανότητα ένα συγκεκριµένο άρθρο να ενδιαφέρει το χρήστη. ΄Ενα
ενδιαφέρον στοιχείο της εργασίας είναι ότι το σύστηµα δε λαµβάνει άµεση (ή ϱητή -
explicit) ανάδραση (π.χ. ϐαθµολόγηση άρθρου). Αντ΄ αυτού, ο περιηγητής λαµβάνει
υπόψη του κάποια στοιχεία όπως ο συνολικός χρόνος ανάγνωσης, συνολικές γραµµές
κειµένου και τι ποσοστό αυτών διάβασε ο χρήστης, ο µέσος όρος των γραµµών που
διαβάζει ο χρήστης κτλ. Συνδυάζοντας τις µετρικές αυτές, το σύστηµα συµπεραίνει
για το αν ϐρήκε ο χρήστης ενδιαφέρον το άρθρο ή όχι και ανανεώνει το µοντέλο του
αναλόγως. Ο τρόπος ανάδρασης εποµένως σε αυτήν την περίπτωση είναι έµµεσος (ή
υποκρυπτόµενος - implicit).
Τέλος, οι Bilssus και Pazzani υλοποίησαν µία Java εφαρµογή που χρησιµοποιεί
τη ϐιβλιοθήκη πρακτόρων της Microsoft για να παρουσιάσει έναν κινούµενο χαρακτή-
12digg - http://digg.com/
13Newscloud - http://www.newscloud.com/
64
3.4. ΕΝΑ ΠΡΟΣΑΡΜΟΣΤΙΚΟ ΣΥΣΤΗΜΑ ΑΝΑΓΝΩΣΗΣ ΕΙ∆ΗΣΕΩΝ
ϱα ("News Dude") ο οποίος διαβάζει τα άρθρα στους χρήστες. Το σύστηµα υποστηρίζει
διάφορους τρόπους ανάδρασης όπως οι δηλώσεις ¨ενδιαφέρον¨, ¨αδιάφορο¨, ¨το ξέρω
ήδη αυτό¨, ¨πες µου περισσότερα για αυτό¨. Μετά από ένα στάδιο εκπαίδευσης, ο χρή-
στης µπορεί να Ϲητήσει από τον πράκτορα να συνθέσει ένα εξατοµικευµένο πρόγραµµα
ειδήσεων.
Τα συστήµατα αυτής της κατηγορίας παρέχουν εξατοµίκευση της πληροφορίας
αλλά δεν είναι διαθέσιµα στο κοινό και δεν υποστηρίζουν RSS και κατά συνέπεια
περιορίζονται σε µία µόνο πηγή.
Προσαρµοστικοί Συγκεντρωτές RSS
Συστήµατα όπως τα Findory14, Spotback15, Reddit16, Google News17, PNS18και My-
Feeds19 είναι αυτά που ϐρίσκονται περισσότερο κοντά στα χαρακτηριστικά του Per-
soNews. Οι εφαρµογές αυτές συγκεντρώνουν πληροφορίες για τους χρήστες τους α)
∆εχόµενα ανάδραση του χρήστη (π.χ. ο χρήστης ϐαθµολογεί τα άρθρα - Reddit, Spot-
back και MyFeeds) ή ϐ) Παρατηρώντας τη συµπεριφορά του χρήστη (π.χ. ποια άρθρα
διαβάζει - Findory, Google News, PNS). ΄Εχοντας αυτή την πληροφορία τα συστήµατα
αυτά µπορούν αυτόµατα να παρουσιάζουν εξατοµικευµένες ειδήσεις χρησιµοποιώντας
κυρίως δύο προσεγγίσεις :
− Βάσει περιεχοµένου (content-based): Χρησιµοποιούνται ταξινοµητές µηχανικής
µάθησης ή απλές µετρικές οµοιότητας για να χαρακτηρισθεί ένα άρθρο ενδιαφέ-
ϱον ή αδιάφορο σύµφωνα µε το περιεχόµενο (λέξεις) του κειµένου. Παράδειγµα
αυτής της κατηγορίας είναι το σύστηµα reddit.
− Βάσει µνήµης (memory-based): Σε αυτήν την περίπτωση οι χρήστες που ϐαθ-
µολογούν µε παρόµοιο τρόπο ίδια αντικείµενα ϑεωρούνται γείτονες και κατά
συνέπεια προτείνονται στους χρήστες άρθρα που δεν έχουν ακόµη διαβάσει, αλ-
λά ϑεωρήθηκαν αξιόλογα από τους γείτονές τους (Google News, Findory, PNS).
Οι µεθοδολογίες που χρησιµοποιούνται αντλούνται από την περιοχή της Συνερ-
γατικής ∆ιήθησης (Collaborative Filtering).
Το προφανές πλεονέκτηµα αυτών των συστηµάτων είναι η εξατοµίκευση που πα-
ϱέχουν µε στόχο την αντιµετώπιση της υπεφόρτωσης πληροφορίας. Τα κύρια πλεονε-
κτήµατα του PersoNews έναντι αυτών είναι :
i Η εφαρµογή ενός αποδοτικού και αποτελεσµατικού πλαισίου µηχανικής µάθησης
ειδικά σχεδιασµένου για εφαρµογές ταξινόµησης ϱοών κειµένων.
14Findory - http://www.findory.com
15Spotback - http://spotback.com
16Reddit - http://www.reddit.com
17Google News - http://news.google.com
18PNS - http://pns.iit.demokritos.gr/
19MyFeeds - http://www.myfeeds.net/
65
ΚΕΦΑΛΑΙΟ 3. ∆ΥΝΑΜΙΚΟΙ ΧΩΡΟΙ ΚΑΙ ΕΠΑΥΞΗΤΙΚΗ ΕΠΙΛΟΓΗ ΧΑΡΑΚΤΗΡΙΣΤΙΚΩΝ
Σχήµα 3.4: Η αρχιτεκτονική τουPersoNews
ii Η χρήση ταξινοµίας ϑεµάτων µε στόχο να δοθεί στο χρήστη η δυνατότητα να παρα-
κολουθεί γενικά ϑέµατα ενδιαφέροντος.
iii Η εξατοµίκευση πληροφορίας γίνεται ξεχωριστά για κάθε χρήστη και για κάθε
ϑεµατική περιοχή ή τροφοδοσία ειδήσεων που αυτός παρακολουθεί.
iv Η απόκρυψη των αδιάφορων ειδήσεων αντί της κατάταξης τους σύµφωνα µε τη
σχετικότητα ϑεωρούµε ότι αποτελεί καταλληλότερη προσέγγιση για το πρόβληµα
της υπερφόρτωσης πληροφορίας.
3.4.3 Αρχιτεκτονική του Συστήµατος PersoNews
Το PersoNews, αποτελείται από τρία ϐασικά στοιχεία που λειτουργούν παράλληλα
ενώ χρησιµοποιούν µία κοινή ϐάση δεδοµένων για να αποθηκεύουν και να ανακτούν
πληροφορία. Τα στοιχεία αυτά είναι τα PersoNews Aggregator, PersoNews Email και
PersoNews Portal και αναλύονται σε αυτή την ενότητα. Συνολικά, η αρχιτεκτονική του
συστήµατος ϕαίνεται στην Εικόνα 3.4.
PersoNews Aggregator
Ο Συγκεντρωτής (Aggregator) του PersoNews συγκεντρώνει περιοδικά τα νέα άρθρα
από όλες τις τροφοδοσίες RSS που είναι καταχωρηµένες στο σύστηµα. Στη ϐάση
δεδοµένων καταχωρούνται µετα-δεδοµένα για κάθε άρθρο όπως ο τίτλος, η περιγραφή,
66
3.4. ΕΝΑ ΠΡΟΣΑΡΜΟΣΤΙΚΟ ΣΥΣΤΗΜΑ ΑΝΑΓΝΩΣΗΣ ΕΙ∆ΗΣΕΩΝ
Σχήµα 3.5: Περιγραφή Ταξινοµίας σε XML
η ηµεροµηνία και η ηλεκτρονική διεύθυνση του άρθρου. Την ίδια στιγµή γίνεται και
η ταξινόµηση των άρθρων ως ενδιαφέροντα (interesting) ή αδιάφορα (junk) για κάθε
χρήστη ξεχωριστά. Η ταξινόµηση γίνεται µε τη µέθοδο INB+IFS που περιγράφεται
στην Ενότητα 3.3, κυρίως λόγω της υπεροχής της στο σύνολο news.
Κατά την προεπεξεργασία των άρθρων πραγµατοποιείται ένα στάδιο αποκοπής κα-
ταλήξεων των λέξεων (stemming) σύµφωνα µε τον αλγόριθµο που πρότεινε ο Martin
Porter (1980). Η διαδικασία αυτή αποτελεί ϐασικό στάδιο προεπεξεργασίας για πολλές
διεργασίες εξόρυξης κειµένων (π.χ. ταξινόµηση, οµαδοποίηση, ανάκτηση, περίληψη)
αφού συχνά το κοινό ϑέµα των λέξεων ϕανερώνει παρόµοια σηµασιολογία. Κατά συ-
νέπεια, ϑεωρείται καλή τακτική, λέξεις µε κοινό ϑέµα να αντιµετωπίζονται ως ίδιες.
Στο PersoNews, ο χρήστης εκτός από συγκεκριµένες τροφοδοσίες RSS µπορεί να
επιλέξει να παρακολουθεί άρθρα που αφορούν ένα ϑέµα ενδιαφέροντος όπως ‘∆ιαχείρι-
ση Βάσεων ∆εδοµένων’ από µία ταξινοµία ϑεµάτων. Τα άρθρα τοποθετούνται αυτόµατα
σε αυτές τις ϑεµατικές κατηγορίες για κάθε χρήστη ξεχωριστά συνδυάζοντας αναζήτηση
ϐάσει λέξεων-κλειδιών και προσωπικούς ταξινοµητές. Η ταξινοµία των ϑεµάτων ορίζε-
ται από ένα XML έγγραφο όπως αυτό που ϕαίνεται στο Σχήµα 3.5. Προς το παρόν, ως
ϐασική ταξινοµία έχει εισαχθεί αυτή της επιστήµης υπολογιστών της ACM (ACM Com-
puting Classification System20). Στο πρώτο επίπεδο περιέχει γενικά ϑέµατα όπως
‘‘Hardware’’ και ‘‘Software’’, ενώ στη συνέχεια ειδικότερα όπως ‘‘Memory Structures’’
και ‘‘Programming Languages’’. Να σηµειωθεί ότι στο σύστηµα µπορεί να εισαχθεί
οποιαδήποτε ταξινοµία αρκεί να εκφράζεται σε XML όπως ϕαίνεται στο Σχήµα 3.5.
20ACM Computing Classification System - http://www.acm.org/class/
67
ΚΕΦΑΛΑΙΟ 3. ∆ΥΝΑΜΙΚΟΙ ΧΩΡΟΙ ΚΑΙ ΕΠΑΥΞΗΤΙΚΗ ΕΠΙΛΟΓΗ ΧΑΡΑΚΤΗΡΙΣΤΙΚΩΝ
Για κάθε χρήστη και κάθε ϑέµα που έχει επιλέξει αυτός να παρακολουθεί η εξατο-
µίκευση υλοποιείται σε δύο επίπεδα. Στο πρώτο επίπεδο πραγµατοποιείται αναζήτηση
ϐάσει λέξεων κλειδιών. Συγκεκριµένα, όταν ο χρήστης επιλέξει να παρακολουθεί το
ϑέµα ‘‘Database Systems’’, το PersoNews αναζητά στη ϐάση των άρθρων κείµενα τα
οποία περιέχουν λέξεις από τους τίτλους των υποκατηγοριών του (π.χ. ‘‘Distributed
Databases’’, ‘‘Multimedia Databases’’ κτλ). Οι χρήστες µπορούν να προσθέσουν και
δικές τους λεξεις κλειδιά σε κάθε κόµβο της ταξινοµίας. Στο δεύτερο επίπεδο, υπάρχει
ένας ταξινοµητής για κάθε Ϲεύγος χρήστη-ϑέµατος όπου καταφθάνουν µόνο τα άρθρα
που περνάνε επιτυχώς το πρώτο επίπεδο. Ο ταξινοµητής, όπως και στην περίπτωση
των τροφοδοσιών, είναι ο INB+IFS που περιγράφεται στην Ενότητα 3.3.
Τα δύο επίπεδα εξατοµίκευσης που περιγράφηκαν παραπάνω ϕαίνονται στο Σχήµα
3.6
PersoNews Email
Το PersoNews Email είναι το στοιχείο που ενηµερώνει τους χρήστες µέσω ηλεκτρονι-
κού ταχυδροµείου για τα νέα ενδιαφέροντα άρθρα στις τροφοδοσίες και ϑέµατα που
είναι εγγεγραµµένοι. Η αποστολή των µηνυµάτων γίνεται µία ϕορά τη µέρα. ∆ίνεται η
δυνατότητα στο χρήστη να ενηµερώνεται µόνο για συγκεκριµένες τροφοδοσίες και ϑέ-
µατα από αυτά που έχει εγγραφεί. Οι ενηµερώσεις µέσω ηλεκτρονικού ταχυδροµείου
ϑεωρούµε ότι είναι σηµαντικές αφού επιτρέπουν στον χρήστη να ενηµερώνεται χωρίς
να χρειάζεται να επισκέπτεται τη σελίδα του PersoNews συνεχώς.
PersoNews Portal
Το PersoNews Portal είναι µία δυναµική διαδικτυακή εφαρµογή προσβάσιµη από
οποιονδήποτε περιηγητή (browser) στη διεύθυνση http://news.csd.auth.gr/. ΄Εχει
σχεδιαστεί µε ϐάσει W3C πρότυπα όπως είναι η XHTML1.0, τα Cascading Style She-
ets, η Javascript και η Dynamic HTML. Η αρχική σελίδα του PersoNews ϕαίνεται στο
Σχήµα 3.7.
3.4.4 Λειτουργικότητα Συστήµατος
Μετά την εγγραφή του ο χρήστης µπορεί να επιλέξει να παρακολουθήσει µία τροφοδο-
σία RSS από τις διαθέσιµες στο σύστηµα ή να καταχωρήσει µία νέα. Υπάρχει επίσης
η δυνατότητα να εισάγει µαζικά µεγάλο αριθµό τροφοδοσιών µέσω του πρωτοκόλλου
OPML. Στο Σχήµα 3.8 ϕαίνεται µία τροφοδοσία όπως την παρακολουθεί ο χρήστης
µέσα από το PersoNews.
Μία συνήθης τακτική των προσαρµοστικών συστηµάτων ανάγνωσης ειδήσεων είναι
να παρουσιάζουν όλα τα άρθρα στο χρήστη αλλά ταξινοµηµένα σύµφωνα µε ϐαθµό
συσχέτισης µε τα ενδιαφέροντά του. Για το PersoNews, όπως αναφέρθηκε ήδη, υιοθε-
τήθηκε µία προσέγγιση ϕιλτραρίσµατος (απόκρυψης) των αδιάφορων άρθρων καθώς
68
3.4. ΕΝΑ ΠΡΟΣΑΡΜΟΣΤΙΚΟ ΣΥΣΤΗΜΑ ΑΝΑΓΝΩΣΗΣ ΕΙ∆ΗΣΕΩΝ
User
myFeeds myTopics
PersoNews Web Interface
F
ee
db
ac
k
Feed1 Feed2 FeedN
Classifier Classifier
Article DataBase
Topic
2
Topic
1
Topic Hierarchy
Selected 
Feeds
Selected 
Topics
Classifier Classifier
Query
Results
P
er
so
na
liz
ed
 
N
ew
s
…..
F
ee
db
ac
k
P
er
so
na
liz
ed
 
N
ew
s
F
ee
db
ac
k
P
er
so
na
liz
ed
 
N
ew
s
F
ee
db
ac
k
P
er
so
na
liz
ed
 
N
ew
s
F
ee
db
ac
k
Σχήµα 3.6: Εξατοµίκευση στο PersoNews
69
ΚΕΦΑΛΑΙΟ 3. ∆ΥΝΑΜΙΚΟΙ ΧΩΡΟΙ ΚΑΙ ΕΠΑΥΞΗΤΙΚΗ ΕΠΙΛΟΓΗ ΧΑΡΑΚΤΗΡΙΣΤΙΚΩΝ
Σχήµα 3.7: Η αρχική σελίδα του personews
ϑεωρούµε ότι είναι καταλληλότερη για το πρόβληµα της υπερφόρτωσης πληροφορί-
ας. ΄Ολα τα άρθρα που ταξινοµούνται αυτόµατα ως αδιάφορα (junk) µεταφέρονται σε
αντίστοιχο ϕάκελο χωρίς όµως να διαγραφούν.
΄Οσον αφορά στην ανάδραση του χρήστη, που ορίζει ουσιαστικά και τον τρόπο µε
τον οποίο τροφοδοτούνται οι ταξινοµητές µε παραδείγµατα, υιοθετήθηκε µία προσέγ-
γιση που συνδυάζει άµεση και έµµεση ανάδραση. Συγκεκριµένα, όταν ο χρήστης
(αφού διαβάσει τον τίτλο του άρθρου και την περίληψη) ακολουθήσει το σύνδεσµο
προς το πλήρες άρθρο, ϑεωρούµε ότι ενδιαφέρθηκε για αυτό και χαρακτηρίζεται ως
παράδειγµα της τάξης ‘ενδιαφέρον άρθρο’ (έµµεση ανάδραση). Αν αντίθετα, ένα άρθρο
χαρακτηρίσει ως junk από το χρήστη πατώντας το σχετικό εικονίδιο τότε προφανώς το
συγκεκριµένο άρθρο αποτελεί παράδειγµα της τάξης ‘αδιάφορο άρθρο’ (άµεση ανά-
δραση). Το σύστηµα αυτόµατα ταξινοµεί τα αδιάφορα άρθρα στο ϕάκελο junk αλλά
ο χρήστης έχει πάντα τη δυνατότητα να διορθώσει τη λάθος ταξινόµηση µεταφέροντάς
το πίσω στα εισερχόµενα. Γίνονται τότε οι ανάλογες ενέργειες για την αναίρεση του
παραδείγµατος ως αρνητικό και την ενσωµάτωσή του ως ϑετικό. Με τη συγκεκριµέ-
νη πολιτική ανάδρασης ο χρήστης απαλλάσσεται από το ϕόρτο της αξιολόγησης των
άρθρων µε ϐάση κάποια κλίµακα.
Παρόµοια λειτουργικότητα υπάρχει και στα ϑέµατα. Στην Εικόνα 3.9α ϕαίνεται η
σελίδα επιλογής ϑέµατος από το χρήστη ενώ το Σχήµα 3.9ϐ παρουσιάζει τη ϕόρµα επε-
ξεργασίας λέξεων κλειδιών από ένα συγκεκριµένο ϑέµα. Ο χειρισµός και η ανάγνωση
ενός ϑέµατος είναι παρόµοια µε αυτή των τροφοδοσιών, µε τη διαφορά ότι ο χρήστης
µπορεί επιπλέον να επισκεφθεί την τροφοδοσία του άρθρου, να την προσθέσει σε αυτές
που παρακολουθεί ή να την τοποθετήσει σε µία «µαύρη λίστα», έτσι ώστε να µη δέχεται
άρθρα από αυτήν την πηγή ακόµη και αν περνούν τα δύο στάδια ϕιλτραρίσµατος.
70
3.4. ΕΝΑ ΠΡΟΣΑΡΜΟΣΤΙΚΟ ΣΥΣΤΗΜΑ ΑΝΑΓΝΩΣΗΣ ΕΙ∆ΗΣΕΩΝ
Σχήµα 3.8: Παράδειγµα τροφοδοσίας RSS όπως ϕαίνεται στο PersoNews
(α΄) (ϐ΄)
Σχήµα 3.9: Ιεραρχία ϑεµάτων και επεξεργασία λέξεων κλειδιών ϑέµατος
71
ΚΕΦΑΛΑΙΟ 3. ∆ΥΝΑΜΙΚΟΙ ΧΩΡΟΙ ΚΑΙ ΕΠΑΥΞΗΤΙΚΗ ΕΠΙΛΟΓΗ ΧΑΡΑΚΤΗΡΙΣΤΙΚΩΝ
3.4.5 Αξιολόγηση Συστήµατος
Το PersoNews ϐρίσκεται σε έκδοση beta και εποµένως δεν ενθαρρύνθηκαν χρήστες να
εγγραφούν σε αυτό. Παρόλο που µία αναλυτική αξιολόγηση είναι στα άµεσα σχέδιά
µας, προς το παρόν, πραγµατοποιήθηκε µία πρόχειρη αξιολόγηση των υπηρεσιών του
συστήµατος στην οποία συµµετείχαν 66 χρήστες.
Από τη λειτουργία έξι µηνών του συστήµατος υπολογίστηκε το ποσοστό των άρθρων
που ο ταξινοµητής αναγνώρισε ως junk (αδιάφορα) αλλά ο χρήστης τα µετακίνησε στον
ϕάκελο των εισερχοµένων. Το ποσοστό αυτό (το λεγόµενο και false positive (FP) rate
- ποσοστό λανθασµένων ϑετικών21 ταξινοµήσεων) ήταν κοντά στο 6% για τις τροφοδο-
σίες RSS και στο 11% στα ϑέµατα της ταξινοµίας. Οι αριθµοί αυτοί πάντως είναι ίσως
παραπλανητικοί αφού υπήρχαν χρήστες που δεν παρείχαν συστηµατικά ανάδραση
και κατά συνέπεια δεν υπήρχε η δυνατότητα να διαπιστωθούν οι λανθασµένες ταξι-
νοµήσεις. Αν ληφθούν υπόψη µόνο οι πιο συστηµατικοί στην ανάδραση χρήστες τα
ποσοστά τότε ϕτάνουν τα 29% και 30% αντίστοιχα. ΄Οπως παρατηρούµε το ποσοστό
των FP είναι υψηλότερο και στους δύο τύπους χρηστών για τις ϑεµατικές κατηγορίες.
Αυτό µπορεί να εξηγηθεί από την ανοµοιογένεια του περιεχοµένου στα πρώτα στάδια
της εκπαίδευσης. Αν και δεν ισχυριζόµαστε τη στατιστική εγκυρότητα αυτής της α-
ξιολόγησης, ϑωρούµε ότι οι ενδείξεις είναι ενθαρρυντικές. Επιπλέον, το συγκεκριµένο
πλαίσιο µηχανικής µάθησης έχει αξιολογηθεί σε παρόµοια δεδοµένα (ϐλέπε Ενότητα
3.3), οπότε πιστεύουµε ότι µε συστηµατική ανάδραση από τους χρήστες η απόδοση
του συστήµατος µπορεί να πλησιάσει τα επίπεδα που παρουσιάζονται στην Ενότητα
3.3.5.
Ζητήθηκε επίσης από τους χρήστες να συµπληρωθεί ένα ερωτηµατολόγιο µε σκοπό
να µετρηθεί η ικανοποίησή τους από το σύστηµα. Το ερωτηµατολόγιο αποτελείται από :
− 5 ερωτήσεις που αφορούν δηµογραφικά στοιχεία και συνήθειες ανάγνωσης ει-
δήσεων και άρθρων στο διαδίκτυο.
− 10 ερωτήσεις από το ερωτηµατολόγιο που προτείνεται στην εργασία (Chin et al.,
1988) και αφορά στην ευκολία µάθησης του συστήµατος.
− 10 ερωτήσεις που αφορούν τα χαρακτηριστικά και τη λειτουργικότητά του Per-
soNews.
Το ερωτηµατολόγιο παρατίθεται στο Παράρτηµα Α. Γενικά, οι χρήστες ήταν ικα-
νοποιηµένοι από τις δυνατότητες του συστήµατος και δήλωσαν ότι είναι εύκολο στην
κατανόηση και λειτουργικότητά του. Οι περισσότεροι από αυτούς δήλωσαν ότι ξο-
δεύουν περισσότερο χρόνο στην ανάγνωση άρθρων µε το PersoNews από πριν αλλά
συνήθως εντοπίζουν περισσότερα ενδιαφέροντα άρθρα. Πολλοί από αυτούς δήλωσαν
ότι δεν δίνουν συστηµατικά ανάδραση στο σύστηµα και κατά συνέπεια παρατήρησαν
ότι προσαρµόζεται στα ενδιαφέροντά τους µε µέτρια ταχύτητα. Αντίθετα, οι χρήστες
21Θεωρούµε ϑετική την τάξη junk
72
3.5. ΣΥΜΠΕΡΑΣΜΑΤΑ
που έδιναν συστηµατικά ανάδραση δήλωσαν ότι το σύστηµα προσαρµόζεται αρκετά
γρήγορα.
3.5 Συµπεράσµατα
Το κεφάλαιο αυτό επικεντρώθηκε σε έναν ενδιαφέροντα τύπο εννοιολογικής απόκλισης
που εµπεριέχεται στις ϱοές κειµένων : Την εµφάνιση νέων χαρακτηριστικών (λέξεων) µε
το πέρασµα του χρόνου. Στο παρελθόν, αυτός ο τύπος της εννοιολογικής απόκλισης
δεν είχε ληφθεί υπόψη από τις µεθόδους της ϐιβλιογραφίας αλλά αντιµετωπιζόταν µε
τη µη αποδοτική λύση της επανεκπαίδευσης. Παρουσιάστηκε ένα πλαίσιο µάθησης,
το οποίο συνδυάζει µία επαυξητική µέθοδο επιλογής χαρακτηριστικών µε έναν ταξινο-
µητή που µπορεί να λειτουργήσει σε δυναµικούς χώρους χαρακτηριστικών µε στόχο
να αντιµετωπιστεί αυτό το πρόβληµα. Τα πειραµατικά αποτελέσµατα αποδεικνύουν
ότι η προτεινόµενη προσέγγιση παρουσιάζει καλύτερη ορθότητα πρόβλεψης σε σχέση
µε την απλή επαυξητική µάθηση και ενθαρύννει τη µελλοντική έρευνα. Επιπλέον, η
συγκεκριµένη προσέγγιση είναι υπολογιστικά µη απαιτητική και απλή στην υλοποίη-
ση, οπότε ϑα µπορούσε να αποτελέσει µέθοδο ϐάσης στην περιοχή. Ελπίζουµε επίσης
ότι το σύνολο δεδοµένων news που προσοµοιώνει απότοµες εννοιολογικές αποκλίσεις
ϑα χρησιµοποιηθεί από την ερευνητική κοινότητα για παρόµοιες αξιολογήσεις.
Τέλος, εφαρµόστηκε το προτεινόµενο πλαίσιο µάθησης σε ένα προσαρµοστικό σύ-
στηµα ανάγνωσης ειδήσεων (PersoNews). Τα κύρια χαρακτηριστικά του είναι η εύκολη
διαχείριση πολλαπλών πηγών ειδήσεων, η απόκρυψη των αδιάφορων άρθρων από το
χρήστη και η δυνατότητα να παρακολουθήσει γενικά ϑέµατα ενδιαφέροντος από µία
ταξινοµία ϑεµάτων.
73
4
Ταξινόµηση Ροών Κειµένων µε
Επανεµφανιζόµενες ΄Εννοιες
Το κεφάλαιο αυτό επικεντρώνεται σε έναν ιδιαίτερο τύπο εννοιολογικής απόκλισης,
τις επανεµφανιζόµενες έννοιες. Το ϕαινόµενο αναφέρεται στην επανεµφάνιση κάποιων
εννοιών που χαρακτηρίζουν µία ή περισσότερες τάξεις του προβλήµατος ταξινόµησης.
Στο κεφάλαιο αυτό, προτείνεται ένα γενικό πλαίσιο ταξινόµησης ϱοών, κατά το ο-
ποίο δέσµες δεδοµένων µετασχηµατίζονται σε ένα νέο χώρο χαρακτηριστικών. Εκεί,
εφαρµόζεται ένας αλγόριθµος οµαδοποίησης ϱοών για την αναγνώριση των επανεµφα-
νιζόµενων εννοιών.
4.1 Εισαγωγή
Η πρόοδος που έχει σηµειωθεί τα τελευταία χρόνια σε τεχνολογία αισθητήρων, µέ-
σων αποθήκευσης και επικοινωνίας υπολογιστικών συστηµάτων έχει κάνει εφικτή την
καταγραφή µεγάλου όγκου ϱοών δεδοµένων (Aggarwal, 2007). Παραδείγµατα τέτοιων
ϱοών είναι τα αρχεία καταγραφής των εξυπηρετητών του παγκόσµιου ιστού (web server
log files και web page click streams), συναλλαγές όπως είναι οι χρήσεις πιστωτικής
κάρτας, δεδοµένα δικτύων αισθητήρων, ϱοές εικόνων (ϐίντεο) από κάµερες ασφαλεί-
ας, ϱοές ειδήσεων σε έναν αναγνώστη RSS, κτλ. Φυσικό επακόλουθο της εµφάνισης
τέτοιων δεδοµένων αποτέλεσε η εφαρµογή µεθόδων µηχανικής µάθησης µε στόχο την
αποτελεσµατικότερη διαχείρισή τους.
Η δυναµική ϕύση των ϱοών δεδοµένων όµως απαιτεί συνεχείς ή τουλάχιστον πε-
ϱιοδικές ενηµερώσεις του µοντέλου µάθησης έτσι ώστε να περιέχεται σε αυτό η πιο
πρόσφατη διαθέσιµη πληροφορία. Η ιδιότητα αυτή είναι ιδιαίτερα σηµαντική σε προ-
ϐλήµατα ταξινόµησης ϱοών όπου η έννοια µίας ή περισσότερων τάξεων αλλάζει σε
σχέση µε το χρόνο. Το ϕαινόµενο αυτό είναι κοινώς γνωστό ως εννοιολογική απόκλιση
(concept drift) (Tsymbal, 2004).
΄Ενας ιδιαίτερος τύπος εννοιολογικής απόκλισης είναι αυτός των επανεµφανιζόµε-
νων εννοιών (recurring contexts) (Widmer and Kubat, 1996) και αφορά στην εµφάνιση
εννοιών που έχουν παρουσιαστεί ξανά στο ιστορικό µίας ϱοής. Παρόλο που το ϕαι-
νόµενο αυτό είναι αρκετά συχνό σε πραγµατικά δεδοµένα (µετεωρολογικά ϕαινόµενα,
75
ΚΕΦΑΛΑΙΟ 4. ΤΑΞΙΝΟΜΗΣΗ ΡΟΩΝ ΚΕΙΜΕΝΩΝ ΜΕ ΕΠΑΝΕΜΦΑΝΙΖΟΜΕΝΕΣ ΕΝΝΟΙΕΣ
συνήθειες αγοραστών, κτλ), δεν είναι παρά ελάχιστες οι µέθοδοι ταξινόµησης που το
αντιµετωπίζουν (Widmer and Kubat, 1996; Harries et al., 1998; Forman, 2006).
Σε αυτό το κεφάλαιο προτείνεται µία µέθοδος οµάδας ταξινοµητών (classifier en-
semble), κατά την οποία χρησιµοποιείται ένα νέο µοντέλο αναπαράστασης κατάλληλο
για προβλήµατα ταξινόµησης ϱοών δεδοµένων που εµπεριέχουν εννοιολογική απόκλι-
ση (Katakis et al., 2009c). Συγκεκριµένα, η ϱοή διαχωρίζεται σε δέσµες δεδοµένων οι
οποίες µετασχηµατίζονται σε διανύσµατα που ονοµάζουµε εννοιολογικά (conceptual
vectors). Τα διανύσµατα αυτά περιέχουν πληροφορία που εκφράζει τις έννοιες που
περιγράφουν την αντίστοιχη δέσµη δεδοµένων. Στην προκύπτουσα ϱοή εννοιολογικών
διανυσµάτων εφαρµόζεται ένας αλγόριθµος οµαδοποίησης ϱοών. Με αυτόν τον τρόπο,
τα εννοιολογικά διανύσµατα (και κατά συνέπεια οι δέσµες δεδοµένων) οργανώνονται
σε οµάδες, όπου επικρατούν οι ίδιες ή παρόµοιες έννοιες. Απώτερος σκοπός είναι η
διατήρηση ενός ταξινοµητή για κάθε έννοια (οµάδα) της ϱοής.
Μία υλοποίηση της προτεινόµενης µεθόδου αξιολογείται σε δύο σύνολα δεδοµένων
ηλεκτρονικού ταχυδροµείου και συγκρίνεται µε πέντε µεθοδολογίες ταξινόµησης ϱοών
της ϐιβλιογραφίας. Τα αποτελέσµατα αποδεικνύουν την καταλληλότητα της προτεινό-
µενης αναπαράστασης και την αποτελεσµατικότητα των ειδικών σε έννοιες ταξινοµητών.
Συνολικά, η συνεισφορά του κεφαλαίου αυτού συνοψίζεται στα παρακάτω σηµεία :
− Προτείνεται ένα νέο µοντέλο αναπαράστασης κατάλληλο για προβλήµατα εννοιο-
λογικής απόκλισης και επανεµφανιζόµενων εννοιών.
− Προτείνεται ένα γενικό πλαίσιο ταξινόµησης ϱοών µε επανεµφανιζόµενες έννοιες.
− Παρουσιάζεται µία πειραµατική αξιολόγηση στην οποία συµµετέχει µία υλοποί-
ηση του προτεινόµενου πλαισίου και πέντε µεθοδολογίες ταξινόµησης ϱοών της
ϐιβλιογραφίας.
− Κατασκευάζονται και διατίθενται διαδικτυακά1 δύο σύνολα δεδοµένων ηλεκτρο-
νικού ταχυδροµείου που προσοµοιώνουν εννοιολογική απόκλιση. Στο ένα εκ
των δύο συνόλων εµπεριέχεται το ϕαινόµενο των επανεµφανιζόµενων εννοιών.
4.2 Μοντέλο Αναπαράστασης
Σε αυτήν την ενότητα, παρουσιάζονται τα προβλήµατα αναπαράστασης που εντοπίζον-
ται στις ϱοές δεδοµένων και στη συνέχεια προτείνεται ένα νέο µοντέλο αναπαράστασης,
κατάλληλο για προβλήµατα εννοιολογικής απόκλισης και επανεµφανιζόµενων εννοιών.
4.2.1 Προβλήµατα Αναπαράστασης Ροών ∆εδοµένων
Το κύριο πρόβληµα που εντοπίζεται κατά την ταξινόµηση ϱοών δεδοµένων είναι ότι υ-
πάρχει περίπτωση, αντικείµενα τα οποία ϐρίσκονται γεωµετρικά κοντά στο χώρο χαρα-
κτηριστικών να ανήκουν σε διαφορετικές τάξεις αν έχουν καταφθάσει σε διαφορετικές
1http://mlkd.csd.auth.gr/concept_drift.html
76
4.2. ΜΟΝΤΕΛΟ ΑΝΑΠΑΡΑΣΤΑΣΗΣ
8
4
7
9
13
6
12
10 2
5
11
3
1
14
(α) (β)
5
4
2
6
3
1
8
9
13
12
10
11
7
14
(γ) (δ)
5
4
2
6
3
1
7
y
x
y
x
y
x
y
x
t<td t>td
Σχήµα 4.1: Πρόβληµα ταξινόµησης στατικών δεδοµένων (α) και ϱοών δεδοµένων χωρίς
εννοιολογική απόκλιση (ϐ). Ταξινόµηση ϱοών δεδοµένων πριν (γ) και µετά (δ) τη στιγµή
της εννοιολογικής απόκλισης (td). Οι αριθµοί στα αντικείµενα δηλώνουν σειρά άφιξης.
χρονικές περιόδους. Χρησιµοποιούµε ένα απλό παράδειγµα για να παρουσιάσουµε
αυτό το πρόβληµα και να εξηγήσουµε το κίνητρο πίσω από το µετασχηµατισµό που
προτείνουµε.
Το Σχήµα 4.1α παρουσιάζει ένα στατικό πρόβληµα ταξινόµησης δύο διαστάσεων (x
και y). Τα αντικείµενα της τάξης ‘τετράγωνο’ (µικρή τιµή στο x και µικρή τιµή στο y) και
τα αντικείµενα της τάξης ‘τρίγωνο’ (µεγάλη τιµή στο x και µεγάλη τιµή στο y) µπορούν
εύκολα να διαχωριστούν µε ένα γραµµικό ταξινοµητή. Το Σχήµα 4.1ϐ αναπαριστά ένα
πρόβληµα ταξινόµησης ϱοών δεδοµένων χωρίς εννοιολογική απόκλιση. Οι αριθµοί
στα αντικείµενα δηλώνουν τη σειρά άφιξής τους. Παρατηρούµε ότι οι τάξεις διατηρούν
κοινά χαρακτηριστικά µε το πέρασµα του χρόνου και εποµένως τα αντικείµενά τους
µπορούν (έστω και δυναµικά) να διαχωριστούν στο χώρο των χαρακτηριστικών.
Τα σχήµατα 4.1γ και 4.1δ παρουσιάζουν ένα πρόβληµα ταξινόµησης ϱοών δεδοµέ-
νων µε εννοιολογική απόκλιση σε δύο διαφορετικές χρονικές περιόδους. Στην πρώτη
περίοδο (Σχήµα 4.1γ) πριν τη στιγµή της απόκλισης (t < td ) αντικείµενα µε µικρό x
και µικρό y χαρακτηρίζουν την κλάση τετράγωνο. ΄Επειτα όµως, µετά τη στιγµή της α-
πόκλισης (δηλ. µετά την άφιξη του αντικειµένου 7 - Σχήµα 4.1δ) οι έννοιες των τάξεων
‘τετράγωνο’ και ‘τρίγωνο’ αλλάζουν (στην περίπτωσή µας αντιµετατίθενται). Το γεγονός
αυτό είναι λογικό να προκαλέσει προβλήµατα σε ταξινοµητή που έχει εκπαιδευτεί από
δεδοµένα πριν την απόκλιση αλλά καλείται να παράγει προβλέψεις για δεδοµένα µετά
τη στιγµή της απόκλισης.
4.2.2 Εννοιολογικό Μοντέλο Αναπαράστασης
Στοχεύοντας στην αντιµετώπιση των προαναφερθέντων προβληµάτων αναπαράστασης
και στην αναγνώριση των (επανεµφανιζόµενων) εννοιών στη ϱοή, προτείνεται ένας µε-
τασχηµατισµός (M ) ο οποίος µετατρέπει τις δέσµες παραδειγµάτων σε διανύσµατα τα
οποία ονοµάζουµε εννοιολογικά (conceptual vectors). Τα διανύσµατα αυτά περιέχουν
πληροφορία η οποία περιγράφει τις έννοιες που έχουν καθιερωθεί στην αντίστοιχη δέ-
77
ΚΕΦΑΛΑΙΟ 4. ΤΑΞΙΝΟΜΗΣΗ ΡΟΩΝ ΚΕΙΜΕΝΩΝ ΜΕ ΕΠΑΝΕΜΦΑΝΙΖΟΜΕΝΕΣ ΕΝΝΟΙΕΣ
σµη παραδειγµάτων. Ο τελικός στόχος, όπως ϑα αναφερθεί αναλυτικότερα παρακάτω,
είναι να χρησιµοποιηθεί αυτή η αναπαράσταση για να αναγνωριστούν οι διαφορετικές
έννοιες στη ϱοή και να εφαρµοστεί ένας ταξινοµητής σε κάθε µία από αυτές.
Αρχικά, η ϱοή χωρίζεται σε δέσµες µικρού αριθµού παραδειγµάτων. Κάθε δέσµη
µετατρέπεται σε ένα εννοιολογικό διάνυσµα το οποίο αποτελείται από έναν αριθµό εν-
νοιολογικών συνόλων χαρακτηριστικών (conceptual feature sets). Κάθε σύνολο χαρα-
κτηριστικών αποτελείται από έναν αριθµό στοιχείων (ϐλέπε παρακάτω) και αντιστοιχεί
σε ένα χαρακτηριστικό του αρχικού χώρου.
Ας υποθέσουµε ότι τα δεδοµένα για τα οποία είναι άγνωστη η τάξη στην οποία
ανήκουν (Unlabeled- U) αλλά και αυτά που είναι γνωστή (Labeled- L), τα λεγόµενα
παραδείγµατα (examples), αναπαρίστανται ως διανύσµατα της µορφής :
~xU = (x1, x2, . . . , xn)



4.1
και
~xL =
(
x1, x2, . . . , xn , cj
)
,



4.2
όπου xi είναι η τιµή του χαρακτηριστικού fi , και cj ∈ C όπου C είναι το σύνολο των
τάξεων. Ο αριθµός των χαρακτηριστικών είναι n και ο αριθµός των τάξεων είναι m. Ας
υποθέσουµε ότι BU είναι δέσµες δεδοµένων για τα οποία δε γνωρίζουµε την τάξη στην
οποία ανήκουν ενώ BL είναι δέσµες δεδοµένων για τα οποία γνωρίζουµε την τάξη στην
οποία ανήκουν (δέσµες παραδειγµάτων) και εκφράζονται αντίστοιχα ως :
BU =
{
~xU (k), ~xU (k+1) . . . , ~xU (k+b−1)
} 


4.3
και
BL =
{
~xL(k), ~xL(k+1), . . . , ~xL(k+b−1)
}
,



4.4
όπου ~xU (k) και ~xL(k) είναι τα πρώτα δεδοµένα της κάθε δέσµης και b το µέγεθος των
δεσµών. Κάθε δέσµη παραδειγµάτων (BL ) µετασχηµατίζεται σε ένα εννοιολογικό διά-
νυσµα ~Z = (z1, z2, ..., zn), όπου zi είναι τα εννοιολογικά σύνολα χαρακτηριστικών.
Λαµβάνοντας υπόψη τα αντικείµενα που περιέχονται στη δέσµη BL και για κάθε χα-
ϱακτηριστικό fi του αρχικού χώρου χαρακτηριστικών τα εννοιολογικά σύνολα χαρα-
κτηριστικών υπολογίζονται ως εξής :
zi =

{
Pvi,j : j = 1..m, v ∈ Vi
}
, αν fi είναι ονοµαστικό{
µi,j, σi,j : j = 1..m
}
, αν fi είναι αριθµητικό
,



4.5
όπου
Pvi,j = P(fi = v|cj), i ∈ [1, n], j ∈ [1,m], v ∈ Vi ,



4.6
µε Vi να είναι το σύνολο των ονοµαστικών (nominal) χαρακτηριστικών fi . Ακολουθών-
τας το πρότυπο του naive Bayes ταξινοµητή, ο όρος Pvi,j ϑεωρείται ίσος µε Nv,j/Nj, όπου
Nv,j είναι ο αριθµός των παραδειγµάτων (της δέσµης BL ) της τάξης cj που έχουν την
τιµή v στην ιδιότητα i και Nj είναι ο αριθµός των παραδειγµάτων (της δέσµης BL ) που
78
4.2. ΜΟΝΤΕΛΟ ΑΝΑΠΑΡΑΣΤΑΣΗΣ
ανήκουν στη κλάση cj. Για αριθµητικές ιδιότητες χρησιµοποιούµε τον µέσο όρο (µi,j)
και την τυπική απόκλιση (σi,j) της ιδιότητας fi που προκύπτει από τα παραδείγµατα
της τάξης cj στη δέσµη BL . Μετά την άφιξη κάθε αντικειµένου, αν η πραγµατική τά-
ξη είναι γνωστή, τότε υπολογίζονται επαυξητικά τα παραπάνω στατιστικά µε στόχο να
δηµιουργηθούν τα διανύσµατα αµέσως µετά το τέλος της δέσµης.
Ο αναµενόµενος αριθµός διαστάσεων της νέας αναπαράστασης είναι av̄m + e2m,
όπου a και e είναι ο αριθµός των ονοµαστικών και αριθµητικών χαρακτηριστικών αντί-
στοιχα και v̄ είναι ο µέσος όρος του αριθµού των διαφορετικών τιµών των ονοµαστικών
χαρακτηριστικών. Για το πρόβληµα της ταξινόµησης κειµένων που αντιµετωπίζουµε σε
αυτό το κεφάλαιο χρησιµοποιώντας τη boolean bag-of-words αναπαράσταση έχουµε
a = n και e = 0 οπότε η πολυπλοκότητα είναι O(nm).
Το κίνητρο πίσω από τη συγκεκριµένη αναπαράσταση είναι ότι κάθε στοιχείο του
εννοιολογικού διανύσµατος εκφράζει σε ποιο ϐαθµό µία ιδιότητα χαρακτηρίζει µια
συγκεκριµένη τάξη. Ας υποθέσουµε ότι έχουµε έναν ταξινοµητή άρθρων όπως αυτόν
που παρουσιάσαµε στο προηγούµενο κεφάλαιο. Σε περίπτωση που παρατηρηθεί ό-
τι σε δύο διαφορετικές δέσµες παραδειγµάτων οι πιθανότητες P(cpu = 1|interesting)
και P(monitor = 1|interesting), δηλαδή οι πιθανότητες να είναι ένα άρθρο ενδιαφέρον
δεδοµένης της παρουσίας των λέξεων ‘‘cpu’’ και ‘‘monitor’’, είναι µε παρόµοιο τρόπο
υψηλές, ϑα µπορούσαµε να υποθέσουµε ότι σε αυτές τις δέσµες επικρατούν ίδιες ή
παρόµοιες έννοιες (όπου δηλ. άρθρα µε ϑέµα τους υπολογιστές ϑεωρούνται ενδιαφέ-
ϱοντα). Το ίδιο σκεπτικό ισχύει και για τις αριθµητικές τιµές. ∆έσµες παραδειγµάτων
στις οποίες οι µέσοι όροι που περιγράφηκαν παραπάνω έχουν παρόµοιες τιµές είναι
πιθανό να περιγράφονται από τις ίδιες έννοιες.
Κατά συνέπεια, ϑα µπορούσε να οριστεί η ‘εννοιολογική’ (σε αντιδιαστολή µε τη
‘γεωµετρική’) απόσταση δύο δεσµών BL(ψ) και BL(ω) ως η Ευκλείδεια απόσταση των
εννοιολογικών διανυσµάτων :
ConDis(BL(ψ),BL(ω)) = Euclidean(Z(ψ), Z(ω)) =
=
{
dis(z1(ψ), z1(ω)) + ... + dis(zn(ψ), zn(ω))
}1/2



4.7
όπου,
dis(zi(ψ), zi(ω)) =
(
ζ 1i(ψ) − ζ
1
i(ω)
)2
+ ... +
(
ζ li(ψ) − ζ
l
i(ω)
)2 


4.8
και ζ
j
i(ψ) είναι το j-οστό στοιχείο του i-οστού εννοιολογικού συνόλου χαρακτηριστικών
του διανύσµατος ψ. Το l αντιπροσωπεύει τον αριθµό στοιχείων των συνόλων.
Με το µετασχηµατισµό αυτό προσπαθούµε να διασφαλίσουµε ότι όσο πιο πολύ
µοιάζουν δύο δέσµες εννοιολογικά τόσο πιο µικρή ϑα είναι η απόσταση των αντίστοιχων
εννοιολογικών διανυσµάτων.
Η εικόνα 4.2 παρουσιάζει ένα πρόβληµα ταξινόµησης µε εννοιολογική απόκλιση
σε ένα µοντέλο αναπαράστασης όπως αυτό που παρουσιάζεται σε αυτήν την ενότητα.
Να σηµειωθεί ότι τα αντικείµενα σε αυτήν την περίπτωση αντιπροσωπεύουν δέσµες
παραδειγµάτων. Οι αριθµοί στα αντικείµενα δηλώνουν σειρά άφιξης. Το Σχήµα 4.2α
παρουσιάζει την απότοµη εννοιολογική απόκλιση ενώ το Σχήµα 4.2ϐ παρουσιάζει τη
79
ΚΕΦΑΛΑΙΟ 4. ΤΑΞΙΝΟΜΗΣΗ ΡΟΩΝ ΚΕΙΜΕΝΩΝ ΜΕ ΕΠΑΝΕΜΦΑΝΙΖΟΜΕΝΕΣ ΕΝΝΟΙΕΣ
(α)
2
1
5
4
3
6
7
8
2
1
5
43
6
7
8
Co
nce
pt 1
Co
nce
pt 2
Gr
ad
ua
lly
 C
ha
ng
ing
 C
on
ce
pt
Recurring 
Concept
M(y)
M(x) M(x)
M(y)
(β)
Σχήµα 4.2: Εννοιολογικά διανύσµατα στο νέο χώρο αναπαράστασης (α) Απότοµη Εν-
νοιολογική Απόκλιση µε επαναλαµβανόµενες έννοιες (ϐ) Σταδιακή απόκλιση µε επα-
ναλαµβανόµενες έννοιες. Οι αριθµοί στα αντικείµενα δηλώνουν σειρά άφιξης
σταδιακή εννοιολογική απόκλιση. Και στις δύο περιπτώσεις έχουµε επανεµφανιζόµε-
νες έννοιες. Ειδικότερα, στο Σχήµα 4.2α οι πρώτες δέσµες (1, 2, 3) ανήκουν στην ίδια
έννοια (Concept1). Μετά από τη δέσµη 3, παρουσιάζεται η εννοιολογική απόκλιση.
Παρόλα αυτά, η έννοια Concept1 επανεµφανίζεται µε τις δέσµες 7 και 8. Από το
σχήµα προκύπτει ότι µία πιθανή λύση του προβλήµατος ϑα ήταν η διατήρηση ενός τα-
ξινοµητή για κάθε έννοια που παρουσιάζεται στη ϱοή. Οι ειδικοί αυτοί ταξινοµητές ϑα
εκπαιδεύονται από δέσµες παραδειγµάτων που ανήκουν στην αντίστοιχη έννοια και
ϑα είναι ταυτόχρονα υπεύθυνοι για την ταξινόµηση των αντικειµένων που ϑεωρείται
ότι ανήκουν στην ίδια έννοια. Στο Σχήµα 4.2ϐ οι έννοιες µετατοπίζονται σταδιακά.
Παρόλα αυτά, οι δέσµες 5 και 8 ϕαίνεται να ϐρίσκονται κοντά εννοιολογικά. Ακόµα
και σε αυτή την περίπτωση ϕαίνεται ότι οι ταξινοµητές είναι αναγκαίο να διατηρούνται
στη µνήµη ώστε να χρησιµοποιηθούν σε περίπτωση που επανεµφανιστούν σχετικές
έννοιες.
Για να αξιολογηθεί η καταλληλότητα της προτεινόµενης αναπαράστασης, ϑα εφαρ-
µοστεί αργότερα ένας αλγόριθµος οµαδοποίησης (clustering) έτσι ώστε να παρατηρή-
σουµε τις οµάδες που προκύπτουν. Στόχος είναι να διαπιστωθεί αν µε τον προτεινόµε-
νο µετασχηµατισµό οι δέσµες δεδοµένων που ανήκουν στις ίδιες έννοιες ϑα ανατεθούν
από τον αλγόριθµο στις ίδιες οµάδες (ϐλέπε ενότητα 4.5.1).
4.3 Το πλαίσιο CCP
Σε αυτή την ενότητα παρουσιάζεται το προτεινόµενο πλαίσιο ταξινόµησης (CCP - Co-
nceptual Clustering & Prediction). Σε αυτό, χρησιµοποιείται ο µετασχηµατισµός που
προτάθηκε στην προηγούµενη ενότητα και ένας αλγόριθµος οµαδοποίησης ώστε να
80
4.3. ΤΟ ΠΛΑΙΣΙΟ CCP
      Ensemble
Time
Stream of Examples
Conceptual Vectors
Mapping Function
Classifier 
1
Classifier 
2
Cluster 1 Cluster 2Conceptual Feature Space
Clustering
Cluster Specific 
Classifiers
Batch of Examples
Σχήµα 4.3: Αρχιτεκτονική του Πλαισίου CCP
οργανωθούν οι διαφορετικές έννοιες σε οµάδες. Απώτερος σκοπός είναι η διατήρηση
ενός ταξινοµητή για κάθε έννοια της ϱοής. Η αρχιτεκτονική του πλαισίου ϕαίνεται στο
Σχήµα 4.3.
Τα ϐασικά στοιχεία του προτεινόµενου πλαισίου είναι :
− Μία συνάρτηση µετασχηµατισµού (Μ), η οποία µετατρέπει τις δέσµες παραδειγ-
µάτων BL(j) σε εννοιολογικά διανύσµατα Zj.
− ΄Ενας επαυξητικός αλγόριθµος οµαδοποίησης (R), ο οποίος οργανώνει τα εννοιο-
λογικά διανύσµατα σε οµάδες.
− ΄Ενας επαυξητικός ταξινοµητής (h), για κάθε έννοια (οµάδα) που αναγνωρίζεται
στη ϱοή.
Σε συνάρτηση µε το χρόνο (t) διατηρείται ένα σύνολο από οµάδεςGt = {g1, g2, ..., gq}
και ένα σύνολο αντίστοιχων ταξινοµητών Ht = {h1, h2, ..., hq}. Ο κάθε ταξινοµητής hi
εκπαιδεύεται από δέσµες που ανήκουν εννοιολογικά στην οµάδα gi . Αρχικά ισχύει
Go = ∅ και Ho = ∅. Η διαχείριση των οµάδων επαφίεται στον αλγόριθµο οµαδο-
ποίησης που χρησιµοποιείται. Στον αλγόριθµο Leader-Follower (οδηγός-ακόλουθος)
(Duda et al., 2000) που χρησιµοποιείται σε αυτό το κεφάλαιο, είναι απαραίτητη η
διατήρηση µόνο των κέντρων των οµάδων. Η κύρια λειτουργικότητα του CCP µπορεί
να διαχωριστεί σε δύο ενέργειες : Στη ∆υναµική Εκπαίδευση (Dynamic Training) και
στην ΄Αµεση Ταξινόµηση (Online Classification) των νέων δεδοµένων. Τα στάδια αυτά
περιγράφονται σύντοµα παρακάτω.
− ∆υναµική Εκπαίδευση. Μετά την άφιξη µίας δέσµης παραδειγµάτων BL(j), το
πλαίσιο CCP κατασκευάζει το αντίστοιχο εννοιολογικό διάνυσµα Z(j). Ο επαυξη-
τικός ταξινοµητής (R) είτε αναθέτει το Zj σε µία οµάδα gs ∈ G είτε δηµιουργεί
81
ΚΕΦΑΛΑΙΟ 4. ΤΑΞΙΝΟΜΗΣΗ ΡΟΩΝ ΚΕΙΜΕΝΩΝ ΜΕ ΕΠΑΝΕΜΦΑΝΙΖΟΜΕΝΕΣ ΕΝΝΟΙΕΣ
µία νέα οµάδα αν χρειαστεί. Στην πρώτη περίπτωση ο αντίστοιχος ταξινοµητής
hs ενηµερώνεται µε τα παραδείγµατα της δέσµης BL(j). Στη δεύτερη περίπτωση
ένας νέος ταξινοµητής δηµιουργείται και εκπαιδεύεται από τα παραδείγµατα της
δέσµης αυτής.
− ΄Αµεση Ταξινόµηση. Τα αντικείµενα της δέσµης BU (j+1) ταξινοµούνται µε ϐάση
τον ταξινοµητή hs που αντιστοιχεί στην οµάδα του προηγούµενου εννοιολογικού
διανύσµατος Z(j)
2.
Είσοδος: Μία ϱοή δεδοµένων xU (i). Μετά το τέλος κάθε δέσµης, οι
πραγµατικές τάξεις των δεδοµένων της ϑεωρούνται γνωστές. b:
Μέγεθος των δεσµών.
΄Εξοδος: ΄Αµεσες ταξινοµήσεις pi των δεδοµένων xU (i)
Αρχή1
H ← ∅, G ← ∅;2
s← 1, j ← 1;3
H ← H
⋃
{hs};4
για i = 1 έως άπειρο κάνε5
pi ← hs.ταξινόµηση( ~xU (i));6
αν i mod b = 0 τότε7
~BL(j) ← { ~xL(i−b), . . . , ~xL(i)};8
~Zj ← M( ~BL(j)) ;9
s← R.οµαδοποίηση(~Zj);10
αν ∃gsϸG τότε11
hs.ενηµέρωση( ~BL(j));12
R.ενηµέρωση(~Zj);13
αλλιώς14
gs ← ~Zj;15
G ← G
⋃
{gs};16
H ← H
⋃
{hs};17
hs.ενηµέρωση( ~BL(j));18
Τέλος19
Σχήµα 4.4: Η κύρια λειτουργικότητα του πλαισίου CCP
Σηµειώνεται, ότι οι παραπάνω δύο ενέργειες εκτελούνται παράλληλα όταν είναι
διαθέσιµες οι πραγµατικές τάξεις των δεδοµένων. Η ταξινόµηση της τρέχουσας δέσµης
από τον ταξινοµητή που έχει εκπαιδευτεί από την οµάδα της προηγούµενης δέσµης
2Αναγκαστικά, η πρώτη δέσµη δεδοµένων ϑα ταξινοµηθεί τυχαία από τον πρώτο µη-εκπαιδευµένο
ταξινοµητή ο οποίος µπορεί να ενηµερωθεί όταν οι τάξεις των δεδοµένων γίνουν γνωστές
82
4.3. ΤΟ ΠΛΑΙΣΙΟ CCP
αποτελεί µία υπόθεση τοπικότητας (Locality Assumption). Σύµφωνα µε την υπόθεση
αυτή, δύο διαδοχικές δέσµες (µικρού µεγέθους) τις περισσότερες ϕορές ϑα ανήκουν
στην ίδια έννοια. Είναι µία υπόθεση που γίνεται συχνά σε τέτοια προβλήµατα ταξινόµη-
σης κυρίως γιατί ο µόνος τρόπος να αναγνωριστεί η απόκλιση είναι να παρατηρηθούν
τα σφάλµατα του µοντέλου σε ένα µικρό χρονικό παράθυρο και να γίνουν οι ανάλογες
προσαρµογές ώστε να επιτευχθεί καλύτερη απόδοση στην επόµενη δέσµη δεδοµένων.
Χαρακτηριστικά παραδείγµατα τέτοιων προβληµάτων, αποτελούν οι έννοιες STAGGER
(Stagger Concepts) (Kolter and Maloof, 2003) και τα κινούµενα υπερεπίπεδα (Moving
Hyperplances) (Hulten et al., 2001). Η περίπτωση των συνεχών αλλαγών σε µικρό
χρονικό διάστηµα είναι δύσκολο να διακριθεί από την περίπτωση του ϑορύβου και
δεν εξετάζεται σε αυτό το κεφάλαιο. Επιπλέον, δεν εµφανίζεται συχνά σε πραγµατικά
προβλήµατα.
Το µέγεθος των δεσµών, αποτελεί ουσιαστικά µία παράµετρο που η τιµή της εξαρ-
τάται από το πρόβληµα που αντιµετωπίζεται κάθε ϕορά. Γενικά, η τιµή της πρέπει
να είναι αρκετά µικρή ώστε να µην ακυρώνεται η προαναφερθείσα υπόθεση τοπικότη-
τας, αλλά ταυτόχρονα ο αριθµός των παραδειγµάτων πρέπει να είναι αρκετός για τον
υπολογισµό των εννοιολογικών διανυσµάτων.
Ο ψευδοκώδικας του προτεινόµενου πλαισίου παρουσιάζεται στο Σχήµα 4.4. Να
σηµειωθεί ότι δεν απαιτείται η άµεση γνώση των πραγµατικών τάξεων των δεδοµένων
από το CCP. ΄Οπως ϕαίνεται από τη γραµµή 12 και 18 οι ενηµερώσεις πραγµατο-
ποιούνται µόνο όταν ολοκληρώνεται η άφιξη µίας δέσµης παραδειγµάτων. Γενικά το
CCP έχει τη δυνατότητα να συνεχίζει τη λειτουργία του χωρίς την απαίτηση των πραγ-
µατικών τάξεων των δεδοµένων. Συγκεκριµένα, οι γραµµές 7 έως 18 του ψευδοκώδικα
ϑα µπορούσαν να εκτελούνται µόνο όταν γίνει γνωστή η πραγµατική τάξη ενός συγ-
κεκριµένου αριθµού δεδοµένων. Ο αριθµός αυτός ϑα µπορούσε να οριστεί ίσος µε το
µέγεθος της δέσµης παραδειγµάτων.
Για την υλοποίηση του CCP µπορεί να χρησιµοποιηθεί οποιοσδήποτε αλγόριθµος
οµαδοποίησης ϱοών όπως ο αλγόριθµος Οδηγού-Ακόλουθου (Leader-Follower) (Duda
et al., 2000). Ο συγκεκριµένος αλγόριθµος (περισσότερες λεπτοµέρειες αναφέρονται
στην ενότητα 4.5.2) είτε αναθέτει ένα αντικείµενο σε µία υπάρχουσα οµάδα (cluster)
είτε δηµιουργεί µία νέα και αναθέτει εκεί το αντικείµενο. Συνεπώς, δεν διατηρούνται
στη µνήµη προηγούµενα δεδοµένα για την ενδεχόµενη ένωση ή διαχωρισµό οµάδων
όπως γίνεται σε άλλους αλγορίθµους ταξινόµησης ϱοών. ΄Οσον αφορά στο στοιχείο της
ταξινόµησης, µπορεί να χρησιµοποιηθεί γενικά οποιοσδήποτε επαυξητικός αλγόριθ-
µος ταξινόµησης.
Είναι σηµαντικό να σηµειώσουµε ότι δεν απαιτείται η διατήρηση στη µνήµη των
προηγούµενων δεσµών ή εννοιολογικών διανυσµάτων. Το µόνο που αποθηκεύεται
είναι η πληροφορία που αντιπροσωπεύει κάθε οµάδα (π.χ. το κέντρο κάθε οµάδας)
και οι αντίστοιχοι ταξινοµητές για κάθε οµάδα. ΄Οσον αφορά την υπολογιστική πολυ-
πλοκότητα του προτεινόµενου πλαισίου πρέπει να αναφερθεί ότι το επιπλέον κόστος
αφορά: α) Στον µετασχηµατισµό των δεδοµένων στα εννοιολογικά διανύσµατα και ϐ)
στην οµαδοποίηση των εννοιολογικών διανυσµάτων για την εύρεση του κατάλληλου
83
ΚΕΦΑΛΑΙΟ 4. ΤΑΞΙΝΟΜΗΣΗ ΡΟΩΝ ΚΕΙΜΕΝΩΝ ΜΕ ΕΠΑΝΕΜΦΑΝΙΖΟΜΕΝΕΣ ΕΝΝΟΙΕΣ
ταξινοµητή.
4.4 Σύνολα ∆εδοµένων
Για να αξιολογηθεί η προτεινόµενη µεθοδολογία δηµιουργήθηκαν δύο σύνολα δεδοµέ-
νων έτσι ώστε να προσοµοιωθεί το πρόβληµα της ταξινόνησης ϱοών κειµένων µε εννοιο-
λογική απόκλιση. Το πρώτο σύνολο περιέχει απότοµη εννοιολογική απόκλιση και επα-
νεµφανιζόµενες έννοιες ενώ το δεύτερο περιέχει σταδιακή εννοιολογική απόκλιση. Η
αναπαράσταση έχει γίνει σύµφωνα µε το µοντέλο boolean bag-of-words. Τα σύνολα δε-
δοµένων είναι διαθέσιµα στη διεύθυνση http://mlkd.csd.auth.gr/concept_drift.html
(Datasets 3).
4.4.1 Σύνολο Λίστας Ηλεκτρονικού Ταχυδροµείου
Το πρώτο σύνολο δεδοµένων (elist) αποτελεί µία ϱοή µηνυµάτων ηλεκτρονικού ταχυ-
δροµείου. Το πρόβληµα που προσοµοιώνεται µε αυτό το σύνολο είναι το αυτόµατο
ϕιλτράρισµα αδιάφορων µηνυµάτων. Μετά την άφιξη ενός µηνύµατος ο χρήστης έχει
τη δυνατότητα να επισηµειώσει το µήνυµα ως ενδιαφέρον (interesting) ή αδιάφορο
(junk). Στόχος είναι η διατήρηση ενός δυναµικού µοντέλου ταξινόµησης το οποίο ϑα
προσαρµόζεται στα ενδιαφέροντα του χρήστη και ϑα αναγνωρίζει µε ακρίβεια τα µη επι-
ϑυµητά µηνύµατα. Για την κατασκευή αυτής της ϱοής χρησιµοποιήθηκαν µηνύµατα
της συλλογής 20 Newsgroup Collection (Asuncion and Newman, 2007).
Επιλέχθηκαν µηνύµατα από συγκεκριµένες ϑεµατικές κατηγορίες. Αυτές ήταν
οι : science.medicine, science.space και recreation.sports.baseball. Το σύνολο που
προέκυψε αποτελείται από 1500 παραδείγµατα και 913 χαρακτηριστικά. Τα χαρακτη-
ϱιστικά είναι λέξεις που εµφανίστηκαν τουλάχιστον 10 ϕορές σε αυτήν τη συλλογή. Η
αναπαράσταση που χρησιµοποιήθηκε είναι η boolean bag-of-words. Η ϱοή χωρίστηκε
σε πέντε περιόδους των 300 παραδειγµάτων. Στο τέλος κάθε περιόδου τα ενδιαφέροντα
του χρήστη αλλάζουν έτσι ώστε να προσοµοιωθεί η εννοιολογική απόκλιση. Ο Πίνα-
κας 4.1 παρουσιάζει ποια µηνύµατα ϑεωρεί ο χρήστης ενδιαφέροντα (+) ή αδιάφορα
(-) σε κάθε χρονική περίοδο. Κατά την πρώτη περίοδο, ο χρήστης ενδιαφέρεται για
µηνύµατα που έχουν σχέση µε ιατρική. Παρατηρούµε ότι τα ενδιαφέροντα του χρήστη
σε κάποιες µη-διαδοχικές περιόδους είνα ίδια. Το χαρακτηριστικό αυτό εισήχθη µε
στόχο την προσοµοίωση των επανεµφανιζόµενων εννοιών.
4.4.2 Σύνολο Spam Filtering
Για τη δηµιουργία αυτού του συνόλου χρησιµοποιήθηκαν µηνύµατα από τη συλλογή
Spam Assassin Collection3. Λεπτοµέρειες για τη δηµιουργία του συνόλου αυτού
έχουν αναφερθεί στο προηγούµενο κεφάλαιο (ϐλ. ενότητα 3.3.2). Αποτελείται από
3The Apache SpamAssasin Project - http://spamassasin.apache.org/
84
4.5. ΑΞΙΟΛΟΓΗΣΗ
Πίνακας 4.1: Το σύνολο δεδοµένων ηλεκτρονικού ταχυδροµείου (elist). Μία ϑεµα-
τική οµάδα µπορεί να ϑεωρείται ενδιαφέρουσα (+) ή αδιάφορη (-) για το χρήστη σε
διαφορετική χρονική περίοδο.
0-300 300-600 600-900 900-1200 1200-1500
medicine + - + - +
space - + - + -
baseball - + - + -
9324 παραδείγµατα και 500 χαρακτηριστικά. ΄Οπως έχουµε δει και στο προηγούµενο
κεφάλαιο, τα δεδοµένα αυτά περιέχουν σταδιακή εννοιολογική απόκλιση.
4.5 Αξιολόγηση
Σε αυτή την ενότητα αρχικά αξιολογούµε την καταλληλότητα της προτεινόµενης ανα-
παράστασης για το πρόβληµα της αναγνώρισης των επανεµφανιζόµενων εννοιών. Στη
συνέχεια, παρουσιάζουµε µία συγκριτική µελέτη στην οποία συµµετέχει µία υλοποίη-
ση του προτεινόµενου πλαισίου (CCP) και πέντε µέθοδοι ταξινόµησης ϱοών.
4.5.1 Αξιολόγηση Εννοιολογικού Μοντέλου Αναπαράστασης
Στοχεύοντας στην αξιολόγηση του µοντέλου αναπαράστασης που παρουσιάστηκε στην
ενότητα 4.2.2, δηµιουργήσαµε αρχικά τα εννοιολογικά διανύσµατα των δύο συνόλων
δεδοµένων. Σε αυτά εφαρµόστηκαν δύο αλγόριθµοι οµαδοποίησης έτσι ώστε να µελε-
τηθούν στη συνέχεια οι οµάδες που ϑα προκύψουν. Το µέγεθος των δεσµών ορίστηκε
στα 50 παραδείγµατα και στα δύο σύνολα δεδοµένων. Η επιλογή αυτή, οδήγησε σε 30
εννοιολογικά διανύσµατα για το σύνολο elist και 186 διανύσµατα για το σύνολο spam.
Μελετώντας το σύνολο elist (ϐλέπε Πίνακα 4.1), παρατηρούµε ότι παρουσιάζονται
ουσιαστικά δύο (επανεµφανιζόµενες) έννοιες. Στην πρώτη (έστω Concept0) ενδιαφέ-
ϱον για το χρήστη παρουσιάζουν µόνο τα άρθρα που σχετίζονται µε ϑέµατα ιατρι-
κής. Στη δεύτερη (έστω Concept1) ενδιαφέροντα άρθρα ϑεωρούνται αυτά που σχε-
τίζονται µε baseball και διάστηµα. Η έννοια Concept0 εµφανίζεται στις περιόδους
[0− 300], [600− 900], [1200− 1500] ενώ η Concept1 στις περιόδους [300− 600] και
[900 − 1200]. Σε περίπτωση που η αναπαράσταση είναι σωστή, αναµένουµε από τον
αλγόριθµο οµαδοποίησης να τοποθετήσει τα διανύσµατα των περιόδων που επικρατεί
η έννοια Concept0 σε µία οµάδα και τα διανύσµατα των περιόδων της Concept1 σε
άλλη οµάδα.
Αρχικά, ο αλγόριθµος k-means (McQueen, 1967) και ο αλγόριθµος Expectation
- Maximization (EM) (Dempster et al., 1977) εφαρµόστηκαν στα εννοιολογικά δια-
νύσµατα του συνόλου elist. Οι αναθέσεις που προέκυψαν ϕαίνονται στο σχήµα 4.5.
85
ΚΕΦΑΛΑΙΟ 4. ΤΑΞΙΝΟΜΗΣΗ ΡΟΩΝ ΚΕΙΜΕΝΩΝ ΜΕ ΕΠΑΝΕΜΦΑΝΙΖΟΜΕΝΕΣ ΕΝΝΟΙΕΣ
Στον αλγόριθµο k-means για k = 2 παρατηρούµε ότι τα διανύσµατα από 0 έως 5
(που αντιστοιχούν στην περίοδο [0 − 300]), από 12 έως 17 ([600 − 900]) και από 24
έως 29 ([1200 − 1500]) ανατίθενται στην ίδια οµάδα (Cluster0). Τα υπόλοιπα δια-
νύσµατα ανατίθενται στην οµάδα Cluster1. Παρατηρούµε εποµένως ότι σε αυτή την
περίπτωση η συγκεκριµένη αναπαράσταση δηµιουργεί διανύσµατα (που αντιστοιχούν
σε δέσµες παραδειγµάτων) που οµαδοποιούνται µε τον επιθυµητό τρόπο. Για k = 5
(Σχήµα 4.5ϐ), ο k-means υποχρεώνεται να αναθέσει κάποια διανύσµατα σε άλλες οµά-
δες αλλά εξακολουθούν να επικρατούν δύο οµάδες (Cluster1 και Cluster3), οι οποίες
αναπαραστούν τις επανεµφανιζόµενες έννοιες. Τέλος, ο αλγόριθµος EM (Σχήµα 4.5γ)
παράγει παρόµοιες οµάδες µε εξαίρεση δύο διανύσµατα.
0
1
0 10 20 30
Conceptual Vector
C
lu
st
er
(α΄) k-means, k = 2
0
1
2
3
4
0 10 20 30
Conceptual Vector
C
lu
st
er
(ϐ΄) k-means, k = 5
0
1
2
0 10 20 30
Conceptual Vector
C
lu
st
er
(γ΄) ΕΜ
Σχήµα 4.5: Οι οµάδες που σχηµατίστηκαν στο σύνολο elist
Για το σύνολο spam (Σχήµα 4.6), δεν υπάρχει πρότερη γνώση σχετικά µε επανεµ-
ϕάνιση εννοιών. Παρόλα αυτά, παρατηρούµε ότι τα αποτελέσµατα και των τριών αλ-
γορίθµων οµαδοποίησης υποδεικνύουν την παρουσία τριών επικρατέστερων οµάδων.
Οι µικρότερες οµάδες πιθανόν να αναπαριστούν ακραίες (outlier) δέσµες οι οποίες
περιέχουν ϑορυβώδη µηνύµατα. Από την πειραµατική αξιολόγηση του πλαισίου CCP
ϑα διαπιστωθεί ότι ακόµη και αυτή η οµαδοποίηση ωφελεί την ταξινόµηση.
0
1
2
3
4
0 50 100 150 200
Conceptual Vectors
C
lu
st
er
(α΄) k-means, k = 5
0
1
2
3
4
5
6
7
8
9
0 50 100 150 200
Conceptual Vectors
C
lu
st
er
(ϐ΄) k-means, k = 10
0
1
2
0 50 100 150 200
Conceptual Vectors
C
lu
st
er
(γ΄) ΕΜ
Σχήµα 4.6: Οι οµάδες που σχηµατίστηκαν στο σύνολο spam
86
4.5. ΑΞΙΟΛΟΓΗΣΗ
4.5.2 Αξιολόγηση του Προτεινόµενου Πλαισίου Ταξινόµησης
Σε αυτή την ενότητα αξιολογείται πειραµατικά το προτεινόµενο πλαίσιο ταξινόµησης.
Αρχικά, περιγράφονται οι µέθοδοι που συµµετέχουν στην πειραµατική διαδικασία και
στη συνέχεια αναφέρονται οι λεπτοµέρειες της υλοποίησή τους. Τέλος, παρουσιάζονται
και σχολιάζονται αναλυτικά τα αποτελέσµατα των πειραµάτων.
Μέθοδοι
Η υλοποίηση του πλαισίου CCP, που ϑα περιγράψουµε αναλυτικότερα στη συνέχεια,
συγκρίνεται πειραµατικά µε τις παρακάτω µεθόδους ταξινόµησης ϱοών.
− Απλός Επαυξητικός Ταξινοµητής (Simple Incremental Classifier - SIC): Αποτελεί-
ται από έναν επαυξητικό αλγόριθµο µε τον οποίο ταξινοµείται ένα κείµενο και
έπειτα χρησιµοποιώντας την πραγµατική τάξη ενηµερώνεται το µοντέλο.
− Ταξινοµητής ∆έσµης (Batch Learner - BL): Αποτελείται από έναν ταξινοµητή ο ο-
ποίος επανεκπαιδεύεται κάθε b παραδείγµατα από τα τελευταία b παραδείγµατα
της ϱοής. Σε αυτήν την περίπτωση δεν είναι απαραίτητο να είναι επαυξητικός ο
ταξινοµητής γεγονός που διευρύνει τις επιλογές σε αλγορίθµους που µπορούν
να χρησιµοποιηθούν.
− Κινούµενο Παράθυρο (Moving Window - MW): ΄Ενας ταξινοµητής ο οποίος µο-
ντελοποιεί τα τελευταία w παραδείγµατα. Ο αλγόριθµος ϑα πρέπει να υλοποιεί
µία συνάρτηση ενηµέρωσης µε ένα νέο παράδειγµα καθώς και µία συνάρτηση
αφαίρεσης ενός παραδείγµατος από το µοντέλο.
− Παραδείγµατα µε Βάρη (Weighted Examples - WE): Η µέθοδος αυτή αποτελείται
από έναν επαυξητικό αλγόριθµο ο οποίος υποστηρίζει µάθηση µε ϐάρη. Μεγαλύ-
τερα ϐάρη δίνονται στα πιο πρόσφατα παραδείγµατα έτσι ώστε να προσαρµοστεί
το µοντέλο ταχύτερα στις ενδεχόµενες αλλαγές της ϱοής.
− ∆υναµική Σταθµισµένη Πλειοψηφία (Dynamic Weighted Majority - DWM ). Απο-
τελεί υλοποίηση του αλγορίθµου που παρουσιάζεται στην εργασία (Kolter and
Maloof, 2007). Η µέθοδος DWM διατηρεί µία οµάδα ταξινοµητών κάθε µέλος
i της οποίας σχετίζεται µε ένα ϐάρος wi . Η παραγωγή πρόβλεψης της οµάδας
γίνεται µε σταθµισµένη πλειοψηφία. Κάθε ϕορά που κάποιο µέλος της οµάδας
παράγει λάθος πρόβλεψη, το αντίστοιχο ϐάρος του µειώνεται κατά ένα ποσοστό
̙. Αν το ϐάρος κάποιου µέλους πέσει κάτω από ένα συγκεκριµένο κατώφλι θ
τότε αφαιρείται από την οµάδα. Επίσης, κάθε ϕορά που η οµάδα συνολικά πα-
ϱάγει λάθος πρόβλεψη, ένα νέο µέλος προστίθεται σε αυτήν µε αρχικό ϐάρος
ίσο µε 1. Μετά την παραγωγή µίας πρόβλεψης η πραγµατική τάξη του αντι-
κειµένου ϑεωρείται γνωστή και όλα τα µέλη της οµάδας ενηµερώνονται. Τέλος,
στη µέθοδο ορίζεται µία παράµετρος p η οποία εκφράζει τη συχνότητα µε την
87
ΚΕΦΑΛΑΙΟ 4. ΤΑΞΙΝΟΜΗΣΗ ΡΟΩΝ ΚΕΙΜΕΝΩΝ ΜΕ ΕΠΑΝΕΜΦΑΝΙΖΟΜΕΝΕΣ ΕΝΝΟΙΕΣ
οποία πραγµατοποιείται ο έλεγχος για την αφαίρεση ή προσθήκη µοντέλων και
η ενηµέρωση των ϐαρών.
Λεπτοµέρειες Πειραµατικής ∆ιαδικασίας
΄Ολες οι µέθοδοι υλοποιήθηκαν χρησιµοποιώντας τη ϐιβλιοθήκη (API) του λογισµικού
Weka (Witten and Frank, 2005a). Ως ϐασικός αλγόριθµος ταξινόµησης, σε όλες τις µε-
ϑόδους ορίστηκε ο ταξινοµητής naive Bayes. Η επιλογή ϐασίζεται κυρίως στη χαµηλή
πολυπλοκότητα και εύκολη επαυξητική εκτέλεση του συγκεκριµένου αλγορίθµου. Ε-
πιπλέον, έχει χρησιµοποιηθεί ευρέως σε εφαρµογές ταξινόµησης κειµένων (Domingos
and Pazzani, 1997; Sebastiani, 2002) αλλά και ειδικότερα ταξινόµησης µηνυµάτων
email (Sahami et al., 1998; Rennie, 2000) που είναι η υπό µελέτη εφαρµογή. Για
τη µέθοδο BL όπως αναφέρθηκε και παραπάνω, δεν απαιτείται η χρήση επαυξητικού
αλγορίθµου. Κατά συνέπεια, εξετάστηκε επιπρόσθετα η χρήση Μηχανών ∆ιανυσµάτων
Υποστήριξης (Support Vector Machines - SVMs) (Vapnik, 1995) ως ϐασικός ταξινο-
µητής. Η χρήση των SVMs παρουσιάζει ενδιαφέρον για τη συγκριτική µελέτη καθώς
ϑεωρούνται ιδιαίτερα αποδοτικοί αλγόριθµοι ταξινόµησης κειµένων (Joachims, 1998;
Peng et al., 2008). Εκτός αυτού, έχουν χρησιµοποιηθεί και σε δεδοµένα ηλεκτρονικού
ταχυδροµείου (Klimt and Yang, 2004). Για τα SVMs διατηρήθηκαν οι προκαθορισµέ-
νες ϱυθµίσεις του Weka. Συγκεκριµένα, επιλέχθηκε η υλοποίηση Sequential Minimal
Optimization - SMO (Platt, 1999) µε γραµµικό πυρήνα και σταθερά πολυπλοκότητας
C = 1. Να σηµειωθεί ότι τα γραµµικά SVMs έχουν παρουσιάσει τουλάχιστον εφάµιλλη
απόδοση σε σχέση µε τα µη-γραµµικά σε προβλήµατα ταξινόµησης κειµένων (Rennie
and Rifkn, 2001; Yang, 1999). Χρησιµοποιήθηκαν τρεις διαφορετικές εκδοχές της
BL, ορίζοντας τρία διαφορετικά µεγέθη δεσµών (50, 100, 200) και για τους δύο ταξι-
νοµητές (Naive Bayes και SVM). Οµοίως, για τη MW δηµιουργήθηκαν τρεις εκδοχές
χρησιµοποιώντας διαφορετικά µεγέθη παραθύρων (50, 100, 200). ΄Επειτα από προ-
καταρκτική µελέτη διαπιστώθηκε ότι ένας κατάλληλος τρόπος για την ενηµέρωση των
ϐαρών στη µέθοδο WE είναι η εξίσωση w(n) = w(n − 1) + n2 για το σύνολο elist και
w(n) = w(n − 1) + 1 για το σύνολο spam, όπου w(n) το ϐάρος του n-οστού παραδείγ-
µατος. Τέλος, για τη µέθοδο DWM χρησιµοποιήθηκαν οι ϱυθµίσεις που προτείνονται
στην εργασία (Kolter and Maloof, 2007), δηλαδή ̙ = 0.5, θ = 0.01 και p = 1.
Αναφορικά µε το µεγέθος της δέσµης που χρησιµοποιήθηκε στο CCP, προκαταρ-
κτικές µελέτες έδειξαν ότι κατάλληλες είναι οι τιµές γύρω στα 50 παραδείγµατα. Η
χρήση µεγαλύτερων δεσµών ακυρώνει την υπόθεση τοπικότητας ενώ οι µικρότερες
δέσµες δεν είναι αρκετές για τον υπολογισµό των εννοιολογικών διανυσµάτων.
Η υλοποίηση του πλαισίου CCP αποτελείται από : α) τον µετασχηµατισµό που
αναφέρθηκε στην ενότητα 4.2.2 ϐ) µία τροποποιηµένη έκδοση του αλγορίθµου Leader-
Follower που περιγράφεται στην εργασία (Duda et al., 2000) και γ) τον επαυξητικό
ταξινοµητή Naive Bayes. Σηµειώνεται ότι και τα τρία στοιχεία είναι ενδεικτικά και ϑα
µπορούσαν να αντικατασταθούν από άλλα όπως περιγράφεται στην ενότητα 4.3.
Ο αλγόριθµος Leader-Follower αποτελεί ουσιαστικά µία on-line έκδοση του γνω-
88
4.5. ΑΞΙΟΛΟΓΗΣΗ
στού k-means και λειτουργεί ως εξής : Το πρώτο αντικείµενο ανατίθεται στην πρώτη
οµάδα. Κάθε ϕορά που καταφθάνει ένα νέο αντικείµενο ο αλγόριθµος υπολογίζει την
απόστασή του µε όλες τις οµάδες (ουσιαστικά µε το κέντρο κάθε οµάδας) και εντοπίζει
τη µικρότερη από αυτές. Αν αυτή η απόσταση είναι µικρότερη από ένα κατώφλι θ,
τότε το αντικείµενο ανατίθεται στην κοντινότερη οµάδα. Το κέντρο αυτής της οµάδας
υπολογίζεται ξανά ώστε να ληφθεί υπόψη και το νέο αντικείµενο. Αν η απόσταση είναι
µεγαλύτερη από το θ τότε δηµιουργείται µία νέα οµάδα στην οποία ανατίθεται το αν-
τικείµενο. Στον αλγόριθµο ορίζεται µία µεταβλητή σταθερότητας (stability) h η οποία
καθορίζει µε ποιο ϱυθµό τα κέντρα της οµάδας ϑα κινηθούν προς το νέο παράδειγµα.
Η παρούσα υλοποίηση του αλγορίθµου Leader-Follower διαφέρει σε δύο σηµεία
από τον αλγόριθµο όπως παρουσιάζεται στο (Duda et al., 2000). Ο ψευδοκώδικας
ϕαίνεται στο σχήµα 4.7. Αρχικά, στοχεύοντας στην απάλειψη της παραµέτρου σταθε-
ϱότητας h, ορίστηκαν ίδια ϐάρη για όλα τα αντικείµενα µίας οµάδας χρησιµοποιώντας
τον αριθµό των αντικειµένων που έχουν ανατεθεί σε µία οµάδα (mj) (γραµµή 7). Αυτή
η αλλαγή όχι µόνο απλοποιεί τον αλγόριθµο, αφού υπάρχει µία λιγότερη παράµε-
τρος, αλλά ταυτόχρονα περιορίζεται η επιρροή των καλά καθορισµένων οµάδων από
αποµακρυσµένα µέλη.
Είσοδος: ~xi : Ροή δεδοµένων, θ: ευαισθησία, cmax : µέγιστος αριθµός
οµάδων, mj: αριθµός αντικειµένων που έχουν ανατεθεί στην
οµάδα cj.
΄Εξοδος: Ανάθεση οµάδας J για κάθε ~xi .
Αρχή1
~c1 ← ~x1, m1 ← 1, n ← 1 ;2
για i ← 2 έως άπειρο κάνε3
J ← argminj(distance(~xi , ~cj)) ;4
αν distance(~xi , ~cJ )) < θ ή n > Cmax τότε5
mJ ← mJ + 1;6
~cJ ← ((mJ − 1)/mJ )~cJ + (1/mJ )~xi ;7
αλλιώς8
n ← n + 1;9
δηµιούργησε νέα οµάδα ~cn ← ~xi ;10
mn ← 1;11
Τέλος12
Σχήµα 4.7: Ο αλγόριθµος οµαδοποίησης Leader-Follower όπως υλοποιήθηκε
στο CCP
Η δεύτερη αλλαγή σχετίζεται µε τους περιορισµούς σε µνήµη που ϑέτουν οι ϱο-
ές δεδοµένων. Συγκεκριµένα, δίνεται στο χρήστη η δυνατότητα να ορίσει το µέγιστο
αριθµό οµάδων (cmax ). Σύµφωνα µε όσα έχουν αναφερθεί, ο αριθµός αντιστοιχεί ου-
89
ΚΕΦΑΛΑΙΟ 4. ΤΑΞΙΝΟΜΗΣΗ ΡΟΩΝ ΚΕΙΜΕΝΩΝ ΜΕ ΕΠΑΝΕΜΦΑΝΙΖΟΜΕΝΕΣ ΕΝΝΟΙΕΣ
σιαστικά στο µέγιστο αριθµό εννοιών και αντίστοιχων ταξινοµητών. ΄Οταν έχει συµπλη-
ϱωθεί το όριο αυτό, το νέο αντικείµενο (εννοιολογικό διάνυσµα) ενσωµατώνεται στην
κοντινότερη οµάδα ακόµα και αν η απόστασή του µε αυτήν ξεπερνάει το θ. Σκοπός
της εισαγωγής της παραµέτρου cmax είναι ο περιορισµός του αριθµού των ταξινοµητών
που διατηρούνται στη µνήµη.
Η παράµετρος θ ορίζει την ευαισθησία του αλγορίθµου στην αναγνώριση της εν-
νοιολογικής απόκλισης. Η παράµετρος αυτή είναι ουσιαστικά αναπόφευκτη και υπάρ-
χει σε διάφορες µορφές σε πολλούς µηχανισµούς αναγνώρισης απόκλισης (Tsymbal,
2004). Η συνάρτηση ϐαρών της µεθόδου WE, το µέγεθος δέσµης της µεθόδου BL,
το µέγεθος παραθύρου της MW και οι παράµετροι ̙ και θ της DWM µπορούν να ϑε-
ωρηθούν τέτοιες παράµετροι. Προφανώς, όσο µειώνεται το θ ο αριθµός των οµάδων
(και κατά συνέπεια των ταξινοµητών) ϑα αυξηθεί. Παρόλαυτά, στην περίπτωσή µας, η
παράµετρος cmax περιορίζει τα προβλήµατα µνήµης ανεξάρτητα από τον ορισµό του θ.
΄Επειτα από προκαταρκτική εξέταση ορίστηκε θ = 4 για το σύνολο elist και θ = 2.5 για
το σύνολο spam. Και στις δυο περιπτώσεις ϑέσαµε cmax = 10. Στη επόµενη ενότητα
ϑα εξεταστεί ο τρόπος µε τον οποίο επηρεάζει η τιµή του θ τον αριθµό των ταξινοµητών
και την απόδοση του συστήµατος.
Η αξιολόγηση περιλαµβάνει µία µέθοδο αναφοράς (Oracle), η οποία αποτελεί µία
εκδοχή του CCP όπου η οµάδα (έννοια) στην οποία ανήκει η κάθε δέσµη ϑεωρείται
γνωστή εκ των προτέρων. Η απόδοση της εκδοχής αυτής ϑα δώσει µία εκτίµηση του
άνω ορίου της απόδοσης του πλαισίου CCP (σε ιδανικές δηλαδή συνθηκες - τέλεια
οµαδοποίηση και ελάχιστο µέγεθος δέσµης).
Η αξιολόγηση των µεθόδων γίνεται ως εξής : Κάθε µέθοδος δέχεται ένα νέο κείµενο
για το οποίο παράγει µία πρόβλεψη. Σύµφωνα µε αυτήν τη λανθασµένη ή σωστή
πρόβλεψη υπολογίζεται και η ορθότητά της. Στη συνέχεια, η πραγµατική τάξη του
κειµένου ϑεωρείται γνωστή και κατά συνέπεια κάθε µέθοδος µπορεί να χρησιµοποιήσει
αυτό το επιπλέον παράδειγµα έτσι ώστε να ενηµερώσει το µοντέλο της. Να σηµειωθεί
όµως ότι το CCP πραγµατοποιεί ενηµερώσεις µόνο όταν µία δέσµη έχει ϕτάσει στο
τέλος και όχι σε κάθε παράδειγµα.
Για κάθε µέθοδο υπολογίζεται η ορθότητα (accuracy), η ακρίβεια (precision), η
ανάκληση (recall) και ο χρόνος εκτέλεσης (time). ∆εδοµένου ότι τα προβλήµατα που
αντιµετωπίζονται σε αυτό το κεφάλαιο είναι προβλήµατα ϕιλτραρίσµατος, για τον υπο-
λογισµό της ακρίβειας και της ανάκλησης ϑεωρούµε ως ϑετική τάξη την τάξη spam για
το σύνολο spam και την τάξη junk για το σύνολο elist.
΄Ολα τα πειράµατα εκτελέστηκαν σε έναν υπολογιστή µε επεξεργαστή Intel Pentium
4 στα 2.0 GHz µε µνήµη RAM 2 GB.
4.5.3 Παρουσίαση και Σχολιασµός Αποτελεσµάτων
Ο Πίνακας 4.2 παρουσιάζει την ορθότητα, ακρίβεια, ανάκληση και χρόνο εκτέλεσης
(σε δευτερόλεπτα) όλων των µεθόδων στο σύνολο elist. Παρατηρούµε αρχικά ότι α-
κόµη και µία ϐασική υλοποίηση του πλαισίου CCP υπερτερεί σε ορθότητα σε σχέση
90
4.5. ΑΞΙΟΛΟΓΗΣΗ
µε τις υπόλοιπες µεθόδους. Αυτό οφείλεται σε µεγάλο ποσοστό στην - όπως ϑα δει-
χθεί αναλυτικά αργότερα - σωστή αναγνώριση των εννοιών της ϱοής και εκπαίδευσης
των ειδικών ταξινοµητών. Η δεύτερη καλύτερη απόδοση επιτυγχάνεται από τη µέθοδο
MW. Το κύριο πλεονέκτηµα της MW είναι ότι πάντα µοντελοποιεί το τελευταίο πα-
ϱάθυρο παραδειγµάτων και κατά συνέπεια αν και δεν εµπεριέχει κάποιον µηχανισµό
αναγνώρισης απόκλισης µπορεί σχετικά γρήγορα να προσαρµοστεί στις ενδεχόµενες
αλλαγές. Η µέθοδος BL δεν έχει την ίδια απόδοση κυρίως λόγω της καθυστερηµένης
- κατά b παραδείγµατα - ενηµέρωσης. Τα SVMs σίγουρα προσδίδουν µία ϐελτίω-
ση αλλά και πάλι δε ϕτάνουν την απόδοση της MW µε τον απλό ταξινοµητή naive
Bayes. Τα Παραδείγµατα µε Βάρη λαµβάνουν υπόψη όλα τα παραδείγµατα για την
ανάπτυξη του µοντέλου και επίσης δεν εµπεριέχουν µηχανισµό αναγνώρισης της α-
πόκλισης. Εποµένως είναι αναµενόµενο να µην αντιµετωπίζουν αποτελεσµατικά τις
απότοµες αλλαγές του συνόλου elist. Η υπόθεση αυτή επιβεβαιώνεται και από τα α-
ποτελέσµατα του Πίνακα 4.2. Παρόλα αυτά, σηµαντικό στοιχείο αποτελεί η υπεροχή
της WE σε σχέση µε τον απλό επαυξητικό naive Bayes αφού το γεγονός αυτό υπο-
γραµµίζει την ωφελιµότητα της συνάρτησης ϐαρών. Σχετικά µε την ιδανική τιµή του
µεγέθους δέσµης/παραθύρου για τις µεθόδους BL/MW αντίστοιχα, παρατηρήθηκε
ότι µικρές τιµές του b/w είναι καταλληλότερες. Συγκεκριµένα, η καλύτερη απόδοση
του BL παρουσιάστηκε για b = 50 (ορθότητα 0.704) και w = 65 (0.751). Η µέθοδος
DWM δεν είναι σχεδιασµένη να αντιµετωπίζει επανεµφανιζόµενες έννοιες και εποµέ-
νως παρουσιάζει χαµηλή απόδοση σε αυτό το σύνολο. Τέλος, πρέπει να σηµειωθεί η
ιδιαίτερα υψηλή απόδοση της µεθόδου Oracle αφού αποδεικνύει την καταλληλότητα
των ειδικών σε έννοιες ταξινοµητών για προβλήµατα επανεµφανιζόµενων εννοιών και
ενθαρύνει τη µελλοντική έρευνα σε αυτήν την κατεύθυνση. Σχετικά µε τους χρόνους
εκτέλεσης, όπως ήταν αναµενόµενο, παρατηρούµε ότι οι απλούστερες µέθοδοι όπως
οι SIC και WE απαιτούν λιγότερο χρόνο για την ταξινόµηση της ϱοής. Παρόλα αυτά,
καµία µέθοδος δεν αποδείχτηκε σηµαντικά ταχύτερη.
Στο σύνολο spam (Πίνακας 4.3) δεν υπάρχει γνώση για το είδος της εννοιολογικής
απόκλισης αφού δεν έχει εισαχθεί µε κάποιον τρόπο τεχνητά όπως το σύνολο elist. Η
διαφορά όµως της απόδοσης των παραδειγµάτων µε ϐάρη και του απλού επαυξητι-
κού ταξινοµητή όπως και η µελέτη του προηγούµενου κεφαλαίου υποδεικνύουν την
ύπαρξη σταδιακής εννοιολογικής απόκλισης. Σε αυτό το σύνολο ϑα περίµενε κανείς
από το CCP να µην αποδίδει καλά κυρίως γιατί χρησιµοποιεί πολλούς ταξινοµητές
µε µικρότερα σύνολα εκπαίδευσης. Φαίνεται όµως ότι η οργάνωση των δεσµών σε
οµάδες ήταν ωφέλιµη για την ταξινόµηση. Μία εξήγηση για την καλή απόδοση του
CCP είναι η ενδεχόµενη αποµόνωση ϑορυβωδών δεσµών που ϑα µπορούσαν να επηρε-
άσουν αρνητικά έναν ταξινοµητή που λαµβάνει υπόψη του όλα τα δεδοµένα. Σχετικά
µε το ιδανικό µέγεθος δέσµης/παραθύρου των µεθόδων BL/MW παρατηρήθηκε σε
αυτό το σύνολο ότι µεγαλύτερες τιµές του b/w είναι καταλληλότερες. Συγκεκριµένα,
η καλύτερη απόδοση της BL επιτεύχθηκε για b = 145 (ορθότητα 0.900) και της MW
για w = 150 (ορθότητα 0.922). Συνολικά την καλύτερη απόδοση σε αυτό το σύνολο
παρουσιάζει το CCP ενώ ακολουθούν η WE, MW και DWM. Αναφορικά µε το χρόνο,
91
ΚΕΦΑΛΑΙΟ 4. ΤΑΞΙΝΟΜΗΣΗ ΡΟΩΝ ΚΕΙΜΕΝΩΝ ΜΕ ΕΠΑΝΕΜΦΑΝΙΖΟΜΕΝΕΣ ΕΝΝΟΙΕΣ
Πίνακας 4.2: Ορθότητα, Ακρίβεια, Ανάκληση και Χρόνος εκτέλεσης (σε δευτερόλεπτα)
όλων των µεθόδων στο σύνολο elist
.
Μέθοδος Ταξινοµ. Ορθότητα Ακρίβεια Ανάκληση Χρόνος
Simple Incremental ΝΒ 0.545 0.612 0.435 1.994
Batch Learner(b=50) ΝΒ 0.704 0.725 0.718 1.885
Batch Learner(b=50) SVM 0.714 0.737 0.721 2.088
Batch Learner(b=100) ΝΒ 0.607 0.642 0.607 1.822
Batch Learner(b=100) SVM 0.642 0.674 0.648 1.880
Batch Learner(b=200) ΝΒ 0.425 0.463 0.426 1.793
Batch Learner(b=200) SVM 0.465 0.505 0.438 2.093
Moving Window(w=50) ΝΒ 0.725 0.742 0.741 2.609
Moving Window(w=100) ΝΒ 0.747 0.779 0.732 2.557
Moving Window(w=200) ΝΒ 0.662 0.694 0.653 2.601
Weighted Examples ΝΒ 0.669 0.685 0.702 1.970
Dyn. Weight. Majority ΝΒ 0.438 0.470 0.425 5.265
CCP (Leader-Follower) ΝΒ 0.775 0.797 0.776 3.034
CCP (Oracle) ΝΒ 0.875 0.883 0.869 3.070
όπως και στο προηγούµενο σύνολο δεδοµένων οι απλούστερες µέθοδοι όπως η SIC και
η WE απαιτούν λιγότερο χρόνο για την ταξινόµηση της ϱοής.
Το σχήµα 4.8 παρουσιάζει την µέση ορθότητα των CCP, MW και WE ανά 50 παρα-
δείγµατα για το σύνολο elist. Παρατηρούµε τις απότοµες πτώσεις όλων των µεθόδων
στα σηµεία απόκλισης (δηλ. µετά τα 300, 600, 900 και 1200 παραδείγµατα). Το CCP
πάντως επιτυγχάνει να ανακάµψει γρηγορότερα σε όλες τις περιπτώσεις ανακαλώντας
τους παλιότερους ταξινοµητές όταν χρειαστεί.
Το σχήµα 4.9, παρουσιάζει τις αναθέσεις σε οµάδες του αλγορίθµου Leader-
Follower που χρησιµοποιήθηκε και οδήγησε στα αποτελέσµατα του πίνακα 4.2. Σε
αυτό το σύνολο παρατηρούµε ότι οι αναθέσεις έγιναν σωστά µε εξαίρεση ένα στιγµιό-
τυπο (δείτε το σχήµα σε σύγκριση µε το σχήµα 4.5α). Στο σύνολο spam ο αλγόριθµος
αναγνώρισε σωστά τις δύο µεγαλύτερες οµάδες (δείτε το σχήµα σε σύγκριση µε το
σχήµα 4.6α).
Τέλος, το σχήµα 4.10 αναπαριστά τη µεταβολή του αριθµού των ταξινοµητών (σχή-
µα 4.10α) και την οθρότητα πρόβλεψης (σχήµα 4.10ϐ) σε σχέση µε την παράµετρο
ευαισθησίας θ. Σε αυτήν την περίπτωση ϑέτουµε cmax = 100 έτσι ώστε να µη πε-
ϱιορίσουµε το µέγιστο αριθµό των οµάδων. ΄Οπως αναµενόταν (ϐλέπε ενότητα 4.5.2),
ο αριθµός των ταξινοµητών µειώνεται µε την αύξηση της ευαισθησίας. ΄Οπως είναι
ϕυσικό, καλύτερη απόδοση παρατηρείται όταν ο αριθµός των ταξινοµητών που δη-
µιουργείται είναι κοντά στον αριθµό των εννοιών της ϱοής κειµένων (ϐλέπε Εικόνα
4.10ϐ).
92
4.6. ΣΥΜΠΕΡΑΣΜΑΤΑ
Πίνακας 4.3: Ορθότητα, Ακρίβεια, Ανάκληση και Χρόνος Εκτέλεσης (σε δευτερόλεπτα)
για όλες τις µεθόδους στο σύνολο spam
Μέθοδος Ταξινόµ. Ορθότητα Ακρίβεια Ανάκληση Χρόνος
Simple Incremental ΝΒ 0.912 0.809 0.856 4.896
Batch Learner(b=50) ΝΒ 0.880 0.851 0.646 4.531
Batch Learner(b=50) SVM 0.881 0.820 0.685 8.083
Batch Learner(b=100) ΝΒ 0.887 0.845 0.685 4.495
Batch Learner(b=100) SVM 0.899 0.848 0.738 8.124
Batch Learner(b=200) ΝΒ 0.889 0.818 0.728 4.463
Batch Learner(b=200) SVM 0.914 0.865 0.790 9.137
Moving Window(w=50) ΝΒ 0.915 0.911 0.742 5.102
Moving Window(w=100) ΝΒ 0.919 0.902 0.770 5.221
Moving Window(w=200) ΝΒ 0.921 0.881 0.801 5.344
Weighted Examples ΝΒ 0.921 0.836 0.864 4.786
Dyn. Weight. Majority ΝΒ 0.918 0.848 0.831 4.753
CCP (Leader-Follower) ΝΒ 0.923 0.857 0.839 8.750
4.6 Συµπεράσµατα
Σε αυτό το κεφάλαιο προτείνεται ένα πλαίσιο ταξινόµησης ϱοών δεδοµένων κατάλ-
ληλο για προβλήµατα που περιέχουν εννοιολογική απόκλιση και επανεµφανιζόµενες
έννοιες. Βασικό στοιχείο του πλαισίου αποτελεί µία συνάρτηση µετασχηµατισµού
δεσµών δεδοµένων σε εννοιολογικά διανύσµατα. Τα διανύσµατα αυτά περιέχουν πλη-
ϱοφορία που σχετίζεται µε τις έννοιες που χαρακτηρίζουν τις αντίστοιχες δέσµες δε-
δοµένων. Στη συνέχεια, εφαρµόζεται ένας αλγόριθµος οµαδοποίησης ϱοών ο οποίος
οργανώνει τα εννοιολογικά διανύσµατα σε οµάδες. Οι οµάδες αυτές αντιστοιχούν στις
διαφορετικές έννοιες που εµφανίζονται στη ϱοή. Για κάθε έννοια εκπαιδεύεται και
ένας ταξινοµητής. Η ταξινόµηση των δεδοµένων πραγµατοποιείται αφού αναγνωριστεί
η έννοια στην οποία ανήκουν έτσι ώστε να κληθεί ο αντίστοιχος ειδικός ταξινοµητής.
Για την αξιολόγηση του πλαισίου χρησιµοποιήθηκαν δύο σύνολα δεδοµένων µε εν-
νοιολογική απόκλιση, το ένα εκ των οποίων περιέχει επανεµφανιζόµενες έννοιες. Τα
πειραµατικά αποτελέσµατα αποδεικνύουν ότι το προτεινόµενο πλαίσιο αναγνωρίζει σω-
στά τις επανεµφανιζόµενες έννοιες µε αποτέλεσµα την υψηλή ορθότητα πρόβλεψης και
στα δύο σύνολα δεδοµένων.
93
ΚΕΦΑΛΑΙΟ 4. ΤΑΞΙΝΟΜΗΣΗ ΡΟΩΝ ΚΕΙΜΕΝΩΝ ΜΕ ΕΠΑΝΕΜΦΑΝΙΖΟΜΕΝΕΣ ΕΝΝΟΙΕΣ
0
0,1
0,2
0,3
0,4
0,5
0,6
0,7
0,8
0,9
1
50 150 250 350 450 550 650 750 850 950 1050 1150 1250 1350 1450
MW
CCP
WE
Σχήµα 4.8: Μέση ορθότητα ανά 50 παραδείγµατα για τις µεθόδους WE, MW και CCP.
Τα σηµεία απόκλισης ϐρίσκονται στα : 300, 600, 900 και 1200 παραδείγµατα.
0
1
2
3
4
0 5 10 15 20 25 30
Conceptual Vector
C
lu
st
er
(α΄) Σύνολο elist
0
1
2
3
4
0 50 100 150 200
Conceptual Vector
C
lu
st
er
(ϐ΄) Σύνολο spam
Σχήµα 4.9: On-line αναθέσεις των εννοιολογικών διανυσµάτων σε οµάδες από την
έκδοση του αλγορίθµου Leader-Follower που παρουσιάζεται σε αυτό το κεφάλαιο.
0
10
20
30
40
1,4 1,6 1,8 2 2,2 2,4 2,6
Sensitivity (")Classif
ie
rs
(α΄)
0,4
0,5
0,6
0,7
0,8
1,4 1,6 1,8 2 2,2 2,4 2,6
Sensitivity (#)Accura
cy
(ϐ΄)
Σχήµα 4.10: Αριθµός ταξινοµητών (α) και ορθότητα (ϐ) σε σχέση µε την παράµετρο
ευαισθησίας θ στο σύνολο elist.
94
5
Ταξινόµηση Κειµένων Πολλαπλών Ετικετών
Σε αυτό το κεφάλαιο παρουσιάζονται δύο µέθοδοι για την ταξινόµηση δεδοµένων πολ-
λαπλών ετικετών. Ιδιαίτερη έµφαση δίνεται σε προβλήµατα που χαρακτηρίζονται από
µεγάλο αριθµό ετικετών. Στην πρώτη µέθοδο (HOMER) οι ετικέτες οργανώνονται σε
µία ιεραρχία σε κάθε κόµβο της οποίας εφαρµόζεται ένας ξεχωριστός ταξινοµητής
πολλαπλών ετικετών. Η δεύτερη µέθοδος (RAkEL) διασπά τυχαία το αρχικό σύνολο
ετικετών σε µικρότερα (ξένα ή επικαλυπτόµενα) σύνολα ετικετών. Σε κάθε ένα από
αυτά εφαρµόζεται ένας ταξινοµητής πολλαπλών ετικετών.
5.1 Εισαγωγή
Η ταξινόµηση µονής ετικέτας (single-label classification) αναφέρεται στη µάθηση από
σύνολα δεδοµένων στα οποία τα παραδείγµατα σχετίζονται µε µία ετικέτα (τάξη) λ
από ένα σύνολο ετικετών L µεγέθους M, µε M > 1. Αν M = 2 τότε το πρόβληµα
ονοµάζεται δυαδική ταξινόµηση (binary classification) ή διήθηση (filtering), ενώ αν
M > 2 ονοµάζεται ταξινόµηση πολλαπλών τάξεων (multi-class classification).
Σε πολλές εφαρµογές όµως, τα δεδοµένα σχετίζονται µε ένα σύνολο (set) από ετικέ-
τες Y ⊆ L. Στην ταξινόµηση κειµένων για παράδειγµα, ένα άρθρο που αναφέρεται στις
αντιδράσεις της Εκκλησίας για την ταινία ¨Κώδικας ντα Βίντσι¨ µπορεί να ταξινοµηθεί
ταυτόχρονα σε δύο κατηγορίες (τάξεις): society\religion και arts\movies1. Οµοίως,
στην ταξινόµηση τοπίων (semantic scene classification) (Boutell et al., 2004; Zhang
and Zhou, 2007), µία ϕωτογραφία µπορεί να ανήκει ταυτόχρονα σε περισσότερες α-
πό µία τάξεις όπως sunset και beach. Το πρόβληµα αυτό αναφέρεται ως ταξινόµηση
πολλαπλών ετικετών (ΠΕ) (multi-label classification). ΄Αλλες ενδιαφέρουσες εφαρµο-
γές ταξινόµησης ΠΕ είναι η κατηγοριοποίηση µουσικών κοµµατιών σε σχέση µε το
συναισθήµατα που εκφράζουν (Li and Ogihara, 2006; Wieczorkowska et al., 2006;
Trohidis et al., 2008), η σηµασιολογική επισηµείωση video (Qi et al., 2007; Snoek
et al., 2006b), το κατευθυνόµενο marketing (Zhang et al., 2006), και η αυτόµατη πρό-
ταση λέξεων επισήµανσης (tags) (Katakis et al., 2008; Song et al., 2008) σε κοινωνικά
δίκτυα.
1Οι κατηγορίες έχουν επιλεχθεί από το Open Directory Project (ODP) - http://www.dmoz.org/
95
ΚΕΦΑΛΑΙΟ 5. ΤΑΞΙΝΟΜΗΣΗ ΚΕΙΜΕΝΩΝ ΠΟΛΛΑΠΛΩΝ ΕΤΙΚΕΤΩΝ
΄Ενα σηµαντικό πρόβληµα στην ταξινόµηση ΠΕ είναι ο µεγάλος αριθµός ετικετών
που µπορεί να εµφανιστεί σε διάφορα πεδία εφαρµογής. Στην ταξινόµηση κειµένων
για παράδειγµα συνήθως υπάρχει ένας µεγάλος αριθµός από ϑεµατικές κατηγορίες
(Lewis et al., 2004). Στην αυτόµατη πρόταση λέξεων επισήµανσης (tags) επίσης, ο
αριθµός των λέξεων που έχουν αναθέσει οι χρήστες στα αντικείµενα (π.χ. ιστοσελίδες
στην περίπτωση συστηµάτων όπως το del.icio.us ή το bibsonomy) µπορεί να είναι χι-
λιάδες. Πρόσφατα έχει παρουσιαστεί µία συλλογή νοµικών κειµένων τα οποία είναι
επισηµειωµένα µε κάποιες από τις συνολικά 4,000 κατηγορίες (Mencia and Furn-
kranz, 2008).
Ο µεγάλος αριθµός ετικετών µπορεί να επηρεάσει αρνητικά τους ταξινοµητές ΠΕ
στην ποιότητα πρόβλεψης, στο χρόνο εκπαίδευσης αλλά και στο χρόνο ταξινόµησης.
Καταρχήν, τα παραδείγµατα µίας ετικέτας ϑα είναι σηµαντικά λιγότερα σε σχέση µε το
συνολικό αριθµό των παραδειγµάτων. Το πρόβληµα αυτό στις µεθόδους µετασχηµατι-
σµού προβλήµατος (ϐλέπε Κεφάλαιο 2) ανάγεται σε αυτό της ανισορροπίας δεδοµένων
(imbalanced data) που εµφανίζεται στην ταξινόµηση µονής ετικέτας (Chawla et al.,
2004). Το ϕαινόµενο µάλιστα είναι εντονότερο σε ταξινοµητές όπως ο LP (2.11.1) ό-
που λαµβάνονται υπόψη οι συνδυασµοί των ετικετών. ΄Ενα άλλο πρόβληµα είναι ότι το
κόστος εκπαίδευσης των ταξινοµητών ΠΕ µπορεί να επηρεάζεται σηµαντικά από τον
αριθµό των ετικετών. Τέλος, κάποιες πραγµατικές εφαρµογές, όπως η αυτόµατη πρό-
ταση λέξεων επισήµανσης (tags), απαιτούν γρήγορες ταξινοµήσεις. Συνεπώς, ακόµη
και αν η πολυπλοκότητα ταξινόµησης µίας µεθόδου είναι γραµµική σε σχέση µε τον
αριθµό των ετικετών αυτό µπορεί να µην είναι αρκετό για προβλήµατα µε σηµαντικά
µεγάλο αριθµό ετικετών. Σε αυτό το κεφάλαιο προτείνονται δύο µέθοδοι ταξινόµησης
που στοχεύουν στην αντιµετώπιση του προβλήµατος του µεγάλου αριθµού ετικετών.
Η πρώτη µέθοδος, HOMER (Hierarchy Of Multilabel classifiERs)(Tsoumakas, Ka-
takis and Vlahavas, 2008), δηµιουργεί µία ιεραρχία ταξινοµητών ΠΕ, κάθε ένας από
τους οποίους αντιµετωπίζει ένα µικρότερο σύνολο ετικετών σε σχέση µε το L και µία πε-
ϱισσότερο ισορροπηµένη κατανοµή παραδειγµάτων. Το χαρακτηριστικό αυτό οδηγεί
σε : α) ϐελτίωση της ποιότητας πρόβλεψης, ϐ) γραµµική πολυπλοκότητα εκπαίδευσης
σε σχέση µε το M και γ) λογαριθµική πολυπλοκότητα ταξινόµησης σε σχέση µε το M.
Μία από τις σηµαντικές διαδικασίες του HOMER είναι η κατανοµή ετικετών σε k ξένα
και ισοµεγέθη υποσύνολα που χρησιµοποιείται για τη δηµιουργία της ιεραρχίας. Τα
σύνολα περιέχουν όµοιες µεταξύ τους ετικέτες. Το πρόβληµα αυτό της οµαδοποίησης
ϐάσει οµοιότητας, µε τον επιπλέον περιορισµό των ισοµεγέθων οµάδων, είναι γνωστό
στη ϐιβλιογραφία ως ισορροπηµένη οµαδοποίηση (balanced clustering) (Banerjee and
Ghosh, 2006). Για την επίλυση αυτού του προβλήµατος προτείνεται ένας νέος αλγό-
ϱιθµος οµαδοποίησης, ο balanced k-means (ισορροπηµένη οµαδοποίηση k-µέσων).
Στη δεύτερη µέθοδο, προτείνεται η τυχαία διάσπαση του αρχικού συνόλου ετικε-
τών σε υποσύνολα (labelsets). Σε κάθε ένα από αυτά εφαρµόζεται ένας ξεχωριστός LP
ταξινοµητής labelset classifier. Με αυτόν τον τρόπο, τα υποπροβλήµατα ΠΕ που προ-
κύπτουν είναι υπολογιστικά απλούστερα και η κατανοµή των τάξεων είναι περισσότερο
ισορροπηµένη. Η προτεινόµενη µέθοδος ονοµάζεται RAkEL (RAndom k labELsets)
96
5.2. HOMER
(Tsoumakas, Katakis and Vlahavas, 2009b), όπου k είναι η παράµετρος που κα-
ϑορίζει το µέγεθος των τυχαίων labelsets. Μελετώνται δύο µέθοδοι κατασκευής των
labelsets. Η πρώτη οδηγεί σε ξένα υποσύνολα ενώ η δεύτερη σε επικαλυπτόµενα.
Πειραµατικά αποτελέσµατα αποδεικνύουν ότι και οι δύο µέθοδοι επιτυγχάνουν τη
ϐελτίωση της ποιότητας πρόβλεψης του LP ειδικά σε πεδία µε µεγάλο αριθµό ετικετών.
Τα επικαλυπτόµενα labelsets παρουσιάζουν υψηλότερη απόδοση αφού ο συγκερα-
σµός των πολλαπλών προβλέψεων µέσα από µία διαδικασία ψηφοφορίας επιτρέπει
τη διόρθωση σφαλµάτων. Παρουσιάζεται επίσης µία συγκριτική µελέτη µε δύο άλ-
λες µεθόδους ταξινόµησης ΠΕ υψηλής ακρίβειας όπου ο RAkEL µε επικαλυπτόµενα
labelsets παρουσιάζει ιδιαίτερα ανταγωνιστική ικανότητα πρόβλεψης.
5.2 HOMER
Ο αλγόριθµος HOMER ουσιαστικά εφαρµόζει τη στρατηγική ‘διαίρει και ϐασίλευε’ σε
προβλήµατα ταξινόµησης ΠΕ. Κεντρική ιδέα αποτελεί ο µετασχηµατισµός ενός προ-
ϐλήµατος ταξινόµησης ΠΕ µε µεγάλο αριθµό ετικετών L σε ένα σύνολο ιεραρχικά
δοµηµένων απλούστερων προβληµάτων. Στο κάθε ένα από αυτά απαντάται ένα σαφώς
µικρότερο του αρχικού σύνολο ετικετών µεγέθους k << M.
Κάθε κόµβος n της ιεραρχικής αυτής δοµής περιέχει ένα σύνολο ετικετών Ln ⊆ L.
Στη ϐάση της ιεραρχίας υπάρχουν M κόµβοι-ϕύλλα, τα οποία περιέχουν ένα σύνο-
λο {λj} το οποίο αποτελείται από µία µόνο ετικέτα λj. Κάθε ετικέτα περιλαµβάνεται
µόνο σε ένα ϕύλλο. Κάθε εσωτερικός κόµβος n περιέχει την ένωση των ετικετών των
κόµβων-παιδιών του δηλαδή Ln =
⋃
Lc, c ∈ children(n). Συνεπώς, η ϱίζα του δένδρου
περιλαµβάνει το σύνολο όλων των ετικετών Lroot = L.
Για τη σαφή περιγραφή του αλγορίθµου, ϑεωρείται σκόπιµος ο ορισµός της µετα-
ετικέτας (meta-label) µn ενός κόµβου n, η οποία εκφράζει την ένωση των ετικετών που
περιέχονται σε αυτόν τον κόµβο, µn ≡
∨
λj, λj ∈ Ln . Πρακτικά, ένα παράδειγµα µπορεί
να ϑεωρηθεί ότι χαρακτηρίζεται από µία µετα-ετικέτα µn αν χαρακτηρίζεται από µία
τουλάχιστον ετικέτα του Ln .
Κάθε εσωτερικός κόµβος n της ιεραρχίας αντιστοιχεί σε έναν ταξινοµητή ΠΕ hn.
Αποστολή του hn είναι η ταξινόµηση ενός αντικειµένου σε µία ή περισσότερες µετα-
ετικέτες των κόµβων-παιδιών του. Συνεπώς, το σύνολο των ετικετών για τον hn είναι
Mn = {µc | c ∈ children(n)}. Το σχήµα 5.1 παρουσιάζει ένα παράδειγµα τέτοιας
ιεραρχικής δοµής για ένα πρόβληµα 8 ετικετών {λ1, . . . , λ8}.
Για την ταξινόµηση ενός αντικειµένου x, ο αλγόριθµος HOMER ξεκινά από τον
ταξινοµητή της ϱίζας hroot µία αναδροµική διαδικασία κατά την οποία το x προωθείται
στον ταξινοµητή hc ενός κόµβου παιδιού c µόνο αν η µc περιλαµβάνεται στις προβλέψεις
του hparent(c). Τελικά, η διαδικασία αυτή µπορεί να οδηγήσει στην πρόβλεψη µίας ή
περισσότερων ετικετών από τους ταξινοµητές ΠΕ που ϐρίσκονται ακριβώς πάνω από το
επίπεδο των ϕύλλων. Η ένωση αυτών των προβλέψεων, αποτελεί ουσιαστικά και την
πρόβλεψη του αλγορίθµου HOMER.
97
ΚΕΦΑΛΑΙΟ 5. ΤΑΞΙΝΟΜΗΣΗ ΚΕΙΜΕΝΩΝ ΠΟΛΛΑΠΛΩΝ ΕΤΙΚΕΤΩΝ
Σχήµα 5.1: ∆είγµα Ιεραρχίας για ένα πρόβληµα ταξινόµησης ΠΕ µε 8 ετικέτες.
Για την εκπαίδευση του HOMER, ϑεωρούµε την ύπαρξη ενός συνόλου παραδειγµά-
των D = {(xi , Yi) | i = 1 . . . |D|}, όπου κάθε παράδειγµα αποτελείται από ένα διάνυσµα
χαρακτηριστικών xi και ένα σύνολο ετικετών Yi ⊆ L. Η δενδρική δοµή δηµιουργείται
αναδροµικά µε στρατηγική από πάνω προς τα κάτω (top-down) και πρώτα σε ϐάθος
(depth-first) ξεκινώντας από τη ϱίζα. Από κάθε κόµβο n δηµιουργούνται k παιδιά
εκτός αν |Ln | < k - σε αυτήν την περίπτωση ο αριθµός των παιδιών είναι |Ln |. Κά-
ϑε κόµβος παιδί ‘περιορίζει’ τα δεδοµένα του κόµβου γονέα, αφού συγκρατεί µόνο τα
παραδείγµατα τα οποία έχουν επισηµειωθεί τουλάχιστον µε µία από τις ετικέτες τις
οποίες περιέχει : Dn = {(xi , Yi) | (xi , Yi) ∈ Dparent(n), Yi ∩ Ln , ∅}. Η ϱίζα εποµένως
χρησιµοποιεί ακέραιο το αρχικό σύνολο δεδοµένων, δηλαδή Droot = D.
Σε κάθε ϐήµα της αναδροµής, εκτελούνται δύο διαδοχικές ενέργειες : α) οι ετικέτες
του τρέχοντος κόµβου κατανέµονται σε k ξένα µεταξύ τους σύνολα, ένα για κάθε κόµβο-
παιδί και ϐ) ένας ταξινοµητής ΠΕ εκπαιδεύεται για να προβλέπει µία ή περισσότερες
από τις µέτα-ετικέτες των κόµβων-παιδιών. Η διαδικασία εκπαίδευσης των ταξινοµητών
εφαρµόζεται σε όλους τους κόµβους που περιέχουν παραπάνω από µία ετικέτα.
Σε κάθε κόµβο n µετασχηµατίζονται τα παραδείγµατα (xi , Yi) ∈ Dn σε µετα-
παραδείγµατα (xi , Zi ), όπου Zi = {µc | c ∈ children(n), Yi ∩ Lc , ∅}. Αυτά τα µετα-
παραδείγµατα χρησιµοποιούνται για την εκπαίδευση του hn.
΄Ενα σηµαντικό Ϲήτηµα σχετικά µε τη διαδικασία που µόλις περιγράφηκε είναι ο
τρόπος µε τον οποίο κατανέµονται οι ετικέτες Ln στους k κόµβους-παιδιά. Προτείνε-
ται τα k υποσύνολα να σχηµατίζονται σύµφωνα µε δύο κανόνες. Ο πρώτος είναι τα
υπο-σύνολα να είναι ισορροπηµένα αριθµητικά και ο δεύτερος είναι οι ετικέτες των
υποσυνόλων να είναι όσο το δυνατόν όµοιες µεταξύ τους και ανόµοιες µε αυτές των άλ-
λων υποσυνόλων. ΄Οπως ϑα δούµε και παρακάτω, η οµοιότητα στις ετικέτες ϐασίζεται
στις κοινές εµφανίσεις αυτών στα αντικείµενα.
98
5.2. HOMER
Το κίνητρο πίσω από την ισάριθµη κατανοµή των ετικετών είναι ότι κάθε ταξινο-
µητής, δεδοµένης µίας µικρής τιµής για το k ϑα αντιµετωπίζει µία πιο ισορροπηµένη
κατανοµή ϑετικών παραδειγµάτων για κάθε µετα-ετικέτα. Το γεγονός αυτό µε τη σειρά
του ϑα οδηγήσει σε ϐελτίωση της ορθότητας πρόβλεψης.
Το κίνητρο πίσω από την οργάνωση µε ϐάση την οµοιότητα είναι ότι αν παρόµοιες
ετικέτες του κόµβου n τοποθετηθούν στο ίδιο υποσύνολο τότε µόνο λίγες (ιδανικά µόνο
µία) από τις µετα-ετικέτες του hn ϑα επιλεχθούν
2 και εποµένως οι ταξινοµητές του
υπόλοιπου υποδένδρου δε ϑα ενεργοποιηθούν. Το γεγονός αυτό ϑα περιορίσει το υπο-
λογιστικό κόστος ταξινόµησης ενός αντικειµένου. ΄Ενα επιπλέον αναµενόµενο πλεονέ-
κτηµα είναι ότι κάθε κόµβος ϑα περιέχει λιγότερα παραδείγµατα εκπαίδευσης, αφού
παραδείγµατα που συνήθως χαρακτηρίζονται από παρόµοιες ετικέτες ϑα υφίστανται
ως παραδείγµατα µόνο µίας µετα-ετικέτας.
Το πρόβληµα της οργάνωσης αντικειµένων σε οµάδες µε ϐάση την οµοιότητα αλλά
µε τον περιορισµό οι οµάδες να περιέχουν ίδιο αριθµό µελών, αναφέρεται στη ϐιβλιο-
γραφία ως ισορροπηµένη οµαδοποίηση (balanced clustering) (Banerjee and Ghosh,
2006), και αποτελεί µία ειδική περίπτωση της οµαδοποίησης µε περιορισµούς (con-
strained clustering).
Στην εργασία (Banerjee and Ghosh, 2004) προτείνεται µία µέθοδος ισορροπηµένης
οµαδοποίησης που ϐασίζεται στον αλγόριθµο k-µέσων κατά την οποία τα αντικείµενα
έχουν περισσότερες πιθανότητες να ανατεθούν σε µία οµάδα µε µικρό αριθµό αντι-
κειµένων. Με αυτόν τον τρόπο δηµιουργούνται οµάδες περίπου ίδιου µεγέθους αλλά
δεν εξασφαλίζεται ότι ϑα έχουν ακριβώς το ίδιο µέγεθος. Ο αλγόριθµος αυτός έχει
πολυπλοκότητα O(|Ln |). Μία άλλη προσέγγιση που και πάλι ϐασίζεται στον αλγόριθ-
µο k-µέσων προτείνεται στην εργασία (Bennett et al., 2000), αλλά µε πολυπλοκότητα
O(|Ln |3).
Σε αυτό το κεφάλαιο προτείνεται ένας νέος αλγόριθµος ισορροπηµένης οµαδοποί-
ησης, η ισορροπηµένη οµαδοποίηση k-µέσων (balanced k-means) που παρουσιάζεται
στην ενότητα 5.2.2 µε πολυπλοκότητα O(|Ln |2) που εξασφαλίζει όµως ότι οι οµάδες ϑα
έχουν ίδιο αριθµό στοιχείων.
5.2.1 Υπολογιστική Πολυπλοκότητα
Για την απλοποίηση της ανάλυσης που ακολουθεί υποθέτουµε ότι M = kd για κάποιον
ακέραιο d, που σηµαίνει ότι η ιεραρχία είναι ένα τέλειο k-αδικό δένδρο ύψους d. ΄Ολοι
οι εσωτερικοί κόµβοι έχουν k παιδιά και όλα τα ϕύλλα ϐρίσκονται στο ίδιο επίπεδο.
Ο αριθµός των εσωτερικών κόµβων σε αυτό το δένδρο είναι ίσος µε (M − 1)/(k − 1)
(Preiss, 1999) ενώ το ύψος logk(M).
2Ουσιαστικά, η οµοιότητα µεταξύ των ετικετών ενός κόµβου εξασφαλίζει ότι η µέτα-ετικέτα αυτού του
κόµβου ϑα έχει κάποια σηµασιολογία αφού ϑα εκφράζει το κοινό περιεχόµενο των ετικετών.
99
ΚΕΦΑΛΑΙΟ 5. ΤΑΞΙΝΟΜΗΣΗ ΚΕΙΜΕΝΩΝ ΠΟΛΛΑΠΛΩΝ ΕΤΙΚΕΤΩΝ
Πολυπλοκότητα Εκπαίδευσης
΄Οπως έχει αναφερθεί, το Ln είναι ίσο µε L στη ϱίζα, αλλά µειώνεται εκθετικά σε σχέση
µε το ύψος (ϐάθος) του δένδρου. Οπότε, αν f (|Ln |) είναι µία συνάρτηση που εκφράζει
την πολυπλοκότητα της ισορροπηµένης οµαδοποίησης σε σχέση µε το Ln τότε η πο-
λυπλοκότητα του HOMER για τον αλγόριθµο οµαδοποίησης είναι O(f (M)). Με άλλα
λόγια, ο αλγόριθµος HOMER διατηρεί την πολυπλοκότητα του αλγορίθµου οµαδοποί-
ησης. Η πολυπλοκότητα της ισορροπηµένης οµαδοποίησης που πραγµατοποιείται σε
κάθε κόµβο n εξαρτάται από τον αλγόριθµο που ϑα χρησιµοποιηθεί και µπορεί να
είναι από O(|Ln |) έως O(|Ln |3) (ϐλέπε προηγούµενη ενότητα).
Ας υποθέσουµε ότι f (|Ln |) = |Ln |2. Στη ϱίζα υπάρχει ένα κόστος M2 ενώ σε επόµενο
επίπεδο έχουµε k επιπλέον κόστη (M/k)2, δηλαδή ένα επιπλέον κόστος M2/k. Στο
επόµενο επίπεδο έχουµε k2 επιπλέον κόστη
(
M/k2
)2
δηλαδή M2/k2. Ο υπολογισµός
αυτός οδηγεί σε άθροισµα γεωµετρικής προόδου από όπου προκύπτει ότι το συνολικό
κόστος είναι 2M2 όταν το ϐάθος του δένδρου τείνει στο άπειρο.
Σε κάθε κόµβο υπάρχει επίσης το κόστος εκπαίδευσης του ταξινοµητή, το οποίο
εξαρτάται από τον αλγόριθµο ταξινόµησης που χρησιµοποιείται. Αν g(M) είναι η συ-
νάρτηση πολυπλοκότητας του ταξινοµητή σε σχέση µε τον αριθµό των ετικετών M, η
πολυπλοκότητα στον κόµβο n είναι O(g(k)). ∆εδοµένου ότι υπάρχουν (M − 1)/(k − 1)
εσωτερικοί κόµβοι, η συνολική πολυπλοκότητα αυτής της διαδικασίας για το HOMER
είναι γραµµική σε σχέση µε το M ανεξάρτητα από τον ταξινοµητή ΠΕ που χρησιµο-
ποιείται. Αυτό είναι ένα ιδιαίτερα σηµαντικό πλεονέκτηµα ειδικά αν η πολυπλοκότητα
του ταξινοµητή ΠΕ είναι µεγάλη σε σχέση µε το M.
Ιδιαίτερα σηµαντικό είναι ότι το µέγεθος του συνόλου εκπαίδευσης Dn του κάθε
κόµβου n επίσης µειώνεται σε σχέση µε το ϐάθος του δένδρου. Ο ϐαθµός της µείωσης
εξαρτάται από πολλούς παράγοντες όπως είναι ο µέσος όρος ετικετών ανά παράδειγµα,
η επικάλυψη ετικετών στα παραδείγµατα, η τιµή του k, και έτσι δε µπορεί να οριστεί
µε ακρίβεια.
Συµπερασµατικά, η πολυπλοκότητα εκπαίδευσης του HOMER είναι O(f (M) +M),
όπου f (M) είναι η πολυπλοκότητα του αλγορίθµου οµαδοποίησης σε σχέση µε το
σύνολο ετικετών L.
Πολυπλοκότητα Ταξινόµησης
Το κόστος ταξινόµησης εξαρτάται από τον µέσο όρο των ταξινοµητών ΠΕ που ενερ-
γοποιούνται κάθε ϕορά. Υποθέτοντας ότι α) κάθε παράδειγµα έχει επισηµειωθεί µε
µικρό αριθµό ετικετών συγκριτικά µε το L, ϐ) ο HOMER προβλέπει επίσης ένα µικρό
αριθµό ετικετών για κάθε αντικείµενο και γ) για την πρόβλεψη µίας συγκεκριµένης
ετικέτας ακολουθείται ένα διαφορετικό µονοπάτι ταξινοµητών από τη ϱίζα προς τα ϕύλ-
λα, τότε µπορούµε να ϑεωρήσουµε ως πολυπλοκότητα ταξινόµησης την O (logk(M)). Σε
σύγκριση µε την τυπική O(M) πολυπλοκότητα, ο HOMER παρουσιάζει ένα σηµαντικό
πλεονέκτηµα ειδικά σε πεδία που η γρήγορη ταξινόµηση αποτελεί σηµαντικό χαρα-
100
5.2. HOMER
κτηριστικό. ΄Ενα παράδειγµα τέτοιας εφαρµογής είναι η αυτόµατη πρόταση λέξεων
επισήµανσης (automated tag suggestion).
5.2.2 Ισορροπηµένη οµαδοποίηση k-µέσων
Για τις ανάγκες του HOMER αναπτύχθηκε ένας νέος αλγόριθµος ισορροπηµένης οµα-
δοποίησης µε όνοµα balanced k means (Tsoumakas, Katakis and Vlahavas, 2008).
Αποτελεί επέκταση του γνωστού αλγορίθµου k-means (k-µέσων) µε τον περιορισµό
των ισάριθµων οµάδων. ∆εδοµένου ότι αντικείµενα της οµαδοποίησης είναι οι ετικέ-
τες, χρησιµοποιείται µόνο το τµήµα της ετικέτας Yi των παραδειγµάτων (xi , Yi) ∈ Dn
σε κάθε κόµβο. Συγκεκριµένα για την οµαδοποίηση χρησιµοποιείται ένα υποσύνολο
Wi του Yi που περιέχει µόνο τις ετικέτες του συγκεκριµένου κόµβου Wi = Yi ∩ Ln .
Ουσιαστικά, κάθε ετικέτα εκφράζεται µε ένα δυαδικό διάνυσµα καταγραφής των εµ-
ϕανίσεων της στα αντικείµενα. ΄Αν wij, j = 1 . . . |Ln | τα στοιχεία των διανυσµάτων αυτών,
τότε wij = 1 αν λj ∈ Wi αλλιώς wij = 0. Κατά την οµαδοποίηση εποµένως, δύο ετικέ-
τες ϑεωρείται ότι µοιάζουν µεταξύ τους όταν έχουν µεγάλο αριθµό κοινών εµφανίσεων
(co-occurencies). Για τον υπολογισµό της οµοιότητας χρησιµοποιείται η Ευκλείδεια
απόσταση.
Ο αλγόριθµος δέχεται ως είσοδο ένα σύνολο ετικετών Ln ⊆ L, ένα σύνολο δεδοµέ-
νων των ετικετών Wi , τον αριθµό των οµάδων k και τον αριθµό των επαναλήψεων it.
Επιστρέφει k ξενα µεταξύ τους υποσύνολα του Ln που κατά προσέγγιση έχουν όλα το
ίδιο µέγεθος. Το σχήµα 5.2 παρουσιάζει τον ψευδοκώδικα του αλγορίθµου.
Το κυριότερο σηµείο στον αλγόριθµο, αλλά και η ϐασική διαφορά µε τον k-means
είναι ότι για κάθε οµάδα i διατηρείται µία λίστα από ετικέτες Ci ταξινοµηµένες µε
αύξουσα απόσταση από το κέντρο της οµάδας ci . Αν κατά την ανάθεση µίας ετικέτας
σε οµάδα προκληθεί υπέρβαση του επιτρεπόµενου µεγέθους (κατά προσέγγιση ίσο
µε τον αριθµό των αντικειµένων διαιρούµενο µε τον αριθµό των οµάδων), το τελευταίο
(πιο αποµακρυσµένο) στοιχείο της λίστας εισάγεται στη λίστα της αµέσως πλησιέστερης
οµάδας. Η διαδικασία αυτή µπορεί να οδηγήσει το πολύ σε k −1 επιπλέον διαδοχικές
εισαγωγές. ΄Αλλη µία διαφορά σε σύγκριση µε τον k-means είναι ότι περιορίζονται
οι επαναλήψεις χρησιµοποιώντας την παράµετρο it, αφού δεν έχει πραγµατοποιηθεί
έρευνα σχετικά µε τη σύγκλιση του αλγορίθµου.
Υπολογιστική Πολυπλοκότητα
Σε κάθε επανάληψη του ισορροπηµένου k means αλγορίθµου, υπολογίζεται η απόστα-
ση όλων των |Ln | ετικετών από τα κέντρα των οµάδων µε κόστος O(|Dn |) και εισάγονται
σε µία ταξινοµηµένη λίστα µέγιστου µεγέθους |Ln |/k. Η εισαγωγή αυτή έχει πολυ-
πλοκότητα O(|Ln |). ΄Οπως αναφέρθηκε και παραπάνω, η διαδικασία αυτή µπορεί να
οδηγήσει το πολύ σε k − 1 εισαγωγές σε ταξινοµηµένες λίστες στη χειρότερη περί-
πτωση αλλά η πολυπλοκότητα παραµένει O(|Ln |). Εποµένως, το συνολικό κόστος του
ισορροπηµένου k means αλγορίθµου είναι O(|Ln ||Dn | + |Ln |2). Επειδή συνήθως ισχύει
101
ΚΕΦΑΛΑΙΟ 5. ΤΑΞΙΝΟΜΗΣΗ ΚΕΙΜΕΝΩΝ ΠΟΛΛΑΠΛΩΝ ΕΤΙΚΕΤΩΝ
Είσοδος: Αριθµός οµάδων k, ετικέτες Ln , δεδοµένα ετικέτας Wi , αριθµός
επαναλήψεων it
΄Εξοδος: k ισορροπηµένες οµάδες ετικετών1
για i ← 1 έως k κάνε2
// αρχικοποίηση οµάδων και κέντρων οµάδων3
Ci ← ∅ ;4
ci ← τυχαίο µέλος του Ln ;5
όσο it > 0 κάνε6
για κάθε λ ∈ Ln κάνε7
για i ← 1 έως k κάνε8
dλi ← απόσταση(λ, ci ,Wi)9
τέλος ← ψευδές ;10
ν ← λ ;11
όσο όχι τέλος κάνε12
j ← arg min
i
dνi ;
13
Εισήγαγε ταξινοµηµένα το (ν, dν) στην ταξινοµηµένη λίστα Cj ;14
αν |Cj | > ⌈|Ln |/k⌉ τότε15
ν ← αφαίρεσε το τελευταίο αντικείµενο της οµάδας Cj ;16
dνj ← ∞ ;17
αλλιώς18
τέλος← αληθές ;19
ξανα-υπολόγισε τα κέντρα ;20
it ← it − 1 ;21
επέστρεψε C1, ..., Ck ;22
Σχήµα 5.2: Αλγόριθµος Balanced k-Means
|Ln | ≪ |Dn |, µπορούµε να ισχυριστούµε ότι ο αλγόριθµος µπορεί αποδοτικά να χωρίσει
τις ετικέτες σε ισορροπηµένες οµάδες ακόµη και σε µεγάλα σύνολα δεδοµένων.
5.2.3 Πειραµατική Αξιολόγηση
Σε αυτή την ενότητα περιγράφεται η πειραµατική αξιολόγηση της προτεινόµενης µε-
ϑόδου. Συγκεκριµένα, παρουσιάζονται τα σύνολα δεδοµένων και οι µέθοδοι που συµ-
µετέχουν στα πειράµατα.
102
5.2. HOMER
Σύνολα ∆εδοµένων
Για την αξιολόγηση του αλγορίθµου HOMER χρησιµοποιούνται δύο σύνολα δεδοµέ-
νων. Το πρώτο, δηµιουργήθηκε από το διαδικτυακό σύστηµα διαχείρισης και δια-
µοιρασµού σελιδοδεικτών παγκόσµιου ιστού (bookmarks) del.icio.us3. Τα δεδοµένα
ανακτήθηκαν την 1η Απριλίου του 2007 και περιέχουν το κείµενο σελίδων του παγ-
κόσµιου ιστού µαζί µε τις λέξεις κλειδιά (tags) µε τα οποία έχουν επισηµειωθεί.
Το σύνολο mediamill έγινε διαθέσιµο αρχικά στο διαγωνισµό Mediamill challenge
for automated detection of semantic concepts το 2006 (Snoek et al., 2006b). Περιέχει
43,907 καρέ (frames) ϐίντεο επισηµειωµένα µε κάποιες από τις 101 έννοιες (concepts)
(π.χ. military, desert, basketball, κτλ). Το σύνολο που χρησιµοποιήθηκε αντιστοιχεί
στο πείραµα 1 (Experiment1 - visual feature extraction) όπως περιγράφεται στο (Sno-
ek et al., 2006b). Κάθε καρέ ϐίντεο αποτελείται από 120 οπτικά χαρακτηριστικά.
Ο πίνακας 5.1 παρουσιάζει πληροφορίες για τα δύο σύνολα δεδοµένων όπως ο
αριθµός παραδειγµάτων, χαρακτηριστικών και ετικετών. Παρουσιάζεται επίσης ο µέ-
σος όρος ετικετών ανά παράδειγµα (label cardinality), καθώς και η κανονικοποιηµένη
έκδοση αυτού (το label cardinality διαιρούµενο µε τον αριθµό των ετικετών), που ο-
νοµάζεται πυκνότητα ετικετών (label density). Στο υπόλοιπο αυτής της υποενότητας
περιγράφουµε τη διαδικασία δηµιουργίας του συνόλου del.icio.us.
Πίνακας 5.1: Πληροφορίες και στατιστικά για τα σύνολα δεδοµένων που χρησιµο-
ποιούνται στα πειράµατα
Παραδείγµατα Χαρακτ. Label Label
Σύνολα Εκπαίδ. Αξιολόγ. Αριθµ. ∆ιακρ. Ετικέτες Cardinality Density
del.icio.us 12920 3185 0 500 983 19.020 0.019
mediamill 30993 12914 120 0 101 4.376 0.043
Αρχικά, συλλέχθηκαν τα 140 πιο δηµοφιλή tags από τη σελίδα del.icio.us/tag/.
΄Επειτα για κάθε ένα από αυτά συγκεντρώθηκαν τα 1,000 πιο πρόσφατα bookmarks
στα οποία έχει αποδοθεί το συγκεκριµένο tag. Από αυτά, επιλέχθηκαν τα 200 πιο δη-
µοφιλή bookmarks ϐάσει του αριθµού των χρηστών που τα εισήγαγαν στις προσωπικές
τους συλλογές. ΄Ετσι προέκυψε ένα σύνολο από 28,000 bookmarks, συµπεριλαµβα-
νοµένων πολλαπλών καταχωρήσεων µετά την αφαίρεση των οποίων προέκυψαν 19,740
bookmarks. Κάθε ένα από αυτά είναι επισηµειωµένο µε περισσότερα του ενός tags,
είτε γιατί ο χρήστης που αρχικά καταχώρησε τη σελίδα το επισηµείωσε µε περισσότερα
του ενός tags είτε επειδή άλλοι χρήστες το επισηµείωσαν µε διαφορετικά tags.
Από κάθε bookmark αποσπάσαµε τα 25 δηµοφιλέστερα tags, όπως αυτά ϕαίνονται
στη σελίδα του κάθε bookmark. Η διαδικασία αυτή, οδήγησε στην δηµιουργία ενός
συνόλου 22,139 tags που αφορούν όλη τη συλλογή των bookmarks. Για να αποφορτί-
σουµε το σύνολο δεδοµένων από tags τα οποία χρησιµοποιούνται σπάνια, αφαιρέσαµε
3http://delicious.com/
103
ΚΕΦΑΛΑΙΟ 5. ΤΑΞΙΝΟΜΗΣΗ ΚΕΙΜΕΝΩΝ ΠΟΛΛΑΠΛΩΝ ΕΤΙΚΕΤΩΝ
αυτά που αναφέρονται σε λιγότερο από 10 bookmarks. Αυτό οδήγησε στην παραγωγή
ενός τελικού συνόλου 983 tags.
Στη συνέχεια, συλλέχθηκαν οι σελίδες που αντιστοιχούν σε κάθε bookmark και
εξάχθηκε το περιεχόµενό τους (µόνο το κείµενο). Ο συνολικός αριθµός των διακριτών
λέξεων που προέκυψε ήταν χαρακτηριστικά µεγάλος (808,255). Για την αποφόρτιση
του συνόλου δεδοµένων από σπάνιες λέξεις, αφαιρέθηκαν αυτές που εµφανίζονται σε
λιγότερο από 10 bookmarks. Η διαδικασία αυτή οδήγησε σε ένα σηµαντικά µειωµένο
λεξικό που αποτελείται από 7,234 λέξεις. Το περιεχόµενο των σελίδων αναπαραστά-
ϑηκε µε το µοντέλο boolean-bag-of-words.
Συνοψίζοντας, για κάθε bookmark έχει συγκεντρωθεί πληροφορία σχετικά µε το
περιεχόµενό του (δηλαδή το κείµενο της σελίδας) αλλά και τα tags µε τα οποία έχει
επισηµειωθεί από τους χρήστες. Το σύνολο αυτό εποµένως αποτελεί ένα σύνολο ΠΕ
όπου τα tags αντιστοιχούν στις ετικέτες.
Με στόχο να µειωθεί ο αριθµός των χαρακτηριστικών, εφαρµόστηκε µία διαδικασία
επιλογής χρησιµοποιώντας την µετρική χ2 έτσι ώστε να αξιολογηθεί το κάθε χαρακτη-
ϱιστικό για κάθε ετικέτα ξεχωριστά. Στη συνέχεια, για κάθε χαρακτηριστικό, διατηρή-
ϑηκε µόνο η υψηλότερη τιµή του χ2. Με αυτές τις τιµές δηµιουργήθηκε µία κατάταξη
των χαρακτηριστικών από την οποία επιλέχθηκαν τα 500 κορυφαία χαρακτηριστικά.
Τα δύο σύνολα δεδοµένων είναι διαθέσιµα σε µορφή ARFF (Weka) στη διεύθυνση
http://mlkd.csd.auth.gr/multilabel.html
Μέθοδοι
Τα πειράµατα επικεντρώθηκαν στη µελέτη κλιµάκωσης του ταξινοµητή Binary Releva-
nce (BR), αφού είναι η πιο διαδεδοµένη µέθοδος ταξινόµησης ΠΕ. Η εκπαίδευση και
η ταξινόµηση του BR έχουν γραµµική πολυπλοκότητα σε σχέση µε το M. Στο HOMER
χρησιµοποιείται ως ϐασικός ταξινοµητής και πάλι ο BR έτσι ώστε να µελετηθεί το ενδε-
χόµενο πλεονέκτηµα της δενδρικής δοµής. Για τη µείωση του υπολογιστικού κόστους
των πειραµάτων, χρησιµοποιήσαµε τον ταξινοµητή naive Bayes ως ϐασικό ταξινοµητή
του BR. Αξιολογήσαµε τις µεθόδους χωρίζοντας κάθε σύνολο δεδοµένων σε ένα σύνολο
εκπαίδευσης και ένα σύνολο αξιολόγησης.
Ο αλγόριθµος HOMER εκτελείται για k = 2 έως k = 8. Εκτός από τον balanced
k-means χρησιµοποιούνται και δύο επιπλέον αλγόριθµοι για την οµαδοποίηση των
ετικετών δηµιουργώντας έτσι δύο επιπλέον εκδοχές του HOMER. Η πρώτη εκδοχή ο-
νοµάζεται HOMER-R και δηµιουργεί ισάριθµες οµάδες ετικετών αλλά µε τυχαίο τρόπο.
Σκοπός της συµµετοχής του HOMER-R είναι η µελέτη της επιρροής του παράγοντα
των ισάριθµων οµάδων. Η δεύτερη εκδοχή ονοµάζεται HOMER-K και κατανέµει τις
οµάδες σύµφωνα µόνο µε την οµοιότητα χωρίς περιορισµό στο µέγεθος των οµάδων.
Για την οµαδοποίηση στο HOMER-K χρησιµοποιείται ο αλγόριθµος k-means. Στόχος
σε αυτήν την περίπτωση είναι η µελέτη της επιρροής του παράγοντα της οµοιογένειας
των οµάδων. Η αρχική εκδοχή του HOMER που χρησιµοποιεί τον balanced k-means
ονοµάστηκε HOMER-B.
104
5.2. HOMER
5.2.4 Σχολιασµός Αποτελεσµάτων
Σε αυτή την ενότητα παρουσιάζονται και σχολιάζονται τα αποτελέσµατα των πειρα-
µάτων. Συγκεκριµένα, γίνεται ξεχωριστή ανάλυση για την ποιότητα πρόβλεψης, την
αποδοτικότητα όσον αφορά στο χρόνο εκπαίδευσης αλλά και την αποδοτικότητα στο
χρόνο ταξινόµησης. Να σηµειώσουµε ότι οι αποδόσεις του BR πολλές ϕορές ϐρίσκον-
ται εκτός γραφηµάτων οπότε σηµειώνονται στο κείµενο ξεχωριστά. Η επιλογή αυτή ϑα
επιτρέψει τη µελέτη των διαφορών µεταξύ των τριών εκδοχών του HOMER.
Ποιότητα Πρόβλεψης
Για την αξιολόγηση των µεθόδων ταξινόµησης ΠΕ έχει προταθεί ένας σηµαντικός α-
ϱιθµός µετρικών (Tsoumakas, Katakis and Vlahavas, 2009a). Κατά την εκτέλεση των
πειραµάτων, έχουν υπολογιστεί 10 διαφορετικές µετρικές µε τη ϐοήθεια του λογισµι-
κού Mulan αλλά για τη διευκόλυνση της παρουσίασης παρατίθενται µόνο οι τιµές των
Hamming Loss και micro averaged F-measure.
Το σχήµα 5.3 παρουσιάζει την ποιότητα πρόβλεψης των τριών εκδοχών του HOMER
στο σύνολο del.icio.us σε σχέση µε τον αριθµό των οµάδων (k). Ο BR παρουσιάζει
Hamming Loss ίσο µε 0.282 και F-measure ίσο µε 0.081. Παρατηρούµε εποµένως
ότι ακόµη και τα χειρότερα αποτελέσµατα του HOMER και των παραλλαγών του είναι
καλύτερα συγκριτικά µε τον BR. Αυτό οφείλεται στο γεγονός ότι ο HOMER, σε αντίθεση
µε τον BR αντιµετωπίζει µε επιτυχία το πρόβληµα ανισορροπίας που υπάρχει στον
αριθµό παραδειγµάτων των ετικετών.
0,1
0,12
0,14
0,16
0,18
0,2
0,22
0,24
0,26
2 3 4 5 6 7 8
Number of Clusters
F
-M
ea
su
re
   
   
  .
HOMER-B
HOMER-K
HOMER-R
(α΄)
0
0,01
0,02
0,03
0,04
0,05
0,06
0,07
0,08
2 3 4 5 6 7 8
Number of Clusters
H
am
m
in
g
 L
o
ss
   
   
  .
HOMER-B
HOMER-K
HOMER-R
(ϐ΄)
Σχήµα 5.3: Ποιότητα πρόβλεψης των τριών εκδοχών του HOMER στο σύνολο
del.icio.us.
Η επόµενη παρατήρηση είναι ότι ο HOMER-B, σε σχέση µε τις άλλες δύο εκδοχές,
παρουσιάζει ανώτερη ποιότητα πρόβλεψης σύµφωνα µε τις δύο µετρικές. Ακολουθεί
ο HOMER-R και έπειτα ο HOMER-K. Αυτό αποδεικνύει ότι η ισάριθµη κατανοµή των
105
ΚΕΦΑΛΑΙΟ 5. ΤΑΞΙΝΟΜΗΣΗ ΚΕΙΜΕΝΩΝ ΠΟΛΛΑΠΛΩΝ ΕΤΙΚΕΤΩΝ
οµάδων είναι σηµαντικότερη από την οµοιότητα. Ο συνδυασµός τους όµως (HOMER-B)
παρουσιάζει ακόµη καλύτερα αποτελέσµατα. Ο HOMER-K ϕαίνεται να παρουσιάζει
ϐελτίωση όσο αυξάνεται ο αριθµός των οµάδων. Ενδεχοµένως ο µεγάλος αριθµός
των οµάδων να µετριάζει το πρόβληµα της ανισορροπίας στα υπο-προβλήµατα της
ιεραρχίας. Η απόδοση των HOMER-B και HOMER-R παρουσιάζει µία πτωτική τάση
στο Hamming Loss. Ενδεχοµένως το ϕαινόµενο αυτό να σχετίζεται µε το γεγονός ότι
οι περισσότερες οµάδες δηµιουργούν ανισορροπία στην κατανοµή των µετα-ετικετών.
Στο σχήµα 5.4 παρουσιάζεται η ποιότητα πρόβλεψης (hamming loss και f-
measure) των τριών εκδοχών του HOMER στο σύνολο mediamill σε σχέση µε τον
αριθµό των οµάδων. Ο BR σε αυτό το σύνολο παρουσιάζει Hamming Loss ίσο µε
0.331 και F-measure ίσο µε 0.157. ΄Οπως και στο προηγούµενο σύνολο παρατηρού-
µε την υπεροχή όλων των παραλλαγών του HOMER σε σχέση µε τον BR.
0,23
0,28
0,33
0,38
0,43
0,48
2 3 4 5 6 7 8
Number of Clusters
F
-m
ea
su
re
   
  .
HOMER-B
HOMER-K
HOMER-R
(α΄)
0,03
0,04
0,05
0,06
0,07
0,08
0,09
0,1
0,11
0,12
0,13
2 3 4 5 6 7 8
Number of Clusters
H
am
m
in
g
 L
o
ss
   
   
 .
HOMER-B
HOMER-K
HOMER-R
(ϐ΄)
Σχήµα 5.4: Ποιότητα πρόβλεψης των παραλλαγών του HOMER στο σύνολο mediamill.
Παρόλα αυτά, σε αυτήν την περίπτωση παρατηρούµε ότι ο HOMER-K ξεπερνάει σε
απόδοση τον HOMER-B ο οποίος παραµένει καλύτερος από τον HOMER-R. Το γεγονός
αυτό αποδεικνύει ότι η οµοιότητα αποτελεί σηµαντικότερο παράγοντα σε αυτήν την
περίπτωση από τις ισάριθµες οµάδες. Μία πιθανή εξήγηση ϑα µπορούσε να είναι ότι
η ισορρόπηση των οµάδων παίζει µεγαλύτερο ϱόλο όσο µεγαλύτερος είναι ο αριθµός
των ετικετών. Το ενδεχόµενο αυτό ϑα πρέπει να εξεταστεί στο µέλλον σε ελεγχόµενα
πειράµατα. Μία άλλη αιτία ίσως να είναι ότι οι ετικέτες στο σύνολο mediamill µπορεί
να έχουν πιο ισχυρές συσχετίσεις µεταξύ τους και οµαδοποιούνται µε ϕυσικότερο
τρόπο. Για παράδειγµα πολλές από τις 101 κατηγορίες σχετίζονται µε την έννοια
people (people, people walking, people marching, κτλ), άλλες µε οχήµατα (car, bus,
vehicle, κτλ) κ.ο.κ (Snoek et al., 2006a). Η απόδοση των τριών εκδοχών του HOMER
µειώνεται σε σχέση µε τον αριθµό των οµάδων. ΄Οπως και προηγουµένως το γεγονός
αυτό ίσως να οφείλεται στο ότι οι περισσότερες οµάδες δηµιουργούν ανισορροπία στην
κατανοµή των µετα-ετικετών.
106
5.2. HOMER
Αποδοτικότητα Εκπαίδευσης
Η εκτίµηση της αποδοτικότητας του HOMER ως προς τη διαδικασία της εκπαίδευσης
πραγµατοποιήθηκε υπολογίζοντας τρεις σχετικούς δείκτες : α) τον αριθµό των δυαδι-
κών (binary) ταξινοµητών που απαιτήθηκαν για την εκπαίδευση, ϐ) το συνολικό αριθµό
παραδειγµάτων που χρειάστηκαν για να εκπαιδευτούν αυτοί οι ταξινοµητές και γ) το
χρόνο εκπαίδευσης.
΄Οπως ήταν αναµενόµενο, για τον αλγόριθµο BR απαιτείται η εκπαίδευση 983 τα-
ξινοµητών στο σύνολο del.icio.us και 101 στο mediamill. Το σχήµα 5.5 δείχνει ότι ο
αλγόριθµος HOMER και οι παραλλαγές του χρειάζεται να εκπαιδεύσουν περισσότε-
ϱους ταξινοµητές. Ο αριθµός αυτός µειώνεται σε σχέση µε τον αριθµό των οµάδων.
1200
1300
1400
1500
1600
1700
1800
1900
2000
2 3 4 5 6 7 8
Number of Clusters
C
la
ss
ifi
er
s 
   
   
 .
HOMER-B
HOMER-K
HOMER-R
(α΄) del.icio.us
120
130
140
150
160
170
180
190
200
210
2 3 4 5 6 7 8
Number of Clusters
C
la
ss
ifi
er
s 
   
   
   
.
HOMER-B
HOMER-K
HOMER-R
(ϐ΄) mediamill
Σχήµα 5.5: Αριθµός δυαδικών ταξινοµητών που απαιτούνται για τις τρεις εκδοχές του
HOMER.
Παρόλα αυτά, στο σχήµα 5.6 παρατηρούµε ότι ο συνολικός αριθµός παραδειγ-
µάτων που απαιτείται από τον HOMER είναι πολύ µικρότερος από τον αριθµό των
παραδειγµάτων που απαιτούν οι ταξινοµητές του BR (M |D|), οι οποίοι στην περίπτωσή
µας είναι περισσότεροι από 15 εκατοµµύρια στο σύνολο del.icio.us και περισσότεροι
από 3 εκατοµµύρια στο σύνολο mediamill. Να σηµειωθεί ότι και η οµοιότητα αλλά και
οι ισάριθµες οµάδες ϐοηθούν στη µείωση των παραδειγµάτων που µεταφέρονται από
τους κόµβους γονείς στους κόµβους παιδιά, αφού ο HOMER-B ϕαίνεται να οδηγεί σε
σύνολα δεδοµένων µε συνολικά λιγότερα παραδείγµατα.
Ο συνολικός χρόνος εκπαίδευσης του BR είναι 24.6 λεπτά στο del.icio.us και 10.1
λεπτά στο mediamill. Εκτός από τον συνολικό αριθµό των παραδειγµάτων, ο συνολικός
χρόνος εκπαίδευσης του HOMER εξαρτάται από τη διαδικασία κατανοµής των ετικετών
στα υποσύνολα. Είδαµε προηγουµένως ότι ο HOMER-B είναι τετραγωνικός σε σχέση
µε το M. Παρά το γεγονός ότι ο αλγόριθµος k means είναι γραµµικός σε σχέση µε
το M, ο HOMER-K είναι επίσης τετραγωνικός επειδή το υπολογιστικό κέρδος από την
ισορροπηµένη οµαδοποίηση δεν υφίσταται. Προφανώς ο HOMER-R είναι γραµµικός
107
ΚΕΦΑΛΑΙΟ 5. ΤΑΞΙΝΟΜΗΣΗ ΚΕΙΜΕΝΩΝ ΠΟΛΛΑΠΛΩΝ ΕΤΙΚΕΤΩΝ
0,0E+00
5,0E+05
1,0E+06
1,5E+06
2,0E+06
2,5E+06
3,0E+06
3,5E+06
4,0E+06
4,5E+06
5,0E+06
2 3 4 5 6 7 8
Number of Clusters
In
st
an
ce
s 
   
   
 .
HOMER-B
HOMER-K
HOMER-R
(α΄) del.icio.us
7,0E+05
8,0E+05
9,0E+05
1,0E+06
1,1E+06
1,2E+06
1,3E+06
1,4E+06
1,5E+06
2 3 4 5 6 7 8
Number of Clusters
In
st
an
ce
s 
   
   
   
.
HOMER-B
HOMER-K
HOMER-R
(ϐ΄) mediamill
Σχήµα 5.6: Αριθµός παραδειγµάτων που απαιτούνται για τους δυαδικούς ταξινοµητές
των παραλλαγών του HOMER.
σε σχέση µε το M. Το σχήµα 5.7 παρουσιάζει το χρόνο εκπαίδευσης των παραλλαγών
του HOMER σε σχέση µε τον αριθµό των οµάδων. Παρατηρούµε ότι ο HOMER-K απαι-
τεί περισσότερο χρόνο, γεγονός που µπορεί να εξηγηθεί από τον αριθµό επαναλήψεων
που απαιτούνται για τη σύγκλισή του k-means. Ο HOMER-B παρουσιάζει ένα µικρό
µόνο µειονέκτηµα σε σχέση µε τον HOMER-R.
0,1
50,1
100,1
150,1
200,1
250,1
2 3 4 5 6 7 8
Number of Clusters
T
ra
in
in
g
 T
im
e 
   
   
 .
HOMER-B
HOMER-K
HOMER-R
(α΄) del.icio.us
4
6
8
10
12
14
16
18
20
2 3 4 5 6 7 8
Number of Clusters
T
ra
in
in
g
 T
im
e 
   
 .
HOMER-B
HOMER-K
HOMER-R
(ϐ΄) mediamill
Σχήµα 5.7: Χρόνος εκπαίδευσης (σε λεπτά) των τριών εκδοχών του HOMER.
Θα αναµέναµε γενικά ο συνολικός χρόνος εκπαίδευσης των εκδοχών του HOMER
να είναι λιγότερος από το BR. Θεωρούµε ότι ο αυξηµένος χρόνος οφείλεται σε µη
ϐελτιστοποιηµένο κοµµάτι της υλοποίησης του HOMER, όπως είναι για παράδειγµα η
διαδικασία ϕιλτραρίσµατος των δεδοµένων, αφού ο χρόνος ϕαίνεται να σχετίζεται γραµ-
µικά µε τον αριθµό των ταξινοµητών. Μία ϐελτιστοποιηµένη υλοποίηση του HOMER
108
5.2. HOMER
είναι στα άµεσα ερευνητικά µας πλάνα.
Αποδοτικότητα Ταξινόµησης
Η ϐελτίωση της απόδοσης στο χρόνο ταξινόµησης αποτελεί έναν από τους ϐασικούς
στόχους του αλγορίθµου HOMER, κινητήρια εφαρµογή για την εφεύρεση του οποίου
ήταν η αυτόµατη πρόταση tags σε κοινωνικά δίκτυα. Η απόδοση ταξινόµησης µετρά-
ται µε τον χρόνο εκτέλεσης ενώ παρουσιάζεται και ο µέσος όρος των ταξινοµητών που
ενεργοποιήθηκαν κατά την ταξινόµηση ενός αντικειµένου αφού αποτελεί καθοριστικό
παράγοντα για το χρόνο εκτέλεσης. Το σχήµα 5.8 παρουσιάζει το µέσο αριθµό ταξινο-
µητών που ενεργοποιήθηκαν και το συνολικό χρόνο ταξινόµησης για τις παραλλαγές
του αλγορίθµου HOMER στο σύνολο del.icio.us. Ο αλγόριθµος BR ενεργοποιεί 983
ταξινοµητές και απαιτεί 69.4 λεπτά για την ταξινόµηση. Το πλεονέκτηµα των εκδοχών
του HOMER λοιπόν είναι προφανές αφού ενεργοποιούνται πολύ λιγότεροι ταξινοµητές
και µειώνεται σηµαντικά ο χρόνος εκτέλεσης. Παρατηρούµε επίσης ότι στον HOMER-
B και στον HOMER-R οι ταξινοµητές που ενεργοποιούνται αυξάνονται σε σχέση µε τον
αριθµό των οµάδων ενώ στον HOMER-K υπάρχει µία αρχική µείωση αλλά στη συνέχεια
παρουσιάζεται αύξηση. Τελικά, ο HOMER-B παρουσιάζεται ταχύτερος.
75
125
175
225
275
325
375
425
2 3 4 5 6 7 8
Number of Clusters
A
vg
 C
la
ss
ifi
er
s 
F
ir
ed
   
   
  .
HOMER-B
HOMER-K
HOMER-R
(α΄)
0
2
4
6
8
10
12
2 3 4 5 6 7 8
Number of Clusters
T
es
t T
im
e 
   
   
 .
HOMER-B
HOMER-K
HOMER-R
(ϐ΄)
Σχήµα 5.8: Μέσος όρος ταξινοµητών που ενεργοποιήθηκαν και χρόνος ταξινόµησης
(σε λεπτά) για τις παραλλαγές του HOMER σε σχέση µε τον αριθµό των οµάδων στο
σύνολο del.icio.us.
Το σχήµα 5.9 παρουσιάζει το µέσο όρο του αριθµού των ταξινοµητών που ενερ-
γοποιήθηκαν και το συνολικό χρόνο ταξινόµησης των παραλλαγών του HOMER στο
σύνολο mediamill. Ο BR ενεργοποιεί 101 ταξινοµητές σε αυτό το σύνολο, ενώ απαιτεί
7.6 λεπτά για την ταξινόµηση. Βελτιώσεις παρουσιάζονται και σε αυτό το σύνολο, αν
και σε µικρότερη έκταση σε σχέση µε το del.icio.us. Παρατηρούµε επίσης ότι ο α-
ϱιθµός των κόµβων που ενεργοποιούνται αυξάνεται σε σχέση µε τις οµάδες ειδικά για
τον HOMER-B και HOMER-R αλλά επίσης και για τον HOMER-K αλλά µε µικρότερο
109
ΚΕΦΑΛΑΙΟ 5. ΤΑΞΙΝΟΜΗΣΗ ΚΕΙΜΕΝΩΝ ΠΟΛΛΑΠΛΩΝ ΕΤΙΚΕΤΩΝ
ϱυθµό. Ο χρόνος ταξινόµησης δεν ακολουθεί αυτή την τάση, ενδεχοµένως επηρεα-
σµένος από εκτέλεση άλλων διαδικασιών επεξεργασίας από τον υπολογιστή εκτέλεσης
πειραµάτων. Η καταµέτρηση του αριθµού εντολών αντί του χρόνου εκτέλεσης είναι στα
άµεσα σχέδιά µας.
0
10
20
30
40
50
60
2 3 4 5 6 7 8
Number of Clusters
A
vg
 C
la
ss
ifi
er
s 
F
ir
ed
   
   
   
  .
HOMER-B
HOMER-K
HOMER-R
(α΄)
3
3,5
4
4,5
5
5,5
6
6,5
7
7,5
8
2 3 4 5 6 7 8
Number of Clusters
T
es
t T
im
e 
   
 .
HOMER-B
HOMER-K
HOMER-R
(ϐ΄)
Σχήµα 5.9: Μέσος όρος ταξινοµητών που ενεργοποιούνται και χρόνος ταξινόµησης (σε
λεπτά) των παραλλαγών του HOMER σε σχέση µε τον αριθµό των οµάδων στο σύνολο
mediamill.
Είναι σηµαντικό να παρατηρήσουµε ότι και πάλι σε αυτό το σύνολο ο HOMER-K
αποδίδει καλύτερα από τον HOMER-B ο οποίος αποδίδει καλύτερα από τον HOMER-
R. Και εδώ µπορεί να ισχύει η ίδια εξήγηση όπως και προηγουµένως. Φαίνεται ότι
οι ισάριθµες οµάδες είναι πιο χρήσιµες σε πεδία µε µεγάλο αριθµό ετικετών ή ότι η
οµοιότητα είναι σηµαντικότερη σε προβλήµατα όπου υπάρχει µία ‘φυσική’ οµαδοποί-
ηση στα δεδοµένα.
5.3 Η µέθοδος RAkEL
΄Οπως αναφέρθηκε και στην εισαγωγή, η µέθοδος του δυναµοσυνόλου ετικετών (Label
Powerset - LP) αντιµετωπίζει δυσκολίες σε προβλήµατα µε µεγάλο αριθµό ετικετών M
και παραδειγµάτων N . Η πολυπλοκότητα του LP σε σχέση µε το M εξαρτάται από
την πολυπλοκότητα του ταξινοµητή µονής ετικέτας που χρησιµοποιείται σε σχέση µε
τον αριθµό των τάξεων. Ο αριθµός αυτός ισοδυναµεί µε τον αριθµό των διακριτών
συνδυασµών ετικετών που εµφανίζονται στο σύνολο παραδειγµάτων. ΄Εχει άνω όριο
ίσο µε min(N, 2M ) και παρά το γεγονός ότι συνήθως η τιµή του είναι πολύ µικρότερη
αποτελεί σηµαντικό πρόβληµα κλιµάκωσης ειδικά σε περιπτώσεις όπου τα N και M
έχουν µεγάλες τιµές. Επίσης, ο µεγάλος αριθµός των τάξεων, πολλές από τις οποίες
εµφανίζονται σε µικρό αριθµό παραδειγµάτων, κάνει την διαδικασία µάθησης ιδιαίτερα
δύσκολη.
110
5.3. Η ΜΕΘΟ∆ΟΣ RAKEL
Η κύρια ιδέα της µεθόδου που παρουσιάζεται σε αυτή την ενότητα είναι η τυχαία
διάσπαση ενός αρχικά µεγάλου συνόλου ετικετών σε µικρότερα υποσύνολα, τα οποία
ονοµάζουµε labelsets (ετικετοσύνολα), για κάθε ένα από τα οποία εκπαιδεύεται ένας
ξεχωριστός LP ταξινοµητής. Με αυτόν τον τρόπο οι labelset-ταξινοµητές που προκύ-
πτουν αντιµετωπίζουν πολύ απλούστερα προβλήµατα µονής ετικέτας και µία περισ-
σότερο ισορροπηµένη κατανοµή τάξεων. Για την ταξινόµηση ενός νέου αντικειµένου,
συνδυάζονται οι αποφάσεις όλων των LP ταξινοµητών.
Για λόγους απλότητας, δηµιουργούνται labelsets ίδιου µεγέθους k. ΄Ενα labelset
R ⊆ L µε k = |R| και L το σύνολο των ετικετών ονοµάζεται k-labelset (k-ετικετοσύνολο).
Ο προτεινόµενος αλγόριθµος ονοµάζεται RAkEL (RAndom k labELsets - Τυχαία k ε-
τικετοσύνολα). Εξετάζεται η κατασκευή δύο τύπων labelsets, δηµιουργώντας έτσι δύο
παραλλαγές του RAkEL: α) labelsets ξένα µεταξύ τους (disjoint - RAkELd ), και ϐ)
labelsets επικαλυπτόµενα (overlapping - RAkELo). Στη δεύτερη περίπτωση, ο RAkEL
συνήθως επιστρέφει πολλαπλές προβλέψεις για την ίδια ετικέτα. Το γεγονός αυτό επι-
τρέπει τη διόρθωση σφαλµάτων µέσα από µία διαδικασία ψηφοφορίας. Στις επόµενες
ενότητες αναλύουµε σε λεπτοµέρεια τις δυο παραλλαγές του RAkEL.
5.3.1 RAkELd
΄Εστω k το µεγέθος των labelsets. Ο RAkELd αρχικά διασπά το σύνολο L τυχαία σε
m = ⌈M/k⌉ ξένα µεταξύ τους labelsets Ri , i = 1 . . . m, µε
⋂m
i=1 Ri = ∅. Τα labelsets Ri ,
i = 1 . . . m − 1 είναι σίγουρα k-labelsets. Αν M/k είναι ακέραιος, τότε το labelset Rm
είναι επίσης k-labelset, αλλιώς το Rm περιέχει τις εναποµείνασες M mod k ετικέτες.
Στη συνέχεια, ο RAkELd εκπαιδεύει m LP ταξινοµητές hi , i = 1 . . . m. Κάθε LP
ταξινοµητής hi αντιµετωπίζει ένα πρόβληµα ταξινόµησης απλής ετικέτας µε τάξεις όσες
οι διακριτοί συνδυασµοί των ετικετών του Ri που εµφανίζονται στο σύνολο εκπαίδευσης.
Το σχήµα 5.10 παρουσιάζει τον αλγόριθµο εκπαίδευσης του RAkELd.
∆εδοµένου ενός αντικειµένου ~x, οι δυαδικές προβλέψεις hi(~x, λj) όλων των ταξι-
νοµητών hi για όλες τις ετικέτες λj ∈ Ri συγκεντρώνονται µε στόχο την ανάπτυξη του
τελικού διανύσµατος ταξινόµησης (ϐλέπε σχήµα 5.11).
5.3.2 RAkELo
΄Εστω οτι όρος Lk δηλώνει το σύνολο όλων των διακριτών k-labelsets του L. Το µέγεθος
του Lk δίνεται από τον δυωνυµικό συντελεστή |Lk | =
(
M
k
)
. ΄Εστω k το µέγεθος των label-
sets και m ≤ |Lk | ο αριθµός των επιθυµητών ταξινοµητών. Ο RAkELo αρχικά επιλέγει
m k-labelsets Ri , i = 1 . . . m από το L
k µε τυχαία επιλογή χωρίς επανατοποθέτηση.
Πρέπει να σηµειωθεί ότι σε αυτήν την περίπτωση τα labelsets µπορεί να είναι επικα-
λυπτόµενα. Η επικάλυψη είναι σίγουρη όταν mk > M. ΄Επειτα, ο RAkELo εκπαιδεύει
m LP ταξινοµητές hi, i = 1 . . . m όπως και στην περίπτωση του RAkELd. Το σχήµα
5.12 παρουσιάζει τη διαδικασία εκπαίδευσης του RAkELo σε ψευδοκώδικα.
Για την ταξινόµηση ενός αντικειµένου ~x, κάθε µοντέλο hi παρέχει µία δυαδική
111
ΚΕΦΑΛΑΙΟ 5. ΤΑΞΙΝΟΜΗΣΗ ΚΕΙΜΕΝΩΝ ΠΟΛΛΑΠΛΩΝ ΕΤΙΚΕΤΩΝ
Είσοδος: Σύνολο ετικετών L µεγέθους M, σύνολο εκπαίδευσης D, µεγέθος
labelset k
΄Εξοδος: Αριθµός µοντέλων m, k-labelsets Ri , LP ταξινοµητές hi
m ← ⌈M/k⌉;1
για i = 1 έως m κάνε2
για j = 1 έως k κάνε3
αν L = ∅ τότε4
break;5
λj ← επέλεξε τυχαία µία ετικέτα από το L;6
Ri ← Ri ∪ {λj};7
L ← L \ {λj};8
Εκπαίδευσε έναν LP ταξινοµητή hi µε δεδοµένα από το D αλλά µε ϐάση τις9
ετικέτες του Ri ;
Σχήµα 5.10: Η διαδικασία εκπαίδευσης του RAkELd.
Είσοδος: Νέο αντικείµενο ~x, αριθµός µοντέλων m, LP ταξινοµητές hi ,
k-labelsets Ri
΄Εξοδος: ∆ιάνυσµα ταξινόµησης πολλαπλών ετικετών Result
για i = 1 έως m κάνε1
για όλα τα λj ∈ Ri κάνε2
Resultj ← hi(x, λj)·3
Σχήµα 5.11: Η διαδικασία ταξινόµησης του RAkELd.
Είσοδος: Σύνολο ετικετών L µεγέθους M, σύνολο εκπαίδευσης D, µέγεθος
labelset k, αριθµός µοντέλων m ≤
(
M
k
)
΄Εξοδος: k-labelsets Ri , LP ταξινοµητές hi
S ← Lk ;1
για i = 1 έως min(m, |Lk |) κάνε2
Ri ← ένα k-labelset τυχαία επιλεγµένο από το S;3
Εκπαίδευσε έναν LP ταξινοµητή hi στο D για τις ετικέτες που υπάρχουν στο4
Ri ;
S ← S \ {Ri };5
Σχήµα 5.12: Η διαδικασία εκπαίδευσης του RAkELo.
112
5.3. Η ΜΕΘΟ∆ΟΣ RAKEL
πρόβλεψη hi(~x, λj) για κάθε ετικέτα λj στο αντίστοιχο k-labelset Ri . Στη συνέχεια, ο
RAkELo υπολογίζει το µέσο αυτών των προβλέψεων για κάθε ετικέτα λj ∈ L και επι-
στρέφει ϑετική τελική έξοδο αν η τιµή αυτή είναι µεγαλύτερη από το κατώφλι του 0.5.
Το κατώφλι αυτό αντιστοιχεί ουσιαστικά στην ψηφοφορία πλειοψηφίας που χρησιµο-
ποιείται ευρέως για το συνδυασµό αποφάσεων ταξινοµητών στην ερευνητική περιοχή
των οµάδων ταξινοµητών (ensemble methods). ΄Εχει χρησιµοποιηθεί επίσης και για
τη λήψη απόφασης στη µέθοδο µετασχηµατισµού RPC (Hullermeier et al., 2008). Ο
ψευδοκώδικας της διαδικασίας ταξινόµησης του RAkELo ϕαίνεται στο σχήµα 5.13.
Είσοδος: Σύνολο ετικετών L µεγέθους M, αριθµός µοντέλων m, k-labelsets Ri ,
LP ταξινοµητές hi , νέο αντικείµενο ~x
΄Εξοδος: ∆ιάνυσµα ταξινόµησης πολλαπλών ετικετών Result
για j = 1 έως M κάνε1
Sumj ← 0;2
Votesj ← 0;3
για i = 1 έως m κάνε4
για όλα τα λj ∈ Ri κάνε5
Sumj ← Sumj + hi(~x, λj);6
Votesj ← Votesj + 1;7
για j = 1 έως M κάνε8
Avgj ← Sumj/Votesj;9
αν Avgj > 0.5 τότε10
Resultj ← 1 ;11
αλλιώς Resultj ← 0 ;12
Σχήµα 5.13: Η διαδικασία ταξινόµησης του RAkELo.
Οι παράµετροι m (αριθµός ταξινοµητών) και k (µέγεθος labelset) καθορίζουν τον
αναµενόµενο αριθµό προβλέψεων για κάθε ετικέτα, που ισούται µε km
M
. Υποθέτουµε
ότι όσο µεγαλύτερος είναι αυτός ο αριθµός, τόσο µεγαλύτερη ϑα είναι και η ακρίβεια
του RAkELo, λόγω του συγκερασµού πολλών ταξινοµητών. ∆εδοµένου ότι το k πρέπει
να είναι µικρό για να αποφευχθεί το πρόβληµα πολυπλοκότητας του LP, τότε για να
αυξηθεί το km καλό ϑα ήταν να τεθεί µεγάλη τιµή στον παράγοντα m. Η πειραµατική
µελέτη που ακολουθεί ερευνά τη σχέση του m και του k µε την ποιότητα πρόβλεψης
και προτείνει κριτήρια για την επιλογή κατάλληλων τιµών.
Ανάλυση Πολυπλοκότητας
Αν η πολυπλοκότητα του αλγορίθµου µονής ετικέτας είναι O(g(C, N, A)) για ένα σύνολο
µε C τάξεις, N παραδείγµατα και A χαρακτηριστικά, τότε η πολυπλοκότητα του RAkEL
113
ΚΕΦΑΛΑΙΟ 5. ΤΑΞΙΝΟΜΗΣΗ ΚΕΙΜΕΝΩΝ ΠΟΛΛΑΠΛΩΝ ΕΤΙΚΕΤΩΝ
είναι O(mg(min(N, 2k), N, A)), όπου m = ⌈M/k⌉ στην περίπτωση των ξένων συνόλων
ετικετών. Η πολυπλοκότητα είναι δηλαδή γραµµική σε σχέση µε τον αριθµό των LP
ταξινοµητών και επιπλέον εξαρτάται από την πολυπλοκότητα του ταξινοµητή µονής
ετικέτας.
Ο αριθµός των LP ταξινοµητών, m, είναι γραµµικός σε σχέση µε το M στην πε-
ϱίπτωση των ξένων labelsets. Η πειραµατική µελέτη που ακολουθεί, υποδεικνύει ότι
στην περίπτωση των επικαλυπτόµενων συνόλων ετικετών µία µικρή τιµή του m που
είναι γραµµική σε σχέση µε το M (π.χ. 2M ) αρκεί για την επίτευξη υψηλής απόδοσης
πρόβλεψης. Ο εκθετικός παράγοντας 2k δεν αποτελεί πρόβληµα αφού το k λαµβάνει
µικρές τιµές.
5.3.3 Σύνολα ∆εδοµένων
Τα πειράµατα εκτελέστηκαν σε 8 σύνολα δεδοµένων πολλαπλών ετικετών4. Ο πίνακας
5.2 περιλαµβάνει διάφορες πληροφορίες για κάθε ένα από αυτά συµπεριλαµβανοµέ-
νου του µέσου αριθµού ετικετών ανά παράδειγµα (label cardinality) και του αριθµού
των διακριτών (distinct) labelsets που αποτελούν σηµαντικούς παράγοντες για µεθό-
δους που χειρίζονται συνδυασµούς ετικετών. Σύντοµες περιγραφές αυτών των συνόλων
δίνονται στις παρακάτω παραγράφους.
Πίνακας 5.2: Σύνολα δεδοµένων πολλαπλών ετικετών και πληροφορίες σχετικά µε
αυτά. Τα σύνολα είναι ταξινοµηµένα σύµφωνα µε το συνολικό αριθµό ετικετών τους.
σύνολο παραδείγµατα χαρακτηριστικά ετικέτες cardinal. distinct
scene 2407 294 6 1.074 15
yeast 2417 103 14 4.237 198
tmc2007 28596 49060 22 2.158 1341
medical 978 1449 45 1.245 94
enron 1702 1001 53 3.378 753
mediamill 43907 120 101 4.376 6555
rcv1 6000 47236 101 2.880 1028
bibtex 7395 1836 159 2.402 2856
Το σύνολο scene περιέχει 2,407 εικόνες που έχουν επισηµειωθεί µε µία ή περισ-
σότερες από 6 έννοιες όπως beach, mountain και field (Boutell et al., 2004). Κάθε
εικόνα αποτελείται από 294 οπτικά (visual) χαρακτηριστικά.
Το σύνολο yeast (Elisseeff and Weston, 2002) περιέχει εκφράσεις γονιδίων µικρο-
συστοιχιών (micro array expressions) και ϕυλογενετικά προφίλ (phylogenetic profiles)
για 2,417 γονίδια του Ϲυµοµύκητα (yeast). Κάθε γονίδιο έχει επισηµειωθεί µε µία ή
περισσότερες από 14 συνολικά κατηγορίες λειτουργιών (π.χ. metabolism, energy, κτλ)
4∆ιαθέσιµα στη διεύθυνση : http://mlkd.csd.auth.gr/multilabel.html
114
5.3. Η ΜΕΘΟ∆ΟΣ RAKEL
από το κορυφαίο επίπεδο του καταλόγου λειτουργιών FunCat (Functional Catalo-
gue5).
Το σύνολο tmc2007 ϐασίζεται σε δεδοµένα του διαγωνισµού που διοργανώθηκε στο
text mining workshop του 7ου SIAM International Conference on Data Mining6. Η
αρχική συλλογή περιέχει 28,596 αναφορές πτήσεων σε µορφή ελεύθερου κειµένου,
επισηµειωµένες µε έναν ή περισσότερους από 22 τύπους προβληµάτων που παρου-
σιάζονται κατά τις πτήσεις (Srivastava and Zane-Ulman, 2005). Η αναπαράσταση
των κειµένων ακολουθεί την προσέγγιση bag-of-words. Επιπλέον, πραγµατοποιήθηκε
επιλογή χαρακτηριστικών µε στόχο την ελάττωση του χρόνου εκπαίδευσης. Χρησι-
µοποιήθηκε η µετρική χ2 για την αξιολόγηση της συσχέτισης όλων των Ϲευγαριών
<χαρακτηριστικό, ετικέτα>. Για κάθε χαρακτηριστικό καταγράφηκε η µεγαλύτερη
από αυτές τις τιµές. Με ϐάση αυτές τις µεγαλύτερες τιµές επιλέχθηκαν τα 500 καταλ-
ληλότερα χαρακτηριστικά. Μία παρόµοια προσέγγιση αποδείχθηκε αποτελεσµατική
για επιλογή χαρακτηριστικών από δεδοµένα κειµένων (Rogati and Yang, 2002).
Το σύνολοmedical 7 ϐασίζεται σε δεδοµένα που έγιναν διαθέσιµα κατά τη διάρκεια
του διαγωνισµού Computational Medicine Center’s 2007 Medical Natural Language
Processing Challenge8. Τα δεδοµένα αποτελούνται από 978 κλινικές αναφορές σε
µορφή απλού κειµένου επισηµειωµένες µε έναν ή περισσότερους από 45 συνολικά
κωδικούς ασθενειών.
Το σύνολο enron ϐασίζεται σε µία συλλογή από µηνύµατα ηλεκτρονικού ταχυ-
δροµείου τα οποία στάλθηκαν µεταξύ των υπαλλήλων της εταιρείας Enron και έγιναν
διαθέσιµα εξαιτίας ενός νοµικού ελέγχου. Περιέχει 1702 µηνύµατα τα οποία κατηγο-
ϱιοποιήθηκαν σε κάποιες από τις 53 συνολικά οµάδες όπως είναι company strategy,
humor, legal advice στο UC Berkeley Enron Email Analysis Project9.
Πληροφορίες για το σύνολο mediamill υπάρχουν σε προηγούµενη ενότητα αυτού
του κεφαλαίου (ενότητα 5.2.3).
Το σύνολο bibtex (Katakis et al., 2008) ϐασίζεται σε δεδοµένα που έγιναν διαθέσιµα
κατά τη διάρκεια του διαγωνισµού ECML/PKDD 2008 discovery challenge. Περιέχει
7,395 εγγραφές bibtex10 από το διαδικτυακό σύστηµα αποθήκευσης και διαµοιρα-
σµού σελιδοδεικτών (bookmarks) και ϐιβλιογραφικών αναφορών (bibtex) Bibsnomy.
Κάθε bibtex εγγραφή έχει επισηµειωθεί µε ένα σύνολο από tags που έχουν ανατεθεί
από τους χρήστες του συστήµατος (π.χ. statistics, quantum, datamining). Ο τίτλος και
η περίληψη του άρθρου χρησιµοποιήθηκαν για την κατασκευή των χαρακτηριστικών
χρησιµοποιώντας την προσέγγιση Boolean bag of words.
Το σύνολο reuters (rcv1) είναι ένα γνωστό σύνολο αξιολόγησης µεθόδων ταξινόµη-
σης κειµένων. Χρησιµοποιήθηκε ένα υποσύνολο αυτού (subset1) το οποίο περιέχει
5http://mips.gsf.de/projects/funcat
6http://www.cs.utk.edu/tmw07/
7Το οποίο αρχικά προµηθευτήκαµε από τη διεύθυνση http://www.cs.waikato.ac.nz/ jmr30/
8http://www.computationalmedicine.org/challenge/index.php
9http://bailando.sims.berkeley.edu/enron_email.html
10BibTeX είναι το σύστηµα διαχείρισης ϐιβλιογραφικών αναφορών του περιβάλλοντος LaTeX
115
ΚΕΦΑΛΑΙΟ 5. ΤΑΞΙΝΟΜΗΣΗ ΚΕΙΜΕΝΩΝ ΠΟΛΛΑΠΛΩΝ ΕΤΙΚΕΤΩΝ
6,000 άρθρα ειδήσεων τα οποία έχουν καταχωρηθεί σε µία ή περισσότερες από 101
κατηγορίες. Για τη µείωση της υπολογιστικής πολυπλοκότητας εκτέλεσης των πει-
ϱαµάτων, διατηρήθηκαν µόνο οι λέξεις που εµφανίζονται τουλάχιστον 50 ϕορές στη
συλλογή καταλήγοντας έτσι σε 1,654 χαρακτηριστικά. Μία αναλυτικότερη περιγραφή
αυτού του συνόλου µπορεί να ϐρεθεί στην εργασία (Lewis et al., 2004).
5.3.4 Αποτελέσµατα
Στην ενότητα αυτή παρουσιάζονται τα αποτελέσµατα της πειραµατικής αξιολόγησης
και παρατίθενται συµπεράσµατα για την απόδοση πρόβλεψης του RAkEL. Το πρώτο
κοµµάτι µελετά την απόδοση των RAkELd και RAkELo σε σχέση µε τις παραµέτρους
τους και τη ϐελτίωση που παρουσιάζουν στην ποιότητα πρόβλεψης σε σχέση µε τον LP.
Παρατίθεται επίσης και µία συγκριτική µελέτη µεταξύ των δύο αυτών εκδοχών, αλλά
και µε δύο άλλες µεθόδους ταξινόµησης ΠΕ. Τέλος, αξιολογούνται τρεις διαφορετικοί
αλγόριθµοι ως ταξινοµητές ϐάσης για τους LP ταξινοµητές του RAkELo.
Αξιολόγηση του RAkEL
Η µελέτη της απόδοσης πρόβλεψης του RAkELd και RAkELo γίνεται για διάφορες
τιµές του µεγέθους των labelsets. Επιπλέον, αξιολογείται η απόδοση του RAkELo
σε σχέση µε τον αριθµό των µοντέλων, m. Αντί για απόλυτες τιµές της µετρικής
(micro-F1), παρουσιάζεται το ποσοστό της ϐελτίωσης σε σχέση µε τη µέθοδο LP. Το
χαρακτηριστικό αυτό ϐελτιώνει την αναγνωσιµότητα και ερµηνεία των γραφηµάτων.
Ο αλγόριθµος C4.5 χρησιµοποιήθηκε ως αλγόριθµος ϐάσης στον LP αλλά και
στους LP ταξινοµητές του RAkEL. Η υλοποίηση που χρησιµοποιείται είναι αυτή του
Weka (Witten and Frank, 2005b) ενώ για τον LP και το RAkEL χρησιµοποιείται η
ϐιβλιοθήκη ταξινόµησης ΠΕ Mulan (Tsoumakas and Vlahavas, 2007).
Αξιολόγηση του RAkELd. Η εικόνα 5.14 παρουσιάζει το ποσοστό ϐελτίωσης του
RAkELd σε σχέση µε τον LP στη µετρική micro-F1 σε σχέση µε τον αριθµό των labelset
(k) σε όλα τα σύνολα δεδοµένων. Οι τιµές του k αντιστοιχούν σε διαφορετικά κλάσµατα
του συνολικού αριθµού των labels (από k = ⌈M/10⌉ έως k = ⌈9M/10⌉), έτσι ώστε η
επιρροή του k να µελετηθεί σε µεγάλο εύρος τιµών και ταυτόχρονα να γίνει εφικτή η
σύγκριση αποτελεσµάτων µεταξύ διαφορετικών συνόλων δεδοµένων. ΄Οταν k = M, ο
RAkELd γίνεται ισοδύναµος µε τον LP.
Μία πρώτη παρατήρηση είναι ότι ο RAkELd παρουσιάζει σηµαντική ϐελτίωση σε
σχέση µε τον LP για όλα τα σύνολα δεδοµένων µε εξαίρεση το σύνολο scene όπου
οδηγείται σε χειρότερα αποτελέσµατα για τιµές του k ∈ {4, 5}. Παρόλα αυτά, αυτό
ήταν ένα αναµενόµενο αποτέλεσµα αφού ο αριθµός των ετικετών σε αυτό το σύνολο
είναι µικρός (6).
Αναφορικά µε την επιρροή του k στην ποιότητα πρόβλεψης του RAkELd, ϑα µπο-
ϱούσαµε να ισχυριστούµε ότι γενικά µικρές τιµές του k οδηγούν σε καλύτερα αποτε-
λέσµατα. Αυτό επιβεβαιώνει την υπόθεση που έγινε νωρίτερα ότι ο διαχωρισµός του
116
5.3. Η ΜΕΘΟ∆ΟΣ RAKEL
-3
0
3
6
9
12
15
18
21
24
27
30
M/10 2M/10 3M/10 4M/10 5M/10 6M/10 7M/10 8M/10 9M/10k
%
 im
p
ro
ve
m
en
t o
ve
r 
L
P
yeast tmc bibtex
rcv1 enron medical
mediamill scene
Σχήµα 5.14: Ποσοστό ϐελτίωσης επί του LP στη µετρική micro F1 για τον RAkELd σε
σχέση µε το k.
αρχικού προβλήµατος πολλαπλών ετικετών σε µικρότερα, ϑα ϐελτιώσει την απόδοση
του LP. Από την άλλη, µεγαλύτερες τιµές του k επιτρέπουν τους LP ταξινοµητές του
RAkELd να λάβουν υπόψη τους περισσότερους συνδυασµούς (και πιθανότατα συσχε-
τίσεις) ετικετών. Αυτό είναι ενδεχοµένως µία εξήγηση για το γεγονός ότι η απόδοση
του RAkELd δε ϐελτιώνεται συνεχώς σε σχέση µε το k. Πάντως, οι τιµές του k που
ϐρίσκονται κοντά στο M παρουσιάζουν χειρότερη απόδοση και πλησιάζουν αυτήν του
LP.
Αναφορικά µε την απόδοση του RAkELd σε σχέση µε τον αριθµό των ετικετών
(M ), διαπιστώνουµε ότι η µεγαλύτερη ϐελτίωση επιτυγχάνεται σε σύνολα δεδοµένων µε
µεγάλο αριθµό ετικετών όπως είναι το reuters (101 ετικέτες), bibtex (159 ετικέτες) και
enron (53 ετικέτες), όπου η απόδοση του LP δεν είναι καλή (micro F1: 0.098, 0.290,
0.395 αντίστοιχα). Εξαίρεση σε αυτόν τον κανόνα αποτελεί το σύνολο mediamill (101
ετικέτες), όπου η ϐελτίωση είναι παρόµοια µε αυτήν των συνόλων µε µικρό M. Η
συµπεριφορά αυτή µπορεί να εξηγηθεί παρατηρώντας την υψηλή απόδοση του LP σε
αυτό το σύνολο (micro F1: 0.454). Επίσης όµως, πρέπει να σηµειωθεί, ότι ακόµη
και η µικρότερη τιµή του k σε αυτό το γράφηµα (⌈M/10⌉) είναι αρκετά µεγάλη για το
mediamill (ίση µε 10). Αν επιλέξουµε µικρότερες τιµές για το k ϑα παρατηρήσουµε
117
ΚΕΦΑΛΑΙΟ 5. ΤΑΞΙΝΟΜΗΣΗ ΚΕΙΜΕΝΩΝ ΠΟΛΛΑΠΛΩΝ ΕΤΙΚΕΤΩΝ
µεγαλύτερη ϐελτίωση σε σχέση µε τον LP. Για παράδειγµα η επιλογή k = 2 οδηγεί σε
ϐελτίωση 11.23% και αν k = 3 τότε η ϐελτίωση είναι ίση µε 8.81%.
Συµπερασµατικά, ϑα µπορούσαµε να ισχυριστούµε ότι µικρές τιµές του k αναµέ-
νεται να οδηγήσουν σε σηµαντικά καλύτερα αποτελέσµατα σε σχέση µε τον LP, ειδικά
σε σύνολα µε µεγάλο αριθµό ετικετών.
Αξιολόγηση του RAkELo. Το σχήµα 5.15 παρουσιάζει τη ϐελτίωση του RAkELo σε
σχέση µε τον LP στη µετρική micro F1 σε συνάρτηση µε το µέγεθος των labelsets (k) σε
όλα τα σύνολα δεδοµένων. Βασισµένοι στα συµπεράσµατα της προηγούµενης ενότητας
χρησιµοποιήσαµε µικρές τιµές για το k (από 2 έως 10). Ο αριθµός των µοντέλων (m)
είναι σταθερός και ίσος µε 2M, έτσι ώστε κάθε ετικέτα να εµφανίζεται στις εξόδους των
µοντέλων του RAkELo περίπου 2k ϕορές ανεξάρτητα από τον αριθµό των ετικετών σε
κάθε σύνολο.
0
5
10
15
20
25
30
35
40
45
2 3 4 5 6 7 8 9 10k
%
 i
m
p
ro
ve
m
en
t 
o
ve
r 
L
P
yeast tmc bibtex
rcv1 enron medical
mediamill scene
Σχήµα 5.15: Ποσοστό ϐελτίωσης στη µετρική micro F1 επί του LP για την µέθοδο
RAkELo (m = 2M ) σε συνάρτηση µε το k.
Αρχικά παρατηρούµε ότι ο RAkELo υπερισχύει του LP για όλες τις τιµές του k και
σε όλα τα σύνολα δεδοµένων. ΄Οσο το k αυξάνεται η ακρίβεια πρόβλεψης του RAkELo
παρουσιάζει τάση αύξησης για τα περισσότερα από τα σύνολα, σε αντίθεση µε το τι
έχουµε δει στο RAkELd στην προηγούµενη ενότητα. Η αιτία είναι ότι µεγαλύτερες
118
5.3. Η ΜΕΘΟ∆ΟΣ RAKEL
τιµές του k σε αυτή την περίπτωση οδηγούν σε περισσότερες ψήφους για κάθε ετικέτα
(αφού ο αριθµός των µοντέλων είναι σταθερός, ίσος µε 2M ). Οι περισσότερες ψήφοι
οδηγούν µε τη σειρά τους σε ακριβέστερες εκτιµήσεις των ετικετών. Τέλος, όπως και
στο RAkELd, η ϐελτίωση της ποιότητας πρόβλεψης ϕαίνεται να είναι σηµαντικότερη
για σύνολα δεδοµένων µε µεγάλο αριθµό ετικετών.
Το σχήµα 5.16 παρουσιάζει τη ϐελτίωση στη micro F1 για το RAkELo σε σχέση
µε τον LP σε συνάρτηση µε το m σε όλα τα σύνολα δεδοµένων. Το k διατηρείται
σταθερά ίσο µε 3. Για να ϐελτιώσουµε την αναγνωσιµότητα του γραφήµατος, ορίσαµε
τις τιµές του m έτσι ώστε να αντιστοιχούν σε διαφορετικά κλάσµατα του συνολικού
αριθµού ετικετών (από m = ⌈M/5⌉ έως m = 2M ). Αυτό που παρατηρούµε είναι ότι
όσο ο αριθµός των ταξινοµητών µεγαλώνει, τόσο αυξάνεται η απόδοση της οµάδας.
΄Οπως και πριν, αυτό οφείλεται στο γεγονός ότι µεγαλύτερες τιµές του m οδηγούν σε
περισσότερες ψήφους για κάθε ετικέτα. Μία ιδιαίτερα σηµαντική παρατήρηση που
ισχύει για όλα τα σύνολα δεδοµένων είναι ότι µετά από ένα συγκεκριµένο αριθµό
µοντέλων, η απόδοση του RAkELo δε ϕαίνεται να παρουσιάζει σηµαντική ϐελτίωση.
Τις περισσότερες ϕορές το M αποτελεί µία καλή προσέγγιση αυτού του αριθµού.
-60
-50
-40
-30
-20
-10
0
10
20
30
40
M/5 2M/5 3M/5 4M/5 5M/5 6M/5 7M/5 8M/5 9M/5 10M/5m
%
 i
m
p
ro
ve
m
en
t 
o
ve
r 
L
P
yeast tmc
bibtex medical
mediamill enron
reuters scene
Σχήµα 5.16: Ποσοστό ϐελτίωσης στη µετρική micro F1 επί του LP για το RAkEL (k = 3)
LP σε συνάρτηση µε το m.
Συµπερασµατικά, η αύξηση είτε του m είτε του k οδηγεί σε ϐελτίωση της απόδοσης
119
ΚΕΦΑΛΑΙΟ 5. ΤΑΞΙΝΟΜΗΣΗ ΚΕΙΜΕΝΩΝ ΠΟΛΛΑΠΛΩΝ ΕΤΙΚΕΤΩΝ
του RAkELo. Η κύρια αιτία είναι οτι αριθµός των ψήφων που έχει δεχθεί η κάθε
ετικέτα είναι ανάλογος µε το km. Αφού όµως η πολυπλοκότητα του RAkEL είναι
εκθετική σε σχέση µε το k αλλά γραµµική σε σχέση µε το m, είναι πιο αποδοτικό
να αυξηθεί η τιµή του m αντί η τιµή του k. Ως γενική οδηγία, προτείνεται η χρήση
µικρής τιµής για το k (π.χ. k = 3), και µία τιµή για το m που είναι ανάµεσα στο M
και το 2M.
Σύγκριση ξένων και επικαλυπτόµενων labelsets. Ο πίνακας 5.3 παρουσιάζει τη
µετρική F1 του LP και τις αντίστοιχες ποσοστιαίες ϐελτιώσεις του RAkELd (k = 3) και
RAkELo (k = 3, m = 2M ) για όλα τα σύνολα δεδοµένων. Παρατηρούµε ότι ο RAkELo
παρουσιάζει µεγαλύτερη ϐελτίωση σε σχέση µε τον LP. Το γεγονός αυτό συµφωνεί µε
την υπόθεση ότι η διαδικασία ψηφοφορίας της οµάδας ταξινοµητών ϑα ϐοηθήσει στη
ϐελτίωση της απόδοσης. Μία εξαίρεση σε αυτόν τον κανόνα ϕαίνεται να είναι το σύνολο
medical, όπου ο RAkELo παρουσιάζει ελάχιστα µικρότερη ϐελτίωση. Πρέπει να ληφθεί
υπόψη όµως ότι σε αυτό το σύνολο δεδοµένων παρόλο το µεγάλο αριθµό ετικετών (45)
υπάρχει πολύ µικρός αριθµός διακριτών labelsets (92). Το χαρακτηριστικό αυτό εξηγεί
την καλή απόδοση του LP αλλά και τη µικρή ϐελτίωση των RAkELd και RAkELo.
Πίνακας 5.3: Micro F1 µετρική για τον LP και % ϐελτίωση του RAkELd και RAkELo.
Σύνολο LP RAkELd RAkELo
scene 0.587 00.34 01.55
yeast 0.526 02.47 15.21
tmc2007 0.788 05.46 10.15
medical 0.745 02.01 01.61
enron 0.395 29.62 37.97
mediamill 0.454 08.81 21.37
reuters 0.098 23.47 29.59
bibtex 0.290 35.86 37.59
Σύγκριση µε άλλες µεθόδους
Σε αυτήν την ενότητα συγκρίνεται ο αλγόριθµος RAkEL µε δύο ταξινοµητές πολλαπλών
ετικετών υψηλής απόδοσης. Ο πρώτος, ο MLkNN (Zhang and Zhou, 2007), αποτελεί
µία έκδοση πολλαπλών ετικετών του αλγορίθµου k κοντινότερων γειτόνων (kΝΝ). Ο
αριθµός των γειτόνων τέθηκε ίσος µε 10 και ο παράγοντας εξοµάλυνσης (smoothing
factor) ίσος µε 1 όπως προτείνεται και στην εργασία (Zhang and Zhou, 2007). Ο
δεύτερος, ο BP-MLL (Zhang and Zhou, 2006), αποτελεί µία έκδοση ΠΕ του αλγορίθ-
µου back propagation για την εκπαίδευση των multi-layer perceptrons. Ο ϱυθµός
µάθησης (learning rate) τέθηκε ίσος µε 0.05, ο αριθµός των εποχών (epochs) ίσος
120
5.3. Η ΜΕΘΟ∆ΟΣ RAKEL
µε 100 και ο αριθµός των κρυµµένων µονάδων (hidden units) στο 20% των εισόδων
(input units) όπως προτείνεται και στην (Zhang and Zhou, 2006). Και οι δύο αυτοί
αλγόριθµοι έχει αποδειχθεί ότι παρουσιάζουν καλύτερη απόδοση από άλλες µεθόδους
ταξινόµησης ΠΕ σε διάφορα σύνολα δεδοµένων. Και στις δύο περιπτώσεις χρησιµο-
ποιήθηκαν οι υλοποιήσεις του Mulan (Tsoumakas and Vlahavas, 2007) µε στόχο την
ενοποιηµένη διαδικασία αξιολόγησης. ΄Οπως και προηγουµένως, οι ταξινοµητές LP
του RAkEL εκπαιδεύτηκαν χρησιµοποιώντας τον αλγόριθµο δένδρων απόφασης C4.5.
Ο πίνακας 5.4 παρουσιάζει τη µετρική micro F1 των RAkELd, RAkELo, MLkNN
και BPMLL σε όλα τα σύνολα δεδοµένων. Για το RAkELd έχουµε ϑέσει k ίσο µε 3 και
για το RAkELo έχουµε ϑέσει k ίσο µε 3 και m ίσο µε 2M σε όλα τα σύνολα δεδοµένων.
Είναι σηµαντικό να αναφερθεί ότι αυτές οι ϱυθµίσεις είναι γενικές και ϐασίζονται στα
συµπεράσµατα της προηγούµενης ενότητας και σίγουρα δεν είναι οι ευνοϊκότερες για
τις παραλλαγές του RAkEL
Πίνακας 5.4: Σύγκριση µε άλλες µεθόδους ταξινόµησης ΠΕ στη µετρική micro F1.
Σύνολο RAkELd RAkELo MLkNN BPMLL
scene 0.589 0.678 0.723 0.520
yeast 0.539 0.606 0.615 0.645
tmc2007 0.831 0.868 0.699 0.715
medical 0.760 0.757 0.650 0.673
enron 0.512 0.545 0.498 0.525
mediamill 0.494 0.551 0.544 0.501
reuters 0.121 0.127 0.107 0.055
bibtex 0.394 0.399 0.262 0.460
Παρατηρούµε ότι ο RAkELo υπερτερεί έναντι του MLkNN και του BPMLL σε 6
από τα 8 σύνολα δεδοµένων. Ο RAkELd από την άλλη υπερτερεί του MLkNN σε 5
σύνολα και του BPMLL σε 4 σύνολα. Ο RAkELo επιτυγχάνει την υψηλότερη απόδοση
σε 4 σύνολα δεδοµένων και τη δεύτερη καλύτερη απόδοση σε 3 σύνολα δεδοµένων.
Μόνο στο σύνολο yeast παρουσιάζει την τρίτη καλύτερη απόδοση. Ο BPMLL είναι
ο δεύτερος συνολικά αποδοτικότερος αλγόριθµος - ϐάσει του αριθµού των συνόλων
που παρουσιάζει τη µεγαλύτερη απόδοση (2 σύνολα) - και ακολουθεί ο MLkNN και ο
RAkELd οι οποίοι παρουσιάζουν την καλύτερη απόδοση µόνο σε ένα σύνολο.
Η επίδραση του ϐασικού ταξινοµητή
Σε αυτή την ενότητα ερευνάται η επίδραση του ταξινοµητή απλής ετικέτας που χρησι-
µοποιείται για την ανάπτυξη των LP ταξινοµητών του RAkELo στην ποιότητα πρόβλεψής
του. Συγκρίνουµε την απόδοση του RAkELo χρησιµοποιώντας τρεις διαφορετικούς αλ-
γόριθµους ϐάσης : α) τον C4.5 που χρησιµοποιήθηκε µέχρι στιγµής στα πειράµατα,
ϐ) τον naive bayes (NB) και γ) τις µηχανές διανυσµάτων υποστήριξης (Support Vector
121
ΚΕΦΑΛΑΙΟ 5. ΤΑΞΙΝΟΜΗΣΗ ΚΕΙΜΕΝΩΝ ΠΟΛΛΑΠΛΩΝ ΕΤΙΚΕΤΩΝ
Machines - SVM). Χρησιµοποιήσαµε τις υλοποιήσεις αυτών των µεθόδων όπως διατί-
ϑενται στο Weka (Witten and Frank, 2005b) (η Weka έκδοση των LibSVMs (Chang
and Lin, 2001) χρησιµοποιήθηκε για τα SVMs). Το SVM έχει γραµµικό πυρήνα (li-
near kernel) για τα κειµενικά δεδοµένα και RBF (Radial Basis Function) πυρήνα για
τα υπόλοιπα δεδοµένα. Οι υπόλοιπες παράµετροι έµειναν όπως είναι ορισµένες στο
Weka . Σε όλες τις περιπτώσεις, για τον RAkELo χρησιµοποιήθηκε k = 3 και m = 2M.
Ο πίνακας 5.5 παρουσιάζει τα αποτελέσµατα αυτών των πειραµάτων.
Πίνακας 5.5: Micro F1 του RAkELo χρησιµοποιώντας τρεις διαφορετικούς ταξινοµητές
µονής ετικέτας
Σύνολο NB C4.5 SVM
scene 0.643 0.678 0.580
yeast 0.570 0.606 0.555
tmc2007 0.620 0.868 0.729
medical 0.662 0.757 0.796
enron 0.336 0.545 0.530
mediamill 0.179 0.551 0.476
reuters 0.095 0.127 0.125
bibtex 0.229 0.399 0.421
Παρατηρούµε ότι ο C4.5 ξεπερνάει τον naive Bayes σε όλα τα σύνολα δεδοµένων
και τον SVM στα 6 από τα 8 σύνολα δεδοµένων. Η υπεροχή του C4.5 σε σχέση
µε τον SVM µπορεί να οφείλεται στο γεγονός ότι δεν έγινε εξαντλητική ϱύθµιση των
παραµέτρων του SVM. Από την άλλη, τα δένδρα αποτελούν καταλληλότερη επιλογή
για οµάδες ταξινοµητών όπως είναι ο RAkEL.
5.4 Συµπεράσµατα
Σε αυτό το κεφάλαιο παρουσιάστηκαν δύο µέθοδοι για το πρόβληµα της ταξινόµησης
ΠΕ µε ιδιαίτερη έµφαση σε προβλήµατα µε µεγάλο αριθµό ετικετών.
Η πρώτη µέθοδος, HOMER, αντιµετωπίζει το πρόβληµα οργανώνοντας τις ετικέτες
σε µία ιεραρχία µε κύριο πλεονέκτηµα τους µικρούς χρόνους ταξινόµησης. Σηµαντική
ϐελτίωση όµως παρατηρήθηκε και στην ποιότητα πρόβλεψης. Για την οργάνωση των
ετικετών στην ιεραρχία προτάθηκε ένας νέος αλγόριθµος ισορροπηµένης οµαδοποίη-
σης. Βασικό πεδίο εφαρµογής αποτέλεσε το πρόβληµα της αυτόµατης πρότασης λέξεων
επισήµανσης (tags) το οποίο µοντελοποιήθηκε ως πρόβληµα ταξινόµησης πολλαπλών
ετικετών. ΄Ετσι, προέκυψε και ένα νέο σύνολο ΠΕ (del.icio.us).
Στη δεύτερη µέθοδο, RAkEL, διασπάται τυχαία το αρχικό σύνολο ετικετών σε υπο-
σύνολα. Σε κάθε ένα από αυτά εφαρµόζεται ένας ξεχωριστός LP ταξινοµητής. Βασικό
κίνητρο ήταν η ϐελτίωση της ποιότητας πρόβλεψης της µεθόδου LP η οποία, σε σύνολα
122
5.4. ΣΥΜΠΕΡΑΣΜΑΤΑ
µε µεγάλο αριθµό ετικετών, αντιµετωπίζει σηµαντικές δυσκολίες. Μελετήθηκαν ξένα
και επικαλυπτόµενα υποσύνολα και προέκυψε ότι και τα δύο ϐελτιώνουν την απόδοση
του LP, ειδικά σε προβλήµατα µε µεγάλο αριθµό ετικετών. Προέκυψε επίσης ότι τα
επικαλυπτόµενα υποσύνολα παρουσιάζουν καλύτερα αποτελέσµατα σε σχέση µε τα
ξένα, εξαιτίας του συγκερασµού των ταξινοµητών. Τέλος, παρουσιάζονται συγκριτικά
αποτελέσµατα µε δύο µεθόδους ταξινόµησης ΠΕ υψηλής ποιότητας πρόβλεψης, τα
οποία είναι ιδιαίτερα ενθαρρυντικά.
123
6
Εφαρµογές Ταξινόµησης Κειµένων στον
Παγκόσµιο Ιστό
Σε αυτό το κεφάλαιο παρουσιάζονται δύο εφαρµογές αυτόµατης ταξινόµησης κειµένων
στο σύγχρονο παγκόσµιο ιστό. Η πρώτη αφορά στη δηµιουργία ενός υποσυστήµατος
παραγωγής συστάσεων για το σύστηµα διαµοιρασµού σελιδοδεικτών παγκόσµιου ιστού
και ϐιβλιογραφικών αναφορών BibSonomy. Η δεύτερη, αφορά στην αυτόµατη ταξι-
νόµηση σηµασιολογικών υπηρεσιών ιστού. Η προτεινόµενη µέθοδος λαµβάνει υπόψη
το κείµενο περιγραφής της υπηρεσίας και τις σηµασιολογικές επισηµειώσεις της υπη-
ϱεσίας. Παρουσιάζονται αποτελέσµατα εφαρµογής ταξινοµητών µηχανικής µάθησης
ξεχωριστά σε αυτά τα δύο στοιχεία ενώ προτείνονται µέθοδοι συνδυασµού τους.
6.1 Εισαγωγή
Η σηµαντική επίδραση του παγκόσµιου ιστού (Word Wide Web) στην καθηµερινότητά
µας είναι αδιαµφισβήτητη. Εκτός από την ταχεία διάδοση πληροφορίας και την εύκολη
επικοινωνία, ο παγκόσµιος ιστός αποτελεί ταυτόχρονα σηµαντικό εργαλείο εργασίας
αλλά και µέσο ψυχαγωγίας. Ιδιαίτερο ενδιαφέρον όµως παρουσιάζει η ϱαγδαία εξέλιξη
του τα τελευταία χρόνια.
Αρχικά, ο παγκόσµιος ιστός ϕαίνεται στατικός και η διάδοση της πληροφορίας µο-
νόδροµη. Υπάρχουν ϕορείς που δηµοσιεύουν περιεχόµενο και το µεγαλύτερο µέρος
των χρηστών αποτελεί τους αποδέκτες του. Σε αυτό το στάδιο, ο παγκόσµιος ιστός
λειτουργεί ουσιαστικά ως µέσο ενηµέρωσης. Η περίοδος αυτή, που χρονολογικά αντι-
στοιχεί στη δεκαετία 1990-2000, συνήθως αναφέρεται ως Web 1.0.
Στη συνέχεια, ο ιστός γίνεται περισσότερο διαδραστικός. Βασικό του στοιχείο εί-
ναι η αµφίδροµη επικοινωνία, ο διαµοιρασµός πληροφορίας και περιεχοµένου και τα
κοινωνικά δίκτυα. Ο χρήστης µε την εισαγωγή των blogs µπορεί εύκολα να δηµοσιεύ-
ει προσωπικό περιεχόµενο. ∆όθηκε η δυνατότητα διαµοιρασµού περιεχοµένου όπως
video (YouTube1), εικόνες (Flickr2), κείµενα (Scribd3), ϐιβλιογραφικές αναφορές (Bib-
1YouToube - Broadcast Yourself - http://www.youtube.com/
2Flickr - PhotoSharing - http://www.flickr.com/
3Scribd - http://www.scribd.com/
125
ΚΕΦΑΛΑΙΟ 6. ΕΦΑΡΜΟΓΕΣ ΤΑΞΙΝΟΜΗΣΗΣ ΚΕΙΜΕΝΩΝ ΣΤΟΝ ΠΑΓΚΟΣΜΙΟ ΙΣΤΟ
Sonomy4) και άλλα. Επίσης, έγιναν διαθέσιµα εργαλεία για τη συνεργατική ανάπτυξη
περιεχοµένου (Wikipedia5) αλλά και κοινωνική δικτύωση (Facebook6) των χρηστών.
Αυτό το στάδιο (2000-2010) αναφέρεται και ως Web 2.0 ή ‘read/write web’7. Βασικό
στοιχείο οργάνωσης περιεχοµένου στο Web 2.0 είναι ο ελεύθερος χαρακτηρισµός των
αντικειµένων από τους χρήστες µε λέξεις επισήµανσης (tags). Η διαδικασία αυτή έχει
γίνει γνωστή µε τον όρο tagging. Σε αυτό το κεφάλαιο παρουσιάζεται ένα σύστηµα το
οποίο υπο-ϐοηθάει το χρήστη στην ανάθεση των λέξεων επισήµανσης (Katakis et al.,
2008).
Το µέλλον του παγκόσµιου ιστού αναφέρεται ως Web 3.0 (2010-2020) ϐασικό στοι-
χείο του οποίου ϑα είναι ο σηµασιολογικός (semantic) ορισµός της πληροφορίας και
των υπηρεσιών, έτσι ώστε να είναι κατανοητές από τις µηχανές και να εξυπητετούνται
τα αιτήµατα του χρήστη χωρίς τη δική του συµµετοχή. Το όραµα αυτό αναφέρε-
ται ως Σηµασιολογικός Ιστός (Semantic Web), ϐασικό στοιχείο του οποίου αποτελούν
οι σηµασιολογικές υπηρεσίες ιστού (Semantic Web Services). Σε αυτό το κεφάλαιο
προτείνεται µία µέθοδος αυτόµατης ταξινόµησης σηµασιολογικών υπηρεσιών µέσω τα-
ξινόµησης κειµένου (Katakis et al., 2009a). Η αυτόµατη ταξινόµηση των υπηρεσιών
µπορεί να διευκολύνει άλλες κρίσιµες διαδικασίες που σχετίζονται µε αυτές, όπως είναι
η ανακάλυψη (discovery), η σύνθεση (composition) και η διαχείριση (management)
υπηρεσιών.
6.2 Σύστηµα Συστάσεων Επισηµάνσεων
Ο όρος tagging αναφέρεται στην ελεύθερη ανάθεση λέξεων επισήµανσης (tags) σε (συ-
νήθως διαδικτυακό) περιεχόµενο (π.χ κείµενα, εικόνες, ϐίντεο, κτλ). Αποτελεί µία
ιδιαίτερα απλή προσέγγιση για την οργάνωση περιεχοµένου που ουσιαστικά χρησιµο-
ποιείται εδώ και δεκαετίες. Οι επιστηµονικές δηµοσιεύσεις για παράδειγµα, συνήθως
συνοδεύονται από µία λίστα λέξεων-κλειδιών (keywords) που εισάγονται είτε ελεύθερα
είτε ϐάσει κάποιας συγκεκριµένης κατηγοριοποίησης (π.χ. η κατηγοριοποίηση της
επιστήµης υπολογιστών της ACM8) από τους ίδιους τους συγγραφείς.
Η αυξηµένη δηµοτικότητα της µεθόδου της επισήµανσης τα τελευταία χρόνια ο-
ϕείλεται κυρίως στην ενσωµάτωσή της σε πολλές εφαρµογές Web 2.0 όπως είναι τα
διαδικτυακά συστήµατα διαµοιρασµού περιεχοµένου (π.χ. YouTube και Flickr). Στις
περισσότερες από αυτές τις εφαρµογές η επισήµανση χαρακτηρίζεται από µία επιπλέον
κοινωνική διάσταση, καθώς µεγάλος αριθµός χρηστών µπορεί ελεύθερα να καταχωρή-
σει λέξεις επισήµανσης στο ίδιο αντικείµενο (συνεργατική επισήµανση - collaborative
tagging).
4Bibsonomy - http://www.bibsonomy.org/
5Wikipedia - http://www.wikipedia.org
6Facebook - http://www.facebook.com
7Berners-Lee on the read/write web - http://news.bbc.co.uk/2/hi/technology/4132752.stm
8ACM Computing Classification - http://www.acm.org/about/class/1998
126
6.2. ΣΥΣΤΗΜΑ ΣΥΣΤΑΣΕΩΝ ΕΠΙΣΗΜΑΝΣΕΩΝ
Η ελευθερία και η απλότητα χρήσης της επισήµανσης δηµιουργεί κάποια προ-
ϐλήµατα όσον αφορά στην οργάνωση της πληροφορίας (Marchetti et al., 2007). Κατ΄
αρχήν, οι χρήστες επιλέγουν λέξεις επισήµανσης ϐάσει των προσωπικών τους πεποιθή-
σεων και της ειδικότητάς τους. Επιπλέον, διαφορετικοί χρήστες µπορεί να επιθυµούν
να περιγράψουν ένα αντικείµενο σε διαφορετικά επίπεδα λεπτοµέρειας. ΄Αλλο ένα
πρόβληµα είναι η χρήση πολύσηµων ή συνώνυµων λέξεων. Τέλος, έχει παρατηρηθεί
η τάση οι χρήστες να αναθέτουν ένα µικρό µόνο αριθµό λέξεων επισήµανσης για έ-
να αντικείµενο. ΄Ολα αυτά τα χαρακτηριστικά µπορεί να οδηγήσουν σε προβληµατική
ανάκτηση πληροφορίας στα συστήµατα που χρησιµοποιούν την ελεύθερη επισήµανση.
Τα παραπάνω προβλήµατα έχουν οδηγήσει στην αναζήτηση µεθόδων που ϐοηθούν
τους χρήστες στην διαδικασία της επισήµανσης, προτείνοντάς τους τους ένα κατάλληλο
σύνολο από λέξεις. Οι πρώτες ερευνητικές εργασίες σε αυτό το πεδίο χρησιµοποιούν
µεθόδους συνεργατικής διήθησης (Jaschke et al., 2007), εξόρυξης γράφων (Jaschke
et al., 2007) και κειµένων (Chirita et al., 2007; Sood et al., 2007). Σε αυτήν την
ενότητα το πρόβληµα της σύστασης ενός συνόλου λέξεων επισήµανσης µοντελοποιεί-
ται ως πρόβληµα ταξινόµησης πολλαπλών ετικετών. Το σύστηµα που παρουσιάζεται
δηµιουργήθηκε µε αφορµή τη συµµετοχή στο διαγωνισµό Discovery Challlenge του
συνεδρίου ECML/PKDD 20089.
6.2.1 Περιγραφή ∆ιαγωνισµού Discovery Challenge
Ο διαγωνισµός αποτελούνταν από δύο δραστηριότητες (tasks): α) Αναγνώριση spam
σε κοινωνικά συστήµατα σελιδοδεικτών (Spam Detection in Social Bookmarking Sy-
stems) και ϐ) Σύσταση επισηµάνσεων σε κοινωνικά συστήµατα σελιδοδεικτών (Tag
Recommendation in Social Bookmarking Systems). Η συµµετοχή µας αφορά στη
δεύτερη δραστηριότητα.
Το σύστηµα BibSonomy10 είναι ένα διαδικτυακό σύστηµα διαχείρισης σελιδοδει-
κτών (bookmarks) και ϐιβλιογραφικών αναφορών (bibtex). Ο χρήστης µπορεί να α-
ποθηκεύσει, να οργανώσει και να κοινοποιήσει τους σελιδοδείκτες ή τις αναφορές της
ηλεκτρονικής συλλογής του. Το κύριο εργαλείο για την οργάνωση περιεχοµένου στο
BibSonomy είναι η ελεύθερη επισήµανση. Οι χρήστες µπορούν να επισηµάνουν σε-
λιδοδείκτες και αναφορές όταν τους/τις καταχωρούν στο σύστηµα. Οι επισηµάνσεις
αντικειµένων που έχουν ήδη καταχωρηθεί στο σύστηµα µπορούν να εµπλουτιστούν µε
νέες λέξεις από άλλους χρήστες.
Ζητούµενο είναι η ανάπτυξη ενός συστήµατος συστάσεων για επισηµάνσεις (tag
recommendation system) για το BibSonomy. Το σύστηµα συστάσεων ϑα πρέπει να
προτείνει ένα σχετικό σύνολο επισηµάνσεων στο χρήστη όταν αυτός καταχωρεί ένα νέο
αντικείµενο (σελιδοδείκτη ή αναφορά) στο BibSonomy. Οι διοργανωτές του διαγωνι-
σµού έθεσαν σε διαθεσιµότητα αρχεία τα οποία περιλαµβάνουν παραδείγµατα επιση-
µάνσεων σε σελιδοδείκτες και αναφορές. Η αξιολόγηση των υποψήφιων συστηµάτων
9ECML/PKDD 2008 Discovery Challenge - http://www.kde.cs.uni-kassel.de/ws/rsdc08/
10Bibsonomy - http://www.bibsonomy.org
127
ΚΕΦΑΛΑΙΟ 6. ΕΦΑΡΜΟΓΕΣ ΤΑΞΙΝΟΜΗΣΗΣ ΚΕΙΜΕΝΩΝ ΣΤΟΝ ΠΑΓΚΟΣΜΙΟ ΙΣΤΟ
Πίνακας 6.1: Τα πεδία των τριών αρχείων
Αρχείο Πεδία
tas user, tag, content id, content type, date
bookmark content id, url hash, url, description, extended description, date
bibtex content id, journal volume, chapter, edition, month, day, booktitle,
howPublished, institution, organization, publisher, address, scho-
ol, series, bibtexKey, url, type, description, annote, note, pages,
bKey, number, crossref, misc, bibtexAbstract, simhash0, simha-
sh1, simhash2, entrytype, title, author, editor year
πραγµατοποιήθηκε σε ξεχωριστά αρχεία µη διαθέσιµα αρχικά στους συµµετέχοντες.
Κριτήριο αξιολόγησης αποτελεί η µετρική F . ΄Εστω D είναι ένα σύνολο αξιολόγη-
σης, που αποτελείται από |D| παραδείγµατα της µορφής (~xi , Yi ), i = 1..|D|, Yi ⊆ L, όπου
L το σύνολο των λέξεων επισήµανσης. Αν h το σύστηµα συστάσεων και Zi = h(~xi) το
σύνολο επισηµάνσεων που συστήνεται από τον h για το αντικείµενο ~xi , τότε η ακρίβεια,
η ανάκληση και η µετρική F του h στο σύνολο D υπολογίζονται ως εξής :
Ακρίβεια(h, D) =
1
|D|
|D|∑
i=1
|Yi ∩ Zi |
|Zi |
Ανάκληση(h,D) =
1
|D|
|D|∑
i=1
|Yi ∩ Zi |
|Yi |



6.1
F (h, D) =
2 ∗ Ακρίβεια ∗ Ανάκληση
Ακρίβεια + Ανάκληση
=
1
|D|
|D|∑
i=1
2|Yi ∩ Zi |
|Zi | + |Yi |



6.2
6.2.2 Προεπεξεργασία και Ανάλυση ∆εδοµένων
Τα αρχεία καταγραφής των δεδοµένων του συστήµατος είναι τα tas, bookmark και
bibtex. Παρακάτω αναφέρονται λεπτοµέρειες για το καθένα.
− Αρχείο tas: περιέχει τις επισηµάνσεις των χρηστών στους σελιδοδείκτες και στις
αναφορές.
− Αρχείο bookmark: περιέχει τα µεταδεδοµένα των σελιδοδεικτών. Τέτοια είναι η
διεύθυνση της σελίδας (URL), η περιγραφή κειµένου της σελίδας, κτλ.
− Αρχείο bibtex: περιέχει µεταδεδοµένα για τις ϐιβλιογραφικές αναφορές όπως
είναι ο τίτλος της εργασίας, οι συγγραφείς, η περίληψη, κτλ.
Στον Πίνακα 6.1 ϕαίνονται αναλυτικά όλα τα πεδία των τριών αρχείων.
128
6.2. ΣΥΣΤΗΜΑ ΣΥΣΤΑΣΕΩΝ ΕΠΙΣΗΜΑΝΣΕΩΝ
Να σηµειωθεί ότι στα αρχεία bookmark και bibtex το ίδιο αντικείµενο (σελιδο-
δείκτης ή αναφορά) µπορεί να υπάρξει πολλές ϕορές, µία για κάθε χρήστη που τα
καταχώρησε. Επίσης, διαφορετικοί χρήστες µπορεί να προσθέσουν επιπλέον µεταδε-
δοµένα και ϕυσικά διαφορετικές επισηµάνσεις σε ένα αντικείµενο. Μία ϐιβλιογραφική
αναφορά αναγνωρίζεται µοναδικά από το πεδίο simhash1 και ένα αντικείµενο σελιδο-
δείκτη από το πεδίο url_hash. Το πεδίο content_id αποτελεί το συνδετικό κρίκο των
τριών αρχείων και προσδιορίζει µοναδικά ένα Ϲεύγος <χρήστη, αντικείµενο>.
Στοχεύοντας στην αξιολόγηση της προτεινόµενης µεθόδου αλλά και στην ανάλυση
των δεδοµένων, τα διαθέσιµα αρχεία χωρίστηκαν σε αρχεία εκπαίδευσης και αρχεία
αξιολόγησης. Επιλέχθηκε το 80% του αρχείου tas για εκπαίδευση και το υπόλοιπο
για αξιολόγηση. Τα αντίστοιχα αρχεία bookmark και bibtex δηµιουργήθηκαν ϐάσει
του αρχείου tas χρησιµοποιώντας τους κωδικούς content_id.
Η πρώτη επεξεργασία των δεδοµένων οδήγησε στην εξαγωγή των παρακάτω στοι-
χείων :
− Στο αρχείο tas υπάρχουν 816,197 εγγραφές, που αντιστοιχούν σε ανάθεση µίας
λέξης επισήµανσης από ένα συγκεκριµένο χρήστη σε ένα συγκεκριµένο αντικεί-
µενο
− Υπάρχουν 268,692 αναρτήσεις (posts) στο αρχείο tas (δηλαδή αναθέσεις ενός
συνόλου λέξεων επισήµανσης σε ένα συγκεκριµένο αντικείµενο από έναν συγκε-
κριµένο χρήστη).
− Υπάρχουν 176,141 αναρτήσεις σελιδοδεικτών
− Υπάρχουν 156,054 διαφορετικοί σελιδοδείκτες στο αρχείο bookmark οι οποίοι
διακρίνονται από το πεδίο url_hash
− Υπάρχουν 92,551 αναρτήσεις ϐιβλιογραφικών αναφορών
− Υπάρχουν 71,704 διαφορετικές αναφορές στο αρχείο bibtex που διακρίνονται
από την ιδιότητα simhash1
− Μόνο 18,192 από τις παραπάνω αναφορές περιέχουν περίληψη (abstract)
Μετά το διαχωρισµό των δεδοµένων σε σύνολο εκπαίδευσης και σύνολο αξιολόγη-
σης υπολογίστηκαν τα παρακάτω ενδιαφέροντα στατιστικά :
− Μόνο το 8.55% των σελιδοδεικτών του συνόλου αξιολόγησης υπάρχουν στο σύ-
νολο εκπαίδευσης
− Μόνο το 9.77% των αναφορών του συνόλου αξιολόγησης υπάρχουν στο σύνολο
εκπαίδευσης
− Το 65.69% των χρηστών που διατηρούν συλλογή σελιδοδεικτών του συνόλου
αξιολόγησης, υπάρχουν στο σύνολο εκπαίδευσης
129
ΚΕΦΑΛΑΙΟ 6. ΕΦΑΡΜΟΓΕΣ ΤΑΞΙΝΟΜΗΣΗΣ ΚΕΙΜΕΝΩΝ ΣΤΟΝ ΠΑΓΚΟΣΜΙΟ ΙΣΤΟ
− Το 21.89% των χρηστών που διατηρούν συλλογή αναφορών του συνόλου αξιολό-
γησης, υπάρχουν στο σύνολο εκπαίδευσης
− Ο µέσος όρος των λέξεων επισήµανσης που ορίζει ένας χρήστης για ένα σελιδο-
δείκτη είναι 2.76
− Ο µέσος όρος των λέξεων επισήµανσης που ορίζει ένας χρήστης για µία αναφορά
είναι 3.25
6.2.3 Προτεινόµενο Σύστηµα Συστάσεων
Συστάσεις απαιτούνται για κάθε Ϲεύγος Si <χρήστης,αντικείµενο> στο αρχείο αξιολό-
γησης TestTasFile. Με άλλα λόγια, το Ϲητούµενο είναι να προβλεφθεί ποιες λέξεις
επισήµανσης ϑα τοποθετούσε ένας συγκεκριµένος χρήστης σε ένα συγκεκριµένο αν-
τικείµενο. Είναι εποµένως προφανές ότι οι συστάσεις πρέπει να είναι προσωποποι-
ηµένες. Μία σηµαντική παρατήρηση που προκύπτει από τα στατιστικά που έχουν
αναφερθεί στην προηγούµενη ενότητα είναι ότι τα αντικείµενα πιθανότατα να µην εµ-
ϕανίζονται στο σύνολο αξιολόγησης αλλά υπάρχει σηµαντική πιθανότητα οι χρήστες
να επανεµφανίζονται. ΄Ετσι, το προτεινόµενο σύστηµα συστάσεων ϑα πρέπει να µπορεί
να εκµεταλλευτεί τη γνώση των επισηµάνσεων του παρελθόντος αλλά ταυτόχρονα να
µπορεί να παράγει προτάσεις για νέους χρήστες και πρωτοεµφανιζόµενα αντικείµε-
να. Με το προτεινόµενο σύστηµα γίνεται µία προσπάθεια να ικανοποιηθούν αυτές οι
προϋποθέσεις.
Η αναλυτική λειτουργία του προτεινόµενου συστήµατος ϕαίνεται στο Σχήµα 6.1.
Αρχικά, γίνεται έλεγχος για το αν το υπό εξέταση αντικείµενο (σελιδοδείκτης ή αναφο-
ϱά) υπάρχει στο σύνολο εκπαίδευσης. Αν ναι, τότε προτείνονται οι N πιο δηµοφιλείς
λέξεις επισήµανσης για το συγκεκριµένο αντικείµενο. Αν το αντικείµενο εµφανίζεται
για πρώτη ϕορά, τότε το σύστηµα εξετάζει αν ο χρήστης έχει εµφανιστεί στο παρελθόν.
Αν ο χρήστης δεν είναι νέος, τότε προτείνονται οι πιο συχνά χρησιµοποιούµενες λέ-
ξεις επισήµανσης του συγκεκριµένου χρήστη. Αν το αντικείµενο αλλά και ο χρήστης
δεν εµφανίζονται στο σύνολο εκπαίδευσης, τότε καλείται ένας ταξινοµητής κειµένου
πολλαπλών ετικετών να προβλέψει ένα σύνολο σχετικών λέξεων επισήµανσης.
Ο ταξινοµητής δέχεται τρεις παραµέτρους εισόδου (ϐλέπε Σχήµα 6.2). Η πρώτη και
κυριότερη είσοδος είναι το κείµενο του αντικειµένου. Ως κείµενο των σελιδοδεικτών
επιλέχθηκε το περιεχόµενο των πεδίων description και extendend description αλλά
και το κείµενο της αντίστοιχης ιστοσελίδας. Για τις αναφορές επιλέχθηκε το κείµενο
των πεδίων journal, booktitle, bibtexAbstract και title. Να σηµειωθεί ότι και στις δύο
περιπτώσεις το κείµενο κάποιων πεδίων µπορεί να λείπει. Η δεύτερη παράµετρος είναι
ο µέγιστος αριθµός συστάσεων (M ) που παράγει ο ταξινοµητής. Η τρίτη παράµετρος
(θ) ορίζει την πιθανότητα (εµπιστοσύνη) που πρέπει να έχει µία ετικέτα για να εισαχθεί
στο σύνολο προβλέψεων του ταξινοµητή.
Χρησιµοποιήθηκε ο ταξινοµητής πολλαπλών ετικετών Binary Relevance (BR) της
130
6.2. ΣΥΣΤΗΜΑ ΣΥΣΤΑΣΕΩΝ ΕΠΙΣΗΜΑΝΣΕΩΝ
∆εδοµένα: Αρχεία εκπαίδευσης TasTrainFile, BookTrainFile και
BibTrainFile.
Είσοδος: Η εγγραφή Si (<χρήστης,αντικείµενο>) από το TasTestFile
΄Εξοδος: Η σύσταση P = {t1, t2, . . . , tn} του συστήµατος, ti ∈ T , όπου T το
σύνολο όλων των λέξεων επισήµανσης
Αρχικοποίησε N1,N2, θ1,θ2,M1,M2;1
για όλα τα Si στο TestTasFile κάνε2
αν το Si .αντικείµενο είναι Σελιδοδείκτης τότε3
αν το Si .αντικείµενο εµφανίζεται στο BookmarkTrainFile τότε4
P ← N1 πιο δηµοφιλείς λέξεις επισήµανσης του Si .αντικείµενο;5
αν P = ∅ τότε6
P ← bookClassifier(Si.αντικείµενο.κείµενο(),θ1,M1);7
αλλιώς8
αν ο Si .χρήστης εµφανίζεται στο TasTrainFile τότε9
P ← N1 πιο συχνές λέξεις επισήµανσης του Si .χρήστης;10
αν P = ∅ τότε11
P ← bookClassifier(Si.αντικείµενο.κείµενο(),θ1,M1);12
αλλιώς13
P ← bookClassifier(Si.αντικείµενο.κείµενο(),θ1,M1);14
αν P = ∅ τότε15
P ← N1 πιο δηµοφιλείς λέξεις επισήµανσης στο16
BookmarkTrainFile;
αν το Si .αντικείµενο είναι Αναφορά τότε17
αν το Si .αντικείµενο εµφανίζεται στο BibtexTrainFile τότε18
P ← N2 πιο δηµοφιλείς λέξεις επισήµανσης του Si .αντικείµενο;19
αν P = ∅ τότε20
P ← bibClassifier(Si.αντικείµενο.κείµενο(),θ2,M2);21
αλλιώς22
αν ο Si .χρήστης εµφανίζεται στο TasTrainFile τότε23
P ← N2 πιο συχνές λέξεις επισήµανσης του Si .χρήστης;24
αν P = ∅ τότε25
P ← bibClassifier(Si.αντικείµενο.κείµενο(),θ2,M2);26
αλλιώς27
P ← bibClassifier(Si.αντικείµενο.κείµενο(),θ2,M2);28
αν P = ∅ τότε29
P ← N2 πιο δηµοφιλείς λέξεις επισήµανσης στο30
BibtexTrainFile;
Σχήµα 6.1: Ψευδοκώδικας του προτεινόµενου συστήµατος συστάσεων
131
ΚΕΦΑΛΑΙΟ 6. ΕΦΑΡΜΟΓΕΣ ΤΑΞΙΝΟΜΗΣΗΣ ΚΕΙΜΕΝΩΝ ΣΤΟΝ ΠΑΓΚΟΣΜΙΟ ΙΣΤΟ
Είσοδος: Si : αντικείµενα προς ταξινόµηση, Μ: µέγιστος αριθµός συστάσεων ,
θ: κατώφλι εµπιστοσύνης
΄Εξοδος: Η σύσταση P = {t1, t2, . . . , tn} του συστήµατος, ti ∈ T , όπου T είναι το
σύνολο όλων των διαθέσιµων λέξεων επισήµανσης
P ← ∅;1
C ← Ταξινοµητής.τιµέςΕµπιστοσύνης(T , Si .αντικείµενο.κείµενο());2
R ← κατάταξη των C σε ϕθίνουσα σειρά;3
για (i = 0; i < M ; i + +) κάνε4
αν Ri > θ τότε5
P = P
⋃
Ri ;6
επέστρεψε P7
Σχήµα 6.2: Ταξινόµηση Πολλαπλών Ετικετών στο προτεινόµενο σύστηµα συστά-
σεων
ϐιβλιοθήκης Mulan11. Επιλέχθηκε ο BR γιατί είναι από τους απλούστερους ταξινοµη-
τές πολλαπλών ετικετών ενώ η κλιµάκωσή του είναι γραµµική σε σχέση µε τον αριθµό
των τάξεων. Εκπαιδεύονται δύο τέτοιοι ταξινοµητές. ΄Ενας από το κείµενο των σελι-
δοδεικτών (bookClassifier) και ένας από το κείµενο των αναφορών (bibClassifier). Ως
αλγόριθµος ϐάσης του BR επιλέχθηκε ο ταξινοµητής naive Bayes.
Για την εκπαίδευση των ταξινοµητών απαραίτητη ήταν η µετατροπή των δεδοµένων
στη µορφή που διαχειρίζεται η ϐιβλιοθήκη Mulan που ϐασίζεται σε αυτή της ϐιβλιο-
ϑήκης Weka (.arff) (Witten and Frank, 2005a). Για τη µείωση των διαστάσεων του
προβλήµατος, διατηρήθηκαν µόνο οι λέξεις κειµένου που παρουσίασαν µια ελάχιστη
συχνότητα εµφάνισης fw(min) και οι λέξεις επισήµανσης που παρουσίασαν µία ελάχιστη
συχνότητα εµφάνισης ft(min).
΄Ετσι, για τη δηµιουργία των συνόλων δεδοµένων ϑέσαµε f 1
w(min) = 3000 και
f 1
t(min) = 300 για τα δεδοµένα σελιδοδεικτών ενώ ϑέσαµε f
2
w(min) = 100 και f
2
t(min) = 50
για τα δεδοµένα αναφορών. Οι ϱυθµίσεις αυτές οδήγησαν σε 208 λέξεις επισήµανσης
και 2150 λέξεις κειµένου για το αρχείο των σελιδοδεικτών ενώ για το αρχείο των ανα-
ϕορών σε 159 λέξεις επισήµανσης και 1836 λέξεις κειµένου. Και τα δύο σύνολα είναι
ελεύθερα διαθέσιµα στη διεύθυνση http://mlkd.csd.auth.gr/multilabel.html.
6.2.4 Αξιολόγηση
Χρησιµοποιήθηκε η µετρική F όπως αναφέρεται στην Ενότητα 6.2.1 µε στόχο την
αξιολόγηση του συστήµατος και τη ϱύθµιση των παραµέτρων. Εξετάστηκαν κάποιες
εναλλακτικές ϱυθµίσεις παραµέτρων χωρίς να εκπονηθεί κάποια εξαντλητική µελέτη.
Κάποια αποτελέσµατα ϕαίνονται στον Πίνακα 6.2.
11Mulan - Multi Label Classification, (http://mlkd.csd.auth.gr/multilabel.html)
132
6.3. ΤΑΞΙΝΟΜΗΣΗ ΣΗΜΑΣΙΟΛΟΓΙΚΩΝ ΥΠΗΡΕΣΙΩΝ ΙΣΤΟΥ
Πίνακας 6.2: Η µετρική F για διάφορες ϱυθµίσεις παραµέτρων
Παράµετροι Μετρική F
θ Μ Ν ΄Ολα Σελιδοδείκτες Αναφορές
0.0 10 10 0.0716 0.0782 0.0633
0.0 5 5 0.0848 0.0940 0.0736
0.0 1 1 0.0700 0.0904 0.0453
0.9 10 10 0.0713 0.0752 0.066
0.9 3 3 0.0847 0.0940 0.0734
0.9 10 3 0.0852 0.0942 0.0740
Παρατηρούµε ότι τα καλύτερα αποτελέσµατα επιτυγχάνονται όταν θ = 0.9,M = 10,
και N = 312. Ας σηµειωθεί ότι αυτές είναι ϱυθµίσεις που παράγουν τρεις προτάσεις
που είναι κοντά στο µέσο όρο των ετικετών που ϑέτουν οι χρήστες όπως παρατηρήθηκε
στην Ενότητα 6.2.2. Υπήρξε µία µικρή ϐελτίωση σε αυτά τα αποτελέσµατα όταν χρησι-
µοποιήθηκε ο ταξινοµητής στη περίπτωση που το σύνολο των πιο δηµοφιλών/συχνών
λέξεων επισήµανσης είναι κενό (ϐλέπε Σχήµα 6.1). Μία επιπλέον µικρή ϐελτίωση
παρατηρήθηκε όταν χρησιµοποιήθηκαν οι πιο δηµοφιλείς λέξεις επισήµανσης όλων
των αντικειµένων όταν ακόµη και το σύνολο προβλέψεων του ταξινοµητή είναι κενό.
Οι τελικές τιµές της µετρικής F ήταν αντίστοιχα 0.0856, 0.0942, 0.0751 αντίστοιχα.
Τελικά, το προτεινόµενο σύστηµα κατέλαβε την 3η ϑέση µεταξύ 5 διαγωνιζόµενων.
6.3 Ταξινόµηση Σηµασιολογικών Υπηρεσιών Ιστού
Οι σηµασιολογικές υπηρεσίες ιστού στοχεύουν στη δηµιουργία υπηρεσιών που ϑα είναι
άµεσα επεξεργάσιµες και κατανοητές από τους υπολογιστές έτσι ώστε να αυτοµατοποι-
ηθούν πολλές διεργασίες που σχετίζονται µε αυτές. Στην ενότητα αυτή παρουσιάζονται
µέθοδοι αυτόµατης ταξινόµησης σηµασιολογικών υπηρεσιών ιστού σύµφωνα µε το πε-
δίο εφαρµογής τους. Οι προτεινόµενες µέθοδοι εφαρµόζονται στις περιγραφές OWL-S
των υπηρεσιών. Η κύρια συνεισφορά της ενότητας συνοψίζεται στα παρακάτω σηµεία :
1. Μελετάται η αποτελεσµατικότητα τεσσάρων µοντέλων αναπαράστασης για την
ταξινόµηση υπηρεσιών που ϐασίζονται στο κείµενο και στις υπογραφές των πε-
ϱιγραφών OWL-S.
2. Προτείνονται και αξιολογούνται τρεις διαφορετικές προσεγγίσεις για το συνδυα-
σµό των χαρακτηριστικών κειµένου και υπογραφών. Ο συνδυασµός αυτός κρίνε-
ται απαραίτητος αφού το κείµενο είναι δύσκολο να αποτυπώσει τη σηµασιολογία
της υπηρεσίας ενώ οι υπογραφές δεν εκφράζουν πάντα το πεδίο εφαρµογής.
12Για την απλοποίηση της επιλογής των παραµέτρων ϑέσαµε θ=θ1=θ2, M=M1=M2 και N=N1=N2
133
ΚΕΦΑΛΑΙΟ 6. ΕΦΑΡΜΟΓΕΣ ΤΑΞΙΝΟΜΗΣΗΣ ΚΕΙΜΕΝΩΝ ΣΤΟΝ ΠΑΓΚΟΣΜΙΟ ΙΣΤΟ
3. Για την αξιολόγηση των προτεινόµενων µεθόδων, δηµιουργούνται έξι διαφορετι-
κές εκδόσεις του συνόλου δεδοµένων οι οποίες διατίθενται ελεύθερα µέσω του
διαδικτύου.
6.3.1 Σηµασιολογικές Υπηρεσίες Ιστού
Μια υπηρεσία ιστού είναι µια αυτόνοµη εφαρµογή ιστού, ανεξάρτητη πλατφόρµας, η
οποία µπορεί να περιγραφεί, δηµοσιευθεί, ανακτηθεί και διαµορφωθεί µε τη χρήση
προτύπων XML. Υπάρχει επίσης η δυνατότητα σύνθεσης µίας νέας υπηρεσίας από
άλλες για την ολοκλήρωση µίας πολύπλοκης διεργασίας.
Οι υπηρεσίες ιστού περιγράφονται µε µια τυποποιηµένη γλώσσα περιγραφής. Η
Γλώσσα Περιγραφής Υπηρεσιών Ιστού (Web Service Description Language - WSDL)13
περιγράφει τις λειτουργικές (functional) και τις µη λειτουργικές (non-functional) ι-
διότητες των υπηρεσιών. Οι λειτουργικές ιδιότητες εκφράζουν στοιχεία της υπηρεσίας
όπως ο τρόπος µε τον οποίο µπορεί να κληθεί, η τοποθεσία στην οποία ϐρίσκεται, κτλ.
Οι µη λειτουργικές ιδιότητες επικεντρώνονται σε ποιοτικά χαρακτηριστικά, όπως για
παράδειγµα το κόστος χρήσης, ο χρόνος απόκρισης, η αξιοπιστία, η διαθεσιµότητα,
κτλ.
Οι σηµασιολογικές υπηρεσίες στοχεύουν µέσω της σηµασιολογικής επισηµείωσης
των περιγραφών στην αυτοµατοποίηση διαδικασιών όπως η ανακάλυψη, η σύνθεση
αλλά και οποιαδήποτε διεργασία σχετίζεται µε αυτές. Οι περισσότερες προσεγγίσεις
για τη σηµασιολογική περιγραφή των υπηρεσιών ιστού ϐασίζονται στην επέκταση των
υπαρχουσών τεχνολογιών των υπηρεσιών (WSDL, SOAP14 και UDDI15) µε σηµασιολο-
γικές επισηµειώσεις.
Μέχρι σήµερα, δεν έχει επικρατήσει κάποια προτυποποίηση για τη σηµασιολογική
επισηµείωση των υπηρεσιών ιστού. Τα επικρατέστερα πρότυπα περιγραφής υπηρεσιών
είναι τα : OWL-S (Martin et al., 2004), WSMO (Roman et al., 2004), SWSF (Battle
et al., 2005), SAWSDL (Kopecký et al., 2007) και WSDL-S (Rajasekaran et al., 2004).
Σε αυτήν την ενότητα, για την αυτόµατη ταξινόµηση των σηµασιολογικών υπηρεσιών
χρησιµοποιούνται οι περιγραφές OWL-S των υπηρεσιών. Παρόλα αυτά η µεθοδολογία
µπορεί να χρησιµοποιηθεί και σε άλλες γλώσσες περιγραφής.
Περιγραφές OWL-S Σηµασιολογικών Υπηρεσιών
Η OWL-S αποτελεί µια οντολογία περιγραφής υπηρεσιών. ΄Εχει τις ϱίζες της στην
DAML-S (DAML Service Ontology) η οποία ανακοινώθηκε το 2001 και αποτέλεσε την
πρώτη επίσηµη προσπάθεια για τη σηµασιολογική επισηµείωση υπηρεσιών.
Βασικό στοιχείο για την περιγραφή των υπηρεσιών µε την OWL-S αποτελεί η υπο-
οντολογία Service Profile, οποία αποτελεί ουσιαστικά τη σηµασιολογική περιγραφή
13www.w3.org/TR/wsdl
14Simple Object Access Protocol - http://www.w3.org/TR/soap12-part1/
15Universal Description, Discovery and Integration - http://www.oasis-open.org/committees/uddi-
spec
134
6.3. ΤΑΞΙΝΟΜΗΣΗ ΣΗΜΑΣΙΟΛΟΓΙΚΩΝ ΥΠΗΡΕΣΙΩΝ ΙΣΤΟΥ
<?xml version="1.0" encoding="WINDOWS-1252"?>
<owl:Ontology rdf:about="">
<owl:imports rdf:resource="http://127.0.0.1/ontology/books.owl" />
...
</owl:Ontology>
<taxonomy:Education rdf:ID="TITLE BOOK PROFILE">
<profile:serviceName xml:lang="en"> BookFinderService
</profile:serviceName>
<profile:textDescription xml:lang="en">
This service returns the information of a book whose title best
matches the given string
</profile:textDescription>
<profile:hasInput rdf:resource="# TITLE"/>
<profile:hasOutput rdf:resource="# BOOK"/>
</taxonomy:Education>
<process:Input rdf:ID=" TITLE">
<process:parameterType rdf:datatype="http://www.w3.org/2001/XMLSchema#anyURI">
http://127.0.0.1/ontology/books.owl#Title
</process:parameterType>
</process:Input>
<process:Output rdf:ID=" BOOK">
<process:parameterType rdf:datatype="http://www.w3.org/2001/XMLSchema#anyURI">
http://127.0.0.1/ontology/books.owl#Book
</process:parameterType>
</process:Output>
Σχήµα 6.3: Παράδειγµα περιγραφής OWL-S
της λειτουργικότητας της υπηρεσίας. Συγκεκριµένα, περιγράφονται οι είσοδοι (in-
puts) και έξοδοι (outputs), οι προϋποθέσεις (preconditions) και οι επιδράσεις (effects)
της υπηρεσίας. Οι είσοδοι και οι έξοδοι επισηµειώνονται µε έννοιες οντολογίας, ορί-
Ϲοντας έτσι τον τύπο των αντικειµένων που πρέπει να σταλούν στην υπηρεσία και των
αναµενόµενων αποκρίσεων. Για τις προϋποθέσεις και τις επιδράσεις µπορούν να χρη-
σιµοποιηθούν διάφοροι τύποι κανόνων όπως για παράδειγµα ο SWRL, DRS ή KIF. ΄Ενα
παράδειγµα περιγραφής OWL-S (στιγµιότυπο της Service Profile) ϕαίνεται στο Σχήµα
6.3. Η υπηρεσία δέχεται ως είσοδο τον τίτλο ενός ϐιβλίου και επιστρέφει πληροφορίες
σχετικά µε αυτό. Στο παράδειγµα, µε έντονη γραφή σηµειώνονται το όνοµα της υπηρε-
σίας, η είσοδος, η έξοδος, η περιγραφή κειµένου της υπηρεσίας καθώς και ο ορισµός
της οντολογίας (owl:imports) σύµφωνα µε την οποία επισηµειώνονται η είσοδος και η
έξοδος.
6.3.2 Η ανάγκη για αυτόµατη ταξινόµηση υπηρεσιών ιστού
Ο µεγάλος και συνεχώς αυξανόµενος αριθµός των διαθέσιµων υπηρεσιών έθεσε την
ανάγκη για µεθόδους που ϑα αυτοµατοποιήσουν τη διαδικασία ταξινόµησής τους σε
135
ΚΕΦΑΛΑΙΟ 6. ΕΦΑΡΜΟΓΕΣ ΤΑΞΙΝΟΜΗΣΗΣ ΚΕΙΜΕΝΩΝ ΣΤΟΝ ΠΑΓΚΟΣΜΙΟ ΙΣΤΟ
πεδία εφαρµογής. Η αυτόµατη ταξινόµηση µπορεί να ϕανεί ιδιαίτερα ωφέλιµη σε ένα
σηµαντικό αριθµό διεργασιών που σχετίζονται µε τις υπηρεσίες ιστού:
− Ανακάλυψη Υπηρεσιών. Η αποτελεσµατικότητα και αποδοτικότητα των µεθόδων
ανακάλυψης υπηρεσιών ιστού (web service discovery) µπορεί να ϐελτιωθεί αν
από την αναζήτηση εξαιρεθούν οι υπηρεσίες που δεν ανήκουν στο Ϲητούµενο
πεδίο εφαρµογής.
− Σύνθεση Υπηρεσιών. Οµοίως, κατά την αυτόµατη σύνθεση υπηρεσιών (web servi-
ce composition) η αναζήτηση των κατάλληλων υπηρεσιών µπορεί να περιοριστεί
µόνο σε αυτές του σχετικού πεδίου εφαρµογής.
− ∆ιαχείριση Υπηρεσιών. Η διαχείριση ενός µεγάλου αριθµού υπηρεσιών ενός µη-
τρώου περιγραφών ιστού UDDI είναι αποτελεσµατικότερη όταν οι υπηρεσίες είναι
οργανωµένες σε τάξεις. Επιπλέον, χρησιµοποιώντας την αυτόµατη ταξινόµηση
µπορούν να προτείνονται κατηγορίες στο χρήστη τη στιγµή της καταχώρησης
(registration) µίας υπηρεσίας στο UDDI.
6.3.3 Σχετικές Εργασίες
Τα τελευταία χρόνια παρουσιάζεται µία σηµαντική προσπάθεια για την ανάπτυξη αυ-
τόµατων ή ηµι-αυτόµατων µεθόδων για την ταξινόµηση υπηρεσιών. Στην εργασία
(Bruno et al., 2005), χρησιµοποιείται κείµενο από περιγραφές WSDL και Μηχανές
∆ιανυσµάτων Υποστήριξης (Support Vector Machines - SVM) (Vapnik, 1995). Πολλές
προσεγγίσεις (Hess and Kushmerick, 2003; Oldham et al., 2005; Saha et al., 2008;
Hess et al., 2004) χρησιµοποιούν κείµενο από δοµηµένα στοιχεία της WSDL (π.χ.
λειτουργίες - operations) ως είσοδο σε διάφορους αλγορίθµους ταξινόµησης όπως ο
naive Bayes (Hess and Kushmerick, 2003; Oldham et al., 2005), τα SVMs (Hess and
Kushmerick, 2003) και τα δένδρα απόφασης (Saha et al., 2008) . ΄Εχουν χρησιµοποι-
ηθεί ακόµη και µέθοδοι οµάδων ταξινοµητών (ensemble methods)(Hess et al., 2004;
Saha et al., 2008). Το κύριο µειονέκτηµα όλων αυτών των προσεγγίσεων είναι ότι
δε λαµβάνουν υπόψη τους σηµασιολογική πληροφορία, η οποία όπως ϑα αποδειχθεί
παρακάτω µπορεί να έχει ιδιαίτερα ϑετική επίδραση στην ορθότητα ταξινόµησης.
Στην εργασία (Corella and Castells, 2006), η ταξινόµηση υπηρεσιών ϐασίζεται σε
περιγραφές OWL-S και επιτυγχάνεται υπολογίζοντας την οµοιότητα των υπηρεσιών.
Για τον υπολογισµό της οµοιότητας λαµβάνονται υπόψη οι έννοιες µε τις οποίες ε-
πισηµειώνονται οι είσοδοι και οι έξοδοι των υπηρεσιών. Συγκεκριµένα, υπολογίζεται
η οµοιότητα της προς ταξινόµηση υπηρεσίας µε όλες τις υπηρεσίες κάθε κατηγορίας
ξεχωριστά. Η κατηγορία για την οποία προκύπτει η µεγαλύτερη συνολική οµοιότητα
αποτελεί και την έξοδο της µεθόδου. Το κύριο µειονέκτηµα αυτής της προσέγγισης
είναι ότι η αναπαράσταση δεν είναι αρκετά ευέλικτη έτσι ώστε να χρησιµοποιηθούν δια-
ϕορετικά µοντέλα µάθησης. ΄Ενα ακόµη µειονέκτηµα είναι το γεγονός ότι αγνοείται το
κείµενο περιγραφής της υπηρεσίας.
136
6.3. ΤΑΞΙΝΟΜΗΣΗ ΣΗΜΑΣΙΟΛΟΓΙΚΩΝ ΥΠΗΡΕΣΙΩΝ ΙΣΤΟΥ
Σε αυτό το κεφάλαιο παρουσιάζονται αποτελέσµατα που αποδεικνύουν την ωφελι-
µότητα ακόµη και µικρών σε έκταση κειµένων των περιγραφών OWL-S.΄Ενα πρόβληµα
σχετικό µε την ταξινόµηση είναι η ανάκτηση παρόµοιων υπηρεσιών (matchmaking).
Σε αυτήν την περίπτωση, δεδοµένης µίας υπηρεσίας ερωτήµατος (query web service
description) αναζητούµε παρόµοιες υπηρεσίες (Kiefer and Bernstein, 2008; Klusch
et al., 2008).
6.3.4 ∆ιανυσµατική Αναπαράσταση Περιγραφών OWL-S
Στην ενότητα αυτή περιγράφονται µέθοδοι αναπαράστασης OWL-S περιγραφών ως δια-
νύσµατα χαρακτηριστικών. Τα διανύσµατα αυτά µαζί µε τις πραγµατικές τάξεις (πεδία
εφαρµογών) των υπηρεσιών - αν είναι αυτές διαθέσιµες - µπορούν να αποτελέσουν ένα
σύνολο παραδειγµάτων για τους αλγόριθµους µηχανικής µάθησης. Για την κατασκευ-
ή των διανυσµάτων χρησιµοποιούνται στοιχεία από : α) το κείµενο περιγραφής, ϐ) τις
εισαγωγές οντολογιών, γ) τη συντακτική υπογραφή και δ) τη σηµασιολογική υπογραφή
της υπηρεσίας. Είναι σηµαντικό να σηµειωθεί ότι αν και χρησιµοποιείται η OWL-S ως
γλώσσα αναφοράς, οι παρακάτω µέθοδοι αναπαράστασης µπορούν να εφαρµοστούν
και σε άλλους τύπους περιγραφών σηµασιολογικών υπηρεσιών όπως η SAWSDL.
Μία πλήρης περιγραφή υπηρεσίας απαιτεί ιδιαίτερες γνώσεις και κόπο για τον
ορισµό της και για το λόγο αυτό σπάνια συναντάται στην πράξη. ΄Ετσι, η προτεινόµενη
µέθοδος, στοχεύει στην ελάχιστη ποσότητα πληροφορίας που συνήθως συναντάται στην
περιγραφή µίας σηµασιολογικής υπηρεσίας ιστού: Στην περιγραφή κειµένου (text
description) και στις επισηµειώσεις των εισόδων/εξόδων της υπηρεσίας που συνήθως
αναφέρονται ως υπογραφές (signatures).
Κείµενο Περιγραφής
Το κείµενο που περιγράφει µία υπηρεσία αντλείται από την ιδιότητα textDescription
των περιγραφών OWL-S. Η αναπαράσταση της υπηρεσίας σε αυτήν την προσέγγιση
γίνεται µε το διάνυσµα:
~Ti =
(
t(i,1), t(i,2), . . . , t(i,|VT |)
) 


6.3
΄Οπου |VT | είναι το µέγεθος του λεξικού VT . Ως λεξικό ϑεωρούµε το σύνολο όλων των
διακριτών λέξεων που υπάρχουν στα κείµενα περιγραφής όλων των υπηρεσιών. Κάθε
όρος t(i,j) εκφράζει το ϐάρος (σηµαντικότητα) της λέξης j του λεξικού για την υπηρεσία
i. ΄Ενας ιδιαίτερα απλός τρόπος για τον καθορισµό των ϐαρών είναι να ϑέτουµε t(i,j) = 1
αν η λέξη j εµφανίζεται στην υπηρεσία i. Αν δεν εµφανίζεται τότε ϑέτουµε t(i,j) = 0. Το
κίνητρο πίσω από αυτήν την αναπαράσταση είναι ότι στο κείµενο ϑα υπάρχουν λέξεις
οι οποίες ϑα διαχωρίζουν τη µία κατηγορία από την άλλη.
137
ΚΕΦΑΛΑΙΟ 6. ΕΦΑΡΜΟΓΕΣ ΤΑΞΙΝΟΜΗΣΗΣ ΚΕΙΜΕΝΩΝ ΣΤΟΝ ΠΑΓΚΟΣΜΙΟ ΙΣΤΟ
Εισαγωγές Οντολογιών
Μία περιγραφή OWL-S περιέχει δηλώσεις εισαγωγής οντολογιών που ορίζουν ουσια-
στικά τις οντολογίες ϐάσει των οποίων επισηµειώνονται οι υπογραφές. Υπάρχει πι-
ϑανότητα οι δηλώσεις αυτές να είναι ωφέλιµες για την ταξινόµηση αφού υπηρεσίες
που χρησιµοποιούν ίδιες οντολογίες µπορεί να ανήκουν στην ίδια κατηγορία. Για την
επαλήθευση αυτής της υπόθεσης προτείνεται µία νέα αναπαράσταση (OntImp) που
στηρίζεται σε αυτό ακριβώς το χαρακτηριστικό.
΄Εστω VO το λεξικό των οντολογιών, δηλαδή το σύνολο όλων των διακριτών οντολο-
γιών που εισάγονται στις περιγραφές όλων των υπηρεσιών. Η διανυσµατική αναπαρά-
σταση σε αυτήν τη περίπτωση είναι της µορφής :
~Oi =
(
o(i,1), o(i,2), . . . , o(i,|VO |)
) 


6.4
όπου o(i,j) = 1, αν η j οντολογία εισάγεται (έµµεσα ή άµεσα) στην περιγραφή της i
υπηρεσίας ή o(i,j) = 0, στην αντίθετη περίπτωση.
Συντακτική και Σηµασιολογική Υπογραφή
Η υπογραφή µίας υπηρεσίας εµπεριέχει σηµαντική πληροφορία που ϑα µπορούσε να
χρησιµοποιηθεί στη διαδικασία της αυτόµατης ταξινόµησης. Οι χρήστες επισηµειώ-
νουν τις εισόδους και εξόδους των υπηρεσιών µε έννοιες οντολογιών ορίζοντας έτσι το
πεδίο των παραµέτρων αυτών χρησιµοποιώντας σηµασιολογικές περιγραφές. Οι σχέ-
σεις οµοιότητας µεταξύ των εννοιών εισόδου και εξόδου των υπηρεσιών ιστού, όπως η
απόλυτη (exact), συνδετική (plugin) και υπαγωγική (subsume) µπορούν να υπολογι-
στούν χρησιµοποιώντας ένα σύστηµα συλλογιστικής οντολογιών (ontology reasoner).
Αν δύο υπηρεσίες έχουν όλες ή κάποιες από τις παραµέτρους παρόµοιες, τότε µπορεί
να ανήκουν και στην ίδια κατηγορία.
Με στόχο να µελετήσουµε την επιρροή των υπογραφών στην ταξινόµηση, προ-
τείνουµε δύο σχετικές προσεγγίσεις. Η µία ϐασίζεται στην συντακτική υπογραφή
(Syntactic Signature - SynSig) όπου οι έννοιες αντιµετωπίζονται ως απλό κείµενο, και
η άλλη ϐασίζεται στις σηµασιολογική υπογραφή (Semantic Signature - SemSig) για
τις οποίες χρησιµοποιείται ένα σύστηµα OWL συλλογιστικής για περιγραφική λογική.
Πρέπει να σηµειωθεί ότι δε γίνεται διάκριση των εννοιών ανάλογα µε το αν ϐρίσκονται
στις εισόδους ή εξόδους µίας υπηρεσίας.
Συντακτική Υπογραφή (SynSig). ΄Εστω ότι VC είναι το λεξικό των εννοιών, δηλαδή
το σύνολο όλων των διακριτών εννοιών που χρησιµοποιούνται για την επισηµείωση των
εισόδων και εξόδων των υπηρεσιών. Η διανυσµατική αναπαράσταση µίας υπηρεσίας
σε αυτήν την προσέγγιση είναι της µορφής :
~Ni =
(
n(i,1), n(i,2), . . . , n(i,|VC |)
) 


6.5
138
6.3. ΤΑΞΙΝΟΜΗΣΗ ΣΗΜΑΣΙΟΛΟΓΙΚΩΝ ΥΠΗΡΕΣΙΩΝ ΙΣΤΟΥ
όπου n(i,j) = 1, αν η έννοια j χρησιµοποιείται στην περιγραφή της υπηρεσίας i,
αλλιώς n(i,j) = 0.
Σηµασιολογική Υπογραφή (SemSig). Το διάνυσµα αναπαράστασης σε αυτήν την
περίπτωση είναι της µορφής
~Si =
(
s(i,1), s(i,2), . . . , s(i,|VC |)
) 


6.6
Τα ϐάρη, όπως και προηγουµένως, είναι δυαδικά αλλά επιλέγονται µε τον τρόπο
που περιγράφεται στον Σχήµα 6.4. Πιο συγκεκριµένα, αν η έννοια j αναφέρεται άµεσα
στην περιγραφή της i υπηρεσίας (γραµµή 4) ή αν υπάρχει κάποια άλλη έννοια k στην
υπηρεσία η οποία είναι ισοδύναµη (equivalent - j ≡ k), υπερκλάση (superclass -
j ⊒ k) ή υποκλάση (subclass - j ⊑ k) µε την j (γραµµή 8) τότε s(i,j) = 1. Αλλιώς, αν δεν
υπάρχει τέτοια έννοια k ή αν οι έννοιες j και k είναι ξένες (γραµµή 6), τότε s(i,j) = 0.
΄Οπως προαναφέρθηκε, για τον υπολογισµό αυτών των σχέσεων χρησιµοποιείται ένα
σύστηµα συλλογιστικής.
Είσοδος: Το λεξικό οντολογιών VC, η περιγραφή της υπηρεσίας i και το
σύστηµα συλλογιστικής R
΄Εξοδος: ∆ιάνυσµα χαρακτηριστικών Si
Υπογραφή← i.΄Εννοιες_Εισόδων ∪ i.΄Εννοιες_Εξόδων;1
Si ← [0, .., 0];2
για όλα j ∈ Υπογραφή κάνε3
Si[VC.δείκτης(j)] ← 1;4
για όλα k ∈ VC κάνε5
αν R(j ⊓ k ⊑⊥) τότε6
συνέχισε;7
αν R(j ≡ k) ∨ R(j ⊑ k) ∨ R(k ⊑ j) τότε8
Si [VC.δείκτης(k)]← 19
επέστρεψε Si10
Σχήµα 6.4: ∆ηµιουργία διανύσµατος SemSig
6.3.5 Συνδυασµός Κειµένου και Σηµασιολογίας
Η ταξινόµηση που ϐασίζεται µόνο στη σηµασιολογία των υπογραφών (SemSig) δε ϑα
είναι πάντα αρκετή για τον καθορισµό της πραγµατικής τάξης. Για παράδειγµα, δύο
υπηρεσίες µε διαφορετικό πεδίο εφαρµογής µπορεί να έχουν ίδιες υπογραφές, (π.χ.
µία υπηρεσία ενοικίασης αυτοκινήτων και µία υπηρεσία ενοικίασης διαµερισµάτων).
139
ΚΕΦΑΛΑΙΟ 6. ΕΦΑΡΜΟΓΕΣ ΤΑΞΙΝΟΜΗΣΗΣ ΚΕΙΜΕΝΩΝ ΣΤΟΝ ΠΑΓΚΟΣΜΙΟ ΙΣΤΟ
Από την άλλη, η ταξινόµηση ϐάσει κειµένου δεν είναι επίσης αρκετή αφού δεν περιέ-
χεται η σηµασιολογία η οποία να µπορεί να αξιοποιηθεί µε µηχανές συλλογιστικής
(inference engines).
Φαίνεται λοιπόν να υπάρχει ανάγκη για το συνδυασµό της πληροφορίας που υ-
πάρχει στο κείµενο της περιγραφής και στην υπογραφή, ο οποίος ϑα οδηγήσει σε
πληρέστερες περιγραφές των υπηρεσιών. Σε αυτήν την ενότητα προτείνονται δύο µέ-
ϑοδοι συνδυασµού: α) µε χρήση εκτεταµένων διανυσµάτων χαρακτηριστικών και ϐ) µε
χρήση οµάδων ταξινοµητών.
Εκτεταµένο ∆ιάνυσµα Χαρακτηριστικών
Σε αυτήν την προσέγγιση ενώνεται το διάνυσµα κειµένου (Text) µε αυτό της συντα-
κτικής (SynSig) και σηµασιολογικής (SemSig) υπογραφής. ΄Ετσι υπάρχει περίπτωση
ο ταξινοµητής να µπορέσει να ανακαλύψει σχέσεις µεταξύ των χαρακτηριστικών του
κειµένου και των υπογραφών αλλά και τον τρόπο µε τον οποίο ο συνδυασµός τους
καθορίζει την εκδήλωση µίας τάξης.
Το διάνυσµα που αντιπροσωπεύει το συνδυασµό περιγραφής κειµένου (~T ) και συν-
τακτικής υπογραφής (~N ), TextSynSig ( ~TN ), ορίζεται ως :
( ~TN )i = (t(i,1), t(i,2), . . . , t(i,|VT |), n(i,1), n(i,2), . . . , n(i,|VC |))



6.7
Επίσης, το διάνυσµα που εκφράζει το συνδυασµό περιγραφής κειµένου και σηµα-
σιολογικής υπογραφής (~N ), TextSemSig ( ~TS), ορίζεται ως :
( ~TS)i =
(
t(i,1), t(i,2), . . . , t(i,|VT |), s(i,1), s(i,2), . . . , s(i,|VC |)
) 


6.8
Οµάδες Ταξινοµητών
Πολλοί ταξινοµητές µηχανικής µάθησης µπορούν να παράγουν ως έξοδο όχι µόνο την
προβλεπόµενη τάξη για ένα αντικείµενο αλλά επίσης και την πιθανότητα (εµπιστοσύνη
- confidence) µε την οποία ένα αντικείµενο µπορεί να ανήκει σε κάθε τάξη. ΄Εστω ο
ταξινοµητής που ϐασίζεται στο κείµενο περιγραφής HT (d, λ)→ [0,1], και HS(d, λ)→
[0,1] ο ταξινοµητής που ϐασίζεται στη σηµασιολογική υπογραφή16. Οι ταξινοµητές
έχουν ως έξοδο την πιθανότητα η υπηρεσία d να ανήκει σε µία τάξη λ. Αν L είναι το
σύνολο όλων των τάξεων τότε :
hT = arg max
λ∈L
HT (d, λ)



6.9
είναι η απόφαση του HT και
hS = arg max
λ∈L
HS(d, λ)



6.10
16∆εν αναπτύσσουµε ταξινοµητή από τη συντακτική υπογραφή αφού όπως ϑα δειχθεί παρακάτω υστερεί
σε απόδοση έναντι της σηµασιολογικής.
140
6.3. ΤΑΞΙΝΟΜΗΣΗ ΣΗΜΑΣΙΟΛΟΓΙΚΩΝ ΥΠΗΡΕΣΙΩΝ ΙΣΤΟΥ
η απόφαση του HS. Οι παραπάνω εξισώσεις απλά δηλώνουν ότι ο ταξινοµητής επιλέγει
να προβλέψει την τάξη µε τη µεγαλύτερη εµπιστοσύνη. Ορίζονται δύο διαφορετικοί
µέθοδοι συνδυασµού των δύο ταξινοµητών. ΄Εστω hE η απόφαση της οµάδας. Η πρώτη
µέθοδος, Emax , επιλέγει την απόφαση του ταξινοµητή που έχει µεγαλύτερη εκτίµηση
πιθανότητας για την τάξη που προβλέπει. ∆ηλαδή:
hE =
{
hT , αν HT (d, hT ) ≥ HS(d, hS)
hS, αλλιώς



6.11
Η δεύτερη µέθοδος, Eavg, υπολογίζει το µέσο όρο των πιθανοτήτων για τους δυο
ταξινοµητές για όλες τις τάξεις και τελικά επιλέγει την τάξη µε το µέγιστο µέσο όρο :
hE = arg max
λ∈L
(
HT (d, λ) + HS(d, λ)
2
)



6.12
6.3.6 Αξιολόγηση
Οι προτεινόµενες µέθοδοι αξιολογήθηκαν χρησιµοποιώντας πέντε διαφορετικούς ταξι-
νοµητές και ένα σύνολο ταξινοµηµένων περιγραφών υπηρεσιών ιστού.
Λεπτοµέρειες Πειραµάτων
Χρησιµοποιήθηκε η συλλογή OWLS-TC17 ver. 2.2 η οποία αποτελείται από 1007
περιγραφές OWL-S. Το κείµενο που αντιστοιχεί σε κάθε υπηρεσία αποτελείται από
το όνοµα της υπηρεσίας και το κείµενο που υπάρχει στο πεδίο textDescription. Οι
παράµετροι εισόδου/εξόδου επισηµειώνονται µε κάποιες από τις 23(= |Vo|) οντολο-
γίες που υπάρχουν στη συλλογή. Οι κατηγορίες στις οποίες είναι ταξινοµηµένες οι
υπηρεσίες είναι οι : Travel, Education, Weapon, Food, Economy, Communication, και
Medical. Πρέπει να σηµειωθεί ότι η συλλογή είναι τεχνητή. Παρολα αυτά είναι η µόνη
διαθέσιµη συλλογή µε ένα σχετικά µεγάλο αριθµό περιγραφών και έχει χρησιµοποι-
ηθεί αρκετές ϕορές σε ερευνητικές εργασίες. Μετά την προεπεξεργασία της συλλογής
προέκυψαν τα µεγέθη των λεξικών |Vc | = 395 και |VT | = 456. ΄Ολες οι διαφορετικές
αναπαραστάσεις της συλλογής είναι διαθέσιµες σε µορφή ARFF (Weka) στη διεύθυνση
http://mlkd.csd.auth.gr/ws.html.
Για την εκτέλεση των πειραµάτων χρησιµοποιήθηκε η 10-απλή σταυρωτή επικύρω-
ση (10 fold cross validation) και το σύστηµα συλλογιστικής Pellet (Sirin et al., 2007)
για τον υπολογισµό των ιεραρχιών υπαγωγής που εισάγονται στις οντολογίες. Στοχεύ-
οντας σε αποτελέσµατα ανεξάρτητα του ταξινοµητή, όλες οι µέθοδοι αξιολογήθηκαν
χρησιµοποιώντας πέντε διαφορετικούς ταξινοµητές :
− Naive Bayes (NB) (John and Langley, 1995)
− Support Vector Machines (SVM) (SMO Implementation (Platt, 1998))
17http://projects.semwebcentral.org/projects/owls-tc/
141
ΚΕΦΑΛΑΙΟ 6. ΕΦΑΡΜΟΓΕΣ ΤΑΞΙΝΟΜΗΣΗΣ ΚΕΙΜΕΝΩΝ ΣΤΟΝ ΠΑΓΚΟΣΜΙΟ ΙΣΤΟ
− k Nearest Neighbor (kΝΝ) (Aha and Kibler, 1991)
− Ripper Rule Learner (Cohen, 1995)
− C4.5 (Quinlan, 1993)
Χρησιµοποιήθηκαν αλγόριθµοι από διαφορετικά πρότυπα (paradigms) µάθησης
µε στόχο την κάλυψη των διαφορετικών απαιτήσεων των πραγµατικών εφαρµογών.
΄Ετσι έχουν συµπεριληφθεί µέθοδοι µε χαµηλές υπολογιστικές απαιτήσεις (π.χ. NB),
µε εύκολη ερµηνεία των παραγόµενων µοντέλων (π.χ. C4.5), και µε υψηλή ακρίβεια
πρόβλεψης (π.χ. SVM)
Χρησιµοποιήθηκαν οι υλοποιήσεις του Weka (Witten and Frank, 2005a) όλων
των αλγορίθµων µε τις προεπιλεγµένες ϱυθµίσεις. Ο αλγόριθµος kΝΝ εκτελέστηκε µε
k = 3 γείτονες. Οι µέθοδοι Emax και οι Eavg έχουν υλοποιηθεί εκπαιδεύοντας δύο τα-
ξινοµητές του ίδιου τύπου (έναν από το κείµενο -Text- και έναν από την αναπαράσταση
σηµασιολογικής υπογραφής - SemSig). Η µελέτη συνδυασµού ταξινοµητών διαφορε-
τικού τύπου παρουσιάζει ενδιαφέρον αλλά ϐρίσκεται εκτός των στόχων του κεφαλαίου.
Σχολιασµός Αποτελεσµάτων
Ο Πίνακας 6.3 παρουσιάζει την ορθότητα πρόβλεψης (accuracy) όλων των µεθόδων
και των ταξινοµητών. Με έντονη γραφή σηµειώνεται ποια µέθοδος παρουσιάζει την
υψηλότερη ορθότητα για κάθε ταξινοµητή. Για κάθε µέθοδο, υπογραµµίζεται η τιµή
του ταξινοµητή µε την υψηλότερη ορθότητα.
Παρατηρούµε αρχικά την υψηλή απόδοση του SVM το οποίο παρουσιάζει την
υψηλότερη ορθότητα πρόβλεψης σχεδόν σε όλες τις περιπτώσεις. Η δεύτερη καλύτερη
επίδοση επιτυγχάνεται από τον αλγόριθµο C4.5.
Σχετικά µε τις διαφορετικές αναπαραστάσεις, παρατηρούµε αρχικά ότι η ακρίβεια
της Text αναπαράστασης ϕθάνει σε υψηλά επίπεδα (ξεπερνώντας την SynSig και On-
tImp) ακόµη και µε το ελάχιστο κείµενο που ϐρίσκεται στο πεδίο textDescription της
OWL-S περιγραφής. Αυτό προφανώς οφείλεται στην ύπαρξη λέξεων που είναι χαρα-
κτηριστικές για κάθε κατηγορία. Η αναπαράσταση OntImp παρουσιάζει τη χειρότερη
απόδοση κυρίως λόγω της ύπαρξης γενικών οντολογιών που χρησιµοποιούνται σε πολ-
λές υπηρεσίες. Επιπλέον, η προσέγγιση SynSig παρόλη την απλότητά της (χωρίς τη
χρήση του συστήµατος συλλογιστικής) παρουσιάζει αρκετά καλή απόδοση. Παρόλα
αυτά, η καλύτερη απόδοση της SemSig σε σχέση µε τη SynSig υπογραµµίζει τη σηµαν-
τικότητα του µηχανισµού συλλογιστικής. Χρησιµοποιώντας το σύστηµα συλλογιστικής
µπορούµε να εξάγουµε σηµασιολογικές συσχετίσεις µεταξύ των εννοιών επισηµείωσης
σε αντίθεση µε την απλή ταύτιση λέξεων (keyword matching) που γίνεται στην αναπα-
ϱάσταση SynSig.
Παρατηρώντας τα αποτελέσµατα των εκτεταµένων διανυσµάτων TextSynSig και
TextSemSig ϐλέπουµε ότι και οι δύο προσεγγίσεις ξεπερνούν τις αντίστοιχες ϐασι-
κές τους αναπαραστάσεις (δηλαδή την Text και τη SynSig για το πρώτο και την Text
142
6.4. ΣΥΜΠΕΡΑΣΜΑΤΑ
Method / Classifier NB SVM kNN C4.5 Ripper AVG
Text 90.37 94.04 91.96 90.17 87.98 90.90
OntImp 60.68 79.64 77.16 80.04 74.98 74.50
SynSig 84.51 94.04 89.37 87.19 86.59 88.34
SemSig 85.80 96.92 90.37 93.55 90.86 91.50
TextSynSig 89.97 95.73 92.85 90.57 87.69 91.36
TextSemSig 91.96 96.52 93.74 93.15 91.96 93.47
Emax 91.76 95.43 94.34 95.63 92.95 94.02
Eavg 91.96 96.23 94.64 95.93 92.85 94.12
AVG 85.89 93.44 90.55 90.78 88.23
Πίνακας 6.3: Ορθότητα Πρόβλεψης όλων των µεθόδων και ταξινοµητών
και τη SemSig για το δεύτερο). Το γεγονός αυτό αποτελεί ένδειξη για την ικανότητα
του ταξινοµητή να εκµεταλλεύεται και τις δύο αναπαραστάσεις.
΄Αλλο ένα χαρακτηριστικό που υπογραµµίζει την σηµαντικότητα του συνδυασµού
κειµένου και σηµασιολογίας είναι η ακρίβεια των δύο οµάδων ταξινοµητών Emax και
Eavg οι οποίοι ξεπερνούν σε απόδοση το TextSemSig. Αυτό συµβαίνει πιθανότατα γιατί
υπάρχουν δύο ειδικοί ταξινοµητές (ένας για το κείµενο και ένας για τη σηµασιολογική
υπογραφή) ενώ στην προσέγγιση TexSemSig υπάρχει µόνο ένας.
6.4 Συµπεράσµατα
Σε αυτό το κεφάλαιο παρουσιάστηκαν δύο εφαρµογές ταξινόµησης κειµένων στο σύγ-
χρονο παγκόσµιο ιστό.
Η πρώτη, αποτελεί ένα σύστηµα συστάσεων λέξεων επισήµανσης για ϐιβλιογρα-
ϕικές αναφορές και σελιδοδείκτες ιστού. Το προτεινόµενο σύστηµα στηρίζεται στο
ιστορικό των αντικειµένων και των χρηστών αλλά και στο κείµενο των αντικειµένων.
Για την αξιοποίηση του κειµένου εκπαιδεύεται ένας ταξινοµητής πολλαπλών ετικετών.
Η δεύτερη εφαρµογή αφορά στην αυτόµατη ταξινόµηση σηµασιολογικών υπηρε-
σιών ιστού. Η µέθοδος ϐασίζεται στις περιγραφές OWL-S των υπηρεσιών. Προτείνονται
τέσσερις µέθοδοι για την µετατροπή των περιγραφών OWL-S σε διανύσµατα χαρακτη-
ϱιστικών, σε κάθε µία από τις οποίες λαµβάνεται υπόψη διαφορετική πληροφορία της
περιγραφής. Στις αναπαραστάσεις αυτές εφαρµόζονται αλγόριθµοι µηχανικής µάθη-
σης. Κάποια ενδιαφέροντα πορίσµατα της πειραµατικής αξιολόγησης ήταν η ωφελι-
µότητα της σηµασιολογικής υπογραφής και του κειµένου περιγραφής της υπηρεσίας.
Σύµφωνα µε το συµπέρασµα αυτό προτάθηκαν δύο µέθοδοι συνδυασµού των δύο αυ-
τών αναπαραστάσεων. Πειραµατικά αποτελέσµατα αποδεικνύουν ότι ο συνδυασµός
αυτός έχει ϑετική επίδραση στην ορθότητα πρόβλεψης.
143
7
Επίλογος
Σε αυτό το κεφάλαιο συγκεντρώνονται τα σηµαντικότερα συµπεράσµατα που προέκυ-
ψαν κατά την εκπόνηση της παρούσας διατριβής αλλά και πιθανές προοπτικές για
µελλοντική έρευνα.
7.1 Συµπεράσµατα
Η παρούσα διατριβή υπάγεται στην ερευνητική περιοχή της εξόρυξης κειµένων και
πραγµατεύεται προβλήµατα που παρουσιάζονται κατά την ταξινόµηση κειµένων. Το
δεύτερο κεφάλαιο αποτέλεσε µία εισαγωγή στην περιοχή της αυτόµατης ταξινόµησης
κειµένων µε χρήση µεθόδων µηχανικής µάθησης. Ιδιαίτερη αναφορά έγινε στα δύο
ειδικά προβλήµατα που αντιµετωπίζονται στη διατριβή, την ταξινόµηση ϱοών κειµένων
και την ταξινόµηση κειµένων πολλαπλών ετικετών.
Το τρίτο κεφάλαιο επικεντρώθηκε σε έναν ενδιαφέροντα τύπο εννοιολογικής από-
κλισης που εµπεριέχεται στις ϱοές κειµένων : Την εµφάνιση νέων χαρακτηριστικών
(λέξεων) µε το πέρασµα του χρόνου. Στο παρελθόν, αυτός ο τύπος της εννοιολογικής
απόκλισης δεν είχε ληφθεί υπόψη από τις µεθόδους της ϐιβλιογραφίας αλλά αντιµετω-
πιζόταν µε τη µη αποδοτική λύση της επανεκπαίδευσης. Παρουσιάστηκε ένα πλαίσιο
µάθησης το οποίο συνδυάζει µία επαυξητική µέθοδο επιλογής χαρακτηριστικών, µε
έναν ταξινοµητή που µπορεί να λειτουργήσει σε δυναµικούς χώρους χαρακτηριστι-
κών, µε στόχο την αντιµετώπιση αυτού του προβλήµατος. Τα πειραµατικά αποτελέ-
σµατα αποδεικνύουν ότι η προτεινόµενη προσέγγιση παρουσιάζει καλύτερη ακρίβεια
πρόβλεψης σε σχέση µε την απλή επαυξητική µάθηση και ενθαρρύνει τη µελλοντική
έρευνα. Επιπλέον, η συγκεκριµένη προσέγγιση είναι υπολογιστικά µη-απαιτητική
και απλή στην υλοποίηση, οπότε ϑα µπορούσε να αποτελέσει µέθοδο ϐάσης στην πε-
ϱιοχή. Ελπίζουµε επίσης ότι το σύνολο δεδοµένων news που δηµιουργήθηκε έτσι
ώστε να προσοµοιώνει απότοµες εννοιολογικές αποκλίσεις ϑα χρησιµοποιηθεί από την
ερευνητική κοινότητα για παρόµοιες αξιολογήσεις.
Τέλος, το προτεινόµενο πλαίσιο µάθησης εφαρµόστηκε σε ένα προσαρµοστικό σύ-
στηµα ανάγνωσης ειδήσεων (PersoNews). Τα κύρια χαρακτηριστικά του είναι η εύκολη
διαχείριση πολλαπλών πηγών ειδήσεων, η απόκρυψη των αδιάφορων άρθρων από το
χρήστη και η δυνατότητα να παρακολουθήσει γενικά ϑέµατα ενδιαφέροντος από µία
145
ΚΕΦΑΛΑΙΟ 7. ΕΠΙΛΟΓΟΣ
ταξινοµία ϑεµάτων.
Στο τρίτο κεφάλαιο προτάθηκε ένα πλαίσιο ταξινόµησης ϱοών δεδοµένων κατάλ-
ληλο για προβλήµατα που περιέχουν εννοιολογική απόκλιση και επανεµφανιζόµενες
έννοιες. Βασικό στοιχείο του πλαισίου αποτελεί µία συνάρτηση µετασχηµατισµού
δεσµών δεδοµένων σε εννοιολογικά διανύσµατα. Τα διανύσµατα αυτά περιέχουν πλη-
ϱοφορία που σχετίζεται µε τις έννοιες που χαρακτηρίζουν τις αντίστοιχες δέσµες δε-
δοµένων. Στη συνέχεια, εφαρµόζεται ένας αλγόριθµος οµαδοποίησης ϱοών ο οποίος
οργανώνει τα εννοιολογικά διανύσµατα σε οµάδες. Οι οµάδες αυτές αντιστοιχούν στις
διαφορετικές έννοιες που εµφανίζονται στη ϱοή. Για κάθε έννοια εκπαιδεύεται και
ένας ταξινοµητής. Η ταξινόµηση των δεδοµένων πραγµατοποιείται αφού αναγνωριστεί
η έννοια στην οποία ανήκουν έτσι ώστε να κληθεί ο αντίστοιχος ειδικός ταξινοµητής.
Για την αξιολόγηση του πλαισίου χρησιµοποιήθηκαν δύο σύνολα δεδοµένων µε εν-
νοιολογική απόκλιση, το ένα εκ των οποίων περιέχει επανεµφανιζόµενες έννοιες. Τα
πειραµατικά αποτελέσµατα αποδεικνύουν ότι το προτεινόµενο πλαίσιο αναγνωρίζει σω-
στά τις επανεµφανιζόµενες έννοιες µε αποτέλεσµα την υψηλή ορθότητα πρόβλεψης και
στα δύο σύνολα δεδοµένων.
Στο τέταρτο κεφάλαιο παρουσιάστηκαν δύο µέθοδοι για το πρόβληµα της ταξινό-
µησης πολλαπλών ετικετών µε ιδιαίτερη έµφαση σε προβλήµατα µε µεγάλο αριθµό
ετικετών. Η πρώτη µέθοδος, HOMER, αντιµετωπίζει το πρόβληµα οργανώνοντας τις
ετικέτες σε µία ιεραρχία µε κύριο πλεονέκτηµα τους µικρούς χρόνους ταξινόµησης.
Σηµαντική ϐελτίωση όµως παρατηρήθηκε και στην ποιότητα πρόβλεψης. Για την ορ-
γάνωση των ετικετών στην ιεραρχία προτάθηκε ένας νέος αλγόριθµος ισορροπηµένης
οµαδοποίησης. Βασικό πεδίο εφαρµογής αποτέλεσε το πρόβληµα της αυτόµατης πρό-
τασης λέξεων επισήµανσης (tags) το οποίο µοντελοποιήθηκε ως πρόβληµα ταξινόµη-
σης πολλαπλών ετικετών. ΄Ετσι, προέκυψε και ένα νέο σύνολο πολλαπλών ετικετών
(del.icio.us).
Στη δεύτερη µέθοδο, RAkEL, διασπάται τυχαία το αρχικό σύνολο ετικετών σε υπο-
σύνολα. Σε κάθε ένα από αυτά εφαρµόζεται ένας ξεχωριστός ταξινοµητής δυναµοσυνό-
λου ετικετών. Βασικό κίνητρο ήταν η ϐελτίωση της ποιότητας πρόβλεψης της µεθόδου
δυναµοσυνόλου ετικετών η οποία, σε σύνολα µε µεγάλο αριθµό ετικετών, αντιµετω-
πίζει σηµαντικές δυσκολίες. Μελετήθηκαν ξένα και επικαλυπτόµενα υποσύνολα και
προέκυψε ότι και τα δύο ϐελτιώνουν την απόδοση της µεθόδου δυναµοσυνόλου ειδικά
σε προβλήµατα µε µεγάλο αριθµό ετικετών. Προέκυψε επίσης ότι τα επικαλυπτόµενα
υποσύνολα παρουσιάζουν καλύτερα αποτελέσµατα σε σχέση µε τα ξένα εξαιτίας του
συγκερασµού των ταξινοµητών. Τέλος, τα συγκριτικά αποτελέσµατα µε δύο µεθόδους
ταξινόµησης πολλαπλών ετικετών της ϐιβλιογραφίας υψηλής ποιότητας πρόβλεψης ή-
ταν ιδιαίτερα ενθαρρυντικά.
Στο έκτο κεφάλαιο παρουσιάστηκαν δύο µέθοδοι ταξινόµησης κειµένων στον παγ-
κόσµιο ιστό. Η πρώτη χρησιµοποιεί έναν ταξινοµητή πολλαπλών ετικετών για τη σύ-
σταση λέξεων επισήµανσης σε σύστηµα διαµοιρασµού ϐιβλιογραφικών αναφορών και
σελιδοδεικτών ιστού. Η προτεινόµενη µέθοδος ϐασίζεται στο ιστορικό των αντικειµένων
και των χρηστών αλλά και στο κείµενο των αντικειµένων.
146
7.2. ΜΕΛΛΟΝΤΙΚΗ ΕΡΓΑΣΙΑ
Η δεύτερη εφαρµογή αφορά στην αυτόµατη ταξινόµηση σηµασιολογικών υπηρε-
σιών ιστού. Προτείνονται τέσσερις µέθοδοι για τη µετατροπή των περιγραφών σε διανύ-
σµατα χαρακτηριστικών, σε κάθε µία από τις οποίες λαµβάνεται υπόψη διαφορετική
πληροφορία της περιγραφής. Στις αναπαραστάσεις αυτές εφαρµόζονται αλγόριθµοι
µηχανικής µάθησης. Τα σηµαντικότερα συµπεράσµατα της πειραµατικής αξιολόγη-
σης ήταν η ωφελιµότητα της σηµασιολογικής υπογραφής και του κειµένου περιγραφής
της υπηρεσίας. Προτείνονται επίσης δύο µέθοδοι συνδυασµού των δύο αυτών αναπα-
ϱαστάσεων. Μέσω πειραµατικής αξιολόγησης αποδείχτηκε ότι ο συνδυασµός αυτός
έχει ϑετική επίδραση στην ορθότητα πρόβλεψης.
7.2 Μελλοντική Εργασία
Σχετικά µε το σύστηµα PersoNews, ενδιαφέρον παρουσιάζει η επέκταση του συστή-
µατος έτσι ώστε ο χρήστης να προσαρµόζει τη δική του ϑεµατική ιεραρχία (π.χ. να
προσθέτει υπο-κατηγορίες) ή να κατασκευάζει ο ίδιος µία από την αρχή. Ενδιαφέ-
ϱον επίσης παρουσιάζει το ενδεχόµενο συνδυασµού µεθόδων ταξινόµησης κειµένων
µε µεθόδους συνεργατικής διήθησης (collaborative filtering) (Kim et al., 2006). Σε
αυτήν την κατεύθυνση έχει αναπτυχθεί στο παρελθόν σύστηµα το οποίο παράγει συ-
στάσεις για ενδιαφέροντα άρθρα µέσω κανόνων συσχέτισης και συνεργατικής διήθησης
(Katakis, 2007).
Για την αναγνώριση της εννοιολογικής απόκλισης και των επανεµφανιζόµενων εν-
νοιών µία ενδιαφέρουσα εναλλακτική προσέγγιση ϑα ήταν η οµαδοποίηση των ταξινο-
µητών της ϱοής. Η οµαδοποίηση των ταξινοµητών έχει ήδη εξεταστεί στη ϐιβλιογραφία
(Tsoumakas et al., 2004) αλλά δεν έχει προσαρµοστεί και εφαρµοστεί στο πρόβλη-
µα της ταξινόµησης ϱοών δεδοµένων. Στην εργασία (Tsoumakas et al., 2004) για
παράδειγµα, λαµβάνονται υπόψη οι τιµές εξόδου των ταξινοµητών µε στόχο τον ορι-
σµό µέτρων απόστασης. Στην συνέχεια χρησιµοποιείται ένας ιεραρχικός αλγόριθµος
οµαδοποίησης.
Ο αλγόριθµος HOMER ϑα µπορούσε εύκολα να εφαρµοστεί σε δεδοµένα µίας
ήδη υπάρχουσας ιεραρχίας ετικετών. Με αυτόν τον τρόπο ϑα αποτελέσει έναν αυτο-
δύναµο ταξινοµητή ιεραρχικών δεδοµένων πολλαπλών ετικετών στον οποίο όµως ϑα
µπορεί να χρησιµοποιηθεί οποιοσδήποτε ταξινοµητής πολλαπλών ετικετών ανάλογα
µε τις απαιτήσεις κάθε εφαρµογής. Μία τέτοια εκτενής µελέτη εφαρµογής διάφορων
ταξινοµητών πολλαπλών ετικετών στο πλαίσιο του HOMER αποτελεί άµεσο ερευνητικό
στόχο. Ενδιαφέρον επίσης παρουσιάζει η εξέταση διαφορετικών ταξινοµητών ϐάσης,
όπως οι µηχανές διανυσµάτων υποστήριξης. Πρόκειται για υπολογιστικά απαιτητικούς
ταξινοµητές αλλά µε µεγαλύτερη ακρίβεια πρόβλεψης.
Η προσέγγιση ταξινόµησης διαδικτυακών υπηρεσιών ϑα µπορούσε να επεκταθεί σε
δύο κατευθύνσεις. Κατ΄ αρχήν η αναπαράσταση σηµασιολογικής υπογραφής (SemSig)
µπορεί να επεκταθεί χρησιµοποιώντας µη δυαδικά διανύσµατα. Συγκεκριµένα, για τα
στοιχεία του διανύσµατος SemSig µπορούν να οριστούν ϐάρη σύµφωνα µε την οµοιό-
τητα των εννοιών. Τέτοιες µετρικές έχουν παρουσιαστεί στη ϐιβλιογραφία (Meditskos
147
ΚΕΦΑΛΑΙΟ 7. ΕΠΙΛΟΓΟΣ
and Bassiliades, 2007) αλλά δεν έχουν αξιοποιηθεί σε ένα διανυσµατικό µοντέλο ανα-
παράστασης όπως το προτεινόµενο. Η δεύτερη επέκταση αφορά στον πειραµατισµό µε
µεθόδους ταξινόµησης πολλαπλών ετικετών (Tsoumakas et al., 2009a) αφού πολλές
υπηρεσίες ιστού ϑα µπορούσαν να ανήκουν σε παραπάνω από µία κατηγορία.
148
Βιβλιογραφία
Aggarwal, C., editor (2007). Data Streams: Models and Algorithms. Springer.
Agrawal, R., Imielinski, T., and Swami, A. N. (1993). Mining association rules
between sets of items in large databases. In Buneman, P. and Jajodia, S., editors,
Proceedings of the 1993 ACM SIGMOD International Conference on Management of
Data, pages 207–216, Washington, D.C.
Aha, D. and Kibler, D. (1991). Instance-based learning algorithms. Machine Lear-
ning, 6:37–66.
Alpaydin, E. (2004). Introduction to Machine Learning (Adaptive Computation and
Machine Learning). The MIT Press.
Androutsopoulos, I., Koutsias, J., Chandrinos, K., Paliouras, G., and Spyropoulos,
C. (2000). An evaluation of naive bayesian anti-spam filtering. In Potamias,
G., Moustakis, V., and van Someren, M., editors, Proceedings of the Workshop
on Machine Learning in the New Information Age, 11th European Conference on
Machine Learning (ECML 2000), pages 9–17.
Apté, C., Damerau, F., and Weiss, S. M. (1994). Automated learning of decision
rules for text categorization. ACM Trans. Inf. Syst., 12(3):233–251.
Asuncion, A. and Newman, D. (2007). UCI machine learning repository.
Baker, L. D. and McCallum, A. K. (1998). Distributional clustering of words for
text classification. In SIGIR ’98: Proceedings of the 21st annual international ACM
SIGIR conference on Research and development in information retrieval, pages 96–
103, New York, NY, USA. ACM.
Banerjee, A. and Ghosh, J. (2004). Frequency-sensitive competitive learning for sca-
lable balanced clustering on high-dimensional hyperspheres. IEEE Transactions
on Neural Networks, 15(3):702–719.
Banerjee, A. and Ghosh, J. (2006). Scalable clustering algorithms with balancing
constraints. Data Mining and Knowledge Discovery, 13(3):365–395.
Barbará, D. (2002). Requirements for clustering data streams. SIGKDD Explora-
tions, 3(2):23–27.
Battle, S., Bernstein, A., and Boley, H. (2005). Semantic web services framework
(swsf) overview. http://www.w3.org/Submission/SWSF.
Bennett, K., Bradley, P., , and Demiriz, A. (2000). Constrained k-means clustering.
Technical Report TR-2000-65, Microsoft Research.
149
ΒΙΒΛΙΟΓΡΑΦΙΑ
Bharat, K., Kamba, T., and Albers, M. (1998). Personalized, interactive news on the
web. Multimedia Systems, 6(5):349–358.
Billsus, D. and Pazzani, M. J. (1999). A hybrid user model for news story classi-
fication. In UM ’99: Proceedings of the seventh international conference on User
modeling, pages 99–108, Secaucus, NJ, USA. Springer-Verlag New York, Inc.
Bishop, C. M. (2006). Pattern Recognition and Machine Learning (Information Science
and Statistics). Springer.
Blockeel, H., Schietgat, L., Struyf, J., Dz?eroski, S., and Clare, A. (2006). Deci-
sion trees for hierarchical multilabel classification: A case study in functional
genomics. Lecture Notes in Computer Science (including subseries Lecture Notes in
Artificial Intelligence and Lecture Notes in Bioinformatics), 4213 LNAI:18–29.
Boutell, M., Luo, J., Shen, X., and Brown, C. (2004). Learning multi-label scene
classification. Pattern Recognition, 37(9):1757–1771.
Brinker, K. and Hullermeier, E. (2007). Case-based multilabel ranking. In Pro-
ceedings of the 20th International Conference on Artificial Intelligence (IJCAI ’07),
pages 702–707, Hyderabad, India.
Bruno, M., Canfora, G., Penta, M. D., and Scognamiglio, R. (2005). An approach
to support web service classification and annotation. In Proceedings of the IEEE
International Conference on e-Technology, e-Commerce and e-Service, pages 138–
143, Washington, DC, USA.
Caropreso, M. F., Matwin, S., and Sebastiani, F. (2001). A learner-independent eva-
luation of the usefulness of statistical phrases for automated text categorization.
pages 78–102.
Carreira, R., Crato, J. M., Gonçalves, D., and Jorge, J. A. (2004). Evaluating
adaptive user profiles for news classification. In IUI ’04: Proceedings of the 9th
international conference on Intelligent user interfaces, pages 206–212, New York,
NY, USA. ACM.
Cesa-Bianchi, N., Gentile, C., and Zaniboni, L. (2006). Incremental algorithms for
hierarchical classification. Journal of Machine Learning Research, 7:31–54.
Chang, C.-C. and Lin, C.-J. (2001). LIBSVM: a library for support vector machines.
Software available at http://www.csie.ntu.edu.tw/ cjlin/libsvm.
Chawla, N. V., Japkowicz, N., and Kotcz, A. (2004). Editorial: special issue on
learning from imbalanced data sets. SIGKDD Explorations, 6(1):1–6.
Cheng, J., Ke, Y., and Ng, W. (2008). A survey on algorithms for mining frequent
itemsets over data streams. Knowledge and Information Systems, 16(1):1–27.
150
ΒΙΒΛΙΟΓΡΑΦΙΑ
Chin, J. P., Diehl, V. A., and Norman, K. L. (1988). Development of an instrument
measuring user satisfaction of the human-computer interface. In CHI ’88: Pro-
ceedings of the SIGCHI conference on Human factors in computing systems, pages
213–218, New York, NY, USA. ACM.
Chirita, P. A., Costache, S., Nejdl, W., and Handschuh, S. (2007). P-tag: large
scale automatic generation of personalized annotation tags for the web. In WWW
’07: Proceedings of the 16th international conference on World Wide Web, pages
845–854, New York, NY, USA. ACM.
Clare, A. and King, R. (2001). Knowledge discovery in multi-label phenotype data.
In Proceedings of the 5th European Conference on Principles of Data Mining and
Knowledge Discovery (PKDD 2001), pages 42–53, Freiburg, Germany.
Cohen, W. W. (1995). Learning to classify english text with ILP methods. In Raedt,
L. D., editor, Advances in inductive logic programming, pages 124–143. IOS Press,
Amsterdam, NL.
Cohen, W. W. and Hirsh, H. (1998). Joins that generalize: text classification using
Whirl. In Agrawal, R., Stolorz, P. E., and Piatetsky-Shapiro, G., editors, Procee-
dings of KDD-98, 4th International Conference on Knowledge Discovery and Data
Mining, pages 169–173, New York, US. AAAI Press, Menlo Park, US.
Cohen, W. W. and Singer, Y. (1999). Context-sensitive learning methods for text
categorization. ACM Transactions on Information Systems, 17(2):141–173.
Corella, M. and Castells, P. (2006). Semi-automatic semantic-based web service
classification. In Eder, J. and Dustdar, S., editors, Business Process Mangement
Workshops, Springer Verlag Lecture Notes in Computer Science, volume 4103,
pages 459–470, Vienna, Austria.
Crammer, K. and Singer, Y. (2003). A family of additive online algorithms for cate-
gory ranking. Journal of Machine Learning Research, 3:1025–1058.
de Comite, F., Gilleron, R., and Tommasi, M. (2003). Learning multi-label alterna-
ting decision trees from texts and data. In Proceedings of the 3rd International
Conference on Machine Learning and Data Mining in Pattern Recognition (MLDM
2003), pages 35–49, Leipzig, Germany.
Deerwester, S., Dumais, S. T., Furnas, G. W., Landauer, T. K., and Harshman, R.
(1990). Indexing by latent semantic analysis. Journal of the American Society for
Information Science, 41:391–407.
Dempster, A. P., Laird, N. M., and Rubin, D. B. (1977). Maximum likelihood from
incomplete data via the EM algorithm. Journal of the Royal Statistical Society.
Series B (Methodological), 39(1):1–38.
151
ΒΙΒΛΙΟΓΡΑΦΙΑ
Dept, I. D., Dagan, I., Karov, Y., and T, D. R. (1997). Mistake-driven learning in text
categorization. In In EMNLP-97, The Second Conference on Empirical Methods in
Natural Language Processing, pages 55–63.
Domingos, P. and Pazzani, M. J. (1997). On the optimality of the simple bayesian
classifier under zero-one loss. Machine Learning, 29(2-3):103–130.
Duda, R. O., Hart, P. E., and Stork, D. G. (2000). Pattern Classification. Wiley-
Interscience.
Dumais, S., Platt, J., Heckerman, D., and Sahami, M. (1998). Inductive learning al-
gorithms and representations for text categorization. In CIKM ’98: Proceedings of
the seventh international conference on Information and knowledge management,
pages 148–155, New York, NY, USA. ACM.
Elisseeff, A. and Weston, J. (2002). A kernel method for multi-labelled classification.
In Advances in Neural Information Processing Systems 14.
Esuli, A., Fagni, T., and Sebastiani, F. (2008). Boosting multi-label hierarchical text
categorization. Information Retrieval, 11(4):287–313.
Fan, W. (2004). Systematic data selection to mine concept-drifting data streams.
In KDD ’04: Proceedings of the tenth ACM SIGKDD international conference on
Knowledge discovery and data mining, pages 128–137, New York, NY, USA. ACM.
Feldman, R. and Sanger, J. (2006). The Text Mining Handbook: Advanced Approa-
ches in Analyzing Unstructured Data. Cambridge University Press.
Forman, G. (2006). Tackling concept drift by temporal inductive transfer. In SIGIR
’06: Proceedings of the 29th annual international ACM SIGIR conference on Resea-
rch and development in information retrieval, pages 252–259, New York, NY, USA.
ACM.
Fuhr, N., Hartmann, S., Lustig, G., Schwantner, M., Tzeras, K., Darmstadt, T. H.,
Informatik, F., and Knorz, G. (1991). Air/x - a rule-based multistage indexing
system for large subject fields. In Proceedings of RIAO’91, pages 606–623.
Gaber, M., Zaslavsky, A., and Krishnaswamy, S. (2007). A survey of classification
methods in data streams. In Aggarwal, C., editor, Data Streams, Models and
Algorithms, pages 39–59. Springer.
Galavotti, L., Sebastiani, F., and Simi, M. (2000). Experiments on the use of feature
selection and negative evidence in automated text categorization. In ECDL ’00:
Proceedings of the 4th European Conference on Research and Advanced Technology
for Digital Libraries, pages 59–68, London, UK. Springer-Verlag.
152
ΒΙΒΛΙΟΓΡΑΦΙΑ
Gama, J., Medas, P., Castillo, G., and Rodrigues, P. P. (2004). Learning with
drift detection. In Bazzan, A. L. C. and Labidi, S., editors, Advances In Artificial
Intelligence, Proceedings of the 17th Brazilian Symposium on Artificial Intelligence
(SBIA 2004), volume 3171 of Lecture Notes in Artificial Intelligence, pages 286–295,
Brazil. Springer.
Ghamrawi, N. and McCallum, A. (2005). Collective multi-label classification. In Pro-
ceedings of the 2005 ACM Conference on Information and Knowledge Management
(CIKM ’05), pages 195–200, Bremen, Germany.
Godbole, S. and Sarawagi, S. (2004). Discriminative methods for multi-labeled
classification. In Proceedings of the 8th Pacific-Asia Conference on Knowledge
Discovery and Data Mining (PAKDD 2004), pages 22–30.
Gövert, N., Lalmas, M., and Fuhr, N. (1999). A probabilistic description-oriented
approach for categorizing web documents. In CIKM ’99: Proceedings of the eighth
international conference on Information and knowledge management, pages 475–
482, New York, NY, USA. ACM.
Harries, M. B., Sammut, C., and Horn, K. (1998). Extracting hidden context. Ma-
chine Learning, 32(2):101–126.
Hastie, T., Tibshirani, R., and Friedman, J. H. (2001). The Elements of Statistical
Learning. Springer.
Hayes, P. J., Andersen, P. M., Nirenburg, I. B., and Schmandt, L. M. (1990). Tcs: a
shell for content-based text categorization. In Proceedings of the sixth conference
on Artificial intelligence applications, pages 320–326, Piscataway, NJ, USA. IEEE
Press.
Hess, A., Johnston, E., and Kushmerick, N. (2004). ASSAM: A tool for semi-
automatically annotating semantic web services. In 3rd International Semantic
Web Conference.
Hess, A. and Kushmerick, N. (2003). Learning to attach semantic metadata to web
services. In The Semantic Web - Proc. Intl. Semantic Web Conference (ISWC 2003),
pages 258–273.
Huang, J. and Ling, C. X. (2005). Using auc and accuracy in evaluating learning
algorithms. IEEE Trans. on Knowl. and Data Eng., 17(3):299–310.
Hullermeier, E., Furnkranz, J., Cheng, W., and Bringer, K. (2008). Label ranking
by learning pairwise preferences. Artificial Intelligence.
Hulten, G., Spence, L., and Domingos, P. (2001). Mining time-changing data stre-
ams. In KDD ’01: 7th ACM SIGKDD International conference on Knowledge Disco-
very and Data Mining, pages 97–106. ACM Press.
153
ΒΙΒΛΙΟΓΡΑΦΙΑ
Jain, A. K., Murty, M. N., and Flynn, P. J. (1999). Data clustering: a review. ACM
Computing Surveys, 31(3):264–323.
Jaschke, R., Marinho, L. B., Hotho, A., Schmidt-Thieme, L., and Stumme, G. (2007).
Tag recommendations in folksonomies. In Proceedings of the 11th European Con-
ference on Principles and Practice of Knowledge Discovery in Databases (PKDD’07),
pages 506–514, Berlin, Heidelberg.
Joachims, T. (1998). Text categorization with support vector machines: learning wi-
th many relevant features. In Nédellec, C. and Rouveirol, C., editors, Proceedings
of ECML-98, 10th European Conference on Machine Learning, pages 137–142,
Chemnitz, DE. Springer Verlag, Heidelberg, DE. Published in the ‘‘Lecture Notes
in Computer Science’’ series, number 1398.
John, G. H. and Langley, P. (1995). Estimating continuous distributions in Baye-
sian classifiers. In UAI ’95: Proceedings of the Eleventh Annual Conference on
Uncertainty in Artificial Intelligence, Montreal, Quebec, Canada, pages 338–345.
Morgan Kaufman.
Kalles, D. and Morris, T. (1996). Efficient incremental induction of decision trees.
Mach. Learn., 24(3):231–242.
Katakis, I. (2007). A recommendation system that utilizes association rules and
collaborative filtering. Master’s thesis, Department of Informatics, Aristotle Uni-
versity of Thessaloniki, Thessaloniki.
Katakis, I., Meditskos, G., Tsoumakas, G., Bassiliades, N., and Vlahavas, I. (2009a).
On the combination of textual and semantic descriptions for automated semantic
web service classification. In Proc. 5th IFIP Conference on Artificial Intelligence
Applications & Innovations (AIAI 2009), pages 95–104. Springer-Verlag.
Katakis, I., Tsoumakas, G., Banos, E., Bassiliades, N., and Vlahavas, I. (2009b). An
adaptive personalized news dissemination system. Journal of Intelligent Informa-
tion Systems, 32(2):191–212.
Katakis, I., Tsoumakas, G., and Vlahavas, I. (2006). Email mining: Emerging
techniques for email management. In Vakali, A. and Pallis, G., editors, Web Data
Management Practices: Emerging Techniques and Technologies, pages 219–240.
Idea Group Publishing.
Katakis, I., Tsoumakas, G., and Vlahavas, I. (2008). Multilabel text classification
for automated tag suggestion. In Proceedings of the ECML/PKDD 2008 Discovery
Challenge, pages 75–83.
154
ΒΙΒΛΙΟΓΡΑΦΙΑ
Katakis, I., Tsoumakas, G., and Vlahavas, I. (2009c). Tracking recurring contexts
using ensemble classifiers. Knowledge and Information Systems (accepted for
publication).
Kiefer, C. and Bernstein, A. (2008). The creation and evaluation of isparql stra-
tegies for matchmaking. In Hauswirth, M., Koubarakis, M., and Bechhofer, S.,
editors, Proceedings of the 5th European Semantic Web Conference, LNCS, Berlin,
Heidelberg. Springer Verlag.
Kim, S.-B., Han, K.-S., Rim, H.-C., and Myaeng, S. H. (2006). Some effective tech-
niques for naive bayes text classification. IEEE Trans. on Knowl. and Data Eng.,
18(11):1457–1466.
Klimt, B. and Yang, Y. (2004). The enron corpus: A new dataset for email classifi-
cation research. In ECML 2004, 15th European Conference on Machine Learning,
Pisa, Italy, pages 217–226. Springer.
Klinkenberg, R. (2004). Learning drifting concepts: Example selection vs. example
weighting. Intelligent Data Analysis, 8(3):281–200.
Klinkenberg, R. and Joachims, T. (2000). Detecting concept drift with support vector
machines. In ICML ’00: Proceedings of the Seventeenth International Conference on
Machine Learning, pages 487–494, San Francisco, CA, USA. Morgan Kaufmann
Publishers Inc.
Klusch, M., Kapahnke, P., and Fries, B. (2008). Hybrid semantic web service re-
trieval: A case study with OWLS-MX. In International Conference on Semantic
Computing, pages 323–330, Los Alamitos, CA, USA. IEEE Computer Society.
Kolter, J. and Maloof, M. (2003). Dynamic weighted majority: A new ensemble
method for tracking concept drift. In Proceedings of the Third IEEE International
Conference on Data Mining, pages 123–130, Los Alamitos, CA. IEEE Press.
Kolter, J. Z. and Maloof, M. A. (2005). Using additive expert ensembles to cope with
concept drift. In ICML ’05: Proceedings of the 22nd International Conference on
Machine learning, pages 449–456, New York, NY, USA. ACM.
Kolter, J. Z. and Maloof, M. A. (2007). Dynamic weighted majority: An ensemble
method for drifting concepts. Journal of Machine Learning Research, 8:2755–
2790.
Kopecký, J., Vitvar, T., Bournez, C., and Farrell, J. (2007). SAWSDL: Semantic
Annotations for WSDL and XML Schema. IEEE Internet Computing, 11(6):60–67.
Lam, S. L. and Lee, D. L. (1999). Feature reduction for neural network based
text categorization. In Chen, A. L. and Lochovsky, F. H., editors, Proceedings of
155
ΒΙΒΛΙΟΓΡΑΦΙΑ
DASFAA-99, 6th IEEE International Conference on Database Advanced Systems
for Advanced Application, pages 195–202, Hsinchu, TW. IEEE Computer Society
Press, Los Alamitos, US.
Larkey, L. S. (1998). Automatic essay grading using text categorization techniques.
In SIGIR ’98: Proceedings of the 21st annual international ACM SIGIR conference
on Research and development in information retrieval, pages 90–95, New York, NY,
USA. ACM.
Larkey, L. S. (1999). A patent search and classification system. In Fox, E. A. and
Rowe, N., editors, Proceedings of DL-99, 4th ACM Conference on Digital Libraries,
pages 179–187, Berkeley, US. ACM Press, New York, US.
Larkey, L. S. and Croft, W. B. (1996). Combining classifiers in text categorization.
In SIGIR ’96: Proceedings of the 19th annual international ACM SIGIR conference
on Research and development in information retrieval, pages 289–297, New York,
NY, USA. ACM.
Lewis, D. D. (1992). An evaluation of phrasal and clustered representations on a
text categorization task. In SIGIR ’92: Proceedings of the 15th annual international
ACM SIGIR conference on Research and development in information retrieval, pages
37–50, New York, NY, USA. ACM.
Lewis, D. D., Yang, Y., Rose, T. G., and Li, F. (2004). Rcv1: A new benchmark
collection for text categorization research. J. Mach. Learn. Res., 5:361–397.
Li, T. and Ogihara, M. (2006). Toward intelligent music information retrieval. IEEE
Transactions on Multimedia, 8(3):564–574.
Li, Y. H. and Jain, A. K. (1998). Classification of text documents. The Computer
Journal, 41(8):537–546.
Luo, X. and Zincir-Heywood, A. (2005). Evaluation of two systems on multi-class
multi-label document classification. In Proceedings of the 15th International Sym-
posium on Methodologies for Intelligent Systems, pages 161–169.
Manning, C. and Schutze, H. (1999). Foundations of Statistical Natural Language
Processing, chapter 16: Text Categorization, pages 575–608. The MIT Press,
Cambridge, US.
Marchetti, A., Tesconi, M., Ronzano, F., Rosella, M., and Minutoli, S. (2007). Sem-
key: A semantic collaborative tagging system. In Proc. WWW 2007 Workshop on
Tagging and Metadata for Social Information Organization, Banff, Canada.
Martin, D., Burstein, M., and Hobbs, J. (2004). Owl-s: Semantic markup for web
services. http://www.w3.org/Submission/OWL-S.
156
ΒΙΒΛΙΟΓΡΑΦΙΑ
Martin Scholz, R. K. (2007). Boosting classifiers for drifting concepts. Intelligent
Data Analysis, Special Issue on Knowledge Discovery from Data Streams, 11(1):3–
28.
McCallum, A. (1999). Multi-label text classification with a mixture model trained
by em. In Proceedings of the AAAI’ 99 Workshop on Text Learning.
McCallum, A. and Nigam, K. (1998). A comparison of event models for naive bayes
text classification. In Proceedings of AAAI-98, Workshop on Learning for Text
Categorization.
McCulloch, W. and Pitts, W. (1943). A logical calculus of the ideas immanent in
nervous activity. Bulletin of Mathematical Biophysics, 5:115–133.
McQueen, J. (1967). Some methods for classification and analysis of multivariate
observations. In the Fifth Berkeley Symposium on Mathematical Statistics and
Probability, volume 1, pages 281–297.
Meditskos, G. and Bassiliades, N. (2007). Object-oriented similarity measures for
semantic web service matchmaking. In Proc. 5th IEEE European Conference on
Web Services (ECOWS 2007), pages 57–66, Halle (Saale), Germany.
Mencia, E. L. and Furnkranz, J. (2008). Efficient pairwise multilabel classification
for large scale problems in the legal domain. In 12th European Conference on Pri-
nciples and Practice of Knowledge Discovery in Databases, PKDD 2008, Antwerp,
Belgium.
Michalski, R. S., Carbonell, J. G., and Mitchell, T. M. (1983). Machine Learning: An
Artificial Intelligence Approach. Springer, Berlin, Heidelberg.
Mitchell, T. M. (1997). Machine Learning. McGraw-Hill, New York.
Ng, H. T., Goh, W. B., and Low, K. L. (1997). Feature selection, perceptron learning,
and a usability case study for text categorization. In Belkin, N. J., Narasimhalu,
A. D., and Willett, P., editors, Proceedings of SIGIR-97, 20th ACM International
Conference on Research and Development in Information Retrieval, pages 67–73,
Philadelphia, US. ACM Press, New York, US.
Oldham, N., Thomas, C., Sheth, A., and Verma, K. (2005). METEOR-S Web Service
Annotation Framework with Machine Learning Classification.
Peng, T., Zuo, W., and He, F. (2008). SVM based adaptive learning method for text
classification from positive and unlabeled documents. Knowledge and Information
Systems, 16(3):281–301.
157
ΒΙΒΛΙΟΓΡΑΦΙΑ
Perkins, S., Lacker, K., and Theiler, J. (2003). Grafting: Fast, incremental feature
selection by gradient descent in function space. Journal of Machine Learning
Research, 3:1333–1356.
Platt, J. (1998). Machines using sequential minimal optimization. In Schoelkopf, B.,
Burges, C., and Smola, A., editors, Advances in Kernel Methods - Support Vector
Learning. MIT Press.
Platt, J. C. (1999). Fast training of support vector machines using sequential mini-
mal optimization. pages 185–208.
Porter, M. (1980). An algorithm for suffix stripping. Program, 14(3):130–137.
Preiss, B. R. (1999). Data Structures and Algorithms with Object-Oriented Design
Patterns in Java. Wiley.
Qi, G.-J., Hua, X.-S., Rui, Y., Tang, J., Mei, T., and Zhang, H.-J. (2007). Corre-
lative multi-label video annotation. In MULTIMEDIA ’07: Proceedings of the 15th
international conference on Multimedia, pages 17–26, New York, NY, USA. ACM.
Qi, X. and Davison, B. D. (2009). Web page classification: Features and algorithms.
ACM Comput. Surv., 41(2):1–31.
Quinlan, R. (1993). C4.5: Programs for Machine Learning. Morgan Kaufmann Pu-
blishers, San Mateo, CA.
Rajasekaran, P., Miller, J., Verma, K., and Sheth, A. (2004). Enhancing web services
description and discovery to facilitate composition. In Proceedings of the 1st
International Workshop on Semantic Web services and Web Process Composition,
pages 34–47.
Read, J. (2008). A pruned problem transformation method for multi-label classifica-
tion. In Proc. 2008 New Zealand Computer Science Research Student Conference
(NZCSRS 2008), pages 143–150.
Rennie, J. (2000). ifile: An application of machine learning to e-mail filtering. In
KDD-2000 Workshop on Text Mining.
Rennie, J., Shih, L., Teevan, J., and Karger, D. (2003). Tackling the poor assum-
ptions of naive bayes text classifiers. In Proceedings of ICML-03, 20th International
Conference on Machine Learning, Washington, DC. Morgan Kaufmann Publishers,
San Francisco, US.
Rennie, J. D. and Rifkn, R. (2001). Improving multiclass text classification with
the support vector machine. Technical Report AIM-2001-026, Massachusetts
Institute of Technology.
158
ΒΙΒΛΙΟΓΡΑΦΙΑ
Rogati, M. and Yang, Y. (2002). High-performing feature selection for text clas-
sification. In CIKM ’02: Proceedings of the eleventh international conference on
Information and knowledge management, pages 659–661, New York, NY, USA.
ACM.
Roman, D., Lausen, H., and Keller, U. (2004). D2v1.0. web service modeling ontology
(wsmo). http://www.wsmo.org/2004/d2/v1.0.
Rousu, J., Saunders, C., Szedmak, S., and Shawe-Taylor, J. (2006). Kernel-based
learning of hierarchical multilabel classification methods. Journal of Machine
Learning Research, 7:1601–1626.
Ruiz, M. E. and Srinivasan, P. (1999). Hierarchical neural networks for text catego-
rization. In Hearst, M. A., Gey, F., and Tong, R., editors, Proceedings of SIGIR-99,
22nd ACM International Conference on Research and Development in Information
Retrieval, pages 281–282, Berkeley, US. ACM Press, New York, US.
Russell, S. J. and Norvig, P. (2003). Artificial Intelligence: A Modern Approach.
Pearson Education.
Saha, S., Murthy, C. A., and Pal, S. K. (2008). Classification of web services using
tensor space model and rough ensemble classifier. In Foundations of Intelligent
Systems, 17th International Symposium, ISMIS 2008, Toronto, Canada, May 20-
23, 2008, Proceedings, pages 508–513.
Sahami, M., Dumais, S., Heckerman, D., and Horvitz, E. (1998). A bayesian appro-
ach to filtering junk E-mail. In Learning for Text Categorization: Papers from the
1998 Workshop, Madison, Wisconsin. AAAI Technical Report WS-98-05.
Salton, G. and Buckley, C. (1988). Term-weighting approaches in automatic text
retrieval. Inf. Process. Manage., 24(5):513–523.
Sarah Jane Delany, Padraig Cunningham, A. T. L. C. (2005). A case-based technique
for tracking concept drift in spam filtering. Knowledge-Based Systems, 18(4-
5):187–195.
Schapire, R. E. and Singer, Y. (2000). Boostexter: A boosting-based system for text
categorization. Machine Learning, 39(2/3):135–168.
Schapire, R. E., Singer, Y., and Singhal, A. (1998). Boosting and Rocchio applied to
text filtering. In Croft, W. B., Moffat, A., Rĳsbergen, C. J. V., Wilkinson, R., and
Zobel, J., editors, Proceedings of SIGIR-98, 21st ACM International Conference on
Research and Development in Information Retrieval, pages 215–223, Melbourne,
AU. ACM Press, New York, US.
159
ΒΙΒΛΙΟΓΡΑΦΙΑ
Schütze, H., Hull, D. A., and Pedersen, J. O. (1995). A comparison of classifiers and
document representations for the routing problem. In Fox, E. A., Ingwersen, P.,
and Fidel, R., editors, Proceedings of SIGIR-95, 18th ACM International Conference
on Research and Development in Information Retrieval, pages 229–237, Seattle,
US. ACM Press, New York, US.
Sebastiani, F. (2002). Machine learning in automated text categorization. ACM
Comput. Surv., 34(1):1–47.
Simon, H. A. (1983). Why should machines learn? In Michalski, R. S., Carbonell,
J. G., and Mitchell, T. M., editors, Machine Learning: An Artificial Intelligence
Approach, pages 25–37. Springer, Berlin, Heidelberg.
Sirin, E., Parsia, B., Grau, B. C., Kalyanpur, A., and Katz, Y. (2007). Pellet: A
practical owl-dl reasoner. Web Semant., 5(2):51–53.
Snoek, C. G., Worring, M., van Gemert, J. C., Geusebroek, J.-M., and Smeulders,
A. W. (2006a). The challenge problem for automated detection of 101 semantic
concepts in multimedia. In Proceedings of ACM Multimedia, pages 421–430.
Snoek, C. G. M., Worring, M., van Gemert, J. C., Geusebroek, J.-M., and Smeulders,
A. W. M. (2006b). The challenge problem for automated detection of 101 semantic
concepts in multimedia. In MULTIMEDIA ’06: Proceedings of the 14th annual ACM
international conference on Multimedia, pages 421–430, New York, NY, USA. ACM.
Song, Y., Zhang, L., and Giles, L. C. (2008). A sparse gaussian processes classifica-
tion framework for fast tag suggestions. In CIKM ’08: Proceeding of the 17th ACM
conference on Information and knowledge management, pages 93–102. ACM.
Sood, S., Hammond, K., Owsley, S., and Birnbaum, L. (2007). TagAssist: Automatic
Tag Suggestion for Blog Posts. In Proceedings of the International Conference on
Weblogs and Social Media (ICWSM 2007).
Spyromitros, E., Tsoumakas, G., and Vlahavas, I. (2008). An empirical study of lazy
multilabel classification algorithms. In Proc. 5th Hellenic Conference on Artificial
Intelligence (SETN 2008).
Srivastava, A. and Zane-Ulman, B. (2005). Discovering recurring anomalies in text
reports regarding complex space systems. In IEEE Aerospace Conference.
Stamatatos, E. (2008). Author identification: Using text sampling to handle the
class imbalance problem. Inf. Process. Manage., 44(2):790–799.
Street, W. N. and Kim, Y. (2001). A streaming ensemble algorithm (SEA) for large-
scale classification. In 7th ACM SIGKDD International Conference on Knowledge
Discovery in Data Mining, pages 277–382. ACM.
160
ΒΙΒΛΙΟΓΡΑΦΙΑ
Streich, A. P. and Buhmann, J. M. (2008). Classification of multi-labeled data: A
generative approach. In 12th European Conference on Principles and Practice of
Knowledge Discovery in Databases, PKDD 2008, Antwerp, Belgium.
Thabtah, F., Cowling, P., and Peng, Y. (2004). Mmac: A new multi-class, multi-label
associative classification approach. In Proceedings of the 4th IEEE International
Conference on Data Mining, ICDM ’04, pages 217–224.
Trohidis, K., Tsoumakas, G., Kalliris, G., and Vlahavas, I. (2008). Multilabel clas-
sification of music into emotions. In Proc. 9th International Conference on Music
Information Retrieval (ISMIR 2008), Philadelphia, PA, USA, 2008.
Tsoumakas, G. (2005). Machine Learning for Combining Multiple, Distributed Intel-
ligent Systems. PhD thesis, Department of Informatics, Aristotle University of
Thessaloniki.
Tsoumakas, G. and Katakis, I. (2007). Multi label classification: An overview.
International Journal of Data Warehouse and Mining, 3(3):1–13.
Tsoumakas, G., Katakis, I., and Vlahavas, I. (2004). Effective Voting of Heteroge-
neous Classifiers. In Proceedings of the 15th European Conference on Machine
Learning, ECML2004, pages 465–476.
Tsoumakas, G., Katakis, I., and Vlahavas, I. (2008). Effective and efficient multilabel
classification in domains with large number of labels. In Proc. ECML/PKDD 2008
Workshop on Mining Multidimensional Data (MMD’08), pages 30–44.
Tsoumakas, G., Katakis, I., and Vlahavas, I. (2009a). Mining multi-label data.
In O. Maimon, L. R., editor, Data Mining and Knowledge Discovery Handbook
(submitted). Springer.
Tsoumakas, G., Katakis, I., and Vlahavas, I. (2009b). Random k-labelsets for multi-
label classification. IEEE Transactions on Knowledge and Data Engineering (sub-
mitted).
Tsoumakas, G. and Vlahavas, I. (2007). Random k-labelsets: An ensemble method
for multilabel classification. In Proceedings of the 18th European Conference on
Machine Learning (ECML 2007), pages 406–417, Warsaw, Poland.
Tsymbal, A. (2004). The problem of concept drift: definitions and related work.
Technical report, Department of Computer Science Trinity College.
Tumer, K. and Ghosh, J. (1996). Error correlation and error reduction in ensemble
classifiers. Connection Science, 8(3-4):385–403.
Ueda, N. and Saito, K. (2003). Parametric mixture models for multi-labeled text.
Advances in Neural Information Processing Systems 15, pages 721–728.
161
ΒΙΒΛΙΟΓΡΑΦΙΑ
Vapnik, V. N. (1995). The nature of statistical learning theory. Springer-Verlag New
York, Inc., New York, NY, USA.
Veloso, A., Wagner, M. J., Goncalves, M., and Zaki, M. (2007). Multi-label lazy
associative classification. In Proceedings of the 11th European Conference on
Principles and Practice of Knowledge Discovery in Databases (PKDD 2007), volume
LNAI 4702, pages 605–612, Warsaw, Poland. Springer.
Vlahavas, I., Kefalas, P., Bassiliades, N., Kokkoras, F., and Sakellariou, I. (2006).
Artificial Intelligence, 3rd edition. B. Gkiourdas.
Wang, H., Fan, W., Yu, P. S., and Han, J. (2003). Mining concept-drifting data
streams using ensembles classifiers. In 9th ACM SIGKDD International conference
on Knowledge Discovery and Data Mining, pages 226–235, Washington, D.C. ACM
Press.
Weiss, S., Indurkhya, N., Zhang, T., and Damerau, F. (2004). Text Mining: Predictive
Methods for Analyzing Unstructured Information. Springer.
Weiss, S. M., Apté, C., Damerau, F. J., Johnson, D. E., Oles, F. J., Goetz, T., and
Hampp, T. (1999). Maximizing text-mining performance. IEEE Intelligent Systems,
14(4):63–69.
Wenerstrom, B. and Giraud-Carrier, C. (2006). Temporal data mining in dyna-
mic feature spaces. pages 1141–1145, Los Alamitos, CA, USA. IEEE Computer
Society.
Widmer, G. and Kubat, M. (1996). Learning in the presense of concept drift and
hidden contexts. Machine Learning, 23(1):69–101.
Wieczorkowska, A., Synak, P., and Ras, Z. (2006). Multi-label classification of emo-
tions in music. In Proceedings of the 2006 International Conference on Intelligent
Information Processing and Web Mining (IIPWM’06), pages 307–315.
Wiener, E. D., Pedersen, J. O., and Weigend, A. S. (1995). A neural network ap-
proach to topic spotting. In Proceedings of SDAIR-95, 4th Annual Symposium on
Document Analysis and Information Retrieval, pages 317–332, Las Vegas, US.
Witten, I. and Frank, E. (1999). Data Mining: Practical machine learning tools with
Java implementations. Morgan Kaufmann.
Witten, I. and Frank, E. (2005a). Data Mining: Practical Machine Learning tools and
techniques, 2nd Edition. San Francisco.
Witten, I. H. and Frank, E. (2005b). Data Mining: Practical machine learning tools
and techniques. Morgan Kaufmann.
162
ΒΙΒΛΙΟΓΡΑΦΙΑ
Wolpert, D. H. (1992). Stacked generalization. Neural Netw., 5(2):241–259.
Yang, Y. (1999). An evaluation of statistical approaches to text categorization.
Journal of Information Retrieval, 1:67–88.
Yang, Y. and Pedersen, J. O. (1997). A comparative study on feature selection in
text categorization. In Fisher, D. H., editor, Proceedings of ICML-97, 14th Inter-
national Conference on Machine Learning, pages 412–420, Nashville, US. Morgan
Kaufmann Publishers, San Francisco, US.
Zhang, M.-L. and Zhou, Z.-H. (2006). Multi-label neural networks with applications
to functional genomics and text categorization. IEEE Transactions on Knowledge
and Data Engineering, 18(10):1338–1351.
Zhang, M.-L. and Zhou, Z.-H. (2007). Ml-knn: A lazy learning approach to multi-
label learning. Pattern Recognition, 40(7):2038–2048.
Zhang, Y., Burer, S., and Street, W. N. (2006). Ensemble pruning via semi-definite
programming. Journal of Machine Learning Research, 7:1315–1338.
Zhu, S., Ji, X., Xu, W., and Gong, Y. (2005). Multi-labelled classification using
maximum entropy method. In Proceedings of the 28th annual international ACM
SIGIR conference on Research and development in Information Retrieval, pages
274–281.
Zhu, X., Wu, X., and Yang, Y. (2006). Effective classification of noisy data streams
with attribute-oriented dynamic classifier selection. Knowledge and Information
Systems, 9(3):339–363.
163
Λίστα ∆ηµοσιεύσεων
΄Αρθρα σε Περιοδικά
1. I. Katakis, G. Tsoumakas, I. Vlahavas, ‘‘Tracking Recurring Contexts using
Ensemble Classifiers: An Application to Email Filtering’’, Knowledge and In-
formation Systems (accepted for publication), Springer, 2009.
2. I. Katakis, G. Tsoumakas, E. Banos, N. Bassiliades, I. Vlahavas, ‘‘An Adaptive
Personalized News Dissemination System’’, Journal of Intelligent Information
Systems, 32(2) , Springer, 2009.
3. G. Tsoumakas, I. Katakis, ‘‘Multi Label Classification: An Overview’’, Inter-
national Journal of Data Warehousing and Mining, David Taniar (Ed.), Idea
Group Publishing, 3(3), pp. 1-13, 2007.
Κεφάλαια Βιβλίων
1. I. Katakis, G. Tsoumakas, I. Vlahavas, ‘‘Email Mining: Emerging Techniques
for Email Management’’, Web Data Management Practices: Emerging Techni-
ques and Technologies, Athena Vakali, George Pallis (Ed.), Idea Group Publi-
shing, pp. 219-240, 2006.
΄Αρθρα σε Πρακτικά Συνεδρίων
1. I. Katakis, G. Meditskos, G. Tsoumakas, N. Bassiliades, I. Vlahavas, ‘‘On the
Combination of Textual and Semantic Descriptions for Automated Seman-
tic Web Service Classification’’, Proceedings of the 5th IFIP Conference on
Artificial Intelligence Applications & Innovations (AIAI 2009), Springer, Thes-
saloniki, 2009.
2. I. Katakis, G. Tsoumakas, I. Vlahavas, ‘‘Multilabel Text Classification for Au-
tomated Tag Suggestion’’, Proceedings of the ECML/PKDD 2008 Discovery
Challenge, pages 75-83, Antwerp, 2008.
3. G. Tsoumakas, I. Katakis, I. Vlahavas, ‘‘Effective and Efficient Multilabel Clas-
sification in Domains with Large Number of Labels’’, Proc. ECML/PKDD 2008
Workshop on Mining Multidimensional Data (MMD’08), pages 30-44, Antw-
erp, Belgium, 2008.
4. I. Katakis, G. Tsoumakas, I. Vlahavas, ‘‘An Ensemble of Classifiers for coping
with Recurring Contexts in Data Streams’’, pages 763-764, 18th European
Conference on Artificial Intelligence, IOS Press, Patras, Greece, 2008.
165
Λίστα ∆ηµοσιεύσεων
5. E. Banos, I. Katakis, N. Bassiliades, G. Tsoumakas, I. Vlahavas, ‘‘PersoNews:
A Personalized News Reader Enhanced by Machine Learning and Semantic
Filtering’’, 5th International Conference on Ontologies, DataBases, and Appli-
cations of Semantics (ODBASE 2006), R. Meersman, Z. Tari (Ed.), Springer-
Verlag, pp. 975-982, Montpellier, France, 2006.
6. I. Katakis, G. Tsoumakas, I. Vlahavas, ‘‘Dynamic Feature Space and Incre-
mental Feature Selection for the Classification of Textual Data Streams’’,
ECML/PKDD-2006 International Workshop on Knowledge Discovery from Da-
ta Streams, pp. 107-116, Berlin, Germany, 2006.
7. G. Tsoumakas, I. Katakis, I. Vlahavas, ‘‘A Review of Multi-Label Classification
Methods’’, 2nd ADBIS Workshop on Data Mining and Knowledge Discovery,
pp. 99-109, 2006.
8. I. Partalas, G. Tsoumakas, I. Katakis, I. Vlahavas, ‘‘Ensemble Pruning using
Reinforcement Learning’’, Proc. 4th Hellenic Conference on Artificial Intelli-
gence (SETN-06), G. Antoniou, G. Potamias, D. Plexousakis, C. Spyropoulos
(Ed.), Springer-Verlag, LNAI 3955, pp. 301-310, Heraklion, Crete, 18-20 May,
2006.
9. I. Katakis, G. Tsoumakas, I. Vlahavas, ‘‘On the Utility of Incremental Feature
Selection for the Classification of Textual Data Streams’’, 10th Panhellenic
Conference on Informatics (PCI 2005), P. Bozanis and E.N. Houstis (Eds.),
Springer-Verlag, LNCS 3746, pp. 338-348, Volos, Greece, 11-13 November,
2005.
10. G. Tsoumakas, I. Katakis, I. Vlahavas, ‘‘Effective Voting of Heterogeneous
Classifiers’’, Proc. European Conference on Machine Learning, ECML 04,
Jean-Francois Boulicaut, Floriana Esposito, Fosca Giannoti, Dino Pedreschi
(Ed.), LNAI 3201, pp. 465-476, Pisa, Italy, 2004.
Υποβληθείσες Εργασίες
1. G. Tsoumakas, I. Katakis, I. Vlahavas, "Mining Multi-label Data", Data Mining
and Knowledge Discovery Handbook, O. Maimon, L. Rokach (Ed.), Springer,
2nd edition, 2009.
2. G. Tsoumakas, I. Katakis, I. Vlahavas, "Random k-labelsets for multi-label
classification", IEEE Transactions on Knowledge and Data Engineering.
166
Λίστα Ετεροαναφορών
Σύνολο ετεροαναφορών: 73
G. Tsoumakas, I. Katakis, I. Vlahavas, ‘‘Effective Voting of Heterogeneous Classifiers’’,
Proc. European Conference on Machine Learning, ECML 04, Jean-Francois Boulicaut,
Floriana Esposito, Fosca Giannoti, Dino Pedreschi (Ed.), LNAI 3201, pp. 465-476,
Pisa, Italy, 2004.
1. A. Lallouet, A. Legtchenko, "Two Contributions of Constraint Programming to Mach-
ine Learning", In Proceedings of the 16th European Conference on Machine Learning
(ECML 2005), Porto, Portugal, October 3-7, pp. 617-624, 2005.
2. Z. Wu, C. Li, "Learning Regularized Optimal Ensembles of Classifiers", In Proceedings
of the Second HKBU-CSD Postgraduate Research Symposium, pp. 40-44
3. Γ. Συγλέτος, ¨Εξόρυξη γνώσης για εξαγωγή πληροφορίας από τον παγκόσµιο ιστό µε
χρήση τεχνικών ψηφοφορίας και συσσωρευµένης γενίκευσης¨, ∆ιδακτορική ∆ιατριβή,
Τµήµα Πληροφορικής και Τηλεπικοινωνιών, Εθνικό και Καποδιστριακό Πανεπιστήµιο
Αθηνών, Αθήνα, Νοέµβριος 2005.
4. C. Yang, S. Letourneau, "Learning to predict train wheel failures", In Proceedings of
the 11th ACM SIGKDD International Conference on Knowledge Discovery and Data
Mining, Chicago, USA, August 21-24, 2005
5. J. Sylvester and N. V. Chawla, "Evolutionary ensembles: Combining learning agents
using genetic algorithms", In AAAI Workshop on Multiagent Learning, pp. 46-51,
2005.
6. S. Bian, W. Wang, ‘‘Investigation on diversity in homogeneous and heterogeneous
ensembles’’, (2006), Proceedings 2006 IEEE International Conference on Neural Ne-
tworks, pp. 3078-3085
7. Mitchell, S. ‘‘Machine assistance in collection building: New tools, research, issues,
and reflections’’ (2006) Information Technology and Libraries, 25 (4), pp. 190-216.
8. S. Bian, W. Wang, ‘‘On diversity and accuracy of homogeneous and heterogeneous
ensembles’’, (2007) International Journal of Hybrid Intelligent Systems 4, pp. 103-
128
9. Lallouet, A., Legtchenko, A. ‘‘Building consistencies for partially defined constraints
with decision trees and neural networks’’ (2007) International Journal on Artificial
Intelligence Tools, 16 (4), pp. 683-706
10. P. Luo, H. Xiong, K. Lau and Z. Shi, "Distributed Classification in Peer-to-Peer Netw-
orks", Proc. KDD 2007 (accepted)
11. Saha, S., Murthy, C.A., Pal, S.K. ‘‘Rough set based ensemble classifier for Web page
classification’’ (2007) Fundamenta Informaticae, 76 (1-2), pp. 171-187.
12. Chunsheng Yang and Sylvain Letourneau, "Two-stage classifications for improving
time-to-failure estimates: a case study in prognostic of train wheels", Applied Intelli-
gence, Springer, 2008.
167
Λίστα Ετεροαναφορών
13. W. Pedricz, P. Rai, J. Zurada, "Experience-conistent modeling for radial basis funtion
neural networks", International Journal of Neural Systems (IJNS), 18(4), pp 279-292,
August 2008.
14. Gonzalo Martinez-Munoz, Daniel Hernadez-Lobato and Alberto Suarez, An Analysis
of Ensemble Pruning Techniques Based on Ordered Aggregation, Transactions on
Pattern Analysis and Machine Intelligence, IEEE, 2008.
I. Katakis, G. Tsoumakas, I. Vlahavas, ‘‘On the Utility of Incremental Feature Sele-
ction for the Classification of Textual Data Streams’’, 10th Panhellenic Conference
on Informatics (PCI 2005), P. Bozanis and E.N. Houstis (Eds.), Springer-Verlag, LNCS
3746, pp. 338-348, Volos, Greece, 11-13 November, 2005.
1. B. Wenerstrom, ‘‘Temporal data mining in a dynamic feature space’’, MSc Thesis,
Brigham Young University, Provo, UT, USA, May 2006
2. B. Wenerstrom, C. Giraud-Carrir, ‘‘Temporal Data Mining in Dynamic Feature Spa-
ces’’, Proc. Int. Conf. on Data Mining, pp. 1141-1145, Hong Kong, 18-22 December,
2006
3. S. Gunal, S. Ergin, M.B. Gulmezoglu, O.N. Gerek, ‘‘On Feature Extraction for Spam
E-Mail Detection’’, Proc. International Workshop on Multimedia Content Represen-
tation, Classification and Security, MRCS 2006, Istanbul, Turkey, September 11-13,
2006, (LNCS Vol. 4105/2006, pp 635-642)
4. Ανυφαντής ∆., Αυτόµατο Φιλτράρισµα ανεπιθύµητης ηλεκτρονικής αλληλογραφίας µε
χρήση µεθόδων µηχανικής µάθησης, Μεταπτυχιακή Εργασία, Τµήµα Μηχανικών Η/Υ,
Πανεπιστήµιο Πατρών, 2008.
5. C. Rohr, D. Tjondronegoro, "Aggregated cross-media news visualization and perso-
nalization", Proceeding of the 1st ACM international conference on Multimedia infor-
mation retrieval, p. 371-378, Vancouver, British Columbia, Canada, 2008.
G. Tsoumakas, I. Katakis, I. Vlahavas, ‘‘A Review of Multi-Label Classification Me-
thods’’, 2nd ADBIS Workshop on Data Mining and Knowledge Discovery, pp. 99-109,
2006.
1. K. Brinker, E. Hullermeier, "Case-Based Multilabel Ranking", Proc. International
Joint Conference on Artificial Intelligence (IJCAI 07), pp. 702-707, Hyderabad, India,
January 6-12, 2007.
2. Yang, S., Kim, S.-K., Ro, Y.M. ‘‘Semantic home photo categorization’’, (2007) IEEE
Transactions on Circuits and Systems for Video Technology, 17 (3), pp. 324-335.
I. Katakis, G. Tsoumakas, I. Vlahavas, ‘‘Dynamic Feature Space and Incremental Fe-
ature Selection for the Classification of Textual Data Streams’’, ECML/PKDD-2006
International Workshop on Knowledge Discovery from Data Streams, pp. 107-116,
Berlin, Germany, 2006.
1. Kim, H.J., Chang, J.: Integrating incremental feature weighting into naive bayes text
classifier, Proc. 6th International Conference on Machine Learning and Cybernetics
(ICMLC 2007), Volume 2, 2007, pp. 1137-1143.
168
Λίστα Ετεροαναφορών
2. Chih-Chin, L, Chih-Hung, W, Ming-Chi, T. (2009) Feature selection using particle
swarm optimization with application in spam filtering, International Journal of Inno-
vative Computing, Information and Control, Volume 5, Issue 2, February 2009, Pages
423-432
3. Kim, Han-Joon and Chang, Jae-Young, "Improving Naive Bayes Text Classifiers with
Incremental Feature Weighting", KIPS Transactions, Korea Information Processing
Society, b15 (5), pp. 457-464, 2008
4. Han-Joon Kim, "Improving Techniques for Naive Bayes Text Classifiers", in Handbook
of Research on Text and Web Mining Technologies, Min Song & Yi-Fang We (Eds), pp.
111-127, Idea Group, 2009.
I. Katakis, G. Tsoumakas, I. Vlahavas, ‘‘Email Mining: Emerging Techniques for Email
Management’’, Web Data Management Practices: Emerging Techniques and Techno-
logies, Athena Vakali, George Pallis (Ed.), Idea Group Publishing, pp. 219-240, 2006.
1. X. Zhang, J. Liu, Y. Zhang, C. Wang. "Spam behavior recognition based on session
layer data mining", Proc. 3rd Int. Conf. on Fuzzy Systems and Knowledge Discovery
(FSKD 2006), LNAI 4223, pp 1289-1298, 2006.
2. Xie De-Ping. "A Study Report for Mining Email", Journal of Software, 2006,15(9)1200-
1210.
3. G. Cselle. "Organizing Email", MSc Thesis, Department of Computer Science and
Electrical Engineering, ETH Zurich, Switzerland, 2006.
4. Berendt, B. & Draheim, M. (2007). The Image of Germany in the World: An Email
and Web Mining Approach. Ku"nstliche Intelligenz, 3/07, 30-36.
I. Partalas, G. Tsoumakas, I. Katakis, I. Vlahavas, ‘‘Ensemble Pruning using Reinforce-
ment Learning’’, Proc. 4th Hellenic Conference on Artificial Intelligence (SETN-06),
G. Antoniou, G. Potamias, D. Plexousakis, C. Spyropoulos (Ed.), Springer-Verlag, LNAI
3955, pp. 301-310, Heraklion, Crete, 18-20 May, 2006.
1. Chan P.P.K., Xiaoqin Zeng, Tsang E.C.C., Yeung D.S., Lee J.W.T., "Neural network
ensemble pruning using sensitivity measure in web applications," Proc. IEEE Interna-
tional Conference on Systems, Man and Cybernetics, 7-10 Oct. 2007, pp.3051-3056
2. C. Dimitrakakis, "Ensembles for sequence learning", PhD Thesis, Ecole Polytechnique
Federale de Lausanne (EPFL), Switzerland, 2007.
3. D. Kalles. ‘‘Measuring Expert Impact on Learning how to Play a Board Game’’, Proc.
4th IFIP Conference on Artificial Intelligence Applications and Innovations, Athens,
Greece, September, 2007.
4. D. Kalles. ‘‘Player Co-Modelling in a Strategy Board Game: Discovering how to Play
Fast’’, (to appear in the journal) Cybernetics and Systems, 2007
5. Dimitris Kalles and Christos Kalantzis "Evolving Computer Game Playing via Human-
Computer Interaction: Machine Learning Tools in the Knowledge Engineering Life-
Cycle, in Knowledge-based Software Engineering, Maria Virvou and T. Nakamura
(Eds), pages 59-68, IOS Press, 2008.
169
Λίστα Ετεροαναφορών
6. Gonzalo Martinez-Munoz, Daniel Hernadez-Lobato and Alberto Suarez, An Analysis
of Ensemble Pruning Techniques Based on Ordered Aggregation, Transactions on
Pattern Analysis and Machine Intelligence, IEEE, 2008.
7. Kalles, D., Kanellopoulos, P. (2008) A Minimax Tutor for Learning to Play a Board
Game, Proc. ECAI ’’08 Workshop on Artificial Intelligence in Games, Patras, Greece,
pp. 10-14
E. Banos, I. Katakis, N. Bassiliades, G. Tsoumakas, I. Vlahavas, ‘‘PersoNews: A Per-
sonalized News Reader Enhanced by Machine Learning and Semantic Filtering’’, 5th
International Conference on Ontologies, DataBases, and Applications of Semantics
(ODBASE 2006), R. Meersman, Z. Tari (Ed.), Springer-Verlag, pp. 975-982, Montpel-
lier, France, 2006.
1. Γ. Γιαννακόπουλος, Α. Γκουβούση, Π. Μπέλσης, Γ. Παλιούρας, Χ. Παπαθεοδώρου, Α.
Ρόδη, Χ. Σκουρλάς, ¨Εξατοµίκευση ∆ιδασκαλίας και Πληροφόρησης στην Ανώτατη Εκ-
παίδευση¨, ε-Περιοδικό Επιστήµης & Τεχνολογίας (e-Journal of Science & Technology
/ e-JST), Directory of Open Access Journals, 2(3), pp. 1-18, 2007.
2. Diletta Leone, "Progettazione e sviluppo di un software per la visualizzazione di cluster
di news", Laurea Specialistica in Ingegneria Informatica, Universita degli Studi di
Modena e Reggio Emilia Facolta di Ingegneria di Modena, 2008.
3. Lucas Drumond, Rosario Girardi, "A multi-agent legal recommender system", Artifi-
cial Intelligence and Law.
4. Giannikopoulos, P., Varlamis, I., Eirinaki, M. (2008) Mining frequent generalized
patterns for Web personalization, ECAI 2008 Workshop on Mining Social Data (MSo-
Da’’08), pp. 11-15.
5. C. Bouras, V. Tsogkas, "Personalization Mechanism for Delivering News Articles on
the User’s Desktop", The Fourth International Conference on Internet and Web Ap-
plications and Services - ICIW 2009, Venice, Italy, 24 - 28 May 2009.
G. Tsoumakas, I. Katakis, ‘‘Multi Label Classification: An Overview’’, International
Journal of Data Warehousing and Mining, David Taniar (Ed.), Idea Group Publishing,
3(3), pp. 1-13, 2007.
1. Kanoksri Sarinnapakorn, ‘‘Induction of Classifiers from Multi-labeled Examples: An
Information-Retrieval Point of View’’, PhD Dissertation, University of Miami, 2007.
2. Stephan Spat, ‘‘Prototype of a Medical Information Retrieval System for Electronic
Patient Records’’, MSc Thesis, Graz University of Technology, Austria, March 2007.
http://www.iicm.tu-graz.ac.at/thesis/D:
3. Andorf, C., Dobbs, D. and Honavar, V. (2007). Exploring Inconsistencies in Genome
Wide Protein Function Annotations: A Machine Learning Approach. BMC Bioinfor-
matics 2007, 8:284 doi:10.1186/1471-2105-8-284.
4. Shu-Peng Wan, Jian-Hua Xu, "A multi-label classification algorithm based on triple
class support vector machine", in Wavelet Analysis and Pattern Recognition, 2007
(ICWAPR ’07). p. 1447-1452
170
Λίστα Ετεροαναφορών
5. Miyao, Y., Tsujii , J. (2008) Exact Inference for Multi-label Classification using Sparse
Graphical Models, Proc. of the 22nd International Conference on Computational
Linguistics (Coling 2008), pp. 63-66
6. Yang Song, Lu Zhang, C. Lee Giles, Sparse Gaussian Processes Classification for Fast
Tag Recommendation", in Proceedings of ACM 17th Conference on Information and
Knowledge Management (CIKM 2008), Napa Valley, California, USA. October 2008.
7. Liu C.-L. (2008) Partial discriminative training for classification of overlapping classes
in document analysis, International Journal on Document Analysis and Recognition,
Volume 11, Issue 2, 2008, Pages 53-65
8. B. Jin, B. Muller, C. Zhai, X. Lu, "Multi-label literature classification based on the
Gene Ontology graph", BMC Bioinformatics 2008, 9:525.
9. Furnkranz, J., Hullermeier, E., Loza Mencia, E., Brinker, K. (2008) ‘‘Multilabel clas-
sification via calibrated label ranking’’, Machine Learning, 73 (2), pp. 133-153.
10. M.-L. Zhang and Z.-H. Zhou. M3MIML: A maximum margin method for multi-
instance multi-label learning. In: Proceedings of the 8th IEEE International Con-
ference on Data Mining (ICDM’08), Pisa, Italy, 2008
11. Tenenbaum Lena, Shapira B., Shoval P., Ontology-Based Classification of News in an
Electronic Newspaper, ITA 2008, Varna, Bulgaria, (2008).
12. Wang, Z., Siu, W.-C., and Feng, D. (2008)." Image annotation with parametric mixture
model based multi-class multi-labeling". In 2008 IEEE 10th Workshop on Multimedia
Signal Processing, pages 634-639.
13. Woolam, C, Khan, L. (2008) " Multi-label large margin hierarchical perceptron" Int.
J. Data Mining, Modelling and Management, Vol. 1, No. 1, pp. 5-22
14. Vens, C., Struyf, J., Schietgat, L., Dzeroski, S., Blockeel, H. (2008) ‘‘Decision trees
for hierarchical multi-label classification’’ Machine Learning, 73 (2), pp. 185-214.
15. Park S-H, Furnkranz J., Multi-Label Classification with Label Constraints, Technical
Report TUD-KE-2008-04, Technische Universitat Darmstadt, 2008
16. R. T. Alves, V. Bevilacqua, M. Delgado, A. A. Freitas, G. Mastronardi, F. Menolascina,
G. Nicosia, A. Paradiso, S. Tommasi, (2008) Artificial Immune Systems in Bioinfor-
matics, in Computational Intelligence in Biomedicine and Bioinformatics: Current
Trends and Applications, Smolinski T.G., Milanova M.G., Hassanien A. (Eds), Sprin-
ger, New York, NY, USA, pp. 305-330, 2008.
17. EL-Manzalawy Y, Dobbs D, Honavar V 2008 On Evaluating MHC-II Binding Peptide
Prediction Methods. PLoS ONE 3(9): e3268 doi:10.1371/journal.pone.0003268
18. Liu, Cheng-Lin. "Partial Discriminative Training of Neural Networks for Classification
of Overlapping Classes", in proceedings of the Thrid IAPR Workshop, Artificial Neural
Networks in Pattern Recognition, ANNPR 2008, Paris, France, July 2-4, 2008
19. Andreas Hess, Philipp Dopichaj and Christian Maass, Multi-Value Classification of
Very Short Texts, Proc. 31st Annual German Conference on Artificial Intelligence.
171
Λίστα Ετεροαναφορών
20. Kawai, K., Fujishima, S., Takahashi, Y. (2008) Predictive activity profiling of drugs by
topological-fragment-spectra- based support vector machines, Journal of Chemical
Information and Modeling, 48 (6), pp. 1152-1160.
21. Vallim, R. M., Goldberg, D. E., Llora‘, X., Duque, T. S., and Carvalho, A. C. (2008).
A new approach for multi-label classification based on default hierarchies and or-
ganizational learning. Proc. 2008 GECCO Conference Companion on Genetic and
Evolutionary Computation (Atlanta, GA, USA, July 12 - 16, 2008), 2017-2022.
22. Alves, R.T., Delgado, M.R., and Freitas, A.A. (2008). Multi-label hierarchical classifi-
cation of protein functions with artificial immune systems. In Proc. Third Brazilian
Symposium on Bioinformatics (BSB-2008), pp. 1-12. Lecture Notes in Bioinformatics
5167, Springer, 2008.
23. Andreas Hess, Christian Maass and Francis Dierick (2008). From Web 2.0 to Seman-
tic Web: A Semi-Automated Approach, Proc. ESWC 2008 Workshop on Collective
Semantics: Collective Intelligence and the Semantic Web (CISWeb 2008).
24. Park, S.-H. and Furnkranz, J. (2008). Multi-label classification with label constraints.
In Hullermeier, E. and Furnkranz, J., editors, Proceedings of the ECML/PKDD-08
Workshop on Preference Learning (PL-08), pages 157-171, Antwerp, Belgium.
25. Streich, A.P, Buhmann J. M. (2008) Classification of Multi-labeled Data: A Generative
Approach. In Proc. ECML/PKDD 2088, pp. 390-405
26. Y.-C. Lin, Y.-H. Yang, and H.-H. Chen, "Exploiting genre for music emotion classifi-
cation", in Proc. IEEE Int. Conf. Multimedia and Expo. 2009 (ICME’09), Cancun,
Mexico.
27. Gaurav Pandey, Chad L. Myers, Vipin Kumar, "Incorporating functional inter-
relationships into protein function prediction algorithm", BMC Bioinformatics 2009,
10:142
28. Lei Tang, Suju Rajan and Vĳay K. Narayanan, Large Scale Multi-Label Classification
via MetaLabeler, WWW 2009
I. Katakis, G. Tsoumakas, I. Vlahavas, ‘‘An Ensemble of Classifiers for coping with
Recurring Contexts in Data Streams’’, pages 763-764, 18th European Conference on
Artificial Intelligence, IOS Press, Patras, Greece, 2008
1. Zliobaite., I. and Krilavicius, T. CLAN: Clustering for Credit Risk Assessment, Tech-
nical Report, Vilnius University, Department of Informatics, 2009.
G. Tsoumakas, I. Katakis, I. Vlahavas, ‘‘Effective and Efficient Multilabel Classifica-
tion in Domains with Large Number of Labels’’, Proc. ECML/PKDD 2008 Workshop on
Mining Multidimensional Data (MMD’08), pages 30-44, Antwerp, Belgium, 2008.
1. Eneldo Loza Mencia, Sang-Hyeun Park, Johannes Furnkranz, "Advances in Efficient
Pairwise Multilabel Classification", Technical Report TUD-KE-2008-06, Knowledge
Engineering Group, Technische Universita"t Darmstadt, 2008.
I. Katakis, G. Tsoumakas, I. Vlahavas, ‘‘Multilabel Text Classification for Automated
Tag Suggestion’’, Proceedings of the ECML/PKDD 2008 Discovery Challenge, pages
75-83, Antwerp, 2008.
172
Λίστα Ετεροαναφορών
1. Eneldo Loza Mencia, Sang-Hyeun Park, Johannes Furnkranz, "Advances in Efficient
Pairwise Multilabel Classification", Technical Report TUD-KE-2008-06, Knowledge
Engineering Group, Technische Universita"t Darmstadt, 2008.
2. Lei Tang, Suju Rajan and Vĳay K. Narayanan, Large Scale Multi-Label Classification
via MetaLabeler, WWW 2009
173
