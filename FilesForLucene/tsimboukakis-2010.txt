ORIGINAL ARTICLE
A comparative study on authorship attribution classification tasks
using both neural network and statistical methods
Nikos Tsimboukakis • George Tambouratzis
Received: 29 January 2009 / Accepted: 15 October 2009 / Published online: 1 November 2009
 Springer-Verlag London Limited 2009
Abstract The present paper investigates the application
of the multi-layer perceptron (MLP) to the task of cate-
gorizing texts based on their authors’ style. This task is of
particular importance for information retrieval applications
involving very large document databases. The emphasis of
this article is to determine the extent to which the MLP
model can be fine-tuned to successfully analyse such data,
uncovering the stylistic differences among authors. The
MLP-based method is compared and contrasted to statis-
tical techniques, such as discriminant analysis, that are
widely used in stylistic studies. The comparison of the
methods is based on their classification performance, to
provide an objective evaluation of the advantages of each
method. A second aim of the study presented here is to
compare the effectiveness of distinct features in the task of
uncovering the author identity for each method. To eval-
uate to a greater depth the effectiveness of the entire
approach, the results of the proposed MLP-based method
are compared to those of established approaches, such as
the support vector machines (SVM), using both the original
parameters employed by the MLP as well as term fre-
quency–inverse document frequency (TF–IDF) parameters,
and the cascade correlation approach. It is found that the
proposed MLP-based approach possesses a number of
advantages, such as high classification accuracy, broadly
comparable to that of the SVM, coupled with the ability to
algorithmically reduce the set of parameters used without
adversely affecting the classification accuracy.
Keywords Document classification  Neural networks 
Feature selection
1 Introduction
Currently, databases containing vast collections of digi-
tized documents are becoming available for general-pur-
pose information retrieval tasks. The amalgamation of
existing, diverse document collections allows users to
obtain more precise results to specialized queries. How-
ever, to be of use in information retrieval tasks, such
document collections need to be organized and annotated
efficiently. In most cases, the document collections are not
extensively indexed, while the range of indices that can be
generated automatically is limited. As document collec-
tions are expanded to include the wealth of documents
written in the past, the manual indexing of documents
becomes a major bottleneck. Even when indices supporting
information retrieval are provided, the set of indices
available remains unavoidably limited. Therefore, when a
user accesses these databases with the intention of locating
documents relevant to his query, the retrieved documents
tend to be excessively large in number and wide in scope.
Furthermore, in many cases, the user may wish to select
documents based on several criteria, of which content is
only one. In such cases, information regarding the style in
which the document is composed may improve the preci-
sion of the search, when compared to using only content-
related information, leading to search results that conform
more closely to the requirements of the user. The manual
categorization of documents and the discrimination of their
authors are a labour-intensive task, in particular when
processing large amounts of data. Thus, for information
retrieval applications, it is essential to incorporate
N. Tsimboukakis (&)  G. Tambouratzis
Institute for Language and Speech Processing,
Artemidos 6 & Epidavrou, Maroussi 151 25, Greece
e-mail: ntsimb@ilsp.gr; nikosilsp@yahoo.com
123
Neural Comput & Applic (2010) 19:573–582
DOI 10.1007/s00521-009-0314-7
automated tools that are able to distinguish the texts
according to the particular linguistic characteristics of their
authors’ writing style, allowing the generation and utili-
zation of the appropriate search indices.
The majority of researchers investigating author dis-
crimination tasks have employed statistical techniques (see
for example [1–3]). Neural network models have also been
used, with most studies focussing on the multi-layer per-
ceptron (MLP) [4], the radial-basis function (RBF) [5] and
the self-organizing map (SOM) [6]. Both the MLP and
RBF models rely on the provision of labelled training
patterns to distinguish between two or more classes of
objects. On the contrary, the SOM operates on the basis of
the similarity between patterns, creating classes of the most
similar patterns.
Here, the MLP neural network model [7] is applied to
the task of separating a set of documents based on their
authors’ style. In an earlier study, Holmes et al. [4] adopted
a basic MLP architecture, trained with a simple back-
propagation-training algorithm, without focusing on
determining the appropriate hidden-layer size for the MLP.
The main purpose of the present study is to improve the
MLP model usage, by adopting an enhanced training and
architecture selection procedure, which can also be used for
feature ranking and selection. An additional aim is to
compare the effectiveness of this procedure to widely used
statistical classification methods for author discrimination
tasks, such as discriminant analysis [2, 8, 9]. Hence, for a
given set of texts produced by a group of known authors,
the aim is to determine the identity of the author of each
text. The experiments reported here represent the contin-
uation of a series of studies on stylistics, which have
focused on (1) separating between different registers of the
Greek language (the term register determining a category
of texts defined by their origin and content) and (2) sepa-
rating a set of documents according to the style of their
author [9], using mainly statistical classification methods.
In the present article, the MLP model is applied to the task
of author style classification, in order to determine how its
accuracy compares to that of established statistical meth-
ods. The main focus of the present study is whether a
neural network such as MLP can achieve superior classi-
fication accuracy when compared to that of the statistical
models formerly used [9].
2 The MLP neural network
The MLP is the most widely used neural network. It has a
layered structure, where the output of each layer forms the
input to the next layer through synaptic weights. Each layer
consists of perceptron units that process their input signals
through a non-linear activation function. It has been
reported that a single, sufficiently large hidden layer
enables the MLP to implement any input-to-output map-
ping. Therefore, the MLP studied here contains three layers
of perceptrons. These employ the hyperbolic tangent acti-
vation function that improves the speed of convergence and
the classification accuracy of the network.
In comparison with other neural network models, the
MLP possesses a number of advantages, such as a good
recognition accuracy in high-dimensional problems and a
fast convergence, in particular with more advanced batch-
learning techniques such as those described in the
remainder of this section. Since the MLP generates con-
tinuous numerical outputs, it can solve classification
problems, providing a confidence measure of the decision
certainty. When used as a classifier, the MLP divides the
pattern space via hyperplanes. MLP is robust with respect
to its parameters since small changes in their values result
in small changes in the decision hyperplanes. On the other
hand, known disadvantages of the MLP include the diffi-
culty of defining the optimal number of hidden neurons for
a given task and the activation function that will lead to the
optimal recognition performance. Additionally, the family
of backpropagation-learning algorithms requires the esti-
mation of a large number of derivatives. Usually, MLP
training tends to lead to overtrained networks when a
validation set is not used, resulting in a poor generalization
performance. MLP networks usually cannot provide solid
justification for the outputs they generate even though this
drawback can be overcome to some extent by using fuzzy
logic theory [10].
In most applications, to train the MLP, the network
weights are adapted using the supervised backpropagation-
training algorithm. This optimization technique minimizes
the mean square error (Mse) between the desired and actual
network output over the training set:
MseðNet;DÞ ¼ E D Yk k2
n o
ð1Þ
where D is the desired output vector, and Y is the network
output vector. Backpropagation depends on estimating
error signals over the network for each weight. Several
backpropagation variants have been developed by using
standard optimization techniques.
Here, the Levenberg–Marquardt (LM) [7] backpropa-
gation variant is chosen, which is a least squares optimi-
zation technique. This algorithm combines the strengths of
the gradient descent method and the Newton algorithm,
selecting each of the two algorithms depending on the error
surface search space, to converge quickly and accurately
towards a local optimal solution. More specifically, the
gradient descent algorithm performs generally a faster
search of the pattern space and becomes slow only near
local minima, where the Newton method is appreciably
574 Neural Comput & Applic (2010) 19:573–582
123
faster. Since the LM algorithm is a batch-training algo-
rithm, weight updates occur only after the whole training
set has been processed by the network, improving the
stability of the learning process. Assuming that Wt is the
weight vector at training epoch t, Jt is the Jacobian matrix
of the first-order derivatives of the error function for all
training examples, I is the identity matrix, and et represents
the network’s output error vector, the LM algorithm is
formulated as follows:
Wtþ1 ¼ Wt  ½JTt Jt þ lI
1JTt et ð2Þ
To avoid the deterioration of the MLP’s generalization
capability over unseen data, two strategies are adopted.
First, a portion of the training data is extracted to form a
validation set. When the network performance over this
validation set decreases for a given number of successive
training epochs (six in the experiments reported here), the
training process is terminated. Secondly, the network
architecture is kept as simple as possible in terms of the
number of weights and weight values. In order to simplify
the architecture, a modified performance criterion is
adopted that punishes networks with large weight values:
ErrorðNet;DÞ ¼ aE D Yk k2
n o
þ b WT W
  ð3Þ
where W is the weight vector, and a, b are parameters
chosen to emphasize classification performance (if a  b)
or network simplicity (if a  b), D is the matrix contain-
ing the desired network responses, and Y is the matrix
containing the actual network responses.
An improved variant of the backpropagation method is
the Bayesian regulation backpropagation [11] that com-
bines criterion (3) with a Bayesian interpolation technique
to estimate optimal values of a and b at each step. Bayesian
regulation backpropagation provides an estimate of the
effective number of parameters of the trained network,
reflecting the network size required to classify the data. To
efficiently initialize weights, the Nguyen–Widrow initiali-
zation technique [12] assigns weight values so that the
node output signals are uniformly distributed near the
activation function centre point and over its active range.
3 Dataset and features
For this study, the dataset chosen comprises texts from the
Minutes of the Greek Parliament. The Minutes comprise a
large amount of texts spanning almost two centuries, which
are edited via a well-established procedure by specialized
personnel and are available in electronic format. Five
speakers have been chosen, one from each political party
represented in the Parliament over the period 1996–2000.
For each speaker, all speeches throughout this specific
period have been extracted from the Minutes to form the
dataset.
The length of speeches from the dataset varies consid-
erably. Still, throughout the experiments only entire spee-
ches have been studied, without any processing aimed at
homogenizing their size, since parts of a given text fre-
quently present different properties in comparison with the
entire text. The corpus contains 1,004 texts, thus providing
a realistic test of the MLP’s ability to cluster large textual
datasets.
For each speech, a set of 85 features has been extracted
in an automated manner, covering a variety of linguistic
aspects as detailed in Tambouratzis et al. [9]. In order to
count the feature values a fully automatic program utility
has been developed, which operates on texts that have been
previously tagged and lemmatized using the tagger—
lemmatizer described by Papageorgiou et al. [13]. Then,
each text is processed by the program utility and is con-
verted into a vector of features, thus being mapped into a
pattern space whose dimensionality is equal to that of the
features selected.
The features chosen are to a large extent defined by the
task to be performed. The requirement to identify the
author style makes the use of term frequency–inverse
document frequency (TF–IDF) features less appropriate,
since these features are based on the frequency of use of
specific terms and thus reflect to a large extent the content.
On the contrary, the set of 85 features selected here com-
prises a wider range of linguistically motivated features
that reflect different aspects of the author style. These
features are divided into the following groups:
• Verbal: 22 verb-related features, which indicate the
manner in which an individual expresses himself, (1)
using verb forms of a given number/person combina-
tion and (2) choosing between the two language
variants of Modern Greek (Katharevoussa and
Demotiki).
• Part-of-Speech (PoS): eleven features, which corre-
spond to the frequencies of occurrence of ten gram-
matical categories (e.g., noun, adverb or verb),
augmented by an additional class for words, which fail
to be classified into one of the categories.
• Structural: 27 features, recording the histogram distri-
bution of (1) word length in terms of letters and (2)
sentence length in terms of words, as well as the
frequency of (3) specific linguistic microstructures and
of (4) several punctuation marks.
• Negation: Eight features, recording the frequency-of-
occurrence of the most common words expressing
negation in the Greek language.
• Lemma related: Seventeen features, recording the
occurrences of specific words/lemmas. These lemmas
Neural Comput & Applic (2010) 19:573–582 575
123
have been selected via an algorithmic procedure, on the
basis of a sample of texts from different speakers so
that they consistently present a low order-of-occurrence
for at least one speaker and a high order-of-occurrence
for at least one other speaker.
4 Experiments
4.1 Experimental setup
The MLP model is applied here to the task of classifying
speeches in accordance with their author style. Given that a
single hidden layer is used, with 85 inputs (equal to the
number of features) and five outputs (the number of
speakers), the number of required hidden nodes may be
estimated, as detailed in the following [11]. For the feature
vector, the total number of weights and biases in the hidden
layer is equal to (85 ? l)h, where h is the number of hidden
nodes. Five output nodes are used, each receiving as inputs
the outputs of the h hidden-layer nodes and thus having
h weights and one bias parameter. Hence, the total
number of parameters in the network, Sp, is expressed as a
function of h:
Sp ¼ ð85þ 1Þhþ ðhþ 1Þ5 ¼ 91hþ 5 ð4Þ
Utilizing the Bayesian regulation method for a network
with 12 hidden nodes (expected to be larger than strictly
necessary) for 300 epochs over the training set, the network
settled to a configuration with a total of 420 effective
parameters. In these initial experiments, it should be noted
that no cross-validation was used as at this point it sufficed
to estimate the number of effective parameters associated
with the complexity of the desired classification. Solving
(4) results in a value of the effective number of parameters
h equal to 4.56. The solution of (4) provided just a starting
point for determining the number of neurons in the hidden
layer. By approximating the number of neural network
weights and biases with the effective number of parameters
calculated and taking into account that network weights do
not adapt or act completely independently, formula (4) is
only a rough estimate of the number of required hidden
neurons h. Since backpropagation doesn’t independently
adapt perceptron weights so as to create a minimal-sized
network, a range of more complex neural networks should
also be tested. To that end, different architectures com-
prising from 5 to 15 neurons were selected for
experimentation.
For all experiments, the data set was separated into ten
subsets of equal size. Eight of the subsets were used for
training the network, one for validation during training and
the last one as a test set to evaluate the network
classification performance. For each architecture, all pos-
sible combinations of sets were run (giving a total of 10
(10 - 1) = 90 unique combinations) so that the training
set, the validation set and the test set remained disjoint. The
results reported hereafter always refer to the classification
accuracy over the previously unseen test set, averaged over
the 90 different combinations.
4.2 The effect of feature reduction on the classification
accuracy
Taking into account that the error criterion of (3) forces the
MLP network to reduce its weight values, the importance
of each input feature is reflected by the magnitude of the
weights that connect the input with hidden-layer neurons.
A measure indicative of each feature importance, Sj, is:
Sj ¼ E
Xh
i¼1
wij
 
( )
ð5Þ
where j is the corresponding feature, wij is the weight that
connects the jth feature with the ith hidden neuron, h is the
number of neurons in the hidden layer, and E denotes the
average value among all possible set combinations.
Following the application of (5) to the experimental
data, features were ordered according to their importance
and then were removed in steps of 20%, starting from the
less important ones and for each feature vector a new MLP
network was trained. The classification performance over
the test set for MLPs with various hidden-layer sizes is
shown in Fig. 1, together with the respective results
obtained using statistical discriminant analysis (this being
the best-performing statistical method, according to earlier
published experiments, cf. [9]).
84,0%
85,0%
86,0%
87,0%
88,0%
89,0%
90,0%
91,0%
92,0%
0% 20% 40% 60% 80%
% feature vector reduction
cl
as
si
fi
ca
ti
o
n
 a
cc
u
ra
cy
5 hidden nodes - OM
6 hidden nodes - OM
7 hidden nodes - OM
8 hidden nodes - OM
9 hidden nodes - OM
10 hidden nodes - OM
11 hidden nodes - OM
12 hidden nodes - OM
13 hidden nodes - OM
14 hidden nodes - OM
15 hidden nodes - OM
Discriminant. An. - OM
Fig. 1 Average classification accuracy over the test set (averaged
over 90 independent runs) for MLP neural networks with between 5
and 15 hidden neurons and discriminant analysis, as a function of the
fraction of features removed from the original 85 feature vector (OM)
576 Neural Comput & Applic (2010) 19:573–582
123
The best MLP classification accuracy (90.5%) was
achieved when 40% of the features were removed. It
should be noted that this MLP value is greater than the
highest accuracy achieved with a statistical method
(namely discriminant analysis using the full model which
was equal to 89.1% [9]). As the fraction of removed fea-
tures reaches and exceeds 60%, the classification accuracy
for both MLP and discriminant analysis deteriorates con-
siderably, indicating the removal of salient features. Dis-
criminant analysis proves to be more sensitive to feature
removal as its accuracy decreases more rapidly than that of
the MLP in all cases. Among MLP networks, the 12 hidden
node MLP performs best, although all networks have a
broadly comparable performance that peaks at between
89.5 and 90.5%. To that end, in the remainder of this
article, the most efficient MLP networks with five, six and
seven hidden nodes are studied in more detail.
This is of particular importance since discriminant
analysis has been used in several stylistics studies (such as
author identification) as a benchmark for the recognition
accuracy (e.g., [2, 8, 9]). The fact that the MLP model
achieves a higher accuracy than discriminant analysis for a
wide range of feature vectors indicates the appropriateness
of the proposed method in comparison with discriminant
analysis.
To evaluate the two methods’ performance in more
detail, a comparison is performed of the composition of the
input vector in the cases of the stepwise discriminant
analysis [9] and the MLP models presented previously. The
features retained in the model are ordered (1) according to
their importance as measured by (5) for the MLP and (2)
according to the f-to-remove parameter for the stepwise
discriminant analysis. The percentage of the M most salient
features of the discriminant analysis that are also included
within the M most important features in the MLP models is
depicted in Fig. 2. For instance, when 40% percent of the
features are removed (and thus 51 features are retained in
the feature vector), over 70% of the most salient MLP
features are also included in the reduced discriminant
model. Using MLP networks with five, six or seven hidden
nodes, when removing 20% of features, the fraction of
retained features common to discriminant analysis ranges
between 85 and 90%. This indicates that the retained fea-
tures convey similar information regarding author style in
both methods. However, when more than 20% of the fea-
tures are removed, the fraction of common features for the
two methods decreases substantially. On the other hand,
the similarity of the vectors of features retained by MLP
networks with different numbers of hidden neurons is
substantially higher, since the percentage of common fea-
tures are at least 85% and in most cases surpasses 94% as
measured in experiments. This indicates that when smaller
feature vectors are chosen, different features are selected
by the MLP models in comparison with discriminant
analysis. In this case, as testified by the results summarized
in Fig. 1, MLP selects a more salient set of features, thus
resulting in higher classification accuracy.
The effective number of parameters, as estimated by
the Bayesian Regulation (LMBR) procedure (over all
validation and test set combinations) after the training
completion, is presented in Table 1. The maximum
number of effective parameters is achieved for the MLP
with only 7 hidden neurons. By increasing the number of
hidden neurons further, the number of effective parame-
ters doesn’t change substantially. On the other hand, the
classification accuracy improves by a small amount (at
most 1%) and peaks when 12 hidden neurons are selected.
This is due to the fact that the effective number of
parameters isn’t necessarily identical to the number of
retained weights within the network. The MLP network
weights cannot be independently adapted since multiple
weights stimulate the same neuron at the next layer.
Additionally, the training procedure adopted imposes
weight decay on the network, thus simplifying the ini-
tially selected architecture and protecting the network’s
generalization ability. This is the reason why the effective
number of parameters doesn’t increase when the actual
number of weights increases. The weights that are finally
retained in larger networks prove able to adjust more
autonomously than other weights.
4.3 Comparison of the Bayesian regulation method
to a simple linear search
The error criterion expressed by (3) minimizes both the
network complexity and the classification error over the
0%
10%
20%
30%
40%
50%
60%
70%
80%
90%
100%
0% 20 % 40 % 60 % 80%
% feature vector reduction
%
 s
im
ila
ri
ty
 w
it
h
 d
is
cr
im
in
an
t 
an
al
ys
is
 f
ea
tu
re
 v
ec
to
r
7 hidden node MLP
6 hidden node MLP
5 hidden node MLP
Fig. 2 Similarity (expressed as the fraction of common features)
between the reduced feature vector following discriminant analysis
and the corresponding MLP feature vectors, as a function of the level
of reduction over the original feature vector
Neural Comput & Applic (2010) 19:573–582 577
123
training set, using the two parameters a and b. By setting
the values of a and b, one can place more emphasis on
achieving small values of the network weights or on
attaining a low mean square error. In order to estimate the
optimal values of a and b, which will lead to the best
performance on unseen data, apart from the Bayesian
regulation approach that automatically adjusts these values,
a linear search method has also been investigated. Obvi-
ously, this latter method tested here is simpler since it
doesn’t modify parameters a and b at each training epoch
as the Bayesian Regulation algorithm does. The main
purpose of this simple method is to provide a basic
benchmark for comparison. In this linear search, initially
the sum of a and b is set to 1. Values of a that are linearly
spaced in the [0, 1] interval employing a step value of 0.2
are adopted to train different networks, resulting in a total
of six networks. The network that performs best over the
validation set, in terms of mean square error, is selected
and its performance over the test set is reported here. The
classification accuracy for Bayesian regulation and the
linear search procedure described are presented in Table 2.
As can be seen, the linear search procedure provides an
improvement in accuracy of less than 1% only for networks
with 8 hidden neurons of less. For larger networks, the
improvement in accuracy is negligible in most cases
(ranging from 0.12 to 0.57%). Additionally, the linear
search procedure is substantially more demanding in terms
of computations as it requires training several different
neural networks (equal to the number of different a values
used) with the Levenberg–Marquardt backpropagation.
Since the linear search procedure is considerably more
demanding and doesn’t result in a substantially improved
performance, Bayesian regulation is used in the remainder
of this article.
4.4 Evaluating the MLP in contrast to the cascade
correlation method
The cascade correlation method (CASCOR) [7, 14, 15] is
an incremental neural network-learning procedure. Its
main advantages are that: a) it automatically determines
the network’s architecture and b) the training proceeds in
an incremental manner. During the training procedure not
only are network weights adapted but additional neurons
are also inserted. Initially, the network doesn’t contain
any hidden neurons, and the input is directly connected to
the output via weights. Whenever a neuron is created, the
algorithm adapts only the weights of this neuron. After
the adaptation of this neuron has been completed, the
procedure continues by adding another neuron, if neces-
sary. Weight adaptation is implemented by using back-
propagation to minimize the mean square error over the
whole training set [14]. The architecture of a CASCOR
network bears a general resemblance to the MLP but it
differs in that the CASCOR contains direct connections
between the input layer and the output layer, and each
hidden neuron is directly connected (via a weight) with
all the hidden neurons created previously. For a CASCOR
network with N inputs, H hidden neurons and O outputs,
the number of parameters Sp is estimated by the following
formula:
Sp ¼ ðN þ 1ÞOþ HOþ ðN þ 1ÞH þ
XH
k¼1
ðk  1Þ !
Sp ¼ ðN þ 1Þ ðOþ HÞ þ HOþ
HðH  1Þ
2
ð6Þ
It can easily be seen that the CASCOR network has more
weights in comparison with an MLP with the same number
of hidden neurons.
Table 1 Effective number of parameters versus the total number of parameters for MLP neural networks with hidden layers comprising between
5 and 15 hidden neurons over 90 independent runs
5 6 7 8 9 10 11 12 13 14 15
Effective Parameters 353.39 377.65 397.07* 353.21 362.26 365.54 372.96 374.01 372.81 379.15 378.50
Total Parameters 460 551 642 733 824 915 1,006 1,097 1,188 1,279 1,370
Percentage of effective parameters 76.8 68.5 61.8 48.2 44.0 39.9 37.1 34.1 31.4 29.6 27.6
The asterisk denotes the maximum effective number of parameters observed
Table 2 Classification accuracy for various MLP networks trained with Bayesian regulation and with the simple linear search procedure to
select the values of parameters a and b
Algorithm 5 (%) 6 (%) 7 (%) 8 (%) 9 (%) 10 (%) 11 (%) 12 (%) 13 (%) 14 (%) 15 (%)
Bayesian regulation 88.73 88.71 88.45 88.78 89.14 89.54 89.42 89.71 89.59 89.33 89.65
Linear search 89.25 89.51 89.24 89.33 89.43 89.22 89.64 89.41 89.72 89.90 89.53
Bold indicates the optimal values for each model
578 Neural Comput & Applic (2010) 19:573–582
123
In order to initialize weights so that the saturation of the
activation function is avoided, the Nguyen–Widrow ini-
tialization technique was used for the CASCOR method
[12]. Additionally, a validation step was introduced in
order to terminate the training procedure, thus protecting
the network generalization performance and confining the
network growth.
The CASCOR algorithm was applied to the document
classification task studied in the present article so as to
compare the proposed approach, which has an a-priori
fixed topology with an incremental-learning algorithm.
Throughout the experiments, the CASCOR algorithm
demonstrated a high degree of sensitivity on the initial
weight values. In order to obtain results of an adequate
quality, five CASCOR networks were trained starting from
different initial value sets. The network that performed
better over the validation set was considered as the final
result of the training and was used to evaluate the classi-
fication accuracy over the previously unseen training test.
Additionally, to avoid early termination due to the vali-
dation process, the training procedure was stopped only if
fifty consecutive training steps worsened the best valida-
tion performance (it should be noted that this parameter for
the proposed MLP LMBR combination was only six as
reported in Sect. 2). The final result of the training proce-
dure was the set of network parameters that resulted in the
best classification accuracy observed on the validation set.
The average classification accuracy achieved by the
CASCOR method over the 90 different set combinations
(as defined in Sect. 4.1) was 87.67%. The average number
of neurons used was 34.9 while the minimum and maxi-
mum numbers were 1 and 126 accordingly, indicating a
very wide variation of network structures. The CASCOR
classification accuracy is lower than the classification
accuracy observed when using the proposed MLP network
with the LMBR-training procedure, which was 89.71% for
networks with 12 hidden nodes. Therefore, the proposed
MLP-based method is preferable over the CASCOR net-
work-growing method.
4.5 Comparison of the MLP to the state-of-the-art
SVM model
The TF–IDF weight (denoting the Term Frequency–
Inverse Document Frequency) is often used in information
retrieval and text mining applications [16] to represent the
occurrence of terms in a set of documents. The ‘‘term
frequency’’ (TF) of a document is defined as the number of
times a given term appears in the specific document. This
count is usually normalized by the number of words in the
document to prevent a bias towards larger documents. The
‘‘inverse document frequency’’ (IDF) measures the general
importance of the term in the data set, obtained by dividing
the number of all documents by the number of documents
containing the term, and then calculating the logarithm of
that quotient. Finally, each document is represented by a
numeric vector of TF–IDF measurements, each component
being the product of the corresponding TF and IDF
measurements.
Support vector machines (SVM) [17] have been suc-
cessfully applied to text mining applications [18], while it
has been reported that the optimal classification results are
obtained when the SVM operates on TF–IDF characteristics
[19–21]. The principle of the SVM model is to preprocess
the data so that patterns are represented in a high-dimen-
sional space, typically much higher than the original feature
space, where the patterns’ classes become linearly separa-
ble. With the use of an appropriate non-linear mapping from
the original feature space to the expanded feature space, a
hyperplane can then always be determined that perfectly
separates data from two categories. The proposed MLP
method presented in Sect. 4.3 is compared to the SVM
approach coupled with TF–IDF characteristics, the latter
serving as a benchmark for the given document set.
The SVM model is designed for two-class classification
tasks. When applying the SVM to a multi-class (as opposed
to a two-class) problem, a combination of several binary
SVM classifiers is required. These SVM classifiers may be
combined using either the ‘one-against-all’ combination
strategy (this being denoted as OAA) or the ‘one-against-
one’ strategy (OAO). According to the first strategy, M
binary classifiers are combined, where M is the number of
classes, and each document is assigned to the classifier that
gives the highest positive response. The second method
constructs one binary classifier for every pair of distinct
classes and so, for the 5-class task studied here in total
5 (5 - 1)/2 binary classifiers are constructed. Each docu-
ment is assigned to the class inferred by the majority of
classifiers (majority vote). For the experiments presented in
this article, the SVM—C model with the Gaussian Kernel
function from the LIBSVM software package [22] was
used.
For each document, the features presented in Sect. 3 (85
features) were normalized by that document’s length in
terms of either words or sentences, depending on the fea-
ture type. More specifically, sentence histogram counts
were divided by the number of sentences. These mea-
surements clearly differ from the classic TF–IDF mea-
surements, as used with the SVM [20].
In order to compare the proposed approach to state-of-
the-art approaches, a number of TF–IDF terms equal to the
number of features of Sect. 3 were initially adopted. The
terms chosen are the N most frequent lemmas (where ini-
tially N = 85) in the entire document dataset that are not
functional words, as identified by the tagger employed
[13].
Neural Comput & Applic (2010) 19:573–582 579
123
In the benchmark study, the SVM and the MLP models
are compared, using both the original measurements
(denoted as OM hereafter) and the TF–IDF measurements.
The classification accuracy for various combinations of the
measurements and the SVM-OAA, SVM-OAO and MLP
models is presented in Table 3. It can be seen that the
SVM-OAO with the original measurements (OM) set per-
forms better than both (1) MLP models with the original
measurements and (2) the SVM model with TF–IDF
measurements. In general, the SVM model achieves higher
classification accuracy than the MLP model. Furthermore,
the original features are found to perform better than the
TF–IDF ones. As expected, due to the increased number of
binary classifiers included in the SVM-OAO variant, the
one-against-one approach (OAO) always performs better
than the one-against-all (OAA) approach.
The TF–IDF SVM model performs better than the pro-
posed MLP when using the complete set of original fea-
tures (85 features). The classification accuracy observed for
the TF–IDF SVM model is 90.6%, which is approximately
0.1% higher than that of any MLP configuration. Addi-
tionally, according to Table 3, the SVM model performs
better when applied to the original measurements instead of
TF–IDF features as in the former case it results in 91.4%
classification accuracy (which is 0.8% higher than the
TF–IDF).
The classification accuracy of the MLP and SVM
models is also studied when the dimensionality of input
features is reduced. Moreover, using the MLP’s feature
importance measure defined by formula (5) for the original
measurements set, SVM and MLP models with fewer
features were studied. Additionally, the equivalent (in
terms of the number of features) TF–IDF SVM models, as
described in the previous section, were evaluated for
comparison purposes. The classification performance over
the test set for the two aforementioned SVM models and
the MLP with twelve hidden neurons is displayed in Fig. 3.
When used with the original measurements’ set, the SVM
performance always surpasses the MLP in terms of clas-
sification accuracy for every feature set (either reduced or
full), as shown in Fig. 3. When the number of features is
reduced by 20% or more, the proposed MLP network
performs better than the state-of-the-art TF–IDF SVM,
though it has a performance inferior to the SVM-OM
combination.
Still, the MLP feature evaluation technique using the
LMBR backpropagation variant, as proposed in this article,
can be used to improve the classification accuracy for the
SVM model. More specifically, when the number of fea-
tures is reduced by 60% in accordance with the MLP
process presented in Sect. 4.2, the SVM performance peaks
at 92.5%, up from 91.4% for the full model. The classifi-
cation accuracy of 92.5% using only 34 original features is
the best accuracy observed over the dataset for the author
discrimination task, for any model and feature combina-
tion. This indicates that a combination of the two network
models (MLP and SVM) leads finally to the optimal rec-
ognition performance, which is higher than that achieved
with only the linear discriminant analysis.
4.6 Feature evaluation
By using the feature evaluation criterion [expressed by (5)],
the average feature contribution in the classification result
Table 3 Classification accuracy for different combinations of the
feature sets and the network models SVM-OAA, SVM-OAO and
MLP, when using 85 features
Model Feature set Classification accuracy (%)
MLP 5 OM 88.45
MLP 6 OM 88.71
MLP 7 OM 88.73
MLP 8 OM 88.78
MLP 9 OM 89.14
MLP 10 OM 89.54
MLP 11 OM 89.42
MLP 12 OM 89.71
MLP 13 OM 89.59
MLP 14 OM 89.33
MLP 15 OM 89.65
SVM-OAA OM 86.66
SVM-OAO OM 91.43
SVM-OAA TFIDF 86.55
SVM-OAO TFIDF 90.64
Bold indicates the optimal values for each model and feature
combination
76%
78%
80%
82%
84%
86%
88%
90%
92%
94%
0% 20% 40% 60% 80%
%  feature vector reduction
%
 c
la
ss
if
ic
at
io
n
 a
cc
u
ra
cy
12 hidden node MLP - OM
SVM - OAO - TFIDF
SVM - OAO - OM
Fig. 3 Classification accuracy for SVM and MLP models as a
function of the fraction of features removed from the two 85 feature
sets (OM and TFIDF)
580 Neural Comput & Applic (2010) 19:573–582
123
is evaluated for the various network sizes tested. For rea-
sons of conciseness and clarity, the feature contribution is
evaluated per feature group (Part of speech, Negation,
Lemma Related, Structural and Verbal). Since the number
of features is different for each category, the results
obtained are normalized by the number of features that
each category contains. These collective results can be
regarded as the average importance for each feature that
belongs to a specific category. Additionally, the total
importance of the input vector was normalized to sum up to
100%. More information on the chosen feature set, which
refer to Greek documents, can be found in [9]. As can be
seen in Table 4, the most important group of features are
the part of speech, and the second most important group are
Lemma-related features. On the other hand, the contribu-
tion of negation features appears to be of substantially
lesser importance. Notably, the feature contribution was
almost constant for the various MLP sizes adopted (from 5
to 15 hidden neurons), indicating the stable behaviour of
the MLP independently of the hidden-layer size.
5 Conclusion
The present paper has focussed on studying the effective-
ness of the MLP when applied to the task of categorizing a
corpus of texts based on the style of their authors and
evaluating the effectiveness of the linguistic features
employed. It has been found that the MLP-based method
can achieve a high classification accuracy, comparing very
favourably to frequently used statistical techniques. The
Bayesian Regulation variant has been shown to be effective
in substantially reducing the number of features used (by
up to 40%), without any detrimental effect to the classifi-
cation accuracy obtained.
A comparison held between the reduced feature vectors
in discriminant analysis and the MLP has shown that the
most salient features in the cases of the MLP and dis-
criminant analysis models overlap to a large extent. In the
extreme case of sparse feature vectors, MLP is found to
reach a set of salient features that supports higher
classification accuracy than discriminant analysis. The
proposed MLP with the LMBR-training procedure has also
been found to perform better than the cascade correlation
incremental-learning algorithm. In addition, the proposed
configuration of an MLP classification network operating
on linguistic parameters has been compared to the estab-
lished combination of SVM model and TF–IDF parame-
ters, using a variety of experiments. It has been found that
in general, the proposed parameters are more effective than
the TF–IDF parameters studied, while the SVM gives a
slightly higher classification than the MLP. However, the
combination of the MLP model and the performance cri-
terion of (3) allows the selection of the most salient
parameters in an automated manner, while the SVM pos-
sesses no such capability. When the parameters selected by
the MLP are employed in the SVM, they provide sub-
stantially improved classification accuracy, indicating the
effectiveness of the MLP feature selection procedure in
optimizing the classification performance.
Acknowledgments The present study was partly funded by the
PENED 03ED97 research project of the General Secretariat for
Research and Technology of the Hellenic Ministry of Development.
References
1. Gurney PJ, Gurney LW (1998) Subsets and homogeneity:
authorship attribution in the Scriptores Historiae Augustae. Lit
Linguist Comput 13(3):133–140
2. Holmes DI (1994) Authorship attribution. Comput Humanit
28:86–106
3. Mosteller F, Wallace DL (1984) Applied Bayesian and classical
inference: the case of the Federalist papers, 2nd edn. Springer,
New York
4. Holmes DI, Singh S, Tweedie FJ (1996) Neural network appli-
cations in stylometry: the Federalist papers. Comput Humanit
30:1–10
5. Lowe D, Matthews R (1995) Shakespeare vs. Fletcher: a stylo-
metric analysis by radial basis functions. Comput Humanit
29:449–461
6. Tambouratzis G, Hairetakis N, Markantonatou S, Carayannis G
(2003) Applying the SOM model to text classification according
to register and stylistic content. Int J Neural Syst 13(1):1–11
7. Haykin S (1999) Neural networks: a comprehensive foundation,
2nd edn. Prentice Hall, Englewood Cliffs
8. Somers H, Tweedie F (2003) Authorship attribution and practice.
Comput Humanit 37:407–429
9. Tambouratzis G, Markantonatou S, Hairetakis N, Vassiliou M,
Tambouratzis D, Carayannis G (2004) Discriminating the regis-
ters and styles in the Modern Greek language—part 2: extending
the feature vector to optimise author discrimination. Lit Linguist
Comput 19(2):221–242
10. Kolman E, Margaliot M (2005) Are artificial neural networks
white boxes? IEEE Trans Neural Netw 16(4):844–852
11. Mackay D (1992) A practical Bayesian framework for back-
propagation networks. Neural Comput 4(3):448–472
12. Nguyen D, Widrow B (1990) Improving the learning speed of
2-layer neural networks by choosing initial values of the adaptive
weights. Proc Int Jt Conf Neural Netw 3:21–26
Table 4 Minimum, average and maximum relative contribution of
each feature category for MLP networks with hidden layers of
between 5 and 15 neurons
Feature
group
Minimum
importance (%)
Average
importance (%)
Maximum
importance (%)
Part of speech 25.95 24.46 26.51
Negation 10.08 10.23 10.44
Lemma Related 24.24 26.29 24.61
Structural 21.26 21.92 22.26
Verbal 16.85 17.10 17.69
Neural Comput & Applic (2010) 19:573–582 581
123
13. Papageorgiou H, Prokopidis P, Giouli V, Piperidis S (2000) A
unified PoS tagging architecture and its application to Greek, vol
3. Second international conference on language resources and
evaluation proceedings. Athens, pp 1455–1462
14. Duda RO, Hart PE, Stork DG (2001) Pattern classification.
Wiley, New York
15. Fahlman S, Lebiere C (1990) The cascade-correlation learning
architecture. Adv Neural Inform Process Syst 2:524–532 Morgan
Kaufmann
16. Salton G, Buckley C (1988) Term-weighting approaches in
automatic text retrieval. Inform Process Manag 24(5):513–523
17. Vapnik V (1998) Statistical learning theory. Wiley Interscience,
New York
18. Diederich J, Kinderman J, Leopold E, Paass G (2003) Authorship
attribution with support vector machines. Appl Intell 19:109–123
19. Bhamidipati NL, Pal SK (2007) Stemming via distribution-based
word segregation for classification and retrieval. IEEE Trans Syst
Man Cybern B Cybern 37(2):350–360
20. Drucker H, Wu D, Vapnik V (1999) Support vector machines for
spam categorization. IEEE Trans Neural Netw 10(5):1048–1054
21. Koprinska I, Poon J, Clark J, Chan J (2007) Learning to classify
e-mail. Inform Sci 177(10):2167–2187
22. Chang C-C, Lin C-J (2001) LIBSVM: a library for support vector
machines. Software available at http://www.csie.ntu.edu.tw/
*cjlin/libsvm
582 Neural Comput & Applic (2010) 19:573–582
123
