Are 140 Characters Enough?
A Large-Scale Linkability Study of Tweets
Mishari Almishari‡, Dali Kaafar‡‡, Gene Tsudik†, Ekin Oguz†
‡ King Saud University
‡‡NICTA
†University of California, Irvine
Abstract. Microblogging is a very popular Internet activity that in-
forms and entertains great multitudes of people world-wide via quickly
and scalably disseminated terse messages containing all kinds of news-
worthy utterances. Even though microblogging is neither designed
nor meant to emphasize privacy, numerous contributors hide behind
pseudonyms and compartmentalize their different incarnations via mul-
tiple accounts within the same, or across multiple, site(s).
Prior work has shown that stylometric analysis is a very powerful tool
capable of linking product or service reviews and blogs that are produced
by the same author when the number of authors is large. In this paper,
we explore linkability of tweets. Our results, based on a very large corpus
of tweets, clearly demonstrate that, at least for relatively active tweeters,
linkability of tweets by the same author is easily attained even when the
number of tweeters is large. We also show that our linkability results
hold for a set of actual Twitter users who tweet from multiple accounts.
This has some obvious privacy implications, both positive and negative.
1 Introduction
Microblogs offer a fast and highly scalable information sharing, allowing mul-
titudes of users to disseminate pithy messages to news-hungry and attention-
challenged followers or subscribers. For either social or professional purposes,
users share their thoughts, interests and sometimes express highly sensitive or
controversial opinions. Twitter, the most prominent microblogging site, has now
grown to a truly global service with hundreds of millions of users [1]. In Twitter,
Weibo Sina and others, the relationship between users (referred to as tweeters
in Twitter) typically requires no reciprocal approval and is often considered as a
form of subscription. Although postings (called tweets in Twitter) can be tagged
as private, most users keep theirs public, as well as their follower information.
At the same time, microblogging has become a rich source of information
about individuals. Although it may be difficult to justify the claim that the
existence of public messages violates privacy of their authors (since they are
ar
X
iv
:1
40
6.
27
46
v1
  [
cs
.I
R
] 
 1
1 
Ju
n 
20
14
the one who make their utterances public in the first place), the potential to de-
anonymize multiple user accounts and to link messages (or sets thereof) produced
by the same author represents a threat to privacy. This is primarily because
multiple accounts owners often expect each set of messages to remain within the
boundaries of the account from which it has been posted.
Consider for example, the case of an activist who uses a pseudonym in Twit-
ter1, to post some highly sensitive or controversial tweets and, in parallel, uses
another account associated with his/her real name. Linkage of these two ac-
counts might pose a serious threat to that person’s privacy and perhaps even to
their physical security.
On the other hand, microblogging site operators and law-enforcement agen-
cies might benefit from techniques that link accounts within a site or across
multiple sites. Legitimate reasons might include: (1) identifying spammers and
phishers who might hide behind multiple accounts to evade detection, (2) track-
ing or correlating messages pertaining to illegal activities2, such as terrorism
incitement, pedophilia or human or drug trafficking.
In this paper, we investigate the use of probabilistic models to link user ac-
counts in the particular microblogging ecosystem of Twitter, where message size
is limited to 140 characters and where both the use of metadata tags (hashtags)
and reposts of other users’ messages (retweeting) is commonplace.
The goal of this work is to assess linkability of tweets by measuring how
much they relate/link to author’s other tweets. We perform our analysis over
two large datasets, each containing over 8, 000 Twitter accounts, with over 28
million tweets in one set and more than 3 million in the other. The first dataset
consists of prolific tweeters, with users producing 2, 000 tweets or more over a
six-months period. The second dataset consists of less prolific tweeters who post
between 300 and 400 tweets, over the same period. Furthermore, we extend our
analysis to show the linkability of tweets of actual users who operate several
Twitter accounts. Our work makes the following contributions:
1. We conduct a large-scale linkability study by applying the Näıve Bayes model
as a classifier to predict linkage between tweets using simple stylometric
features and analyzing the effect of a specific Twitter feature – hashtags.
Results demonstrate that tweets are highly linkable. By simply analyzing
letter frequencies, our classifier can – in some scenarios – link tweets at a large
scale with over 90% accuracy. We also show that hashtags are particularly
useful in the linkage process: by only using hashtags, our classifier achieves
high linkability ratios and can link two thirds of the tweets.
1 Twitter, as opposed to other major OSNs, does not require users to provide real
names; pseudonyms are accepted as long as they do not impersonate other users
accounts https://support.twitter.com/entries/18311
2 Clearly, the definition of illegal activities varies widely from country to country.
2
2. We extend and verify our linkability technique to link tweets of dual Twitter
accounts owners. We consider a set of tweets from 14 Twitter users who
maintain and simultaneously use two accounts or more, and successfully
classify and extract linkage of their tweets amongst sets of over 8000 users.
We envision several possible uses of our technique. First, it could be implemented
as a service usable by prospective tweeters to assess linkability of their multi-
ple accounts. Second, it can be used by the provider (i.e., Twitter) to identify
multiple accounts holders who generate libel, spread disinformation or promote
illegal activities.
2 Background: Näıve Bayes Model
This section overviews the Näıve Bayes Model [2] used in the subsequent linka-
bility analysis.
Näıve Bayes (NB) is a probabilistic model based on the so-called Näıve Bayes
assumption, which states that all features/tokens are conditionally independent,
given some category. In our case, the category is a tweeter (user). Given a docu-
ment with a set of tokens/features: token1, token2, . . . , tokenn, NB model com-
putes the corresponding user model as follows:
User = argmaxUP (U |token1, . . . , tokenn)
where U varies over all distinct users in our dataset, in order to maximize the
probability P (U |token1, . . . , tokenn) of categorizing a document (represented
by token1, token2, . . . , tokenn) as belonging to a specific user. Using the Bayes
Rule[3], P (U |token1, . . . , tokenn) is defined as:
P (U |token1, token2, . . . , tokenn) =
P (U)P (token1, token2, . . . , tokenn|U)
P (token1, . . . , tokenn)
where P (token1, token2, . . . , tokenn|U) is the probability of generating the set
of tokens token1, . . . , tokenn by U . When using the Näıve Bayes assumption,
P (token1, . . . , tokenn|U) = P (token1|U) · · ·P (tokenn|U), finding a matching User
for token1, token2, . . . , tokenn for a given tweeter profile boils down to:
User = argmaxUP (token1|U) · · ·P (tokenn|U)
where P (tokeni|U) is the probability of generating tokeni by U . We assume
that P (U) – the probability of associating a document to a user without any
information about the tokens in the document – is the same for all tweeters. Also,
the denominator P (token1, . . . , tokenn) in the equation above is the combined
probability of all tokens; it is therefore independent of the user. Finally, to avoid
the under-flow problem, we consider the log of the products, which results in:
User = argmaxU
∑
i logP (tokeni|U)
3
We estimate all probabilities of the form P (tokeni|U) using the Maximum Like-
lihood estimator [4] with Laplace smoothing [3].
3 Dataset
We use a portion of the dataset crawled by Yang et al. [5], that spans an approx-
imately six-months period from June to December, 2009, excluding October3.
Parameter Value
Total # of Tweets 400, 834, 808
Total # of Tweeters 15, 905, 473
Max. # of Tweets per Tweeter 82, 177
Min. # of Tweets per Tweeter 1.0
% Tweeters with ≥ 2000 Tweets 0.05%
% Tweeters with ≥ 500 Tweets 0.68%
% Tweeters with ≥ 300 Tweets 1.4%
% Tweeters with ≥ 50 Tweets 9.5%
% Tweeters with ≤ 10 Tweets 73%
% Tweeters with ≤ 1 Tweets 33%
Table 1: Dataset Statistics
The dataset consists of more than 400 million tweets, authored by over 15
million users (see Table 1). Majority of tweeters authored no more than 10 tweets
each, i.e., most are not what we would call prolific tweeters. However, there is
still a substantial number of prolific tweeters.
For analysis purposes, we extracted two subsets. The first is referred to as
Prol. It contains all tweets of all users who authored at least 2, 000 tweets dur-
ing the observed 6-month period. This set consists of 8, 262 different twitter
accounts. We consider these to be highly-prolific tweeters. The total number of
tweets in Prol is 28, 625, 352.
The second subset is referred to as Low. It contains all tweets authored by
a set of 10, 000 users, randomly chosen among all users who authored between
300 and 400 tweets. This corresponds to a total of 73, 004 users – much broader
demographic. The total number of tweets in Low is 3, 449, 635. Since the original
dataset is from 2009, given ever-increasing popularity of Twitter, we speculate
that Low is a sample of very large demographic in the current state of Twitter.
We extracted two subsets, instead of one, since we aim to assess linkability of
tweets for users in different prolificacy scales. We acknowledge that our selection
3 Due to some technical difficulties in extracting data for October 2009
4
of thresholds in constituting these subsets is subjective. However, we believe that
increasing use of Twitter [1] results in more users falling into the ranges of these
thresholds. Linkability analysis for users who produce fewer tweets is deferred
to future work.
4 Settings and Methodology
We adopt the settings, linkability-related definitions and abbreviations similar
to those in [6]. Our goal is to first assess how much tweets say about their
authors, i.e., how accurately a seemingly anonymous recent tweet can be linked
to previous tweets by the same author. Later, in Section 5.5, we analyze how
tweets authored by the same tweeter, while using two different accounts, can be
re-linked.
We build a Näıve Bayes classifier as our matching/linking model, which is
partially trained on two subsets: Prol and Low, to perform the linkage. Specif-
ically, for each author U in both Prol and Low, we randomly split her tweets
into two sets: Identified Record (IR), and Anonymous Record (AR). The set of
all IRs is used for training the classifier and the set of all ARs is used to assess
linkability – the accuracy of linking an AR to its corresponding IR. Note that
we conduct linkability analysis independently over each set.
For each set and for each author, the task of the classifier is to link her AR to
a corresponding IR while maximizing the number of ARs correctly linked. For
each set, it matches each author’s AR to an IR by returning a list of candidate
IRs, sorted in decreasing order of likelihood of being the correct match.
We consider a given AR to have Top-x linkability if the actual correspond-
ing IR is among the top x candidate IR records that the classifier returns. We
measure performance of our classifier in terms of linkability ratio (LR), which
computes the percentage of ARs that have been correctly classified within the
top x candidates. We experimented with three x values: 1, 5, and 10.
We partitioned each author’s tweets into IR and AR as follows: First, we
sorted a user’s tweets in random order. Then, we assigned all tweets (except the
last 100) to IR. For the last 100 tweets, we assigned the first y to AR. We vary
y over the following values: 5, 10, 20, 50 and 100. The main reason for varying
y is to evaluate the impact of the number of anonymous tweets on linkability.
5 Linkability Analysis
We use the Näıve Bayes (NB) model as a matching tool to link tweets based on
two types of lexical tokens: (i) unigrams: all letters of the English alphabet, i.e.,
26 tokens. (ii) bigrams: all possible two-letter combinations, i.e., 676 tokens. We
perform separate analysis on Prol and Low, and compare respective results. For
5
each set, we build a NB model based on all IRs of the set, match all ARs and
compute the resulting LR.
5.1 Unigrams
Figures 1(a) and 1(b) show LRs for Prol and Low, respectively. Specifically, they
show Top-1, Top-5 and Top-10 LRs for various AR sizes, using unigrams in NB.
First, we observe that all curves exhibit clear upward trend, showing that the
bigger the AR size, the higher LR we obtain. For AR size of 100, Top-10 LR is as
high as 92% for Prol and 74% for Low. Additionally, we observe relatively high
LRs for Top-1(Top-5) – 74% (88%) of the ARs are linked in Prol for AR size of
100. Even for small AR sizes, we link a large number of ARs. For example, for
AR size of 20, Top-10 LR is 59% for Prol. Even though the number of tweeters
is large and the number of tokens is only 26, we can link a substantial number of
ARs. As expected, we observe that LRs are higher in sets that have larger IRs
(Prol better than Low), since larger IRs offer the classifier more information to
capture the user’s writing style.
(a) (b)
Fig. 1: Top-1, Top-5, and Top-10 LRs of unigram-based NB model for Prol (a)
and Low (b)
5.2 Bigrams
Figures 2(a) and 2(b) show Top-1, Top-5 and Top-10 LRs, when bigrams are
used. Substituting unigrams with bigrams substantially increases LRs, even when
using a rather small AR. For instance, Top-1 LR is 95% and 87% for Prol and
6
Low, respectively, for AR size of 100. Even for small AR sizes, we achieve high
LRs. For example, for AR size of 5(10), Top-10 LR exceeds 67(84)% in Prol.
Also, for AR size of only 20, Top-5 (Top-10) LR in Low is around 75(80)%. As
observed earlier with unigrams, sets with larger IRs offer higher LRs, which is
again due to offering more information to model user’s tweets. Notably, when
using bigrams, the classifier needs a smaller AR size to achieve substantially
higher LRs (e.g. using bigrams with an AR size of 20, the classifier obtains a
Top-5 LR of over 70% for Low tweeters, while it needs an AR of 100 or more to
obtain similar performance with unigrams). These results suggest that there is a
compromise in choosing between unigrams and bigrams. On one hand, bigrams
lead to better linkability ratios with a less number of tweets to learn from. On
the other hand, unigrams are less computationally demanding and should be
considered when there is a need for a higher scalability and faster computation.
(a) (b)
Fig. 2: Top-1, Top-5, and Top-10 LRs of bigram-based NB model for Prol (a)
and Low (b)
5.3 Varying the Number of Users
In the previous sections, we considered the full set of users, i.e., we included all
8, 262 users in Prol and 10, 000 – in Low. We now reduce the number of users in
the sets and explore the effect of user set size on linkability.
Unigrams. We vary the number of users in Prol and Low between 1, 000
users and full set size (i.e. 8, 262 and 10, 000 users respectively). Figures 3(a)
and 3(b) show LRs for different set sizes when AR size is 100. As expected, LR
increases with the smaller number of users. Top-10 LR reaches 99% and 92% in
7
Prol and Low, respectively, when the set size is 1, 000, which is reasonably large.
When the set size is 5, 000, Top-5 LR exceeds 90% and 70% in Prol and Low,
respectively. Note that when we increase to the full set size, reduction of Top-10
LR does not exceed 7% and 20% in Prol and Low, respectively. This points to
the resilience of our linkability model that is based on unigrams.
(a) (b)
Fig. 3: LRs of unigram-based NB model when varying the number of users in
Prol (a) and Low (b)
Bigrams. With similar ranges, we vary the number of users in Prol and Low.
Figures 4(a) and 4(b) show LRs for different set sizes with AR size of 100.
Interestingly, LR does not decrease much when we increase set size. For example,
looking at the entire range, Top-1 LR does not decrease over 4% and 7% in Prol
and Low, respectively. Meanwhile, Top-1 LR stays above 95% in Prol and above
87% in Low. Also, in Top-5 and Top-10 LR, the decrease does not exceed 5%
in Low and almost 0-1% in Prol. This shows that the bigram-based NB model
is very resilient against increasing the number of users. We believe that these
results should be very troubling to tweeters worried about linkability of their
tweets.
5.4 Improving Unigram-based Model
Previously, we observed that relying on only bigram tokens yields very high
LRs. However, bigrams also require more resources than unigrams: 676 vs 26
tokens. Thus, bigram-based models are less scalable. To this end, we consider
improving LRs when only unigrams are used, by exploring the use of hashtags.
We first consider using unigrams from the hashtags themselves, and then
8
(a) (b)
Fig. 4: LRs of bigram-based NB model when varying the number of users in Prol
(a) and Low (b)
combine them with unigrams from full-tweet texts.
Hashtags are a peculiar, yet popular, feature of Twitter. Not surprisingly, many
tweets in our dataset contain one or more hashtags. We first filter out from Prol
and Low all tweets that do not include any hashtags. We then discard all users
with fewer than 300 hashtag-containing tweets; this is so that we can populate
their corresponding AR sets with 100 tweets4. This leaves us with 3, 179 and 160
users in Prol and Low, respectively. Since the resultant size of Low is small, we
confine our analysis to Prol. The number of tweets in filtered Prol is 4, 274, 188.
Initially, we intended to use hashtags as tokens in the NB model. However,
this resulted in a very large number (> 150, 000) of hashtags, which is very
resource-consuming. To remedy the situation, we decided to use unigram tokens
within hashtags. Since hashtags can include 11 non-alphabetical characters (i.e.,
0− 9 and “ ”), we ended up with 37 tokens.
Figure 5 shows LRs for hashtag-based unigrams in NB5. As can be easily
seen, Top 10 LR reaches 67% for AR of 100. Despite only relying on hashtags,
we can successfully link 2/3 of ARs.
Combining Hashtags and Full-Tweet Texts.
We consider improving LR by exploring unigrams of full-tweet texts (a set
of 26) combined with hashtags-based unigram tokens – a set of 37. Combining
these two sets yields 63 tokens, which is still a lot less than 676 with bigrams.
4 We defer to future work the case of linkability when IR size is smaller than AR size.
5 Recall that our analysis is based on the filtered version of Prol with 3, 179 users.
9
Fig. 5: Top-1, Top-5, and Top-10 LRs of hashtag-based NB model when using
unigrams
As discussed in Section 2, we use the following Log−Sum to sort the matching
users from a set of tokens:
Fig. 6: Top-1, Top-5 and Top-10 LRs when varying beta β values from 0 to 1
∑
i
logP (ti|U)
We now use a weighted average for combining the Log−Sum of full-tweet-text-
based tokens and hashtag-based tokens as follows:
(β)×
∑
ttweet
i
logP (t
tweet
i |U) + (1− β)×
∑
t
hashtag
i
logP (t
hashtag
i |U)
However, there is no clear way to assign a value to β. We experimented with
several choices. Specifically, we tried all β values ranging in [0− 1] at 0.1 incre-
10
ments and observed the highest LR with β = 0.6 in Top-1, Top-5 and Top-10
LRs. Figure 6 shows LRs for different β values. Note that β selection process
(training) is restricted to the set of IRs (ARs are excluded). That is, β is learned
using IRs, by further splitting them into identified and anonymized6 sets, and
computing the corresponding LR values in the filtered version of Prol.
Results of Combining. Having chosen β = 0.6, we used it in computing the
weighted average. Figures 7(a), 7(b) and 7(c) show Top-1, Top-5 and Top-10
LRs, when combining unigrams of full-tweet texts and hashtags for the filtered
Prol. All figures show LR for β set to 0 (hashtags only), 1 (full-tweet texts only),
and 0.6 (combination of tweet texts and hashtags). As evident from the figures,
combining full-tweet texts with hashtags substantially boosts LRs for all AR
sizes. The improvement over the best of two other curves ranges from 8− 13%,
6 − 13% and 4 − 11% in Top-1, Top-5 and Top-10 LRs, respectively. Note that
LRs, when β = 1, are different from that in Section 5.1. That is because we are
assessing the LRs of filtered Prol, which is much smaller (in terms of number of
tweets for IRs) than Prol. We conclude that unigrams in hashtags make tweets
linkable, but they are more powerful when combined with unigrams from full-
tweet texts. This combination definitely depends on the choice of β.
(a) (b) (c)
Fig. 7: Top-1 (a) , Top-5 (b) and Top-10 (c) LRs of the revised version of Prol
when combining unigrams of full-tweet texts and hashtags
6 We allocate the last 50 tweets of IRs as the new ARs used for training.
11
5.5 Considering Dual-Account Tweeters
So far, we analyzed many sets of tweets, each set authored by a distinct user
corresponding to a Twitter account. After artificially splitting each such set into
Identification Record (IR) and Anonymous Record (AR), we discovered that they
are highly linkable. In practice, our technique aims to link distinct users, i.e.,
multiple bodies of tweets emanating from different Twitter accounts. Therefore,
results discussed above can be criticized for being too artificial. Indeed, if our
approach is truly effective, it must be evaluated using some “ground truth”, i.e.,
real users who tweet via multiple accounts. In this section, we apply the NB
classifier to exactly this type of data.
Clearly, we can not assemble a comprehensive collection of all multi-account
bodies of tweets, even for a fixed period of time. Instead, as ground truth data,
we use a fairly small number of account-pairs that are known to be operated
by the same author/user. We merge (or mix in) this new information into the
much larger set of tweets used in the previous sections, and then re-apply our
NB classifier.
Multi-Account Dataset In order to collect tweets from dual-account authors,
we manually (and extensively) searched the web for public information pertain-
ing to individuals who operate multiple accounts.. For example, we used search
variations of keywords, such as “multiple twitter accounts”, and found several
blog posts where Twitter users publicly reveal tweeting via multiple accounts.
This netted us a total of 41 accounts operated by 14 distinct Twitter users. Of
these, 11 actively maintain 2 accounts, while remaining 3 users have 3 or more
accounts. For each account, we collect corresponding sets of tweets via Twitter
API with twitter-logger7.
Because of quotas in Twitter API, we could only dump up to ∼3200 of a
given account’s most recent tweets. After crawling 41 accounts, we observed an
average number of tweets per account of 1, 631, with a maximum of 3, 241 and a
minimum of 34. For each multi-account user, we considered a set of most-prolific
two accounts, that have the highest number of tweets. This set constitutes 14
dual-account owners, along with their corresponding tweets, referred as Dual.
Most users in Dual operate one relatively general personal account and another
that is more focused on a specific topic, e.g., professional, hobbies, political, or
sports.
Linkability Results Based on results discussed in the earlier part of this paper,
we again use bigram NB as the linking model for the Dual dataset. As a sanity
check, we first assessed NB’s performance with Dual without mixing in tweets
7 https://dev.twitter.com/ and https://github.com/sixohsix/twitter
12
from any external dataset. For each dual-account user, we randomly selected one
of the two accounts (i.e, all tweets therein) as IR, and the other – as AR.
As before, we varied AR size between 5 to 50, by randomly selecting tweets8.
Figure 8 shows LRs of 14 users in Dual. Top-1 LR is 100% for AR size of at least
20. Also, Top-1 LR exceeds 85% for AR size less than 10. We therefore conclude
that the NB bigram model is very successful in linking tweets from different
accounts.
Fig. 8: Top-1 LR in Dual – Total number of dual-account owners is 14.
As the next step, we verify that the classifier is scalable, i.e., performs well
if tweets from Dual are merged with Prol and Low datasets, respectively. Specif-
ically, we merge IRs from Dual and Prol / Low. Likewise, we augment ARs of
Dual with ARs of Prol / Low. Figures 9(a) and 9(b) show LRs of 14 dual-account
owners in Dual augmented by Prol and Low, respectively9. Once again, Top-1,
Top-5 and Top-10 are at 100% when AR size exceeds 20. Surprisingly, for AR size
of 10, Top-10 LR exceeds 90% for both cases. This clearly confirms effectiveness
of our NB bigram model for the dual-account user linkage.
6 Key Results
Key elements of our analysis can be summarized as follows:
1. Tweets are highly linkable. Top-1/Top-10 LRs reach up to 95/99% for a large
set of users (over 8, 000) by only relying on bigrams; see Section 5.2.
8 The maximum AR size was set to 50, instead of earlier 100, since a few accounts
had less than 100 tweets.
9 The total number of users is 8, 262 + 14 = 8, 276 in Figure 9(a) and 10, 000 + 14 =
10, 014 in 9(b).
13
(a) (b)
Fig. 9: Top-1, Top-5 and Top-10 LRs in Dual when merging accounts with Prol
– (a) and Low – (b)
2. Tweets remain highly linkable even in the context of only unigrams. Top-10
LR exceeds 97% and 85% in Prol and Low, respectively; see Section 5.1.
3. ARs are highly linkable even when their sizes are small. For example, with
bigrams and AR size of 20, Top-10 LRs exceed 95% and 79% in Prol and
Low; see Section 5.2.
4. LRs are the highest in Prol. However, even with less prolific tweeters, we
obtain high LRs. For example, in Low, Top-10 LR reaches 95%, 96% and
98%, for the cases of: 10, 000, 5, 000 and 1, 000 users, respectively (with
bigrams); see Section 5.3.
5. Again, with bigrams, LRs do not decrease beyond 7% and 4% in Prol and
Low, if we increase the number of users from 1, 000 to the full user set size;
see Section 5.3. We believe these results are troubling to privacy-conscious
tweeters.
6. Unigram-based LR can be substantially improved by combining the unigram
model derived from full-tweet texts with that derived from hashtags; see
Section 5.4.
7. We evaluated our approach with data from a small number of actual dual-
account users. The linkability ratio can reach 100% for all 14 dual-account
owners that we used as the “ground truth” dataset; see Section 5.5.
7 Related Work
Author Attribution in Twitter. Some prior results focused on authorship
identification and stylometric analysis of microblogging, e.g., [7,8,9,10,11]. [7]
14
considered re-identifying authorship of tweets from a set of three authors, while
using over 5, 000 dimensions as input for a Support Vector Machine (SVM)
classifier. Similarly, [9] investigated pseudonymity for a set of 50 Twitter users.
[8] studied the use of n-grams with Näıve Bayesian as the linkability model. In
particular, 2- to 6-grams are evaluated and a 98% linkability is achieved in the
setting of 50 authors. An identification technique based on extracting a set of
lexical and syntactical features along with SVM is proposed in [11]. It achieves
91% accuracy for a set of 15 authors. Moreover, a technique based on extracting
a set of textual signatures per author is proposed in [10]. Character n-gram 4
and word n-grams are used as features and an accuracy of 30 is achieved when
the number of authors is 1,000 (70% accuracy when the number of authors is
50).
There are four main differences between aforementioned results and our work
First, we assess linkability on a large scale. The numbers of tweeters is way larger
than in prior related studies. Second, we use unigrams, which drastically reduces
the number of tokens. Third, we also include hashtags and show their effective-
ness in linkability when used alone or in combination with other unigrams. Fi-
nally, we successfully re-produce and confirm linkability results for a small set
of actual dual-account twitter users.
Cross-Linking Accounts. [12] reports on efforts to cross-link accounts between
different social networks, in particular, from Yelp to Twitter and from Flickr to
Twitter. Geo-location information, timestamps and text-based features are used
in linking user accounts, along with the cosine distance function. There are some
notable differences between this study and ours. Techniques that link accounts
across social networks might not work for linking accounts within the same
network; we do the latter. One reason is that accuracy (across social networks)
tends to be high when linking models use similarities among user-names and
location information as features (Otherwise, it is quite low). Whereas, a user
operating two separate accounts within the same social network would likely not
pick similar user-names. Also, location services might be disabled in some social
networks.
Other prior work that explored linkability of accounts across platform in-
cludes [13] and [14].
Author Attribution. A recent effort [15] investigated de-anonymization of
“anonymous” peer reviews of academic papers. The best result achieved is close
to 90%.
One of the best-known results in this area is [16] which uses an extensive set
of features, called Writeprints. This approach attained identification accuracy
of 91%. Other related studies include [6] which explored author linkability in
user reviews using similar (to ours) probabilistic techniques. [17] tackled large-
scale online authorship re-identification using linguistic stylometry techniques,
15
achieving up to 80% accuracy. We refer to [18] for an extensive survey of author
identification and authorship attribution literature.
8 Discussion
Although there are many stylometric features in the literature, the focus of this
paper is on scalable linkability analysis, which motivated us to consider only
simple features, allowing the models to perform well with the large number of
users.
Even though our technique was evaluated over a very large dataset with
numerous accounts, it is possible that some accounts we “linked” are actually
operated by a group of authors, rather than by a single one. This might occur if
an account serves as an outlet for an organization, e.g., a business, a government
agency or a professional society. While privacy concerns are clearly much less
serious with such accounts, we believe it is very helpful for their owners to be
aware of linkability issues.
Finally, recall that our analysis considered the maximum AR size of 100.
While this might seem large, it represents ≤ 5% (≤ 30%) of the total tweets of
the user with the minimum contribution in Prol (Low). In practice, it is easy
to collect a daily global snapshot of all tweets by using the dedicated Twitter
API10.
9 Future Work
As part of future work, we plan to improve LRs for smaller AR sizes by con-
sidering probabilistic models other than NB (with dependencies among some
features) and by looking into other features, such as ratio of tweets to retweets
and corse-grained categories of hashtags. We also would like to perform link-
ability analysis on different author demographics, such as those with very few
tweets. Moreover, we believe that further analysis is needed to understand what
makes tweets more (or less) linkable. This would allow us to make concrete
recommendations for tweeters to retain more privacy.
References
1. “Twitter Blog,” https://blog.twitter.com/2013/celebrating-twitter7.
2. D. Lewis, “Naive(bayes) at forty:the independence assumption in information re-
trieval,” in Proceedings of the 10th European Conference on Machine Learning,
1998.
10 Accessible via: https://dev.twitter.com/docs/api/1.1/get/search/tweets
16
3. T. Mitchell, Machine Learning. McGraw Hill, 1997.
4. C. Bishop, Pattern Recognition and Machine Learning. Springer, 2006.
5. J. Yang and J. Leskovec, “Patterns of temporal variation in online media,” in
WSDM, 2011.
6. M. Almishari and G. Tsudik, “Exploring linkability in user reviews,” in European
Symposium on Research in Computer Security, 2012.
7. R. Silva and G. Laboreiro and L. Sarmento and T. Grant and E. Oliveira and B.
Maia, “Automatic Authorship Analysis of Micro-Blogging Messages,” in NLDB,
2011.
8. S. R. Boutwell, “Authorship Attribution of Short Messages Using Multimodal Fea-
tures,” in Master Thesis, Naval Postgraduate School, 2011.
9. R. Layton, P. Watters, and R. Dazeley, “Authorship Attribution for Twitter in 140
Characters or Less,” in Cybercrime and Trustworthy Computing Workshop (CTC),
2010.
10. R. Schwartz, O. Tsur, A. Rappoport, and M. Koppel, “Authorship Attribution of
Mirco-Messages,” in EMNLP, 2013.
11. M. Bhargava, P. Mehndiratta, and K. Asawa, “Stylometric Analysis for Authorship
Attribution on Twitter,” in Big Data Analytics, 2013.
12. O. Goga, H. Lei, S. H. K. Parthasarathi, G. Friedland, R. Sommer, and R. Teixeira,
“Exploiting Innocuous Activity for Correlating Users Across Sites,” in WWW,
2013.
13. D. Perito, C. Castelluccia, M. A. Kaafar, and P. Manils, “How Unique and Trace-
able Are Usernames?” in PETS, 2011.
14. D. Irani, S. Webb, K. Li, and C. Pu, “Large online social footprints–an emerging
threat,” in CSE ’09: Proceedings of the 2009 International Conference on Com-
putational Science and Engineering. Washington, DC, USA: IEEE Computer
Society, 2009, pp. 271–276.
15. M. Nanavati, N. Taylor, W. Aiello, and A. Warfield, “Herbert West –
Deanonymizer,” in 6th USENIX Workshop on Hot Topics in Security, 2011.
16. A. Abbasi and H. Chen, “Writeprints: A Stylometric Approach to Identity-Level
Identification and Similarity Detection in Cyberspace,” in ACM Transactions on
Information Systems, 2008.
17. A. Narayanan, H. Paskov, N. Gong, J. Bethencourt, E. Stefanov, E. Shin, and
D. Song, “On the Feasibility of Internet-Scale Author Identification,” in IEEE
Symposium on Security and Privacy, 2012.
18. E. Stamatatos, “A Survey of Modern Authorship Attribution Methods,” in Journal
of the American Society for Information Science and Technology, 2009.
19. A. Narayanan and V. Shmatikov, “Robust De-anonymization of Large Sparse
Datasets,” in IEEE Symposium on Security and Privacy, 2009.
20. “Netflix,” http://www.netflix.com.
21. D. Frankowski, D. Cosley, S. Sen, L. Terveen, and J. Riedl, “You Are What You
Say: Privacy Risks of Public Mentions,” in International ACM SIGIR Conference
on Research and Development in Information Retrieval, 2006.
17
