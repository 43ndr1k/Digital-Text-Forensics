Feature Combination for Genre Classification
Eva Forsbom
evafo@stp.ling.uu.se
Uppsala University/
Graduate School of Language Technology
Artificial Neural Networks MN1
Teacher: Olle Gällmo
Spring 2006
Abstract
In this paper, we describe an experiment on genre classification of Swedish
texts, using as predictors the frequency of the top 50 most frequent words in the
text collection Stockholm-Umeå Corpus (SUC). The purpose of this particular ex-
periment was to find out if the combination of features in a fully-connected feed-
forward multi-layer perceptron (MLP) gives better classification than single fea-
tures in a decision tree.
The 1,040 text samples in SUC, classified into 9 major genres, were divided
into 10 sets, and used for 10-fold cross-validation training of 10 MLPs (50-7-9),
where the hidden layer is supposed to correspond to the 7 stylistic dimensions of
Biber (1995). The result was better than for a previous experiment using a decision
tree (48.6 vs. 58.8% misclassification). Given the simplicity of the predictors, the
sparse data and skewed distribution of genres in the text collection, the result is
rather promising.
In order to explain the knowledge learnt by the MLPs, we also extracted deci-
sion trees from the input and output of the MLPs. Extra input was generated by
sampling from the feature space of the original training data. The resulting trees
used finer distinctions (more branches) than the tree from the previous experiment,
about the same features but with additional split points, and a few more features.
1 Introduction
Many natural language processing applications could benefit from knowing what genre
a document belongs to when processing the document, e.g. for resolving various lexical
and grammatical disambiguities, and for relevance ranking in information retrieval. In
our case, we would ultimately like to use knowledge of genre as guidance in discourse
parsing of texts. The purpose of the experiment here, though, is to see if the com-
bination of features given to a multi-layer perceptron gives better classification than
a previous experiment with decision trees, where single features were used for every
decision node (Forsbom, 2005).
We will follow the genre typology (cf. Appendix A) used in the text collection
Stockholm-Umeå Corpus (SUC, 2002). Based on a previous experiment using decision
1
trees, we expect to find linguistic cues to genre classification in the top 50 most frequent
words in the whole corpus.
In order to see if the total combination of features gives better prediction than the
splitpoints of a decision tree, a multi-layer perceptron (50-7-9) will be used for clas-
sification, where the 50 input nodes correspond to the frequences of the top 50 most
frequent words, the 7 hidden nodes correspond to the 7 stylistic dimensions of Biber
(see Section 2.1), and the 9 output nodes correspond to the 9 genres of SUC.
The paper is organised as follows: First, the concept of genre is introduced in
Section 2.1 together with a short background on rule extraction from trained neural
nets in Section 2.2. In Section 3, a brief description of the features and corpus used
is given, while the setup for the current experiment is described in Section 4. The
outcome is discussed in Section 5, and, finally, some concluding remarks sum up the
paper (Section 6).
2 Background
2.1 Genres
Genre classification is related to both text categorisation, and author attribution and
identification, but the various classification tasks focus on different aspects of lan-
guage (Manning and Schütze, 1999, p. 575). While text categorisation is about clas-
sifying texts in topics or themes (’domain’), genre and author classification is about
distinguishing different styles. In genre classification, it is the functional style that mat-
ters, and in author classification, the issue is the individual variation within a functional
style (van Halteren et al., 2005). Functional, in this respect, refers to the communicative
function of the text, e.g. narrative, expository or instructional function.
Since genre classification is supposed to be based on functional variations of style,
frequences of function words, such as pronouns (her, which) and prepositions (on,
with), have often been used as the feature set for genre classification, as well as author
classification (Lebart et al., 1998, p. 167f). In particular, the highest-frequency func-
tion words have been used, alone or as a complement to other stylometrics (Baayen,
2001, p. 214).
Biber (1995) used 67 linguistic criteria in a multidimensional analysis of the given
genres, as well as some of the subcategories, in the Lancaster-Oslo/Bergen (LOB) and
London-Lund corpora to define 7 English text types along 7 dimensions: 1) involved
vs. informational production, 2) narrative vs. non-narrative discourse, 3) situation-
dependent vs. elaborated reference, 4) overt expression of argumentation, 5) abstract
vs. non-abstract style, 6) online informational vs. edited or not informational, and 7)
“academic hedging”.
2.2 Rule extraction from neural nets
By using combinations of features, neural nets usually do better than decision trees,
which look at a single feature at each decision node. But, the rules in the decision tree
are more transparent for a human than the weights of an MLP, and we would like to
understand the MLPs better.
Several methods have been tried to extract rules from trained MLPs, some of which
are restricted to a particular architecture or to particular input. Global methods treat the
MLP as a black box, while local methods look at each hidden or output node.
2
The quality of the extracted rules can be measured by 1) accuracy, i.e. the fraction
of instances which are correctly classified by the extracted rules, 2) fidelity, i.e. the
fraction of instances where the MLP and extracted rules give the same answer, and 3)
comprehensibility, i.e. the size of rule set and number of antecedents in each rule (for
an overview, see Duch et al. (2004)).
As a global method, the method of training a decision tree on the output from the
MLP, often with more or less sophisticated preprocessing of the MLP output, including
generating interpolated training instances, or adapted splitting criteria for building the
decision tree has often been used (e.g. by Boz (2002); Krishnan et al. (1999); Schmitz
et al. (1999)).
3 Feature selection and corpus
In a previous experiment, we tried to find the subset of words in a base vocabulary
which gave the best classification according to genre using a decision tree, and found
that the best subset was the top 50–100 most frequent words (Forsbom, 2005).
In a related study, Stamatatos et al. (2000b) used the most frequent words computed
from a much larger corpus, British National Corpus, and tested it on a more homoge-
neous set of genres from the Wall Street Journal. They found that the best performance
was with the top 30 words set, and from then on the performance degraded. Used in
combination with punctuation marks, that set was also more stable for fewer training
samples than the other sets. Based on the findings of these two studies, we chose the top
50 most frequent words as our feature set for genre classification for this experiment.
Both the base vocabulary and the text typology on which the classification is based
come from the Stockholm-Umeå Corpus (SUC, 2002), so we begin with a desciption
of the corpus (Section 3.1) before we move on to a description of the base vocabulary
(Section 3.2).
3.1 Corpus
SUC is a balanced corpus of modern Swedish prose covering approximately 1 mil-
lion word tokens. The texts are from the years 1990 to 1994, and they were selected
and classified according to criteria corresponding to the ones used for the Brown cor-
pus (Francis and Kucera, 1979) and the Lancaster-Oslo/Bergen (LOB) corpus (Johans-
son et al., 1986), albeit adapted to Swedish culture. The basic balancing idea of the
compilation was that it should mirror what a Swedish person might read in the early
nineties. The taxonomy of texttypes, i.e. genres and domains, is shown in Appendix A.
The distribution of genres (or main categories) is shown in Figure 1. As can be
noted, the distribution is not ideal for genre analysis, but although SUC is not compiled
for the purpose of genre analysis, and really has too few samples of most genres, it is
the only Swedish larger corpus with other text types than news texts and a given text
typology. Since it has been compiled in the same spirit as other corpora used for genre
classification, it is also possible to compare the results.
SUC consists of text samples from 1,040 texts, grouped into 500 files with an av-
erage of 2,065 tokens per file. The samples were selected at random, but with an effort
to choose coherent stretches of text. For this experiment, we used the 1,040 texts as
instances, since we would like to be able to predict the genre of a single text.
Stamatatos et al. (2000a) tried to find out the minimum size of a corpus for train-
ing genre classifiers, and found that for homogeneous genres, 10 texts per genre were
3
a b c e f g h j k
Genre
F
re
qu
en
cy
0
50
10
0
15
0
20
0
25
0
Figure 1: Distribution of texts per genre in SUC.
enough, and that the lower boundary for text lengths is 1,000 words per text. In SUC,
many of the texts in genre A, Press: Reportage, are much shorter than that, and the
genres cannot be said to be ideally homogeneneous. Given this information, together
with the fact that we are only using one type of feature, we do not expect the classifier
to be perfect.
3.2 Base vocabulary
A base vocabulary is a vocabulary that can be reused for most domains, text types and
applications. We will use a base vocabulary we have previously extracted from SUC.
The units of our base vocabulary are lemmas1, or rather the baseforms from the
SUC annotation disambiguated for part-of-speech, so that the preposition om ’about’
becomes om.S and the subjunction om ’if’ becomes om.CS. They are ranked accord-
ing to relative frequency weighted with dispersion, i.e. how evenly spread-out they
are across the subdivisions of the corpus, so that more dispersed words with the same
frequency are ranked higher. This is done to compensate for accidental peaks of fre-
quency due to certain texts, domains or genres. The weighting scheme used is called
Korrigierte Frequenz (or adjusted frequency) (Rosengren, 1972, p. XXIX), and is given
in Equation 1.
AF =
(
∑ni=1
√
dixi
)2
where
AF = adjusted frequency
di = relative size of category i
xi = frequency in category i
n = number of categories
(1)
The total vocabulary has 69,560 entries, but the base vocabulary is restricted to
entries which occur in at least 3 genres, 8,554 entries, since this turned out to give
the most stable ranking for adjusted frequency across three category divisions (genre,
1A lemma is the baseform of a unique inflectional paradigm, e.g. dog for dog, dog’s, dogs, dogs’.
4
domain, text). Our base vocabulary, therefore, are those words that are not genre and
domain dependent, given the subdivisions of SUC. The top-ranked entries are mostly
function words, but also punctuation marks and stylistically neutral content words, e.g.
words in multi-word function words.
4 Experimental setup
The resulting decision tree for the top 50 most frequent words from the previous ex-
periment is shown in Figure 2. It was built using 10-fold cross-validation, and gives
a cross-validated misclassification estimate of 59%; not a very impressive result, but
better than baseline classifiers classifying according to uniform class probability (89%)
or according to majority class (74%).
|
han.PF< 4.5
eller.CC< 0.5
av.S< 4.5
att.CS< 3.5 man.PI< 0.5
a
c e
h j
k
Figure 2: Decision tree for genre classification using the top 50 most frequent words in
SUC.
Although decision trees are convincingly easy to interpret and good for feature
extraction, they tend to only look at one feature at a time, and do not account well for
dependencies between features. Features that are potentially useful in combination are
easily masked by stronger features. Therefore, for this experiment, we tried a multi-
layer perceptron (MLP), instead, which take dependencies more into account.
Given the scarcity of labelled patterns, we used 10-fold cross-validation for training
10 MLP classifiers with 50 input nodes, 7 hidden nodes, and 9 output nodes. The 50
input nodes correspond to the log-normalised relative frequency of the top 50 most
frequent words of the base vocabulary, the 7 hidden nodes are supposed to represent
Biber’s 7 stylistic dimensions (cf. Section 1), and the 9 output nodes correspond to the
9 genres in SUC.
The experiments were performed within the JavaNNS platform (JavaNNS Group,
5
2002), where each MLP used random initial weights and standard backpropagation,
and ran for 500 epochs.
4.1 Features and values
For each SUC text, frequency counts for the selected features were extracted into a fea-
ture vector. The counts were log-normalised for text length, in the manner frequently
used for topic categorisation (Manning and Schütze, 1999, p. 580). The score, s, in
Equation 2 reflects the fact that an increase in relative frequency suggests that the fea-
ture is important, but the importance is not linearly proportional to the increase, rather
log-linearly proportional.
si j = round(10 ·
1+logt fi j
1+log l j
)
where
si j = score for term i in document j
t fi j = number of occurrences of term i in document j
l j = length of document j
(2)
4.2 Global rules
As a global method for rule extraction, we used the training data output from each
MLP, together with extra input, to train a decision tree, to get an approximation of
what features and kind of rules were used. The extra input was generated by sampling
from the original training data for each fold. For each sample, a genre was randomly
selected from the training data distribution, and for each feature, a value was randomly
selected from the training data distribution for that genre and feature. To ensure that
the generated sample was plausible, the sample was checked against a k-nearest neigh-
bour classifier (Venables and Ripley, 2002), in a similar manner as in the ANN-DT
algorithm Schmitz et al. (1999). If the probability of the classification exceeded a
threshold, the sample was used, otherwise another sample was generated.
The decision trees were trained with the turnkey rpart algorithm in R (R Devel-
opment Core Team (2004); Therneau and Atkinson (2004), based on Breiman et al.
(1984)). The only adaptation we did was in using information gain as splitting crite-
ria instead of the Gini index, since it gave better fidelity. The approximate trees were
trained using 10-fold cross validation.
We tried a number of parameters for generating an optimal set of extra input: 1) the
number of extra input, 2) restricting the classification to the original genre or using the
new classification, 3) the number of nearest neighbours used in plausibility checking,
and 4) the probability threshold. The best set, based on both fidelity and accuracy, was
300 instances, k = 5, same genre, and a probability threshold of 11% (see Table 1).
5 Results
5.1 Classification
As can be seen in Table 2, the 10 MLPs did better than the decision tree on average,
48.6 vs. 58.8% misclassification (12.6% error reduction). The result, however, varied
6
Fidelity (mean±σ ) Accuracy (mean±σ )
Training 55.1±5.1 41.9±4.8
+Interpolated Same class Any class Same class Any class
# Prob. k=10 k=5 k=10 k=5 k=10 k=5 k=10 k=5
25
11 56.3±4.9 55.0±5.8 57.4±5.5 56.6±4.7 42.8±5.0 41.9±5.8 44.1±4.7 43.8±5.3
22 56.6±5.3 55.0±5.8 56.8±6.0 56.9±5.3 43.2±6.1 42.0±5.9 44.2±4.7 44.1±5.6
33 55.0±6.6 55.3±5.5 56.1±5.0 56.8±5.3 42.2±5.7 42.7±5.2 43.9±4.5 44.1±5.6
44 56.3±5.2 56.6±5.3 53.2±7.6 56.9±6.5 44.4±4.3 43.3±5.7 41.4±5.2 43.6±5.4
50
11 56.4±4.8 56.3±6.0 56.7±6.5 55.0±5.7 43.0±5.7 43.7±3.8 44.0±6.3 43.3±5.0
22 55.4±4.3 56.1±5.6 56.8±6.4 56.9±5.3 42.1±4.6 43.2±4.5 43.7±6.7 44.1±5.6
33 56.2±3.9 56.6±5.0 54.3±5.2 56.1±6.0 42.8±3.8 43.7±4.3 42.6±4.6 44.4±6.2
44 54.8±6.6 55.1±6.9 53.6±6.6 55.6±6.6 43.1±5.0 44.2±5.2 41.3±5.0 43.5±6.0
75
11 55.8±6.2 56.3±6.7 55.6±5.1 55.4±4.6 43.7±6.0 43.1±6.5 43.9±5.1 42.6±5.0
22 55.3±5.7 55.2±6.5 55.6±4.8 55.1±6.0 43.0±6.1 42.6±6.9 44.1±4.9 43.0±5.9
33 55.0±5.4 55.4±5.9 55.3±4.9 55.1±6.1 42.3±4.6 43.4±6.7 43.9±5.1 43.2±6.0
44 56.4±5.4 54.0±5.8 55.7±5.0 57.1±4.7 43.4±4.2 43.0±5.2 42.1±3.3 44.4±4.2
100
11 56.2±5.6 54.9±5.0 55.1±4.2 54.3±5.3 43.6±5.1 43.1±5.1 43.3±5.2 42.4±5.6
22 56.0±4.9 56.5±5.1 54.8±4.9 55.3±5.8 44.5±5.4 44.0±5.9 43.1±5.5 42.4±6.4
33 55.1±5.0 57.4±4.9 54.2±4.4 56.7±4.2 42.5±3.6 44.1±6.1 43.4±5.1 42.5±6.0
44 54.8±5.5 53.8±6.7 54.7±4.7 53.9±6.5 43.5±4.0 41.8±5.2 42.1±3.3 41.8±6.0
200
11 55.5±5.7 56.8±4.9 54.5±5.5 55.3±4.7 43.2±4.0 45.2±5.4 43.0±6.0 42.1±5.8
22 55.4±4.4 55.5±6.5 54.3±4.4 54.6±5.0 43.0±5.2 42.2±6.8 43.4±5.4 46.6±5.9
33 53.9±4.3 55.7±6.4 54.3±5.2 55.0±4.9 42.3±5.4 42.1±6.0 43.7±5.8 43.5±5.2
44 54.7±6.2 55.3±5.8 53.9±7.0 56.0±5.4 45.3±5.4 43.6±5.4 42.9±4.8 44.2±4.3
300
11 55.3±6.7 57.3±4.6 52.6±6.7 54.8±5.3 43.0±6.3 46.0±5.5 42.3±6.5 42.5±7.7
22 55.0±5.2 57.4±4.6 51.3±4.1 56.2±6.1 43.8±5.4 44.1±5.0 42.6±4.3 43.1±5.7
33 55.5±5.6 55.9±5.8 54.2±4.8 55.2±5.6 44.2±3.7 43.3±5.0 44.1±4.4 42.5±6.4
44 54.8±5.5 55.9±3.0 52.8±6.4 54.7±5.5 43.5±4.0 44.7±5.6 42.2±4.3 42.8±6.3
400
11 53.9±8.5 54.7±3.9 53.9±5.7 54.7±4.5 41.9±7.1 44.9±6.0 42.3±4.5 43.5±7.0
22 53.9±7.5 56.1±6.8 53.4±5.5 55.9±5.4 42.1±6.9 43.6±6.1 43.9±4.6 44.1±6.8
33 52.0±4.7 56.0±5.1 54.2±4.6 55.5±3.9 43.0±5.7 44.5±4.6 42.8±4.2 43.0±6.6
44 55.1±5.0 54.9±6.1 55.5±5.8 55.1±5.0 43.5±4.0 42.6±7.0 43.4±5.7 43.9±5.9
Table 1: Quality of extracted rules with and without interpolated data (all 10 folds).
a great deal between the various MLPs, from nearly no error reduction at all (1.9%) to
an error reduction of 30.3%.
The amount of misclassification and confusion genres for each genre are listed
in Table 3. The MLPs are best at classifying fiction (k) and worst at classifying the
three genres with the fewest instances in SUC, editorial press (b), biographies (g) and
popular lore (f). They handle the majority class reportage press (a) rather well, and,
more surprisingly, equally well learned and scientific writing (j), which have only a
few more instances than b.
The confusion genres for each genre are generally its rough equivalence classes
given their median feature values: {a, b, c}, {e, h}, {f, g, j, k} (cf. Appendix B). In
this case, the median gives a better discrimination between the genres than the mean.
5.2 Explanation
To see what kind of global rules could be extracted from the 10 MLPs, we used the
best set of extra inputs (cf Section 4.2) in addition to the training data to train decision
trees. As the extracted rules are not of the best quality (an average error reduction of
7
Mean Std dev. Max. Min.
48.6% 5.6% 57.7% 41.0%
Table 2: Misclassification over all 10 folds.
Confusion Genre
Genre a b c e f g h j k Total Misses
a (178) 3 20 31 0 2 26 2 7 91(269) 34%
b 6 (4) 10 31 0 0 13 4 2 66( 70) 94%
c 24 0 (73) 16 0 1 5 4 4 54(127) 43%
e 24 1 14 (41) 3 0 19 15 7 83(124) 67%
f 2 1 0 16 (4) 0 9 27 3 58( 62) 94%
g 0 0 1 6 0 (1) 0 13 6 26( 27) 96%
h 30 1 9 28 3 0 (64) 9 1 81(145) 56%
j 1 0 1 13 3 1 9 (58) 0 28( 86) 33%
k 5 0 2 5 1 4 0 1 (112) 18(130) 14%
Total 92 6 57 146 10 8 81 75 30 505 49%
(270) (10) (130) (187) (14) (9) (145) (133) (142) (1040)
Table 3: Confusion genres for misclassified texts (all 10 folds taken together).
only 6.9% compared to the decision tree from the previous experiment), the results are
only tentative. The 10 MLPs did not produce the same tree, although many of the trees
included the same rules. The approximate decision trees were larger than the one from
the previous experiment, and used more features over and above the ones used by the
previous tree. The previous tree had one rule per genre, while the approximate trees
had one to five rules per genre. The previous tree had no rules for classifying genres b,
f or g, and neither did the approximate trees, except for two trees with a rule for genre
f. Both the previous and the approximate trees used the majority genre a as the default.
The same rules as in the previous tree were used in most approximate trees, but
they were often refined with narrower feature value ranges or more features in combi-
nation. For example, the rule if han.PF<4.5 then k used in the previous tree
was always combined with one or more features to distinguish between the equiva-
lence classes of k, and new splitpoints (e.g. han.PF<1.5) were sometimes used to
distinguish genre a from its equivalence classes.
New features (e.g. sig.PF, kunna.V, and denna.DF) and splitpoints showing
up are listed in Table 4 in order of importance. The higher splitpoints are in general
used high in the trees to distinguish between the rough equivalence genres with fea-
ture values on average above the median {f, (g), j, k} and the others, while the lower
splitpoints in general are used to make finer disticntions between the rough equivalence
with feature values on average below the median, {a, (b), c} and the rest.
6 Concluding remarks
In this paper, we described an experiment on genre classification of Swedish texts,
using as predictors the frequency of the top 50 most frequent words of a base lemma
vocabulary previously derived from the Stockholm-Umeå Corpus, and 50-7-9 multi-
layer perceptrons as classifiers.
We wanted to see if the combination of features in a fully-connected feed-forward
multi-layer perceptron (MLP) gave better classification than single features in a deci-
8
Feature Splitpoint(s) Frequency
han.PF 0.5,1.5,2.5,2.5,4.5 16
denna.DF 0.5,1.5,2.5,3.5 14
(.F 0.5,1.5,2.5,3.5 11
man.PI 0.5,0.5,1.5,2.5 9
eller.CC 0.5,2.5 6
inte.RG 2.5,2.5 6
hon.PF 0.5,3.5,4.5 6
ska.V 1.5,1.5,2.5,3.5 6
att.CS 2.5,3.5 5
".F 3.5 4
och.CC 4.5,5.5 4
sig.PF 3.5 3
kunna.V 2.5 3
).F 1.5,2.5 3
för.S 3.5,4.5 3
den.DF 4.5 2
som.CC 0.5,2.5 2
komma.V 2.5 2
jag.PF 3.5 2
få.V 2.5 2
den.PF 1.5 2
annan.AQ 3.5 2
vara.V 3.5 1
de.PF 2.5 1
en.DI 4.5 1
så.RG 2.5 1
Table 4: Features used in approximate decision trees (all 10 folds).
sion tree induced in a previous experiment, which it did (12.6% error reduction). Given
the simplicity of the predictors, the sparse data and skewed distribution of genres in the
text collection, the result is rather promising.
We also wanted to explain the knowledge learnt by the MLPs by extracting decision
trees from the input and output of the trained MLPs. Although the extracted trees only
approximated the knowledge learnt (average fidelity of 57.3%), we could see that the
resulting trees used finer distinctions (more branches) than the tree from the previous
experiment, about the same features but with additional splitpoints, and a few more
features.
For future research, it would be interersting to see whether another learning method
could do better than the MLPs, or equally good with better understandability, e.g. de-
cision trees induced by genetic programming.
9
References
R. Harald Baayen. Word Frequency Distributions. Text, Speech and Language Technology 18.
Kluwer Academic Publishers, Dordrecht, The Netherlands; Boston, Massachusetts, USA, and
London, England, 2001. ISBN 0-7923-7017-1.
Douglas Biber. Dimensions of register variation: A cross-linguistic comparison. Cambridge
University Press, Cambridge, UK, 1995. ISBN 0-521-47331-4.
Olcay Boz. Extracting decision trees from trained neural networks. In Proceedings of the eighth
ACM SIGKDD international conference on Knowledge discovery and data mining, pages
456–461, Edmonton, Alberta, Canada, July 2002. URL http://citeseer.ist.psu.
edu/article/boz02extracting.html.
Leo Breiman, Jerome H. Friedman, Richard A. Olshen, and Charles J. Stone. Classification
and Regression Trees. The Wadsworth Statistics/Probability Series. Wadsworth International
Group, Belmont, California, USA, 1984. ISBN 0-534-98053-8.
Włodzisław Duch, Rudy Setiono, and Jacek M. Z̀urada. Computational intelli-
gence methods for rule-based data understanding. Proceedings of the IEEE,
92(5):771–805, May 2004. URL http://ci.uofl.edu/zurada/papers/
ZuradaSetionoDuchPIEEE2004.pdf.
Eva Forsbom. Feature extraction for genre classification, 2005. URL http://stp.ling.
uu.se/~evafo/gslt/statmet/statmet05forsbom.pdf. Term paper for the
GSLT course Statistical Methods.
W. Nelson Francis and Henry Kucera. Manual of information to accompany a Standard Sample
of Present-day Edited American English, for use with digital computers. Providence, R.I.,
USA, 1979. URL http://www.hit.uib.no/icame/brown/bcm.html. Original
ed. 1964, revised 1971, revised and augmented 1979.
JavaNNS Group. JavaNNS: Java Neural Network Simulator, version 1.1. Wilhelm-Schickard-
Institute for Computer Science (WSI), University of Tübingen, Germany, 2002. URL http:
//www-ra.informatik.uni-tuebingen.de/software/JavaNNS/.
Stig Johansson, Eric Atwell, Roger Garside, and Geoffrey Leech. The Tagged LOB Corpus
Users’ Manual. Bergen, Norway, 1986. URL http://www.hit.uib.no/icame/
lobman/lob-cont.html.
R. Krishnan, G. Sivakumar, and P. Bhattacharya. Extracting decision trees from trained neural
networks. Pattern Recognition, 32(12):1999–2009, 1999.
Ludovic Lebart, André Salem, and Lisette Berry. Exploring Textual Data. Text, Speech and
Language Technology 4. Kluwer Academic Publishers, Dordrecht, The Netherlands; Boston,
Massachusetts, USA, and London, England, 1998. ISBN 0-7923-4840-0.
Christopher D. Manning and Hinrich Schütze. Foundations of Statistical Natural Language
Processing. The MIT Press, Cambridge, Massachusetts, USA and London, England, 1999.
ISBN 0-262-13360-1. Sixth printing with corrections 2003.
R Development Core Team. R: A language and environment for statistical computing. R Founda-
tion for Statistical Computing, Vienna, Austria, 2004. URL http://www.R-project.
org.
Inger Rosengren. Ein Frekvenzwörterbuch der deutschen Zeitungssprache. CWK Gleerup, Lund,
1972.
10
Gregor P. J. Schmitz, Chris Aldrich, and François S. Gouws. ANN-DT: an algorithm for extrac-
tion of decision trees from artificial neural networks. IEEE Transactions on Neural Networks,
10(6):1392–1401, November 1999.
Efstathios Stamatatos, Nikos Fakotakis, and George Kokkinakis. Automatic text categorization
in terms of genre and author. Computational Linguistics, 26(4):461–485, 2000a. URL http:
//www.icsd.aegean.gr/lecturers/stamatatos/papers/CL2000.pdf.
Efstathios Stamatatos, Nikos Fakotakis, and George Kokkinakis. Text genre detection using
common word frequencies. In Proceedings of the 18th International Conference on Com-
putational Linguistics (COLING2000), pages 808–814, Saarbrücken, Germany, July 31 -
August 4 2000b. URL http://www.icsd.aegean.gr/lecturers/stamatatos/
papers/COLING00.pdf.
SUC. Stockholm-Umeå corpus. Version 2.0. Stockholm University, Department of Linguistics
and Umeå University, Department of Linguistics, 2002.
Terry M. Therneau and Beth Atkinson. rpart: Recursive Partitioning, 2004. R package version
3.1-20. R port by Brian Ripley <ripley@stats.ox.ac.uk>. S-PLUS 6.x original at http:
//www.mayo.edu/hsr/Sfunc.html.
Hans van Halteren, Harald R. Baayen, Fiona Tweedie, Marco Haverkort, and Anneke Neijt.
New machine learning methods demonstrate the existence of a human stylome. Journal of
Quantitative Linguistics, 12(1):65–77, 2005.
W. N. Venables and B. D. Ripley. Modern Applied Statistics with S. Springer, New York,
fourth edition, 2002. ISBN 0-387-95457-0. URL http://www.stats.ox.ac.uk/
pub/MASS4.
11
A SUC taxonomy
ID Genre ID Domain
A Press: Reportage AA Political
AB Community
AC Financial
AD Cultural
AE Sports
AF Spot News
B Press: Editorial BA Institutional
BB Debate articles
C Press: Reviews CA Books
CB Films
CC Art
CD Theater
CE Music
CF Artists, shows
CG Radio, TV
E Skills and Hobbies EA Hobbies, amusements
EB Society press
EC Occupational and trade union press
ED Religion
F Popular Lore FA Humanities
FB Behavioral sciences
FC Social sciences
FD Religion
FE Complementary life styles
FF History
FG Health and medicine
FH Natural science, technology
FJ Politics
FK Culture
G Biographies, essays GA Biographies, memoirs
GB Essays
H Miscellaneous HA Government publications
HB Municipal publications
HC Financial reports, business
HD Financial reports, non-profit organisations
HE Internal publications, companies
HF University publications
J Learned and scientific writing JA Humanities
JB Behavioral sciences
JC Social sciences
JD Religion
JE Technology
JF Mathematics
JG Medicine
JH Natural science, technology
K Imaginative prose KK General fiction
KL Science fiction and mystery
KN Light reading
KR Humour
12
B Median and Median Absolute Deviation
In the following table, the median and median absolute deviation for each feature and
genre are listed. The median is a clearer discriminator than the mean, and since word
frequencies usually are not distributed according to the normal curve, the median ab-
solute deviation, taking less notice of long tails, is a better measure of spread than the
standard deviation.
Values above the median for all genres are given in bold, and values below the
median for all genres are given in bold italics. If the difference lies only in median
absolute deviation, the value is represented in italics.
Rank Feature Median and Median Absolute Deviation (MAD)
All A B C E F G H J K
1 ..F 6.0±0.0 6.0±1.5 6.0±0.0 6.0±0.0 6.0±0.0 7.0±0.0 7.0±0.0 6.0±0.0 6.0±0.0 7.0±0.0
2 ,.F 5.0±1.5 5.0±1.5 5.0±1.5 5.0±1.5 5.0±1.5 6.0±0.0 6.0±0.0 5.0±1.5 6.0±0.0 6.0±0.0
3 och.CC 5.0±1.5 4.0±1.5 5.0±0.0 5.0±0.0 5.0±1.5 6.0±0.0 6.0±0.0 5.0±1.5 6.0±0.0 6.0±0.0
4 i.S 5.0±1.5 5.0±1.5 5.0±0.0 5.0±1.5 5.0±0.0 6.0±0.0 6.0±0.0 5.0±1.5 6.0±0.0 5.0±0.0
5 en.DI 5.0±1.5 4.0±1.5 5.0±0.0 5.0±0.0 5.0±1.5 5.5±0.7 6.0±0.0 5.0±1.5 6.0±0.0 6.0±0.0
6 vara.V 5.0±1.5 4.0±1.5 5.0±0.0 5.0±0.0 5.0±0.0 5.0±1.5 6.0±0.0 5.0±1.5 5.0±0.0 6.0±0.0
7 den.DF 5.0±1.5 4.0±1.5 5.0±0.0 4.0±1.5 5.0±1.5 5.0±0.0 6.0±0.0 5.0±1.5 6.0±0.0 5.0±0.0
8 på.S 4.0±1.5 4.0±1.5 4.0±0.0 4.0±1.5 5.0±0.7 5.0±0.0 5.0±0.0 4.0±1.5 5.0±0.0 5.0±0.0
9 det.PF 4.0±1.5 3.0±1.5 4.0±1.5 4.0±1.5 5.0±1.5 5.0±0.0 5.0±0.0 4.0±1.5 4.0±1.5 5.0±0.0
10 av.S 4.0±1.5 3.0±1.5 4.0±1.5 4.0±1.5 4.0±1.5 5.0±0.0 5.0±0.0 5.0±1.5 5.0±0.0 4.0±0.0
11 ha.V 4.0±1.5 3.0±1.5 4.0±1.5 3.0±1.5 4.0±1.5 5.0±0.0 5.0±0.0 4.0±1.5 4.0±1.5 5.0±0.0
12 att.CI 4.0±1.5 3.0±1.5 4.0±1.5 3.0±1.5 4.0±1.5 5.0±0.0 5.0±0.0 4.0±1.5 5.0±0.0 5.0±0.0
13 som.PH 4.0±1.5 3.0±1.5 4.0±1.5 4.0±1.5 4.0±1.5 5.0±0.0 5.0±0.0 4.0±1.5 5.0±0.0 4.5±0.7
14 för.S 4.0±1.5 3.0±1.5 4.0±0.0 3.0±1.5 4.0±0.7 5.0±0.0 5.0±0.0 5.0±1.5 5.0±0.0 4.0±0.0
15 att.CS 4.0±1.5 3.0±1.5 4.0±0.0 2.0±1.5 4.0±0.0 5.0±0.0 5.0±0.0 4.0±1.5 5.0±0.0 5.0±0.0
16 med.S 4.0±1.5 3.0±1.5 3.0±1.5 4.0±1.5 4.0±1.5 5.0±0.0 4.0±1.5 4.0±1.5 5.0±0.0 5.0±0.0
17 till.S 4.0±1.5 3.0±1.5 3.0±1.5 3.0±1.5 4.0±1.5 4.0±0.7 5.0±0.0 4.0±1.5 5.0±0.0 4.0±0.0
18 inte.RG 3.0±1.5 2.0±3.0 4.0±1.5 3.0±1.5 4.0±1.5 4.0±1.5 4.0±1.5 3.0±1.5 4.0±0.0 5.0±0.0
19 “.F 2.0±3.0 0.0±0.0 3.0±1.5 3.0±3.0 3.0±1.5 3.0±3.0 5.0±0.0 0.0±0.0 4.0±1.5 3.0±3.0
20 han.PF 2.0±3.0 1.0±1.5 1.0±1.5 3.0±1.5 1.0±1.5 1.0±1.5 4.0±1.5 0.0±0.0 1.0±1.5 6.0±0.0
21 kunna.V 3.0±1.5 1.0±1.5 3.0±1.5 2.0±1.5 3.0±1.5 4.5±0.7 4.0±0.0 3.0±1.5 4.0±1.5 4.0±0.0
22 jag.PF 0.0±0.0 0.0±0.0 0.0±0.0 0.0±0.0 1.0±1.5 1.0±1.5 5.0±1.5 0.0±0.0 1.0±1.5 5.0±1.5
23 -.F 3.0±1.5 2.0±3.0 1.5±2.2 2.0±3.0 4.0±1.5 3.0±1.5 4.0±1.5 3.0±1.5 3.0±1.5 4.0±1.5
24 som.CC 3.0±1.5 1.0±1.5 2.0±1.5 3.0±1.5 3.0±1.5 4.0±1.5 4.0±0.0 3.0±1.5 4.0±0.0 4.0±0.0
25 sig.PF 3.0±1.5 1.0±1.5 2.0±1.5 3.0±1.5 3.0±1.5 3.0±1.5 4.0±0.0 1.0±1.5 3.5±0.7 4.0±1.5
26 ska.V 3.0±1.5 1.0±1.5 3.0±1.5 1.0±1.5 3.0±1.5 3.0±1.5 3.0±1.5 3.0±1.5 3.0±1.5 4.0±0.0
27 de.PF 2.0±3.0 0.0±0.0 2.0±1.5 1.0±1.5 3.0±1.5 4.0±1.5 3.0±0.0 1.0±1.5 3.0±1.5 4.0±1.5
28 men.CC 3.0±1.5 2.0±3.0 2.0±1.5 2.0±1.5 3.0±1.5 4.0±0.7 4.0±0.0 1.0±1.5 3.0±1.5 4.0±0.0
29 om.S 3.0±1.5 1.0±1.5 2.0±1.5 2.0±1.5 3.0±1.5 4.0±1.5 4.0±0.0 3.0±1.5 4.0±1.5 4.0±0.7
30 vi.PF 1.5±2.2 0.0±0.0 1.0±1.5 0.0±0.0 3.0±3.0 3.0±3.0 4.0±1.5 1.0±1.5 2.5±2.2 3.0±1.5
31 få.V 3.0±1.5 2.0±3.0 2.0±1.5 1.0±1.5 3.0±1.5 3.0±1.5 3.0±1.5 3.0±1.5 3.0±1.5 4.0±0.0
32 man.PI 2.0±3.0 0.0±0.0 1.5±2.2 1.0±1.5 3.0±1.5 4.0±1.5 3.0±1.5 0.0±0.0 3.0±1.5 3.0±1.5
33 sin.PS 2.0±1.5 1.0±1.5 2.0±1.5 3.0±1.5 3.0±1.5 3.0±1.5 4.0±1.5 2.0±1.5 3.0±1.5 4.0±0.7
34 från.S 3.0±1.5 1.0±1.5 1.0±1.5 1.0±1.5 3.0±1.5 3.0±1.5 3.0±1.5 3.0±1.5 3.5±0.7 3.0±1.5
35 eller.CC 2.0±3.0 0.0±0.0 1.0±1.5 1.0±1.5 2.0±1.5 3.0±1.5 3.0±1.5 2.0±3.0 3.0±1.5 3.0±1.5
36 så.RG 2.0±1.5 0.0±0.0 1.0±1.5 2.0±1.5 3.0±1.5 3.0±1.5 3.0±0.0 1.0±1.5 3.0±1.5 4.0±0.0
37 komma.V 2.0±1.5 1.0±1.5 2.0±1.5 1.0±1.5 2.0±1.5 2.0±1.5 3.0±1.5 2.0±1.5 3.0±1.5 4.0±0.0
38 hon.PF 0.0±0.0 0.0±0.0 0.0±0.0 0.0±0.0 0.0±0.0 0.0±0.0 1.0±1.5 0.0±0.0 0.0±0.0 4.0±1.5
39 när.RH 2.0±1.5 0.0±0.0 1.0±1.5 1.0±1.5 2.0±1.5 3.0±1.5 3.0±1.5 2.0±1.5 2.0±1.5 4.0±0.0
40 om.CS 2.0±1.5 0.0±0.0 1.0±1.5 1.0±1.5 2.0±1.5 3.0±1.5 3.0±1.5 1.0±1.5 2.0±1.5 3.0±1.5
41 bli.V 2.0±1.5 1.0±1.5 1.0±1.5 1.0±1.5 3.0±1.5 3.0±1.5 3.0±1.5 1.0±1.5 2.0±1.5 3.0±0.0
42 den.PF 1.0±1.5 0.0±0.0 1.0±1.5 1.0±1.5 1.0±1.5 3.0±1.5 4.0±0.0 1.0±1.5 2.0±1.5 3.0±1.5
43 ).F 1.0±1.5 0.0±0.0 0.0±0.0 1.0±1.5 1.0±1.5 3.0±1.5 3.0±1.5 1.0±1.5 4.0±1.5 0.0±0.0
44 (.F 1.0±1.5 0.0±0.0 0.0±0.0 1.0±1.5 1.0±1.5 3.0±1.5 3.0±1.5 1.0±1.5 4.0±1.5 0.0±0.0
45 stor.AQ 2.0±1.5 0.0±0.0 1.0±1.5 1.0±1.5 2.0±1.5 3.0±1.5 3.0±1.5 2.0±1.5 3.0±1.5 2.0±1.5
46 finnas.V 2.0±1.5 0.0±0.0 1.0±1.5 1.0±1.5 2.0±1.5 3.0±1.5 2.0±1.5 2.0±1.5 3.0±1.5 2.0±1.5
47 göra.V 2.0±1.5 0.0±0.0 1.0±1.5 1.0±1.5 2.0±1.5 2.0±1.5 3.0±1.5 1.0±1.5 3.0±1.5 3.0±1.5
48 annan.AQ 2.0±1.5 0.0±0.0 1.0±1.5 0.0±0.0 1.5±2.2 3.0±1.5 3.0±1.5 2.0±1.5 3.0±1.5 3.0±1.5
49 denna.DF 1.0±1.5 0.0±0.0 1.0±1.5 0.0±0.0 1.0±1.5 3.0±1.5 3.0±1.5 2.0±1.5 4.0±0.0 2.0±1.5
50 någon.DI 2.0±1.5 0.0±0.0 1.0±1.5 1.0±1.5 2.0±1.5 2.5±0.7 3.0±1.5 1.0±1.5 3.0±0.0 3.0±0.0
13
