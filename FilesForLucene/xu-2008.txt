Genre Identification of Chinese Finance Text using
Machine Learning Method
Jun Xu, Yuxin Ding, Xiaolong Wang, Yonghui Wu
Department of Computer Science and Technology
Harbin Institute of Technology Shenzhen Graduate School
Shenzhen, China
hit.xujun@gmail.com yxding@hitsz.edu.cn
Abstract—Document genre information is one of the most dis-
tinguishing features in information retrieval, which brings order
to the search results. What the genre classification concerned
is not the topic but the genre of document. In this paper, we
examine the effectiveness of using machine learning techniques
to solve genre classification of Chinese text with the same topic,
viz. finance. Based on the likelihood ratio test, we present a
new method for selecting feature terms, which can improve the
performance clearly and perform better than others with up to
80% terms removal. In empirical results with SVMs classifier
on the real world corpora, we find that this method can gain a
better selecting effect and likelihood ratio is a reliable measure
for selecting informative features.
Index Terms—Genre Classification, Likelihood Ratio Test,
Support Vector Machines
I. INTRODUCTION
As the developing of the WWW, the available information
is becoming abundant than before. However, even with the
help of search engine, it’s still hard to find the most suitable
information due to the huge amount of abundant information.
In order to help user to acquire relevant and useful information,
classification and cluster tools are imported to classify search
engine results. All these techniques are topic-centered, succeed
in topic classifying, and neglect the importance of identifying
the genres in results ranking, takes little account of the
individual user’s needs and preferences.
Our research focus on professional financial search. In
finance domain, different genres of information have different
authority which is important. Positive or negative news will
influence the price of a stock. Depending on circumstances,
users are always interested in certain or particular genres of
information. For example, financial analysts are interested in
objective news and announcement. But most of common in-
vestors pay more attention to the different opinions in financial
reviews. So, a further classification by different genres will be
very useful for investment decision making.
This paper makes the following contributions:
1). To investigate the feasibility of genre classification of
Chinese finance documents using machine learning. We wish
to investigate whether machine learning can successfully be
applied to the task of genre classification.
2). To investigate the possibility of a feature selection
method which can get a good compromise on performance
and size of feature. We wish to produce a classifier which is
accurate and efficient enough to be applied to financial search
with large collections of documents.
The structure of this paper is as follows. Section 2 intro-
duces genre classification and sketches out existing work, de-
scribes the genre classes of finance text. Section 3 describes the
new term selection method through the purpose ,the theory and
the algorithm. Section 4 describes the classifier and the corpus
chosen for empirical validation, presents the experiments and
the results. At last, discusses the major findings. Section 5
summarizes the conclusions and future work.
II. GENRE CLASSIFICATION
A. Genre Classification
There is no agreement on the definition of genre. The term
”genre” is used frequently in connection with music, with
literature and arts. Literally, genre is a category of artistic
composition, as in music or literature, marked by a distinctive
style, form, or content [1]. Outwardly, genre can be viewed
through the macro-features, so-called genre facets [2]: amount
of graphics, several pictures, or many links, etc. Inside, it
can be viewed through the facets: subjectivity, wording and
phrasing, etc.
Genre classification is often regarded as orthogonal to the
classification based on the document’s contents. It groups a set
of documents into same sets according to the predefined genre
classes. Here we give a problem statement about the genre
classification: Let C = {c1, c2, ...cm} be a set of categories
(genre classes) and D = {d1, d2, ...dn} a set of documents.
The task of the genre classification consists in assigning class
label ci to each document dj , if the document dj belong to ci,
which exactly one category must be assigned to each dj . It is
single-label text categorization.
B. Genre Classes
Prior research on genre classification defined genre classes
correspond to individual task. In this paper, We describe the
genre of finance text through the subjectivity, the style of
writing, the form, the targeted audience and the functional trait.
Finance text can be divided into three main types:
1).Announcement, which is an official or authoritarian
declaration, such as exchange notice, circular in respect of very
substantial acquisition, or clarification of announcement from
board meeting.
455
1-4244-2384-2/08/$20.00 c© 2008 IEEE
Authorized licensed use limited to: Aegean University. Downloaded on July 27,2010 at 15:27:58 UTC from IEEE Xplore.  Restrictions apply. 
TABLE I
THE DIFFERENCE BETWEEN ANNOUNCEMENT, NEWS REPORTS AND OPINION&REVIEW
Category Announcement News Opinion
Subjectivity objective low subjectivity subjective
Author company reporter analyst
Authority authoritative low authority no authority
Style official formal informal
2).News report, which present factual information objec-
tively. News reports was published by newspapers or dis-
tributed electronically on financial news sites, and written by
reporter. News reports are supposed to be objective in the
reporting of the latest stock prices and various events that are
likely to influence the stock price of a particular company.
Pure objectivity in factual news reporting could be too ideal
in reality. Most of news reports have certain subjectivity. It is
not only the objective description to the affairs, but also joins
author’s personal judgment and the standpoint.
3).Review&opinion that describe authors’ views, estima-
tion and judgments about stock or a company, give implications
of events of the day for future stock prices and advise on
investment. Reviews appear in columns such as ”Opinion”,
”Forum”, ”Blog”, are written by a single judge like analyst
or blogger. Since it is a personal viewpoint or belief, opinions
vary widely on a given subject by different people. Of course,
opinions are subjective.
C. Related Work
There is a lot of work on genre identification. Most re-
search are three-step approach: i) Definition of particular
genre classes of respective domain. ii) Selection of features.
iii) quantification of the classification methods. The methods
and features of automatic genre identification are relatively
independent tasks, so in the following we give a brief of the
existing work in respect of methods and features.
Traditional text classification techniques perform well on
genre classification. For corpus-specific genre classification,
they have either used term frequency analysis(sometimes called
bag-of-word, BOW) [3] or a linguistic approach involves
POS tagging [4] [5]. In previous research [6], the linguistic
approaches do achieve better accuracy than term frequency ap-
proaches. Finn et al. [4] investigate different features: Bag-of-
Words, Part-of-Speech statistics, and text statistics for building
genre classifiers and their ability to transfer across multiple
topic domains. All three techniques proved to be effective
in single domain tests in English. Working across domains
and across languages is a more challenging and complex task.
Peng et al. [7] present a simple method based on character-
level n-gram language models to classify genre. The method
view documents merely as a sequence of characters, without
requiring feature selection or extensive pre-processing which
makes it easy to implement. Eissen et al. [8] gives an overview
of features for genre classification.
Genre classification of web pages is a popular topic now.
The presentation-related features are commonly used for this
kind of task [8] [9]. This type of features relate to the
appearance of a document, such as hyperlinks, amount of
graphics and tables, HTML tags, URL specifications, etc. Lim
et al. [10] used URL depth, presence of a filename at the
end of the URL, document type (HTML, ASP, PHP etc.),
top-level domain and genre-specific words in the URL (faq,
news, board, detail etc.) as features. Eissen et al. [8] show
that with a small set of features, which captures linguistic and
presentation related aspects, text statistics, and word frequency
classes, acceptable classification results can be achieved. Their
analysis reveals that about 70% of the documents are assigned
correctly.
III. FEATURE SELECTION
We are focusing our work on devising machine learning
techniques that understand and parse the purpose of the docu-
ment that the search engine retrieves. We want to find a feature
selection method for vocabulary reduction in consideration of
the following:
1). To filter those terms which are only topic-related. All the
retrieval results have the same topic: finance. These features
are either non-informative for category prediction, or not
influential in global performance.
2). To achieve good performance with a small number of
representative features. These features should have a higher
document frequency to avoid sparse vector in document repre-
sentation. These features also should not be too common, such
as the stop words are frequent words but carry no information.
3). To select the features with high class discrimination
power which can represent genres well and get better per-
formance in the automatic classification. These features are
class-discriminating terms.
4). To reduce the computation of time, while retaining
higher accuracy. Since search engine is a large scale ap-
plication, a high accuracy and efficiency is necessary. The
decreasing feature numbers can improve the efficiency but lose
accuracy. A good feature selection algorithm can reduce fea-
ture space aggressively and have no or little loss of accuracy.
We design this feature selection algorithm to find features
which could discriminate between genres of document with the
same topic better. The algorithm of feature selection is based
on the likelihood ratio test [11]. Likelihood ratio test has been
applied successfully in opinion mining [12] and the detection
of new terms [11].
A. Likelihood Ratio Test
Let C be a collection of documents with same label c, C ′ is
the collection of all the documents with different label, and cft
456 2008 IEEE International Conference on Systems, Man and Cybernetics (SMC 2008)
Authorized licensed use limited to: Aegean University. Downloaded on July 27,2010 at 15:27:58 UTC from IEEE Xplore.  Restrictions apply. 
TABLE II
COUNTS OF A FEATURE TERM
C C′
cft f11 f12
cft f21 f22
is a feature term. Using the two-way contingency table(Table
II ) of a term cft and the category c, where f11 is the number
of times cft and c co-occur, f12 is the number of time the cft
occurs without c, f21 is the number of times c occurs without
cft, f22 is the number of times neither c nor cft occurs.
In applying the likelihood ratio test to feature selection, the
following two hypotheses are assumed:
Hypothesis 1:P (d ∈ C|cft ∈ d) = p = P (d ∈ C|cft ∈
d),i.e. the relevancy of document d is independent of the
presence cft.
Hypothesis 2:P (d ∈ C|cft ∈ d) = p1 = p2 = P (d ∈
C|cft ∈ d),i.e. the relevancy of document d is independent
of the presence cft assuming p1  p2.
Assuming that each cft is Bernoulli event, and
b(p, k, n) =
(
n
k
)
pk(1 − p)n−k
Log of the likelihood ratio λ is then as follows:
logλ = log
L(H1)
L(H2)
= log
b(p, f11, f11 + f12) ∗ b(p, f21, f21 + f22)
b(p1, f11, f11 + f12) ∗ b(p2, f21, f21 + f22)
λ is a likelihood ratio of a particular form, then the quantity
−2 log λ is asymptotically χ2 distributed and then computed
as follows:
−2logλ =
{ −2 ∗ lr p2 < p1
0 p2 ≥ p1
p1 =
f11
f11 + f12
p2 =
f21
f21 + f22
p =
f11 + f21
f11 + f12 + f21 + f22
lr = (f11 + f21) log p + (f12 + f22) log(1 − p)
− f11 log p1 − f12 log(1 − p1) − f21 log p2 − f22 log(1 − p2)
The higher the value of −2logλ, the more likely the cft is
relevant to the class C and important to the classification of
C and C ′.
B. Feature Selection Based on Likelihood Ratio Test(LRT)
We computed for each category the likelihood ratio between
each unique term in a training corpus and that category, and
Input: T , A set of collections of documents with labels;
v, Pre-defined likelihood score threshold; n,
Pre-defined required numbers of features, if
non-zero,keep at least this many features even if
their likelihoodd scores are less than v
Output: F , A list of selected features for classification
Method:
Step 1: Scan T ,Generate candidate feature terms list L
with Stat. info;
Step 2:
for each candidate feature term f ∈ L do
for each Ci ∈ T do
C ′ =
⋃
Cj , All Cj ∈ T and j = i;
compute f ’s likelihood score l(f, Ci) between
CiandC ′;
end
if UseAvg then
l(f) =
∑
Pr(Ci) ∗ l(f, Ci);
end
else
l(f) = MAX{l(f, Ci)};
end
add (f, l(f)) to F ′;
end
Step 3:
if 0 = n then
add top n features in F ′ to F ;
end
else
add all features in F ′ to F whose l(f) ≥ v
end
return F ;
Algorithm 1: LRT Feature Selection Algorithm
then combined the category specific ratios of each term into
two scores:
lavg(f) =
∑
Pr(Ci) ∗ l(f, Ci)
lmax(f) = MAX{l(f, Ci)}
The algorithm (Algorithm 1.)is used here to find the
category-discriminating terms. The higher the likelihood score,
the higher discrimination power the feature term have. Con-
fined to the size and coverage of training data, such features
can not be numerous. So there should be a compromise on the
size and the discrimination power of the features.
IV. EXPERIMENTS AND ANALYSIS
A. Data Collections
Using the definitions and class descriptions developed, the
corpus we used for this paper was collected from internet.
There are 1,689 documents with human assigned genre labels
in the full collection. The corpus was divided randomly into
a training set and a test set. Table III shows the partition of
training set and test set, and the distribution of documents in
the corpus. The training set has 19,422 unique terms.
2008 IEEE International Conference on Systems, Man and Cybernetics (SMC 2008) 457
Authorized licensed use limited to: Aegean University. Downloaded on July 27,2010 at 15:27:58 UTC from IEEE Xplore.  Restrictions apply. 
TABLE III
PARTITION AND CLASS DISTRIBUTION OF THE CORPUS
News Opinion Announcement
training set 311 355 178
test set 311 355 179
total 622 710 357
B. Experimental Settings and Performance Measures
For Chinese lexical analysis, we select the ELUS [13]
system to segment and tag the corpus for our research. It is one
of the best lexical analyzers in the Chinese natural language
with high segmentation and tag accuracy.
Support Vector Machine is a popular technique for clas-
sification, and have been shown to be highly effective at
traditional text categorization. For our research, we chose to
use libSVM [14], an open source SVM package. The libSVM
package has several kernel functions available, and we chose
to use the radial basis functions (RBF) for training and testing,
with all parameters set to their default values. The results are
reported in this paper uses term frequency as feature weight.
The effectiveness of a feature selection method is evaluated
by the performance of classifier. Since our task is a multi-class
categorization, our experiments adopted precision and recall
for each category. For comprehensive study and evaluating
performance average across categories, we adopted macro-
averaging F1 and micro-averaging F1. Micro-averaging gives
equal weight to every document, while macro-averaging gives
equal weight to each category.
C. Primary Results and Discussion
Table IV and Table V show the summary of recall and
precision for each category. The LRT method with options
avg and max were tested with a number of different term-
removal thresholds. Both precision and recall increases when
the number of features for training increases. Compare to the
results reported in Table VI , when considering only the best
performance of the classifier, CHI(χ2 statistic), LRT method
have similar effects on preserving up to about 25%(5000) or
more of the unique terms.
Figure 1 and Figure 2 display the performance curves
after term selection with CHI and LRT respectively. We tested
the two options, avg and max, and the results are represented
in the figures. LRTmax has a better performance with up-to
80% term removal.
Like CHI, LRT is task-sensitive which uses the category
information. The LRT uses term absence to predict the cat-
egory probability. For a term t, if PrC(t) = PrC′(t), then
R1 = R2 = size of C/total number of docs, so l(t) =
0. LRT removes all these terms. Its bias towards the terms with
large disparity between category probability PrC(t). LRTmax
prefer to choose the terms which has higher discrimination
power on one category, but LRTavg bias towards discrimina-
tion power on all category. The number of features with high
category-discrimination power is limited. This is the reason
LRTmax has a better performance on smaller size of features.
Fig. 1. Micro Average F1 vs Number of Features
Fig. 2. Macro Average F1 vs Number of Features
V. CONCLUSIONS AND FUTURE WORK
This paper gives a new approach to feature selection based
on likelihood ratio test, which can improve the performance
with more than 80% terms removal. The paper has compared
the feature selection algorithm with CHI . In empirical results
on the real world corpora, we find that the LRTmax can
gain a better selecting effect and likelihood ratio is a reliable
measure for selecting informative features. Considering about
the conflict between the features size and the classification
performance, we can see that the trained classifier with about
3,000 features which were selected by LRTmax method is
one of the best choice for our system. And machine learning
method can successfully be applied to identify the genres of
Chinese finance text.
In the future, we will investigate the generation of other
feature sets, such as dates, times, name entities, statistics on
words sentences and document, structural features as POS,
sentence type etc., looking for the features has a significant
458 2008 IEEE International Conference on Systems, Man and Cybernetics (SMC 2008)
Authorized licensed use limited to: Aegean University. Downloaded on July 27,2010 at 15:27:58 UTC from IEEE Xplore.  Restrictions apply. 
TABLE IV
RESULTS OF EXPERIMENT WITH LRTavg (N:NEWS REPORTS O:OPINION&REVIEW A:ANNOUNCEMENT)
No Number N O A Micro Macro
of Features Recall Precision Recall Precision Recall Precision Average F1 Average F1
1 10000 91.00 87.89 88.73 91.57 97.77 97.77 92.44 91.48
2 5000 89.07 89.35 87.04 90.62 96.09 88.66 90.08 89.67
3 3000 85.53 89.86 92.11 78.99 72.07 95.56 84.95 85.39
4 2000 84.24 87.92 90.14 75.29 63.69 93.44 81.28 82.18
5 1000 81.03 86.30 89.58 69.89 52.51 95.92 76.66 78.13
6 500 81.03 82.08 87.32 66.67 40.22 98.63 71.44 73.89
TABLE V
RESULTS OF EXPERIMENT WITH LRTmax(N:NEWS REPORTS O:OPINION&REVIEW A:ANNOUNCEMENT)
No Number N O A Micro Macro
of Features Recall Precision Recall Precision Recall Precision Average F1 Average F1
1 10000 91.64 87.69 88.17 92.88 97.77 95.63 92.26 91.47
2 5000 89.07 89.64 86.48 91.37 97.21 87.00 90.01 89.67
3 3000 85.85 89.60 84.51 88.50 96.65 83.17 87.85 87.53
4 2000 85.53 87.79 90.42 76.07 64.25 95.83 82.06 82.90
5 1000 81.99 86.15 89.58 70.20 52.51 97.92 77.03 78.47
6 500 83.28 84.09 91.55 71.27 43.02 95.06 74.35 77.02
TABLE VI
RESULTS OF EXPERIMENT WITH CHIavg (N:NEWS REPORTS O:OPINION&REVIEW A:ANNOUNCEMENT)
No Number N O A Micro Macro
of Features Recall Precision Recall Precision Recall Precision Average F1 Average F1
1 10000 91.00 87.62 87.89 92.31 97.77 95.11 91.91 91.11
2 5000 87.78 91.00 87.04 90.62 98.88 86.76 90.19 89.77
3 3000 85.53 88.67 90.99 79.36 74.30 96.38 85.25 85.44
4 2000 84.57 87.67 90.14 75.12 62.57 94.12 81.07 82.03
5 1000 81.03 85.14 89.01 69.45 50.84 96.81 75.91 77.46
6 500 80.06 83.56 89.01 66.95 40.78 97.33 71.89 74.38
impact on genre identification. We will also investigate other
non-machine learning methods, such as subjective Bayesian
method. The other major product for our future work is to
develop a finance search engine which combine the genre
classification to improve the users experience.
ACKNOWLEDGMENT
This investigation was supported in part by the National
Natural Science Foundation of China ( No. 60435020 and
No. 90612005) and the National 863 Program of China(No.
2006AA01Z197).
REFERENCES
[1] The American Heritage Dictionary of the English Language. Houghton
Mifflin Company, 2000.
[2] B. Kessler, G. Nunberg, and H. Schtze, “Automatic detection of text
genre,” in Proceedings of the 35th Annual Meeting of the Association
for Computational Linguistics and Eighth Conference of the European
Chapter of the Association for Computational Linguistics, Madrid, Spain,
1997.
[3] E. Stamatatos, N. Fakotakis, and G. Kokkinakis, “Text genre detection
using common word frequencies,” in Proceedings of the 18th Int.
Conference on Computational Linguistics, Saarbrcken, Germany, 2000.
[4] E. Finn and N. Kushmerick, “Learning to classify documents according
to genre,” in IJCAI-03 Workshop on Computational Approaches to Style
Analysis and Synthesis, 2003.
[5] M. Santini, “A shallow approach to syntactic feature extraction for genre
classification.” in Proceedings of the 7th Annual Colloquium for the UK
Special Interest Group for Computational Linguistics, Birmingham, UK,
2004.
[6] E. Stamatatos, G. Kokkinakis, and N. Fakotakis, “Automatic text cat-
egorization in terms of genre and author,” Computational Linguistics,
vol. 26, no. 4, pp. 471–495, 2000.
[7] F. Peng, D. Schuurmans, and S. Wang, “Language and task independent
text categorization with simple language models,” in Proceedings of
Conference of the North American Chapter of the Association for
Computational Linguistics on Human Language Technology, Edmonton,
Canada, 2003.
[8] S. M. zu Eissen and B. Stein, Genre Classification of Web Pages: User
Study and Feasibility Analysis. Berlin: Springer, 2004.
[9] E. S. Boese and A. E. Howe, “Effects of web document evolution
on genre classification,” in Proceedings of the 14th Conference on
Information and Knowledge Management, Bremen, Germany, 2005.
[10] C. S. Lim, K. J. Lee, and G. C. Kim, “Multiple sets of features for au-
tomatic genre classification of web documents,” Information Processing
and Management, vol. 41, no. 5, pp. 1263–1276, September 2005.
[11] D. Ted, “Accurate methods for the statistics of surprise and coincidence,”
Computational Linguistics, vol. 19, pp. 61–74, 1993.
[12] J. Yi, T. Nasukawa, R. Bunescu, and W. Niblack, “Sentiment analyzer:
Extracting sentiments about a given topic using natural language pro-
cessing techniques,” in Proceedings of the Third IEEE International
Conference on Data Mining, November 2003.
[13] W. JIANG, X.-L. WANG, Y. GUAN, and J. ZHAO, “Research on chinese
lexical analysis system by fusing multiple knowledge sources,” Chinese
Journal of Computers, vol. 30, no. 1, pp. 137–145, 2007.
[14] C.-C. Chang and C.-J. Lin, LIBSVM:a library for support vector ma-
chines, http://www.csie.ntu.edu.tw/ cjlin/libsvm/, 2001.
2008 IEEE International Conference on Systems, Man and Cybernetics (SMC 2008) 459
Authorized licensed use limited to: Aegean University. Downloaded on July 27,2010 at 15:27:58 UTC from IEEE Xplore.  Restrictions apply. 
