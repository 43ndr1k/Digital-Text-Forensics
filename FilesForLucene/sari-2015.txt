IJDAR
DOI 10.1007/s10032-015-0254-y
ORIGINAL PAPER
Structural feature-based evaluation method of binarization
techniques for word retrieval in the degraded Arabic document
images
Toufik Sari1 · Abderrahmane Kefali1 · Halima Bahi1
Received: 16 August 2014 / Revised: 14 July 2015 / Accepted: 18 September 2015
© Springer-Verlag Berlin Heidelberg 2015
Abstract One of the most important and necessary steps
in the process of document analysis and recognition is the
binarization, which allows extracting the foreground from
the background. Several binarization techniques have been
proposed in the literature, but none of themwas reliable for all
image types. Thismakes the selection of onemethod to apply
in a given application very difficult. Thus, performance eval-
uation of binarization algorithms becomes therefore vital.
In this paper, we are interested in the evaluation of bina-
rization techniques for the purpose of retrieving words from
the images of degraded Arabic documents. A new evalu-
ation methodology is proposed. The proposed evaluation
methodology is based on the comparison of the visual fea-
tures extracted from the binarized document images with
ground truth features instead of comparing images between
themselves. The most appropriate thresholding method for
each image is the one for which the visual features of the
identified words in the image are “closer” to the features
of the reference words. The proposed technique was used
here to assess the performances of eleven algorithms based
on different approaches on a collection of real and synthetic
images.
Keywords Binarization · Word spotting · Document
retrieval · Thresholding evaluation · Edit distance ·
Performance assessment
B Abderrahmane Kefali
kefali@labged.net
Toufik Sari
sari@labged.net
Halima Bahi
bahi@labged.net
1 LabGED Laboratory, Badji Mokhtar University,
Annaba, Algeria
1 Introduction
The libraries, museums and institutions with pedagogic or
sociopolitical concerns contain considerable collections of
documents, mostly handwritten. Historical documents of old
civilizations and public archives are typical examples of such
richness, which represent the patrimony and the nation’s his-
tory. In fact, these documents incur a progressive degradation
because they are not preserved in good conditions and there-
fore they are threatened with a real danger of disappearance.
Amethodof preserving documents is to scan and to save them
as images. But alone, the digitalization is not sufficient; it
must be accompanied by tools and techniques allowing their
automatic processing and analysis.
In most cases, automatic processing and analysis of docu-
ment images pass through a binarization step, i.e., a transition
from a gray scale or color image to an image in black
and white. The main objective of this step is to reduce
the amount of information in the image (remove the back-
ground and noise) and only preserve the relevant information
(text, figures, tables), which allow using simple methods
against grayscale or color images. The following steps in
the document processing depend strongly on the results of
the binarization. In this way, the binarization is a critical
step; imperfect binarization may cause the loss of relevant
information or the insertion of some noise, and in both cases
generating wrong results. This difficulty increases for old
manuscripts full of deteriorations and damages during their
life cycle, making their automatic processing difficult at sev-
eral levels.
Consequently, a great number of techniques have been
proposed in the literature for the binarization of gray-level
or color images, and this number increases continually each
year. Also, several papers surveyed the literature of bina-
rization methods. Despite the great number of proposed
123
T. Sari et al.
binarization techniques, none of them was reliable for all
image types, and even for the same type, the results were dif-
ferent froman image to another [10]. Thismakes the selection
of onemethod in the context of a particular system a very dif-
ficult task. Performance evaluation of binarization algorithms
is therefore essential to find the best suitable algorithm for
a given application, thus is an important research subject.
While devising newer image segmentation algorithms has
attracted significant attention, relatively fewer efforts have
been done for the evaluation specifically for recognition pur-
poses [49].
The evaluation of thresholding algorithms is not an easy
task because there is no standard evaluation process to com-
pare the results, especially taking into account the different
objectives for which the evaluation is intended for: OCR,
categorization, segmentation, retrieval, etc. Different meth-
ods, measures and criteria have been proposed to estimate
the quality of the binarized images.
Ntirogiannis et al. [25] established a classification of the
evaluation methodologies of thresholding into three cate-
gories. In the first category, the evaluation is done by a human
viewer. In the second, the binarization results are imputed to
an OCR engine and the binarization quality stands for the
recognition rate. The third category combined human eval-
uation and OCR accuracy. The work in [26] added a fourth
category using a binary images as ground truth, and the eval-
uation was done by comparing the two images (the ground
truth and the binarization results) at pixel level. Another
classification is proposed by Kumar et al. [18] in which
the evaluation strategies are grouped into three categories:
supervised-pixel, supervised-components and recognition-
based strategies. In the last strategy, the OCR results are used
for the evaluation. Since the binarization in fact image seg-
mentation in text and background, the segmentation quality
assessment (SQA) has been used for binarization evalua-
tion. Zhang et al. [50] classified the different methods of
SQA into two categories: subjective and objective. Objective
evaluation is decomposed into two groups: direct evaluation
and system-level evaluation. In the direct evaluation, we can
distinguish two groups: analytical and empirical. Empirical
methods are finally divided into two classes: unsupervised
methods and supervised methods.
In this paper, we focus on the binarization as a preprocess-
ing step in the process of pattern retrieval in the degraded
Arabic documents. Since our goal is to identify the best bina-
rization method for our retrieval system, we propose here
a new evaluation methodology which avoids the OCR and
reduces the human intervention in the preparation of ground
truth data. In this methodology, the quality of a binarization
method is judged by the performance of the final phase of
the retrieval process. The basic principle is to compare the
visual features extracted from the binarized images instead
of comparing images themselves.
The rest of the paper is organized as follows. Section 2
presents the state of the art of previous evaluation works of
thresholding techniques and classifies them into categories.
Section 3 provides the details of our evaluation method-
ology. Section 4 draws the experimental results on both
synthetic and real document images and compares the pro-
posed approach with other competing methods. Conclusions
are made in the final section.
2 State of the art of previous work: performances,
advantages and limits
In this section, we will study the various techniques used
for performance evaluation of binarization methods. We will
separate them into categories and mention their uses, advan-
tages and limits.
2.1 Subjective evaluation
The human subjective evaluation remains acceptable and
widely adopted in applications needing human judgment.
It makes sense as the human is the ultimate viewer or
observer. The visual subjective evaluation is the most fre-
quently used evaluation technique. In this kind of evaluation,
several human subjects are asked to name the best binariza-
tion method. It may be done directly [8,15,19,20,30], or
according to well-defined visual criteria where the viewer
assigns a score to each image. Som et al. [42], for example,
evaluated the binarization methods in terms of the rate of
symbols recognized by a human. In [45], the authors used
five criteria: broken line structures, broken symbols, text,
etc., blurring of lines, symbols and text, loss of complete
objects, noise in homogeneous areas. This type of evaluation
has the advantage of being guided by the goal, but, however
is very subjective, time-consuming, lacks of robustness [25]
and gave dubious and inaccurate results. In addition, different
viewers can disagree with each other for the same images.
2.2 Analytical evaluation
Analytical methods examine and assess segmentation algo-
rithms independently of their results by analyzing their
principle, requirements, properties, utility, complexity, etc,
while some properties of the segmentation algorithms can
easily be obtained by analysis, other properties cannot
because no formal model is known. These properties are
generally independent of the quality of the obtained segmen-
tation results; thus, they are not effective for the estimation of
the real performance of segmentation algorithms [49]. The
work of Kamel and Zhao [11] assessed their new proposed
method with other methods from the literature following:
123
Structural feature-based evaluation method of binarization techniques for word retrieval in…
memory requirement, speed, stroke width restriction, num-
ber of parameters, parameter setting.
2.3 System-level evaluation
The system-level evaluation examines the impact of a seg-
mentation method on the whole system and is directed by
the final goal. This approach allows system designers to
affirm or not that a segmentationmethod is appropriate based
on the empirical system performance. Unfortunately, this
evaluation method is indirect, when the steps following the
segmentation generate superior results, it does not necessary
mean that the segmentation results were superior, and vice
versa.Noting that, the system-level results fromdifferent seg-
mentation methods simply indicate that the characteristics of
the results were more suitable for that particular system [49].
An evaluation directed by character segmentation in the
binarized image was proposed in [17]. The performance of a
thresholdingmethod is thus the number of correctly extracted
characters to the total number of characters in the image.
Woo [48] proposed a new criterion, the MNFS (Minimum
Number of Foreground Segments) related to specific features
of footprints images, in order to compare six thresholding
methods for subsequent analysis of scanned insect footprints.
Therefore, certainly the most used system for empirical eval-
uation in the case of document images was the OCR.
2.3.1 OCR-based evaluation
Asdescribed in [13], an objective evaluation approach should
involve an OCR tool to test the readability of non-noisy
images. Several works employed the OCRs as assessors.
Among the evaluation works of this class, we note that of
Trier and Jain [46], in which the authors studied the perfor-
mance of different global and local thresholding algorithms
based on the number of digits correctly classified. Another
work is that of He et al. [10] which used the commercial
recognition software Abbyy 6.0 to compare five binariza-
tion algorithms on historical documents. In [28], O’Gorman
compared seven thresholding techniques on thirty pages
of newspapers of poor quality. The evaluation was done
by calculating the recognition rate of the binarized images
by a commercial recognition software (Calera model RS
9000). Leedham et al. [21] proposed two new threshold-
ing techniques and compared them with three methods of
the literature. The evaluation was performed on 40 docu-
ment images of four different types (historical manuscript
documents, checks, forms, and newspaper pages) and was
expressed in terms of recall and precision. Gatos et al. [6],
evaluated binarization techniques on historical documents of
poor quality. Gupta et al. [9] tested the performance of thresh-
olding algorithms for historical Latin printed documents
retrieval and indexing. The evaluation was made on 12 news-
paper images andwas estimated by the recognition rate using
the commercial recognition softwareABBYY FineReader 7.1
SDK. The recognition rate is also used in [19] to quantify the
performance of thresholding methods on images of histori-
cal documents. In [3], themusic recognition softwareAruspix
evaluated several thresholding algorithmson images fromold
music books in terms of the recognition recall and precision
measures.
Noting that the use of OCR as an evaluator allows provid-
ing a clear quantitative decision but it may only be applied
on modern printed documents, supported by contemporary
recognition engines [13]. In the case of Arabic historical doc-
uments, subject of our work, where the poor quality prevents
the recognition, thisway of assessment cannot be considered.
2.4 Unsupervised evaluation
Theunsupervisedmethods alsoknownas empirical goodness
methods evaluate the performance of segmentation algo-
rithms by estimating the quality of the segmented images
based on how well it matches a broad set of characteristics
of segmented images as expected by humans. Different types
of measures, such as the intra-region uniformity, inter-region
contrast, and the region shape have been proposed. The unsu-
pervised evaluation is quantitative and objective. Its main
advantage is that it not requires any reference image mak-
ing it relevant for a wide range of conditions (or systems)
and different types of images, where reference images do
not exist or are very tedious to obtain. However, experiments
have shown that unsupervisedmethods are less effective than
supervised ones [5].
Sahoo et al. [37] used two unsupervised measures for the
evaluation: Uniformity measure andshape measure. In [41],
Region nonuniformity measure is used in combination with
other supervised measures for assessing the performances
of thresholding algorithms. In [35], the most appropri-
ate measures for OCR applications are: weighted variance
anduniform variance. Kumar et al. [18] devised a new
measure for assessing the binarized images. The proposed
measure is evolved fromprincipal component analysis (PCA)
and is based on eigenvalues decomposition. A feature matrix
is constructed for each class from the binarized images. The
columns of these matrices are the normalized gray values.
The number of rows equals to the number of pixels belonging
to this class. Thus, two matrices are obtained. One esti-
mates the covariance matrices of the two sets of vectors.
The eigenvalue decomposition is performed on the covari-
ance matrices. Then, the product of eigenvalues is calculated
for each binarized image. The binarized image with the max-
imum product value is chosen as the best binarized image.
As authors noted, the selected binarized image may not be
of good quality for recognition, but it provides an objective
measure to choose from a set of binarized images.
123
T. Sari et al.
2.5 Supervised evaluation
Supervised evaluation methods, also known as discrepancy
empirical methods, compare the segmented images with a
set of pre-established reference images (the ground truth)
and the discrepancy determines the segmentation quality.
A potential advantage of supervised methods, compared to
unsupervised ones, is that the direct comparison between a
segmented image and a reference image is assumed to pro-
vide a finer resolution of the evaluation problem. The major
drawback of these methods is the requirement of reference
images which is very tedious to obtain for real applications.
A solution to circumvent this problem is to use synthetic
images. A semiautomatic method of ground truth image gen-
eration has been proposed in [25]. This method is used by the
organizers ofDIBCO2009 [7],H-DIBCO2010 [31],DIBCO
2011 [32], H-DIBCO 2012 [33], DIBCO 2013 [34], and H-
DIBCO 2014 [27] competitions to prepare the ground truth
images. In [47], the above semiautomatic ground truthing
method was compared to some fully manual ground truthing
results especially on DIBCO 2009 images. However, the
author explores the variability that exists when images are
ground truthed by humans and how this might affect the eval-
uation of automated binarization algorithms. The accuracy is
evaluated with four metrics.
We distinguish two types of supervised techniques.
2.5.1 Supervised-pixel evaluation (at pixel level)
This evaluation technique is widely used. It evaluates each
pixel whether it is well classified or not through the definition
of several statistical quantitative measures [14]. Hence, the
employed measures are calculated by comparing the bina-
rized images with ground truth images. This evaluation is
performed at pixel level and does not fit tasks such as recog-
nition or retrieval. In this technique, either the noise is added
to the ground truth images in order to obtain synthetic gray-
level images, or the original grayscale images are binarized
by human subjects by some cleaning operations to have intel-
ligible black and white images.
In [36], the following measures were used to estimate the
performance of eight thresholding algorithms: the percentage
of correct classification (PCC), Jaccard coefficient (JC), Yule
coefficient (YC). Sezgin and Sankur [41] combined five cri-
teria: misclassification error (ME), edge mismatch (EMM),
relative foreground area error (RAE), modified Hausdorff
distance (MHD) and region nonuniformity (RU) to assess
the binarization algorithms on two types of images: docu-
ment images and natural images. Stathis et al. [43] performed
an evaluation on historical documents using: mean square
error (MSE), signal-to-noise ratio (SNR), peak signal-to-
noise ratio (PSNR) and pixel error rate (PEER). Pixel-level
evaluationwas also used inDIBCO1 2009, H-DIBCO2 2010,
DIBCO 2011, H-DIBCO 2012, and DIBCO 2013 competi-
tions. In DIBCO 2009 [7], the following measures were
used: F-measure, PSNR, negative rate metric (NRM), mis-
classification penaltymetric (MPM). InH-DIBCO2010 [31],
the evaluation was done using the following measures: F-
measure, Pseudo F-measure, PSNR,NRM,MPM. InDIBCO
2011 [30], we find F-measure, PSNR, MPM, and distance
reciprocal distortion metric (DRD). In the context of H-
DIBCO2012 [33], themeasures used are: F-measure, PSNR,
and DRD.
However, objective measures do not always agree with
the human subjective evaluation. For example, the PSNR,
which is one of thewell-usedmeasures, has not well matched
with subjective assessment; since it is a pixel-based measure,
the mutual relation between pixels is not captured [22]. In
contrast, the DRD measure provides an effective mean for
gauging the distortion in the binary images. It is better than
PSNR in the sense that it takes the human visual percep-
tion into account and hence correlates well with subjective
assessment [22].
2.5.2 Supervised-component evaluation
In the supervised-component evaluation, the connected com-
ponents or features measured from the ground truth image
are used in the evaluation. Nitrogiannis et al. [25] evaluated
binarization algorithms by comparing the skeletons of the
different binarization algorithms resultswith reference skele-
tons in terms of F-measure, precision, recall, false alarms,
missing text, broken text and deformations. In [5], a new tech-
nique has been proposed for the automatic selection of the
most optimal binarization algorithm in four steps. The pro-
posed technique is basedon edgedetection, feature extraction
and machine learning.
3 Evaluation methodology
We describe in this section our proposed methodology for
the objective evaluation of thresholding algorithms. As we
said earlier, the assessment is not designed to find a generic
method for all systems but to answer a specific goal which
is in our case the pattern, or word, retrieval in the images
of degraded Arabic documents. Therefore, the utility of a
binarization method is judged by the performance of the
final phase of the retrieval system. We will use for that a
modified version of our Arabic document retrieval system
proposed in [38]. The basic idea is to compare the extracted
features of text documents, which were binarized by several
1 Document image binarization contest.
2 Handwritten document image binarization competition.
123
Structural feature-based evaluation method of binarization techniques for word retrieval in…
Fig. 1 General outline of the
evaluation methodology
Comparison
Edit Distance 
Ground truth 
signature
(GTS)
Expert
Degraded document 
Image 
Méthode de 
seuillage
éthode de 
seui lage
……………
……………
Thresholding 
methodBinarization
Image binariséeImage binariséeImage binariséeBinarized image
SignatureSignatureSignatureSignat r
Line/ PAW
Segmentation
Feature extraction
Coding
Skew correction
thresholding algorithms, with ground truth features instead
of comparing the images themselves. This is justified by the
fact that, on one hand, these features describe the writing
which is one of the main subjects of retrieval systems, and
on the other hand, the preparation of the ground truth features
is much less difficult and less expensive than the preparation
of ground truth images.
The principle is as follows: We first represent each image
from our test collection with a signaturemade of all relevant
information that we can extract from text documents. This
signature contains features of the writing and is encoded in
ASCII. The obtained signature is considered as ground truth
signature (GTS) [38].Afterward,we binarize each test image
by several binarization methods and on each resulting binary
image we apply a series of processing aiming to extract the
features of the writing and coding them as a textual signature.
This latter will be compared with the GTS, and the difference
is quantified by the edit distance. The scheme of Fig. 1 sum-
marizes the steps involved in the evaluation process.
3.1 Preparation of ground truth signatures (GTS)
The first thing to do is to prepare for each document image
the corresponding GTS. The GTS of a document is a tex-
tual description of the structural features of the writing of the
document, explicitly we use: diacritical points which may
be single or multiple points above or below the main body
of characters, ascenders and descenders, which correspond
to high and low extensions, respectively; and loops corre-
Fig. 2 Structural features present in an Arabic word
sponding to occlusions. Figure 2 shows an example of such
features.
To do this, an expert visually analyzes the documents in
order to extract the various existing structural features. Each
feature is assigned a code: A for ascenders, D for descenders,
L for loops, H for high diacritical points and Q for down
diacritical points. Thus, theGTSof a document is obtained by
concatenating the codes of the different identified structural
features, and separating the PAWs (Part of Arabic Word)
with a semicolon. Considering that Arabic script is cursively
written from right to left, the GTS of the word in Fig. 2 is:
“HHA;HHLD;HHA”.
The use of synthetic images can significantlyminimize the
time of preparing GTSs by automating the feature extraction
process and limiting the human intervention only to the cor-
rection of possible errors.
A synthetic image is obtained by superposing a binary,
clear and well-written, Arabic document image considered
as ground truth image (GTI) with a mask of old backgrounds
123
T. Sari et al.
using the Mosaicing technique by maximum intensity [43].
On each GTI, we apply a series of processing in order to be
able at the end to extract a reliable textual signature represent-
ing the text structural features. An expert is asked to check
and rectify possible errors. The evaluation using synthetic
images is summarized in Fig. 3.
3.2 Processing of binarized document images
On each (real or synthetic) image of the test collection, we
apply the different thresholding methods, considered in the
evaluation, and the resulting binary images are subject to a
number of treatments to have their signatures. The processing
steps are as follows:
(a) Skew correction
The old documents in our collection are sometimes slanted,
and so require a skew correction procedure (Fig. 4). To do
this, we used a skew correction method based on the partial
projection technique. This method proceeds in five steps:
1. Division of the image in columns of fixed size (100 pix-
els).
2. Calculation of the histogram of horizontal projections for
each column.
3. Extraction of baselines corresponding to the peaks of his-
tograms calculated before.
4. Calculation of the skew angle θ of the document as the
average of all the angles formed by two baselines of two
successive columns.
5. Rotation of the image by the angle θ .
(b) Segmentation into lines and PAWs
After smoothing and skew correction, we must extract the
PAWs of the text. The choice to work with PAWs is justi-
fied by the fact that they seem to offer a better compromise
between the complexity of the segmentation of handwritten
Arabic words in letters and the global approach which han-
dles the whole words and thus needs a dictionary of limited
size. To extract the PAWs, we first need to segment the text
into lines.
Fig. 3 General outline of the
evaluation methodology using
synthetic images
ComparisonEdit 
distance
Mask of old 
background 
Mosaicing
Ground truth 
images GTI
Ground truth 
Signature 
GTS
Line/PAW 
Segmentation
Feature extraction
Coding
Expert
Synthetic degraded 
document Image
Binarization
Méthode de 
seuillage
éthode de 
seui lage
…………
…………
Thresholding 
methods
Binarized Images Image binariséeBinarized images
Line/ PAW 
Segmentation
Feature extraction
Coding
SignatureSignatureSignatureSignatures
Skew correction
123
Structural feature-based evaluation method of binarization techniques for word retrieval in…
Fig. 4 Skew correction. a Skewed image, b aligned image
Fig. 5 Line segmentation. a
Original image, b segmented
image
Text lines separation is done by using the density mea-
sure of white lines in the horizontal projections (Fig. 5). The
algorithm proceeds as follow:
1. Calculation of the horizontal projection histogram of the
image.
2. Extraction of the local minima corresponding to the sep-
aration zones between lines.
3. Filtering of the minima by eliminating the minima hav-
ing a width lower than a predetermined threshold and by
removing one of the twominima which are closer to each
other.
4. Resolution of the conflicts by assigning the black pixels
existing in the separating zones to the nearest text line.
Afterward, the PAWs are extracted from each text line.
In Arabic writing, a PAW corresponds to a principal con-
nected component (the body) and some auxiliary connected
components representing diacritic marks. PAWs extraction
consists of labeling the different connected components of
the image and then assigning each diacriticmark to its PAW’s
body. Connected components labeling is done by gathering
the neighboring black pixels in a separate unit (Fig. 6).
Fig. 6 Text line segmented into connected components
Deciding whether a connected component is a diacritic
mark, or not, is based on the observation that diacritics
are generally smaller than letters’ bodies. Connected com-
ponents whose size is below a predefined threshold are
therefore considered as diacritic marks. The threshold is cho-
sen related to the average size of connected components:
Threshold = average size/n. where n is determined by
experiments. Finally, the diacritics are assigned to the body
of the nearest PAW.
(c) Feature extraction
This phase should guarantee maximum reliability, because
the extracted features determinate the signature which repre-
sent the document identity. A fundamental problem in image
analysis is to determine which features we should use to
get good results. Structural primitives coming from human
perception related to the writing shapes are considered rele-
vant for the discrimination of handwritten characters [4]. We
choose to extract from each PAWfour structural features, i.e.,
ascenders, descenders, loops (or holes) and diacritic points.
To do it, we apply:
– Baseline detection: By definition, the baseline is the
virtual line onwhich cursive or semi-cursivewriting char-
acters are aligned and/or joined [2]. The baseline in the
Arabic text carries significant information of text orienta-
tion and the positions of diacritic points. The most used
method for baseline detection is the horizontal projec-
tions of text lines. The baseline corresponds to the line
whose projection contains the greatest number of black
pixels (the red line in Fig. 7).
123
T. Sari et al.
Fig. 7 Baseline and median zone detected on a text line (color figure
online)
Fig. 8 Features extracted from a text line (color figure online)
– Median zone detection: The main part of an Arabic word
or character appears in a zone called the median zone.
This zone, delimited by two borders: upper and lower the
baseline, is identified by analyzing the horizontal projec-
tion histogram. To draw the higher border, respectively,
the lower, we first calculate the average number of pix-
els in each row existing above, respectively, below, the
baseline. After that, we traverse these rows bottom-up,
respectively, top-bottom, to find the first line containing
the lowest number of pixels to the average. This line cor-
responds to the upper border, respectively, lower border.
In Fig. 7, the upper and lower borders are drawn in blue.
– Contour following: The contour following is commonly
used for extracting structural features. The contour of a
PAW is the set of points delimiting the stroke where each
point is coded by its direction according to the Freeman
code.
We can now extract the various features:
– Diacritics: A connected component is considered as a
diacritic point if its size is lower than a predefined thresh-
old.
– Descenders: correspond to slopes below the median
zone.
– Ascender: are elongations upper the median zone.
– Loops: loops are useful for the identification of certain
characters. To detect loops, we look for contour points
inside other contours.
Each feature is represented by a different color in Fig. 8.
(d) Coding
After extracting features, an ASCII signature is assigned to
the document as described for preparing the GTSs: ascen-
ders with A, descenders with D, loops with L , high diacritic
points with H and lower diacritic points with Q. A semicolon
separates adjacent PAWs. For example, the text in Fig. 8 is
coded as from right to left:
D;HQQDH;DH;HAQD;QH;HA;HD;D;HA;
QD;QH;HA
3.3 Comparison
Finally, for each image in the test collection, their differ-
ent signatures obtained from binarization results of different
methods are compared to the GTS. We use for that the edit
distance from [41].
Given two images represented by two signatures noted
X = (x1, . . . , xm) and Y = (y1, . . . , yn).
To determine the edit distance between these two
sequences, we compute a matrix D ofm rows and n columns
where D(i, j) is the distance of the alignment of the subse-
quence pairs starting at 1 and ending at i and j , respectively.
The values of the matrix D are:
D (i, j) =
⎧
⎨
⎩
D (i, j − 1)
D (i − 1, j)
D (i − 1, j − 1)
⎫
⎬
⎭
+ c (xi , y j
)
(1)
with c(xi , y j ) is the mapping cost between xi and y j .
The distance between the two signatures is contained in
the last cell of the matrix D.
The best thresholding algorithm for each image in the test
collection is then the one with the minimal distance.
4 Experiments and results
For the purposes of this study, we selected eleven binariza-
tion methods, cited below, and were reimplemented in Java
by ourselves and applied on two datasets of images and
the performances have been evaluated separately for each
dataset. For local methods, we used same parameter values
as described in the original papers. It is well beyond the scope
of this paper tomake an in-depth reviewof all used algorithms
and their parameters.
Note that experiments were run on a standard PC with
core i3 CPU at 2.20GHz, 4GB RAM running the Windows
7 OS.
4.1 Binarization methods
The binarization methods considered in the evaluation are
the following:
1. Otsu’s method [29]: one of the most known global meth-
ods.
2. Kapur et al.’s method [12]: representing entropic meth-
ods.
3. Bernsen’s method [1]: local method based on local gray
range.
4. Niblack’s method [23]: classical local technique based
on local variation.
5. Sauvola and Pietikainen’s method [40]: famous local
thresholding technique based on local variation.
123
Structural feature-based evaluation method of binarization techniques for word retrieval in…
6. Wolf and Jolian’s method [47]: another local method
based on local variation.
7. Nick’s method [19]: based on local variation.
8. Su et al.’s method [44]: winner in H-DIBCO 2010 com-
petition.
9. Howe’s method [24]: winner in H-DIBCO 2012 compe-
tition.
10. Kefali et al.’s method [16]: neural network-based bina-
rization technique.
11. Sari et al.’s method [39]: hybrid and two stage-based
binarization technique.
4.2 Datasets
Two datasets of images have been used in the experiments
(a) First dataset
The first dataset contains 50 images of degraded Arabic doc-
uments collected from the Web, and thus they do not have
the same characteristics. They are very different in nature,
taken from several sources, covering several fields, present-
ing different types of degradations of old documents.Most of
them deal with religion and sociology and others talk about
mathematics, natural science and medicine including herbal.
Since we are interested essentially in documents with textual
content rather than graphical illustrations, the first two kinds
were preferred. Figure 9 shows two images of this set.
(b) Second dataset
The second dataset is composed of synthetic images. In fact,
the reduced cost of obtaining ground truth signatures from
synthetic images compared to real imagesmakes possible the
use of a large number of images in the experiments.
These images havebeen createdusing the fusion technique
by Mosaicing proposed by Stathis et al. [43]. So, 300 doc-
ument images have been obtained by the fusion of 30 clean
images (images in black and white selected from PDF doc-
uments) containing printed and/or handwritten text with 10
images of empty old backgrounds collected from theWeband
representing themost of problems of old documents (stains of
ink and humidity, shadows, folds and tears, etc.). An example
of synthetic image is shown in Fig. 10.
4.3 Evaluation scheme
The aim of the experiments is not only to use the pro-
posed methodology to assess the performance of different
binarization algorithms, but also to verify its robustness, con-
sistency with other evaluation approaches, and to find the
most appropriate algorithm for Arabic degraded document
retrieval application.
In order to show the relevance of the proposed evaluation
method to word retrieval, and to determine how well the
usedmeasure (the edit distance) relates to the performance of
the whole system, we conducted word retrieval experiment.
At the end, the performance of binarization techniques is
measured by recall and precision. Hence, the retrieval system
proposed in [38] is employed.
In conjunction with the goal-directed evaluation using
our methodology, we conducted a supervised-pixel evalu-
ation in order to have a global view of the performances of
binarization techniques. We used four well-known empiri-
cal measures that have been used in DIBCO and H-DIBCO
competitions. These measures are: F-measure (FM), peak
signal-to-noise ratio (PSNR), negative rate metric (NRM),
misclassification penalty metric (MPM).
Fig. 9 Examples of real Arabic document images
123
T. Sari et al.
Fig. 10 Example of synthetic image. a Old background, b black and white image, c synthetic image
Noting TP, TN, FP, FN, are true-positive, true-negative,
false-positive and false-negative values, respectively.
(a) F-measure (FM)
FM = 2× Recall× Precision
Recall+ Precision . (2)
where
Recall = TP
TP + FN and Precision =
TP
TP+ FP
(b) Peak signal-to-noise ratio (PSNR)
PSNR is a similaritymeasure between two images. However,
the higher the value of PSNR, the higher the similarity of the
two images.
PSNR = 10 · log
(
C2
MSE
)
. (3)
where MSE =
∑M
x=1
∑N
y=1 (I (x,y)−I2(x,y))2
MN
I and I2 represent the two images, M and N their height
and width, respectively. C is the difference between fore-
ground and background (here 255).
(c) Negative rate metric (NRM)
NRM is based on the pixel-wise mismatches between the
ground truth and the binarized image. It combines the false-
negative rate NRFN and the false-positive rate NRFP. It is
denoted as follows:
NRM = NRFN + NRFP
2
. (4)
with NRFN = FN
FN+ TP and NRFP =
FP
FP+ TN .
The better binarization quality is obtained for lowerNRM.
(d) Misclassification penalty metric (MPM)
The misclassification penalty metric (MPM) compares the
binarization result with the ground truth, object by object.
MPM = MPFN +MPFP
2
. (5)
where MPFN =
∑FN
i=1 diFN
D and MPFP =
∑FP
j=1 d
j
FP
D d
i
FN and d
j
FP
denote the distance of the i th false-negative and the j th false-
positive pixel from the contour of theGTI. The normalization
factor D is the sum over all pixel-to-contour distances of
the ground truth object. A low MPM score denotes that the
algorithm is good at identifying an object’s boundary.
In order to estimate the robustness of the proposed eval-
uation methodology on a high level, we have performed
goal-directed and supervised-pixel evaluations together with
visual subjective evaluation. Thereby, five viewers have been
asked to examine the binarization results of the different
methods, and classify them according to their results from
the best to the worst (from 1 to 11). Finally, we calculate for
each method the average scores.
4.4 Obtained results
The eleven binarization methods, previously mentioned,
have been applied separately on the two datasets of images.
For local methods, we used same parameter values defined
in original works.
The evaluation is done both visually and at system level
using our evaluation methodology. Recall and precision met-
rics were also computed in order to confirm the correlation
between the proposed edit distance-based evaluation and the
123
Structural feature-based evaluation method of binarization techniques for word retrieval in…
Ta
bl
e
1
T
he
gr
ou
nd
tr
ut
h
si
gn
at
ur
e
an
d
th
os
e
ex
tr
ac
te
d
fr
om
bi
na
ri
ze
d
im
ag
es
O
ri
gi
na
li
m
ag
e
G
ro
un
d
tr
ut
h
si
gn
at
ur
e
Q
A
L
D
;A
;A
A
A
L
;A
;A
D
;L
D
H
;A
;A
D
;Q
L
D
;D
;Q
;H
H
Q
D
H
;
A
;A
L
;A
A
L
;D
;Q
,A
;A
A
;L
A
Q
D
H
;D
;L
A
Q
D
;A
;A
A
L
;A
D
Q
;Q
A
;H
A
;A
L
A
;D
;A
D
Q
T
he
m
et
ho
d
R
es
ul
ts
E
xt
ra
ct
ed
si
gn
at
ur
es
O
ts
u
Q
A
A
L
;A
;A
A
A
L
;A
;A
D
;L
D
H
;A
;A
D
;Q
D
;D
;Q
;
H
H
Q
D
H
;A
L
;A
H
L
;L
;A
A
L
;D
;Q
;A
;A
A
;A
Q
D
H
D
;D
;L
A
Q
;A
;A
A
L
;A
Q
;Q
;H
A
;L
;D
;A
D
D
Q
K
ap
ur
et
al
.
Q
A
A
A
A
H
H
;A
;A
A
A
L
;A
;A
H
D
;L
H
;A
;A
;H
H
Q
Q
D
;
Q
D
;Q
;H
Q
Q
H
Q
H
;H
;A
;A
;A
A
L
;D
;H
Q
;A
Q
;A
A
;A
Q
D
H
D
H
;D
;L
A
Q
;A
;A
A
L
;A
Q
;Q
;H
A
;L
;
D
;H
D
A
D
H
D
Q
Q
;H
B
er
ns
en
Q
A
A
Q
H
Q
Q
H
H
H
H
H
H
H
H
H
H
H
H
H
H
H
H
H
H
H
L
H
;H
;H
;A
;A
A
A
L
;A
;A
H
D
;H
L
H
H
D
H
;H
;A
;
A
A
D
;H
H
H
H
H
H
H
H
Q
H
H
D
;H
;D
;Q
;H
H
H
H
H
Q
H
D
H
;H
;Q
;Q
;Q
Q
A
Q
;A
Q
D
Q
Q
Q
A
D
;
A
Q
A
Q
A
Q
Q
L
Q
;D
;Q
;A
;A
Q
Q
A
;A
Q
D
H
D
;D
;L
A
Q
D
;A
;A
A
Q
Q
A
Q
L
Q
;Q
Q
A
Q
D
;Q
A
;H
A
Q
Q
;
A
Q
L
Q
;D
H
;D
A
D
D
Q
;Q
Q
Q
;H
;H
;H
N
ib
la
ck
Q
A
A
A
A
Q
Q
Q
Q
Q
Q
Q
Q
Q
H
H
H
H
H
Q
H
Q
H
H
H
L
H
H
H
;H
H
Q
H
H
;
A
Q
;Q
A
A
A
L
;Q
A
;A
D
;L
H
;A
;A
;Q
D
;H
D
;Q
;H
Q
H
Q
H
;A
Q
;
A
H
A
;A
A
L
;H
H
D
;H
H
H
H
H
Q
;A
;A
A
;A
Q
H
H
H
;D
;H
H
H
H
L
A
Q
;A
;A
A
L
;A
Q
;Q
H
;H
A
;L
;D
;
A
H
D
Q
H
H
H
H
H
H
;H
Sa
uv
ol
a
et
al
.
Q
A
A
L
D
;A
;A
A
A
L
;A
;A
D
;D
L
D
D
H
;A
;A
D
;Q
D
;D
;Q
;H
H
Q
D
D
H
;A
;A
L
;L
;A
A
L
;D
;
Q
Q
;A
;A
A
;A
Q
D
H
D
;D
;L
A
Q
;A
;A
A
L
;A
Q
;Q
;H
A
;L
;D
;D
A
D
D
Q
W
ol
f
et
al
.
Q
A
A
A
A
L
;A
;A
A
A
L
;A
;A
D
;L
H
;A
;A
;Q
D
;D
;Q
;H
H
Q
H
;A
;A
;A
A
L
;D
;Q
;A
;A
A
;A
Q
H
;L
A
Q
;
A
;A
A
L
;A
Q
;Q
;H
A
;L
;D
;A
D
Q
N
ic
k
Q
A
A
H
H
H
L
;A
;A
A
A
L
;Q
A
;A
D
;L
H
;A
;A
;
Q
D
;D
;Q
;H
H
Q
H
;H
;A
;A
;A
A
L
;D
;H
Q
;A
;A
A
;A
Q
H
;L
A
Q
;A
;A
A
L
;A
Q
;Q
;H
A
;L
;D
;A
D
Q
123
T. Sari et al.
Ta
bl
e
1
co
nt
in
ue
d
Su
et
al
.
D
H
;Q
A
H
H
H
A
A
H
Q
H
Q
L
Q
;H
;H
;Q
;H
A
;A
H
A
H
H
A
L
;A
;Q
A
Q
H
Q
D
;Q
;H
Q
Q
L
H
D
H
H
Q
;Q
A
;A
H
D
;Q
;
H
Q
Q
Q
H
Q
H
H
H
Q
D
;Q
;L
Q
D
;Q
H
H
;H
Q
Q
Q
H
H
H
Q
H
H
H
;H
;A
;A
Q
H
;Q
A
A
H
H
L
H
;H
;D
;Q
Q
;A
;H
;A
L
A
;
Q
H
A
Q
H
H
;Q
Q
D
;L
H
Q
H
A
Q
Q
H
;A
;A
A
L
;A
Q
H
;Q
Q
Q
Q
H
;H
H
A
;H
L
H
;H
;Q
;Q
D
Q
;Q
H
H
H
A
Q
D
H
Q
Q
Q
H
ow
e
Q
A
A
A
A
L
;A
;A
A
A
L
;A
;A
D
;L
H
;A
;A
;Q
D
;D
;Q
;H
H
Q
H
;A
;A
;A
A
L
;D
;Q
;A
;A
A
;A
Q
H
;D
;L
A
Q
;A
;A
A
L
;
A
Q
;Q
;H
A
;L
;D
;A
D
Q
K
ef
al
ie
ta
l.
Q
Q
A
A
A
A
L
;A
;A
A
A
L
;A
;A
D
;L
H
;A
;A
;Q
D
;
D
;Q
;H
H
H
;A
L
;A
L
L
;A
A
L
;D
;Q
;A
;A
A
;A
Q
D
H
;D
;L
A
Q
;A
;A
A
L
;A
Q
;Q
;H
A
;L
;D
;A
D
D
Q
Sa
ri
et
al
.
Q
A
A
L
;A
;A
A
A
L
;A
;A
D
;L
D
H
;A
;A
D
;Q
D
;
D
;Q
;H
H
Q
D
H
;A
;A
L
;A
A
L
;D
;Q
;A
;A
A
;A
Q
D
H
D
;D
;L
A
Q
;A
;A
A
L
;A
Q
;Q
;H
A
;L
;D
;A
D
D
Q
123
Structural feature-based evaluation method of binarization techniques for word retrieval in…
overall word retrieval performance. So, for each binariza-
tion technique, the extracted signatures were also saved.
After that, we interrogated the system by twenty Arabic
textual queries for which we manually prepared the list of
corresponding relevant documents. The average recall and
precision are finally calculated for the performance of the
retrieval system.
Regarding supervised-pixel evaluation, it may be per-
formed only on synthetic images accompanied by their
ground truth images. For the dataset of real images, with
no ground truth images, the pixel-level evaluation cannot be
done and consequently we should have to work only with the
two previous assessment approaches.
Table 2 Evaluation results of binarization methods of the image of
Fig. 9b
Binarization methods Evaluation criteria
Average visual rank Edit distance
Otsu 3.8 19
Kapur et al. 8.6 37
Bernsen 10.8 111
Niblack 9.9 75
Sauvola et al. 3.6 19
Wolf et al. 5.5 21
Nick 5.8 25
Su et al. 10 107
Howe 2.4 18
Kefali et al. 4.4 21
Sari et al. 1.2 13
To have a more clear idea, the binary images resulting
from the eleven binarization methods on a portion of the
image of Fig. 9b are shown in Table 1. This table also shows
the ground truth signature and the signatures extracted from
the binarized images. The visually estimated performances
(average rank assigned by the viewers) and the performances
obtained by our approach (in terms of edit distance) are sum-
marized in Table 2.
As we can see from the two above tables, both assessment
approaches (visual and system level) gave the same ranking
of binarizationmethods for the previous image: 1—Sari et al.,
2—Howe, 3—Sauvola et al., 4—Otsu, 5—Kefali et al., 6—
Wolf et al., 7—Nick, 8—Kapur et al., 9—Niblack, 10—Su
et al., 11—Bernsen. This shows that the system-level evalu-
ation using our approach fully agrees with the human visual
assessment.
For the twodatasets, the performances of eachbinarization
method on each image are averaged and the global ranking
on each dataset is computed. The average evaluation results
of binarization methods on the first and the second datasets
are summarized, respectively, in Tables 3 and 4. The results
are ranked according to the average of edit distancemeasured
between the signatures extracted from binarized images and
the corresponding GTS.
It is necessary to note that no binarization algorithm has
outperformed the others for all images, and the previous rank-
ing (Tables 3, 4) was based on averaged scores.
From the previous tables, we can observe that the evalua-
tion results obtained using our proposed assessment method-
ology rank Sari et al.’s method [39] in first place with the
minimal average edit distance, and present slightly better
performances than Howe’s method [24]. This ranking is the
same for both datasets, but a small deterioration of the edit
Table 3 Evaluation results of binarization methods over the first dataset
Binarization methods Evaluation criteria
Average visual rank Average recall Average precision Average edit distance
Sari et al. 2 0.8934 0.73864 29.1635
Howe 2.6 0.8612 0.77033 32.569
Kefali et al. 2.9 0.7966 0.7228 34.7666
Nick 3.3 0.7520 0.6843 38.33333
Sauvola et al. 3.6 0.7403 0.6615 44.26
Su et al. 5.4 0.6953 0.6602 46
Otsu 7.4 0.6886 0.6194 50.943
Wolf et al. 8.8 0.6611 0.5830 62.111
Kapur et al. 9.1 0.6102 0.6019 70.9
Bernsen 10.2 0.5433 0.5836 143
Niblack 10.7 0.4715 0.5203 158.66667
123
T. Sari et al.
Ta
bl
e
4
E
va
lu
at
io
n
re
su
lts
of
bi
na
ri
za
tio
n
m
et
ho
ds
ov
er
th
e
se
co
nd
da
ta
se
t
B
in
ar
iz
at
io
n
m
et
ho
ds
E
va
lu
at
io
n
cr
ite
ri
a
A
ve
ra
ge
vi
su
al
ra
nk
A
ve
ra
ge
ed
it
di
st
an
ce
A
ve
ra
ge
re
ca
ll
A
ve
ra
ge
pr
ec
is
io
n
FM
PS
N
R
N
R
M
(×
10
−2
)
M
PM
(×
10
−3
)
Sa
ri
et
al
.
1.
8
20
.8
42
68
0.
92
47
0.
74
22
6
0.
82
77
16
.3
33
9.
66
7
7.
24
H
ow
e
2.
3
22
.3
33
3
0.
88
33
0.
77
95
8
0.
83
05
17
.1
16
8.
55
7
6.
88
3
K
ef
al
ie
ta
l.
3.
3
26
.9
01
1
0.
83
20
0.
74
03
0.
81
75
5
15
.9
2
10
.7
8
6.
90
4
N
ic
k
4
28
.6
66
66
7
0.
80
96
0.
70
35
0.
78
9
14
.5
3
9.
7
8.
87
Sa
uv
ol
a
et
al
.
4.
6
30
.9
41
33
33
0.
77
96
0.
67
26
0.
81
2
16
.2
07
10
.7
6.
66
Su
et
al
.
5.
7
31
.3
37
0.
73
88
0.
68
91
0.
75
1
14
.8
4
11
.5
14
.5
O
ts
u
6
38
.2
0.
71
45
0.
60
77
0.
79
6
15
.3
3
10
.8
3
7.
22
W
ol
f
et
al
.
7.
9
53
.1
66
66
7
0.
69
66
0.
59
91
0.
77
3
14
.8
2
12
.9
7.
8
K
ap
ur
et
al
.
9.
8
64
0.
65
33
0.
58
02
0.
79
2
15
.3
1
10
.8
1
8.
04
B
er
ns
en
10
13
2.
66
66
7
0.
59
22
0.
62
89
0.
57
8.
26
19
.8
14
1
N
ib
la
ck
10
.6
14
6
0.
53
11
0.
55
63
0.
54
5
7.
95
16
.1
15
6.
13
123
Structural feature-based evaluation method of binarization techniques for word retrieval in…
distance can be observed on the first dataset compared to the
second. This deterioration is plausible since the handwriting
in real documents is more irregular and unrestricted than in
synthetic images due to their ancient nature.
The presence of Sari et al.’s method in the first place of
the ranking obtained by our evaluation methodology proves
that this method did have a good compromise between the
two datasets. The structural features were extractedwith high
accuracy attested by the minimal edit distance between the
signatures extracted from the binary images and the GTS
describing the actual features. The obtained results also con-
firm the correlation between the proposed edit distance-based
approach and the performance of the overall word retrieval
system. Therefore, Sari et al.’smethod seems themost appro-
priate for our Arabic document images retrieval system.
As we said earlier, the visual assessment has been con-
ducted in order to test the robustness of the proposed evalua-
tion methodology. When comparing the ranking obtained by
the proposed evaluation methodology with the ranking of the
visual assessment, we find that the two evaluation approaches
which have two different points of views are fully compli-
ant. The same ranking has been obtained for the two test sets.
The concordance of our evaluation methodology with visual
assessment is a strong point and demonstrates its robustness.
Thus, the human has an understanding faculty with which he
can judge the quality of a binarized image taking into account
various criteria: clarity of the document, text readability, lack
of noise, etc.
Regarding the relationship with the supervised-pixel
assessment, we observe that the ranking obtained using our
evaluation methodology does not meet the supervised-pixel
assessment (in terms of the 4 measures: Fmeasure, PSNR,
NRM and MPM). This latter provides the following rank-
ing: 1—Howe, 2—Sari et al., 3—Sauvola et al., 4—Kefali
et al., 5—Otsu, 6—Kapur et al., 7—Nick, 8—Wolf et al.,
9—Su et al., 10—Bernsen, 11—Niblack. Indeed, our assess-
ment methodology is a system-level evaluation guided by the
objective of the evaluation which is to select the most appro-
priate algorithm for degraded Arabic document retrieval.
However, in our assessment methodology, the relevance of a
binarization algorithm is measured by its ability to preserve
all the structural features of writing present in the docu-
ment. It contradicts the supervised-pixel evaluation which
uses statistical measures based on the number of correctly
classified pixels without taking into account of their posi-
tion, the important criterion in the case of document images
where the text is themost essential part of the image. So, using
the previous supervised-pixel measures, the thinning or the
thickening of charactersmay cause a significant deterioration
in the performance of the binarization methods. For clarifi-
cation purposes, Fig. 11 shows a ground truth image (of the
Arabic letter , “letter m in English”) and two images result-
ing of its dilation and its erosion, respectively. We consider
the last two images as the results of two different algorithms.
The estimation of the quality of the two binarized images
by both supervised-pixel measures and using our methodol-
ogy is given by Table 5.
As we can see from Table 5, the supervised-pixel evalu-
ation of the quality of the two binarized images gave more
or less weak performances considering that the two images
are readable, visually acceptable and describe the essential
information contained in the reference image (the letter ).
Using the proposed methodology, we reached to extract
a loop and a descender from the two binary images and
assigned them the signature LD. The assigned signature is
identical to the ground truth signature. However, despite
Fig. 11 Example of ground
truth image, its dilation and its
erosion. a Ground truth image, b
dilation result, c erosion result
Table 5 Estimation of the
quality of the two images of
Fig. 11
Image Criteria
Edit distance FM PSNR NRM (×10−2) MPM (×10−3)
Image of Fig. 11b 0 0.7863 12.12117 3.458 0.1815
Image of Fig. 11c 0 0.5424 11.4949 31.392 0.23002
123
T. Sari et al.
the deformations due to the thickening and the thinning,
both images retain the initial global shape of the charac-
ter and therefore its structural features, the only information
considered by the proposed methodology. As a result, our
methodology considers the previous binary images are of
good quality with a null edit distance.
5 Conclusion
In this paper, we proposed a new methodology for eval-
uating the performance of thresholding algorithms for the
purpose of retrieving words in the images of degraded Ara-
bic documents. The proposed methodology belongs to the
class of system-level evaluation techniques, which assesses
the relevance of a given technique for a particular applica-
tion. The proposed methodology is based on the comparison
of the structural features extracted from binarized images
with pre-established ground truth features, which differ from
supervised-pixel evaluation where the comparison is made
between the binarized images and a ground truth images at
pixel level. First, a textual description of the ground truth
features of each image is computed either manually or semi-
automatically. Then, we apply on the binarized images, a
series of operations aiming to extract their features. Finally,
the edit distance between these features and the ground
truth features is calculated. The most appropriate threshold-
ing method for each image is that with which the extracted
features are the closest to the reference features. The pro-
posed approach in conjunction with a visual assessment and
a supervised-pixel evaluation have been used to assess the
performance of eleven binarization algorithms on a dataset
of real images and on another dataset of synthetic images.
The results show the robustness of the proposed methodol-
ogy and its consistency with the human visual evaluation.
Finally, the most efficient method according to our evalua-
tion methodology was that of Sari et al. [39].
References
1. Bernsen, J.: Dynamic thresholding of grey-level images. In: Pro-
ceedings of the 8th International Conference on Pattern Recogni-
tion, Paris, France, pp. 1251–1255 (1986)
2. Boubaker, H., Kherallah, M., Alimi, A.M.: New algorithm of
straight or curved baseline detection for short Arabic handwrit-
ten writing. In: Proceedings of the International Conference on
Document Analysis and Recognition, pp. 778–782 (2009)
3. Burgoyne, J.A., Pugin, L., Eustace, G., Fujinaga, I.: A comparative
survey of image binarisation algorithms for optical recognition on
degraded musical sources. In: Proceedings of ISMIR, pp. 509–512
(2007)
4. Cheriet, M., Miled, H., Olivier, C., Lecourtier, Y.: Visual aspect of
cursive Arabic handwriting recognition. In: Proceedings of Vision
Interface, pp. 262–270 (1998)
5. Fung, C.C., Chamchong, R.: A review of evaluation of optimal
binarization technique for character segmentation in historical
manuscripts. In: Proceedings of the 2010 Third International Con-
ference on Knowledge Discovery and Data Mining, pp. 236–240
(2010)
6. Gatos, B., Pratikakis, I., Perantonis, S.J.: An adaptive binarization
technique for low quality historical documents. In: Proceedings of
the 6th International Workshop on Document Analysis Systems,
pp. 102–113 (2004)
7. Gatos, B., Ntirogiannis, K., Pratikakis, I.: ICDAR 2009 Document
Image Binarization Contest (DIBCO 2009). In: Proceedings of
ICDAR, pp. 1375–1382 (2009)
8. Goyal, R., Kaur, A.: A review of optimal binarization techniques on
documentswith damagedbackground. Int. J.Comput. Sci. Technol.
2(2), 237–239 (2011)
9. Gupta, M.R., Jacobson, N.P., Garcia, E.K.: OCR binarization and
image pre-processing for searching historical documents. Pattern
Recognit. 40, 389–397 (2007)
10. He, J., Do, Q.D.M., Downton, A.C., Kim, J.H.: A comparison of
binarizationmethods for historical archive documents. In: Proceed-
ings of the Eight International Conference on Document Analysis
and Recognition, pp. 538–542 (2005)
11. Kamel, M., Zhao, A.: Extraction of binary character/graphics
images from grayscale document images. CVGIP Comput. Vis.
Graph. Image Process. 55(3), 203–217 (1993)
12. Kapur, J.N., Sahoo, P.K., Wong, A.K.C.: A new method for gray-
level picture threshold using the entropy of the histogram. Comput.
Vis. Graph. Image Process. 29(3), 273–285 (1985)
13. Kavallieratou, E., Stathis, S.: Adaptive binarization of historical
document images. In: Proceedings of ICPR, pp. 742–745 (2006)
14. Kavallieratou, E.: An objective way to evaluate and compare bina-
rization algorithms. In: Proceedings of the 2008 ACM Symposium
on Applied Computing, pp. 397–401 (2008)
15. Kefali, A., Sari, T., Sellami, M.: Evaluation of several binarization
techniques for oldArabic documents images. In: First International
Symposium on Modeling and Implementing Complex Systems
MISC’10. Constantine, Algeria, pp. 88–99 (2010)
16. Kefali, A., Sari, T., Bahi, H.: Foreground–background separation
by feed-forward neural networks in old manuscripts. Informatica
38(4), 329–338 (2014)
17. Kim, I.K., Jung, D.W., Park, R.H.: Document image binarization
based on topographic analysis using a water flow model. Pattern
Recognit. 35(1), 265–277 (2002)
18. Kumar, D., Prasad, M.A., Ramakrishnan, A.G.: Evaluation of doc-
ument binarization using eigen value decomposition. IS&T/SPIE
Electronic Imaging. International Society forOptics andPhotonics,
pp. 86580X–86580X (2013)
19. Khurshid, K., Siddiqi, I., Faure, C., Vincent, N.: Comparison of
Niblack inspired binarization methods for ancient documents. In:
Proccedings of the 16th Document Recognition and Retrieval Con-
ference, USA (2009)
20. Leedham, G., Varma, S., Patankar, A., Govindaraju, V.: Separating
text and background in degraded documents images—a compari-
son of global thresholding techniques for multi-stage thresholding.
In: Proccedings of the 8th International Workshop on Frontiers
in Handwriting Recognition, Canada, August 6–8, pp. 244–249
(2002)
21. Leedham, G., Yan, C., Takru, K., Tan, J.H.N., Mian, L.: Com-
parison of some thresholding algorithms for text/background
segmentation in difficult document images. In: Proceedings of
the Seventh International Conference on Document Analysis and
Recognition, vol. 2, pp. 859–864 (2003)
22. Lu, H., Kot, A.C., Shi, Y.Q.: Distance–reciprocal distortion mea-
sure for binary document images. IEEE Signal Process. Lett. 11(2),
228–231 (2004)
123
Structural feature-based evaluation method of binarization techniques for word retrieval in…
23. Niblack,W.: An Introduction to Digital Image Processing. Prentice
Hall, Englewood Cliffs (1986)
24. Howe, N.R.: A Laplacian energy for document binarization 2011.
In: Proceedings of the International Conference on Document
Analysis and Recognition, pp. 6–10 (2011)
25. Ntirogiannis, K., Gatos, B., Pratikakis, I.: An objective evaluation
methodology for handwritten image document binarization tech-
niques. In: Proceedings of the 11th International Conference on
Frontiers in Handwriting Recognition, Montreal, Canada, August,
pp. 586–591 (2008)
26. Ntirogiannis, K., Gatos, B., Pratikakis, I.: An objective evaluation
methodology for document image binarization techniques. In: Pro-
ceedings of the 8th International Workshop on Document Analysis
Systems, Nara, Japan, September, pp. 217–224 (2008)
27. Ntirogiannis,K.,Gatos, B., Pratikakis, I.: ICFHR2014 competition
on handwritten document image binarization (H-DIBCO 2014).
In: Proceedings of the International Conference on Frontiers in
Handwriting Recognition, pp. 809–813 (2014)
28. O’Gorman, L.: Experimental comparisons of binarization and
multi-thresholding methods on document images. In: Proceedings
of the International Conference on Pattern Recognition, pp. 395–
398 (1994)
29. Otsu, N.: A threshold selectionmethod fromgray-level histograms.
IEEE Trans. Syst. Man Cybern. 9(1), 62–66 (1979)
30. Palumbo, P.W., Swaminathan, P., Srihari, S.N.: Document image
binarization: evaluation of algorithms. Proc. Soc. Photo-Opt.
Instrum. Eng. 697, 278–285 (1986)
31. Pratikakis, I., Gatos, B., Ntirogiannis, K.: H-DIBCO 2010—
Handwritten document image binarization competition. In: Pro-
ceedings of the 2010 International Conference on Frontiers in
Handwritting Recognition, Kolkata, India, pp. 727–732 (2010)
32. Pratikakis, I., Gatos, B., Ntirogiannis, K.: ICDAR 2011 document
image binarization contest (DIBCO 2011). In: Proceedings of the
International Conference on Document Analysis and Recognition.
Beijing, China, pp. 1506–1510 (2011)
33. Pratikakis, I., Gatos, B.,Ntirogiannis,K.: ICFHR2012 competition
on handwritten document image binarization (H-DIBCO 2012).
In: Proceedings of the International Conference on Frontiers in
Handwriting Recognition, pp. 813–818 (2012)
34. Pratikakis, I., Gatos, B., Ntirogiannis, K.: ICDAR 2013 document
image binarization contest (DIBCO 2013). In: Proceedings of the
International Conference on Document Analysis and Recognition
(ICDAR), pp. 1471–1476 (2013)
35. Ramirez-Ortegeon, M.A., Rojas, R.: Unsupervised evaluation
methods based on local gray-intensity variances for binarization
of historical documents. In: Proceedings of the 20th International
Conference on Pattern Recognition, Istambul, Turkey, pp. 2029–
2032. IEEE Computer Society (2010)
36. Rosin, P.L., Ioannidis, E.: Evaluation of global image thresholding
for change detection. Pattern Recognit. Lett. 24(14), 2345–2356
(2003)
37. Sahoo, P.K., Soltani, S., Wong, A.K.C.: A survey of thresholding
techniques. Comput. Vis. Graph. Image Process. 41(2), 233–260
(1988)
38. Sari, T., Kefali, A.: Recognition-free retrieval of old Arabic docu-
ment images. Comput. Sist. 15(2), 165–208 (2011)
39. Sari, T., Kefali, A., Bahi, B.: Text extraction from historical
document images by the combination of several thresholding tech-
niques. Adv. Multimed. Article ID 934656. doi:10.1155/2014/
934656 (2014)
40. Sauvola, J., Pietikainen, M.: Adaptive document image binariza-
tion. Pattern Recognit. 33(2), 225–236 (2000)
41. Sezgin,M., Sankur, B.: Survey over image thresholding techniques
and quantitative performance evaluation. J. Electr. Imaging 13(1),
146–165 (2004)
42. Som, H.M., Zain, J.M., Ghazali, A.J.: Application of threshold
techniques for readability improvement of jawi historical manu-
script images. Adv. Comput. Int. J. 2(2), 60–69 (2011)
43. Stathis, P., Kavallierato, E., Papamarkos, N.: An evaluation survey
of binarization algorithms on historical documents. In: Proceedings
of the 19th International Conference on Pattern Recognition, pp.
1–4 (2008)
44. Su, B., Lu, S., Tan, C.L.: Binarization of historical document
images using the local maximum and minimum. In: DAS ’10, June
9–11, Boston, MA, USA (2010)
45. Trier, Ø.D., Taxt, T.: Evaluation of binarization methods for doc-
ument images. IEEE Trans. Pattern Anal. Mach. Intell. 17(3),
312–315 (1995)
46. Trier, Ø.D., Jain, A.K.: Goal-directed evaluation of binarization
methods. IEEE Trans. Pattern Anal. Mach. Intell. 17(12), 1191–
1201 (1995)
47. Wolf, C., Jolion, J.M.: Détection et extraction de texte de la vidéo.
In: Proceedings of CFED, pp. 215–224 (2002)
48. Woo, Y.W.: Performance evaluation of binarizations of scanned
insect footprints. In: Proceedings of the International Conference
on Combinatorial Image Analysis, Auckland, New Zealand, pp.
669–678 (2004)
49. Zhang, Y.J., Gerbrands, J.J.: Segmentation evaluation using ulti-
mate measurement accuracy. In: EI 92. International Society for
Optics and Photonics. pp. 449–460 (1992)
50. Zhang, H., Fritts, J.E., Goldman, S.A.: Image segmentation eval-
uation: a survey of unsupervised methods. Comput. Vis. Image
Underst. 110(2), 260–280 (2008)
123
