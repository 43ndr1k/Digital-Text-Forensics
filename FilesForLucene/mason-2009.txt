An N-gram Based Approach to Automatically Identifying Web Page Genre 
 
 
Jane E. Mason 
Dalhousie University 
 jmason@cs.dal.ca   
Michael Shepherd 
Dalhousie University 
 shepherd@cs.dal.ca  
Jack Duffy 
Dalhousie University 
jack.duffy@dal.ca 
 
Abstract 
The research reported in this paper is the first 
phase of a larger project on the automatic 
classification of web pages by their genres, using n-
gram representations of the web pages. In this study, 
the textual content of web pages is used to create 
feature sets consisting of the most frequent n-grams 
and their associated frequencies. We present three 
methods, each of which uses a distance measure to 
determine the dissimilarity between two feature sets. 
Each method forms a feature set for every web page 
in the test set, however the formation of feature sets 
from the training set differs between methods: we 
experiment using one feature set per web page, per 
genre, and a combination of genre-based feature sets 
supplemented by subgenre feature sets. We present 
results for a balanced corpus of seven genres (blog, 
eshop, FAQs, front page, listing, home page, and 
search page). Initial results are encouraging. 
 
 
1. Introduction  
 
In the book Genre Analysis [16], Swales observes 
that it is a component of human behavior to organize 
our communicative events, at least in part, through 
the use of groups of genres. It is no surprise then, that 
the extraordinary growth in both the size and 
popularity of the World Wide Web has spawned a 
growing interest in identifying web page genres, and 
in using these genres to classify web pages.   
The research reported in this paper is the first 
phase of a larger project on the automatic 
classification of web pages by their genres, using n-
gram representations of the web pages. The goal of 
this initial research is threefold. First, we want to 
assess the potential of using feature sets created from 
raw byte n-grams to represent web pages during the 
genre classification process. Secondly, we want to 
establish whether, beyond an initial base size, 
increasing the size of the feature set (the number of 
frequent n-grams used from each web page), or 
increasing the size of the n-gram, causes a significant 
difference in the results. Finally, we want to compare 
our three classification methods, both to each other 
and to the results of other researchers on the same 
corpus, and determine which, if any, of the methods 
warrants further investigation. 
The remainder of the paper proceeds as follows. 
Section 2 gives a brief overview of related work, 
while Section 3 reviews our methodology, including 
a description of the data set, web page representation, 
evaluation metrics, and our classification methods. 
Section 4 describes our experiments and discusses the 
results; supplementary tables and figures are given in 
Appendix 1. Finally, Section 5 presents our 
conclusions and the direction of our future work. 
 
2. Related work  
 
As early as 1997, Crowston and Williams [4] 
conducted a survey of 100 web pages, looking for 
both reproduced and emergent genres. That same 
year, Chekuri et al. [3] automatically classified web 
pages into pre-specified categories, with the goal of 
increasing the precision of web searches. Roberts 
[11] demonstrated that personal homepages represent 
a distinct genre, and Dillon and Gushrowski [5] 
identified features and components of personal home 
pages. Shepherd and Watters [14] examined the 
emergence of what they termed cybergenres. 
Analyzing genre in academic and research settings, 
Swales [16] noted that members of a particular genre 
tend to exhibit similar patterns of content, style, 
structure, and intended audience; analyzing genre in 
an online setting, Shepherd and Watters [14] 
proposed a similar characterization of cybergenres, 
using the properties content, form, and functionality.  
In more recent years, the term cybergenre has 
been largely replaced by the phrase web page genre, 
however various combinations and representations of 
content, form, and functionality continue to be used 
in algorithms that automatically identify the genre of 
a web page. For example, Asirvatham and Ravi [1] 
obtained encouraging results using feature sets with 
components based on content (e.g. common words), 
form (e.g. image information), and functionality (e.g. 
link information) to classify web pages.  
Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009
1978-0-7695-3450-3/09 $25.00 © 2009 Crown Copyright
Authorized licensed use limited to: Agean University. Downloaded on March 20, 2009 at 10:59 from IEEE Xplore.  Restrictions apply.
Dong et al. [6] examined the use of feature sets 
with combinations of content, form, and 
functionality. Their data set included four genres, as 
well as noise pages. Their results indicated that using 
combinations of the attributes content, form, and 
functionality always gave better results than using 
only one of the attributes. Similarly, Shepherd et al. 
[15] found that combinations of feature types gave 
better results, though their data set was smaller. Lim 
et al. [10] used five distinct feature sets, based on 
information extracted from the URL, from html tags, 
and from token, lexical, and structural information. 
They found that the best combination of feature sets 
included the URL, html tags, token information, most 
frequently used words and punctuation, and chunks 
(multi-word expressions). Santini [12] tested a 
support vector machine (SVM) classifier with three 
different feature sets that included, for example, html 
tags, part-of-speech tags, common word frequencies, 
and genre-specific facets. She concluded that such 
mixed feature sets gave high accuracy on the data 
sets tested, and were relatively inexpensive to 
compute. 
The research reported in this paper represents web 
pages using feature sets of the most frequent L n-
grams in the textual content of each web page. N-
grams can be thought of as the contents of a fixed-
size sliding window moved through the text. N-grams 
have been used in language modeling since at least 
1948 when Shannon [13] investigated the question of 
determining the likelihood of the next letter in a 
given sequence of characters. Since that time, n-
grams have been widely used in natural language 
processing and statistical analysis. Most closely 
related to the n-gram techniques in this paper is the 
work on authorship attribution by Keelj et al. [9], as 
well as the work by Keelj et al. [8], in which n-gram 
profiles are used to recognize spam emails. Cavnar 
and Trenkle [2] also use n-gram profiles to categorize 
text. In the area of web page genre identification, 
Kanaris and Stamatatos [7] use feature sets of 
variable-length character n-grams, combined with 
information about the most frequent html tags, to 
perform classification using a support vector 
machine. Our approach is much less complex; we use 
feature sets of fixed-length byte n-grams with 
classification performed based on a simple distance 
measure. 
 
3. Methodology  
 
3.1. Data set 
 We use the popular corpus known as the 7genre or 
7-web-genre collection1. The corpus contains 1400 
English web pages, and is evenly balanced with 200 
web pages in each of seven genres. These genres are 
blog, eshop, FAQs, online newspaper front page, 
listing, personal home page, and search page. The 
granularity of the collection is consistent, with the 
exception of the listing genre, which can be 
decomposed into the subgenres checklist, hotlist, 
sitemap, and table. The personal home page genre, 
although it does not have specifically labeled 
subgenres, includes a variety of types of personal 
home pages, such as academic and administrative 
personal home pages [12].  
 
3.2. Web page representation 
  
In the experiments for this paper, each web page 
in the collection is preprocessed to remove all html 
and JavaScript information. The remaining textual 
content of each web page is then used to form an n-
gram representation of the web page. No stemming of 
terms or stopword removal is performed. The n-gram 
representation of each web page is a profile (feature 
set) consisting of the most frequent L fixed-length 
byte n-grams in each document and their normalized 
frequencies within the document. These n-gram 
feature sets are produced using the Perl package 
Text:Ngrams.2 The byte n-grams are raw character n-
grams in which no bytes are ignored, including the 
whitespace characters, as opposed to character n-
grams which use letters only and typically ignore 
digits, punctuation, and whitespace. A distance 
measure is used to compare the n-gram feature sets. 
For the experiments presented in this paper, the 
dissimilarity between two n-gram feature sets is 
computed using the formula suggested by Keelj et 
al. [9] in their paper on the use of n-gram profiles for 
authorship attribution. The distance (dissimilarity) 
between two profiles (feature sets) is defined as 
 
where f1(m) and f2(m) are frequencies of n-gram m in 
the two feature sets, S1 and S2, that are being 
compared. For two identical web pages, or for two 
                                                 
1 http://www.itri.brighton.ac.uk/~Marina.Santini 
2 http://search.cpan.org/dist/Text-Ngrams/ 
( ) ( )
( ) ( )
( ) ( )( )
( ) ( ) ,
2
2
21
21
2
21
21
2
21
21
∪∈
∪∈
+
−⋅=
+
−=
SSm
SSm
mfmf
mfmf
mfmf
mfmf
d
Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009
2
Authorized licensed use limited to: Agean University. Downloaded on March 20, 2009 at 10:59 from IEEE Xplore.  Restrictions apply.
web pages in which the L most frequent n-grams are 
identical, the distance will be zero. Because the 
number of unique n-grams is large, the L most 
frequent n-grams in each web page are unlikely to be 
identical. For example, when using the most frequent 
500 2-grams from each web page (i.e. L = 500), the 
total number of unique 2-grams used is 5947. The 
frequency of the unique n-grams found in the top L n-
grams of all the web pages has a Zipf-like 
distribution; there are a few n-grams that appear 
frequently, and many n-grams that appear 
infrequently. Figure 1 shows the normalized 
frequency of the unique 2-grams found in the top 500 
2-grams of all the web pages. 
 
Figure 1. Distribution of the total number of 
unique 2-grams found in the most frequent 
500 2-grams for each web page(L = 500). 
 
3.3. Cross-validation and evaluation metrics 
  
All of the experiments are run using 10-fold cross 
validation to increase robustness against overfitting. 
The results for all of the iterations are averaged to 
give the final results. 
Because the data set is perfectly balanced and has 
one genre label for each web page, the evaluation 
metrics of classification accuracy, micro-precision, 
micro-recall, and macro-recall are all equivalent. For 
this reason, we use the metrics of macro-precision 
and macro-recall (classification accuracy) to evaluate 
the experimental results. Macro-precision, Pm, and 
macro-recall, Rm, are defined as follows: 
 
and 
 
where |G| is the number of genres, TPi is the number 
of true positives for genre i (pages correctly labeled 
genre i), FPi is the number of false positives for genre 
i (web pages incorrectly labeled as being genre i), 
and FNi is the number of false negatives for genre i 
(incorrectly labeled web pages that belong to genre i). 
 
3.4. Classification methods 
 
This study looks at three methods of using n-gram 
profile (feature set) representations of web pages in 
the automatic identification of the genre of the web 
pages. For each of the three methods, each web page 
in the test set is represented by an n-gram feature set 
consisting of the most frequent L n-grams in the 
textual content of the web page, and the 
corresponding normalized frequency of each of these 
n-grams. The first method, hereafter referred to as the 
individual comparison method, uses this same 
representation for each web page in the training set. 
With this method, the n-gram feature set for each 
web page in the test set is compared to the n-gram 
feature set of each web page in the training set, and 
assigned the genre of the web page to which it is 
closest (most similar), according to the distance 
measure given in Section 3.2. 
The second and third methods tested in this study 
also form an n-gram feature set of the most frequent 
L n-grams for each web page in the test set, but they 
differ in their treatment of the web pages in the 
training set. The second method, henceforth referred 
to as the genre comparison method, uses the web 
pages in the training set to form an n-gram feature set 
for each genre. As with the test set, an n-gram feature 
set of the most frequent L n-grams is created for each 
web page in the training set, however these feature 
sets are then combined based on the genre of the web 
pages. We can think of this as forming a centroid 
feature set for each genre. The n-gram feature set for 
each genre initially contains the top L n-grams from 
each web page of that particular genre in the training 
set. The corresponding n-gram frequencies are 
averages of the frequencies for all of the training web 
pages of that genre. Because the top L n-grams in 
each web page feature set are unlikely to be the same, 
combining them to form the genre feature sets can 
result in feature sets much larger than L. When all of 
the genre n-gram feature sets have been formed, the 
n-grams in each feature set are sorted by frequency, 
and the genre feature sets are then truncated to the 
size of the smallest of the genre n-gram feature sets. 
Table 3 in Appendix 1 gives the size ranges for these 
genre n-gram feature sets. The n-gram feature set for 
each web page in the test set is then compared to each 
genre feature set, and assigned the label of the genre 
( )+= =
G
i ii
i
m FPTP
TP
G
P
1
1
( ) ,
1
1 +
=
=
G
i ii
i
m FNTP
TP
G
R
0 1000 2000 3000 4000 5000
0
0.02
0.04
0.06
0.08
0.1
Number of 2-grams
N
or
m
al
iz
ed
 f
re
qu
en
cy
Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009
3
Authorized licensed use limited to: Agean University. Downloaded on March 20, 2009 at 10:59 from IEEE Xplore.  Restrictions apply.
feature set to which it is most similar, according to 
the distance measure given in Section 3.2.  
The final method investigated in this study, the 
subgenre comparison method, differs from the genre 
comparison method only in its treatment of the listing 
genre. The listing genre is composed of an equal 
number of web pages from the subgenres checklist, 
hotlist, sitemap, and table. Rather than creating a 
single listing genre n-gram feature set, an n-gram 
feature set is created, from the training set web pages, 
for each of these four subgenres. The n-gram feature 
set for each web page in the test set is then compared 
to each of the n-gram feature sets formed from the 
training set, i.e., six genre feature sets and four 
subgenre feature sets. As before, each web page in 
the test set is assigned the label of the genre feature 
set to which its feature set is most similar, based on 
the distance measure given in Section 3.2. Table 3 in 
Appendix 1 gives the size ranges for the subgenre n-
gram feature sets.  
An advantage to these classification methods is 
that they allow the use of a large number of features. 
As shown in Table 3 in Appendix 1, even when using 
only the most frequent 500-5000 n-grams from each 
web page, the total number of unique n-grams used is 
large, particularly as the size of the n-gram increases. 
Using a more traditional approach such as a Naïve 
Bayes or  SVM-based classifier would require further 
feature selection to limit the size of the feature sets. 
In addition, an SVM-based classifier would need to 
be retrained when new genres are added, and so is 
less scalable than our methods. 
 
4. Results and discussion 
 
4.1. Experiments 
 
The experiments reported in this paper are carried 
out for each of the three methods described in Section 
3.4. For each method, 60 trials are performed, each 
with a different combination of n-gram size and 
number of n-grams, L, selected from each web page 
(the number of features). The n-gram size ranges 
from 2 to 7 in increments of 1, and the number of the 
most frequent n-grams selected from each web page 
ranges from 500 to 5000 in increments of 500. These 
ranges and increments were chosen based on 
preliminary tests, with the idea that they would be 
fine-tuned for future experiments, based on the 
results of this study.  
 
4.2. Overall results 
 
Of the three methods tested in this study, the 
subgenre comparison method gives the best results in 
terms of macro-precision and macro-recall 
(classification accuracy). The individual comparison 
method is least successful; the highest precision and 
recall reached by this method are 0.837 and 0.832 
respectively, for the case in which we use the 1000 
most frequent 2-grams from each web page. With this 
method, as the size of the n-gram increases from 2 to 
7, precision and recall decrease. Figures 2-7 in 
Appendix 1 give plots of the recall (accuracy) for 
each method; the precision follows a similar pattern. 
Due to their close proximity to one another, the lines 
on the plots in Figures 2-7 are differentiated by color 
and pattern rather than symbols. 
Both the genre and subgenre comparison methods 
outperform the individual comparison method. The 
best results for the genre comparison method are for 
n-grams of size 7. The highest precision (0.937) and 
highest recall (0.934) for this method are found using 
the most frequent 2000 7-grams from each web page. 
The subgenre method, in which we form separate n-
gram feature sets for each sub-genre in the listing 
genre, gives the highest precision (0.949) and highest 
recall (0.946) found in these experiments. This best 
case occurs using the 1000 most frequent 7-grams 
from each web page. Unlike the individual 
comparison method, with the subgenre comparison 
method, as the n-gram size increases from 2 to 7, the 
precision and recall increase as well. See Figures 2-7 
in Appendix 1 for plots of the recall (accuracy). 
Table 1 gives a comparison of the best results 
obtained in these experiments with those of three 
other researchers using the same corpus. Santini [12] 
uses a support vector machine (SVM) classifier using 
three different feature sets that include, for example, 
html tags, part-of-speech tags, common word 
frequencies, and genre-specific facets. Kanaris and 
Stamatatos [7] also use an SVM classifier, but their 
feature set includes a combination of variable-length 
character n-grams and structural information from 
html tags. Dong et al. [6] use a Naïve Bayes classifier 
on a subset of the corpus containing the genres eshop, 
FAQs, online newspaper front page, and personal 
home page. Their best accuracy is obtained using a 
feature set that combines the attributes of content, 
form, and functionality. When using only content 
information (word features), Dong et al. achieved a 
precision of only 0.905. Although the best 
classification accuracy of the experiments performed 
for this paper is not as high as the best results  of 
Kanaris and Stamatatos or Dong et al., our approach 
is much less complex, and achieves superior results 
on the 7genre corpus than does Santinis SVM 
approach.  
Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009
4
Authorized licensed use limited to: Agean University. Downloaded on March 20, 2009 at 10:59 from IEEE Xplore.  Restrictions apply.
Table 1. Best classification accuracy results 
for the 7genre corpus. (*The results reported 
in [6] refer to a sub-corpus of four genres.) 
 
Researchers Accuracy 
Santini [12] 0.906 
Kanaris and Stamatatos [7] 0.965 
Dong et al. [6]* 0.965 
Mason et al. 0.946 
 
Tables 4 and 5 in Appendix 1 give the confusion 
matrices for the experiment using the 1000 most 
frequent 7-grams for the genre and subgenre 
comparison methods respectively.  A comparison of 
Tables 4 and 5 shows that the classification accuracy 
for the listing genre increases from 0.80 to 0.92 when 
separate n-gram feature sets are created for each of its 
four subgenres. It does not, however, decrease the 
number of genres that are falsely labeled as 
belonging to the listing genre. In both cases, at least 
one page from each of the six other genres is 
incorrectly labeled as being of the listing genre. What 
does decrease greatly between the two cases is the 
number of web pages incorrectly labeled as being of 
the listing genre (false positives). The other slight 
differences between the two tables can be attributed 
to the difference in the total number of frequent n-
grams used in the genre and subgenre feature sets. 
Because the size of these feature sets is truncated to 
that of the smallest feature set, the subgenre 
comparison method uses somewhat shorter n-gram 
genre and subgenre feature sets. Table 3 in Appendix 
1 gives the size ranges for these feature sets. 
 
4.3. Effect of feature set size 
 
In these experiments, the number of most 
frequent n-grams used from each web page ranges 
from 500 to 5000 in increments of 500. We expected 
to see a significant difference in the results as this 
feature set size changed. The effect of the feature set 
size was not significant on the precision of the 
individual comparison method (p=0.997), however it 
was significant on the precision for the genre and 
subgenre comparison methods (p<0.001 for both), 
and on the recall for all three methods (p=0.043, 
p<0.001, and p<0.001 respectively). However, the 
partial Eta squared for the number of features for 
both the precision and recall in each method is 
<0.040 in every case. The partial Eta squared is the 
proportion of total variability attributable to a factor; 
therefore these results tell us that the feature set size 
accounted for less than 4% of the overall variance of 
the dependent variables. Figures 2-7 in Appendix 1, 
which give plots of the recall (classification 
accuracy) for each method, support this conclusion. 
 
4.4. Effect of n-gram size 
 
In these experiments, the n-gram size ranges from 
2 to 7 in increments of 1. The effect of n-gram size 
on the precision and recall for each method is 
significant at p<0.001. The partial Eta squared for the 
n-gram size for both the precision and recall in each 
method is >0.200. These results indicate that the 
proportion of total variability in the recall and 
precision for each method is moderately influenced 
by the n-gram size. Figures 2-7 in Appendix 1 
support this conclusion. 
 
4.5. Effect of genre 
 
As described in Section 3.1, the data set for these 
experiments is evenly balanced with 200 web pages 
in each of seven genres. The granularity of the 
collection is consistent, with the exception of the 
listing genre, which can be decomposed into four 
evenly balanced subgenres. The effect of genre on the 
variability in the recall and precision for each method 
is significant at p<0.001. The partial Eta squared for 
genre, for both the precision and recall in each of the 
three methods, is >0.560. This indicates that genres 
can be successfully differentiated to a high degree, 
which supports the findings of Dong et al. [6]. This 
also gives support to the idea of treating some genres 
differently than others, such as creating separate 
feature sets for the subgenres of the listing genre. 
Table 2 shows the precision and recall 
(classification accuracy) by genre for our best 
experimental results. These results are the average of 
the results found using 10-fold cross-validation. As 
discussed in Section 4.2, the best results are for the 
subgenre comparison method, using n-grams of size 
7 with the n-gram feature sets built using the most 
frequent 1000 n-grams from each web page.  
 
Table 2. Best results for precision and recall.  
 
Genre Precision Recall 
Blog 0.872 0.990 
Eshop 0.957 0.940 
FAQs 0.990 0.990 
Front page 0.990 1.000 
Listing 0.898 0.920 
Home page 0.987 0.850 
Search page 0.950 0.930 
Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009
5
Authorized licensed use limited to: Agean University. Downloaded on March 20, 2009 at 10:59 from IEEE Xplore.  Restrictions apply.
Table 2 shows that the genres front page, blog, 
and FAQs have the highest recall, and that the home 
page genre has the lowest recall (p<0.05). This is not 
entirely surprising, because, as noted in Section 3.1, 
although the personal home page genre does not have 
specifically labeled subgenres, it does include a 
variety of types of personal home pages, such as 
academic and administrative personal home pages. 
The fact that the personal home page genre has high 
precision indicates that few web pages from other 
genres are being misclassified as being of the home 
page genre; the low recall indicates that web pages 
from this genre are being incorrectly labeled as being 
of another genre. This further supports the idea that 
some genre representations, such as the home page 
genre, could benefit by being broken into subgenres. 
 
5. Conclusions and future work  
 
The research reported in this paper is the first 
phase of a larger project on the automatic 
classification of web pages by their genres, using n-
gram representations of the web pages.  The goal of 
this initial research was threefold. First, we wanted to 
assess the potential of using feature sets created from 
raw byte n-grams to represent web pages during the 
genre classification process. Based on the initial 
results presented in this paper, we can conclude that 
the n-gram representation does indeed have good 
potential for use in genre classification. 
 Secondly, we wanted to establish whether, 
beyond an initial base size, increasing the size of the 
feature set (the number of frequent n-grams used 
from each web page), or increasing the size of the n-
gram itself, causes an appreciable increase in the 
precision and recall. Based on the results given in 
Sections 4.3 and 4.4, we conclude that increasing the 
number of most frequent n-grams used from each 
web page beyond a base number of 500 does not 
appreciably affect the precision and recall. On the 
other hand, increasing the n-gram size beyond the 
base size of 2 does have a significant impact 
(p<0.001, partial Eta squared >0.200) on precision 
and recall, and warrants further investigation. 
 Finally, we wanted to compare our three 
classification methods, both to each other and to the 
results of other researchers on the 7genre corpus. As 
discussed in Section 4.2, the individual comparison 
method is not considered successful; however the 
genre and subgenre methods give results within the 
range of those achieved by other researchers on this 
corpus. The subgenre comparison method performs 
slightly better, on average, than the genre comparison 
method, and this difference is statistically significant 
(precision: t = -4.579, df = 4199, p < 0.001; recall: 
t=-5.204, df=4199, p<0.001). Although the difference 
between the methods is statistically significant, we 
feel that both methods performed well enough to 
justify additional exploration. 
The major contribution of this preliminary 
research is to show that a byte n-gram approach to 
genre classification is feasible. We recognize the 
need to expand this work to a larger scale in which 
we work with more genres, noise, varying levels of 
genre granularity, and unbalanced data sets. Our 
future work will also include expanding the scope of 
the experimental work to include a wider range of n-
gram sizes, and to increase the incorporation of 
subgenre information. We will also investigate the 
effects of using a different distance function to 
compute the distance between two n-gram feature 
sets. Several interesting possibilities are suggested by 
Tomovi  et al. [17] in their work using n-gram 
profiles to classify and cluster genome sequences. 
 
6. Acknowledgements  
 
We thank Marina Santini, for making her web 
page genre data set available, and Vlado Keelj, for 
the use of his Text::Ngrams Perl package. 
This research has been supported by the Killam 
Trust and the Natural Sciences and Engineering 
Research Council of Canada (NSERC). 
 
7. References  
 
[1] Asirvatham, A. and K. Ravi, Web Page Classification  
      Based on Document Structure, IEEE Ntl. Con., 2001. 
[2] Cavnar, W., and J. Trenkle, N-Gram Based Text  
      Categorization, Proc. 3rd Annual Symposium on  
      Document Analysis and Information Retrieval, 1994. 
[3] Chekuri, C., M. Goldwasser, P. Raghavan, and E.  
      Upfal, Web Search using Automatic Classification,  
      Proc. International Conference on the WWW, 1997. 
[4] Crowston, K. and M. Williams, Reproduced and  
      Emergent Genres of Communication on the World- 
      Wide Web, Proc. HICSS, 1997, pp. 30-39. 
[5] Dillon, A., B. Gushrowski, Genres and the Web: Is the  
      Personal Home Page the First Uniquely Digital  
      Genre?, Journal of the American Society for    
      Information Sciences, 51(2), Wiley, 2000, pp. 202-205. 
[6] Dong, L., C. Watters, J. Duffy, and M. Shepherd, An  
      Examination of Genre Attributes for Web Page  
      Classification, Proc. HICSS, 2008, pp. 133.  
[7] Kanaris, I. and E. Stamatatos, Webpage Genre  
      Identification using Variable-length Character n- 
       grams, Proc. IEEE International Conference on Tools  
      with Artificial Intelligence, 2007, pp. 3-10.  
[8] Keelj, V., E. Milios, A. Tuttle, S. Wang, and R. Zhang,  
      DalTREC 2005 Spam Track: Spam Filtering Using N- 
      gram Based Techniques, Proc. TREC, 2005.  
 
Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009
6
Authorized licensed use limited to: Agean University. Downloaded on March 20, 2009 at 10:59 from IEEE Xplore.  Restrictions apply.
[9] Keelj, V., F. Peng, N. Cercone, and C. Thomas, N- 
      gram Based Author Profiles for Authorship  
      Attribution, Proc. PACLING 03, 2003, pp. 255-264.  
[10] Lim, C., K. Lee, G. Kim, Multiple Sets of Features  
      for Automatic Genre Classification of Web  
      Documents, Information Processing and Management,  
      41(5), Elsevier, 2005, pp. 1263-1276.  
[11] Roberts, G., The Home Page as Genre: A Narrative  
       Approach, Proc. HICSS, 1998, pp. 78-86. 
[12] Santini, M., Automatic Identification of Genre in  
      Webpages, PhD Thesis, University of Brighton, 2007.  
[13] Shannon, C., A Mathematical Theory of  
      Communication, Bell System Technical Journal, 1948,  
      27, pp. 379-423 and 623-656.  
[14] Shepherd, M. and C. Watters, The Evolution of  
      Cybergenres, Proc. HICSS, 1998, pp. 97-109.  
[15] Shepherd, M., C. Watters, and A. Kennedy,  
      Cybergenre: Automatic Identification of Home Pages  
      on the Web, Journal of Web Engineering, 3(3&4),  
      Rinton Press, 2004, pp. 236-251.  
[16] Swales, J., Genre Analysis, Cambridge University  
      Press, New York, 1990.  
[17] Tomovi , A., P. Jani i , and V. Keelj, N-gram  
      Based Classification and Unsupervised Hierarchical  
      Clustering of Genome Sequences, Computer Methods  
      and Programs in Biomedicine, 81(2), Elsevier, 2006,  
      pp. 137-153.  
 
Appendix 1. 
 
Table 3. Comparison of genre and subgenre feature set sizes,  
and the total number of unique n-grams used for L = 500 to 5000.  
N-gram size Genre feature set size range Subgenre feature set size range Unique n-grams used 
2 2095  - 2901 1880 - 2767 5947  - 8620 
3 4623   - 18005 4311  - 15799 29242  - 78419 
4 12188   - 50112 8206  - 41205 83329  - 281040 
5 20472  - 93057 10809  - 70088 157226  - 633411 
6 27129   - 137969 12636  - 82590 230481  - 1090173 
7 32726   - 175272 14065  - 98735 302815  - 1568047 
 
 
Table 4. Confusion matrix of classification accuracy (macro-recall)  
for the genre comparison method, using the most frequent 1000 7-grams per web page. 
Actual genre Assigned genre 
 Blog Eshop FAQs Front page Listing Home page Search page 
Blog 0.985 0.005 0.005  0.005   
Eshop 0.020 0.930   0.025  0.025 
FAQs   1.000     
Front page    1.000    
Listing 0.045 0.010 0.025 0.010 0.800 0.035 0.075 
Home page 0.100 0.005   0.025 0.860 0.010 
Search page 0.005 0.010  0.005 0.025 0.005 0.950 
 
 
Table 5. Confusion matrix of classification accuracy (macro-recall) 
for the subgenre comparison method, using the most frequent 1000 7-grams per web page. 
Actual genre Assigned genre 
 Blog Eshop FAQs Front page Listing Home page Search page 
Blog 0.990 0.005   0.005   
Eshop 0.015 0.940   0.025  0.020 
FAQs   0.990  0.010   
Front page    1.000    
Listing 0.025 0.010 0.010 0.005 0.920 0.010 0.020 
Home page 0.105 0.005   0.030 0.850 0.010 
Search page 0.005 0.025  0.005 0.035  0.930 
Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009
7
Authorized licensed use limited to: Agean University. Downloaded on March 20, 2009 at 10:59 from IEEE Xplore.  Restrictions apply.
Figure 2. Classification accuracy (macro-recall) for variable number of features (2-grams). 
 
 
Figure 3. Classification accuracy (macro-recall) for variable number of features (3-grams). 
500 1000 1500 2000 2500 3000 3500 4000 4500 5000
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
Features from each web page
C
la
ss
ifi
ca
tio
n 
A
cc
ur
ac
y
 
 
Subgenre comparison method
Genre comparison method
Individual comparison method
500 1000 1500 2000 2500 3000 3500 4000 4500 5000
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
Features from each web page
C
la
ss
ifi
ca
tio
n 
A
cc
ur
ac
y
 
 
Subgenre comparison method
Genre comparison method
Individual comparison method
Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009
8
Authorized licensed use limited to: Agean University. Downloaded on March 20, 2009 at 10:59 from IEEE Xplore.  Restrictions apply.
Figure 4. Classification accuracy (macro-recall) for variable number of features ( 4-grams). 
 
 
Figure 5. Classification accuracy (macro-recall) for variable number of features ( 5-grams). 
 
500 1000 1500 2000 2500 3000 3500 4000 4500 5000
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
Features from each web page
C
la
ss
ifi
ca
tio
n 
A
cc
ur
ac
y
 
 
Subgenre comparison method
Genre comparison method
Individual comparison method
500 1000 1500 2000 2500 3000 3500 4000 4500 5000
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
Features from each web page
C
la
ss
ifi
ca
tio
n 
A
cc
ur
ac
y
 
 
Subgenre comparison method
Genre comparison method
Individual comparison method
Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009
9
Authorized licensed use limited to: Agean University. Downloaded on March 20, 2009 at 10:59 from IEEE Xplore.  Restrictions apply.
Figure 6. Classification accuracy (macro-recall) for variable number of features ( 6-grams). 
 
 
Figure 7. Classification accuracy (macro-recall) for variable number of features ( 7-grams). 
 
500 1000 1500 2000 2500 3000 3500 4000 4500 5000
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
Features from each web page
C
la
ss
ifi
ca
tio
n 
A
cc
ur
ac
y
 
 
Subgenre comparison method
Genre comparison method
Individual comparison method
500 1000 1500 2000 2500 3000 3500 4000 4500 5000
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
Features from each web page
C
la
ss
ifi
ca
tio
n 
A
cc
ur
ac
y
 
 
Subgenre comparison method
Genre comparison method
Individual comparison method
Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009
10
Authorized licensed use limited to: Agean University. Downloaded on March 20, 2009 at 10:59 from IEEE Xplore.  Restrictions apply.
