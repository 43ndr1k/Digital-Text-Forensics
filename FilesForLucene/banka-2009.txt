EXTRACTION OF SIGNATURE AND HANDWRITTEN REGIONS FROM OFFICIAL BINARY
DOCUMENT IMAGES
Ritesh Banka,Farshad Nourbakhsh
MILE Lab
Department of Electrical Engineering, Indian Institute od Science
Bangalore 560012 India
ritesh024@gmail.com,farshad noorbakhsh@yahooo.com
ABSTRACT
This paper presents a new two level scale invariant classifi-
cation technique to extract the gray scale handwritten area
from document image printed in English. In the First level,
the printed characters possessing self symmetry(vertical, hor-
izontal and diagonal) are extracted from the document, based
on which the threshold values are estimated. Some printed
characters are misclassified as handwritten in this level. To
reclassify them, a second level classifier is designed which
uses the presence of a symmetric hole as the feature. The
classification has been done at the character level and the tech-
nique has been tried successfully on images of printed docu-
ments containing handwritten area, signatures, seals, and bar
codes. Experimental results show that the proposed method
gives 98.3% for printed English text. The overall accuracy
achieved is 95.6%.
Index Terms— Feature extraction.
1. INTRODUCTION
Analysis of a document image involves following tasks: (i)
conversion of an editable text for reusability, (ii) extraction of
important information, (iii) separation of the text and non-text
elements of the image and subsequent analysis, (iv) analysis
of the document image, that enable efficient archiving and
retrieval.
Many official documents consist of a multiple set of ob-
jects such as text (printed and handwritten), signature, bar-
codes, logos and seals. One of the important tasks in OCR is
separation of the handwritten part from the printed text.
Several approaches have been implemented to segment
and analyze a document page image for its constituent ob-
jects Djeziri et. al [1] proposed a scheme for extraction of
signatures from bank cheques. Based on a topological crite-
rion specific to handwritten lines, referred to as filiformity, a
good accuracy in segmenting the signatures out of such pat-
terned back-ground documents is achieved . However, the
scheme fails to work when document contains lot of back-
ground patterns. Guo and Ma [2] presented a scheme which
combines the statistical variations in projection profiles with
Hidden Markov Models (HMM’s) to separate the handwrit-
ten material from machine printed text. The machine printed
text contains large number of regularities in the Projection
Profile and this has been used as a clue to perform classifica-
tion. In a similar approach,Kavallieratou and Stamatatos [3]
tried to take advantage of the structural properties to discrim-
inate printed from handwritten text. The height of the printed
characters is more or less stable within a text-line while the
distribution of the height of handwritten characters is quite di-
verse. Hobby [5] employed a scheme by incorporating shape
and layout information. Pal and Chaudhuri [6] use horizontal
projection profiles for separating the printed and hand-written
lines in Bangla script. Sabari et. al [7] designed a Gabor func-
tion based filter-bank to classify the text elements against all
other kinds of clutter. The technique works well on camera
captured images as well.
Most of such reported schemes work with the characters
on a particular scale. In the present work, we demonstrate
a scale invariant technique using the efficiency of symmetric
and loop features that are the property of object for extracting
handwritten text from printed elements. Our printed elements
consist of text, logos, barcode, seals and other such objects.
The class of documents considered do not contain graphs and
images and are referred to as ”Official Documents” in this
work. We consider an area containing handwritten text and
also some handwritten elements such as signature, digit num-
bers and some handwritten lines.
2. SYSTEM DESCRIPTION
We present a scheme to detect the handwritten elements
present in English official documents. Our scheme works in
two levels. In the first level, we use the self symmetry fea-
ture of English characters to extract all the printed characters
having self symmetry. We observed that for printed English
documents, most characters exhibit symmetry in either ver-
tical or horizontal or diagonal directions. This symmetric
property is absent in the handwritten elements of these scripts
and can be used to perform a coarse classification at the first
level. The self symmetry feature alone is not sufficient to
extract all the printed characters from the document, as a few
characters lack proper self symmetry and are misclassified
as handwritten text at the first level. To correctly reclassify
these characters we design a second level classifier. The
misclassified printed characters in the first level contain a sin-
gle symmetric loop in them, which discriminates them from
handwritten elements. The presence of this loop is used as a
feature for the reclassification at the second level. Figure 1
shows the English script. Figure 2 gives the block schematic
of the system.
Fig. 1. English Script.
Fig. 2. Block diagram of the scheme for handwritten extrac-
tion from official document images.
2.1. Preprocessing
Prior to classification, skew correction algorithms are applied
to the document. Connected Component Algorithm (cca) is
applied to the resulting image.
2.2. Feature Extraction at the first level
After the preprocessing, some further processing is preformed
before the extraction of the features. Zero moment and center
point is found for each connected component obtained (Fig
3). Zero padding is done on the new image to make the center
point of zero moment (czm) same as the center point of area
(ca) (Fig 4). The size (height or width) of each image compo-
nent is set to have an even value. Each component image is
then divided into segments as shown in Fig 5(a), 5(b), 5(c).
Fig. 3. the pink mark shows the centroid and the blue mark
shows the center point of the connected component .
Fig. 4. the reformed image having center point and the cen-
troid is coinciding with each other.
Fig. 5. 8 Divisions of the component image.
Normalized Hamming distances between segments are
computed as follows. Normalization with respect to area of
the image
From Figure 5(a)
IFLIP2 = FlipRighttoLeft(I2)
D1 =
1
AREA
H∑
i=0
W∑
j=0
I1[i][j]&IFLIP2 [i][j] (1)
From Figure 5(b)
IFLIP4 = FlipDowntoUp(I4)
D2 =
1
AREA
H∑
i=0
W∑
j=0
I3[i][j]&IFLIP4 [i][j] (2)
From Figure 5(c)
IFLIP6 = FlipRighttoLeft(I6)
D3 =
1
AREA
H∑
i=0
W∑
j=0
I5[i][j]&IFLIP6 [i][j] (3)
IFLIP8 = FlipRighttoLeft(I8)
D4 =
1
AREA
H∑
i=0
W∑
j=0
I7[i][j]&IFLIP8 [i][j] (4)
IFLIP7 = FlipDowntoUp(I7)
D5 =
1
AREA
H∑
i=0
W∑
j=0
I5[i][j]&IFLIP7 [i][j] (5)
IFLIP8 = FlipDowntoUp(I8)
D6 =
1
AREA
H∑
i=0
W∑
j=0
I6[i][j]&IFLIP8 [i][j] (6)
IFLIP8 = FlipRightDowntoLeftUp(I8)
D7 =
1
AREA
H∑
i=0
W∑
j=0
I5[i][j]&IFLIP8 [i][j] (7)
IFLIP7 = FlipLeftDowntoRightUp(I7)
D8 =
1
AREA
H∑
i=0
W∑
j=0
I6[i][j]&IFLIP7 [i][j] (8)
The minimum value of the set {D1,...D8} MDHA, is the
desired feature. If MDHA is less than the threshold (T1) , the
component is classified as printed text.
2.3. Feature2 Extraction
Some printed characters lack symmetry, and are misclassi-
fied as Hand Written in the first level. To reclassify them, we
design a second level classifier that employs an-other unique
feature present in most of the English characters. In this ap-
proach, we examine the components having a single hole or
a loop. We extract the area of the hole present in the objects
based on the characteristics, such as the geometric position of
center point of hole respect to center point of whole compo-
nent. The first feature method with 4 divisions is applied on
the extracted hole characters. The figure 4 shows the 4 divi-
sions. The formulas and are used for calculating the HDAs
of this component. The MDHA of these 2 HDAs gives the
second feature. If the is grater than the threshold T2, it is
considered to be as handwritten.
Fig. 6. 4 Divisions of the component image.
2.4. Handwritten Localization
To group together the small, but closely located handwritten
stuff, a run length smoothing algorithm (RLSA) [8] is applied.
The threshold for this is so chosen that all the gaps existing
between small handwritten stuffs are closed.
3. EXPERIMENTAL RESULTS
The algorithm was experimented on two domains viz. the
character level and the document level. At the character level,
the data base consists of 48393 segmented printed English
characters with different font sizes. At the first level of clas-
sification the accuracy achieved is 97.6%. The final accuracy
obtained on the database is 98.23%.
The algorithm was also tested on 100 documents that were
a priori divided into 3 categories (1) document with printed
and handwritten text, (2) document with printed, handwrit-
ten, and other elements (such as logo, barcode and seals)
and(3) documents with only printed text. The overall accu-
racy achieved is around 93% at the second level.
The efficiency of the algorithm decreased when tested on
documents with poor quality where the numbers of broken
and joint characters were very high.
The algorithm is implemented in Visual C++, and it is
enormously fast and efficient. The average time taken for
each image is 3 sec. The time coefficient is dependent on
: (1) the number of connected components, (2) the number
of characters with single hole, and (3) the number of hand-
written stuff. The figure 7 shows the time was taken for 100
document images and the red graph shows the average time
taken by our algorithm to process the image. The Figure 8
and 9 shows the input and the resulting images, respectively.
Fig. 7. . Shows the time(in sec.) taken by the proposed al-
gorithm. The horizontal axes show the number of connected
component, and the vertical axes show the time taken for each
image.
4. CONCLUSIONS AND FUTURE WORK
In this paper we presented a scheme for handwritten region
extraction. The algorithm is implemented in two levels. In the
first level, printed characters with self-symmetry are extracted
from the document. In the second level of extraction, printed
characters with a single symmetric hole or loop are extracted.
Subsequent part of algorithm is localization. The method is
robust to variations in scale and gives an overall accuracy of
95.6%. Further avenues of research include modification of
the algorithm to achieve better accuracy for documents con-
taining large number of broken and joint characters. The al-
gorithm can be further applied on the scripts having self sym-
metric features like Old Persian script, Chinese and Japanese
with minor modifications.
5. REFERENCES
[1] Salim Djeziri, F. Nouboud, and R. Plamondom, ”Ex-
traction of signature from check background based on a
filiformity criterion” IEEE Transactions on Image Pro-
cessing, vol. 7, no. 10, pp. 1425-1438, 1998.
[2] Jinhong K. Guo and Matthew Y. Ma, ”Separating hand-
written materials from machine printed text using hid-
den markov models”, in Proceedings of the International
Conf. on Document Analysis and Recognition, 2001,
pp. 439-443.
[3] Ergina Kavallieratou and Stathis Sta-
Fig. 8. The resulting image showing the handwritten regions
marked with grey boxes.
matatos,”Discrimination of machine-printed from
handwritten text using simple structural characteris-
tics”, ”, in Proceeding of the 17th Int. Conf. on Pattern
Recognition, 2004, pp. 437-440.
[4] Jan Neumann, Hanan Samet, and Aya Soffer, ”Integrat-
tion of local and global shape analysis for logo classi-
fication”, Pattern Recognation Letters, vol. 23, no. 12,
2002, pp. 1449-1457.
[5] J D Hobby, ”Using shape and layout information to find
signatures, text and graphics”, Computer Vision and Im-
age Understanding, vol. 80, 2000, pp. 88-110.
[6] U. Pal and B. B. Chaudhuri, ”Automatic separation of
machine-printed and hand-written text lines”, in Pro-
ceeding of Int. Conf. on Document Analysis and Recog-
nition, 1999, pp. 645-648.
[7] S Sabari Raju, PB Pati and A G Ramakrishnan, ”Ga-
bor filter based block energy analysis for text extraction
from digital document images”, in Proc. Of the First Int.
Workshop on Document Image Analysis for Libraries
(DIAL’04), 2004, pp. 233-243.
[8] K Mahata and A G Ramakrishnan, ”Precision skew de-
tection through principal axis”, in Proc. Int. Conf. on
Multimedia Processing and Systems, IIT Chennai, 2000.
