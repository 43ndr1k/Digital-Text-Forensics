Pattern Recognition Letters 33 (2012) 364–369Contents lists available at SciVerse ScienceDirect
Pattern Recognition Letters
journal homepage: www.elsevier .com/locate /patrecContent-based mobile spam classification using stylistically motivated features
Dae-Neung Sohn a,1, Jung-Tae Lee a, Kyoung-Soo Han b, Hae-Chang Rim a,⇑
a Department of Computer and Radio Communications Engineering, Korea University, 1, 5-ga, Anam-dong, Seongbuk-gu, Seoul 136-713, South Korea
b Division of Computer Engineering, Sungkyul University, 400-10, Anyang 8-dong, Manan-gu, Anyang-si, Gyeonggi-do 430-742, South Koreaa r t i c l e i n f o
Article history:
Received 9 November 2009
Available online 15 November 2011
Communicated by F. Roli
Keywords:
Mobile spam classification
Text messaging service
Stylistic features0167-8655/$ - see front matter  2011 Elsevier B.V. A
doi:10.1016/j.patrec.2011.10.017
⇑ Corresponding author. Tel.: +82 2 3290 3195; fax
E-mail addresses: danny@nlp.korea.ac.kr (D.-N. Soh
Lee), kshan@sungkyul.ac.kr (K.-S. Han), rim@nlp.kore
1 Present address: 5th Fl., NHN Green Factory, 178-
Seongnam-si, Gyeonggi-do 463-867, South Korea.a b s t r a c t
The feature of brevity in mobile phone messages makes it difficult to distinguish lexical patterns to iden-
tify spam. This paper proposes a novel approach to spam classification of extremely short messages using
not only lexical features that reflect the content of a message but new stylistic features that indicate the
manner in which the message is written. Experiments on two mobile phone message collections in two
different languages show that the approach outperforms previous content-based approaches signifi-
cantly, regardless of language.
 2011 Elsevier B.V. All rights reserved.1. Introduction
Mobile spam, which most often refers to the abuse of the Short
Message Service (SMS) to indiscriminately send out unsolicited
(and unwanted) bulk messages, has progressively become a major
issue from the early 2000s with the increasing popularity of mobile
phones. Spam messages may be particularly irritating for many
recipients because of the inconvenience that they cause, and also
because of the fees that may apply for every message received
according to the market; for example, fees apply for recipients in
the United States. In order to reduce mobile spam, governments
and many mobile service providers have taken various counter-
measures (e.g. by imposing substantial fines on spammers, block-
ing specific phone numbers, creating an alias address, etc.).
Nevertheless, the mobile spam rate is still on the rise.
Recently, a content-based approach for spam classification,
which had previously brought enormous success in detecting e-
mail spam, has started to gain attention among mobile spam
researchers. Gómez Hidalgo et al. (2006) explored the use of statis-
tical learning-based classifiers that are trained with lexical fea-
tures, such as character and word n-grams, for mobile spam
classification; the approach explored classification similar to e-
mail spam classification (Sahami et al., 1998; Cormack and Lynam,
2007). Unlike for e-mails, however, mobile phone messages are of-
ten much shorter, because of the limited size of mobile devices.
The feature of brevity causes each message to have fare less infor-
mation for content-based spam classifiers, which makes the taskll rights reserved.
: +82 2 929 7914.
n), jtlee@nlp.korea.ac.kr (J.-T.
a.ac.kr (H.-C. Rim).
1, Jeongja-dong, Bundang-gu,very challenging. Therefore, succeeding studies on mobile spam
classification focused on expanding the feature set for learning
the classifiers with features additionally engineered from the mes-
sage content, in order to consider the contextual information with
relative word positions (Cormack et al., 2007a,b).
Collectively, the features used in earlier content-based ap-
proaches for mobile spam classification were topical terms and
phrases that statistically indicated the spamness of a message, such
as ‘‘% off sale,’’ ‘‘poker,’’ and ‘‘no pay’’. However, there is no guaran-
tee that legitimate messages would not contain such expressions.
For example, an average person may send messages such as:
‘‘Danny, ABC mall is having a 56% off sale tomorrow!!’’
‘‘Jane, we are planning to play poker with no pay tomorrow night,
got it?’’
Current content-based mobile spam filters may label such legit-
imate messages as spam messages. Such a misclassification can
cause serious problems for instant mobile communication. We
have thus decided to not only depend on the message content it-
self, but also to incorporate new features that indicate how the
messages are written from a linguistic point of view. We propose
the use of new features that reflect this ‘‘style’’, or the manner in
which the content is expressed, namely stylistic features.
In this paper, we introduce a number of stylistic features (Sohn
et al., 2009)2 that originated mostly from authorship classification,2 This paper is an extended version of our previous work (Sohn et al., 2009). This
paper proposes a revised methodology (with addition of new features for training the
classification model), evaluates it by applying on two different SMS datasets in two
different languages (English and Korean) to test whether the approach is language-
independent, and reports new performance tables and graphs. Moreover, this paper
contains the result based on SVM models as an additional experiment.
Table 1
Examples of part-of-speech tri-grams and their lexicals.
Class POS tri-grams Lexical examples
Spam PRP VBP VBN you have been
CD NN NN 000 cash await
Legitimate PRP NN NN my lab report
PRP VBP RB I think still
D.-N. Sohn et al. / Pattern Recognition Letters 33 (2012) 364–369 365which involves identifying the author of a given text, for learning mo-
bile spam classifiers. The features include readily extractable and
countable information from message texts, such as word and sen-
tence lengths (Mendenhall, 1887), function word counts (Mosteller
and Wallace, 1984), part-of-speech tags (Argamon-Engelson et al.,
1998), and syntactic information (Stamatatos et al., 2000). We then
use a machine learning-based classifier to learn such features. We
conduct an empirical evaluation that uses two real-world SMS test
collections.
The remainder of this paper is organized as follows. Our mobile
spam classification algorithm is briefly described in Section 2. In
Section 3 we introduce the proposed stylistic features. In Section
4 and 5, we report the setting of our experiments and discuss the
results. Finally, we conclude the paper in Section 6.
2. Mobile spam classifier
In this paper, we take a supervised learning approach to mobile
spam classification. In particular, we use the maximum entropy
framework (Berger et al., 1996) to learn a classifier to test our ap-
proach to mobile spam classification. The maximum entropy
framework is a strong learning model that has been commonly
used in various text classification tasks including e-mail and mo-
bile spam classification. The main advantage of the maximum en-
tropy framework is that it is robust and statistically efficient, while
still allowing arbitrarily diverse features that may be inter-depen-
dent (Ratnaparkhi, 1999).
The principle of maximum entropy is simple: given a set of
facts, choose a model consistent with all the facts, but otherwise
as uniform as possible (Berger et al., 1996). In the case of mobile
spam task, a fact corresponds to a message sample x with a label
y = {spam, legitimate} in a set of training data. The model seeks to
maximize the entropy of the posterior conditional distribution
P(yjx) with the constraint that the expected value of a certain fea-
ture function as predicted by the model equals the empirical value
of the feature function observed in the training data. Formally, the
model computes the conditional probability of y given x as:
pðyjxÞ ¼ 1
Zðk1; . . . ; knÞ
exp
Xn
i¼1
kifiðx; yÞ
" #
where Zðk1; . . . ; knÞ ¼ exp
Xn
i¼1
X8ðx;yÞ
ðx;yÞ
kifiðx; yÞ
" #
fi(x,y) are the feature functions of text messages with weight ki, and
n is the number of features. The weight parameters are learned from
training data using the Limited Memory Variable Metric algorithm,
which had been proven to be the most effective parameter estima-
tion method for maximum entropy framework (Malouf, 2002).
3. Stylistic features for mobile spam classification
We propose the use of stylistic features to improve content-
based mobile spam classifiers under following assumptions:
 There are two types of mobile phone message senders, namely
spammers and non-spammers.
 Spammers have distinctive linguistic styles and writing behav-
iors (as opposed to non-spammers) and use them consistently.
 The SMS message, as an end product, carries the author’s
‘‘fingerprints’’.
These assumptions are acceptable, because the purpose of most
spammers is to advertise products or services. Thus, the content of
mobile spam is very different from legitimate messages related to
daily life; a spammer’s diction is different from that of a non-spam-mers. In this paper, we introduce stylistic features that character-
izes the manner in which a SMS message is written. We
specifically focus on proposing features that are easily extractable
from message text without complex analysis but empirically effec-
tive for improving the performance to minimize a possible text
messaging service delay due to feature extraction cost in mobile
spam classification.
3.1. Length features: LEN
We measure the overall byte length of SMS messages and the
average byte length of words in the message as features. Non-
alphanumeric characters such as ‘‘.!?#@;’’ are not considered in
the lengths.
3.2. Function word features: FW
Function words are ones that have little lexical meaning or have
ambiguous meaning but exist to explain grammatical or structural
relationships with other words in a sentence or specify the attitude
or mood of the speaker. They might be prepositions, pronouns,
auxiliary verbs, conjunctions, grammatical articles or particles.
We measure the frequencies of function words in SMS messages
as features. Due to the high frequency of function words in lan-
guages and their highly grammatical roles, function words are un-
likely to be subject to conscious control by the author and the
frequencies of different function words would vary greatly with
varying authorship (Argamon and Levitan, 2005).
3.3. Part-of-speech tri-gram features: POS
Part-of-speech is a linguistic category of lexical items, which is
generally defined by the syntactic or morphological behavior of the
lexical item in a sentence. We extract part-of-speech tri-grams
from the SMS messages and use their frequencies as features.
The idea behind their utility is that spammers would favor certain
syntactic constructions in their messages. Table 1 lists examples of
part-of-speech tri-grams, which are relatively more or less fre-
quent in spam messages than in legitimate messages. We choose
tri-gram features, because they are large enough to encode useful
syntactic style information, yet is small enough to be computation-
ally manageable (Santini, 2004).
3.4. Special character features: SC
We have observed that many SMS messages contain special
characters and that their usage varies between spam and non-spam
messages. For instance, non-spammers often use special characters
to create emoticons to express their mood, such as ‘‘:-)’’ (smiling) or
‘‘T_T’’ (crying), whereas spammers tend to use special characters or
patterns that are related to monetary matters, such as ‘‘$$$’’ or ‘‘%’’.
Therefore, we also measure the ratio of special characters, the num-
ber of emoticons, and the number of special character patterns in
SMS messages as features. For emoticon and special pattern counts,
we use manually constructed lexicons consisting of 439 emoticons
and 229 special patterns.
366 D.-N. Sohn et al. / Pattern Recognition Letters 33 (2012) 364–3693.5. Phrasal category features: PC
We measure the ratio of several phrasal categories including
noun phrases, verb phrases, adjective phrases, adverbial phrases,
prepositional phrases and conjunction phrases in text messages.
The idea behind these features is that spammers favor certain
phrasal categories in their expressions. In the training phase, we
extract these features with use of a syntactic tree parser. In the
testing phase, however, we construct phrase dictionaries for every
phrasal categories consisting of phrases observed in the training
phase and use them to extract features to minimize computation
due to tree parsers.4. Experimental design
4.1. Data
We use two sets of SMS messages in two different languages,
English and Korean, for the evaluation of the proposed method.
The English dataset consists of 1,125 (67%) legitimate messages
and 552 (33%) spam messages. This set was derived from freely
available resources on the Web, similarly as in the work of Gómez
Hidalgo et al. (2006). The legitimate ones are messages randomly
chosen from the SMS corpus built by the National University of
Singapore, which contains roughly 10,000 legitimate messages col-
lected mostly from student volunteers attending the university for
research purposes (How and Kan, 2005). The spam messages are
ones manually collected from Grumbletext, which is an online for-
um in the United Kingdom in which mobile phone users make pub-
lic claims of mobile spam messages.
The Korean SMS dataset, which is based on one used in a previ-
ous work (Sohn et al., 2008) augmented with new SMS messages,
consists of 12,000 (60%) legitimate messages and 8,000 (40%) spam
messages.10.00
1.00
0.10
%
 F
al
se
 N
eg
at
iv
e 
R
at
e 
(lo
gi
t s
ca
le
) Proposed
Style
Baseline4.2. Feature setting
We compare three types of feature sets defined as follows:
 Baseline: This feature set consists of lexical features in text mes-
sages, including words, character bi-grams, character tri-grams,
and orthogonal sparse word bigram (OSB).3 This feature set rep-
resents the previous content-based approaches suggested by
Gómez Hidalgo et al. (2006) and Cormack et al. (2007a,b).
 Style: This set consists of the stylistic features described in the
previous section. It includes length features, function word fea-
tures, POS tri-gram features, special character features, and
phrasal category features.
 Proposed: This set is a combination of both the baseline and all
the stylistic features (Baseline + Style). The intent of this setting
is to harmonize both the contents and the stylistic information
in SMS messages.
The total number of extracted features are 56,862 and 382,427
in English and Korean dataset respectively. In order to diminish the
feature space, we applied feature selection based on information
gain, which is a very effective and reliable technique for selecting
prominent features in text classification (Yang and Pedersen,
1997). For all three feature settings, we used 250 features with3 An OSB indicates words separated by fewer than or equal to three words, along
with an indicator for the relative positions in a sentence; for example, the expression,
‘‘the quick brown fox’’ would be contain following OSB features: ‘‘the (0) quick’’, ‘‘the
(1) brown’’, ‘‘the (2) fox’’, ‘‘quick (0) brown’’, ‘‘quick (1) fox’’, and ‘‘brown (0) fox’’
Cormack et al. (2007b).the highest information gain values according to preliminary
experiment (see Appendix A).4.3. Evaluation measure
Since spam classification is very sensitive to false-positives (i.e.
legitimate classified as spam) and false-negatives (i.e. spam classi-
fied as ham), we report the result of each experiment using an ROC
curve that plots the false-positive rate against the false-negative
rate. We also report one minus the area under the ROC curve
(1  AUC) as a percentage with confidence intervals, which is a
common aggregate measure used in the TREC Spam Track (Cor-
mack and Lynam, 2005). All the resulted values were calculated
by the TREC Spam Filter Evaluation Toolkit. Note that a lower
1  AUC (%) value indicates that the probability of occurrences of
the mis-classifications is lower (i.e. a better performance).4.4. Cross validation
All experiments were performed using stratified ten-fold cross
validation. We report the statistical significance of the differences
between results of folds calculated with a two tailed paired t-test.
The symbol  in the performance tables predicates statistical signif-
icance over an appropriate baseline at p < 0.01 level.5. Results and discussion
5.1. Overall performance
The ROC curves corresponding to all feature settings applied to
the English and the Korean test collections are shown in Figs. 1 and
2 respectively. The 1-AUC (%) summary result of the comparison
experiment for each feature setting is shown in Table 2.
On both the English and Korean test collections, the Style shows
results comparable to the Baseline. This result is very surprising,
because the Style setting does not use any of the lexical informa-
tion that has played key roles in most content-based spam classi-
fication studies. We may infer from the result that our
assumption, that there is a difference in the writing style of spam-
mers and non-spammers, is correct. Since the stylistic features we
chose to use in this paper are very simple features that do not re-
quire any complex linguistic analysis, leveraging how a message is
written in mobile spam classification is potentially effective de-
spite the language.50.00
50.0010.001.000.10
% False Positive Rate (logit scale)
Fig. 1. ROC curves on the English SMS dataset.
Table 3
Performances by removing one stylistic feature set from the Proposed set.
Feature English Korean
Proposed 2.0694 [1.6555–2.4833] 3.2806 [2.6245–3.9368]
LEN 2.6072 [2.0857–3.1286] 3.7899 [4.1957–6.2936]
FW 2.3562 [1.8849–2.8274] 3.5978 [2.8782–4.3173]
POS 2.3502 [1.8801–2.8202] 3.5283 [2.8226–4.2339]
SC 2.5582 [2.0466–3.0699] 3.9341 [3.1473–4.7210]
PC 2.4059 [1.9247–2.8871] 3.8939 [3.1151–4.6727]
Table 4
Performances by adding one stylistic feature set to the Baseline set.
Feature English Korean
Baseline 5.5717 [4.4574–4.4413] 5.2446 [4.1957–6.2936]
+LEN 3.7011 [2.9608–3.1286] 3.8156 [3.0525–4.5788]
+FW 4.0443 [3.2354–4.8531] 4.2186 [3.3749–5.0624]
+POS 4.3741 [3.4992–5.2489] 4.7224 [3.7779–5.6669]
+SC 3.7302 [2.9842–4.4763] 3.6846 [2.9477–4.4215]
+PC 3.9155 [3.1324–4.6986] 3.8941 [3.1153–4.6731]
50.00
10.00
1.00
0.10
50.0010.001.000.10
%
 F
al
se
 N
eg
at
iv
e 
R
at
e 
(lo
gi
t s
ca
le
)
% False Positive Rate (logit scale)
Proposed
Style
Baseline
Fig. 2. ROC curves on the Korean SMS dataset.
Table 2
Performances of different feature settings on English and Korean datasets.
Feature English Korean
Baseline 5.5717 [4.4574–6.6861] 5.2446 [4.1957–6.2936]
Style 3.8337 [3.0671–4.6005] 5.2313 [4.1851–6.2776]
Proposed 2.0694 [1.6555–2.4833] 3.2806 [2.6245–3.9368]
D.-N. Sohn et al. / Pattern Recognition Letters 33 (2012) 364–369 367The Proposed significantly outperforms all of the other feature
settings and shows a statistically significant improvement over
Baseline again on both datasets. Such a result clearly indicates that
the state-of-the-art content-based approaches to mobile spam fil-
tering may be enhanced significantly with use of stylistic
information.4
In case of the Proposed, we can see that the performance
improvement is more significant on the English dataset than the
Korean dataset. A possible reason is that the Korean language is
agglutinative in its morphology; most Korean words are formed
by joining morphemes together. Consequentially, it would be more
difficult to express Korean SMS messages (382,427 features ex-
tracted) by constrained number of features (250) than English
SMS messages (56,862 features extracted).5.2. Performance of individual feature
In order to evaluate the contribution of different types of stylis-
tic features, we performed a series of experiments by eliminating
specific features from Proposed. Table 3 displays the detailed re-
sults of this action. LEN, SC, and PC features proved to be the most
useful for both English and Korean, since the performance drops
significantly if any of them is removed. FW and POS features also
show considerable contributions. The substantial result of the SC
features implicitly indicates that the written style of special char-
acters is very distinctive between spammers and non-spammers.
Since the combination of stylistic features that we have used
may be highly dependent on each other, we conducted another
series of experiments where one feature type was added at a time
to Baseline. Table 4 displays the results. LEN, SC, and PC features
were consistently helpful. The most interesting result is that POS4 As an additional experiment, we carried out a series of experiments based on
SVM, which is known as an outstanding classifier and widely used in email spam
filtering tasks (we use SVM-light (Joachims, 1999 )). In the experiments, we only
change the classification model; all other settings are untouched. Appendix B shows
the results of the additional experiments.features consistently contributed the least. We suspect it is due to
high dependencies between POS and lexical features.
All of the experiments are performed on a server platform with
Intel (R) Xeon (TM) CPU 2.80 GHz (2 cores) and with 8 GB DDR
3200 memory. The maximum memory usage during spam filtering
process is about 179 megabytes. Mean classification time per mes-
sage in English and Korean are 0.062 and 0.157 s respectively.
Regarding the memory usage, we believe that our approach is suit-
able for being adopted on server-side or on workstations in practi-
cal situations.
We briefly introduce some guidelines for choosing a suitable
operating point to adapt our approach server-side. Firstly, the sys-
tem should meet some hardware requirements. Since the feature
extraction step includes linguistic analysis, a platform with four
cores CPU running at 2.0 GHz and with 16 GB main memory is rec-
ommended; such platform can process about 40 English SMS mes-
sages per second. Secondly, the system should support multi-
threading. To increase the throughput, a multi-threading architec-
ture would be suitable for the system.
6. Conclusion
This paper focuses on the task of mobile spam classification,
which involves distinguishing spam messages from legitimate
messages. The main contributions of this paper is twofold:
 We propose an approach to mobile spam classification using a
variety of new, stylistically motivated features that do not
require high computation cost. It aims at improving the perfor-
mance of content-based spam classifiers for brief written SMS
messages having relatively less lexical information.
 We empirically demonstrate the proposed approach is both
effective and language-independent by conducting a series of
experiments with a learning-based classifier on real world Eng-
lish and Korean SMS datasets.
As future work, we plan to explore the potential effect of text
normalization (i.e. error correction) on text messages, which are
widely known to be very noisy. Moreover, evaluating the evadabil-
ity of spam filtering methods may be a valuable study for building
more well-performing and adaptive spam filters to block spam-
mers who try to modify their messages dynamically.
In addition, we have no reason to believe that we have yet
found the optimal usage of the feature sets. Exploring multiple
Table A.1
Performances of Proposed using each feature selection method with the number of features.
Method/Num 1-AUC (%)
50 100 150 200 250 300 350 400 450 500
MI 31.5185 22.9626 18.9856 18.2638 17.8951 18.2136 15.9725 15.8614 16.2632 15.3724
DF 4.2313 3.5504 3.2200 2.8325 3.4164 3.6541 4.5486 4.7506 4.1166 5.1953
CHI 2.7459 2.6328 2.6089 2.5386 2.4602 2.8619 3.0070 4.2019 5.4068 5.5492
IG 2.2521 2.2835 2.2449 2.1788 2.0694 3.0683 3.6642 3.9244 5.6214 6.2006
Table B.1
Performances of different feature settings on English and Korean datasets classified by
SVM.
Feature English Korean
Baseline 4.3731 [3.2578–5.7421] 6.4971 [4.1957–6.2936]
Style 3.2976 [2.6712–4.1282] 5.8231 [4.5238–7.2542]
Proposed 2.6493 [1.8372–3.0216] 4.4353 [3.1589–5.2102]
50.00
10.00
1.00
0.10
50.0010.001.000.10
%
 S
pa
m
 M
is
cl
as
si
fic
at
io
n 
(lo
gi
t s
ca
le
)
% Ham Misclassification (logit scale)
Proposed
Style
Baseline
Fig. B.1. ROC curves on the English SMS dataset classified by SVM.
50.00
10.00
1.00
0.10
50.0010.001.000.10
%
 S
pa
m
 M
is
cl
as
si
fic
at
io
n 
(lo
gi
t s
ca
le
)
% Ham Misclassification (logit scale)
Proposed
Style
Baseline
Fig. B.2. ROC curves on the Korean SMS dataset classified by SVM.
368 D.-N. Sohn et al. / Pattern Recognition Letters 33 (2012) 364–369classifier systems for combining different types of features, such as
for lexical and stylistic features, will be a possible future work.
Acknowledgements
This work was supported by the 2nd Brain Korea 21 Project. Any
opinions, findings and conclusions or recommendations expressedin this material are those of the authors and do not necessarily re-
flect the views of the sponsor.
Appendix A. Determination of feature selection method and
optimal number of features
As a preliminary experiment, we examine several widely-used
feature selection methods using English SMS test collection based
on maximum entropy model in order to find the appropriate meth-
od and optimal number of features for mobile spam filtering. The
work of Yang and Pedersen (1997) reports that the usage and effec-
tiveness of feature selection methods seem to depend on the task.
We compared four feature selection methods, namely document
frequency (DF), information gain (IG), chi-square static (CHI), and
mutual information (MI) (Yang and Pedersen, 1997). Table A.1 dis-
plays the performance of Proposed, which augmented 50 features
selected by each feature selection method at a time. IG, which
showed the best performance 2.0694 1-AUC (%) with 250 features,
outperformed the other three methods. MI showed the worst per-
formance among others. We believe that this is because there are
many rare features (or terms) in SMS messages due to its sparse
representation (Gómez Hidalgo et al., 2006). This may have caused
MI, which has a disadvantage of giving a higher score to rare fea-
tures than to common features, to perform the worst (Yang and
Pedersen, 1997).
Appendix B. Additional experiment based on SVM
For experiments, we used SVMlight (Joachims, 1999). In learn-
ing process, the regularization parameter C was set to 100 in accor-
dance with Cormack et al. (2007b). All other parameters were fixed
to their default values in SVM-light. Fig. B.1 and B.2 respectively
show the ROC curves on English and Korean datasets using SVMs
with different feature settings. The Proposed significantly outper-
forms both the Baseline and Style feature settings on both datasets.
Table B.1 describes the performance figures of SVMs using dif-
ferent feature settings on English and Korean SMS test collections.
The SVM models show results similar to our maximum entropy
model. Proposed remarkably outperforms both Baseline and Style
on both datasets.
References
Argamon, S., Levitan, S., 2005. Measuring the usefulness of function words for
authorship attribution. In: Proc. 2005 Joint Conf. Association for Computers and
the Humanities and the Association for Literary and Linguistic Computing.
Argamon-Engelson, S., Koppel, M., Avneri, G., 1998. Style-based text categorization:
What newspaper am i reading. In: Proc. AAAI-98 Workshop on Learning for Text
Categorization, pp. 1–4.
Berger, A.L., Della Pietra, V.J., Della Pietra, S.A., 1996. A maximum entropy approach
to natural language processing. Computational Linguistics 22 (1), 39–71.
Cormack, G., Lynam, T., 2005. Trec 2005 spam track overview. In: Proc. 14th Text
Retrieval Conf.
Cormack, G.V., Gómez Hidalgo, J.M., Sánz, E.P., 2007a. Feature engineering for
mobile (sms) spam filtering. In: Proc. 30th Annual Internat. ACM SIGIR Conf.
Research and Development on Information Retrieval, pp. 871–872.
Cormack, G.V., Gómez Hidalgo, J.M., Sánz, E.P., 2007b. Spam filtering for short
messages. In: Proc. 16th ACM Conf. Information and Knowledge Management,
pp. 313–320.
D.-N. Sohn et al. / Pattern Recognition Letters 33 (2012) 364–369 369Cormack, G.V., Lynam, T.R., 2007. Online supervised spam filter evaluation. ACM
Trans. Inform. Syst. 25 (3), 1–31.
Gómez Hidalgo, J.M., Bringas, G.C., Sánz, E.P., García, F.C., 2006. Content based
sms spam filtering. In: Proc. 2006 ACM Symp. Document Engineering, pp.
107–114.
How, Y., Kan, M.-Y., 2005. Optimizing predictive text entry for short message service
on mobile phones. In: Proc. 11th Internat. Conf. Human–Computer Interaction.
Joachims, T., 1999. Making large-scale support vector machine learning practical.
Advances in kernel methods: support vector learning.
Malouf, R., 2002. A comparison of algorithms for maximum entropy parameter
estimation. In: Proc. 2002 Conf. Computational Natural Language Learning, pp.
1–7.
Mendenhall, T.C., 1887. The characteristic curves of composition. Science, 237–246.
Mosteller, F., Wallace, D.L., 1984. Applied Bayesian and classical inference: the case
of the Federalist papers. Springer Verlag.
Ratnaparkhi, A., 1999. Learning to parse natural language with maximum entropy
models. Machine Learning 34, 151–175.Sahami, M., Dumais, S., Heckerman, D., Horvitz, E., 1998. A bayesian approach to
filtering junk e-mail. In: Proceedings of the AAAI-98 Workshop on Learning for
Text Categorization.
Santini, M., 2004. A shallow approach to syntactic feature extraction for genre
classification. In: Proceedings of the 7th Annual Computational Linquistics UK
Colloquium.
Sohn, D.-N., Lee, J.-T., Rim, H.-C., 2008. Contents-based korean sms spam filtering
using morpheme unit features (korean). In: Proceedings of the 20th Annual
Conference on Human and Cognitive Language Technology. pp. 194–199.
Sohn, D.-N., Lee, J.-T., Rim, H.-C., 2009. The contribution of stylistic information to
content-based mobile spam filtering. In: ACL-IJCNLP ’09: Proceedings of the
ACL-IJCNLP 2009 Conference Short Papers. Association for Computational
Linguistics, Morristown, NJ, USA, pp. 321–324.
Stamatatos, E., Fakotakis, N., Kokkinakis, G., 2000. Automatic text categorization in
terms of genre and author. Comput. Linguist. 26 (4), 471–495.
Yang, Y., Pedersen, J.O., 1997. A comparative study on feature selection in text
categorization. In: Proc. 14th Internat. Conf. Machine Learning. pp. 412–420.
