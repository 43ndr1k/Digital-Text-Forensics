(IJCSIS) International Journal of Computer Science and Information Security,  
Vol. 13, No. 1, January 2015 
Efficient Support Vector Machines for Spam 
Detection: A Survey                                    
 
Zahra S. Torabi  
Department of Computer Engineering, 
Najafabad branch, Islamic Azad 
University, Isfahan, Iran. 
Zahra.torabi@sco.iaun.ac.ir 
 
  
 
Mohammad H. Nadimi-Shahraki 
Department of Computer Engineering, 
Najafabad branch, Islamic Azad 
University, Isfahan, Iran. 
Nadimi@ieee.org 
 
Akbar Nabiollahi  
Department of Computer Engineering, 
Najafabad branch, Islamic Azad 
University, Isfahan, Iran. 
Nabi@iaun.ac.ir
 
 
Abstract— Nowadays, the increase volume of spam has been 
annoying for the internet users. Spam is commonly defined as 
unsolicited email messages, and the goal of spam detection is to 
distinguish between spam and legitimate email messages. Most of 
the spam can contain viruses, Trojan horses or other harmful 
software that may lead to failures in computers and networks, 
consumes network bandwidth and storage space and slows down 
email servers. In addition it provides a medium for distributing 
harmful code and/or offensive content and there is not any 
complete solution for this problem, then the necessity of effective 
spam filters increase. In the recent years, the usability of machine 
learning techniques for automatic filtering of spam can be seen. 
Support Vector Machines (SVM) is a powerful, state-of-the-art 
algorithm in machine learning that is a good option to classify 
spam from email. In this article, we consider the evaluation 
criterions of SVM for spam detection and filtering. 
Keywords- support vector machines (SVM); spam detection; 
classification;  spam filtering;  machine learning; 
I.  INTRODUCTION  
Influenced by the global network of internet, time and place 
for communication has decreased by emails. As a result the 
users prefer to use email in order to communicate with others 
and send or receive information. In fact spam filtering is an 
application for classification of emails, and has a high 
probability of recognizing the spam. Spam is an ongoing issue 
that has no perfect solution and there is no complete solution 
technique about spam problem [1]. According to the recent 
researches done by Kaspersky Laboratory (2014), almost 
65.7% of all emails were considered as spam, respectively in 
January. In this regards, a huge amount of bandwidth is 
wasted and an overflow occurs while sending the emails. 
According to reported statistics United State of America, 
China and South Korea are among the main sources of these 
spam respectively with 21.9%, 16.0% and 12.5%. Fig. 1 
shows the spam sources for each country [2].  Fig. 2 shows the 
spam sources according to geographical area.  
In figure 2, Asia and North America are the greatest sources 
for the spam, respectively with 49.1 and 22.7 percentage [2]. 
Recently, separating legitimate emails from spasm has been 
considerably increased and developed. In fact, separating 
spam from legitimate emails can be considered as a kind of 
text classification, because the form of all emails is generally 
textual and by receiving the spam, the type has to be defined. 
Support Vector Machines are supervised learning models or 
out-performed other with associated learning algorithms and 
good generalization that analyze data and recognize patterns, 
used for classification and regression analysis. SVM is a 
representation of the examples as points in space, mapped so 
that the examples of the separate categories are divided by a 
clear gap that is as wide as possible. SVM is used to solve 
quadratic programming problem with inequality constraints 
and linear equality by discriminating two or more classes with 
a hyperplane maximizing the margin. 
 
 
 
11 http://sites.google.com/site/ijcsis/ 
ISSN 1947-5500 
 
Figure 1. Sources of Spam by country
  
 
Figure 1. Sources of spam by region
 
In this paper, we have examined using support vector 
machine metrics in spam detection. Section 2 discuss an initial 
background of Spam filtering, discussing spam filtering 
techniques and content base learning spam filtering 
architecture. Section 3 introduces standards support vector 
machine and assessment spam detection using standard 
support vector machine. Section 4 evaluates spam detection 
using improved support vector machine. Section 5 is about 
conclusions and future work.  
II. INITIAL DISCUSSIONS 
A. Spam Filtering Techniques 
As the threat is widely spread, variety of techniques have 
been known to detect spam emails. In fact the techniques are 
divided two categories Client Side Techniques and Server side 
techniques [1]. These methods can be applied as a useful filter 
individually, however in commercial applications, the 
combination of these methods are generally used in order to 
recognize the spam more precise. Some of these methods are 
12 http://sites.google.com/site/ijcsis/ 
ISSN 1947-5500 
(IJCSIS) International Journal of Computer Science and Information Security,  
Vol. 13, No. 1, January 2015 
defined manually on server side, such as Yahoo email filters. 
However, they have a main defect and that is the constancy of 
these pre-defined rules [3]. Another problem is that the spam, 
spammers can deceive these filters. Furthermore, a popular 
method of filtering is to identify each spam on the basis of its 
content [4]. 
 
1)  End-User (Client Side Techniques or Techniques to 
React to Spam) 
 
These techniques are implemented on client side and once 
the mails have been downloaded and client examine the mails 
and then decide what to do with them. So, client can limit the 
availability of their email addresses, preventing their 
attractiveness or reducing to spam individually [1, 5-9].  
 
a) Discretion and Caution  
One way to restrict spam is a shared email address is just 
among a limited group of co-workers or correspondents. Then, 
sending and forwarding email messages to receivers who don't 
know should be rejected. 
 
b) Whitelists 
A list of contacts that users suppose that they should not 
send them to the trash folder automatically and they are 
suitable to receive email from is a whitelist. Then, whitelist 
methods can also use confirmation or verification [6]. If a 
whitelist is preemptive, just the email from senders on the 
whitelist will receive. If a whitelist is not preemptive, it 
forbids email from being deleted or prevents sent to the spam 
folder by spam filtering [5]. Usually, just end-users (not email 
services or Internet service providers) can delete all emails 
from sources which are not in the white list by setting a spam 
filter. 
 
c) Blacklists 
A blacklist method is a mechanism of access control that 
allow users through except members of the blacklist. It is the 
opposite method of whitelist [1]. A spam email filtering may 
save a blacklist of addresses, any message from which would 
be prevented from achieving its intended destination [5]. 
 
d) Egress spam filtering 
 Client can install anti spam filtering to consider emails 
receiving from the other customers and users as can be done 
for message coming from the others or rest of the Internet [8]. 
 
e) Disable HTML in email 
Most of programs of email combine web browser or 
JavaScript practicality, like display of HTML sources, URLs 
and images. This causes displaying the users to put images in 
spam easily[9]. On the other hand, there are web bugs on the 
spam email written in HTML and it can allow spammers to 
know the email address is valid. 
 
f) Port 25 interception 
Network address translation causes rate limiting by 
intercepting port 25 traffic and direct traffic to mail server and 
exit spam filtering. On the other hand it can enforce the 
problems in email privacy, also making it is not able to occur 
if port 587 submission port isn't used and SMTP-AUTH and 
STARTTLS is used [7]. 
 
g) Quarantine 
Spam emails are placed in provisional isolation until a 
proper person like administrator  examines them for final 
characterization [6]. 
 
2) Server side techniques 
 
In these techniques the server block the spam message. 
SMTP doesn't detect the source of the message. On the other 
hand, spammers can forge the source of the message by 
hijacking their unsecured network servers which is known as 
"Open relays". Also, "Open proxy", can help the user to 
forward Internet service request by passing the firewalls, 
which might block their requests. Verifying the source of the 
request with open proxy is impossible [1]. Some DNS 
Blacklists (DNSBLs) have the list of known open relays, 
known spammers domain names, known proxy servers, 
compromised zombie spammers, as well as hosts that 
shouldn‟t be sending outer emails on the internet, like the 
address of end-user from a consumer ISP. Spamtraps are 
usually the email addresses that are invalid or are not valid to 
collect spam for a long time. A lot of poorly software are 
written by spammers that cannot right control on the computer 
sending spam email (zombie computer).Then, they unable to 
follow with the standards. On the other hand with setting 
limitations on the MTA
1
, an email server administrator able to 
decrease spam emails significantly, like enforcing the right fall 
back of MX
2
 records in the Domain Name System, or 
Teergrube the right controlling of delays
.
 Suffering caused 
from spam emails is far worse, where some of spam messages 
might crash the email server temporary. 
 
a) Limit rate 
This technique restrict the rate of receipt of messages from 
a user that even this user has not been characterized as a 
spammer. This technique is used as an indirect way of 
restricting spam at the ISP level [6].
  
 
b) Spam report feedback loops 
                                                          
1 mail transfer agent 
2 Mail exchange 
13 http://sites.google.com/site/ijcsis/ 
ISSN 1947-5500 
(IJCSIS) International Journal of Computer Science and Information Security,  
Vol. 13, No. 1, January 2015 
ISPs can often prevent seriously damage by monitoring 
spam reports from places like Spamcop, Network Abuse 
Clearinghouse and AOL's feedback loop, the domain's 
abuse@ mailbox, etc to catch spammers and blacklist them 
[10]. 
 
c) Quantity 
 In this technique, in a given time period spam emails detect 
by examining the number of emails send by a particular user 
[6, 11]. As the number increases, the possibility that the sender 
is a spammer increases also.  
 
d) Domain Keys Identified Mail 
Some systems utilize DNS, as apply DNSBLs to allow 
acceptance of email from servers which have authenticated in 
some fashion as senders of only legitimate email but rather 
than being used to list non conformant sites. [12, 13]. Many 
authentication systems unable to detect  a message is email or 
spam. Because their lists are static and they allow a site to 
express trust that an authenticated site will not send spam. 
Then, a receiver site may select to ignore costly spam filtering 
methods for emails from the authenticated sites [14]. 
 
e) Challenge/Response 
This technique includes two parties: one party presents a 
question („„challenge‟‟) and the other party must provide a 
valid answer or response in order to be authenticated [6]. This 
method is utilized by specialized services, ISPs and enterprises 
to detect spam is to need unknown senders by passing 
different tests before their emails are delivered. The main 
purpose of this technique is to ensure a human source for the 
message and to deter any automatically produced mass emails. 
One special case of this technique is the Turing test and 
Channel email [15]. 
 
f) Country-based or regional- based filtering 
Some servers of email do not want to communicate with 
particular regions or countries or from which they receive a 
great deal of spam. Some countries and regions are mentioned 
in introduction section according kaspersky lab.  Therefore, 
some email servers use region or country filtering. This 
technique blocks all emails from particular regions or 
countries by detecting sender's IP address [16]. 
 
g) Greylisting 
This technique temporarily rejects or blocks messages from 
unknown sender. In this method for rejecting unknown 
senders  use a 4xx error code that is recognized with all 
MTAs, so launch to retry delivery later [17]. Greylisting 
downside is that all legitimate emails from the first time that 
senders will have a delay time in delivery, with the delay 
period before a new email is received from an unknown 
sender normally being adjustable in the software [18]. It 
maybe exists that some legitimate emails won't be delivered, 
that it can happen if a weakly configured but legal mail server 
realizes the immediate rejection as a stable rejection and sends 
a bounce email to the main sender, instead of attempting to 
resend the email later, as it done. 
 
h) Honeypots 
Another method is really an imitation TCP/IP proxy server 
which gives the appearance of being an open proxy or simply 
an imitation mail transfer agent that gives the form of being an 
open message relay [19]. Spammers who check systems for 
open proxies/ relays will detect a host and try to send message 
through it, wasting their resources, time, possibility revealing 
datas about themselves and also the source of the spam emails 
sending to the entity that act the honeypot. A system may 
simply reject the spam efforts, store spams for analysis or 
submit them to DNSBLs [20]. 
 
i) Sender-supported tags and whitelists  
Some organizations that suggest licensed tags and IP 
whitelisting which can be placed in message for money to 
convince receivers' systems that the emails consequently 
tagged are not as spam email. This system depends on legal 
implement of the tags. The purpose is for email server 
administrators to whitelist emails bearing the IP whitelisting 
and licensed tags [21]. 
 
j) Outbound spam protection 
This method involves detecting spam, scanning email traffic 
as it exits in network and then taking an action like blocking 
the email or ignoring the traffic source. Outbound spam 
protection can be perform on a network-wide level  by using 
policy of routing also it can be run within a standard SMTP 
router [22]. When the primary economic impact of spam is on 
sending networks, spam message receivers also experience 
economical costs, like wasted bandwidth or the risk of having 
IP addresses rejected by receiving networks. One of the 
advantage of outbound spam protection is that it blocks spam 
before it abandons the sending network, maintaining receiving 
networks globally from the costs and damage. Furthermore it 
allows system email administrators track down spam email 
sources in the network such as providing antivirus tools for the 
customers whose systems have become infected with viruses. 
Given a suitably designed spam filtering method, outbound 
spam filtering can be perform with a near zero false positive, 
that keeps customer related issues with rejected legitimate 
message down to a minimum [23]. There are some 
commercial software sellers who suggest specialized outbound 
spam protection products, such as Commtouch and 
MailChannels. Open source software like SpamAssassin may 
be useful. 
14 http://sites.google.com/site/ijcsis/ 
ISSN 1947-5500 
(IJCSIS) International Journal of Computer Science and Information Security,  
Vol. 13, No. 1, January 2015 
 
k) Tarpits 
A tarpit is a server software that purposely responds very 
slowly for client commands. With implementing a tarpit that 
acts acceptable message generally and detect spam email 
slowly or that seems to be an open mail relay, a site can slow 
down the rate at which spammers can send messages into the 
mail simply [24]. Most of systems will really disconnect if the 
server doesn't answer quickly, which will detect the spam. 
Then, some legitimate message systems will also do not 
correctly with these delays [25]. 
 
l) Static content filtering lists 
 These techniques require the spam blocking software 
and/or hardware to scan the entire contents of each email 
message and find what‟s inside it. These are very simple but 
impressive ways to reject spam that includes given words. Its 
fault is that the rate of false positives can be high, that would 
forbid someone applying such a filter from receiving legal 
emails [1, 26]. Content filtering depend on the definition of 
lists of regular expressions or words rejected in emails. So, if a 
site receives spam email advertising "free", the administrator 
may place this word in the configuration of filtering. Then, the 
email server would reject any emails containing the word [27-
29] . Disadvantages of this filtering are divided into 3 folds: 
Time-consuming is the first one in this filtering. Pruning false 
positives is Second one. Third one is, the false positives are 
not equally distributed. Statistical filtering methods use some 
words in their calculations to know if an email should be 
classified as email or spam. Some programs that run statistical 
filtering are ASSP, DSPAM, Bogofilter, SpamBayes, later 
revisions of SpamAssassin, Mozilla Thunderbird and 
Mailwasher. 
 
m) Content base Learning Spam Filtering Systems 
One of the solutions is an automated email filtering. Many 
of filtering techniques take usage of machine learning 
algorithms, that improve their accuracy rate over manual 
approach. So, many people require filtering intrusive to 
privacy and also some email administrators prefer rejecting to 
deny access their machines from sites.[1].Variety of feasible 
contributions in the case of machine learning have addressed 
the problem of separating spam emails from legitimate emails 
[30, 31]. The best classifier is the one that reduces the 
misclassification rate. However, the researchers have realized 
later the nature and structure of emails are more than text such 
as images, links, etc. Some machine learning techniques are 
such as K-nearest Neighbor classifier, Boosting Trees, 
Rocchio algorithm, Naïve Bayesian classifier, Ripper and 
Support Vector Machine [32].  
 
B.   Content base Learning Spam Filtering Architecture 
 
The common architecture of spam filtering base machine 
learning or learning content spam filtering is shown in Fig. 3. 
Firstly, a dataset includes individual user emails which are 
considered as both spam and legitimate email is needed.  
 
15 http://sites.google.com/site/ijcsis/ 
ISSN 1947-5500 
(IJCSIS) International Journal of Computer Science and Information Security,  
Vol. 13, No. 1, January 2015 
 
Figure 2. Content base Learning spam filtering architecture 
 
The model includes 6 steps: Pre-Processing, Feature 
Extraction, Weighted Features, Feature Representation, 
email data classification, and evaluation or analyzer section. 
Machine learning algorithms are employed at last to train 
and test whether the demanded email is spam or legitimate.  
 
1)  Pre-processing 
When an email receives the first step runs on email is pre-
processing. Pre-processing includes tokenization. 
 
a) Tokenization  
Tokenization is a process to convert a message to its 
meaningful component. It takes the message and separate it 
into a series of tokens or words [33]. The tokens are taken 
from the email‟s message body, header and subject fields 
[5]. The tokenization process will extract all the features and 
words from the message without consideration of its 
meaning [32].  
 
2) Feature extraction   
After pre-processing step and breaks email message into 
tokens or features. Feature extraction process is started to 
extract useful features in all features and reduce the space 
vector. Feature extraction can include stemming, noise 
removal and stop word removal steps. 
 
a) Stemming   
 Stemming is a method to reduce terms to its main form 
with stripping the plural from nouns the suffixes from verbs 
[5, 32].  This process is suggested by Porter on 1980, it 
determines stemming as an approach for deleting the 
commoner structural and in-flexional endings from terms in 
English [34]. A collection of rules 
 is referred to convert words to their stems or roots 
iteratively. This method increases speed of learning and 
classification steps for many classes and decrease the 
number of attribute in the feature space vector [35].  
 
b) Noise removal 
Unclear terms in an email cause noise. A intentional 
action of misplaced space, misspelling or embedding 
particular characters into a word is pointed to as 
obfuscation. For instance, spammers obfuscated the word 
Free into“fr33” or Viagra into “V1agra”,“V|iagra”. 
Spammers employ this approach in an effort to bypass the 
right  recognition of these words by spam filtering [5, 32] 
To contrast these misspelled words, Regular expression and 
statistical deobfuscation techniques is used. 
 
c) Stop-word removal 
16 http://sites.google.com/site/ijcsis/ 
ISSN 1947-5500 
(IJCSIS) International Journal of Computer Science and Information Security,  
Vol. 13, No. 1, January 2015 
Stop-word removal technique is the process for 
elimination of usual terms that have the most frequency but 
have less meaning than the words [36]. Messages contains 
large number of noninformative words like articles, 
prepositions, conjunctions and these words will increase the 
size of the attributes vector space cause complicating the 
classifier.  
 
3)  Weighted Features 
When the useful features are selected, it is the time to 
choose a measure to assign the features to create features 
vectors before classification. Weighted features includes 
Information gain, Document frequency, Mutual information, 
Chi-square steps. 
 
a) Information gain (IG)   
IG is the attribute‟s impact on reducing entropy [37]. IG 
calculates the number of bits of information gained for the 
class by knowing the attendance or lack of  presence of a 
word in a document[5]. Let denote the set of classes in the 
goal space. IG formula is defined as:  
 
 
(1)   
 
 
b) Document frequency [11] 
DF points to the number of documents in which an 
attribute occurs[5].The weight of the attributes is calculated 
in the lower frequency, that is less than the predefined 
threshold, is deleted[38]. Negligible attributes that do not 
contribute to classification are deleted then improving the 
efficiency of the classifier. The following formula 
represents the form of document frequency: 
 
 
(2) 
 
c) Mutual information (MI) 
MI is a quantity that calculates the mutual dependence of 
the 2 variables.  If a attribute does not depend on a category 
then it is eliminated from the  attribute vector space[39]. For 
each attribute feature X with the class variable C, MI can be 
computed as follows:  
  
)3) 
 
 
MI is an easier method to run and valid in predictions. 
 
d) Chi-square 
Chi-Square test is a statistical measure that calculates the 
existence of attribute against the expected number of the 
existences of those attributes [5] . In the Chi-square test, the 
features refer to the independent variables and categories 
indicate the dependent variables that is spam and legitimate 
[39, 40]. 
 
(4) 
 
 
Formula 4 calculates the term of goodness, class c and t, 
which A is the number of times t and c exists together, B is 
the number of times the exists without c , C is the number of 
times c  exists without t , and D is the number of times 
neither c not  t exists. The chi-square equation for class 
computation is as follows: 
                        
(5) 
 
                
(6) 
 
 
4)  Feature Representation  
 
Feature representation converts the set of weighted features 
to a specific format required by the machine learning 
algorithm used. Weighted features are usually shown as bag 
of words or VSM
1
. The literal features are indicated in 
either numeric or binary.  VSM represents emails as vectors 
such as x = {x1,x2,…,xn}. All features are binary: xi=1, if 
the corresponding attribute is available in the email, 
differently xi= 0. The numeric presentation of the features 
where xi  is a number represents the occurrence frequency of 
the attribute in the message. For instance if the word 
“Viagra” seems in the email then a binary value equal will 
be assigned to the attribute. The other generally used 
attribute representation is n-gram character model that gets 
characters sequences and TF-IDF
2
 [41]. N-gram model is N-
characters piece of a word. It can be noted as each co-
occurring collection of characters in a word. N-gram model 
infolds bi-gram, tri-gram and qua-gram. TF-IDF is measure 
that is statistical utilized to calculate how importance a word 
is to a document in a attribute dataset. Word frequency is 
defined with TF
3
, that is a number of times the word exists 
in the email yields the importance of the word in to the 
                                                          
1 Vector Space Model 
2 frequency-inverse document frequency 
3 term frequency 
17 http://sites.google.com/site/ijcsis/ 
ISSN 1947-5500 
(IJCSIS) International Journal of Computer Science and Information Security,  
Vol. 13, No. 1, January 2015 
document. Then frequency is multiplied with IDF
1
 which 
measures the frequency of the word happening in all emails 
[42]. 
 
5) Classifier 
  
Supervised machine learning techniques run by collecting 
the training dataset, which is manually prepared 
individually. The training dataset have two phases, one 
phase is legal emails, another one is the spam emails. Then, 
each email is converted into features that is images, time, 
words for instance in the email. So, the classifier builds that 
would determine the nature of next incoming email[1]. Most 
of machine learning algorithms have been worked in the 
direction of spam detection like Boosting Trees [43, 44], K-
Nearest Neighbor classifier [29, 45], Rocchio algorithm [44, 
46], Naïve Bayesian classifier [29, 47-49] and Ripper [44, 
50]. Furthermore, these algorithms filter the email by 
analyzing the header, body or the whole message. Support 
Vector Machine Is one of the most used techniques as the 
base classifier to overcome the spam problem [51]. SVM 
algorithm is used wherever there is a need for model 
recognition or classification in a specific category or class 
[52]. Training is somehow easy and in some researches the 
efficiency is more than other classifications. This is due to 
the fact that in data training step, Support vectors use data 
from database but for high dimension data, the validity and 
efficiency decrees due to the calculating complexities [53, 
54]. 
 
6) Evaluation or Performance Measures 
 
Filtering needs to be evaluated with performance 
measures that it divided into two categories: decision theory 
like (false negatives, false positives, true positive and true 
negative) and information retrieval such as (accuracy, recall, 
precision, error rate and derived measures) [32].  Accuracy, 
precision and spam recall are the most practical  and useful 
evaluation parameters. Accuracy indicates the ratio between 
the number of legitimate mails and the number of correctly 
classified spam emails to the total correctly classified emails 
used for testing. Recall refers to the ratio between the 
number of correctly classified spam against spam that is 
misclassified as legitimate and the number of spam emails 
detected as spam.  Precision shows the ratio between the 
numbers of correctly classified spam to the number of all 
messages recognized as spam. Table 1 represents 
performance measures of spam filtering: 
 
 
                                                          
1 inverse document frequency 
TABLE I.  Performance Measures of Spam Filtering 
Equations 
Performance 
measures 
 
(nL→L + nS→S)/( nL→L + nL→S + nS→L + nS→S) 
 
Accuracy 
(nL→S + nS→L)/( nL→L + nL→S + nS→L + nS→S) Error Rate 
(nL→S)/( nL→L + nL→S) False positive 
(nS→L)/( nL→L + nL→S) False negative 
(nS→S)/( nS→L + nS→S) Recall 
(nS→S)/( nL→S + nS→S) Precision 
( nS→L + nS→S)/ λ.( nL→S + nS→L) 
TotalCost Ratio 
(TCR) 
Ratio between true positive and false positive for 
various threshold values. 
ROC Curve 
 
 
 
As shown in table 1, nL→L and  nS→S refer to the legitimate 
emails and spam emails that correctly classified. nS→L  
indicates spam emails incorrectly have been classified as 
legitimate emails and nL→S  point to the legitimate emails 
incorrectly have been classified as spam emails. Error rate is 
the rate between spam and legitimate emails are incorrectly 
classified to the total correctly classified emails  used for 
testing. False negatives [55] is a measure to recognize the 
spam emails that are classified as legitimate emails. False 
positives (FP) refers to the legitimate email classified as. 
Spam emails that correctly classified as spam emails 
represent to true positive (TP = 1 - FN). Legitimate emails 
that are correctly classified as legitimate emails refer to true 
negative (TN = 1 - FP). ROC
2
  curve indicates [56], true 
positive as a function of the false positive for various 
threshold values. Total cost ratio (TCR) use for comparing 
the rate of effectual filtering by a given value of λ in 
comparison with no filtering is used. If TCR >1, the using of 
filtering is proper. 
 
 
III. EVALUATION OF SPAM DETECTION WITH STANDARD 
SVM 
A. Standard Support Vector Machines 
 
SVM is a classifier that is included as a sub branch of 
Kernel Methods in Machine Learning. It is based on 
statistical learning theory [57]. In SVM, assuming a linear 
categories are separate frames of acceptance, with a 
maximum margin hyperplane that acquires are separate 
categories. Separate data linearly in matters that are not 
accepted frames of data are mapped to a higher dimensional 
space so that they can be separated in the new space 
linearly. If there are two categories that are linearly 
separable, what is the best way of separating of two 
                                                          
2 Received Operating Characteristic 
18 http://sites.google.com/site/ijcsis/ 
ISSN 1947-5500 
(IJCSIS) International Journal of Computer Science and Information Security,  
Vol. 13, No. 1, January 2015 
categories? Various algorithms such as "Perceptron" can do 
this separation. The idea of SVM, to separate a category is 
to create two borders: two parallel plate boundary 
classification and draw them away from each other so that 
to hit the data we are dealing. Board Categories that owns 
the maximum distance from the boundary of the plates may 
be best the separator. Fig. 4 shows SVM classification: 
 
 
Figure 3. SVM classification 
 
 
Nearest training data to the hyperplane separator plates is 
called "support vector." The proper using of the SVM 
algorithm is the power of generalization, because despite 
having large dimensions, the over fitting can be avoided. 
This property is caused by the optimization algorithm used 
in data compression. In fact, Instead of training data, 
support vectors are used. To solve the problem, we have a 
number of training samples, x  
n
 which is a member of 
the class y and y  [-1, 1]. SVM linear decision function is 
defined as follows: 
 
f(x) = sign(<w,x> + b) , w  
n 
, b    (7) 
 
Separating hyperplane is defined below: 
 
<w,x> + b = 0 , w1x1 + w2x2 … + wnxn + b = 0     (8) 
 
We should find the values of W, b so that the training 
samples are closely grouped, with the assumption that data 
can be separated linearly to a maximum margin. For this 
purpose we use the following equation: 
 
 
(9) 
 
(10) 
In the relations of (9) and (10), the values of    or Dual 
Coefficient and b by using QP equations are solved. New 
values of x, the test phase in relation to the following places: 
 
 (11) 
 
There are different kernel functions. Thus, solving 
equations using kernel function is defined as follows: 
 
 (12) 
 
 (13) 
 
 (14) 
 
SVM can be used in pattern recognition and where you 
need to identify patterns or categories of classes particular. 
Training is fairly simple. Compromise between complexity 
and classification error rate clearly is controlled. Fig. 5 
presents SVM algorithm [58]. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
19 http://sites.google.com/site/ijcsis/ 
ISSN 1947-5500 
(IJCSIS) International Journal of Computer Science and Information Security,  
Vol. 13, No. 1, January 2015 
 
ALGORITHM 1  :  Support Vector Machine 
 
Input: sample x to classify, Training set  
T = {(x1,y1),(x2,y2),……(xn,yn)}; 
Output:  decision yj   [-1,1] 
compute SVM solution w, b for data set with imputed labels 
compute outputs yi = (w , xi) + b for all xi in positive bags 
set yi = sign(yi) for every i[-1,1] 
for (every positive bag Bi) 
if ( ∑i yi
Compute i* = arg max iI yi 
Set yi =1 
end 
end 
While (imputed lables have changed) 
Output (w,b) 
Put values w,b in yi and get get the result yi 
 
Figure 4. SVM algorithm
B. Examining of Standard SVM in Spam Detection 
 
A spam email classification based on SVM classifier was 
presented by Drucker and his co-workerss. In this article, 
speed and accuracy metrics on SVM and 3 other 
classifications like Ripper, Rocchio and Boosting Decision 
trees were compared on 2 datasets. One dataset had 1000 
features another one had over than 7000 features. Moreover, 
TF-ID and applying STOP words were used on features. 
Results had been shown that the speed of binary SVM 
algorithm on training dataset was much higher than other 
classification and its accuracy was very near to Boosting 
algorithm. Also the error rate of binary SVM was lower than 
other classification on two dataset with 0.0213% [44].  
Woitaszek et al used linear SVM classification and a 
personalized dictionary to model the training data. They 
proposed a classification that implemented on Microsoft 
Outlook XP and  they could categorize the emails on Outlook 
XP. The accuracy rate of proposed method was 96.69% that 
was 1.43 higher than system dictionary with the accuracy rate 
of 95.26 [59]. Matsumoto and et al applied their tests results 
on two classifications such as SVM and Naive Baysian and 
used TF and TF-IDF on features vector. The accuracy rate of 2 
classifiers were the same, but the one with a lower false alarm 
rate and miss rate is better classifier. Their results showed that 
Naive Baysian has better performance than SVM on a dataset. 
The false alarm rates and miss rates for Naive Baysian were 
stable in almost all the data sets [60]. Scheffer et al, developed 
an approach for learning a classifier using publicly available 
(labeled) and (unlabeled) messages. In this case n users were 
currently subscribed, the classifier for a new user was obtained 
by training a linear SVM, where the misclassification cost of 
the messages was based on the estimated bias-correction term 
of each message. The experiments run on Enron corpus and 
Spam messages from various public and private sources of 
email users on binary representation. It was verified that the 
proposed formulation (1 _ AUC)  decreased the risk up to 
40%, in comparison with the user of a single classifier for all 
user [61]. Kanaris et al, used n-gram characters while n was 
predefined and was used as a variable in linear SVM. In this 
research, information retrieval was used to select features and 
the binary representation words frequency TF were also used. 
Experiment run on LingSpam and Spam Assassin data sets. 3 -
, 4 - and 5 - gram and 10-fold cross-validation was performed. 
N-gram model is better than the other methods. Results were 
shown that with variable N in a cost-sensitive scenarios, with 
binary features, spam precision seem to provide better results. 
Also TF features are better than for spam recall. Then, spam 
precision rate was higher than 98%    and spam recall rate was 
higher than 97%. TCR value  of the proposed approach was 
not greater than 1 because the precision ratio failed to be 
100% [62].Ye et al provided a distinct model based on SVM 
and DS theory. They used SVM to classify and sort mail based 
on header contents features and applied DS theory to detect 
spammers with the accuracy rate of 98.35% [63]. Yu and Xu 
et al, compared 4 machine learning algorithms such as NB
1
, 
                                                          
1 Naïve Bayes 
20 http://sites.google.com/site/ijcsis/ 
ISSN 1947-5500 
(IJCSIS) International Journal of Computer Science and Information Security,  
Vol. 13, No. 1, January 2015 
NN
1
, SVM and RVM
2
. Test results showed that NN classifier 
was very sensitive and was the only unfit for rejecting spam 
mails. SVM, RVM had much better performance than NB. 
RVM had a higher run time rather than SVM [53]. Chhabra et 
al used SVM classifier for spam filtering and compared 
multiple VM kernel function on the Enron data set with 
different rates. In these tests, the performance of the linear 
kernel and polynomial kernel with degree= 1 were equal 
because the performance of those kernel functions were the 
same. If the degree of polynomial kernel increases, the 
performance of its function decreases [64]. Shahi et al used 
SVM and Naïve Bayes to classify the Nepali SMS as non-
Spam and Spam. The accuracy measure was used to empirical 
analyze for various text cases to evaluate of the classification 
methodologies. The accuracy of SVM was 87.15% and the 
accuracy of Naïve Bayes was 92.74% [65]. A method based 
on Artificial Immune System (AIS) and incremental SVM 
were proposed for spam detection. In this study to effect 
change of the content of email dynamically and label email a 
sliding window was used. Experiments run on PU1 and Ling 
datasets with compared 8 methods, considered as different  
including Hamming Distance(without  and with without 
mutation), SVM ,Included Angle and Weighted Voting. The 
results show that methods in SVM group had a good 
performance with miss rate below 5% on corpus PU1. When 
the number of support vectors was growth, the speed would 
increase. The performance of AIS group has been 
unsatisfactory. On the other hand with the increase in size of 
window from 3 to 5, the performance of WV group and AIS 
group raised [66]. Summary of this section is shown in Table 
2. 
 
TABLE II. OVERVIEW OF STANDARD SVM IN SPAM EMAILS 
 
Authors 
 
year 
 
Idea  
 
 
Harris 
Drucker, , 
Donghui 
Wu, and 
Vladimir 
N. Vapnik 
 
 
 
1999 
 
In this study, 3 classification such as Ripper, 
Rocchio and Boosting Decision trees were 
compared with SVM. Moreover, TF-ID was 
used for both binary features, Bag of Words. 
STOP words was applied on features. Results 
represented that the performance in term of 
speed and accuracy of binary SVM was much 
higher than other classification and its 
accuracy was very close to Boosting algorithm. 
 
Woitaszek 
M, 
Shaaban 
M, 
Czernikow
ski R 
 
 
2003 
 
To model the training data, used linear SVM 
classification and a linear dictionary. The 
classification implemented on Microsoft 
Outlook XP and  they could categorize the 
emails on Outlook. The accuracy rate of 
proposed method was 96.69%. 
                                                          
1 neural network 
2 Relevance vector machine 
 
Matsumot
o R, 
Zhang D, 
Lu M 
 
2004 
 
In this research SVM and Naive Baysihean 
compared together. TF and TF-IDF were 
applied on features. Their results showed that 
Naive Baysian had better performance than 
SVM on a dataset. 
 
 
Kanaris, I., 
Kanaris, 
K., 
Houvardas
, I., & 
Stamatatos
, E 
 
 
 
2007 
 
In this research, n-gram characters, 
information retrieval were used to select 
features. Binary representation words 
frequency TF were also applied on features. 
Experiments run on LingSpam and Spam 
Assassin data sets with 3 -, 4 - and 5 - gram 
and 10-fold cross-validation. N-gram model is 
better than the other methods and results show 
that spam precision rate was higher than 98%    
and spam recall rate was higher than 97%. 
TCR value  of the proposed approach was not 
greater than 1. 
 
 
Bickel, S , 
Scheffer, 
T 
 
 
 
 
2007 
 
A model is presented a classification 
framework for learning generic messages, 
available (labeled) and unavailable messages. 
Linear SVM was used for classification a new 
user. Experimental results implemented on 
Enron corpus dataset with binary 
representation. This research proposed the risk 
formula (1 _ AUC) decreased to 40%. 
 
 
Ye M, 
Jiang QX, 
Mai FJ 
 
 
2008 
 
A distinct model based on SVM and DS theory 
was suggested. They used SVM to classify and 
sort mail based on header contents features and 
applied DS theory to detect spammers with the 
accuracy rate of 98.35%. 
 
Yu B, Xu 
Z 
 
2008 
 
4 machine learning algorithms NB, NN, SVM 
and RVM compared. Test results showed that 
NN was very sensitive and unfit for rejecting 
spam mails. SVM, RVM had much better 
performance than NB and RVM had a higher 
run time rather than SVM. 
 
Priyanka 
Chhabra, 
Rajesh 
Wadhvani, 
Sanyam 
Shukla 
 
 
2010 
 
SVM classifier used for spam filtering and 
compared multiple VM kernel function on the 
Enron data set with different rates. In these 
tests, the performance of the linear kernel, 
polynomial kernel with degree one were equal. 
If the degree of the polynomial kernel 
increases, performance decreases. 
 
Tej 
Bahadur 
Shahi, 
Abhimanu 
Yadav 
 
2013 
 
Naïve Bayes and SVM were used to classify 
the Nepali SMS as Spam and non-Spam and it 
was found to be 87.15% accurate in SVM and 
92.74% accurate in the case of Naïve Bayes. 
 
 
 
TAN, Y 
and 
RUAN, G 
 
 
 
2014 
A hybrid method based on AIS and 
incremental SVM were suggested. A sliding 
window to effect the change of the content of 
email dynamically and label email was used. 
Experiments run on PU1 and Ling datasets 
with compared 8 methods. The results show 
that SVM group had a good performance with 
miss rate below 5% on corpus PU1. When the 
number of support vectors was growth, the 
speed would increase. The performance of AIS 
group has been unsatisfactory. On the other 
hand with the increase in size of window from 
3 to 5, the performance of WV group and AIS 
group had raised. 
21 http://sites.google.com/site/ijcsis/ 
ISSN 1947-5500 
 
IV. EVALUATION OF SPAM DETECTION WITH 
IMPROVED SVM 
 
A.  Improved Support Vector Machines  
One common weakness from the point of parametric 
methods like SVM classification is that the computational 
complexity is not appropriate for data with high 
dimensions. Weight ratio is not constant, so the marginal  
value is varied. Also there is need to decide to choose a 
good kernel function in order to select and the proper 
value for C parameter. SVM is suitable to deal with the 
problems of limited training data features [67]. In 
researches of [55, 68-72], SVM is much more efficient 
than other non-parametric classifications for example 
Neural Networks, K-Nearest Neighbor in term of 
classification‟s accuracy, computational time and set the 
parameters but it has a weak function in the data set with 
high dimension features. Four classifications including 
neural networks, SVM, J48, simple Bayesian filtering 
were used for spam email data set. All emails were 
classified as spam (1) or not (0). Compared with the J48 
and simple Bayesian classifier with many features, it was 
reported that SVM, neural network and NN did not show 
a good result. Based on this fact, the researchers 
concluded that the NN and SVM are not suitable for 
classification of large datasets email. The result of the 
study of [64] revealed that SVM captures a high range of 
time and memory for big size of the data set. To solve the 
classification problem of SVM, the most effective and 
proper features are necessary as feature candidates rather 
than using the entire feature space and the sample choose 
as support vectors in order to keep performance and 
accuracy for SVM. 
 
B. Examining of Improved SVM in Spam Detection  
Wang et al proposed a new hybrid algorithm based on 
SVM and Genetic algorithms to select the best email 
features named GA-SVM and then compared it with SVM 
on UCI spam database. The experiments were represented 
that the new algorithm is more accurate. The accuracy 
rate for proposed method was 94.43 that 0.05 increased 
rather than SVM with accuracy rate 94.38%   [73]. Ben 
Medlock & Associates introduced a new adaptive method 
named “ILM
1
” which used the combination of Weights 
and N-gram language and in the end compared it with 
SVM, BLR
2
, MNB
3
. The results showed that the ILM 
accuracy is higher than other algorithms with 0.9123% 
                                                          
1 Interpolated Language Model 
2 Bayesian Logistic Regression 
3 Multinomial Naive Bayes 
and SVM accuracy was 0.8472% [74]. A new approach 
based Online SVM was proposed for spam filtering which 
was compatible with any new training set, for each 
system. In this method, an adaptive situation was 
provided for the parameter C (one of the main issues in 
the classification of SVM, the choice to obtain the 
maximum distance between a bunch of C) and then it was 
compared with SVM method. The proposed method 
accuracy was 0.1% more than SVM accuracy [75]. 
Blanco et al suggested a solution to reduce false negative 
errors based on SVM for spam filtering. In this study a 
combining of multiple dissimilarities of an ensemble of 
SVM is proposed. Results had shown that the proposed 
method was more efficient rather than SVM [76]. 
Blanzieri et al, had an improvement on the SVM classifier 
to detect spam by localizing data. In this reasearch, two 
algorithms were proposed and implement on TREC 2005 
Spam Track corpus and SpamAssassin corpus, one was 
the SVM Nearest Neighbor Classifier which was a 
combination of SVM and K Nearest Neighbor and the 
second one was HP-SVM-NN which was the previous 
algorithm with a high degree of probability. Both methods 
were compared with SVM and the results show that the 
accuracy of these two algorithms are higher than SVM 
with 0.01% higher[77]. Sun et al used two algorithms 
LPP
4
and LS-SVM
5
 in order to detect spam. They used 
LPP algorithm for extracting features from emails and 
LS-SVM algorithm for classification and detection of 
spams from mails received. Their results showed that the 
performance of proposed method was better than the other 
categories with the accuracy rate of 94% [78]. Tseng et al 
proposed an Incremental SVM for spam detection on 
dynamic social networks. The proposed system was called 
MailNET that installed on the network. Several features 
extracted from user for training on dataset of the network 
were applied and then updating plan with the incremental 
learning SVM. The proposed system implemented on a 
data set from a scale of university email server. Results 
have shown that the proposed MailNET was effective and 
efficient in real world  [79]. Ren proposed email spam 
filtering framework for feature selection using SVM 
classifier. In this way, (TF-IDF) weight was applied on 
features. The accuracy of proposed method on TREC05p-
1, TREC06p and TREC07p datasets were 98.830, 
99.6414% and 99.6327%. Experiments represent that the 
proposed method of feature extraction increases the 
effectiveness and performance of text detection with less 
computational cost and the proposed model can run on 
dataset in other languages, such as Japanese ,Chinese etc 
[80]. Rakse et al used SVM classifier for spam filtering 
and proposed a new kernel function called Cauchy kernel 
                                                          
4 locality pursuit projection 
5 least square version of SVM 
22 http://sites.google.com/site/ijcsis/ 
ISSN 1947-5500 
(IJCSIS) International Journal of Computer Science and Information Security,  
Vol. 13, No. 1, January 2015 
function. Experiments run on ECML-PKDD dataset and 
results represented that the performance of the new kernel 
function was better AUC values on experiments of 
eval01,eval02 and eval03 datasets with the accuracy of 
0.72343%,  0.77703%,  0.89118% when C=1.0 [81]. 
Yuguo et al prepared a sequential kernel functions 
commonly called PDWSK to classify SVM. The kernel 
function had the ability to identify dependence criteria 
among existing knowledge when words created on the net 
and capable to calculate the semantic similarity in a text 
and had higher accuracy compared with SVM. The 
proposed method was run on trec07p corpus with 5-cross 
validation and compared with other kernel function of 
SVM such as RBF, Polynomial, SSK, WSK. The 
precision, recall and F1 measures for PDWSK were 
93.64%, 92.21%, 92.92% that were higher than the other 
kernel functions  [82]. A predictive algorithm combined 
with fuzzy logic, Genetic algorithms and SVM classifier 
with RBF kernel was presented. The proposed method 
used LIBSVM and MATLAB to implemented SVM, 
fuzzy rules and GA. The proposed method can detect 
errors in pages according to their SVM classification in 
comparison with standard SVM.  The accuracy of 
proposed method  had a higher efficiency with 95.6% 
[83]. Hsu and Yu proposed a combination algorithm from 
Staelin and Taguchi methods for the optimization of SVM 
with the choice of parameters for classifying spam email. 
The proposed method SVM (L64 (32X32X2)) were 
compared with other methods such as improved Grid 
search(GS), SVM(Linear), Naїve Bayes and 
SVM(Taguchi Method L32) on 6 data sets of Enronspam 
Corpa. If the parameters C and γ were not set up for linear 
kernel SVM, the accuracy of SVM(Linear) would lower 
than proposed method and Naїve Bayes algorithms. On 
the other hand, the proposed method was not the best 
accuracy and was lower than GS(32×32). But GS need 
computing 32×32 = 1024 times, searching and the 
proposed method required 64 times. The propose method 
was 15 times faster. The accuracy of proposed method 
was near to GS and can select good parameters for SVM 
with RBF kernel [84]. FENG and ZHOU proposed two 
algorithms OCFS
1
, MRMR
2
 for dimension reduction and 
elimination related features. They incorporated OCFS and 
MRMR and proposed OMFS
3
 algorithm. This algorithm 
had two phases: the first phase was OCFS algorithm 
which selected features from data space and useed in the 
next stage. The second phase of the algorithm used the 
characteristics of the candidates features which are 
selected then MRMR was used to reduce the redundant 
attributes. These algorithms reduce the dimensions on the 
                                                          
1 Orthogonal Centroid Feature Selection 
2 Minimum Redundancy Maximum Relevance 
3 Orthogonal Minimum Feature Selection 
classifications of Naive Bayes, KNN and SVM on PU1 
dataset. Results have shown that MRMR get the best 
feature selection accuracy in comparison of SVM, NB 
and KNN. The worst accuracy rate belongs to CHI. The 
accuracy of NB on CHI is lower than 85%. It also 
displays the poorer accuracy on SVM, with fluctuating 
on75%. The accuracy of KNN has increased with feature 
selection but even below 85%. Finally, with increasing 
feature of the proposed algorithm the accuracy, F-
Measure, ROCA on proposed method increases in 
comparison of the other algorithms [54]. Maldonado and 
Huillier, proposed a distributed feature selection method 
on datasets with minimal error determined nonlinear 
decision boundaries. Also by using two-dimensional 
formulation, can reduce the number of features are useless 
on SVM binary. With proposed method, the width of RBF 
kernel is optimized by using of the reduced gradient. 
Experiments run on 2 real world spam datasets. Results 
show that the proposed feature selection method perform 
better than the other feature selection algorithms when a 
smaller number of variables are using [85]. Yang et al 
used LSSVM
4
 algorithm to detect spam. These algorithms 
solved the problem of garbage tags. In this method, 
inconsistent changes in the structure of traditional SVM, 
is converted to a balanced structure. An empirical 
function for square errors exists in the test data set. So 
Quadratic Program (QP), convergent to the linear 
equations. This algorithm increases the speed and 
classification accuracy under high dimensional 
gisette_scale data set. LSSVM training time was near 
less10 times than SVM. The accuracy of SVM was 
47.50% and the LSSVM accuracy was 60.50%  [86]. 
Hong-liang ZHOU and LUO proposed a method by 
combining SVM and OCFS
5
 for feature selection 
algorithm to detect spams. Experiments were performed 
on 5 spam corpuses (ZH1, PU1, PU2, PU3 and PUA). 
The result showed that the proposed method compared 
with other traditional combinations, had better 
performance in terms of accuracy and F-Measure. The 
accuracy rate of proposed method was above 90% on 5 
dataset of spam corpuses [87]. GAO et al modify the 
SVM classifier by exploiting web link structure. They 
firstly construct the link structure preserving within-class 
scatter matrix with direct link matrix and indirect link 
matrix. Then they incorporate web link structure into 
SVM classifier to reformulate an optimization problem. 
The proposed method is useful for the link information on 
the web. Results show that the combination of web link 
structure and SVM can significantly outperform related 
methods on web spam datasets. The proposed method 
almost had better performs from the other method of 
                                                          
4 least Squares support vector machine classifiers 
5 Orthogonal Centroid Feature Selection 
23 http://sites.google.com/site/ijcsis/ 
ISSN 1947-5500 
(IJCSIS) International Journal of Computer Science and Information Security,  
Vol. 13, No. 1, January 2015 
SVM on WEBSPAM-UK2006 except spam pages 
accuracy, followed by MCLPVSVM and MCVSVM. 
Also, the results on link features were better than results 
on other feature selection combination. It was clear that 
the proposed method had better performs on WEBSPAM-
UK2007 integral features. Although, the proposed method 
was just a little better than MCVSVM, it maybe had the 
reason that the indirect link matrix and the direct link 
matrix were both sparse matrices [88]. Renuka and et.al 
proposed a method name Latent Semantic Indexing (LSI) 
for feature extraction method to select the proper and 
suitable feature space. The Ling spam email corpus 
datasets was used for the experimentation. The accuracy 
of SVM (TF-IDF) was 85% while the accuracy of SVM 
(LSI) was 93% Then the performance improvement of 
SVM (LSI) over the SVM (TF-IDF) was 8% [89] The 
Summary of this section is shown in table 3.  
 
TABLE III. OVERVIEW OF IMPROVED SVM IN SPAM EMAILS 
 
Authors 
 
Year 
 
Idea 
 
Huai-bin Wang, 
Ying Yu, and 
Zhen Liu 
 
 
2005 
 
A new hybrid algorithm (GA-SVM) is 
proposed based on SVM and Genetic 
algorithm. GA used to select suitable email 
features. The proposed method was 
compared with SVM. Results show that 
the new algorithm was more accurate with 
0.05 increased. 
 
 
Ben Medlock, 
William Gates 
Building, JJ 
Thomson 
Avenue 
 
 
 
2006 
 
A new adaptive method named ILM was 
proposed which used the combination of 
Weights and n-gram language. ILM 
compared with SVM, BLR and MNB. The 
results showed that the ILM accuracy is 
higher than other algorithms with 
0.9123%. 
 
 
D.Sculley, 
Gabriel M. 
Wachman 
 
 
 
 
2007 
 
A new approach based Online SVM was 
proposed for spam filtering which was 
compatible with any new training set, for 
each system. In this method, an adaptive 
situation was provided for the parameter C. 
The proposed method had better 
performance rather than SVM and its 
accuracy was 0.1% more than SVM. 
 
Angela Blanco, 
Alba María 
Ricket, 
Manuel Martín-
Merino 
 
 
 
2007 
 
A solution to reduce false negative errors 
based on SVM for spam filtering is 
suggested. Then to achieve this goal an 
ensemble of SVM that hybrids multiple 
dissimilarities is proposed. Results have 
shown that the proposed method is more 
efficient rather than SVM with one branch. 
 
 
Enrico 
Blanzieri, 
Anton Bryl 
 
 
 
2008 
 
 
 
Two algorithms were proposed, one was 
the SVM Nearest Neighbor Classifier 
which was a combination of SVM and K 
Nearest Neighbor and the second one was 
HP-SVM-NN which is the previous 
algorithm with a high degree of 
probability. Results show that the accuracy 
of these two algorithms were higher than 
SVM with 0.01% higher. 
 
 
Sun X, Zhang 
Q, Wang Z 
 
 
2009 
 
Two algorithms LP Pand LS-SVM were 
proposed.  LPP algorithm used for feature 
selection and LS-SVM algorithm used for 
classification. The results showed that the 
performance was better than the other 
categories with the accuracy rate of 94%. 
 
 
Chi-Yao Tseng, 
Ming-Syan 
Chen 
 
 
2009 
 
An Incremental SVM for spam detection 
on dynamic social networks named 
MailNET was suggested. The proposed 
system was installed on the network. 
Several features extracted from user for the 
training of the network were applied and 
then updating plan for the incremental 
learning SVM. 
 
 
 
Qinqing Ren 
 
 
 
2010 
 
An email spam filtering framework for 
feature selection using SVM classifier was 
proposed. In this way, the attribute 
frequency (TF-IDF) weight is applied on 
features. The accuracy of proposed method 
on TREC05p-1, TREC06p and TREC07p 
datasets were 98.830, 99.6414% and 
99.6327% and proposed model can run on 
datasets in other languages, such as 
Japanese ,Chinese etc. 
 
Surendra Kumar 
Rakse,Sanyam 
Shukla 
 
 
2010 
 
A new kernel function for SVM classifier 
in spam detection was proposed, called 
Cauchy kernel function and the 
performance measured on ECML-PKDD 
dataset. Results are shown that the 
performance of the new kernel function is 
better than rest. 
 
 
Liu Yuguo , 
Zhu Zhenfang, 
Zhao Jing 
 
 
2011 
 
A sequential kernel functions commonly to 
classify SVM called DPWSK was 
proposed. DPWSK kernel can identify 
dependence criteria among existing 
knowledge and can calculate the semantic 
similarity in a text and had higher accuracy 
compared with SVM. Results show that 
precision=93.64%, recall=92.21% and 
F1=92.92% for PDWSK. 
 
S. Chitra, K.S. 
Jayanthan, S. 
Preetha, R.N. 
Uma Shankar 
 
 
2012 
 
 
A predictive hybrid algorithm with fuzzy 
logic, GA and SVM classifier was 
presented. The proposed algorithm can 
detect errors in pages according to fuzzy 
rules and GA and can classifier with SVM 
classification. Results show the accuracy 
of SVM had a higher efficiency with 
95.6%. 
 
Wei-Chih Hsu 
, Tsan-Ying Yu 
 
 
2012 
 
A combination Algorithm with Staelin and 
Taguchi methods to aim optimization of 
SVM and the choice of parameters for 
classifying spam email, have been 
proposed. The parameters of the proposed 
method with other methods such as 
improved grid search on 6 data sets were 
compared. The results show that the 
propose method was 15 times faster than 
GS and the accuracy of proposed method 
was near to GS. 
24 http://sites.google.com/site/ijcsis/ 
ISSN 1947-5500 
(IJCSIS) International Journal of Computer Science and Information Security,  
Vol. 13, No. 1, January 2015 
 
 
 
Yu FENG, 
Hongliang Zhou 
 
 
 
2013 
 
A hybrid algorithms base on OCFS and 
MRMR for dimension reduction named 
OMFS was proposed. OMFS had 2 phases: 
first OCFS algorithm run to select features 
from data space second MRMR to reduce 
the redundant attributes. These algorithms 
reduce the dimensions of Naive Bayes, 
KNN and SVM on PU1 dataset. Results 
have shown that with increasing feature of 
the proposed algorithm, the accuracy, F-
Measure and ROCA on these classification 
have been increased. 
 
 
 
Sebastían 
Maldonado, 
Gaston 
L‟Huillier 
 
 
 
 
2013 
 
A distributed approach on datasets with 
minimal error was determined nonlinear 
decision boundaries. Also used two-
dimensional formulation to reduce the 
number of features on SVM binary. With 
proposed method, the width of RBF kernel 
is optimized by using of the reduced 
gradient. Results on 2 real spam dataset 
represented that the proposed feature 
selection method perform better than the 
other feature selection algorithms when a 
smaller number of variables were used. 
 
 
 
Xiaolei Yang , 
Yidan Su , 
JinPing Mo 
 
 
 
 
2013 
 
LSSVM algorithm is proposed to solve the 
problem of garbage tags. In this method, 
quadratic program (QP), convergent to the 
linear equations with inconsistent changes 
in the structure of traditional SVM that is 
converted to a balanced structure. Also an 
empirical function for square errors exists 
in the test data set. This idea increases 
speed and classification accuracy. LSSVM 
training time was near less10 times than 
SVM. The accuracy of SVM was 47.50% 
and the LSSVM accuracy was 60.50% 
 
 
Hong-liang 
Zhoou, Changy-
yong Luo 
 
 
 
2014 
 
A hybrid method base on and OCFS for 
feature selection is proposed. Experiment 
results are run on five spam corpuses 
(PU1, PU2, PU3, PUA and ZH1). The 
result showed that F-Measure and accuracy 
of proposed method are more excellent 
than other traditional combinations. The 
accuracy rate of proposed method was 
above 90% on 5 dataset of spam 
 
 
Shuang Gao, 
Huaxiang 
Zhang, Xiyuan 
Zheng, Xiaonan 
Fang 
 
 
2014 
 
A framework to modify the SVM classifier 
by exploiting web link structure is 
proposed. They firstly construct the link 
structure preserving within-class scatter 
matrix with direct link matrix and indirect 
link matrix. Then they incorporate web 
link structure into SVM classifier to 
reformulate an optimization problem. 
 
 
Renuka, K.D. , 
Visalakshi, P 
 
 
2014 
 
A method name Latent Semantic Indexing 
(LSI) for feature extraction is proposed. 
The Ling spam email corpus datasets was 
used for the experimentation. The accuracy 
of SVM (TF-IDF) was 85% while the 
accuracy of SVM (LSI) was 93%. 
 
 
V. CONCLUSIONS AND FURTHER WORK 
When spam email come to internet, they become a 
problem for Internet users to present a conservative 
estimate of 70 to 75 percent of email-related products. 
The most dynamic and best methods of machine learning 
techniques in spam filtering, is a high-speed filtering with 
high accuracy. In this paper we review and examine 
support vector machine to detect and classifier spam as 
standard and improved with combined with other 
classification algorithms, dimension reduction and 
improved with different kernel functions. SVM algorithm 
is suitable for pattern recognition, classification, or 
anywhere that needs to be classified in a special class, can 
be used. In some studies, its performance relative to other 
categories more thrust, because the data in the data 
training phase of support vectors are selected .In the 
computational complexity of high-dimensional data 
collection, the performance decrease, so it can be 
classified by algorithms reduce the size and selection of 
features to be combined or select good value for it's 
parameters like C and γ that some of them are mentioned 
in this article. 
 
REFERENCES 
 
[1] Amayri, O., On email spam filtering using support vector machine. 
2009, Concordia University. 
[2] kaspersky. 2014; Available from: 
http://www.kaspersky.com/about/news/spam/. 
[3] Cook, D., et al. Catching spam before it arrives: domain specific 
dynamic blacklists. in Proceedings of the 2006 Australasian 
workshops on Grid computing and e-research-Volume 54. 
2006. Australian Computer Society, Inc. 
[4] Zitar, R.A. and A. Hamdan, Genetic optimized artificial immune 
system in spam detection: a review and a model. Artificial 
Intelligence Review, 2013. 40(3): p. 305-377. 
[5] Subramaniam, T., H.A. Jalab, and A.Y. Taqa, Overview of textual 
anti-spam filtering techniques. International Journal of 
Physical Sciences, 2010. 5(12): p. 1869-1882. 
[6] Nakulas, A., et al. A review of techniques to counter spam and spit. 
in Proceedings of the European Computing Conference. 
2009. Springer. 
[7] Seitzer, L., Shutting Down The Highway To Internet Hell. 2005. 
[8] Du, P. and A. Nakao. DDoS defense deployment with network 
egress and ingress filtering. in Communications (ICC), 2010 
IEEE International Conference on. 2010. IEEE. 
[9] Sheehan, K.B., E‐mail survey response rates: A review. Journal 
of Computer‐Mediated Communication, 2001. 6(2): p. 0-0. 
[10] Rounthwaite, R.L., et al., Feedback loop for spam prevention. 
2007, Google Patents. 
[11] Sandford, P., J. Sandford, and D. Parish. Analysis of smtp 
connection characteristics for detecting spam relays. in 
25 http://sites.google.com/site/ijcsis/ 
ISSN 1947-5500 
(IJCSIS) International Journal of Computer Science and Information Security,  
Vol. 13, No. 1, January 2015 
Computing in the Global Information Technology, 2006. 
ICCGI'06. International Multi-Conference on. 2006. IEEE. 
[12] Allman, E., et al., DomainKeys identified mail (DKIM) signatures. 
2007, RFC 4871, May. 
[13] Delany, M., Domain-based email authentication using public keys 
advertised in the DNS (DomainKeys). 2007. 
[14] Leiba, B. and J. Fenton. DomainKeys Identified Mail (DKIM): 
Using Digital Signatures for Domain Verification. in CEAS. 
2007. 
[15] Iwanaga, M., T. Tabata, and K. Sakurai, Evaluation of anti-spam 
method combining bayesian filtering and strong challenge 
and response. Proceedings of CNIS, 2003. 3. 
[16] Dwyer, P. and Z. Duan. MDMap: Assisting Users in Identifying 
Phishing Emails. in Proceedings of 7th Annual 
Collaboration, Electronic Messaging, Anti-Abuse and Spam 
Conference (CEAS). 2010. 
[17] Heron, S., Technologies for spam detection. Network Security, 
2009. 2009(1): p. 11-15. 
[18] González-Talaván, G., A simple, configurable SMTP anti-spam 
filter: Greylists. Computers & Security, 2006. 25(3): p. 229-
236. 
[19] Spitzner, L., Honeypots: tracking hackers. Vol. 1. 2003: Addison-
Wesley Reading. 
[20] Dagon, D., et al. Honeystat: Local worm detection using 
honeypots. in Recent Advances in Intrusion Detection. 2004. 
Springer. 
[21] Ihalagedara, D. and U. Ratnayake, Recent Developments in 
Bayesian Approach in Filtering Junk E-mail. SRI LANKA 
ASSOCIATION FOR ARTIFICIAL INTELLIGENCE, 
2006. 
[22] Goodman, J., G.V. Cormack, and D. Heckerman, Spam and the 
ongoing battle for the inbox. Communications of the ACM, 
2007. 50(2): p. 24-33. 
[23] Goodman, J.T. and R. Rounthwaite. Stopping outgoing spam. in 
Proceedings of the 5th ACM conference on Electronic 
commerce. 2004. ACM. 
[24] Hunter, T., P. Terry, and A. Judge. Distributed Tarpitting: 
Impeding Spam Across Multiple Servers. in LISA. 2003. 
[25] Agrawal, B., N. Kumar, and M. Molle. Controlling spam emails at 
the routers. in Communications, 2005. ICC 2005. 2005 IEEE 
International Conference on. 2005. IEEE. 
[26] Zdziarski, J.A., Ending spam: Bayesian content filtering and the 
art of statistical language classification. 2005: No Starch 
Press. 
[27] Khorsi, A., An overview of content-based spam filtering 
techniques. Informatica (Slovenia), 2007. 31(3): p. 269-277. 
[28] Obied, A., Bayesian Spam Filtering. Department of Computer 
Science University of Calgary amaobied@ ucalgary. ca, 
2007. 
[29] Androutsopoulos, I., et al., Learning to filter spam e-mail: A 
comparison of a naive bayesian and a memory-based 
approach. arXiv preprint cs/0009009, 2000. 
[30] Seewald, A.K., An evaluation of naive Bayes variants in content-
based learning for spam filtering. Intelligent Data Analysis, 
2007. 11(5): p. 497-524. 
[31] Sebastiani, F., Machine learning in automated text categorization. 
ACM computing surveys (CSUR), 2002. 34(1): p. 1-47. 
[32] Guzella, T.S. and W.M. Caminhas, A review of machine learning 
approaches to spam filtering. Expert Systems with 
Applications, 2009. 36(7): p. 10206-10222. 
[33] Zdziarski, J., Tokenization: The building blocks of spam. Ending 
Spam: Bayesian Content Filtering and the Art of Statistical 
Language Classification, 2005. 
[34] Porter, M.F., An algorithm for suffix stripping. Program: electronic 
library and information systems, 1980. 14(3): p. 130-137. 
[35] Ahmed, S. and F. Mithun. Word Stemming to Enhance Spam 
Filtering. in CEAS. 2004. Citeseer. 
[36] Silva, C. and B. Ribeiro. The importance of stop word removal on 
recall values in text categorization. in Neural Networks, 
2003. Proceedings of the International Joint Conference on. 
2003. IEEE. 
[37] Kent, J.T., Information gain and a general measure of correlation. 
Biometrika, 1983. 70(1): p. 163-173. 
[38] Tokunaga, T. and I. Makoto. Text categorization based on 
weighted inverse document frequency. in Special Interest 
Groups and Information Process Society of Japan (SIG-IPSJ. 
1994. Citeseer. 
[39] Yang, Y. and J.O. Pedersen. A comparative study on feature 
selection in text categorization. in ICML. 1997. 
[40] Yerazunis, W.S., et al. A unified model of spam filtration. in 
Proceedings of the MIT Spam Conference, Cambridge, MA, 
USA. 2005. 
[41] Ramos, J. Using tf-idf to determine word relevance in document 
queries. in Proceedings of the First Instructional Conference 
on Machine Learning. 2003. 
[42] Church, K. and W. Gale, Inverse document frequency (idf): A 
measure of deviations from poisson, in Natural language 
processing using very large corpora. 1999, Springer. p. 283-
295. 
[43] Carreras, X. and L. Marquez, Boosting trees for anti-spam email 
filtering. arXiv preprint cs/0109015, 2001. 
[44] Drucker, H., S. Wu, and V.N. Vapnik, Support vector machines for 
spam categorization. Neural Networks, IEEE Transactions 
on, 1999. 10(5): p. 1048-1054. 
[45] Blanzieri, E. and A. Bryl. Instance-Based Spam Filtering Using 
SVM Nearest Neighbor Classifier. in FLAIRS Conference. 
2007. 
[46] Rocchio, J.J., Relevance feedback in information retrieval. 1971. 
[47] Androutsopoulos, I., et al., An evaluation of naive bayesian anti-
spam filtering. arXiv preprint cs/0006013, 2000. 
[48] Androutsopoulos, I., et al. An experimental comparison of naive 
Bayesian and keyword-based anti-spam filtering with 
personal e-mail messages. in Proceedings of the 23rd annual 
international ACM SIGIR conference on Research and 
development in information retrieval. 2000. ACM. 
26 http://sites.google.com/site/ijcsis/ 
ISSN 1947-5500 
(IJCSIS) International Journal of Computer Science and Information Security,  
Vol. 13, No. 1, January 2015 
[49] Metsis, V., I. Androutsopoulos, and G. Paliouras. Spam filtering 
with naive bayes-which naive bayes? in CEAS. 2006. 
[50] Cohen, W.W. Learning rules that classify e-mail. in AAAI Spring 
Symposium on Machine Learning in Information Access. 
1996. California. 
[51] Schölkopf, B. and A.J. Smola, Learning with kernels: support 
vector machines, regularization, optimization, and beyond. 
2002: MIT press. 
[52] Schölkopf, B. and A.J. Smola, Learning with kernels: support 
vector machines, regularization, optimization, and beyond 
(adaptive computation and machine learning). 2001. 
[53] Yu, B. and Z.-b. Xu, A comparative study for content-based 
dynamic spam classification using four machine learning 
algorithms. Knowledge-Based Systems, 2008. 21(4): p. 355-
362. 
[54] FENG, Y. and H. ZHOU, An Effective and Efficient Two-stage 
Dimensionality Reduction Algorithm for Content-based Spam 
Filtering⋆. Journal of Computational Information Systems, 
2013. 9(4): p. 1407-1420. 
[55] Chapelle, O., P. Haffner, and V.N. Vapnik, Support vector 
machines for histogram-based image classification. Neural 
Networks, IEEE Transactions on, 1999. 10(5): p. 1055-1064. 
[56] Fawcett, T., ROC graphs: Notes and practical considerations for 
researchers. Machine learning, 2004. 31: p. 1-38. 
[57] Vapnik, V.N. and V. Vapnik, Statistical learning theory. Vol. 2. 
1998: Wiley New York. 
[58] Andrews, S., I. Tsochantaridis, and T. Hofmann. Support vector 
machines for multiple-instance learning. in Advances in 
neural information processing systems. 2002. 
[59] Woitaszek, M., M. Shaaban, and R. Czernikowski. Identifying junk 
electronic mail in Microsoft outlook with a support vector 
machine. in 2012 IEEE/IPSJ 12th International Symposium 
on Applications and the Internet. 2003. IEEE Computer 
Society. 
[60] Matsumoto, R., D. Zhang, and M. Lu. Some empirical results on 
two spam detection methods. in Information Reuse and 
Integration, 2004. IRI 2004. Proceedings of the 2004 IEEE 
International Conference on. 2004. IEEE. 
[61] Bickel, S. and T. Scheffer, Dirichlet-enhanced spam filtering 
based on biased samples. Advances in neural information 
processing systems, 2007. 19: p. 161. 
[62] Kanaris, I., et al., Words versus character n-grams for anti-spam 
filtering. International Journal on Artificial Intelligence 
Tools, 2007. 16(06): p. 1047-1067. 
[63] Ye, M., Q.-X. Jiang, and F.-J. Mai. The Spam Filtering Technology 
Based on SVM and DS Theory. in Knowledge Discovery and 
Data Mining, 2008. WKDD 2008. First International 
Workshop on. 2008. IEEE. 
[64] Chhabra, P., R. Wadhvani, and S. Shukla, Spam filtering using 
support vector machine. Special Issue IJCCT, 2010. 1(2): p. 
3. 
[65] Shahi, T.B. and A. Yadav, Mobile SMS Spam Filtering for Nepali 
Text Using Naïve Bayesian and Support Vector Machine. 
International Journal of Intelligence Science, 2013. 4: p. 24. 
[66] Tan, Y. and G. Ruan, Uninterrupted approaches for spam 
detection based on SVM and AIS. International Journal of 
Computational Intelligence, 2014. 1(1): p. 1-26. 
[67] Auria, L. and R.A. Moro, Support vector machines (SVM) as a 
technique for solvency analysis. 2008, Discussion 
papers//German Institute for Economic Research. 
[68] Kim, K.I., et al., Support vector machines for texture classification. 
Pattern Analysis and Machine Intelligence, IEEE 
Transactions on, 2002. 24(11): p. 1542-1550. 
[69] Wei, L., et al., A study on several machine-learning methods for 
classification of malignant and benign clustered 
microcalcifications. Medical Imaging, IEEE Transactions on, 
2005. 24(3): p. 371-380. 
[70] Song, Q., W. Hu, and W. Xie, Robust support vector machine with 
bullet hole image classification. Systems, Man, and 
Cybernetics, Part C: Applications and Reviews, IEEE 
Transactions on, 2002. 32(4): p. 440-448. 
[71] Kim, K.I., K. Jung, and J.H. Kim, Texture-based approach for text 
detection in images using support vector machines and 
continuously adaptive mean shift algorithm. Pattern Analysis 
and Machine Intelligence, IEEE Transactions on, 2003. 
25(12): p. 1631-1639. 
[72] Youn, S. and D. McLeod, A comparative study for email 
classification, in Advances and Innovations in Systems, 
Computing Sciences and Software Engineering. 2007, 
Springer. p. 387-391. 
[73] Wang, H.-b., Y. Yu, and Z. Liu, SVM classifier incorporating 
feature selection using GA for spam detection, in Embedded 
and Ubiquitous Computing–EUC 2005. 2005, Springer. p. 
1147-1154. 
[74] Medlock, B. An Adaptive, Semi-Structured Language Model 
Approach to Spam Filtering on a New Corpus. in CEAS. 
2006. 
[75] Sculley, D. and G.M. Wachman. Relaxed online SVMs for spam 
filtering. in Proceedings of the 30th annual international 
ACM SIGIR conference on Research and development in 
information retrieval. 2007. ACM. 
[76] Blanco, Á., A.M. Ricket, and M. Martín-Merino, Combining SVM 
classifiers for email anti-spam filtering, in Computational 
and Ambient Intelligence. 2007, Springer. p. 903-910. 
[77] Blanzieri, E. and A. Bryl, E-Mail Spam Filtering with Local SVM 
Classifiers. 2008. 
[78] Sun, X., Q. Zhang, and Z. Wang. Using LPP and LS-SVM for 
spam filtering. in Computing, Communication, Control, and 
Management, 2009. CCCM 2009. ISECS International 
Colloquium on. 2009. IEEE. 
[79] Tseng, C.-Y. and M.-S. Chen. Incremental SVM model for spam 
detection on dynamic email social networks. in 
Computational Science and Engineering, 2009. CSE'09. 
International Conference on. 2009. IEEE. 
[80] Ren, Q. Feature-fusion framework for spam filtering based on svm. 
in Proceedings of the 7th Annual Collaboration, Electronic 
messaging, Anti-Abuse and Spam Conference. 2010. 
27 http://sites.google.com/site/ijcsis/ 
ISSN 1947-5500 
(IJCSIS) International Journal of Computer Science and Information Security,  
Vol. 13, No. 1, January 2015 
[81] Rakse, S.K. and S. Shukla, Spam classification using new kernel 
function in support vector machine. 2010. 
[82] Yuguo, L., Z. Zhenfang, and Z. Jing, A word sequence kernels 
used in spam-filtering”. Scientific Research and Essays, 
2011. 6(6): p. 1275-1280. 
[83] Chitra, S., et al., Predicate based Algorithm for Malicious Web 
Page Detection using Genetic Fuzzy Systems and Support 
Vector Machine. International Journal of Computer 
Applications, 2012. 40(10): p. 13-19. 
[84] Hsu, W.-C. and T.-Y. Yu, Support vector machines parameter 
selection based on combined Taguchi method and Staelin 
method for e-mail spam filtering. International Journal of 
Engineering and Technology Innovation, 2012. 2(2): p. 113-
125. 
[85] Maldonado, S. and G. L‟Huillier, SVM-Based Feature Selection 
and Classification for Email Filtering, in Pattern 
Recognition-Applications and Methods. 2013, Springer. p. 
135-148. 
[86] Yang, X.L., Y.D. Su, and J.P. Mo, LSSVM-based social spam 
detection model. Advanced Materials Research, 2013. 765: p. 
1281-1286. 
[87] Hong-liang  ZHOU and C.-y. LUO, Combining SVM  with  
Orthogonal  Centroid  Feature  Selection  for Spam Filtering, 
in International Conference on Computer, Network. 2014. p. 
759. 
[88] GAO, S., et al., Improving SVM Classifiers with Link Structure for 
Web Spam Detection⋆. Journal of Computational Information 
Systems, 2014. 10(6): p. 2435-2443. 
[89] Renuka, K.D. and P. Visalakshi, Latent Semantic Indexing Based 
SVM Model for Email Spam Classification. Journal of 
Scientific & Industrial Research, 2014. 73(7): p. 437-442. 
 
 
 
 
 
 
 
 
28 http://sites.google.com/site/ijcsis/ 
ISSN 1947-5500 
