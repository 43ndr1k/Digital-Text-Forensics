Efficient search with tree-edit distance for
melody recognition∗
David Rizo, Francisco Moreno-Seco, José M. Iñesta,
and Luisa Micó
Dept. Lenguajes y Sistemas Informáticos
Universidad de Alicante, E-03071 Alicante, Spain
{drizo,paco,inesta,mico}@dlsi.ua.es
Abstract
The search of a given melody in large data-bases is one of the problems in the
modern topic of music information retrieval (MIR). A huge amount of music files
in symbolic formats can be found today in the Internet, and this has motivated
new challenges for identification and categorization of music data. A number of
pattern recognition techniques can be used to solve this problem. In this paper
we explore the capabilities of trees to provide an expressive representation of
music information. Trees are compared to string representations in terms of
dissimilarity measures, using edit distances. The high computational cost of tree
edit distances needs of complexity reduction techniques to be applied. Partial
tree edit distances will be considered in order to solve this problem. Also, a new
approximate nearest neighbour search for non-vector representation of patterns
(such as trees) is applied to speed up the classification. The combination of
both techniques produces a significant reduction in classification error rates of
string representations while keeping similar classification times.
Keywords: Nearest neighbour, computer music, structural recognition, tree edit
distance, complexity reduction
1 Introduction
1.1 Context and previous works
The search of a particular melody in large data-bases is a great challenge that needs
of accurate and efficient recognition algorithms. In the past few years, the amount
of music files available, such as MP3, MIDI, XML representations, ringtones, etc.
has grown very quickly. Even different variations of the same original theme can
∗This work was supported by the projects Spanish CICYT TIC2003–08496–C04, partially sup-
ported by EU ERDF, and Generalitat Valenciana GV043-541.
218 Pattern Recognition : Progress, Directions and Applications
Edited by F.Pla, P.Radeva, J.Vitrià, 2006.
be found, so another difficult problem is the recognition of different interpretations
of the same melody. Also, music identification from inaccurate or distorted queries
is needed. The approaches to solve those problems are part of the modern topic
of music information retrieval (MIR) and have lots of applications like organization
and indexing digital libraries or copyright management, to name just two of them.
Some recent papers explore the capabilities of pattern recognition algorithms
to recognize music data. These data can be classified into two main categories:
digitized sounds and symbolic sequences. With regard to digital sounds, a number of
works explore the capabilities of pattern recognition algorithms for finding different
categories in music. A few of them are cited next, covering a representative range
of applications.
In a recent work [1], the authors evaluate the ability of different sets of audio
features, like low-level signal properties, mel-frequency spectral coefficients, and lin-
ear prediction coefficients, for classifying digital sound segments into a set of sound
classes, like sung music, instrumental music, speech, noise, etc. The classification
is performed through a Bayesian approach. In [2] a system based on neural net-
works and support vector machines is presented for classifying audio fragments into
a given list of sources or artists. Also in [3] a neural system to recognize music types
from sound inputs is described. Other audio classifications are based on clustering
analysis. In [4], the authors use self-organizing maps (SOM) to pose the problem of
organizing music digital libraries according to sound features of musical themes, in
such a way that similar themes are clustered, performing a content-based classifica-
tion of the sounds.
On the other hand, symbolic sequences refer to digital scores available in a num-
ber of public formats, like MIDI [5] or MusicXML [6]. Different pattern recognition
techniques have been applied to process and classify these sequences. In [7], the
authors show the ability of grammatical inference methods for modelling musical
style. Stochastic finite automata for a number of musical styles are inferred from
the training set, and then they are utilized to parse and classify new melodies into
the selected styles. In [8], the authors compare the performance of different pattern
recognition paradigms to recognize music style using descriptive statistics of pitches,
intervals, durations, rests, etc. Other approaches like hidden Markov models [9] or
classifier ensembles [10] have been used to recognize melodies, styles, authors or
performers from symbolic data.
The work presented in this paper uses symbolic data as input and deals with the
recognition of melodies with different degrees of distortion. Preliminary results of
the proposed technique have been published in former works [11, 12].
Pattern Recognition : Progress, Directions and Applications 219
1.2 Objectives of this paper
Some papers [13, 14] have discussed the sensitivity of the recognition algorithm
performance to the encoding scheme used to represent the melodic sequences. The
authors point out the need of designing an appropriate representation framework,
because otherwise the algorithms can fail in their classification task. In [13], the
authors present a number of string representations of melodies in terms of symbols
coding the sequence of notes. The results for the different codings are compared,
showing that the way in which the melody is coded strongly conditions the outcome
of the string classification algorithms.
One possible alternative to music string representation are trees [15, 11, 16]. This
data structure has the advantage of being able to represent music note duration
implicitly, so there is no need of designing an alphabet of symbols to represent
durations and time proportions. This way, tree representation of music will be less
sensitive to coding. On the other hand, tree construction, processing, and analysis
are more expensive than for strings.
There is a need of studying whether trees are useful for posing this sort of
problems, and what has to be taken into account to do it. In this paper, a method
for representing melodies as trees is presented. Also, a set of rules are introduced
to label the tree nodes and reduce the initial size of the tree in order to deal with
complexity.
Once the melodic sequences are tree-coded, an efficient classification algorithm
is needed. The trees are compared in terms of dissimilarity measures, using tree edit
distances, that are provided to a nearest neighbour (NN) search algorithm. The
high computational cost of tree edit distances [17] needs of complexity reduction
techniques to be applied. Two cooperative techniques are combined in order to
reduce computational load, keeping the accuracy in a high standard. The first uses
a tree edit distance that is cheaper than the full edit distance, and the second is
based on using a new approximate NN search instead of exact NN search to reduce
the number of distance computations, and thus to reduce classification times. This
new approximate NN search is the extension of previous works on approximate NN
search for prototypes codified as vectors to non-vector representations of prototypes.
Classification error increases with approximate search, but avoids the computation of
a large amount of expensive tree edit distances. The combination of both techniques
reduces the cost, reaching times even better to those of string-coded representations.
Firstly, the method for tree construction will be presented and how it deals with
the notation problems that may appear. Secondly, a set of rules for tree simplifica-
tion is described. Thirdly, the methods for tree comparison and efficient neighbour
search are explained. Finally, the results are presented and some conclusions are
220 Pattern Recognition : Progress, Directions and Applications
stated.
2 Representations for music sequences
A melody has two main dimensions: rhythm and pitch. Basically, the first is de-
termined by note onset times and durations, and the second by the fundamental
frequencies of the notes. The main methods for melody search are based on differ-
ent string codings of those dimensions [7, 14], focusing mainly on pitch. Nevertheless,
rhythm is an important component of music. One can find melodies having the same
sequence of note pitches but sounding completely different due to the differences in
their durations.
In string representations, note durations are coded with explicit symbols, but
trees are able to implicitly represent this dimension, making use of the logarithmic
nature of time in music, in the sense that note durations are multiples of basic time
units, mainly in a binary (sometimes ternary) structure. This way, trees are less
sensitive to the codes used to represent melodies, since there are less degrees of
freedom for coding.
In this section the proposed tree construction method for representing a melody is
presented, defining the terms needed to build the model. First, string representations
are described as a reference. For all the discussions, the melodies are assumed to be
monophonic: only one note can be played at a given time.
2.1 Pitch and duration representations
In string representations, note durations are coded with explicit symbols. For rep-
resenting a melody as a string, symbols from a pitch description alphabet, Σp, and
from that of duration, Σd are combined in s ∈ Σ
∗, s = σ1σ2...σ|s|. When these
symbols are linked to those of pitch, the code is said to be coupled. In this case,
Σ = Σp × Σd, and σi will be a pair of pitch and duration descriptors. The pair for
a note can only be formed when both dimensions are defined for it.
When both dimensions are handled independently, the representation is said to
be decoupled or splitted. For decoupled string representations, Σ = Σp
⋃
Σd, being
σ2i−1 ∈ Σp and σ2i ∈ Σd; i = 1, 2, ...,
|s|
2 . Similarly as before, the symbols for a note
are included in the string only if both dimensions are defined for it.
Different kind of properties can be used for the symbols to represent the sequence
of pitches in a melody [13, 14, 18]. They can be absolute, if the property depends
only on the represented note, or relative, if it is defined in terms of differences to
other notes, usually the preceding one. Next, some commonly used pitch properties
Pattern Recognition : Progress, Directions and Applications 221
are presented. In each case, the alphabet, Σp, applicable is enunciated. The symbol
‘s’ (for ‘silence’) denotes a rest.
Definition 2.1 Pitch properties for each note:
p1 pitch name (absolute) the name and octave. If notes are extracted from
MIDI files, the alphabet is Σp1 = {C−2,C−2, ...,F8,G8}
⋃
{‘s’}, |Σp1| =
129, although in practice is usually more reduced. The range for piano is
{A−1, ...,C7}, which is enough for most cases. Using this range, |Σp1| = 89.
p2 folded pitch (absolute) the name without octave. |Σp2| = 13, corresponding
to the 12 halftones of the octave, from A to G, including flat and sharp notes,
and the rest.
p3 pitch contour (relative) Σp3 = {−,=,+}; ‘+’ if the pitch of the note is higher
than that of the previous note, ‘−’ if it is lower, and ‘=’ if it is the same. As
for the other relative pitch properties, for the first note in the sequence it is
not defined. |Σp3| = 3.
p4 high-definition contour (relative) same as before but it also includes ‘+2’
and ‘−2’ if the pitch difference exceeds 4 halftones. Σp4 = {−2,−1, 0, +1,+2}.
|Σp4| = 5.
p5 intervals (relative) the difference in halftones between a note and the preced-
ing one. Theoretically, Σp5 = {i ∈ Z |−127 ≤ i ≤ +127}, but in practice large
intervals seldom appear, and some authors limit Σp5 = {i ∈ Z | − 24 ≤ i ≤
+24}, being any other larger value assigned to the extremal values. This way,
|Σp5| = 49.
Rests are not involved in the calculation of relative properties for the note fol-
lowing it, that are computed using the pitch of the note preceding the rest.
Similar definitions can be stated for the durations of the note sequence, defining
a number of duration properties.
Definition 2.2 Duration properties for each note:
d1 duration (absolute) the difference between its onset and offset times, tOFF −
tON , usually expressed as multiples or fractions of the beat duration. Strictly
speaking, this is not a numerable set, but in practice a limited set of durations
appear.
222 Pattern Recognition : Progress, Directions and Applications
d2 rhythm contour (relative) Σd2 = {−,=,+}; ‘+’ if the duration of the note
is longer than that of the previous note, ‘−’ if it is shorter, and ‘=’ if it is the
same. For the first note in the sequence it is not defined. |Σd2| = 3.
d3 inter-onset interval, IOI (absolute) the time lapse from the ith note onset
to that of the next; IOIi = tON,i − tON,i+1, expressed as for d1. For the
last note, d3 is defined as its duration (d1). The same described about |Σd1|
is applicable for this case and the next. Note that rests disappear for this
property.
d4 inter-onset ratio, IOR (relative) the ratio between successive IOIs; IORi =
IOIi
IOIi+1
. It is not defined for the last note and for rests.
Rest durations are treated the same way as notes for the properties d1 and d2,
but are ignored for the other two.
For the illustration of these properties, a simple melody has been displayed in
figure 1 and coded in terms of these pitch and duration properties.
4
4
 
   
  
    
B3 D3 A3 C4 E3 s E3
PITCHES DURATIONS
p1: B3 , D3 , A3 , C4 , E3 , s , E3 d1:
1
2
, 1
4
, 1
4
, 1, 1
2
, 1
2
, 1
p2: B , D , A , C , E , s , E d2: -, –, =, +, –, =, +
p3: - , – , + , + , – , - , = d3: 1
2
, 1
4
, 1
4
, 1, 1, -, 1
p4: - , −2 , +2 , +1 , −2 , - , 0 d4: 2, 1, 1
4
, 1, 1, -, -
p5: - , −9 , +7 , +3 , −8 , - , 0
Figure 1: Simple example of melody and how it is represented in terms of different
pitch and duration descriptors. A short dash has been written when the code for a
note is not defined.
Using the above defined descriptions, there are 5 × 4 × 2 = 40 different ways of
coding melodies as strings, being 5 the number of pitch codings, 4 the number of
duration codings, and 2 corresponding to the coupled and decoupled way of com-
bining both dimensions. Nevertheless, the ways of coding a melody as a tree using
the proposed method are just 5, the number of different pitch descriptions defined
above, since duration is implicit in the tree structure. In Fig. 2 some of these rep-
resentations are displayed as an example. Note that the pair of symbols coding a
note are only included when both are defined for it. For example, for the first note,
interval (p5) and duration contour (d2) are not defined, or inter-onset properties (d3
and d4) are not defined for rests.
Pattern Recognition : Progress, Directions and Applications 223
p1 and d1, decoupled: B3 ,
1
2
, D3 ,
1
4
, A3 ,
1
4
, C4 , 1 , E3 ,
1
2
, s , 1
2
, E3 , 1
p1 and d1, coupled: (B3,
1
2
) , (D3,
1
4
) , (A3,
1
4
) , (C4,1) , (E3,
1
2
) , (s, 1
2
) , (E3,1)
p2 and d2, coupled: - , (D,–) , (A,=) , (C,+) , (E,–) , (s,=) , (E,+)
p5 and d3, decoupled: - , - , −9 , 1
4
, +7 , 1
4
, +3 , 1 , −8 , 1 , 0 , 1
Figure 2: Some string representations using different combinations of properties for
the melody in Fig. 1. A short dash has been written when the code for a note is not
defined.
2.2 Tree construction method
The tree representation approach proposed in this work is based on the fact that
the duration of the music notation symbols are designed on a logarithmic scale: a
whole note lasts twice a half note, whose length is the double of a quarter note, etc.
(see Fig. 3).  


































































Figure 3: Duration hierarchy for different note figures. From top to bottom: whole
(4 beats), half (2 beats), quarter (1 beat), and eighth (1/2 beat) notes.
Each melody measure is initially represented by a tree, τi. Each note or rest will
be a leaf node. The left to right ordering of the leaves keeps the same time order of
the notes in the melody. The level of each leaf in the tree determines the duration
of the note it represents, as displayed in figure 3: the root (level 1) represents the
duration of the whole measure (a whole note), each of the two nodes at level 2
represents the duration of a half note. In general, nodes at level i represent the
duration of a 1/2i−1 of a measure.
During the tree construction, internal nodes are created when needed to reach the
appropriate leaf level. Initially, only the leaf nodes will contain a label value, using
the pitch properties described in definition 2.1, but then, a bottom-up propagation of
these labels is performed to fully label the tree nodes. The rules for this propagation
will be described later, in section 2.5.
224 Pattern Recognition : Progress, Directions and Applications
An example of this scheme is presented in Fig. 4 using folded pitches as labels.
In the resulting tree, the left child of the root has been splitted into two subtrees
to reach the level 3, that corresponds to the first note (a quarter note, duration of
a 1/22 of the measure, pitch B). In order to represent the durations (both are 1/8
of the measure) of the rest and note G, a new subtree is needed for the right child
in level 3, providing two new leaves for representing the rest (s) and the note (G).
The half note (C) onsets at the third beat of the measure, and it is represented in
level 2, according to its duration.
It can be seen in figure 4 how the order in time of the notes in the score is
preserved when traversing the tree from left to right. Note how onset times and
durations are implicitly represented in tree, compared to the explicit encoding of
time needed by strings. Using the definitions 2.1, only five tree representations are
possible, compared to the 40 for strings. In addition, this representation is invariant
against changes in tempo, or different meter representations of the same melody
(2/2, 4/4, or 8/8, for example).
4
4      
B s G C












B




s G
C
Figure 4: Simple example of tree construction with folded pitches (def. p2).
2.3 Processing non binary durations
In some occasions the situation can be more complicated. There are note durations
that do not match a binary division of the whole measure. This happens, for ex-
ample, for dotted notes (duration is extended in an additional 50%) or tied notes
(their durations are summed) (see Fig. 5-left). In this situation, a note can not be
represented just by one leaf in the proposed scheme. It is well known [19, 20] that
our auditory system perceives in a similar way one note of a given duration and two
notes of the same pitch, played one after the other, which durations sum that of the
single one.
Thus, when a note exceeds the proper duration, in terms of binary divisions of
time, it will be subdivided into notes of binary durations, and the resulting notes are
Pattern Recognition : Progress, Directions and Applications 225
coded in their proper tree levels. In Fig. 5 an example of these situations is shown
and how they are represented by this scheme.
4
4  
 
  
C D s E


















C




C D










s E
E
1
Figure 5: Tree representations of notes exceeding their notation duration: dotted
and tied notes. Both ‘C’ leaves correspond to the same dotted quarter note. The
two ‘E’ leaves represent the two tied notes.
Other frequently used non binary divisions are ternary rhythms. In that case,
the length of one measure is usually 3 beats and it is splitted into 3 quarter notes,
etc. This is not a problem, since neither the tree construction method nor the
metrics used to compare trees need them to be binary, and the number of children
for each node can be an arbitrary number. In ternary meters or ternary divisions, the
number of children for a node will be three. This can be generalized to other more
complicated cases that can appear in musical notations, like tuplets or compound
meters. In figure 6 an example of compound meter based on ternary divisions and
its representing tree is shown.
9
8  
      
s E C B A G F D






























s s E
C


















B A




G F
D
Figure 6: The meter 9/8 is a compound one based on ternary divisions. The tree
construction method can represent this melody without problems.
There are other subtle situations that may appear in a score, like for example
grace notes1, that are not included in the cases described above. Anyway, in the
1 A grace note is a very short note or a series or notes to achieve musical effects that occupies
no time in the duration notation in a score. They also are named “acciaccatura”.
226 Pattern Recognition : Progress, Directions and Applications
digital scores, like MIDI files, these special notes do not appear, and short notes
would be present for grace notes that will be coded in the level of the tree that
corresponds to its actual duration. The details of these situations are described in
detail elsewhere [11].
2.4 Representation of complete melodies
The method described above is able to represent a single measure as a tree, τ . A
measure is the basic unit of rhythm in music, but a melody is composed of a series
of M measures. Next, the way of combining the set of trees {τi}
M
i=1 computed for
every single measure is discussed.
Joining the set of computed measure trees in an ordered way is needed to build
the tree, T , for the complete melody. For this purpose, a method for grouping the
sub-trees is required. They can be grouped two by two, by adjacent pairs, repeating
this operation bottom-up, hierarchically, with the new nodes until a single tree is
obtained. Nevertheless, with this grouping method, the trees would grow in depth
quickly:
h(T ) = log2M + 1 + max
i
h(τi) ,
making the tree edit distance computation very time consuming, as will be discussed
in section 3.1. Another possibility is to build a tree with a root for the whole melody,
being each measure sub-tree a child of that root. This can be considered as a forest
of sub-trees, but linked to a common root node that represents the whole melody.
This way, the tree depth for the whole melody will be only
h(T ) = 1 + max
i
h(τi) .
This smaller depth of the whole melody tree, T , is a key point to choose this approach
to build T . Figure 7-left displays an example of a simple melody, composed of three
measures and how it is represented by a tree composed of three sub-trees, one per
measure, rooted to the same parent node. The level 0 will be assigned to this
common root.
2.5 Bottom-up propagation of labels and pruning
Two causes motivate the procedure described in this section. Firstly, tree edit
distance algorithms need all the nodes (both internal and leaves) to have a label [17,
21]. After the structure of the tree is completed, the pitch labels are just in the
leaves. A set of rules are used for propagating the labels from the leaves upwards,
labelling the internal nodes. The propagation of a label is decided on the basis
Pattern Recognition : Progress, Directions and Applications 227
4
4      
  

B D E F C






















B




D E
F








F










S C
C
Figure 7: An example of the tree representation of a complete melody. The root of
this tree links all the measure sub-trees.
that the note in that node is more important than that of the sibling node. The
importance of a note is related to its capability to contribute to the melody identity.
Secondly, the high complexity of the tree edit distance computing (see section 3),
requires the trees to be as small as possible. When very short notes appear or they
do not match exactly the binary or ternary subdivisions of the beat, the resulting
trees are very deep. Thus, the label propagation rules are accompanied of a pruning
action to delete little significant branches when applying the rules below a given
pruning level. This process also contributes to remove irrelevant information that
would make the classification more difficult, obtaining reduced trees able to keep
the main musical features of the melody.
Given a pruning level, p, the rules for propagating the labels to internal nodes and
pruning the tree are defined below. In each case, a rule is applied to a sub-tree, and if
the level l of the sub-tree is below the pruning level p, the labels are propagated and
the tree is pruned; otherwise, the rule only propagates labels, keeping the structure
of the tree. This pruning level is equivalent to the resolution desired for the resulting
tree in terms of note lengths. This way, in the pruning tree, the notes represented
will be always longer or equal to a 1/2p−1 fraction of the measure length. A value
p = ∞ means that pruning is never applied.
The set of propagation (and pruning when applicable) rules are described below
and illustrated in figure 8. For the definitions, a parenthesis notation is used for the
trees, in such a way that a subtree, t, having a father node with label a, and two
children: left with label b and right with label c, is denoted as t = a(bc). If a node
has not a label, we will consider it as labelled with the empty label, . All the labels,
except , are symbols in one of the Σp alphabets. The value ‘s’ is explicitly used for
228 Pattern Recognition : Progress, Directions and Applications
rests.
All the definitions have been stated for binary sub-trees but they can be extended
for ternary trees, keeping the meaning of each situation. The number of possible
cases for each rule is much greater, so they have not been included here for clarity.
All these rules are illustrated in figure 8.
Definition 2.3 Propagation and training rules:
r1 The r1 rule simply propagates/prunes a unary tree:
r1
[
(a)
]
=
{
a if l ≥ p
a(a) otherwise
If there is only one child it is automatically upgraded. This situation seldom
appears but it can be found in the rightmost note of an incomplete measure
or building the tree from a single measure.
r2 The r2 rule makes the pitch propagate over a rest:
r2
[
(sa)
]
=
{
a if l ≥ p
a(sa) otherwise
r2
[
(as)
]
=
{
a if l ≥ p
a(as) otherwise
r3 The r3 rule is also very simple, and joins equal pitches:
r3
[
(aa)
]
=
{
a if l ≥ p
a(aa) otherwise
If all the children of a node have the same label, they are deleted and its label
is placed in the father node. Thus, two equal notes are equivalent to just one
with double duration.
r4 If one of the children nodes has the same label as that of the father’s sibling
node, then the other label is propagated. This rule tries to avoid the propa-
gation of a pitch that would be lost by the application of r3 in the next step.
This is formalized here for all possible cases:
r4
[
((ba)b)
]
=
{
(ab) if l ≥ p
(a(ba)b) otherwise
r4
[
((ab)b)
]
=
{
(ab) if l ≥ p
(a(ab)b) otherwise
Pattern Recognition : Progress, Directions and Applications 229
r4
[
(b(ba))
]
=
{
(ba) if l ≥ p
(ba(ba)) otherwise
r4
[
(b(ab))
]
=
{
(ba) if l ≥ p
(ba(ab)) otherwise
r5 The r5 rule limits the applicability of the former rules, that otherwise could
propagate a very short pitch to a much longer note, eliminating other longer
pitches. In order to avoid that, any rule (denoted as r in the rule below) can
be applied only three times for the same label (this implies to stretch its length
in a factor of 23 for binary meters).
r5
[
(ab)
]
=
{
b if l ≥ p
b(ab) otherwise
r5
[
(ba)
]
=
{
b if l ≥ p
b(ba) otherwise
iff
a is the root of t = r
[
r
[
r
[
. . .
]]]
and
a comes from a node 3 levels below.
r6 The r6 rule is a “default” case, whenever any other rule may be applied:
r6
[
(ab)
]
= a(ab)
This rule upgrades the label of the left child, because in binary meters, the
notes placed in odd beats are usually stressed. These notes are represented by
left children in the tree.
All these rules are applied under certain conditions and precedence order that
are described in the algorithm 1:
An example of the application of these rules is displayed in figure 9 with a level
p = 2. One measure with some notes with different durations is considered. In the
left side of that figure, the score and the tree as it results from the construction pro-
cedure is presented. The labels in that tree are folded pitches (p2) in definition 2.1).
In Fig. 9-left it can be observed how the propagation and pruning rules apply
to the tree. A value of the pruning level p = 2 has been considered. This way,
the rules applied below that level in the tree (l ≥ p) are pruning rules, otherwise
230 Pattern Recognition : Progress, Directions and Applications
a a
a a
a a a a
a a
r1:
r3:
a s a
a a
r2:
s
a
a
r4:
b
b b
ab
a b
r5:
r6:
a b a b
a a
ba
r(r(r( ... )))
ba
b b
as a
a a
s
a
a
b
b b
ab
ab
a
a
b
b b
a b
a b
a
a
b
b b
a b
ab
b a b a
b b
r(r(r( ... )))
r(r(r( ... ))) r(r(r( ... )))
Figure 8: Propagation and pruning rules. (left column): original sub-tree; (center
column) propagation rules; (right column): pruning rules.
Pattern Recognition : Progress, Directions and Applications 231
Algorithm 1 Application of rules
if arity(t) = 1 then
r1
else if left-child(t) = ‘s’ or right-child(t) = ‘s’ then
r2
else if left-child(t) = right-child(t) then
r3
else if root(t) comes from a leaf 3 levels below then
r5
else if t = ((ba)b) or t = ((ab)b) or t = (b(ba)) or t = (b(ab)) then
r4
else
r6
end if
s F F A G
s
F F
G
G
G
A G
s
F F
A G
G
G
F
F
A
A
G
F
r4
r4
r5
r3
r2
r6
r3
A G
r4
p=2
s F A G
Figure 9: (left) One measure-melody and its tree representation with interval labels
(only in the leaves now) before pruning and label propagation. (right) Final tree
with propagated and pruned nodes (in dashed lines after applying dashed rules).
The equivalent melody to the pruned tree is also displayed (right-bottom).
232 Pattern Recognition : Progress, Directions and Applications
are just propagation rules. In the first half of the melody, the deepest levels have
equal labels (F), so they are upgraded by the rule r3 and then by r2 because the
sibling node is labelled with a rest. The second part shows how a very short note
(A) is propagated by applying r4 three times. Thus, r5 is applied instead of r6 that
otherwise would have been applied, propagating ‘A’ again.
Note that in the score equivalent to that tree (Fig. 9-left-bottom) only quarter
notes (in this context, their duration can be stated as a 1/2p−1 of the measure)
have survived to the propagation and pruning rules, keeping the main features of
the original melody.
3 Tree edit distance
Once the tree representation scheme has been introduced, the next section of this
paper is for describing how the trees are compared. The problems that arise related
to the complexity of this task are also discussed.
The edit distance between two trees can be defined as the minimum cost of
the sequence of operations that transforms a tree into the other [17]. The editing
operations are the same as those used in standard string edit distance (i.e. the
Levenshtein distance): deletion of a node, insertion, and substitution of a node label.
The more similar the structures of the trees are, the less operations of deletion and
insertion have to be done, and the smaller the distance between them is.
3.1 Full edit distance
The Shasha and Zhang method [17] to compute the edit distance between two trees,
TA and TB , has a time complexity of O(|TA| × |TB | × h(TA) × h(TB)), where |Ti|
are the number of nodes in the trees and h(Ti) are their depths. It uses the tree
editing operations described above, giving a cost to each operation. The objective
is to achieve a mapping between both trees that requires the least cost sequence of
operations, looking for similar tree structures, that is, similar rhythmical patterns.
We have used the Shasha and Zhang algorithm [17] to compute the full tree
edit distance. It obtains the distance between both trees that requires the least cost
sequence of operations, looking for similar tree structures, that is, similar rhythmical
structures.
The cost weights used for the edit distance operations have been set to 1 for
insertion and deletion. For substitution, the weight is 0 if the label is the same and
1 otherwise. Other tested weights did not improve the results.
Pattern Recognition : Progress, Directions and Applications 233
3.2 Partial edit distance
The high cost of the full edit distance, makes it advisable to look for a cheaper
alternative. The technique introduced by Selkow [21] has this property. The main
functional difference of this technique is that node insertions and deletions can be
done only at the leaves of the trees. Only after removing all the subtree rooted at a
node it can be deleted. The restriction of the way a node can be inserted or deleted
makes the algorithm simpler, but less accurate.
The lower complexity is the main advantage of the Selkow method. Its time
complexity is O(nAnBh) where nA and nB are the maximum arities of the trees TA
and TB, respectively, and h is the maximum depth of both trees. Due to the whole
melody tree construction method described in section 2.4, joining all the measure
sub-trees in a single, root, in our case, nA and nB will be the number of measures
of the two melodies to be compared.
4 Nearest neighbour classification with tree edit dis-
tance
The NN classification rule is a widely known non-parametric technique for classifi-
cation tasks. Although usually an object (prototype) is represented as a vector of
features (a point in Rn), the NN rule may also be used when objects are represented
as strings or trees, if an adequate dissimilarity measure is defined.
When the distance has very high time complexity (like in our case), the classifi-
cation time per sample becomes very high, if the exhaustive NN search is applied.
As the bottleneck in this task is obviously the distance computation, a fast NN
search algorithm is essential. More precisely, we need an algorithm that computes
a very low number of distances, like AESA [22], LAESA [23], and TLAESA [24].
These algorithms are not the fastest when prototypes are represented as vectors,
but do their best when distance computations are very time consuming, like when
prototypes are represented as strings or trees, for instance, due to the small number
of distance computations.
However, even with the algorithm that computes less distances (AESA), the
average classification time per sample in our experiments was still too high, as we
will explain later in section 5. In order to address this problem we have tried two
alternatives: first, to use the Selkow tree edit distance, which is much faster but less
accurate. Second, to extend previous work on approximate NN search [25], mainly
focused on vector spaces of representation, to the algorithms mentioned above, which
are suitable for any metric space, not only for vector spaces. We have also extended
234 Pattern Recognition : Progress, Directions and Applications
the Fukunaga and Narendra’s algorithm [26], which is also suitable for metric spaces
in general.
4.1 Approximate NN search in non-vector spaces
The idea of approximate NN as stated in [25] is to find a neighbour of the unknown
object (the sample) which is not farther than a certain factor  from the actual NN
of the sample, that is, its distance is not greater than (1 + )dnn, where dnn is the
distance to the actual NN. The approximate NN search is thus faster than exact
NN search when  increases, but usually error rates also increase with the value of .
Thus, the problem is to find an adequate value of  in order to speed up classification
without increasing too much the error rates.
In this work we present the application of the ideas in [25] to algorithms suitable
for non-vector spaces; however, the changes needed for this task are algorithm-
dependent. In the case of AESA and LAESA, the algorithms compute a lower
bound of the distance of each prototype p to the sample x, g(x, p), using the triangle
inequality and some previously computed distances: given a set B of prototypes
whose distance to the sample has been computed, and given that the distances
from these protoypes to all other prototypes in the training set have been computed
during the training of the classifier, the lower bound can be computed as:
g(x, p) = maxb∈B |d(x, b) − d(b, p)|
In the case of AESA, the set B is the set of all prototypes whose distance to
the sample has been computed (this implies a continuous reevaluation of the lower
bound); however, a table holding all the distances between the prototypes in the
training set has to be stored, thus the spatial complexity becomes quadratic. In the
case of LAESA, the set B is selected at training time so that the prototypes in B
are maximally separated, allowing an acceptable lower bound computation without
the quadratic spatial complexity (see [22, 23] for the details).
Both algorithms traverse the training set, selecting a candidate to nearest neigh-
bour as the one with the lowest lower bound. Then, its distance to the sample is
computed and the current nearest neighbour is updated, if possible. The algorithm
finishes the search when the next candidate c has a lower bound higher than the
distance to the current nearest neighbour, dnn, that is, when:
g(x, c) > dnn (terminating condition for exact NN search)
The extension of these algorithms for approximate NN search is straightforward:
(1 + )g(x, c) > dnn (terminating condition for approximate NN search)
Pattern Recognition : Progress, Directions and Applications 235
M
x
Rp
d(x,M )-Rp p
p
Figure 10: Lower bound of the distance from the sample x to a node p in the
Fukunaga and Narendra’s algorithm.
By using this new terminating condition the algorithm stops the search earlier (de-
pending on the value of ), thus allowing a faster classification.
The TLAESA and Fukunaga and Narendra’s (FN75) algorithms both build up a
tree from the training set and traverse it using a branch and bound scheme, similar
to the tree traversal that uses the k-d tree, in which is based the approximate search
proposed in [25]. One of the various implementations of approximate search over a
tree uses a priority queue to store unvisited tree nodes. The nodes are stored along
with a key m, which is used to sort the nodes in the queue, so that the node with the
minimum key is the first to be extracted from the queue. In the case of TLAESA
and FN75, the key for the priority queue is a lower bound of the distance from all
the prototypes contained in a node p to the sample x (see figure 10):
m = d(x,Mp) − Rp (FN75)
m = g(x,Mp) − Rp (TLAESA)
where Mp is the representative of the node, Rp is the radius of the node and g(·, ·)
is a lower bound of d(·, ·) (computed exactly in the same way as in the LAESA
algorithm). The expressions for the keys are derived from elimination condition for
non-leaf nodes of each algorithm.
The search phase is very similar in both algorithms: at each step, the algorithm
extracts a node from the queue (the one with the minimum key), and then it prunes
one or both of its children and stores the others in the queue. Whenever the next
node extracted from the queue has a key higher than dnn, the algorithm finishes the
search. When using a priority queue to traverse the tree, the approximate search
is easy to incorporate: as in the case of AESA and LAESA, when m(1 + ) > dnn
the search finishes. In the four algorithms, letting  = 0 means an exact (non-
approximate) NN search.
236 Pattern Recognition : Progress, Directions and Applications
5 Experiments and results
The dataset has a total number of 641 prototypes (melodies extracted from MIDI
files), from 149 different classes (different melodies). The MIDI files corresponded to
film soundtrack themes, some well known pop-rock songs and classical music pieces
from the ”classical period”, in such a way that different versions of those themes
could be easily found in the Internet. Each melody prototype has been represented
by a tree for each pitch property (producing 5 different trees) and by the 40 possible
different string representations, as discussed in section 2.1.
The evaluation of classification error has been made using the leaving-one-out
technique, due to the low number of prototypes per class available. All the classifi-
cation experiments have been performed with the NN classifier.
The first experiment has been designed to assess the ability for melody identi-
fication of the different pitch properties described in definitions 2.1, and compare
them to their use in strings together with the duration properties presented in defi-
nitions 2.1.
The second experiment tries to evaluate the classification and time performance
of full and approximate tree edit distance, using approximate NN search. String
representation performance will be taken as a reference also in these experiments.
5.1 Pitch representations
The performances for the five different kind of pitch properties as a function of the
pruning level, p ∈ [3, 8] and p = ∞ have been tested and compared to a number of
string representations in terms of error rate and classification times.
The classification results for the pitch properties are plotted in figure 11. Inter-
vals (p5) achieved the best performances, and a pruning level of p = 5 was the best
in most cases. Note that strings performed worse than trees in general.
The error rates for all the considered representations were averaged for both
trees and strings (dotted lines in figure 12). Average classification times (measured
as time in seconds per prototype in the training set), computed with the full tree
edit distance, are plotted in the same graph for comparison. Note that the string
edit distance is much faster (around 0.3 s/prototype) than tree edit distance and
this measure increases in time dramatically for p ≥ 5. From the plots in that graph
can be stated that p = 5 can be a good compromise between time and classification
error, and this value will be utilised for the next experiments.
Pattern Recognition : Progress, Directions and Applications 237
10
15
20
25
30
35
40
3 4 5 6 7 8 inf String
A
ve
ra
ge
 e
rr
or
 r
at
e 
(%
)
Pruning level
 p1
 p2
 p3
 p4
 p5
Figure 11: Classification performances with different pitch properties as a function
of the pruning level. For clarity, the string results are displayed only for the duration
property “duration” (d1) in a coupled coding with the different pitch properties.
5.2 Partial distance and approximate search
In this experiment, intervals have been used both for the tree representation and
for the strings. For trees, the pruning level is p = 5. First, the performance of the
full edit distance is studied versus the value of  defined in section 4.1 and then, the
same is done for the partial edit distance.
The error rates and average classification times per sample for the Shasha and
Zhang distance are plotted in figure 13, for increasing values of , with the error
rates and classification time for the string representation as a reference (without
approximate NN search). The results show that using a tree representation improves
the performance of the classifier, lowering its error rates around a 10 percent with
regard to strings using the same pitch representation with the best of the four posible
duration representations for that pitch. A value of  = 2% have been the maximum
allowed in such a way that trees perform better than the best string coding.
The results depend highly on the NN search algorithm: the error rates and
classification time for LAESA and TLAESA are very similar; in the case of AESA,
its time performance is always the best, but has a quadratic space complexity that
makes it useless for large training sets. The FN75 algorithm needs higher values for
, as the other three algorithms compute the lower bound of the distance from a node
to the sample. The best results are those of the AESA, but if we discard AESA due
238 Pattern Recognition : Progress, Directions and Applications
 0
 1
 2
 3
 4
 5
3 4 5 6 7 8 inf
5
10
15
20
25
30
A
ve
ra
ge
 c
la
ss
ifi
ca
tio
n 
tim
e 
(s
ec
on
ds
)
A
ve
ra
ge
 e
rr
or
 r
at
e 
(%
)
Pruning level
Tree time
Tree error rate
String time
String error rate
Figure 12: Evolution of time and error rate versus tree pruning level (averaged for
all the different labels). References for strings are plotted as horizontal lines.
to its quadratic spatial complexity, all other three algorithms obtain similar results
(although with different values of ): if we allow approximately a 2 percent increase
in error rates, the classification time may be reduced in more than a third part with
respect to an exact NN search.
The classification times of Shasha and Zhang’s distance are still too high with
respect to the string representation, so we tested Selkow’s tree edit distance. The
same experiments were reproduced using this new distance, and the results are shown
in figure 14. Although error rates increase a little with this distance, classification
times have been dramatically reduced, and still it is possible to reduce them more
using approximate NN search. Once again, the best results are obtained by AESA,
but the results for the other algorithms are similar than those of the Shasha and
Zhang distance. The important point is that the tree representation classification
times are similar (and sometimes better) to those of the string representation, while
the error rates keep lower than string ones.
6 Conclusions
Tree representation of melodies has been proposed to improve identification rates
achieved by string representations and to reduce the degrees of freedom of strings
for coding. To overcome the higher processing time of tree representation classifiers,
a combination of low-cost partial tree edit distance and approximate NN search has
Pattern Recognition : Progress, Directions and Applications 239
24
22
20
18
16
76543210
er
ro
r 
ra
te
 (
%
)
value of ε
Music melodies identification (Shasha and Zhang's distance)
AESA
LAESA
TLAESA
FN75
string (p3) (ε=0)
string (p5) (ε=0)
4
3
2
1
0
76543210
tim
e 
(s
ec
s)
value of ε
Music melodies identification (Shasha and Zhang's distance)
AESA
LAESA
TLAESA
FN75
string (p3) (ε=0)
string (p5) (ε=0)
Figure 13: Error rates (top) and per-sample classification time (bottom) for the
Shasha and Zhang distance. The error rates for a string representation are plotted
as a reference.
240 Pattern Recognition : Progress, Directions and Applications
24
22
20
18
16
76543210
er
ro
r 
ra
te
 (
%
)
value of ε
Music melodies identification (Selkow distance)
AESA
LAESA
TLAESA
FN75
string (p3) (ε=0)
string (p5) (ε=0)
0
5
10
15
20
30
40
0 1 2 3 4 5 6 7
tim
e 
(1
/1
00
 s
)
value of ε
Music melodies identification (Selkow distance)
AESA
LAESA
TLAESA
FN75
string (ε=0)
Figure 14: Error rates (top) and per-sample classification time (bottom) for the
Selkow distance.
Pattern Recognition : Progress, Directions and Applications 241
been proposed.
The results show that the tree representation reduces the error rates of string
representations. The addition of rhythmic information to string coding in order to
improve classification rates opens a high number of different possibilities that must
be explored in order to reach the best possible result, while tree coding naturally
represents that information in its hierarchical structure in a unique manner, thus
reducing the degrees of freedom in the representation.
A set of rules have been defined in order to fully label the tree internal nodes
and to prune the tree to keep its depth limited. Both things are needed to apply
the tree edit distance and to reduce classification times. A maximum pruning depth
equal to 5 (no notes shorter than an eighth note remain) provided small trees and
good classification rates with our corpus.
Among all the pitch properties defined to label the trees, note intervals have
produced the best results.
The combination of partial tree edit distance with approximate NN search allows
the classification times to be comparable to or sometimes better than those of strings,
with a small increase in error rates that still remain lower than those of strings.
For the future work we plan to develope and use methods for automatic mo-
tive extraction and segmentation of melodies. This would allow to extract melodic
“thumbnails” that could be used as a representative of the whole melody for more
efficient search and identification.
References
[1] Dongge Li, Ishwar K. Sethi, Nevenka Dimitrova, and Tom McGee. Classification
of general audio data for content-based retrieval. Pattern Recognition Letters,
22:533–544, 2001.
[2] Brian Whitman, Gary Flake, and Steve Lawrence. Artist detection in music
with minnowmatch. In Proc. of the 2001 IEEE Workshop on Neural Networks
for Signal Processing, pages 559–568. Falmouth, Massachusetts, September 10–
12 2001.
[3] H. Soltau, T. Schultz, M. Westphal, and A. Waibel. Recognition of music types.
In Proceedings of the IEEE International Conference on Acoustics, Speech, and
Signal Processing (ICASSP). Seattle, Washington, May 1998.
242 Pattern Recognition : Progress, Directions and Applications
[4] E. Pampalk, S. Dixon, and G. Widmer. Exploring music collections by browsing
different views. In Proc. of the 4th Int. Conf. on Music Information Retrieval,
ISMIR, pages 201–208, Baltimore, USA, 2003.
[5] Midi standard.
[6] MusicXML.
[7] P. P. Cruz and E. Vidal. Learning regular grammars to model musical style.
In V.Honavar and G.Slutzki, editors, Proc. of 4th. International Colloquium
on Grammatical Inference (ICGI-98), pages 211–222. Springer-Verlag (LNAI
Series), 1998.
[8] P. J. Ponce de León and J. M. Iñesta. Feature-driven recognition of music styles.
In Proc. of the 1st Iberian Conf. on Pattern Recognition and Image Analysis,
Lecture Notes in Computer Science, volume 2652, pages 773–781, Majorca,
Spain, 2003.
[9] W. Chai and B. Vercoe. Folk music classification using hidden markov models.
In Proc. of the Int. Conf. on Artificial Intelligence, Las Vegas, USA, 2001.
[10] Efstathios Stamatatos and Gerhard Widmer. Music performer recognition us-
ing an ensemble of simple classifiers. In Proc. of the Xth European Conf. on
Artificial Intelligence ECAI, pages 335–339, Lyon, France, 2002.
[11] David Rizo and José M. Iñesta. Tree-structured representation of melodies for
comparison and retrieval. In Proc. of the 2nd Int. Conf. on Pattern Recognition
in Information Systems, PRIS 2002, pages 140–155, Alicante, Spain, 2002.
[12] David Rizo, José Manuel Iñesta, and Francisco Moreno-Seco. Tree-structured
representation of musical information. In Proc. of the 1st Iberian Conf. on
Pattern Recognition and Image Analysis, Lecture Notes in Computer Science,
volume 2652, pages 838—846. Springer-Verlag, 2003.
[13] P. P. Cruz, E. Vidal, and J. C. Pérez-Cortes. Musical style identification us-
ing grammatical inference: The encoding problem. In Alberto Sanfeliu and
José Ruiz-Shulcloper, editors, Proc. of the 8th Iberoamerican Conf. on Pattern
Recognition, CIARP, pages 375–382, 2003.
[14] Shyamala Doraisamy and Stefan Rüger. Robust polyphonic music retrieval with
n-grams. Journal of Intelligent Information Systems, 21(1):53–70, 2003.
[15] F. Lerdahl and R. Jackendoff. A Generative Theory of Tonal Music. MIT Press,
Cambridge, Massachusetts, 1983.
Pattern Recognition : Progress, Directions and Applications 243
[16] Carlos Agón, K. Haddad, and Gerard Assayag. Representation and rendering
of rhythm structures. In Proc. of the 2nd Int. Conf. on Web Delivering of Mu-
sic, Wedelmusic, pages 109–116, Darmstadt, Germany, 2002. IEEE Computer
Press.
[17] S. Shasha and K. Zhang. Approximate Tree Pattern Matching. Pattern Match-
ing Algorithms, chapter 11, pages 341–371. Oxford Press, 1997.
[18] Y.E. Kim, W. Chai, R. Garcia, and B. Vercoe. Analysis of a contour-based
representation for melody. In Proc. of the Int. Symposium on Music Information
Retrieval, 2000.
[19] A.L. Uitdenbogerd and J. Zobel. Manipulation of music for melody matching.
In B. Smith and W. Eelsberg, editors, Proc. of ACM International Multimedia
Conference, pages 235–240, Bristol, UK, 1998.
[20] M. Mongeau and D. Sankoff. Comparison of musical sequences. Computers and
the Humanities, 24:161–175, 1990.
[21] Stanley M. Selkow. The tree-to-tree editing problem. Information Processing
Letters, 6(6):184–186, 1977.
[22] E. Vidal. New formulation and improvements of the nearest-neighbour approxi-
mating and eliminating search algorithm (AESA). Pattern Recognition Letters,
15:1–7, 1994.
[23] L. Micó, J. Oncina, and E. Vidal. A new version of the nearest neigh-
bour approximating and eliminating search algorithm (AESA) with linear
preprocessing-time and memory requirements. Pattern Recognition Letters,
15:9–17, 1994.
[24] L. Micó, J. Oncina, and R. C. Carrasco. A fast branch and bound nearest
neighbour classifier in metric spaces. Pattern Recognition Letters, 17:731–739,
1996.
[25] S. Arya, D.M. Mount, N.S. Netanyahu, R. Silverman, and A. Wu. An optimal
algorithm for approximate nearest neighbor searching. Journal of the ACM,
45:891–923, 1998.
[26] K. Fukunaga and M. Narendra. A branch and bound algorithm for computing
k–nearest neighbors. IEEE Transactions on Computing, 24:750–753, 1975.
244 Pattern Recognition : Progress, Directions and Applications
