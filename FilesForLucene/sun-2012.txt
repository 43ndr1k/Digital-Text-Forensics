Applying Stylometric Analysis Techniques to 
Counter Anonymity in Cyberspace 
 
Jianwen Sun, Zongkai Yang, Sanya Liu* 
National Engineering Research Center for E-learning, Central China Normal University, Wuhan, China 
Email: sunjw.work@gmail.com, zkyang@mail.ccnu.edu.cn, lsy5918@gmail.com 
 
Pei Wang 
School of Information Management, Wuhan University, Wuhan, China 
Email: wangpei.work@gmail.com 
 
 
 
Abstract—Due to the ubiquitous nature and anonymity 
abuses in cyberspace, it’s difficult to make criminal identity 
tracing in cybercrime investigation. Writeprint 
identification offers a valuable tool to counter anonymity by 
applying stylometric analysis technique to help identify 
individuals based on textual traces. In this study, a 
framework for online writeprint identification is proposed. 
Variable length character n-gram is used to represent the 
author’s writing style. The technique of IG seeded GA based 
feature selection for Ensemble (IGAE) is also developed to 
build an identification model based on individual author 
level features. Several specific components for dealing with 
the individual feature set are integrated to improve the 
performance. The proposed feature and technique are 
evaluated on a real world data set encompassing reviews 
posted by 50 Amazon customers. The experimental results 
show the effectiveness of the proposed framework, with 
accuracy over 94% for 20 authors and over 80% for 50 ones. 
Compared with the baseline technique (Support Vector 
Machine), a higher performance is achieved by using IGAE, 
resulting in a 2% and 8% improvement over SVM for 20 
and 50 authors respectively. Moreover, it has been shown 
that IGAE is more scalable in terms of the number of 
authors, than author group level based methods. 
 
Index Terms—stylometric analysis, writeprint identification, 
character n-gram, ensemble learning, genetic algorithm 
I.  INTRODUCTION 
With the emergence and rapid proliferation of Internet, 
it has created a new way for exchange of information and 
opinions, as well as propaganda dissemination. A variety 
of web-based channels are developed for communication 
and information sharing, the typical channels such as 
website, email, online forum, blog, microblog, etc. 
Despite its numerous benefits, Internet has also become a 
good venue for criminal activities attributable to its 
ubiquitous nature and anonymity abuses. Criminals often 
use online messages to distribute illegal materials. 
Electronic commerce is susceptible to deception from 
easy identity change and reputation manipulation which 
have facilitated numerous forms of fraud. Moreover, 
terrorist and extremist organizations are using online 
forum as one of their major communication channels to 
support psychological warfare, fundraising, recruitment, 
coordination, and distribution of propaganda materials [1]. 
Compared to traditional crimes in real world, it’s 
difficult to trace criminal identity in cybercrime 
investigation. This is partially attributable to the abuses of 
anonymity in cyberspace. When dealing with large 
numbers of cyber users and activities, the situation is 
more complicated, and it’s impossible to meet the 
investigation requirements by making a manual tracing. 
Hence, tools providing automated criminal identification 
are necessary to counter anonymity abuses and strengthen 
the social accountability in cyberspace. 
Note that the aforementioned forms of cybercrime all 
involve text based mode of communication. Therefore, 
it's feasible to find the potential identity traces in textual 
messages left by web users. Stylometry is the statistical 
analysis of writing style by examining the characteristics 
of a piece of writing to draw conclusions on its 
authorship. Writeprint identification, characterization and 
similarity detection are three major fields of stylometric 
analysis studies. In current research we only address 
writeprint identification (also called authorship 
identification or authorship attribution in some literature) 
for online messages, which is the task of predicting the 
most likely author of a piece of textual online message 
given a predefined set of candidate authors. 
Despite significant progress in the research of online 
stylometric analysis, there are several current limitations, 
in which one of the biggest is the lack of scalability in 
terms of number of authors. This is partially because the 
selected features can’t capture the author’s writing style 
sufficiently, and the technique for stylometric analysis is 
not sufficient to deal with large scale of the authors. 
Moreover, pervious work has mostly focused on 
developing the single classifier technique. There has been 
limited emphasis on ensemble-based technique for online 
stylometric analysis. 
In this study we propose a framework for writeprint 
identification to address some of the current limitations of 
 
Corresponding author: Sanya Liu, lsy5918@gmail.com. 
This is the extended version of our paper at 2010 International
Conference on Multimedia Information Networking and Security
(MINES 2010), Nanjing, November 2010. 
JOURNAL OF NETWORKS, VOL. 7, NO. 2, FEBRUARY 2012 259
© 2012 ACADEMY PUBLISHER
doi:10.4304/jnw.7.2.259-266
online stylometric analysis. We use the variable length 
character n-gram for representing the author’s writing 
style. An ensemble-based classification model is 
developed to improve the performance and scalability of 
writeprint identification, which is built on individual 
author level feature set type. Experiments are conducted 
on a real world data set to evaluate the effectiveness of 
the proposed feature and technique. 
The remainder is organized as follows. Section 2 
surveys the related work. Section 3 presents a framework 
for online writeprint identification using variable length 
character n-gram feature type and ensemble-based 
technique. Section 4 describes an individual author level 
feature subspacing method based on hybrid Genetic 
Algorithm (GA). Section 5 includes the performed 
experiments. Conclusions and future directions are given 
in last section. 
II.  RELATED WORK 
From a machine learning point of view, writeprint 
identification can be seen as a single-label multi-class 
text categorization problem. Three important 
characteristics of this task are stylometric features, 
feature set types, and the techniques employed to analyze 
these features. 
A.  Features 
Similar to human fingerprint, writeprint is composed 
of multiple features such as frequency of word, 
vocabulary richness, length of sentence, structural 
information, etc. These features can represent an author’s 
unique, immutable writing style and further become the 
basis of writeprint analysis [2]. Previous studies proposed 
taxonomies of features under different labels and criteria 
[3]. Among all the measures, the character n-gram 
approach has been proven to be quite useful to quantify 
the writing style [4,5]. One of the best performing 
algorithms in an authorship attribution competition was 
also based on a character n-gram representation [6]. It is 
able to capture the nuances of higher level and tolerate 
the noises such as grammatical errors or misuse of 
punctuations. Moreover, the procedure of extracting n-
grams is language-independent and requires no special 
tools, especially for Chinese where the tokenization 
procedure is not trivial [7].  
However, an important issue of using character n-gram 
is the definition of n . A large n  would better capture 
lexical and contextual information but it would also 
capture thematic information and increase the feature 
dimensionality, while a small n  would not be adequate to 
capture contextual information. The drawbacks of 
defining a fixed value for n  can be avoided by extracting 
variable length n-grams. And the variable approach is 
used in this study. 
B.  Feature Set Types 
Depending on whether is a single feature set applied 
across all authors, two typical feature set types are author 
group level and individual level feature set. For group 
level, there is only one set across all authors, and it is 
commonly used in most previous research [8]. For 
individual level, each author has an individual feature set, 
and it’s especially suitable for dealing with large potential 
feature space problems, such as n-gram based features. 
Typical studies can be shown in [9,10], in which a feature 
set containing the 5,000 most frequent character n-grams 
and misspelled words was created for each author, 
respectively. Since traditional machine learning 
techniques dealing with group level type, typically train a 
classifier on a single set, special techniques are required 
to handle individual level feature set type. 
C.  Techniques 
Ensemble learning is one of the typical techniques 
which could handle individual level feature set type [11]. 
Sample subspacing and feature subspacing are two 
common methods for ensemble construction, and the 
feature subspacing approach has been shown effective for 
style or pattern recognition problems. The basic idea of 
individual level feature subspacing is that it allows each 
base classifier to act as an “expert” on its particular sub 
area of feature space. For writeprint identification, limit 
work has been done by using ensemble-based technique 
on individual level feature set. In [5], an ensemble model 
based on randomly feature set subspacing was proposed 
to perform author identification, and it was shown that 
ensemble scheme was quite effective. 
Based on the success of individual level feature set and 
the corresponding ensemble technique, we propose a 
framework for writeprint identification to counter 
anonymity in cyberspace. More details are presented in 
the next section. 
III.  FRAMEWORK FOR WRITEPRINT IDENTIFICATION IN 
CYBERSPACE 
To get a better understanding, several variables are 
defined as follows.  
Giving a data set D  for stylometric analysis, there are   
I  messages and K  authors. Let refer the i -th message as 
im  and the k -th author as ka . Each message im  is 
represented as a vector of character n-grams ordered by 
decreasing frequency of occurrence. Let 
{ }tt ggggG , ,,, 321 =  be the ordered set of all 
character n-gram features extracted from D . Consider 
ijf  as the occurrence frequency of the j -th n-gram of tG  
in im . Then the message im  could be represented as  
{ }itiiii ffffm ,,,, 321 = .  
Let tsG :  be a subset of tG  ( ts ≤ ) and k tsG :  the subset 
of ktG  for author ka . In addition, there is a corresponding 
set ktW  for ka , which contains the weight information of 
features in ktG . Consider ),( : LAGC k tsk  as a base classifier 
trained on k tsG :  using a specific learning algorithm LA . 
Then )),,(( : CombLAGCE ktsk  denotes an ensemble of such 
base classifiers for all the K  authors according to a 
combination method Comb . 
260 JOURNAL OF NETWORKS, VOL. 7, NO. 2, FEBRUARY 2012
© 2012 ACADEMY PUBLISHER
Figure 1.  Framework for online writeprint identification. 
Using the above notation, a framework for writeprint 
identification is proposed base on the previous review 
and the questions addressed in last section. As shown in 
Fig. 1, there are five steps included in this framework to 
carry out writeprint identification of online messages. 
As previously mentioned, the basic idea of the 
proposed framework is building an ensemble model 
based on individual level feature set, with each base 
classifier trained using a particular author’s features, 
allowing it to become an “expert” on identifying that 
author against others. 
A. Data Collection 
The first step is to collect a set of textual online 
messages written by a certain number of potential authors 
( I  messages for K  authors are included in D ). Each 
message is considered as a unit that contributes separately 
to the model trained on D . Moreover, it’s better to 
preserve a balanced distribution of training sample over 
the candidate authors to get a reliable model as well as 
good performance. 
B.  Feature Extraction 
The raw messages collected in Step 1 are in 
unstructured text format. To train a model on these 
messages, they have to be represented as a vector of 
stylometric features. As stated above, variable length 
character n-gram feature is adopted in this study. 
Consequently, an extraction component dealing with such 
feature type need be developed for a special purpose. 
Using this tool, an initial set of character n-grams with 
variable length will be extracted from D . Then, each 
message im  could be represented as a set of character n-
grams ordered by decreasing occurrence frequency 
{ }itiiii ffffm ,,,, 321 = . 
C.  Feature Selection on Individual Author Level 
This step aims to partition the feature space using 
feature selection method for building the ensemble-based 
writeprint identification model that will be discussed in 
next step. That means we need select one feature subset 
k
tsG :  consisting of a number of character n-grams with 
variable length for each potential author ka . The point is 
that the selected character n-gram features in the final 
individual subset k tsG :  should be representative for ka  
and discriminative against others. After the feature 
selection, an ensemble could be built on these individual 
author level feature subsets.  
As illustrated in Fig. 1, three successive procedures are 
utilized in this step: shallow selection, feature weighting, 
and feature selection for individual author. All these 
procedures will be discussed in more detail below. 
(1) Shallow Selection for Individual Author 
For character n-gram features, there are countless 
potential features giving a data set that is not trivial. It’s 
necessary to reduce the feature space by a pre-selection 
(shallow selection). A common criterion for selecting n-
gram based features in stylometric analysis task is their 
frequency [12]. But there is no agreement on the setting 
of the minimum frequency threshold (MFT) in prior work. 
It’s typical to set MFT as a fixed number such as a 
threshold of 10 or to use the most frequent n-grams for a 
predefined number such as 1000. Another important issue 
of the variable length character n-gram approach is the 
definition of n . A large n  would better capture high 
level information, but it would also increase the feature 
dimensionality substantially and capture more thematic 
information. Moreover, it has to be underlined that the 
selection of the best n  value is dependent on language.  
Taking these into consideration, we use the MFT 
approach to select features with a minimum usage 
frequency. Unlike the previous methods, we think the 
setting of MFT is related to the author and data set. That 
means each author in a dataset would have a MFT. To an 
author, the less frequent n-grams are representative and 
discriminative if they only appear in messages written by 
that specific author but not all the ones. Moreover, it’s 
reasonable to adjust MFT according to the number of 
messages of an author giving a data set. In this paper, we 
set MFT equal to half of the number of messages to an 
author. Note that the feature is not representative if it 
distributes over a small number of messages. And we use 
only up to 5-grams which containing 1-gram, 2-grams, 3-
grams, 4-grams and 5-grams. 
After this process, a reduced set tG  containing all the 
character n-grams not being filtered would be derived. 
Each author ka  also gets a set ktG  in which the totally 
insignificant features have been eliminated. It’s easy to 
find that tG  is a collection of the distinct elements of all 
the K  sets ktG . 
 
JOURNAL OF NETWORKS, VOL. 7, NO. 2, FEBRUARY 2012 261
© 2012 ACADEMY PUBLISHER
Figure 2.  Illustration of ensemble construction. 
(2) Feature Weighting for Individual Author 
Feature weighting is a technique used to estimate the 
degree of the individual feature’s discriminatory power 
by using a metric in classification problem. For 
stylometric analysis based on author group level, feature 
weighting algorithm is generally applied across all classes 
(i.e., authors in this context) for utilizing a single feature 
set that could best discriminate authorship across all 
authors. Unlike most conventional usage, this procedure 
aims to approximate the optimal degree of influence of 
individual feature at differentiating a specific author 
against all others for each author. 
Information Gain (IG) is a typical feature weighting 
algorithm used in many text categorization tasks as an 
efficient method [13]. In this paper, Shannon entropy 
measure [14] is employed as the feature weighting 
technique using symbols defined above. That is 
                  )()(),( tkktk gaHaHgaIG −=                       (1) 
where ),( tk gaIG  is the information gain for feature tg  
across K  authors, )( kaH  ( )(log)()( 2
1
k
K
k
kk apapaH 
=
−= ) is 
the overall entropy across K  authors and )( tk gaH  
( )(log)()( 2
1
tk
K
k
tktk gaPgaPgaH 
=
−= ) is the conditional 
entropy for tg . 
Using IG, the major processes for feature weighting for 
individual author level are illustrated as follows: 
1) For K  authors in data set D  
a) Do a two-class setup (one against others) for 
author ka . 
b) For each feature tg  in ktG  
Compute ),( tk gaIG  using (1) as the 
weight of tg  for ka  ( ),( tkkt gaIGW = ). 
 c) Repeat step b for each feature. 
2) Repeat step 1 for each author. 
After this process, The set ktW  containing the feature 
weight information would be derived for ka . And there is 
a one-to-one correspondence between ktW  and ktG . 
(3) Feature Selection for Individual Author 
Feature selection is a technique of selecting a subset of 
relevant features which helps to improve the performance 
of learning models. It also helps to alleviate the effect of 
the curse of dimensionality and enhance interpretability 
of the learning model. For ensemble learning, another 
advantage of feature selection is to encourage diversity 
among the predictions of the base classifiers by partition 
the feature space. This is essential for good ensemble 
performance. 
Filter and wrapper are two approaches for feature 
selection. GA has been used in numerous feature 
selection applications [2,15]. It uses a wrapper model 
where the accuracy is used as the evaluation criterion to 
improve the feature subset in future generations. A 
consequence of using GA in a wrapper model is that 
convergence towards an ideal solution can be slow when 
dealing with very large solution space. However, feature 
selection is considered an offline task that dose not need 
to be repeated constantly. And some heuristic information 
can be incorporated to facilitate improved accuracy and 
convergence efficiency. 
In this paper we propose an IG seeded GA based 
feature selection technique for Ensemble (IGAE). In 
IGAE, GA is employed as a feature selection technique, 
by incorporating IG heuristic, to construct an ensemble 
model for writeprint identification based on individual 
author level feature set. More details of IGAE are 
provided in the next section. 
D.  Ensemble-based Model Construction 
As illustrated in Fig. 2, based on the resulting feature 
subset k tsG :  for each author ka , a base classifier 
),( : LAGC
k
ts
k  will be built by employing a learning 
algorithm LA . In this study, SVM is used as the LA  due 
to its performing in writeprint identification tasks. Then, 
the ensemble-based model for writeprint identification 
)),,(( : CombLAGCE
k
ts
k  is constructed. Additionally, Simple 
Majority Voting (SMV) is used as the combination 
method for its simplicity and effectiveness. 
E.  Writeprint Identification 
If the performance of )),,(( : SMVSVMGCE ktsk  is verified 
by testing set, it could be applied to identify the writeprint 
of new messages. 
IV.  INDIVIDUAL AUTHOR LEVEL FEATURE SELECTION 
FOR ENSEMBLE USING IGAE 
Like most hybrid GA variations, the key idea behind 
IGAE is that it incorporates the feature weights 
information produced by IG as heuristic into the GA’s 
initial population and operators (e.g., crossover and 
mutation). But unlike the conventional GA based feature 
selection for single classifier, some diversity strategies 
are utilized to facilitate convergence efficiency for such 
ensemble feature selection problem. The pseudo-code for 
IGAE is given in Fig. 3 below. 
The chromosome design, fitness function and genetic 
operators of IGAE are described in detail as follows. 
262 JOURNAL OF NETWORKS, VOL. 7, NO. 2, FEBRUARY 2012
© 2012 ACADEMY PUBLISHER
Figure 3.  Pseudo-code for IGAE. 
A.  Chromosome Decoding and Initial Population 
In this study, each chromosome is decoded using a 
binary string of length equal to the number of authors K  
multiply the size of the feature set tG . Each chromosome 
represents an ensemble solution. K  gene segments in 
each chromosome represents K  authors. Each gene may 
have values “0” or “1” indicating whether a feature is 
selected or not. 
As standard GA, the initial population of IGAE is 
randomly generated. The difference is that one 
chromosome of the initial population is randomly 
selected to recode using heuristics from ktG  and ktW . 
Two steps have to be done. Firstly, the binary string of 
the chromosome is modified according to ktG . That 
means the new value of a gene should be strictly 
consistent with the status of the corresponding feature of 
the corresponding author in ktG . Secondly, the modified 
chromosome would be improved again using the feature 
weight information from ktW . The basic principle is that a 
feature with an information gain less than 0.0025 (i.e., 
0025.0),( >tk gaIG ) should be selected according to prior 
work using IG for text feature selection [15]. 
B.  Fitness Evaluation 
As designed in [17], it’s straightforward to use the 
accuracy of the ensemble for fitness function. But this 
way is biased towards some particular integration method 
and prone to overfitting. An alternative solution is using 
diversity and individual accuracy for fitness function. 
Another motivation for this alternative is the fact that 
overfitting at the level of the individual classifiers is more 
desirable than overfitting of the ensemble itself. 
Moreover, it was shown that the feature subsets selected 
by GA have more features than other search strategies 
[18]. It also could be a good choice to add a control 
measure to control the complexity of the model. Taking 
into account all these factors, a 3-criteria fitness formula 
is given below. 
               featNoDivAccxFitness .)( ×+×+= βα             (2) 
Here, )(xFitness  is the fitness of an ensemble solution x  
based on a feature subspacing scheme. Acc  represents 
the average accuracy of the individual classifiers 
),( : SVMGC
k
ts
k  built on the feature subsets k tsG :  
corresponding to each author ka . Div  is the total 
ensemble diversity that is the average of all the classifier 
pairs measured by Kappa statistic [19] in this study. 
featNo.  represents the average numbers of K  feature 
subsets k tsG : . α  and β  are two constants specified 
according to the problem. α  is used to control the 
contributes to the fitness function from Div . β  is used to 
control the model’s complexity by setting a threshold. 
Following the definition in [18], let K  be the number 
of authors and N  be the total number of messages. Then, 
ijN  is the number of messages identified as author i  by 
the first classifier and as author j  by the second one, ∗iN  
is the number of messages identified as i  by the first 
classifier, and iN∗  is the number of messages identified 
as i  by the second classifier. Define 1Φ  and 2Φ  as 
        

=
∗∗=





 ×=Φ=Φ
K
i
ii
K
i
ij
N
N
N
N
N
N
1
2
1
1 ,        (3) 
where 1Φ  estimates the probability that the two 
classifiers agree, and 2Φ  is a correction term for 1Φ , 
which estimates the probability that the two classifiers 
agree simply by chance. The pair wise diversity 
ijKappaDiv _  is then defined as follow: 
                       
2
21
1
_
Φ−
Φ−Φ
=ijKappaDiv                          (4)                      
C.  Genetic Operators 
As the traditional genetic operators, selection, 
crossover, and mutation are used in IGAE. Roulette-
wheel selection scheme is used to select the members 
randomly with a probability proportional to fitness. The 
crossover operator uses uniform crossover in which each 
feature of the two offspring randomly takes a value from 
one of the parents.  
Unlike the traditional mutation, the mutation operator 
in IGAE is modified to incorporate the IG heuristic into 
the mutate operation. The basic idea is to increase the 
probability of features with higher heuristic value in ktW  
while decreasing the probability of features with lower 
value. 
V. EXPERIMENTAL EVALUATION 
A description of the test bed, experimental design, and 
result discussion are encompassed in this section. 
A.  Test Bed Description 
The online reviews of 50 customers from Amazon's 
Top Customer Reviewers are collected as our test bed, of 
which the main characteristics are listed in TABLE I. 
JOURNAL OF NETWORKS, VOL. 7, NO. 2, FEBRUARY 2012 263
© 2012 ACADEMY PUBLISHER
Figure 4.  Results of the first experiment. 
B.  Experimental Design 
Two experimental tasks are conducted to examine the 
effectiveness of the proposed approach. The first aims at 
examining the performance of variable length character 
n-gram approach in comparison with fixed length 
approach. The second task is concerning the effectiveness 
evaluation of the proposed IGAE technique. 
The first experiment uses frequency and IG to examine 
the performance of variable length character n-gram 
approach. Firstly, an initial set of 18,167 character n-
grams (including all the 91 1-grams, 3,076 2-grams, the 
5,000 most frequent 3-grams, the 5,000 most frequent 4-
grams, and the 5,000 most frequent 5-grams) is extracted 
from 600 messages of 20 authors. Then, IG is used to 
select the most significant 1,000 to 10,000 n-grams with a 
step of 1,000. The same approach is followed by fixed 
length n-grams. For example, using an initial set of 
15,000 most frequent 3-grams, we also use IG to select 
the best 1,000 to 10,000 3-grams with a step of 1,000. 
In the second experiment, we compare IGAE with a 
single classifier built on author group level feature set. 
SVM is a powerful single classifier for writeprint 
identification according to previous studies [3,20]. We 
also compare IGAE with other two typical ensemble-
based techniques on individual author level: Simple 
Random Subspacing for Ensemble (SRSE) and Simple 
GA based subspacing for Ensemble without incorporating 
heuristic such as entropy (SGAE). For SVM, standard 10-
fold cross-validation is used to validate its performance. 
For the three ensemble-based techniques, a same pre-
processing (e.g., character n-gram based feature 
extraction and shallow selection for individual author) is 
applied before feature subspacing. After that, the set tG  
for all K  authors and ktG  for each one are derived. Then 
the same number of feature subspace partitions as K  
authors is obtained to construct base classifiers. In SRSE, 
half of the original features in ktG  are randomly selected 
for each author ka , and it is repeated 10 times with the 
average value as the overall accuracy of SRSE. The only 
difference between IGAE and SGAE is whether to 
incorporate the information gain as a heuristic in GA. 
The original data set is divided by the ratio of 2:1 into 
two parts: the training set and test set. We use the 
LIBLINEAR algorithm [21] in Matlab7. In all 
experiments, linear kernels are used with C=1. For GA 
based methods, they are both run for 1000 iterations, with 
a population size of 50 for each generation, using a 
mutation probability of 0.5 (as proposed in [22]). The α  
and β  in fitness function are set to 0.6 and -0.25, 
respectively. 
C.  Results Discussion 
The results of the first experiment are shown in Fig. 4. 
As can be seen, the variable length character n-gram 
approach outperforms fixed length approaches when the 
selected features are less than 6,000. But for a higher 
dimensionality, the improvement on performance began 
to decline. It could be observed that the variable length n-
gram approach even fails to compete with fixed length 
approach, especially for 3-grams, when the number of 
features is over 6,000. These results are generally 
consistent with previous study [11]. Moreover, the 
highest accuracy rate of nearly 93% illustrates that the 
variable length character n-gram vector is quite effective 
for representing an author’s writing style, and SVM is 
indeed a suitable algorithm for dealing with a high 
dimensional feature space and sparse data like this 
scenario. 
Comparative results for the proposed IGAE and 
several other techniques designed in the second 
experiment are given in TABLE II and Fig. 5. Clearly, 
IGAE achieves the best performance in all cases. And it 
is followed by SGAE, another GA based ensemble 
feature selection technique. This indicates the 
effectiveness of the GA based ensemble feature selection 
technique for application of writeprint identification. 
However, all the four techniques’ accuracy decreases 
when the number of authors increases from 20 to 50. But 
compared with other three techniques for individual 
author level, the performance of SVM drops more sharply 
as the number of authors goes from 20 to 50. For 50 
authors, IGAE obtains a great performance improvement, 
TABLE I.   
THE CHARACTERISTICS OF TEST BED 
No.  of 
authors 
Average no. of 
messages per 
author 
Average length of 
message Time span
50 30 1,038 characters 1 year 
TABEL II. 
PERFORMANCE COMPARISON OF FOUR TECHNIQUES FOR WRITEPRINT 
IDENTIFICATION 
Techniques 
No. of authors
SVM SRSE SGAE IGAE 
20 92.96% 89.76% 93.19% 94.32%
30 87.75% 86.10% 89.20% 90.27%
40 80.12% 80.45% 83.55% 85.12%
50 72.41% 73.23% 78.29% 80.74%
264 JOURNAL OF NETWORKS, VOL. 7, NO. 2, FEBRUARY 2012
© 2012 ACADEMY PUBLISHER
60
65
70
75
80
85
90
95
100
20 authors 30 authors 40 authors 50 authors
SVM SRSE SGAE IGAE
Figure 5.  Performance comparison of four methods. 
Figure 6.  Evolutionary processes of IGAE and SGAE. 
resulting in a 8% improvement over SVM. Consequently, 
it seems that the ensemble-based techniques for 
individual author level are more scalable than author 
group level based methods as the number of author 
increases. 
Fig. 6 shows the performance of two GA based 
techniques (IGAE and SGAE) across the 1000 
generations. As can be seen, the evolutionary process of 
IGAE converges after about 480 generations, and it is 
much faster than SGAE which is about 800 generations. 
This is due to the use of IG heuristic incorporated in the 
initial population and the mutation operator of IGAE. 
Although seeded by IG heuristic, it’s interesting to be 
found that the accuracy of IGAE declines at the 
beginning of the dozens of generations. This is the result 
of the application of replacement strategy in selection 
operator that prevents the IG seeded solution from 
dominating the whole population. But the heuristic 
carried by the IG seeded solution is gradually 
disseminated to the remaining. As a result, the IGAE is 
able to converge on an improved solution, and it is 
outperformed than SGAE. 
VI. CONCLUSIONS AND FUTURE WORK 
In this research we applied stylometric analysis 
techniques to counter anonymity in cyberspace. An 
effective framework for writeprint identification was 
presented to address the anonymity abuse problem in 
cyberspace. In this framework, variable length character 
n-gram feature was used as the representation of author’s 
writing style, and was evaluated for writeprint 
identification. Then, IGAE was also developed to build 
an ensemble model based on individual author level 
feature set. Several specific components for dealing with 
the individual based feature set type were integrated in 
this framework. The proposed features and technique 
were evaluated on a real world test bed. The experimental 
results indicated the effectiveness of the proposed 
framework. Compared with SVM (the baseline technique 
for writeprint identification), IGAE obtained a 
considerable performance improvement. Moreover, it had 
been shown that the ensemble-based technique for 
individual author level, especially IGAE had a better 
scalability than author group level based methods when 
the number of authors increases.  
Like most wrapper based feature selection problems 
using an optimal search method, it is computationally 
intensive when dealing with a large number of authors. 
Although feature selection is considered an offline task 
which does not need to be repeated constantly, it’s still 
important to improve the efficiency of the proposed 
method. We found that the efficiency of the ensemble-
based model is related to the employed base classifier. 
The training time can be significantly reduced when 
using solver type 1 of LIBLINEAR, while obtaining a 
comparable accuracy. A full examination of this 
relationship needs a separate study.  
In the future we would continue to improve the 
writeprint identification technique for online messages. 
We believe that the ensemble technique based on 
individual author level could improve the performance, 
scalability, and interpretability of online writeprint 
identification. Future research will focus on the 
optimization of the design of fitness function, in 
particular the setting of α , β , and the use of other 
measures of Div , in order to further narrow in on a key 
feature subset for each author. In addition, the 
relationship between the option of base classifier and the 
efficiency of the ensemble, together with parallel GA 
algorithm will be explored in next study to deal with the 
large number of authors. 
ACKNOWLEDGMENT 
We thank the reviewers for their constructive 
comments and suggestions. This work was supported in 
part by a grant from the National Key Technology R&D 
Program in the 12th Five-Year Plan (No. 
2011BAK08B03) and self-determined research funds of 
CCNU from the colleges’ basic research and operation of 
MOE (No. CCNU09A02006). 
REFERENCES 
[1] Jialun Qin, Yilu Zhou, Edna Reid, Guanpi Lai, and 
Hsinchun Chen, "Analyzing terror campaigns on the 
internet: Technical sophistication, content richness, and 
JOURNAL OF NETWORKS, VOL. 7, NO. 2, FEBRUARY 2012 265
© 2012 ACADEMY PUBLISHER
Web interactivity," International Journal of Human-
Computer Studies, v.65, n.1, pp.71-84, January, 2007. 
[2] Li, J., Zheng, R., and Chen, H., "From fingerprint to 
writeprint," Communications of the ACM, 49(4), pp.76-82, 
2006. 
[3] Abbasi, A., Chen, H., "Applying authorship analysis to 
extremist-group web forum messages," IEEE Intelligent 
Systems, 20(5), pp.67-75, 2005. 
[4] Grieve, J., "Quantitative authorship attribution: An 
evaluation of techniques," Literary and Linguistic 
Computing,22(3), pp.251-270, 2007. 
[5] Stamatatos, E., "Ensemble-based author identification 
using character n-grams," In Proceedings of the 3rd 
International Workshop on Text-based Information 
Retrieval, pp.41-46, 2006. 
[6] Juola, P., "Ad-hoc authorship attribution competition," In 
Proceedings of the Joint Conference of the Association for 
Computers and the Humanities and the Association for 
Literary and Linguistic Computing, pp.175-176, 2004. 
[7] Stamatatos, E., "A survey of modern authorship attribution 
methods," Journal of the American Society of Information 
Science and Technology, 60(3), pp.538-556, 2009. 
[8] Jianwen Sun, Zongkai Yang, Pei Wang, and Sanya Liu, 
"Variable length character n-gram approach for online 
writeprint identification," 2010 International Conference 
on Multimedia Information Networking and Security, 
pp.486-490, 2010. 
[9] Peng, F., Schuurmans, D., Keselj, V., and Wang, S., 
"Automated authorship attribution with character level 
language models," In Proceedings of the 10th Conference 
of the European Chapter of the Association for 
Computational Linguistics (EACL 2003), pp.267-274, 
2003. 
[10] Chaski, C. E., "Empirical evaluation of language-based 
author identification techniques," Forensic Linguist, 8,1, 
pp.1-65, 2001. 
[11] Dietterich, T. G., "Ensemble methods in machine 
learning," In Proceedings of the 1st International 
Workshop on Multiple Classifier Systems, pp.1-15, 2000. 
[12] Houvardas, J., and Stamatatos E., "N-gram feature 
selection for authorship identification," In Proceedings of 
the 12th International Conference on Artificial Intelligence: 
Methodology, Systems, Applications, pp.77-86, Springer, 
2006. 
[13] Forman, G., "An extensive empirical study of feature 
selection metrics for text classification," Journal of 
Machine Learning Research, 3, pp.1289-1305, 2003. 
[14] Shannon, C. E., "A mathematical theory of 
communication," Bell System Technical Journal, Vol.27, 
pp.379-423 and 623-656, July and October, 1948. 
[15] Yang, J., Honavar, V., "Feature subset selection using a 
genetic algorithm," IEEE Intelligent Systems, 13, 2, pp.44-
49, 1998. 
[16] Yang, Y., Pederson, J.O., "A comparative study on feature 
selection in text categorization," In Proceedings of the 14th 
International Conference on Machine Learning, pp.412-
420, 1997. 
[17] L.I Kuncheva, L.C. Jain, "Designing classifier fusion 
systems by genetic algorithms," IEEE Transactions on 
Evolutionary Computation, 4(4), pp.327-336, 2000. 
[18] Alexey Tsymbal, Mykola Pechenizkiy, Pádraig 
Cunningham, "Diversity in search strategies for ensemble 
feature selection," Information Fusion, Vol.6, pp.83-98, 
2005. 
[19] J. Cohen, "A coefficient of agreement for nominal scales," 
Educational and Psychological Measurement, 20, pp.37-46, 
1960. 
[20] Zheng, R., Li, J., Chen, H., and Huang, Z., "A framework 
for authorship identification of online messages: Writing 
style features and classification techniques," Journal of the 
American Society of Information Science and Technology, 
57(3), pp.378-393, 2006. 
[21] R.E. Fan, K.W. Chang, C.J. Hsieh, X.R. Wang, and C.J. 
Lin, "LIBLINEAR: A library for large linear classication," 
The Journal of Machine Learning Research, 9:1871–1874, 
2008. 
[22] D. Opitz, "Feature selection for ensembles," Proc. 16th 
National Conf. on Artificial Intelligence, AAAI Press, 
pp.379–384, 1999. 
 
 
 
 
Jianwen Sun is a Ph.D. Candidate at National Engineering 
Research Center for E-learning (NERCEL), Central China 
Normal University (CCNU), Wuhan, China. He received the 
B.S degree from CCNU in 2005. His research interests are in 
machine learning, intelligent system and knowledge service. 
 
Zongkai Yang received the B.E. and M.E. degrees from 
Huazhong University of Science and Technology (HUST), 
Wuhan, China, in 1985 and 1988, respectively, and the Ph.D. 
degree from Xi'an Jiaotong University, Xi'an, China, in 1991. 
From 1991 to 1993, he devoted himself to his postdoctoral 
research in HUST. He is currently a professor in NERCEL, 
CCNU. He is the author of more than 80 journal and conference 
papers. His research interests include signal processing, network 
communication, and information technology. 
 
Sanya Liu received the B.E. and M.E. degrees in 1996 and 
1999, and received the Ph.D. degree in 2003 from HUST. He 
devoted himself to his postdoctoral research in Xiamen 
University from 2003 to 2005. Currently, he is a professor in 
NERCEL, CCNU. His research interests include artificial 
intelligence, and computer application. 
 
Pei Wang received her master's degree from the Australian 
National University, Australia, and bachelor's degree from 
Wuhan University (WHU), Wuhan, China. She is currently a 
Ph.D. Candidate at School of Information Management in WHU. 
Her research interest focuses on public sector information 
systems. 
 
266 JOURNAL OF NETWORKS, VOL. 7, NO. 2, FEBRUARY 2012
© 2012 ACADEMY PUBLISHER
