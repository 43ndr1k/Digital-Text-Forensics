Appl Intell (2009) 31: 107–121
DOI 10.1007/s10489-008-0116-0
Robust classification for spam filtering by back-propagation
neural networks using behavior-based features
Chih-Hung Wu · Chiung-Hui Tsai
Published online: 1 February 2008
© Springer Science+Business Media, LLC 2008
Abstract Earlier works on detecting spam e-mails usually
compare the contents of e-mails against specific keywords,
which are not robust as the spammers frequently change the
terms used in e-mails. We have presented in this paper a
novel featuring method for spam filtering. Instead of clas-
sifying e-mails according to keywords, this study analyzes
the spamming behaviors and extracts the representative ones
as features for describing the characteristics of e-mails. An
back-propagation neural network is designed and imple-
mented, which builds classification model by considering
the behavior-based features revealed from e-mails’ head-
ers and syslogs. Since spamming behaviors are infrequently
changed, compared with the change frequency of keywords
used in spams, behavior-based features are more robust with
respect to the change of time; so that the behavior-based fil-
tering mechanism outperform keyword-based filtering. The
experimental results indicate that our methods are more use-
ful in distinguishing spam e-mails than that of keyword-
based comparison.
Keywords Spam e-mails · Back-propagation · Neural
networks · Machine learning · Classification
Partially supported by National Science Council, Taiwan, under grant
NSC 93-2213-E-390-009.
C.-H. Wu ()
Department of Electrical Engineering, National University
of Kaohsiung, Kaohsiung, Taiwan
e-mail: johnw@nuk.edu.tw
C.-H. Tsai
Computer and Network Center, Chung Hwa University
of Medical Technology, Tainan, Taiwan
1 Introduction
With the popularity of e-mail communication, the abuse of
unsolicited commercial e-mails (or spam), has been becom-
ing a troublesome problem on the Internet. Estimates on the
growth of spam show that up to 80 percent of all e-mails
are spam, which indicate the severity of spam inundation.
Nowadays, anti-spam becomes an important issue for In-
ternet users, network administrators, service providers, and
businesses. Various techniques for automatically detecting
or filtering out spam e-mails have been proposed. Com-
monly used techniques build comprehensive databases for
blocking e-mails whose addresses have been reported as
black-lists or whose message bodies contain specific words
or phrases defined as threatening terms. Among the oth-
ers, machine-learning based techniques for context investi-
gation receive a lot of attentions. Such methods investigate
the positions, frequencies and context associations of terms
or phrases used in e-mails and then construct classification
rules or models in conjunction with weighted scoring that
estimate the likelihood whether an incoming e-mail is spam
or not. Methods based on such context filtering, or termed
in this paper as “keyword-based” methods, are effective
and commonly employed in practical applications. From the
point of view of machine-learning, the key to success of ap-
plying machine-learning based classification is the correct-
ness of features which can precisely describe the character-
istics of a sufficient amount of training samples. However,
spammers usually attempt to make their messages as indis-
tinguishable from legitimate e-mails as possible and change
the patterns used in spam to foil the filters. Some spam e-
mails are tailored by sophisticated programs and look like
normal messages containing no specifically suspicious key-
words. As a consequence, conventional approaches cannot
precisely capture the characteristics of changing spam.
108 C.-H. Wu, C.-H. Tsai
The objective of sending spam is to sell products or ser-
vices to those customers who are possibly available on the
Internet. For this purpose, spam e-mails are massively and
repeatedly dispatched in order to broadly contact such cus-
tomers. Besides, in order not to be detected, spam e-mails
are elaborately pretended as hams. By observing what spam-
mers do, we found that spam e-mails are generated and de-
livered according to some “spamming behaviors.” For in-
stance, spam e-mails are usually sent with anonymous or
forged sender information, forwarded by illegal permission
or accounts, delivered repeatedly with a bunch of the same
message to many different recipients, etc. Using specific
keywords can be viewed as a class of spamming behaviors.
Spam filtering according to the concept of spamming behav-
iors is first presented in [36] which claimed that such behav-
iors can be used for identifying spams since they have better
resistance to the change of time.
The basic idea of this study is to utilize the spamming
behaviors, instead of keywords, as classification features for
detecting spam. That is, this method does not concentrate on
what keywords are used in spam; instead, this method fo-
cuses on what spamming behaviors are performed in spam
by spammers. Since spamming behaviors change inactively,
in comparison with the frequency of keyword-change, clas-
sification of spam using behavior-based features may be
more robust than keyword-based methods. In this paper,
a back-propagation neural network is designed for spam
classification using spamming behaviors as features. Experi-
mental results show that spam classification using behavior-
based features is more robust than using keyword-based fea-
tures.
The rest of this paper is structured as follows. Section 2
describes the concept of spamming behaviors of e-mails.
Section 3 presents the formulation of spamming behaviors
and their characteristics for spam classification. In Sect. 4
we present the designs of a back-propagation neural network
for behavior-based spam classification. The experimental re-
sults are presented in Sect. 5. Section 6 gives a brief re-
view on related research. Finally, we conclude this study in
Sect. 7.
2 Spamming behaviors as classification features
Though, there is no world-wide accepted definition on what
a spam is, we try to describe spam e-mails according to
their “behaviors” as follows. A spam is generally recognized
as an electronic message in which the recipient’s personal
identity and context are irrelevant because the message is
equally applicable to many other potential recipients; the re-
cipient has not verifiably granted deliberate, explicit, and
still-revocable permission for it to be sent; and the trans-
mission and reception of the message appears to the recipi-
ent to give a disproportionate benefit to the sender [17, 34,
35, 37]. In order to accomplish the purpose of sending spam
and prevent from being detected, spammers elaborately dis-
guise a spam as a normal e-mail (generally known as a
“ham”) using automated spamming programs (also known
as “spambots”). Such pretending tricks usually have some
or all of the following characteristics.
• Irrelevant subject to the e-mail contents. Spammers may
randomly generate characters in the subject line in order
to bypass spam filters.
• Forged headers. To hide the origin of spam, routing or
returning addresses are usually forged or invalid, making
it difficult to trace back the source of persistent spammers.
• Massive distribution. Spam e-mails are usually massively
sent to designated addresses which are collected manually
by the spammers or automatically by spambots.
• Long transmission relays. Spam is transmitted through
several mail-relays which are not protected. Sometimes,
spam e-mails are transmitted directly without connecting
to any authorized mail-relay.
• Non-Office hour delivery. Spam e-mails are usually deliv-
ered at non-office hours, such as 02:00 AM–06:00 AM,
because of larger bandwidth available and lower risk to
be coped.
• Dictionary-based collection of addresses. To contact
possible recipients, spambots systemically generate
variants of the recipient’s e-mail addresses. For example,
when a valid e-mail address Johnw@hotmail.com is
collected, variant addresses such as Johnw@aol.com,
Johnw@yahoo.com, Johnw@gmail.com are also gener-
ated.
• Unworkable unsubscription. The link for unsubscription
often does not work, or opens up an advertisement’s web-
site which verifies the legitimacy of the recipient’s ad-
dress and collects it in the mailing list.
• Hidden scripts. Spam e-mails in HTML format may con-
tain hidden Java Script, which can open up web-sites and
activate popup windows for advertisement.
• Image or document attachments. The message contents
are converted into files in non-plain text formats, such as
GIF, JPG, or PDF. Then the spammers transmit a blank
e-mail with such files attached.
• Metaphor context. In order to confuse static filtering rules,
spammers compose metaphors context and try not to use
lexicons that can be directly identified as advertising.
The so-called spamming behavior is a tricking method that
spammers use for composing or delivering spam for specific
purposes such as the ones mentioned above. Using specific
keywords can be viewed as a class of such spamming behav-
iors. A spam can be delivered by using one or more than one
such tricks. For example, an image spam or a sophisticated
metaphor context can be massively delivered at non-office
hours via several unauthorized mail-relays.
Robust classification for spam filtering by back-propagation neural networks using behavior-based features 109
Fig. 1 Samples of the formats of headers and syslogs
The actions of spammers are hard to be defined explicitly
and formally. However, they can be partially observed from
the transmission records of e-mails. Let us recall the sce-
nario of e-mail transmission. Usually, the users compose or
read e-mails using mail user agents (MUAs) which connect
to mail servers. A mail transfer agent (MTA) is installed on
the mail server for delivering e-mails and communicating
with MUAs. E-mails received by an MTA are retained in
a temporary file called mailbox until being downloaded by
the recipients. Regarding to the structure of an e-mail, the
header is a piece of structured messages stating the orga-
nization and destination of the mail. Some of the informa-
tion in the header is given by the sender manually; some by
MUAs automatically. An MTA delivers an e-mail according
to the information in the e-mail’s header. When an e-mail
is delivered by an MTA, a record describing this delivery is
added to an auditing file, referred to as syslog. Each record
in an e-mail’s header or syslog consists of several “fields”
each of which describes a piece of information related to
the e-mail. Figure 1 presents sample headers and syslogs of
e-mails, where From:, Reply-To:, etc., are fields in the
header and daemon, nrcpts, etc., are fields in the syslog.
Note that, e-mails transmitted with different communication
protocols may have different formats in constructing head-
ers and syslogs. Throughout this paper, we explore e-mails
delivered by the Simple Mail Transfer Protocol (SMTP) and
sendmail in BSD 4.4 format. The readers may refer to [9]
for more details.
The concept of spamming behaviors is first presented
in [36] which uses knowledge-based techniques to describe
all possible spamming behaviors. They claim that such
spamming behaviors can be used for identifying spam since
they have better resistance to the change of time. By extend-
ing the same concept, the following assumptions are formed
as the bases of this study.
1. Spam e-mails are composed and delivered with one or
more spamming behaviors and regular e-mails are done
with “normal” behaviors.
2. In normal e-mails, the values of all fields in the headers
and syslogs could be correctly and properly given. Con-
versely, the associated headers and syslogs of spam may
contain inconsistent or abnormal information.
3. Terms or phrases extracted from the contents of e-mails
form the features for keyword-based classification.
110 C.-H. Wu, C.-H. Tsai
Behaviors identified from the associated headers and sys-
logs of e-mails form the features for behavior-based clas-
sification.
4. Spamming behaviors do not matter how the e-mail’s con-
tents are formatted (in image, text, etc.)
5. E-mail users can access to and modify the e-mail’s header
and contents through MUAs, but not the associated sys-
logs on MTAs.
6. Spamming behaviors like forging messages, late or mas-
sively delivering, and the ones that cause inconsistency
in e-mails can be extracted from headers and syslogs.
In such settings, data recorded in the contents, headers, and
syslogs can be viewed as fingerprints of the senders of e-
mails. Among the sources of such fingerprints that pro-
vide clues for identifying the intentions of spammers, we
select headers and syslogs since they are not effected by
the formats and forms of e-mails. Message bodies of e-
mails, though, directly present the contents of spam, do
change frequently and are not stable sources of clues for
spam filtering. Then, if we can identify the spamming be-
haviors from e-mails, we may achieve a better performance
of spam filtering. Notably, the spamming behaviors men-
tioned here are not absolutely defined. They are observa-
tions from volumes of spam. It is possible that normal
users behave as spammers do, e.g., sending e-mails to a
group of co-workers at mid-night. But they usually do not
have to send e-mails with faked information. Addition-
ally, the spamming behaviors discussed here are for ac-
complishing the purposes we mentioned previously. Dis-
cussions on various delivering behaviors for sending bulk
e-mails for various purposes are not in the scope of this
study.
3 Feature formulation
3.1 Selecting effective behavior-based features
Conceptually, we can formulate an e-mail e according to m
fields selected from its header h1, h2, . . . , hm and n fields
from syslog s1, s2, . . . , sn in the following form.
e = 〈h1, h2, . . . , hm, s1, s2, . . . , sn〉. (1)
According to [9], there are more than 190 header fields and
23 syslog fields available for designing MUAs/MTAs. Con-
sequently, the length of e in (1) may be more than 213 since
m ≥ 190 and n ≥ 23. Evidently, it is too long to be processed
for efficient classification. Besides, each feature are encoded
in plain text which is difficult to be processed directly. By
observing the activities of MUAs/MTAs and the information
recorded in headers and syslogs, we found that not all fields
are used; some of them are even not used by MUAs/MTAs.
Therefore, not all fields of headers and syslogs are needed to
be used as features for classification. To reduce the complex-
ity, the following methods are used for selecting and trans-
forming the most significant features.
3.1.1 B-features
First, we consider the header part. In order to get statistical
evidences, we analyze on the headers of 10,022 spams and
22,809 hams which are publicly available at [27] and list
in Table 1 the ones that are most frequently used. Among
them, we select the top-6 which meaningfully appear in ham
and spam as the representative header fields. They are Re-
ceived:, Return-Path:, From:, Delivered-To:, To:, and Date:.
Then we consider the syslog part. Since there are no pub-
lic corpora collecting syslogs for spam analysis, we take
MTAs available to the authors. We select the syslog fields
which appear most frequently and are meaningful to hu-
mans. The fields from, to, nrcpts, date are selected. The rest
fields in syslog are seldom used or are serial numbers gener-
ated by MTAs for auditing. Then, for describing an e-mail,
we obtain 10 features, where 6 features from header and 4
ones from syslog. For convenience, we term these fields as
the basic features or B-features of an e-mail and use H =
〈To:, From:, Return-Path:, Date:, Delivered-To:, Received:〉
and L = 〈to, from, date, nrcpts〉 for denoting the B-features
extracted from header and syslog, respectively, of an e-mail.
3.1.2 X-features
Let us recall the discussions in Sect. 2 which state that spam-
mers possibly act like normal users and vice versa. Each
B-feature presents a piece of primitive information about
what the sender had done with the e-mail. Identifying spam
using only B-features may be not enough, because the spam-
ming behaviors are not absolutely defined and spammers are
able to modify the header information. Our solution to this is
to cross-verify H and L of B-features based on the assump-
tion we made previously. That is, syslog is not modified by
MUAs. According to the designs of MTAs and MUAs, some
fields in H and L are related and should be consistent in
the same e-mail. For instance, From: in H and from in L
should direct to the same sender. Also, To: and Delivered-
To: should be consistent in H . These relationships are con-
sistent in ham but may be not in spam.
We utilize this property and define cross-referred features
or simply X-features as the consistency status of two close-
related B-features in H or L. Based on their formats (for ex-
ample, address- or date-format), we extract 16 meaningful
combinations of B-features as X-features. Comparisons on
the B-features in different formats (e.g., addresses v.s. dates
or number of receivers) are ignored. Each X-feature is repre-
sented as X&Y , where the symbol “&” indicates that the X
Robust classification for spam filtering by back-propagation neural networks using behavior-based features 111
Table 1 Statistics on the
appearing frequencies of header
fields
HAM SPAM
Field Frequency (%) Field Frequency (%)
Delivered-To: 100.0 Received: 100.0
Return-path: 100.0 Delivered-To: 100.0
Subject: 100.0 Return-Path: 100.0
From: 100.0 Message-Id: 99.9
Date: 100.0 Date: 99.9
Message-Id: 99.9 From: 98.3
Received: 99.9 Subject: 97.2
Precedence: 99.9 To: 84.5
Errors-To: 99.9 Content-Type: 60.5
Sender: 99.9 Mime-Version: 55.1
To: 99.6 Status: 54.3
Content-type: 97.8 Reply-To: 33.8
Mime-Version: 97.6 Content-Transfer-Encoding: 29.1
In-Reply-To: 50.4 X-Priority: 23.5
X-Mailer: 47.2 X-MSmail-Priority: 21.5
Content-Transfer-Encoding: 43.3 X-Mailer: 20.7
Cc: 40.7 Comments: 9.3
Reply-To: 34.5 Sender: 7.2
References: 33.5 Precedence: 7.0
User-Agent: 19.2 Cc: 4.8
Table 2 X-features extracted from H and L
X-feature From Subclass
To:&From: H H XH
To:&Return-Path: H H
To:&Delivered-To: H H
From:&Return-Path: H H
From:&Delivered-To: H H
Return-Path:&Delivered-To: H H
to&from L L XL
To:&to H L XX
To:&from H L
From:&to H L
From:&from H L
Delivered-To:&from H L
Delivered-To:&to H L
Return-Path:&from H L
Return-Path:&to H L
Date:&date H L
are Y are two B-features from H or L which are needed to
be cross-referred. Table 2 lists the X-features we define. For
convenience, X-features are classified into three subclasses
XH , XL, and XX , stating that B-features from only head-
ers, only syslog, and both header and syslog are compared,
respectively. Note that, the fields in X-features are picked
up for cross-reference and the their relationship is reflexive,
e.g., Delivered-To:&from = from&Delivered-To:.
Finally, by using B- and X-features, an e-mail e can be
represented as a 5-tuple e = 〈H,L,XH ,XL,XX〉 which
describes the spamming behaviors of e. Next, the values
of these features have to be instantiated from plain-text to
discrete values for further processing. Notably, like in other
non-linear classification problems, each single feature is not
a dominator that can absolutely determine whether an e-
mail is ham or spam. All features are considered together
for identifying spam. For example, the director of a soft-
ware development team may send massive e-mails to her/his
overseas co-workers at midnight. In this case, the receiving
date is in non-office hours. In classification, each training
example may present some characteristics as their features.
They even have counter presentations in the same set of
data. Their relationships are analyzed by the learning algo-
rithms.
3.2 Instantiation of features
In order not to directly process plain text in the classifica-
tion phase, we convert text-values of 〈H,L,XH ,XL,XX〉
into discrete symbols. According to the characteristics of
B-features and X-features, we categorize the correspond-
ing values into several types. For the transmission purposes,
112 C.-H. Wu, C.-H. Tsai
Table 3 Discretized values of behavior-based features
(a) B-Features
Value Format Characteristics Value Format Characteristics
B N/A Empty string “ ” H Date-and-time Illegal date/time
C Address User account empty I Date-and-time Legal but “late” time
D Address Domain name empty J Numeric Larger/less than or
E Address Faked or non-existed account equal to a threshold
F Address Faked or non-existed domain N Any Empty
G Address Random strings A Any None of above applicable
(b) X-Features
Value Format Difference Characteristics Value Format Difference Characteristics
N N/A b1 or b2 empty Q Same b1 = b2
T Same b1 = b2 X Different N/A
[A,A,A,A,A,J,A,A,A,J,Q,Q,Q,T ,Q,Q,Q,T ,Q,Q,T ,Q,Q,T ,Q,Q]
(a) Ham in Fig. 1
[A,G,E,A,N,A,A,F,A,A,X,X,N,X,N,N,X,Q,X,X,X,N,N,X,X,Q]
(b) Spam in Fig. 1
Fig. 2 Corresponding input vectors of e-mails in Fig. 1
the values in B-features are generally represented in the
form of addresses, date-and-time, or numbers. Most normal
MTAs/MUAs fill legitimate values to all fields. Conversely,
spambots may fill illegitimate values (e.g., non-numeric text
to “Date:”) or legitimate but incorrect values (e.g., 3018-12-
34 to Date:.) According to the characteristics of each for-
mat, we discretize these cases and convert them intro concise
values heuristically as listed in Table 3(a). If none of these
cases in this table applicable, the B-feature is considered as
a normal case A. Similarly, cases for determining the value
of an X-feature are to examine its two component B-features
b1 and b2, as shown in Table 3(b).
For instantiating each feature, several procedures are de-
signed and invoked when needed. For example, examining
the legitimacy of address or date-and-time formats is per-
formed through regular expressions. To test if a mail ad-
dress is valid, the format of the address is scanned and ver-
ified against the valid domains retained on a cached data-
base. Valid user accounts or domain names are archived for
fast investigation. New domain addresses are checked on
the public Internet services. In case G, tests on randomness
of strings are performed. Since accurate detection of ran-
dom strings is a hard problem [7], we apply dictionary- and
entropy-based detection for scanning the relationships be-
tween characters in the B-feature. For case I , the so-called
“late” delivery time is temporarily set as the period between
23:30 to 06:30, which is generally not working hours of nor-
mal e-mail users. In case J , the number of relays recorded
in Received: are counts and checked if the number of relays
is larger than a threshold. The same case J is also applica-
ble to nrcpts. When testing on X-features, the procedures
for testing B-features are also invoked. For instances, the
fields (To: andy@stu.com) and (From: andy@stu.com) have
the value (andy@stu.com) in the same format (address for-
mat); while (To: 12, Feb, 2006, CST 05:43:55) and (From:
andy@stu.com) are in different formats (time format v.s. ad-
dress format).
Using the instantiation strategies above, an e-mail e =
〈H,L,XH ,XL,XX〉 can be encoded discretely. Consider
the number of features defined in 〈H,L,XH ,XL,XX〉.
There are 6 fields in H , 4 fields in L, 6 fields in XH ,
one fields in XL, and 9 fields in XX . The total length of
〈H,L,XH ,XL,XX〉 is 6 + 4 + 6 + 1 + 9 = 26. The e-mail
e then can be encoded as a 26-tuple and instantiated by the
values given in Table 3. Consequently, an e-mail e can be de-
scribed as a 26 × 1 vector I (e) = [I1, I2, . . . , I26]T , where
I1 ∼ I6, I7 ∼ I10, I11 ∼ I16, I17, and I18 ∼ I26 represent
the discrete values of H , L, XH , XL, and XX , respectively.
Considering the header and syslog of the e-mails presented
in Fig. 1 as an example, the corresponding vectors are pre-
sented in Fig. 2.
Robust classification for spam filtering by back-propagation neural networks using behavior-based features 113
Fig. 3 The proposed BPNN architecture for spam classification
4 Using back-propagation neural networks
The back-propagation neural network (BPNN) is a com-
monly used neural network architecture. Its generalization
ability can model many high degree exponential problems,
making BPNN robust to fit a wide range of applications.
BPNN is suitable for classification, function approximation,
prediction, etc. Since the high dimensionality of the pro-
posed behavior-based features and the existence of ambigu-
ity in determining which features are critically used in spam
or ham, we adopt BPNN as a learning mechanism. Gener-
ally, to maximize the performance of BPNN, it is needed to
determine the network organization and learning algorithms
that best fit the unique requirements of the underlying ap-
plication [6, 12]. Below are our considerations according to
the characteristics of the behavior-based features for spam
filtering.
4.1 Network architecture
A generic BPNN consists of an input layer, an output layer,
and one or several hidden layers. The input layer governs
the number of inputs and internal states that the net-
work uses in classification. Typically, the number of nodes
in the input layer is determined by the number of dis-
tinct features, or the length of feature vector. Likewise, the
output nodes govern the total number of classes the net-
work is classifying. According to the proposed behavior-
based features, we design a BPNN, as depicted in Fig. 3.
In this BPNN, there are 26 input nodes which are par-
titioned into two groups, nodeI (Bi) and nodeI (Xj ), 1 ≤
i ≤ 10 and 1 ≤ j ≤ 16. For an e-mail e and its corre-
sponding input vector I (e) = [I1, I2, . . . , I26]T , the input
nodes nodeI (Bi) accepts the first 10 features which present
the behaviors of H and L; while nodeI (Xj ) takes care of
114 C.-H. Wu, C.-H. Tsai
the rest 16 values which hold information about XH , XL,
and XX .
Regarding to the hidden layers, a neural network with no
more than two hidden layers can generate arbitrarily com-
plex regions in the state space [18]. Considering the dif-
ferences among behavior-based features, two hidden lay-
ers are used; one is for the inputs from B-features and
X-features and another is for the weighted outputs from
the first hidden layer. In the first hidden layer, 10 nodes
are used, where nodeH1(Bp), p = 1 . . .5, accept the out-
puts from nodeI (Bi) and nodeH1(Xq), q = 1 . . .5, accept
the outputs from nodeI (Xj ). The second hidden layer has
6 nodes, nodeH2(Nr), r = 1 . . .6, which connect all outputs
from nodeH1(·) to the output layer. There is only one output
node nodeO in the proposed architecture, which indicates
the classification result. All nodes between two layers are
fully connected.
4.2 Input feature biases
Inputs to BPNNs are features of the underlying classifica-
tion problem. In this study, discretized B- and X-features are
such inputs. The proposed B- and X-features are selected ac-
cording to their appearing frequencies. Every field of them
should have equal importance if it is properly instantiated.
However, due to varied design styles of MTAs/MUAs or
spambots, some fields are not used for composing or deliv-
ering e-mails. Thus, it is possible that there are empty or null
values appearing in 〈H,L,XH ,XL,XX〉. In B-features, null
values are frequently found in H but not in L, since the fields
in H are modifiable by spammers and the ones in L are pro-
tected by MTAs and are not accessed by users. A null value
appearing in a B-feature indicates that the field is not used
by MTAs. Here, we define that a null value appearing in a
X-feature indicates that one of its cross-referred B-features
is also null-valued. As the example shown in Table 3, null
values may multiply appear in 〈H,L,XH ,XL,XX〉 and in-
stantiated the victim fields by “N .”
If there is only few such null values, they can be treated as
noises and deleted from the training dataset. Unfortunately,
there are many such null values appearing in practical e-
mails. Their presence can not be just ignored or removed.
However, too many such null values in the training dataset
cause biased results of classification. To eliminate the effects
of null values, we give each feature a feature bias indicating
the importance of features based on its appearing frequency
and the presence of null values.
Suppose that S is a dataset of e-mails and K is a B-feature
defined over S. Let |K∗| be the number of K which are in-
stantiated by non-null values in S and nodeB(K) be an input
node that takes care of the input signals from K . The input
to nodeB(K) is biased by the input weight θB(K) which is
defined as
θB(K) = |K
∗|
|S| . (2)
Similarly, for an X-feature Z = K1 & K2 which cross-
refers to two B-features K1 and K2, the input to the node
nodeX(Z) which accepts the input signals from Z is associ-
ated with the feature bias defined as follows.
θX(Z) = |K
∗
1 | + |K∗2 |
2 × |S| . (3)
Therefore, for the pth example presented to the network,
the inputs of nodeB(K) and nodeX(Z) are biased by
θB(K) and θX(Z), respectively. The corresponding output
of nodeB(K) is Ip(K)θB(K); while the output of nodeX(Z)
is Ip(Z)θX(Z).
4.3 Activation functions
In a BPNN, a signal transferred through connections be-
tween two neurons is associated with different weight or
connection strength of importance. The net inputs to the hid-
den and output neurons follow the general form. That is, for
the pth example presented to the network, the net input to a
node nodei is
vpi =
n∑
j=1
Opjθij , (4)
where n is the number of nodes having connections to the
nodei , Opj is the output of nodej and θij is the weight of
the connection from the nodej to nodei .
The net input to the neuron is compared with an activa-
tion function. Here, the standard sigmoidal function of the
following form is adopted as the activation function.
f (x) = 1
1 + e−αx . (5)
Table 5 lists the parameter settings of the BPNN. The
weights associated with input neurons are determined by
feature biases defined in (2) and (3); while the others are
learned during the training process. Here, θij is explicitly
assigned in the initial state. In the training phase, the val-
ues of θij are tuned by standard back-propagation learning
algorithm [12]. The parameter α controls the slope of the
step function and so as the difficulty to activate the neuron.
The α values differ in neurons. We set α = 1.0 in nodeH1(·)
and α = 0.8 in the other nodes. One of the reasons of doing
this is that the determination of behavior-based features is
heuristic and may include inaccuracy. Input signals are bi-
ased in the input layer, a lower α in the H1 hidden layer
Robust classification for spam filtering by back-propagation neural networks using behavior-based features 115
Table 4 Null values in
〈H,L,XH ,XL,XX〉 No To: From: . . . date . . . To:&From: . . . to&from . . . Class
1 A A . . . A . . . Q . . . Q . . . HAM
2 N A . . . A . . . N . . . N . . . SPAM
3 C N . . . B . . . T . . . N . . . SPAM
4 N A . . . A . . . N . . . N . . . HAM
5 C C . . . I . . . T . . . T . . . SPAM
Table 5 Initial parameters used
in the proposed BPNN Parameter nodeI (Bi) nodeI (Xj ) nodeH1(Bp) nodeH1(Xq) nodeH2(Nr ) nodeO
α – – 1.00 1.00 0.80 0.80
θ (2) (3) 0.75 0.50 0.10 1.00
β – – 0.24 0.20 0.20 0.20
η – – 0.30 0.25 0.25 0.25
may activate nothing and cause a long training time. Be-
sides, putting lower α in the H2 hidden layer and the output
layer can have better tolerance of errors propagated from
their previous layers.
4.4 Learning strategies
The training process is to adjust the weight of importance as-
sociated with the connections among neurons. Suppose that
in the propose BPNN, a neuron nodej transmits signals to
another neuron nodek and θkj is the weight of the connec-
tion from nodej to nodek . Also, vpk is the net input to nodek
and ypk the output from nodek for the pth training example.
Let dpk be the desired output and ypk the actual output of
nodek . In the output layer, vp is the net input to the output
node, dp the desired output and yp the actual output of the
network. The updating of weights is done in an on-line man-
ner by gradient descent method with a momentum term [2]
as follows.
θkj (t + 1) = θkj (t) + ηδpkypj + β(θkj (t) − θkj (t + 1)), (6)
where θkj (t) is the weight θkj at iteration t , δpk is the error
term of nodej , η is the learning rate, and 0 < β < 1 is the
momentum factor. If nodek is in the output layer,
δpk = f ′(vp)(dp − yp). (7)
Otherwise, nodek is in the hidden layers, and
δpk = f ′k(vpk)
∑
i
δpj θik. (8)
For the details of the learning algorithms, please refer
to [18].
The values of η and β have different settings in the
hidden layers H1(Bi) and H1(Xj ). The momentum term
β(θkj (t) − θkj (t + 1)) adds the difference of weights be-
tween two iterations. The learning rate considers the output
errors. Currently, η and β in H1(Bi) are 20% larger than
those in H1(Xj ). These parameters are determined based
on the assumption that some B-features from headers are
instantiated heuristically (see Table 3(a)) and are empty-
valued frequently (see Table 4). Additionally, it is more
certain to determine the values X-features and they have
fewer values of instantiation. Larger β and η in H1(Bi) may
better reflect drastic changes caused by input B-features.
Conversely, lower β and η in H1(Xj ) are enough for X-
features which are relatively unvaried. These parameters are
determined heuristically and are verified by several tests on
smaller datasets. Table 5 lists the values of β and η used in
the BPNN.
4.5 Processing flow
Our method can be viewed as two-pass classification. First,
we try to classify the spamming behaviors of an e-mail
e according to the information recorded in its header and
syslog. Then, we employ BPNN to produce a classifica-
tion model. A training example is the discrete form I (e) =
[I1, I2, . . . , I26]T of e together with its class label O(e) =
1(0) indicating whether e is spam(ham). The BPNN is
trained with supervision; thus, the desired output O(e) for
each 26 × 1 input vector is supplied to the network in the
training phase. The feature bias of each feature in the train-
ing data set is calculated and θI (·) is determined. Then,
training patterns are fed into the BPNN until the training
error is satisfactory. Currently, the training process applies
116 C.-H. Wu, C.-H. Tsai
Fig. 4 Processing flow of our
method
the learning algorithm on the proposed BPNN until the total
MSE (mean squared error) is less than 0.001. The training
process fails if its running time exceeds 1800 seconds or
targeted MSE can not be approached within 10000 epochs.
The training process starts over again with new parameters
(if necessary.) Once the classification model is obtained by
BPNN, incoming e-mails are investigated accordingly. Be-
low is brief description of the processing flow which is also
depicted in Fig. 4.
• Data Collection: collecting e-mails and selecting the por-
tions of samples for training and testing, respectively.
• Heuristic Pre-Processing: converting e-mails into the
behavior-based vector form.
• Building BPNN architecture and initialization: determin-
ing the number of nodes in each layer and their connectiv-
ity and initializing the weights and thresholds associated
with the network.
• Feature reduction: removing the features whose values are
not recognizable for ham and spam according to informa-
tion entropy.
• BPNN training: performing the back-propagation algo-
rithm for updating weights of the network and generating
classification model.
• Validation: testing the validity of the classification model
against the testing data and modifying the model if not
satisfactory.
• Application: applying the final model for classifying in-
coming e-mails.
5 Experiments
5.1 Data collection
In order to test the effectiveness of the proposed method,
we have to collect enough amount of e-mails to be used as
training examples wherein both the headers and syslogs are
available. Public corpora such as the ones in [21, 26, 32, 33]
collect a huge number of e-mails. However, these e-mails
are submitted by Internet users who received spam and all
of them only contain headers and message bodies. Informa-
tion of syslogs is not available in these corpora. If we want
to identify spamming behaviors from syslogs, we need to
collect e-mails in some other ways. To overcome this obsta-
cle, we installed a MTA for collecting e-mails. More than
50 e-mail accounts are created on the MTA and are used
as contacting information for bulletin board systems, news
groups, and web sites which are publicly available on the
Internet. Also, we publish these accounts on web sites.
The purpose of doing these is to try to let these accounts
be catched by spambots or web crawlers. These strategies
were deployed since August 2004 and have being success-
fully collected more than 120,000 e-mails which are deter-
mined as ham or spam by golden rules. We delete the e-mails
in local language (BIG-5 format) and select the ones (mainly
in English) transmitted across wide-area Internet and parti-
tion them into 5 groups, as shown in Table 6. Since data
Robust classification for spam filtering by back-propagation neural networks using behavior-based features 117
are collected via MTA, all ham and spam are with complete
headers, message bodies, and syslogs and can be used as the
training examples.
5.2 Measurements
To estimate the effectiveness of our approach, several per-
formance indicators are used. Let a be the number of spam
correctly predicted as spam; b the number of ham predicted
as spam; c the number of ham correctly predicted as ham;
and d the number of spam predicted as ham. Also let the
classification mechanism consider ham as positive, the fol-
lowing measures are used.
• Mean squared error (MSE): The standard mean-square
difference measured from the output node of the
BPNN.
• True positive (TP = cb+c ): The number of ham correctly
identified to the number of all real ham.
• True negative (TN = aa+d ): The number of spam correctly
identified to the number of all real spam.
• False positive (FP = bb+c ): The number of misclassified
ham to the number of all real ham.
• False negative (FN = da+d ): The number of misclassified
spam to the number of all real spam.
• Precision (PS = TP +TN2 ): The average precision of correct
classification.
Table 6 The number of ham and spam collected from the MTA
Group Dates HAM SPAM Total
01 2004/08–2005/02 23142 31721 54863
02 2005/03 7891 10322 18213
03 2005/04 6975 9813 16788
04 2005/05 7212 9877 17089
05 2005/06 5431 7823 13254
Total 50651 69556 120207
• Accuracy (AC = a+ca+b+c+d ): The number of e-mails cor-
rectly identified to the number of all e-mails.
• F-measure (F = 2×R×PS
R+PS ): The harmonic mean of pre-
cision (PS ) and recall (R), where R is TN in the testing
phase.
• Total cost ratio (TCR = a
λb+d ): The number of correctly
identified spam to the number of incorrectly identified
e-mails, where λ is a cost parameter.
For convenience, an empty-set symbol φ in the tuple
〈H,L,XH ,XL,XX〉 denotes that the feature at that posi-
tion is not used and the corresponding feature bias is set as
0 in the BPNN. For example, 〈H,φ,XH ,φ,φ〉 means that
only H in the B-features and XH in the X-features are used
and the feature biases at the input connections for nodeI (L),
nodeI (XL), and nodeI (XX) are 0.
5.3 Experiment I
The first experiment is to test the suitability of behavior-
based features 〈H,L,XH ,XL,XX〉 for spam classification
on BPNN. Training patterns are randomly extracted from the
corpora in Table 6 and submitted to the proposed BPNN.
From group 01, we randomly select 80% (about 43,890)
e-mails, wherein 21,945 spam and 21,956 ham (50% of
19,788) are collected, for training the BPNN. The rest of
5,000 spam and 5,000 ham are used for validation. Also,
we randomly select 20,400 e-mails (10,200 ham and 10,200
spam) from the same data set and use them for testing. In
these datasets, duplicated samples are ignored. We repeat
this experiment for 10 times with the same settings and av-
erage the experimental results, as presented in Table 7.
The experimental result shows that the accuracy of clas-
sification using 〈H,φ,XH ,φ,φ〉 is better than just using
〈φ,L,φ,XL,φ〉. Additionally, 〈H,L,XH ,XL,XX〉 out-
performs the others. This phenomenon can be explained
by that the features from 〈H,φ,XH ,φ,φ〉 may be nor-
mal in ham but faked in spam so that it is possible to
identify spam using 〈H,φ,XH ,φ,φ〉 directly. However, a
Table 7 Experimental I: Statistics on the suitability of data in different features on BPNNs
Training Phase MSE (%) Ps (%) AC (%) TP (%) TN (%) FP (%) FN (%) F (%) TCR (%)
〈H,φ,XH ,φ,φ〉 28.63 87.57 86.93 80.37 93.46 19.63 6.54 81.52 358.18
〈φ,L,φ,XL,φ〉 47.93 68.20 60.72 92.72 28.83 7.28 71.17 85.84 36.77
〈H,L,XH ,XL,XX〉 4.83 99.77 99.77 99.72 99.82 0.28 0.18 99.72 21,556.52
Testing Phase MSE (%) Ps (%) AC (%) TP (%) TN (%) FP (%) FN (%) F (%) TCR (%)
〈H,φ,XH ,φ,φ〉 28.54 87.36 86.70 80.10 93.50 19.90 6.50 81.05 346.41
〈φ,L,φ,XL,φ〉 47.80 67.28 60.82 91.84 28.89 8.16 71.11 84.05 36.33
〈H,L,XH ,XL,XX〉 5.05 99.75 99.75 99.83 99.66 0.17 0.34 99.83 19,291.67
118 C.-H. Wu, C.-H. Tsai
Fig. 5 Experimental result II: Effectiveness compared with keyword-based classification
spam which is sophisticatedly faked may make the values
of 〈H,φ,XH ,φ,φ〉 looked just like ham and the classi-
fier confused. Conversely, features from 〈φ,L,φ,XL,φ〉
contain real information since they are recorded by the
MTA. 〈φ,L,φ,XL,φ〉 presents real, not faked, transmis-
sion information in both ham and spam, resulting in low
identification rate and misleading the classifier. When us-
ing 〈H,L,XH ,XL,XX〉 which combines 〈H,φ,XH ,φ,φ〉
and 〈φ,L,φ,XL,φ〉, the accuracy is significantly im-
proved due to cross-reference to both 〈H,φ,XH ,φ,φ〉 and
〈φ,L,φ,XL,φ〉.
5.4 Experiment II
Next, we compare the time-robustness of the proposed
method with the keyword-based method. The e-mails from
group 02–05 in Table 6 are partitioned into 10 subsets ac-
cording to the receiving dates. Spam/ham are randomly se-
lected from each partition so that the numbers of spam and
ham in the same dataset are almost even. These e-mails are
applied to the BPNN model that is built in Experiment I.
The process of building neural networks for keyword-based
spam filtering is similar to the ones in [6, 8]. Here, keywords
are extracted from the message bodies of these e-mails ac-
cording to the TF × IDF [31] method after stemming and
the removal of stop-words. A number of 3000 frequently ap-
peared keywords are extracted and transformed into vector-
form and applied to a BPNN with (log2(3000) + 1) ×
5 × 5 × 1 = 12 × 5 × 5 × 1 nodes using the same learning
algorithms presented in Sect. 4.4 except that the learning
strategies are unbiased. Also, this experiment is repeated
for 10 times and the results are averaged and presented in
Fig. 5.
Though the accuracy of the keyword-based method is
pretty good in the training phase but its time-robustness
becomes unstable and unsatisfactory when identifying new
e-mails. Conversely, the proposed behavior-based method is
more rigid with respect to the change of time. Since the data
for building the classification model are historical e-mails
(August 2004–February 2005) but the ones for testing are
newly collected (March 2005–June 2005), it is possible that
new keywords and behaviors associated with new e-mails
are not considered in the training phase and the classification
model can not perform correctly in the testing phase. This
may conclude that (1) the change of keywords is much faster
than that of spamming behaviors; and (2) the behavior-
based features can better describe the characteristics of
e-mails.
5.5 Experiment III
Finally, we compare the effectiveness of the proposed
BPNN architecture and the weighted learning strategy with
some machine-learning approaches. The learning algo-
rithms are obtained from Weka (version 3.4) [14]. In our
method, all fields in 〈H,L,XH ,XL,XX〉 are used in BPNN
with the same settings in Experiment I. The results are given
in Table 8.
From the results, the proposed BPNN with weighted
learning strategy outperforms the others. Interestingly,
machine-learning based spam filtering using keywords as
descriptive features are reported to have satisfactory per-
formance. However, when they are applied with behavior-
based features, the performance seems not that good. This
may due to the insufficient number of recognizable features
used in classification. In keyword-based methods, thousands
of keywords are usually needed to gain satisfactory perfor-
mance [22, 23, 30]; while in the proposed approach, only
26 features are used. It may be deduced that using behavior-
based features can sufficiently distinguish spam and ham
than keyword-based features do. Additionally, the classifi-
Robust classification for spam filtering by back-propagation neural networks using behavior-based features 119
Table 8 Experimental result III: effectiveness compared with other learning algorithms
Methods MSE (%) Ps (%) AC (%) TP (%) TN (%) FP (%) FN (%) F (%) TCR (%)
BPNN 5.05 99.75 99.75 99.83 99.66 0.17 0.34 99.83 19,291.67
RBFNet 34.26 83.52 83.47 81.72 85.28 18.28 14.72 81.83 254.30
SMO 34.16 88.49 88.33 85.07 91.69 14.93 8.31 85.36 387.27
Logistic 28.03 88.64 88.63 89.34 87.90 10.66 12.10 89.12 380.97
ADTree 27.03 91.16 91.15 90.42 91.91 9.58 8.09 90.37 511.99
BayesNet 31.03 87.18 87.19 87.16 87.21 12.84 12.79 87.00 335.43
NaiveBayes 31.03 87.18 87.19 87.16 87.21 12.84 12.79 87.00 335.43
Ridor 11.09 98.78 98.77 97.57 100.00 2.43 0.00 97.57 4005.17
Dagging 29.63 88.65 88.65 88.12 89.20 11.88 10.80 88.03 387.29
LWL 36.47 82.40 82.39 83.52 81.23 16.48 18.77 83.12 227.35
VFI 47.58 86.08 86.08 85.65 86.53 14.35 13.47 85.54 306.40
cation mechanisms may need to be specially tailored ac-
cording to the features of data to gain a better perfor-
mance.
6 Related work
Many spam filtering methods have been proposed, such
as the ones presented in [4, 13, 20, 22, 24]. Commonly
used machine learning-based techniques include decision
trees [10], case-based reasoning [11, 28], support vector ma-
chine (SVM) [5, 40], and artificial immune systems [3,
39, 41], etc. Among the others, artificial neural networks
(ANNs) for spam filtering are also studied. For example,
LINGER [8] is an ANN-based system for automatic e-mail
classification. The experimental results show that the ANN-
based filter achieves better accuracy in the training phase
but has unstable portability across different corpora. Özgür
et al. present in [29] a spam filtering method for agglutina-
tive languages such as Turkish using ANNs and Bayesian
networks. This method first deals with the morphology of
keywords and then classifies e-mails by using the roots of
the keywords extracted from morphological analysis. Two
ANN structures and three Bayesian models are employed
and compared. In [25], Luo et al. present a SOM based se-
quence analysis system for the spam filtering task. A kNN
classifier is designed to work with SOM. It is reported that
proposed system is superior to the naive Bayesian filters.
Cárpinteiro et al. propose in [6] a multi-layer perceptron
model to classify ham and spam e-mails. Several models of
multi-layer perceptron are evaluated. The experiments show
that a good ANN-based spam filter need to elaborate on its
architecture and learning strategy. In [38], two linear classi-
fiers, Perceptron and Winnow, are integrated for spam filter-
ing. A hybrid method which combines neural networks and
genetic algorithms for feature selection is presented in [15]
for robust detection of spam. Most of these work report a
good training accuracy can be achieved using neural net-
works. Unfortunately, they use keyword-based features from
static datasets and do not provide further information on
their time-robustness.
Researches on e-mail classification from the perspective
of user behaviors are also studied, such as [1, 16]. It is as-
sumed that e-mail users have specific behaviors in handling
their e-mails; so that the e-mail which most users take sim-
ilar actions on it would likely belong to the same class, i.e.,
ham or spam. Hershkop [19] present a framework called
Email Mining Toolkit(EMT) for extracting models of user’s
behaviors from email corpora about what actions the e-mail
users take in sending and receiving e-mails. A number of
anomaly detection algorithms are embedded in the system to
model the user’s email behavior in order to classify emails.
An artificial immune-inspired method is presented in [42],
which continuously collects and analyzes relevant spam e-
mails. The authors analyze the “behaviors” of spam e-mails
according to the reliability of sender’s IP, SMTP ID number,
and reply addresses and give a score of similarity for cluster-
ing spam accordingly. Zhang et al. present in [43] a method
for recognizing spam behaviors using decision trees learned
from data maintained during transfer sessions. They exam-
ine if IP associated with an incoming e-mail is abnormal,
faked, or unreachable. Notably, the so-called behaviors they
defined are not the same as what we defined here. Accord-
ing to the literature, investigating user behaviors, either in
editing, receiving, or distributing e-mails, for handling doc-
uments and e-mails is a feasible approach.
7 Discussions and conclusions
We have presented in this paper a novel method for spam
filtering. Instead of using keywords, this study analyzes the
120 C.-H. Wu, C.-H. Tsai
spamming behaviors and extracts the representative ones as
features for spam classification. Spamming behaviors are
identified according to the information recorded in headers
and syslogs of e-mails. An enhanced BPNN model is pre-
sented, which builds classification models with feature bi-
ases that reflect the importance of behavior-based features.
Our method can be considered as a two-pass classifica-
tion: (1) determining the spamming behaviors of incoming
e-mails and (2) identifying spam according to the behavior-
based features. Since spamming behaviors are changed in-
frequently, compared with the change of keywords in spam,
spam filtering using behavior-based features is time-robust.
It may not be possible to detect, totally and always exactly,
all spam using a single technique. Hybridizing several work-
able techniques for anti-spamming is essential. The pro-
posed behavior-based features can be integrated with other
classification algorithms for advanced spam classification.
Although our method seemingly gives a promising solution
to spam filtering, there are several subjects should be stated.
• There are only 26 features selected from the headers and
syslogs of e-mails. These features are selected since they
are used most frequently by MUAs/MTAs. Potential fea-
tures may exist. In the future, selecting features can fur-
ther consider their importance using matrices other than
appearing frequencies.
• The procedures invoked for converting plain-text val-
ues of headers and syslogs can be further improved. For
example, determining if a string is randomly generated,
partitioning office- and non-office hours, checking if an
account or domain is legal, etc., need more engineering
considerations.
• Though behavior-based features are resistant to the chan-
ge of time, they do change slowly. Some features may be
out of date after a period of time; and hence, the feature
biases should be changed dynamically.
• The unstable training time and the determination of pa-
rameters associated with the learning algorithm are trou-
blesome in BPNN applications. The number of features
and effective training samples dominate the training effi-
ciency. We are broadly collecting e-mails for finding the
features that effectively improve the training efficiency.
Currently, the parameters associated with the BPNN, such
as α, η, and β in (5) and (6), are determined heuristically.
Studies on determining these values are included in the
future work.
• We do not compare the performance of our method with
commercial products such as the ones adopted by hotmail
or yahoo. To our best knowledge, commercial products
usually perform keyword-based filtering with world-wide
blacklists. Since we need information from syslog and can
not get complete blacklists and filters used by hotmail or
yahoo, such comparisons are not discussed.
• The focus of this paper is on spam classification accord-
ing to spamming behaviors other than keywords. It hap-
pens that re-training the neural networks is necessary
when new patterns, no matter behavior-based or keyword-
based, arise. Since selecting and instantiating behavior-
based features are done by heuristics through surveys on
massive spam e-mails, re-training the neural network is
needed for new features. Techniques of incremental train-
ing BPNNs may partially solve this problem. This could
be our future work.
Acknowledgements The authors thank anonymous reviewers for
their very useful comments and suggestions.
References
1. Aris A, Gemmell J, Lueder R (2004) Exploiting location and time
for photo search and storytelling in Mylifebits. Technical report
MSR-TR-2004-102, Microsoft Research
2. Attoh-Okine NO (1999) Analysis of learning rate and momentum
term in backpropagation neural network algorithm trained to pre-
dict pavement performance. Adv Eng Softw 30(4):291–302
3. Bezerra GB, Barra TV, Ferreira HM, Knidel H, de Castro LN, Von
Zuben FJ (2006) An immunological filter for spam. In: Proceed-
ings of the international conference on artificial immune systems.
Oeiras, Portugal, pp 446–458
4. Blanzieri E, Bryl A (2006) A survey of anti-spam techniques.
Technical report DIT-06-056, Informatica e Telecomunicazioni,
University of Trento
5. Camastra F (2005) Kernel methods for clustering. In: Proceedings
of the international workshop on natural and artificial immune sys-
tems, pp 1–9
6. Carpinteiro OAS, Lima I, Assis JMC, de Souza ACZ, Moreira
EM, Pinheiro CAM (2006) A neural model in anti-spam systems.
In: Lecture notes in computer science, vol 4132. Springer, Berlin,
pp 847–855
7. Chaitin GJ (1974) Information theoretic limitations on formal sys-
tems. J Assoc Comput Mach 21(3):403–424
8. Clark J, Koprinska I, Poon J (2003) A neural network based ap-
proach to automated e-mail classification. In: Proceedings of the
2003 IEEE/WIC international conference on Web intelligence.
Halifax, Canada, October 2003, pp 702–705
9. Costales B, Allman E (2002) Sendmail, 3rd edn. O’Reilly & As-
sociates, Sebastopol
10. Crawford E, Kay J, McCreath E (2001) Automatic induction of
rules for e-mail classification. In: Proceedings of the 6th Aus-
tralasian document computing symposium. Coffs Harbour, Aus-
tralia, 7 December 2001, pp 13–20
11. Delany SJ, Cunningham P, Doyle D, Zamolotskikh A (2005) Gen-
erating estimates of classification confidence for a case-based
spam filter. In: Munoz-Avila H, Ricci F (eds) Proceedings of the
international conference on case-based reasoning. Chicago, Illi-
nois, USA, pp 177–190
12. Dreyfus G (2005) Neural networks, 1st edn. Springer, New York
13. Fdez-Riverola F, Iglesias EL, Díaz F, Méndez JR, Corchado JM
(2007) Applying lazy learning algorithms to tackle concept drift
in spam filtering. Expert Syst Appl 33(1):36–48
14. Garner S (1995) WEKA: The waikato environment for knowledge
analysis. In: Proceedings of the New Zealand computer science
research students conference. New Zealand, pp 57–64
Robust classification for spam filtering by back-propagation neural networks using behavior-based features 121
15. Gavrilis D, Tsoulos IG, Dermatas E (2006) Neural recognition and
genetic features selection for robust detection of e-mail spam. In:
Antoniou G, Potamias G, Spyropoulos C, Plexousakis D (eds) Pro-
ceedings of the 4th Helenic conference on AI, Heraklion, Crete,
Greece. Lecture notes in computer science, vol 3955. Springer,
Berlin, pp 498–501
16. Gemmell J, Williams L, Wood K, Bell G, Lueder R (2004) Passive
capture and ensuing issues for a personal lifetime store. In: Pro-
ceedings of the first ACM workshop on continuous archival and
retrieval of personal experiences (CARPE04). New York, USA,
pp 48–55
17. Grimes GA (2007) Compliance with the CAN-SPAM Act of 2003.
Commun ACM 50(2):56–62
18. Haykin S (1998) Neural networks: A comprehensive foundation,
2nd edn. Prentice Hall, New York
19. Hershkop S (2006) Behavior-based email analysis with applica-
tion to spam detection. Ph.D. thesis, Columbia University
20. Hoanca B (2006) How good are our weapons in the spam wars?
IEEE Technol Soc Mag 25:22–30
21. Hopkins M, Reeber E, Forman G, Suermondt J (2005) Spam e-
mail database from UCI machine learning repository. http://www.
ics.uci.edu/~mlearn/MLRepository.html
22. Jiang E (2006) Learning to semantically classify email messages.
In: Proceedings of the international conference on intelligent com-
puting. Kunming, China, pp 700–711
23. Kanaris I, Kanaris K, Stamatatos E (2006) Spam detection us-
ing character n-grams. In: Antoniou G et al (eds) Proceedings of
the Hellenic conference on artificial intelligence. Heraklion, Crete,
Greece, pp 95–104
24. Lai C-C, Tsai M-C (2004) An empirical performance comparison
of machine learning methods for spam e-mail categorization. In:
Proceedings of the fourth international conference on hybrid intel-
ligent systems. Kitakyushu, Japan
25. Luo X, Zincir-Heywood N (2005) Comparison of a SOM based se-
quence analysis system and naive Bayesian classifier for spam fil-
tering. In: Proceedings of international joint conference on neural
networks, vol 4. Montreal, Canada, pp 2571–2576
26. Mark B, Perrault RC (2005) Enron email dataset. http://www-2.
cs.cmu.edu/~enron/
27. Massey B, Thomure M, Budrevich R, Long S (2005)
The PSAM project. http://nexp.cs.pdx.edu/~psam/cgi-bin/view/
PSAM/CorpusSets
28. Mendez JR, Fdez-Riverola F, Iglesias EL, Diaz F, Corchado JM
(2006) Tracking concept drift at feature selection stage in spam
hunting: An anti-spam instance-based reasoning system. In: Roth-
Berghofer TR et al (eds) Proceedings of the European conference
on case-based reasoning. Fethiye, Turkey, pp 504–518
29. Özgür L, Gungor T, Gurgen F (2004) Adaptive anti-spam filter-
ing for agglutinative languages: a special case for Turkish. Pattern
Recognit Lett 25(16):1819–1833
30. Pampapathi R, Mirkin B, Levene M (2006) A suffix tree approach
to anti-spam email filtering. Mach Learn 65:309–338
31. Salton G, Buckley C (1988) Term-weighting approaches in auto-
matic text retrieval. Inf Process Manag 24(5):513–523
32. SpamArchive.org. (2005) Spamarchive project. http://
spamarchive.org/
33. SpamLinks.net. (2005) Spam links—spam archives. http://
spamlinks.net/filter-archives.htm
34. The Spamhaus Project Ltd. (2007) The definition of spam.
http://www.spamhaus.org/definition.html
35. Trend Micro, Inc. (2005) Definition of “spam”. http://www.
mail-abuse.com/spam_def.html
36. Tseng L-S, Wu C-H (2003) Detection of spam e-mails by analyz-
ing the distributing behaviors of e-mail servers. In: Proceedings
of the third international conference on hybrid intelligent systems.
Kitakyushu, Japan, pp 1024–1033
37. U.S. Senate and House of Representatives (2004) CAN-SPAM Act
of 2003 (S. 877). http://www.cauce.org/S877.pdf
38. Wang B, Jones GJF, Pan W (2006) Using online linear classifiers
to filter spam emails. Pattern Anal Appl 9:339–351
39. Wang F, You Z, Man L (2006). Immune-based peer-to-peer model
for anti-spam. In: Proceedings of the international conference on
intelligent computing. Kunming, China, pp 660–671
40. Wang H-B, Yu Y, Liu Z (2005). SVM classifier incorporating fea-
ture selection using GA for spam detection. In: Proceedings of the
2005 international conference on embedded and ubiquitous com-
puting. Nagasaki, Japan, pp 1147–1154
41. Webb S, Chitti S, Pu C (2005). An experimental evaluation of
spam filter performance and robustness against attack. In: Pro-
ceedings of the 1st international conference on collaborative com-
puting: networking, applications and worksharing. San Jose, CA,
USA, pp 19–21
42. Yue X, Abraham A, Chi Z-X, Hao Y-Y, Mo H (2007) Artificial im-
mune system inspired behavior-based anti-spam filter. Soft Com-
put 11:729–740
43. Zhang X, Liu J, Zhang Y, Wang C (2006). Spam behavior recogni-
tion based on session layer data mining. In: Wang L et al (eds) Pro-
ceedings of third international conference on fuzzy systems and
knowledge discovery. Xian, China, pp 1289–1298
Chih-Hung Wu received the B.S. degree in En-
gineering Science from National Cheng-Kung
University in 1990, and the M.S. and Ph.D. de-
grees in Electronic Engineering from National
Sun Yat-Sen University, Taiwan, in 1992 and
1996, respectively. He is currently an Asso-
ciate Professor with the Department of Electri-
cal Engineering, National University of Kaoh-
siung. Taiwan. His research interests include
Artificial Intelligence, Knowledge Engineering,
Data mining, Soft-Computing, Global Positioning System, Evolv-
able Hardware, and Intelligent Robotics. He is a Member of IEEE—
Institute of Electrical and Electronics Engineers (Computer, SMC,
CI, GRS Societies), ISCA—International Society for Computers and
Their Applications, IAENG—International Association of Engineers,
TAAI—Taiwanese Association for Artificial Intelligence, TFSA—
Taiwan Fuzzy Systems Association and CSIM—Chinese Society of
Information Management. He also has been serving as Guest Editor,
Member of Editorial Board, Program Committees Member for many
International Conferences and Symposiums.
