 
 
Authorship Attribution of Ancient Texts Written by 
Ten Arabic Travelers Using Character N-Grams 
 
 Siham OUAMOUR 
USTHB University 
siham.ouamour@gmail.com, siham.ouamour@uni.de 
Halim SAYOUD 
USTHB University 
halim.sayoud@gmail.com, halim.sayoud@uni.de 
  
Abstract—In this paper the authors investigate the authorship 
of some old Arabic books that are written by ten ancient Arabic 
travelers. Hence, several experiments of authorship attribution 
are conducted on these Arabic texts, by using different features 
such as characters, character-bigrams, character-trigrams and 
character-tetragrams. Furthermore, four different classifiers are 
employed, namely: Stamatatos distance, Manhattan distance, 
Multi Layer Perceptron (MLP) and Support Vector Machines 
(SVM). 
For the evaluation task, several experiments of authorship at-
tribution, using those features and classifiers, are conducted on 
the Arabic dataset (called AAAT), which contains 3 short texts 
from every book. Results show good authorship attribution per-
formances with an optimal score of 90% of good attribution. 
Moreover, this investigation has revealed interesting results con-
cerning the Arabic language.    
Keywords—Authorship attribution, Text-mining, Artificial Intel-
ligence, Arabic language, Character N-Grams. 
 
I. INTRODUCTION 
Stylometry has attracted a lot of interest during the last years, 
especially (but not exclusively) for security purposes. Author-
ship Attribution (AA) is a research field of stylometry, which 
consists in identifying the author(s) of a piece of text by using 
some techniques of text mining. The longer is the text; the 
better is the identification accuracy. 
Stylometry or Authorship recognition can be divided into 
several related fields that are: 
- Authorship attribution (AA) or identification: consists in 
identifying the author(s) of a set of different texts; 
- Authorship verification: consists in checking whether a 
piece of text is written or not by an author who claimed to be 
the writer; 
- Authorship discrimination: consists in checking if two dif-
ferent texts are written by a same author or not [1]; 
- Plagiarism detection: in this research field we look for the 
sentences or paragraphs that are taken from another author [2]; 
- Text indexing and segmentation: when several texts, 
which are issued from different authors, are concatenated in a 
form of a global book or forum text, one particular interest in 
stylometry is to segment the global text into homogeneous 
segments (each segment or paragraph contains the contribu-
tion of only one author) by giving the name of the appropriate 
author in each text segment (paragraph) [3]; 
In general, individuals have distinctive ways of speaking 
and writing, and there exists a long history of linguistic and 
stylistic investigation into authorship attribution.  
Although several works are reported for the English, Greek 
and Hebrew languages [2] [3] [4] [5], the authors have not 
found any serious research work made with Arabic texts. That 
is why, they propose in the present paper an overall research 
work of AA (Authorship Attribution) that handles 30 different 
texts written by 10 ancient Arabic travelers who wrote several 
books describing their travels. 
A special Arabic corpus has been built by the authors in or-
der to assess several features and classifiers that are usually 
employed in stylometry. 
The experiments of AA are described in the following sec-
tions. 
In section two, we describe the text corpus which was built 
to undergo the experiments. Section three defines the different 
classifiers used for the task of authorship attribution. The dif-
ferent results are presented in the forth section. Finally, we 
conclude with a conclusion, future work and some references. 
 
II. DESCRIPTION OF THE TEXT DATASET 
The text dataset, called AAAT corpus (i.e. Authorship at-
tribution of Ancient Arabic Texts) [6], is built by the authors of 
this paper for a purpose of authorship attribution. It contains 
10 groups of old Arabic texts that are extracted from 10 differ-
ent Arabic books and which belong respectively to 10 differ-
ent ancient authors (table1). Each group contains 3 different 
texts that are written by the same author, which means that 
each group corresponds to only one ancient author. This set of 
texts has been collected in 2011 from “Alwaraq library” (fig-
ure 1).  
 
The different ancient texts are summarized in table 1.  
 
 
 
Table 1. Description of the different books. 
Author name Date AD Book title Book subject 
Ibn Batuta  1325-1352 Travels of Ibn Batuta  Travels 
ابن بطوطةرحلة    ابن بطوطة   
Ibn Jubayr  1182-1185 Travels of Ibn Jubayr  Travels 
  رحلة ابن جبير  ابن جبير
Nasser Khasru 1045  Book of the Travels  Travels 
  سفر نامه  ناصر خسرو
Ibn Fathlan 921  Travels of Ibn Fathlan  Travels 
  رحلة ابن فضالن  ابن فضالن 
Ibn Al Mujawer  1233  History of the Mustabsir Travels 
  تاريخ المستبصر  ابن المجاور
Al Yussee  1684  Conferences in language and litera-
ture  
Travels 
  المحاضرات في اللغة و األدب  اليوسي
Lessan Addin  1684  Khatrat Al Tife during the tra Travels 
  vel of the winter and summer   
بن  لسان الدين 
 الخطيب
  خطرة الطيف في رحلة الشتاء و الصيف 
Al Alussi  1852  Strangeness of travels  Travels 
  غرائب االغتراب  اآللوسي
Al Hamawi  
 
1542-1608 Hady Alathaan Annajdia to the 
Egypt houses  
Travels 
الحمويمحب الدين     حادي األظعان النجدية إلى الديار المصرية  
Al Balwi 
 
Before 1364 Taj Almafraq Fi Tahlyet oriental 
scientist  
Travels 
  تاج المفرق في تحلية علماء المشرق  البلوي 
 
Table 2 gives the number of words (tokens) contained in 
each text. As we can see, each author is presented by 3 differ-
ent texts. The texts are very short: the average text length is 
about 550 words; furthermore some texts have less than 300 
words. This situation involves bad experimental conditions, 
since it has been shown in previous research works conducted 
by Eder [7] and Signoriello [8] that the minimum number of 
words per text should be 2500 words in order to obtain a good 
attribution results.  
We have chosen to use short text documents in order to 
evaluate the different classifiers using the Character N-Grams. 
In fact, when short texts are used, the AA performances de-
crease and it becomes easy to evaluate the different classifiers 
(i.e. avoiding high scores). 
 
Table 2. Size of the texts in terms of words (number of words in the text). 
Size of the texts in terms of words 
Author designation Text 1 Text 2 Text 3 Average size 
Author 1 630 605 308 514 
Author 2 575 540 598 571 
Author 3 657 800 290 582 
Author 4 599 593 593 595 
Author 5 459 511 722 564 
Author 6 511 559 636 568 
Author 7 599 460 541 533 
Author 8 515 653 578 582 
Author 9 322 629 548 551 
Author 10 591 345 353 429 
 
 
Fig. 1. Ancient portrait and sheet of paper containing a text of Au-
thor3 (Nasser Khasru) 
III. DESCRIPTION OF THE CLASSIFIERS 
The different experiments of authorship attribution are made 
by using one of the four classifiers:  
Stamatatos distance, Manhattan distance, Multi Layer Per-
ceptron (MLP) and Support Vector Machines (SVM). Moreo-
ver, the Character N-Grams are chosen as features. 
Brief definitions of the different classifiers are given below: 
A. Manhattan distance 
The Manhattan distance [1] between two vectors f and g is 
given by the following formula: 
 
 |) − 	)|



          
  (1) 
 
Where n is the length of the vector. 
B. Stamatatos distance 
The Stamatatos distance [9] between two vectors f and g is 
given by the following formula: 
                                   
           [2) − 	))/) + 	))]



                 
   (2) 
 
Where n is the length of the vector. 
C. Multi-Layer Perceptron (MLP) 
The MLP is a neural network classifier that uses the errors of 
the output to train the neural network [10]. The MLP can uses 
different back-propagation schemes to ensure the training of 
the classifier. The MLP is trained by the two first texts for 
every author, whereas the remaining text (the third one) is 
used for the testing task. 
 
D. The Sequential Minimal Optimization based Support 
Vector Machine (SMO-SVM) 
The SVM is a very accurate classifier that uses bad examples 
to form the boundaries of the different classes [11]. The SMO 
algorithm is only used to speed up the training of the SVM 
[12]. The SVM is trained by the two first texts for every au-
thor, whereas the third one is used for the testing task. 
 
IV. EXPERIMENTS OF AUTHORSHIP ATTRIBUTION 
In this section, we present the different experiments of author-
ship attribution on an old Arabic set of texts that were written 
by old Arabic travelers.  
Several features are tested: characters, character Bigram, 
character Trigram and character Tetragram. 
The different classifiers are employed by using the jgaap 
tool kit [1] for the task of authorship attribution. Furthermore 
for the training classifiers (MLP and SVM), the two first texts 
of each author are used for the training step and the third one 
is used for the testing one. 
 
 
Fig. 2.     Authorship Attribution Precision (AAP) for the different 
classifiers. 
Figure 2 and table 3 display the precision in % that is got by 
the four classifiers with the different features. As we can ob-
serve, we obtain a score of good attribution of 90% by the 
Manhattan Centroid distance using the character tetragram. 
This score is the best score for all the classifiers and all the 
features that have been employed in this experiment.  
Concerning the classifiers, we remark that the best scores 
for the distances (Stamatatos and Manhattan) are obtained 
with character tetragram when for the training machines (MLP 
and SVM) the best scores are given with the two features: 
character bigram and trigram. We remark also that by using 
the Manhattan distance, the score increases with the size of 
character n-grams.  
0
10
20
30
40
50
60
70
80
90
100
S
ta
m
at
at
o
s 
C
en
tr
o
id
 
d
is
ta
n
ce
M
an
h
at
ta
n
 
C
en
tr
o
id
 
d
is
ta
n
ce
M
L
P
S
M
O
-
S
V
M
Character
Character  
Bigram
Character   
Trigram
Character  
Tetragram
A
u
th
o
rs
h
ip
 A
tt
ri
b
u
ti
o
n
 P
re
ci
si
o
n
in
 %
 
 
Table 3.       Percentage of good authorship attribution. The symbol * means that only the 600 most frequent features are used. 
 
 
 
 
 
 
 
 
 
 
 
Fig. 3.     Best scores of authorship attribution (AAP) given by the 
different classifiers. 
Figure 3 summarizes the overall best results given by the dif-
ferent classifiers for the experiment of authorship attribution 
of old Arabic texts using one feature from the character n-
grams. We remark that the Manhattan distance seems to be 
very accurate, with a score of 90%, followed by the training 
machines (MLP and SVM), with a score of 80%, and the 
Stamatatos distance, with a score of 60%.    
 
It is important to mention that an accuracy of 90% with 
short text documents is relatively high, since several previous 
works showed that the minimum amount of text that is re-
quired for a good A.A. is at least 2500 words per text [7][8]. 
In this investigation, very short texts are used, ranging from 
only 209 words to a maximum of 800 words in the text. 
 
Note that the Authorship Attribution Precision (AAP) is 
calculated, in our investigation, by using the following formu-
la: 
                                     
 AAP =  

     !! "
! 
  
    
   (3) 
V. CONCLUSION 
In this research work a new authorship attribution task has 
been experimented on an old Arabic set of texts that were 
written by ancient Arabic travelers. The character n-gram 
features have been tested for the Arabic language and particu-
larly for very short texts. These two particularities (Arabic 
language and small text size) represent the main originality of 
this research work. Hence, four different classifiers were used 
for the attribution task with the different features (Manhattan 
and Stamatatos distances, MLP and SVM learning machines) 
as described in section 3. The MLP and SVM are trained by 
using 20 texts and tested on 10 different texts (not present in 
the training dataset). 
 
Experiments of authorship attribution, for each classifier 
and each feature, have shown the following important points: 
• Character n-grams are very interesting for the task of au-
thorship attribution, since the score reaches the 90% of 
good attribution on a corpus containing small texts (maxi-
mum of 800 words in the text).  
• Character tetragrams seem to be suitable for the used dis-
tances (Stamatatos and Manhattan distances), while for the 
training machines (MLP and SVM), character bigrams and 
trigrams are the most suitable ones. 
• Manhattan centroid distance shows excellent performances 
in this experiment of A.A, with a score of 90% when using 
the character tetragram, followed by the MLP and SVM 
(with a score of 80%), and Stamatatos distance (score of 
only 60%). 
• The precision of Manhattan distance increases with the 
length of the character n-grams:  scores of 30%, 40%, 70% 
and 90% are obtained by using 1-gram, 2-gram, 3-gram and 
4-gram respectively. 
• Although the text size was too small (between 209 words 
and 800 words in the text), the AAP precision seems inter-
esting (80 ~ 90% of good attribution); 
 
This new work of authorship attribution, which represents a 
rare research work on Arabic language, shows a real motiva-
0%
10%
20%
30%
40%
50%
60%
70%
80%
90%
100%
Stamatatos 
Centroid 
distance
Manhattan 
Centroid 
distance
MLP SMO-SVM
A
u
th
o
rs
h
ip
 A
tt
ri
b
u
ti
o
n
 P
re
ci
si
o
n
A
A
P
 i
n
 %
Classifier
   Classifier Character Character  
Bigram 
Character   
Trigram 
Character  
Tetragram 
Stamatatos distance 10% 40% 60% 60% 
Manhattan distance 30% 40% 70% 90% 
MLP 60% 80% 80%* 60%* 
SMO-SVM 60% 80% 80%* 70%* 
tion and interest for this type of language. It also shows that 
the rules are almost the same for both English and Arabic (for 
the character level). Consequently, it should be possible to 
exploit most of the knowledge that has been acquired with the 
Latin or Greek language (regarding the character level), in 
order to employ it in Arabic text-mining applications. 
Finally, an important question would be: is it reasonable to 
generalize this conclusion and say that all the stylistic results 
and knowledge that have been acquired over time for the Latin 
languages could be applied in Arabic? 
 
ACKNOWLEDGMENT 
The authors wish to warmly thank: Dr G. Tambouratzis and 
Dr M. Vassiliou (from the ILSP of Athens), Dr E. Stamatatos 
(from Aegen University of Samos), Prof M. Oakes (from Sun-
derland University) and Dr P. Juola (from Duquesne Universi-
ty). 
 
REFERENCES  
1. H. Sayoud, “Author Discrimination between the Holy Quran and 
Prophet’s Statements”, Literary and Linguistic Computing, Vol-
ume 27 Issue 4, pp.427-444, 2012. 
2. R. Küppers, and S. Conrad, “A Set-Based Approach to Plagia-
rism Detection”, PAN 2012 Lab Uncovering Plagiarism, Au-
thorship, and Social Software Misuse held in conjunction with 
the CLEF 2012, 17-20 September, Rome, Italy, 2012.   
3. D. Forest, “Application de Techniques de Forage de Textes de 
Nature Prédictive et Exploratoire à des Fins de Gestion et 
d’Analyse Thématique de Documents Textuelles Non Structurés. 
Thèse de Doctorat, Université du Québec à Montréal, Juin 2006. 
4. P. Juola, “Authorship Attribution, a survey and technical mono-
graph on authorship attribution, the process of inferring the au-
thor or author's characteristics from the text of a document,” 
published through NOW Publishers, 2006. 
5. G. Tambouratzis, S. Markantonatou, N. Hairetakis, M. 
Vassiliou, D. Tambouratzis & G. Carayannis, “Discriminating 
the Registers and Styles in the Modern Greek Language,” Pro-
ceedings of the Workshop on Comparing Corpora (held in con-
junction with the 38th ACL Meeting), Hong Kong, China, 7 Oc-
tober. pp. 35-42, 2000. 
6. S. Ouamour, H. Sayoud, Authorship Attribution of Ancient 
Texts Written by Ten Arabic Travelers Using a SMO-SVM 
Classifier. The 2nd International Conference on Communica-
tions and Information Technology (ICCIT): Digital Information 
Management, Hammamet, Tunisia 2012. pp 37-40. 
7. M. Eder, “Does size matter? : autorship attribution, short sam-
ples, big problem,” In Digital humanities 2010 conference, pp. 
132-135, London, 2010.   
8. D. J. Signoriello, S. Jain, M. J. Berryman, D. Abbott, “Advanced 
text authorship detection methods and their application to bibli-
cal texts,” Proceedings of SPIE (2005), Volume: 6039, Publish-
er: Spie, pp. 163–175, 2005.  
9. E. Stamatatos, Author identification using imbalanced and lim-
ited training texts. In Proceedings of the 4th International Work-
shop on Text-based Information Retrieval, 2007, pp. 237-241. 
10. H. Sayoud, “Automatic speaker recognition – Connexionnist ap-
proach”, PhD thesis, USTHB University, Algiers, 2003. 
11. Ian H. Witten, Eibe Frank, Len Trigg, Mark Hall, Geoffrey 
Holmes, and Sally Jo Cunningham, “Weka: Practical machine 
learning tools and techniques with Java implementations,” In 
Nikola Kasabov and Kitty Ko, editors, Proceedings of the 
ICONIP/ANZIIS/ANNES'99 Workshop on Emerging Knowledge 
Engineering and Connectionist-Based Information Systems, pp. 
192-196, Dunedin, New Zealand, 1999. 
12. S.S. Keerthi, S.K. Shevade, C. Bhattacharyya & K.R.K, 
“Murthy, Improvements to Platt’s SMO Algorithm for SVM 
Classifier Design”, Neural Computation 13, pp. 637–649, 2001. 
 
 
 
 
 
