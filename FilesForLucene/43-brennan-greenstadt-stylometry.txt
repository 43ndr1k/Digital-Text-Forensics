Practical Attacks Against Authorship Recognition
Techniques
Michael Brennan & Rachel Greenstadt
Dept. of Computer Science, Drexel University
{mb553,greenie}@cs.drexel.edu
Abstract.The use of statistical AI techniques in authorship recognition (or sty-
lometry) has contributed to literary and historical breakthroughs. These successes
have led to the use of these techniques in criminal investigations and prosecutions.
However, few have studied adversarial attacks, motivated by a desire to protect
anonymity and privacy in a variety of scenarios, and their devastating effect on
the robustness of existing classification methods. This paper presents a framework
for adversarial attacks including obfuscation attacks, where a subject attempts
to hide their identity and imitation attacks, where a subject attempts to frame
another subject by imitating their writing style. The major contribution of this
research is that it demonstrates that both attacks work very well. The obfuscation
attack reduces the effectiveness of the techniques to the level of random guess-
ing and the imitation attack succeeds with 68-91% probability depending on the
stylometric technique used. These results are made more significant by the fact
that the experimental subjects were unfamiliar with stylometric techniques, with-
out specialized knowledge in linguistics, and spent little time on the attacks. This
paper also provides another significant contribution to the field in using human
subjects to empirically validate the claim of high accuracy for current techniques
(without attacks) by reproducing results for three representative stylometric meth-
ods. Current work based on these results that looks deeper into implications of
stylometry on privacy and anonymity on the Internet is also discussed.
1 Introduction
(Disclaimer – this work has been accepted for publication in Innovative Appli-
cations of Artificial Intelligence (IAAI 2009) which will take place in Pasadena,
CA July 11-14, 2009. This workshop paper provides additional focus on privacy
and current work that is not present in the version published with IAAI).
The field of stylometry (or authorship recognition) has been used to great
effect by historians and literary detectives to identify the authors of the Feder-
alist Papers, Civil War letters, and Shakespeare’s plays [10, 14]. While stylo-
metric methods existed before computers and artificial intelligence techniques,
the field is currently dominated by AI techniques such as neural networks and
statistical pattern recognition. In many historical matters, authorship has been
unintentially lost to time and it can be assumed that the authors did not have
the knowledge or inclination to attempt to hide their linguistic style. However,
this may not be the case for modern authors who wish to hide their identity. For
example, stylometric techniques are currently used as evidence in courts of law
in Britain, the U.S., and Australia [13].
In some criminal, civil, and security matters, language can be evidence...When
you are faced with a suspicious document, whether you need to know
who wrote it, or if it is a real threat or a real suicide note, or if it is too
close for comfort to some other document, you need reliable, validated
methods. [6]
But the need for hiding the writing style of an author goes beyond criminal
courts. The motivation for hiding one’s writing extends to those who use the In-
ternet to publish anonymously. The goal of these authors is to keep their identity
private and attacking stylometry is a means to accomplish that goal.
This study seeks to discover how robust current methods of stylometry are
in dealing with adversarial attacks. Until now the field has focused on creating
new methods that attempt to classify existing unknown works sets of authors,
with little attention being given to the question of what happens when an ad-
versary tries to intentionally circumvent the classification system that has been
established. Recently attention has been brought to this problem. Dr. Patrick
Juola, an expert in computer linguistics at Duquesne University, discussed the
importance of research in this area in his 2008 book on authorship attribution,
stating “there is obviously great potential for further work here” [8].
This study looks at three specific approaches and their resilience against
two types of adversarial attacks. The first, which will be referred to as an ob-
fuscation attack, is when an author attempts to write a document in such a
way that their personal writing style will not be recognized. The second, which
will be referred to as an imitation attack, is when an author attempts to write
a document such that their writing style will be recognized as that of another
specific author. The three methods of stylometry investigated were chosen for
their variety in both metrics and methodology. The study found that none of the
methods performed better than chance in identifying the correct author in either
of these attacks. Additionally, the imitation attacks were widely successful, at-
tributing authorship of the passages to the intended victim of the attack in most
instances.
This study also provides a clear validation of three prominent stylomet-
ric methods using a significantly larger data set than former studies. Further-
more, our study involves more original authors than most other stylometric
studies. Our results thus provide further evidence of their effectiveness in non-
adversarial scenarios. Our experimental design provides a framework for identi-
fying adversarial attacks and analyzing the adversarial risk of stylometric meth-
ods. Finally, we show that even naive users lacking in expertise in the field of
stylometry, linguistics, or even literature can successfully perform imitation and
obfuscation attacks.
The findings of this research indicate that the studied techniques are in-
sufficient to determine authorship in an adversarial context. We call upon the
research community to refine our framework for testing methods of stylometry
against adversarial attacks so it can play a role in determining the effectiveness
of existing and future work in the field.
We have continued research in this area by looking at the impact of this
research on privacy and anonymity. This additional work, which explained in
section 5 and is not present in the IAAI version, is looking at the potential for
stylometry to effectively de-anonymize internet forum communication and how
adversarial attacks can be adopted to stifle attempts at doing so. The PET (Pri-
vacy Enhancing Technologies) community has focused on protecting location
anonymity, but this research shows how the linguistic content of messages can
also negatively impact anonymity. We will investigate how this can be mitigated,
initially through the conscious attempts to hide one’s writing style exhibited in
this study and eventually by automatically performing these obfuscation attacks.
2 Background & Related Work
The classic example case in the field of Stylometry is that of the Federalist pa-
pers. 85 papers were published anonymously in the late 18th century to persuade
the people of New York to ratify the American Constitution. The authorship of
12 of these papers was heavily contested [14]. To discover who wrote the un-
known papers, researchers have analyzed the writing style of the known authors
and compared it to that of the papers of unknown authorship. The features used
to determine writing styles have been quite varied. Original attempts looked at
the length of words, whereas later attempts looked at pairs of words, vocabu-
lary usage, sentence structure, function words, and so on. Most studies show the
author was James Madison.
It is important to note that stylometry is not handwriting analysis; it only
looks at the linguistic style of the text.
There are some interesting hurdles in the field of Stylometry that, while
far from unique, certainly are not common. One such aspect is the fact that
the writing style of individuals tends to change over time, and compensating for
that is a difficult task. Over time, the entire body of test data for a specific author
slowly becomes dated and less reliable.
There is still no consensus on what method of stylometry is the most ef-
fective or even which features are the most important. The only true consensus
is that the method chosen should reflect the text that is going to be classified.
For example, counting the number of semicolons might be appropriate for clas-
sifying the author of code but not for classifying essays written by children in
elementary school.
A number of resources are available that give an overview of stylometry
methods that exist [11, 19], and focus on the state of the field as it relates to
computer science and computer linguistics [8]. Artificial Intelligence has been
embraced in the field of stylometry, leading to more robust classifiers using ma-
chine learning and other AI techniques [17, 5, 18]. There has also been some
work on circumventing attempts at authorship attribution [7, 9] and looking at
stylometry as a method of communication security [2], but these do not deal
with malicious attempts to circumvent a specific method. Some research has
looked at imitation of authors but not in any widespread study, such as [16]
who compared the work of Gilbert Adair’s pastiche of Lewis Carroll’s Alice in
Wonderland, and found mixed results. There has also been some work done that
looks into the impact of stylometry on pseudonymity [15] and author segmen-
tation [1].
3 Methodology
Countless methods of authorship attribution have been developed. Since there is
no consensus on which available method is the best, three specific approaches
were selected for their variety in both methodology and the features they used
for comparison. Additionally, a strict process was set up to collect the samples
used in this study for both the training text and the example attacks.
3.1 Study Format and Setup
The results of this study are based upon the participation of 15 individual au-
thors. This is significantly larger than most studies in the field which generally
deal with 2-4 authors [17, 4, 14, 3]. There were three basic elements to their par-
ticipation.
First, each author had to submit approximately 5000 words of pre-existing
sample writing. Each writing sample had to be from some sort of formal source,
such as essays for school, reports for work, and other professional and aca-
demic correspondence. This was intended to eliminate slang and abbreviations,
instead concentrating on consistent, formal writing style of everyone involved.
This also helped to limit possible errors that are not a result of the malicious at-
tack attempts but nonetheless could have an effect on the accuracy of the author-
ship attribution. Participants submitted anywhere from 1 to 5 sample documents
which were combined and split into 500 word sample passages.
Second, each author had to perform an obfuscation attack in which they
try to hide their identity through their writing style. This was accomplished by
writing a new 500 word passage on a specific topic. The task given to them was
to write a description of their neighborhood directed at a friend who had never
been there. This task was designed to encourage thought about the writing style
and not weigh down the author with having to think about a complex topic or
be too creative with their content.
Third, each author had to perform an imitation attack in which they try to
imitate another author’s style. For this task the participants were given a 2500
word sample from The Road by Cormac McCarthy to model their passage after.
This selection was made for a variety of reasons. Most importantly Cormac
McCarthy has a distinct writing style:
On the far side of the river valley the road passed through a stark black burn. Charred
and limbless trunks of trees stretching away on every side. Ash moving over the road
and the sagging hands of blind wire strung from the blackened lightpoles whining thinly
in the wind.1
Since the participants are not linguists this would allow them to make a fair
attempt at emulating another style. Furthermore the passage is an engaging read
which once again encourages the reader to think more about style than forcing
them to trudge through boring content. The assumption was that engaged par-
ticipants yield more representative passages and thus more accurate results. The
writing task given to the participant was to narrate their day from the point at
which they get out of bed, and to do so using a third-person perspective. This is
also similar to the events in the sample text. For testing purposes an additional
2500 words were taken from The Road and used as training text for Cormac
McCarthy along with the original sample. It should also be noted that the ex-
cerpt distributed to readers is freely available as a promotional passage from the
book.
Asking the participants to attempt the obfuscation attack before the imitation
attack was intentional. We were concerned that if participants chose to do the
imitation attack first then all of the obfuscation attacks would simply read as a
second Cormac McCarthy imitation attack.
3.2 Method 1: Statistical Method using the Signature Stylometric System
Method 1 analyzes the text, then uses a basic statistical method for comparison.
The features used for the analysis are word lengths, letter usage, and punctu-
ation. The method of authorship attribution compares a sample text with each
1 Full excerpt at http://www.bookbrowse.com/excerpts/index.cfm?book_
number=1964
training corpus (one per author, consisting of all sample texts from that author)
and sums the Chi-square result of the two texts. The higher the value, the less
likely it is that the author of the sample piece and the author of the reference
text are the same individual. The minimum of the sum of the Chi-Square values
for each comparison pair is then selected as the author of the sample text.
The reliability of this method was confirmed by randomly selecting a sample
text from each author in each set of authors and classifying it amongst that
set. Signature is an established platform for author recognition but the current
version unfortunately lacks the ability to automate testing. Because of this, all
testing had to be performed manually and led to less robust testing since fewer
random samples could be tested for each group than in the other methods. We
feel, however, that these results combined with the off-the-shelf nature of the
software correctly reflect the strength of the Signature system. On average this
method correctly identified the original author 95% of the time.
3.3 Method 2: Neural Network Approach
Method 2 is adapted from the approach outlined in Neural Network Applications
in Stylometry [17]. This approach is one of the first and most widely used ap-
proaches of combining Stylometry with the field of Artificial Intelligence. The
method was developed and tested using the classic Federalist Papers. The fea-
tures previously used in this system are function words that were hand-picked
after comparing each of the known Federalist Papers to discover which words
would be the most effective for classification. The function word feature set
was not used in this study due to the wide range of topics in the training data.
In the original method the use of the Federalist Papers allowed for many as-
sumptions to be made about the content, but here—as in the real world—this
luxury does not exist. Instead a series of nine features were used which could
be automatically generated from each sample text: number of different words,
lexical density, Gunning-Fog readability index, character count without whites-
pace, average syllables per word, sentence count, average sentence length, and
an alternative readability measure. These metrics were automatically generated
using Textalyser, a freely available text analysis tool2. The tool also ignored the
numbers in the text, applied a stop list on common words, and ignored words
less than 3 characters in length.
The effectiveness of Method 2 was confirmed through repeated random sub-
sampling validation. We randomly splitting the sample texts from the authors in
each group, using 90% for training and 10% for testing. A total of 16 random tri-
als were conducted for each group giving an overall average accuracy of 78.5%.
2 www.textalyser.net
3.4 Method 3: Synonym-Based Classifier
The final method is based on the vocabulary of the author. This method uses
three different models created and evaluated by [4]. The authors found the most
effective model to be the second, giving them 94% to 98% accuracy depending
on the number of authors, but results in this study showed a hybrid of models
1 and 2 to be the best approach for the training text, giving us 89% to 99%
accuracy for the same numbers of authors. This accuracy was measured through
leave-one-out-cross-validation.
The general approach of this method is to examine how each author chooses
synonyms. The theory behind the method is that when a word has a large num-
ber of synonyms to choose from, the choice the author makes is significant in
understanding his or her writing style.
A feature vector is created for each word w in a text, having two elements:
the number of synonyms s that the word has according to Princeton’s WordNet
lexical database [12], and the shared frequency n of the word w between the
sample text and the training text of a known author. The match value for a sam-
ple text u from an unknown author and a reference text k from a known author
is then the sum of n ∗ s for all shared words between the two texts. Authorship
is attributed to a text based on the known author with the highest match value to
the sample text.
Model 2 expands upon Model 1 in two ways; it first adds a stop word list
based on the 319 most common words in the English language according to
the Glasgow University Information Retrieval Group3. It also takes into account
the overall frequency of a word in all of the available text and uses it to help
determine the match value. We found the former change to be beneficial while
the latter was not. The resulting accuracy of Model 1 plus the stop word list
was 91.67% on average. The accuracy of the method on the training set was
accomplished by comparing each individual sample passage against the rest of
the entire set of test passages for all authors, minus the one being tested. This
test was repeated exhaustively for each sample passage in each set of authors.
Since the training text for each author was split up into 500 word passages
there were two methods of classifying authors. A sample text could be attributed
to the author of any single passage with the highest match value, or it could be
attributed to the author with the highest match value over all samples from that
author. It was decided to use an average of the two methods.
3.5 Deployed Applications Used
A number of tools were used in implementing the three stylometry methods.
3 www.dcs.gla.ac.uk/idom/ir_resources/linguistic_utils
Signature Stylometric System. Signature is freeware developed by Dr. Peter
Millican of Oxford University4. It uses a basic statistical approach for compar-
ing texts. It is not inherently a classifier, but the similarity measurements within
it were adapted for this study to be used for classification.
Textalyser. A free, web-based text analysis tool.
Weka. Weka is a collection of open source machine learning algorithms in-
tended to be used for data mining5. It has an excellent neural networks model
that was used to generate the neural networks for Method 2.
WordNet. Princeton has long developed and maintained this large lexical database
of English6. It has many functions but the part used for this study is the ability
to traverse synsets, or the sets of synonyms for adjectives, nouns, verbs, and
adverbs.
4 Evaluation
The bulk of the work in the field of Stylometry looks at comparing small sets
of authors [17, 4, 14, 3]. The relatively large number of subjects in this study
enabled us to compare multiple groups of authors at various “standard” sizes.
Four randomly chosen sets of 2, 3, 4, and 5 authors each were tested across
all three methods of authorship recognition. The accuracy of the methods when
tested against each attack was calculated by comparing the attack passages to the
entire set of training texts for each author in each set. The methodology for eval-
uating the initial accuracy of each method has been explained in their respective
sections. The accuracy measurements in all of the graphs are an average of the
four sets in each group.
Figure 1 shows the strength of the various stylometric methods that have
been implemented in this study. The top three lines represent the three meth-
ods used in this study and the bottom line represents the probability of selecting
the correct author by random chance. It is important to note the significance
of the accuracy measurements when compared to random chance as the ad-
versarial attacks weaken all methods to the point of being equivalent or worse
than random selection. With accuracies ranging from 91.5% to 100%, Method
1 had the best performance, but it is important to stress that this is not a study
4 www.philocomp.net/humanities/signature
5 www.cs.waikato.ac.nz/ml/weka
6 wordnet.princeton.edu
 0
 20
 40
 60
 80
 100
 1  2  3  4  5
A
cc
ur
ac
y
Number of Subjects
Signature
Neural Net
Synonym
Random
Fig. 1. Accuracy of the three methods without active attack. X-axis shows the number of sub-
jects, y-axis shows the average percentage of documents correctly classified. Error bars show the
standard error for each experiment.
in comparing these stylometric methods with each other but rather against the
prospect of resisting adversarial attacks. Methods 2 and 3 still performed very
well, with Method 2 ranging from 73% to 90% and Method 3 ranging from
88.7% to 98.7%.
Not all of the methods follow a smooth degradation curve as the number of
authors in each set increases. In fact, all methods jump up in accuracy between
sets of 4 and 5 authors. We believe this is a function of the sets of authors
used and that further testing these methods will result in a smooth degradation
curve. For example, when particularly “distinct” authors were included in more
5-author sets than 4-author sets, the accuracy of those sets increased.
Figure 2 shows how each method performed against obfuscation attacks
under different numbers of subjects, represented by the three bar graphs above
each author count on the x-axis. The line represents the probability of selecting
the correct author through random chance. In only three cases, a method did
better than chance in selecting the correct author of an obfuscation attack with
Method 1 achieving 62.5% and Method 3 achieving 56.3% success in sets of two
authors and Method 2 achieving 25% accuracy in sets of 5 authors. There were
also a few instances where the methods performed worse than chance but the
overall degradation of the accuracy closely follows the probability of selecting
the correct author at random. This demonstrates the weakness of these methods
in resisting such attacks.
Imitation attacks were effective in circumventing all three methods, as can
be seen in Figure 3 which illustrates the accuracy measurements in the same
 0
 20
 40
 60
 80
 100
 1  2  3  4  5  6
A
cc
ur
ac
y
Number of Subjects
Signature
Neural Net
Synonym
Random
Fig. 2. Accuracy in detecting obfuscation attacks. The x-axis shows the number of subjects, the
y-axis shows the average percentage of obfuscation attacks correctly classified. The error bars
show the standard error for each experiment.
way as Figure 2. Only once did any method have higher than 10% success rate
in detecting the correct author and the average accuracy was below 5% for all
three. It is also interesting to note that all three methods did much worse in the
face of an imitation attack than an obfuscation attack in detecting the correct
author. This could be attributed to the participants in the study having more
direction in creating the imitation attack which makes it easier to write in a
different style.
Figure 4 shows that all three methods largely attributed authorship of the
imitation attacks to the intended victim of the attack. Only once did any method
classify less than 60% of the imitation attacks as being authored by Cormac Mc-
Carthy. Method 3 was particularly susceptible to this attack, classifying 87.5%
to 93.75% of the imitation attacks as authored by McCarthy. This result also did
not appear to degrade with the addition of more authors.
We also ran a test to see how Methods 2 and 3 held up in the case eight
unique authors. This is a very large sample when compared to most studies in
stylometry. While this testing is not as exhaustive as the trials with 2-5 authors,
it indicates a continuation of the trends that have been observed. Method 3 had
a training set accuracy of 91.7% and Method 2 had a training set accuracy of
64.1%, both in line with the degradation curves shown in Figure 1. Method 2
did classify 25% of the obfuscation attacks correctly, but none of the imitation
attacks. Method 3 classified only 6.25% of each of the attacks correctly, and
imitation attacks were successful more than 75% of the time in both cases.
 0
 20
 40
 60
 80
 100
 1  2  3  4  5  6
A
cc
ur
ac
y
Number of Subjects
Signature
Neural Net
Synonym
Random
Fig. 3. Accuracy in detecting imitation attacks. The x-axis shows the number of subjects, the y-
axis shows the average percentage of imitation attacks correctly classified. The error bars show
the standard error for each experiment.
4.1 Discussion & Future Work
There are a number of design choices made in this study that warrant discussion
and have implications for future work.
Training Set Content and Size. The amount of training text for each author
is not exceptionally large, but the total number of authors in the study is sig-
nificantly bigger than most studies of stylometry methods. Having such a large
number of authors to work with allowed us to do more extensive testing by
choosing random groups of authors and averaging the accuracies across them.
This also allowed us to see interesting patterns in the study such as which au-
thors did a better job than others in creating successful attacks. It was clear that
certain authors did a poor job in creating their attacks and that was displayed in
the average results of the groups they were in. Certain authors also had a style
that seemed to be particularly susceptible to obfuscation attacks. Authorship of
the attacks were often attributed to these authors when they were a member of a
test set. An interesting avenue of research would be to determine if it is possible
to create a “generic” writing style, though this may be better suited for the field
of linguistics than computer science.
The domain of possible content in this study was fairly open. Participants
were allowed to present samples from a variety of subjects so long as they were
formal in nature. It could be beneficial to study the effects of adversarial attacks
in stricter domains where there is less room for maneuvering and thus less op-
 0
 20
 40
 60
 80
 100
 2  3  4  5
P
ro
ba
bi
lit
y 
of
 S
uc
ce
ss
Number of Subjects
Signature
Neural Net
Synonym
Fig. 4. Success rate of imitation attacks. The x-axis shows the number of subjects, the y-axis
shows the average percentage of imitation attacks that were classified as being authored by the
intended victim of the attack. The error bars show the standard error for each experiment.
tions for how an author could hide his or her identity. Stylometric methods used
in restricted domains may prove less susceptible to our attacks.
Participant Skill Level. In general the participants in this study were unskilled
in the fields of linguistics, stylometry and literature. Despite this lack of exper-
tise they were able to consistently circumvent the authorship attribution methods
that were put in place. This strengthens our findings as it would be reasonable
to expect authors with expertise in such areas could do a better job at attacking
the system.
In informal discussions with participants after completing the study we found
that many of them tried to obfuscate their style by “dumbing down” their writing—
using shorter sentences and less descriptive words. In imitating the writing style
of Cormac McCarthy the participants described attempting to use descriptive
and grim language. Formally incorporating the ways in which participants at-
tempted to change their writing style into the study could provide insight into
how to better defend against these attacks.
Other Stylometic Methods. While the methods chosen for this study were
picked for their effectiveness and coverage of the design space, other methods
may be more resistant to adversarial attacks. A possible avenue of research is to
examine which metrics and methods might offer resistance, including looking at
the possibility of using ensembles of classifiers to create more effective possible
methods.
5 Work in Progress
Upon completing this study we felt we could continue this research in one of
two distinct ways. The first is to look deeper into linguistic features which may
provide some resistance against obfuscation and imitation attacks and develop
a method of stylometry based on this resistance. The other direction this re-
search could take is to look into the implications that stylometry and attacks on
it have on anonymous communication published on the internet and on privacy
in general.
While the former is certainly important we opted to pursue the latter. The
web is full of anonymous communication that was never meant to be analyzed
for authorship attribution. An anonymous message board, for example, is often
not meant to reveal which posts are by which authors, or how many authors
exist on the forum in the first place. There has been some research showing
that similarity detection of texts based on stylometry is possible using unsu-
pervised learning techniques [1, 15] and these results could be used to segment
anonymous forums into groups of posts by author. This alone would likely be
enough for some users to longer feel they are using an anonymous forum, and
the privacy implications beyond that could be even more significant as a large
corpus of text that is from the same unknown author could lead to identifying
the author. This is especially true if these same techniques are applied to a larger
scale of documents, including some that are from websites or forums that are
not anonymous in the first place.
Our current research looks at the author similarity detection that has been
put forth already [1, 15] and how strongly they hold up in “real world” scenarios.
Current research has only looked at pairing documents of unknown authorship.
In these studies all existing text by each author in a known set was split into
two halves. Various unsupervised learning techniques were then used to attempt
to correctly assign each pair of texts that are from the same author. The results
were positive, but we feel that further research needs to be done to discover if
similar results hold true in more realistic scenarios. Message boards and other
forms of communication on the Internet have unknown numbers of authors with
unknown numbers of texts written by each author. Our research is focusing on
identifying how effective stylometry can be at the task of author segmentation
given this greater level of uncertainty.
Showing that stylometry can effectively “de-anonymize” internet forums in
some capacity will allow us to examine the privacy implications and work on
methods of truly preserving anonymity where intended. Expanding upon pre-
vious work in the area of automatic obfuscation [9] could pave the way for
a system that transforms text by obfuscation author identity while preserving
the semantic content of the message. Such a system would also help preserve
anonymity in the face of adversaries who would like to use stylometry to in-
fringe upon the privacy of the author.
5.1 Preliminary Results at HOTPETS
The research outlined in this section will be largely complete by HOTPETS. We
will be presenting our findings in this area at the workshop, explicitly detailing
the success that stylometry has in unsupervised author segmentation, the degree
to which this can be used in de-anonymizing internet forums, and preliminary
results on the feasibility and effectiveness of automatic obfuscation.
6 Conclusion
The most important conclusion to draw from this study is that we must test sty-
lometric methods for their resistance to adversarial attacks in situations where
attacks are likely. This paper looks at only a small fraction of the authorship at-
tribution techniques that exist, but these techniques use a wide range of metrics
and methodology that is representative of the field of stylometry. Yet all three
methods showed significant failings when faced with adversarial attacks.
The obfuscation attacks weaken all three methods to the point that they are
no better than randomly guessing the correct author of a document. The im-
itation attacks were widely successful in having their authorship attributed to
the intended victim of the attack. In addition the attacks were generated in very
short periods of time with no expert knowledge in linguistics or stylometry.
This study also strengthens the original claims of high accuracies by vali-
dating the methods on a large set of new data produced for a variety of purposes.
When these methods are used in situations where adversarial attacks is not con-
sidered to be a threat, they perform quite well.
Our framework for testing against adversarial attacks can be used as a ba-
sis for testing the resistance of both existing and future methods of authorship
attribution against obfuscation and imitation attacks.
This study shows stylometry failing in the face of basic attacks by individ-
uals relying solely on intuition (they have no formal training or background in
authorship attribution). While the use of stylometry as a security feature is not
common, it is used as forensic evidence [13]. Our results showing that stylome-
try methods are weak against trivial attacks should have an impact on how such
evidence is weighed.
Does this mean the end of stylometry in sensitive areas? Certainly not. Sty-
lometry is a massive field with a lot of research and a history of positive con-
tributions to science and the humanities. The results of this study should bring
further attention to an element of the field that has been overlooked. Frameworks
for testing methods of authorship attribution on existing texts have been around
for a long time, and now it is clear that there is a need to use a similar frame-
work for testing these very same methods in their resilience against obfuscation,
imitation, and other methods of attack.
References
1.Ahmed Abbasi and Hsinchun Chen. Writeprints: A stylometric approach to identity-level
identification and similarity detection in cyberspace. ACM Trans. Inf. Syst., 26(2):1–29, 2008.
2.K Calix, M Connors, D Levy, H Manzar, G MCabe, and S Westcott. Stylometry for e-mail
author identification and authentication. Proceedings of CSIS Research Day, Pace University,
2008.
3.Ebru Celikel and Mehmet Emin Dalkilic. Investigating the effects of recency and size of
training text on author recognition problem. ISCIS, pages 21–30, 2004.
4. J.H. Clark and C.J. Hannon. A classifier system for author recognition using synonym-based
features. Lecture Notes in Computer Science, 4827:839–849, 2007.
5.D.I. Holmes and R.S. Forsyth. The federalist revisited: New directions in authorship attribu-
tion. Literary and Linguistic Computing, 10:111–127, 1995.
6. Inc. Institute for Linguistic Evidence. Mission & philosophy. www.
linguisticevidence.org, 2008.
7.R.R. Josyula and R. Pankaj. Can pseudonymity really guarantee privacy. COLING/ACL,
pages 444–451, 2006.
8.Patrick Juola. Authorship attribution. Foundations and Trends in information Retrieval,
1(3):233–334, 2008.
9.Gary Kacmarcik and Michael Gamon. Obfuscating document stylometry to preserve author
anonymity. Proceedings of the 9th USENIX Security Symposium, 9:7–7, 2000.
10.Erica Klarreich. Bookish math. Science News, 164(25), 2003.
11.M.B. Malyutov. Information transfer and combinatories. Lecture Notes in Computer Science,
4123(3):233–334, 2006.
12.G.A. Miller. Wordnet: A lexical database for english. Communications of the ACM, 38:39–41,
1995.
13.Andrew Morton and Sidney Michaelson. The qsum plot. Internal Report CSR-3-90, 1996.
14.M. Oakes. Ant colony optimisation for stylometry: The federalist papers. Proceedings of the
5th International Conference on Recent Advances in Soft Computing, pages 86–91, 2004.
15. Josyula Rao R. and Pankaj Rohatgi. Can pseudonymity really guarantee privacy? In SSYM’00:
Proceedings of the 9th conference on USENIX Security Symposium, pages 7–7, Berkeley, CA,
USA, 2000. USENIX Association.
16.Harold Somers and Fiona Tweedie. Authorship attribution and pastiche. Computers and the
Humanities, 37:407–429, 2003.
17.F.J. Tweedie, S. Singh, and D.I. Holmes. Neural network applications in stylometry: The
federalist papers. Computers and the Humanities, 30(1):1–10, 1996.
18. Üzlem Uzuner and Boris Katz. Capturing expression using linguistic information. In AAAI,
2005.
19. Üzlem Uzuner and Boris Katz. A comparative study of language models for book and author
recognition. In IJCNLP, page 969, 2005.
