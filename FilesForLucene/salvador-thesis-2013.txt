Detección de plagio
translingüe utilizando una
red semántica multilingüe
Marc Franco Salvador
DEPARTAMENTO DE SISTEMAS INFORMÁTICOS
Y COMPUTACIÓN
Dirigido por:
Paolo Rosso
Trabajo Final de Máster desarrollado dentro del Máster
en Inteligencia Artificial, Reconocimiento de Formas e
Imagen Digital
Valencia, Febrero 2013

Cuanto más cercana a la verdad, mejor será la mentira, y la
misma verdad, cuando puede utilizarse, es la mejor mentira.
Isaac Asimov

Resumen
El plagio es definido como el uso no autorizado del contenido ori-
ginal de la obra de otros autores. Es un fenómeno dif́ıcil de detectar
cuyo problema se ha agravado en los últimos años a causa de Inter-
net: una inmensa fuente de información que permite a los usuarios
copiar y apropiarse, de forma muy sencilla, del contenido original de
otros autores. Aunque el plagio se puede detectar de forma manual,
dada la gran cantidad de contenidos que se publican, es una tarea
prácticamente imposible de llevar a cabo, aún más si las fuentes de
plagio vienen de documentos en otros idiomas.
Actualmente existe un gran interés, dentro de la literatura y la
ciencia, por investigar y desarrollar sistemas de detección de simili-
tud a nivel monolingüe y translingüe que sean capaces de detectar de
forma automática las secciones de plagio entre documentos. La co-
munidad académica también se ve beneficiada por dichos sistemas,
ya que permite la detección y disuasión por parte de los profesores
hacia su alumnado, de las prácticas habituales de copiar y pegar, sin
referencia alguna a la fuente de procedencia, de contenidos originales
obtenidos de la Web.
En la presente tesis describimos el estado del arte en materia
de detección de plagio textual a nivel monolingüe y translingüe.
Además, se estudia la utilización de una red semántica multilingüe
para crear dos modelos de detección de plagio translingüe: utilizan-
do un diccionario estad́ıstico, y mediante grafos de conocimiento a
modo de modelos de contexto para modelar fragmentos de docu-
mento. Los resultados experimentales resultan muy prometedores.
Como trabajos futuros, se definen diferentes ĺıneas de investigación
haciendo uso de grafos de conocimiento.
IV

Abstract
Plagiarism is defined as the unauthorized use of the original con-
tent of other authors. It is a difficult phenomenon to detect whose
problem has worsened in recent years because of the Internet: a vast
source of information that allows users to copy and take possession,
very simply, of the original content of other authors work. Although
plagiarism can be detected manually, given the large amount of con-
tent published, it is virtually impossible to carry out, even more if
the source of plagiarism comes from documents in other languages.
Currently, literature and science have strong interest in research
and development of automatic monolingual and cross-language si-
milarity detection systems, capable of detecting plagiarism among
sections between documents. The Academic Community also bene-
fits by such systems. It allows teachers to detect and discourage their
students of the usual practice of copy and paste, without reference
to its source, from original content obtained from Internet.
In this thesis we describe the state-of-the-art in text plagiarism
detection at monolingual and cross-language level. In addition, we
study the use of a multilingual semantic network to create two cross-
language plagiarism detection models: using a statistical dictionary,
and using knowledge graphs as context models from document frag-
ments. Experimental results are very promising. As future work, we
define different research lines using knowledge graphs.
VI

Agradecimientos
Me gustaŕıa dar mi más sincero agradecimiento a algunas perso-
nas sin las que no hubiera sido posible llevar a cabo este trabajo de
final de máster.
A la Conselleŕıa D’educació, Formació i Ocupació de la Generali-
tat Valenciana por la financiación por parte del programa Gerónimo
Forteza, sin el cual no hubiera sido posible llevar a cabo mi investiga-
ción. Este trabajo se ha hecho dentro del ámbito del VLC/CAMPUS
Microcluster on Multimodal Interaction in Intelligent Systems y co-
mo parte del proyecto de la Comisión Europea WIQ-EI IRSES (no.
269180), quiero agradecer su financiación para mi estancia de un mes
en México, en el Centro de Investigación en Computación del Insti-
tuto Politécnico Nacional (México D.F.) y en el Instituto Nacional
de Óptica Electrónica y Astrof́ısica (Puebla).
A mi director de tesina, el doctor Paolo Rosso, el cual depositó su
confianza en mı́ y me ofreció toda la ayuda y apoyo necesarios pa-
ra seguir adelante en mi trabajo. A los doctores Grigori Sidorov y
Manuel Montes por su amabilidad y ayuda durante mi estancia en
México. A mi compañero de laboratorio Parth Gupta, por prestarme
su ayuda y consejo en tantas ocasiones, y por ser tan paciente conmi-
go cuando apenas comenzaba mi labor de investigación. A Enrique
Flores por su ayuda durante las fases finales de esta redacción. Tam-
bién a Roberto Navigili por haber desarrollado BabelNet y ofrecer
su ayuda para familiarizarnos con el API sistema.
A todos mis amigos de dentro y fuera del máster que han tenido
que soportar todas mis quejas e inquietudes en los peores momentos,
además de interesarse por mi trabajo cuando no estaban relaciona-
dos con la investigación.
VIII
Quiero agradecer especialmente a mis padres su apoyo y por ser
tan pacientes y comprensivos conmigo durante todo el proceso que
duró esta investigación. Tampoco olvidar a la familia que se ha preo-
cupado de saber como me iba durante todo este tiempo.
Por último, agradecer a todo aquel que haya olvidado nombrar
en este apartado y que haya influido de alguna manera en el éxito
de esta dura etapa de mi vida.
Índice general
Índice general . . . . . . . . . . . . . . . . . . . . . . . . . X
Índice de figuras . . . . . . . . . . . . . . . . . . . . . . . . XI
Índice de tablas . . . . . . . . . . . . . . . . . . . . . . . . XII
1 Introducción 1
1.1 Descripción del problema, motivación y objetivos . . . 1
1.2 Estructura de la tesis . . . . . . . . . . . . . . . . . . 6
2 Estado del Arte 9
2.1 Detección de reutilización y plagio en texto . . . . . . 9
2.2 Detección automática de plagio textual monolingüe . 12
2.2.1 Detección de plagio intŕınseco monolingüe . . . . . . . 13
2.2.2 Detección de plagio externo monolingüe . . . . . . . . 14
2.3 Detección automática de plagio textual translingüe . . 20
2.3.1 Detección de plagio intŕınseco translingüe . . . . . . . 20
2.3.2 Detección de plagio externo translingüe . . . . . . . . 21
3 Redes semánticas 27
3.1 Red semántica . . . . . . . . . . . . . . . . . . . . . . 27
3.2 Red semántica multilingüe . . . . . . . . . . . . . . . 29
3.2.1 BabelNet . . . . . . . . . . . . . . . . . . . . . . . . . 29
4 Modelos propuestos 35
4.1 CL-ASA con el diccionario estad́ıstico de BabelNet . . 35
4.2 Análisis de similitud basado en grafos de conocimiento 37
5 Evaluación 41
5.1 Corpus PAN-PC’11 . . . . . . . . . . . . . . . . . . . 41
5.1.1 Unidades de medida . . . . . . . . . . . . . . . . . . . 42
5.1.2 Análisis detallado de similitud . . . . . . . . . . . . . 44
5.2 Experimentos . . . . . . . . . . . . . . . . . . . . . . 46
X
5.2.1 Valores de relevancia de conceptos y relaciones . . . . 46
5.2.2 Detección de plagio externo translingüe . . . . . . . . 47
6 Conclusiones y trabajos futuros 55
6.1 Conclusiones . . . . . . . . . . . . . . . . . . . . . . . 55
6.2 Ĺıneas de investigación abiertas . . . . . . . . . . . . 58
Bibliograf́ıa 70
A Publicaciones y charlas invitadas 71
Índice de figuras
2.1 Algoritmo COPS . . . . . . . . . . . . . . . . . . . . 16
2.2 Algoritmo SPEX . . . . . . . . . . . . . . . . . . . . . 16
3.1 Ejemplo de red semántica sobre el mundo animal. . . 27
3.2 Estructura de BabelNet . . . . . . . . . . . . . . . . . 30
3.3 Ejemplo de grafo de conocimiento . . . . . . . . . . . 32
4.1 Proceso de detección con grafos de conocimiento . . . 39
5.1 Comparación de fragmentos con ventana deslizante . . 44
5.2 Análisis detallado de similitud . . . . . . . . . . . . . 45
XI
Índice de tablas
5.1 Estad́ısticas plagio externo translingüe del PAN-PC’11 42
5.2 Relevancia de conceptos y relaciones . . . . . . . . . . 46
5.3 Resultados de la detección de plagio translingüe es-en 48
5.4 Resultados de la detección de plagio translingüe de-en 49
5.5 Estad́ısticas del uso de los diccionarios . . . . . . . . . 49
5.6 Resultados por tipo de traducción de caso de plagio . 50
5.7 Promedio de resultados en detección de plagio . . . . 52
XII

Caṕıtulo 1
Introducción
1.1. Descripción del problema, motivación y
objetivos
En los últimos años, Internet ha tenido un impacto profundo en
el mundo laboral, el ocio y el conocimiento a nivel mundial. Gracias
a la Web, millones de personas tienen acceso fácil e inmediato a
una cantidad extensa y diversa de información online. Desde su
creación ha supuesto toda una revolución en la manera de pensar y
actuar de las personas. En contraposición, si bien ha contribúıdo a
mejorar enormemente a nuestra sociedad, su concepción también
ha significado la aparición de toda una nueva serie de delitos o
infracciones que hacen uso de este como conducto: suplantación
de identidad, robo de cuentas bancarias, redes de pederastia,
infracciones del copyright, etc. Gracias a la Web, también ha surgido
una práctica nueva para los autores: la reutilización. Esta hace uso
de fragmentos parciales o totales de otras fuentes para elaborar
“nuevo” contenido. Dicha práctica no siempre es ilegal ya que puede
venir acompañada de referencias a su fuente original, o ser parte de
una publicación de libre disposición, siendo libre su reutilización.
El problema ocurre cuando los contenidos provienen de fuentes no
citadas, y por tanto, se está asumiendo la autoŕıa de los mismos.
Este fenómeno es conocido como plagio.
En la RAE se define el plagio (plagiarism) como “la acción de
copiar en lo sustancial obras ajenas, dándolas como propias” [13].
1
CAPÍTULO 1. INTRODUCCIÓN 2
Este hecho ha ocasionado graves problemas de autoŕıa en la
literatura y la ciencia. Un claro ejemplo seŕıa cuando en abril de
2011 saltó a la prensa una noticia que supuso un escándalo a nivel
internacional: el ex ministro alemán de Defensa Karl Theodor zu
Guttenberg fue condenado por la v́ıa penal y tubo que dimitir
de todos sus cargos por plagiar gran parte del texto de su tesis
doctoral1. Dentro de la literatura también podemos encontrar listas
de presuntos casos de “plagio célebres“2 con nombres de autores
hispanos de reconocido renombre: Garcilaso de la Vega, Camilo
José Cela, Pablo Neruda, Gabriel Garćıa Márquez, etc.
Dentro de la ciencia, concretamente en las publicaciones de
art́ıculos cient́ıficos, aparece el término de auto-plagio (self-
plagiarism). Este consiste en copiar partes de tamaño significativo
de trabajos propios, publicados previamente, sin citar la fuente de la
publicación original. Ciertamente no se incurre en delito de autoŕıa si
tomamos parte de un contenido propio, pero se está cometiendo una
falta con respecto a la comunidad cient́ıfica. Actualmente no existe
una poĺıtica consensuada respecto al auto-plagio [22]. Por ejemplo,
IEEE3 no admite reutilización de porciones largas del texto de tra-
bajos previos, mientras que ACM4 lo permite si viene acompañado
de la referencia a la fuente original.
Si bien es f́ısicamente posible la detección de plagio de forma
manual por parte de personas expertas, actualmente, debido a la
gran cantidad de publicaciones que se producen diariamente, su
detección manual en la práctica se hace imposible; aún más si el
origen del plagio proviene de una fuente en otro idioma. Lo cual es
conocido como el plagio translingüe (cross-language plagiarism).
La investigación dentro del campo de la detección de plagio trans-
lingüe está justificada. En una encuesta realizada recientemente so-
1El 23 de febrero de 2011 Guttenberg ha sido desposéıdo de su t́ıtulo de doctorado
por la Universidad de Bayreuth tras las pruebas de plagio detectadas en su tesis doc-
toral: http://www.elpais.com/articulo/internacional/Dimite/ministro/Defensa/aleman/
plagiar/tesis/doctoral/elpepuint/20110301elpepuint_6/Tes
2Lista de conocidos autores que han cometido plagio literario abiertamente: http://
elplagio.com/?page_id=27
3http://www.ieee.org/publications_standards/publications/rights/ID_Plagiarism.
html
4http://www.acm.org/publications/policies/plagiarism_policy
CAPÍTULO 1. INTRODUCCIÓN 3
bre las actitudes y prácticas de los estudiantes en las universida-
des [2], se pone de manifiesto que el plagio translingüe es un proble-
ma real: un 63.75 % de los estudiantes opina que copiar y traducir
fragmentos de texto desde otros documentos y incluirlos en sus tra-
bajos no es plagio. De todo lo anterior podemos deducir que no solo
el plagio se produce en una gran medida dentro de la comunidad
académica, sino que además la población no está concienciada de
que lo que están cometiendo es un grave delito. Para la detección
y disuasión de esta práctica, es necesaria la investigación y el desa-
rrollo de herramientas que permitan la detección de plagio, a nivel
monolingüe y translingüe, de forma automática.
Existen modelos de detección de plagio translingüe que traducen
el texto completo antes de comenzar un análisis posterior para
determinar si existe plagio [39, 19], lo cual conlleva una pérdida
de recuperación (recall) de casos de plagio y no es realista en
un escenario como la Web. Por ello, existen una serie de modelos
de análisis de similitud, que pueden utilizarse a nivel translingüe
para llevar a cabo la detección de plagio de forma automática
sin tener que pasar por esta traducción previa. Éstas hacen uso
de tesauros, modelos de alineamiento o diccionarios estad́ısticos
para detectar la similitud a nivel translingüe. Cross-language
character n-gram (CL-CNG) [30] es un modelo que se basa en
la sintaxis de los documentos, haciendo uso de n-gramas a nivel
de caracter, que ofrece un rendimiento notable para lenguajes con
similitudes sintácticas. Cross-language conceptual thesaurus based
similarity (CL-CTS) [21], como su nombre indica, utiliza un tesauro
lingǘıstico para analizar la similitud entre documentos. Cross-
language explicit semantic analysis (CL-ESA) [43] es un modelo
de análisis de semejanzas de colecciones relativas, lo que significa
que un documento está representado por sus similitudes con una
colección de documentos, las cuales son comparadas con un modelo
de detección de similitud monolingüe. Cross-language alignment-
based similarity analysis (CL-ASA) [4, 41] se basa en la tecnoloǵıa
de máquinas de traducción estad́ıstica, la cual combina traducciones
estad́ısticas, usando diccionarios estad́ısticos, y análisis de similitud.
Los anteriores modelos han sido comparados [43, 21], ofreciendo CL-
ASA y CL-CNG el mejor desempeño. Por ese motivo, en nuestra
CAPÍTULO 1. INTRODUCCIÓN 4
evaluación comparamos nuestra aproximación con éstos.
Dentro del ámbito de la detección de plagio automática, desde
el año 2009 se celebra anualmente una competición internacional,
Uncovering Plagiarism Authorship and Social Software Misuse
(PAN)5, en la cual se presentan y ponen a prueba aproximaciones
para la detección de plagio a nivel monolingüe y translingüe.
Dentro de la competición tenemos dos tareas: detección de plagio
intŕınseco y externo. La detección de plagio intŕınseco se trata de,
dado un documento, analizar su estructura para determinar las
caracteŕısticas del autor y detectar las secciones que no parecen
propias de este. El plagio externo en cambio trata de, dado un
conjunto de documentos fuente y un conjunto de documentos
sospechosos, determinar las secciones concretas de los documentos
fuente que están presentes en los sospechosos.
El objetivo principal del presente trabajo es estudiar el estado
del arte en materia de análisis de similitud textual, a nivel mono-
lingüe y translingüe, para su posterior aplicación en detección de
plagio. Además, estudiamos la utilización de un recurso lingǘısti-
co como es la red semántica multilingüe de BabelNet [33], para su
aplicación en detección de plagio translingüe. En concreto, haciendo
uso de ésta, se proponen dos nuevas aproximaciones de análisis de
similitud translingüe. En primer lugar se propone una aproximación
utilizando el diccionario estad́ıstico de BabelNet sobre el modelo
CL-ASA como base. A continuación se propone un nuevo modelo,
llamado cross-language knowledge graphs analysis (CL-KGA), que
mediante grafos de conocimiento generados por una red semántica
multilingüe, los cuales expanden y relacionan los conceptos origina-
les del texto, proporciona un modelo de contexto de los documentos
sospechosos y fuente a comparar. Aśı, la similitud entre documentos
se mide mediante un método de análisis de similitud entre grafos.
Para la evaluación de los modelos utilizamos el corpus del PAN-
PC’11 [44]6. En concreto, en nuestra evaluación utilizamos la par-
tición de detección de plagio translingüe de la tarea de detección
5http://pan.webis.de/
6http://www.uni-weimar.de/cms/medien/webis/research/corpora/corpus-pan-pc-
11.html
CAPÍTULO 1. INTRODUCCIÓN 5
de plagio externo, para comparar los modelos del estado de arte,
CL-CNG y CL-ASA, con nuestras aproximaciones.
CAPÍTULO 1. INTRODUCCIÓN 6
1.2. Estructura de la tesis
Además del actual caṕıtulo introductorio, el presente trabajo
consta de otros cinco caṕıtulos y un apéndice, los cuales se describen
a continuación:
Caṕıtulo 2 Estado del arte.
Este caṕıtulo describe el estado del arte en detección de plagio
textual. En primer lugar se definen los tipos de plagio existen-
tes y los enfoques que se utilizan en texto para su detección:
intŕınseco y externo. A continuación se describen los principa-
les modelos de detección de plagio textual monolingüe, y final-
mente describimos los modelos de detección de plagio textual
translingüe.
Caṕıtulo 3 Red semántica multilingüe.
En este caṕıtulo se describe en qué consisten las redes semánti-
cas, y dentro de estas, su extensión como redes semánticas mul-
tilingües. A continuación describimos la red semántica multi-
lingüe BabelNet, la cual utilizamos en nuestro trabajo, y los
diferentes usos que se le pueden dar. Finalmente, dentro de
estos, explicamos en qué consisten los grafos de conocimiento
que se pueden generar a partir de una red semántica, y sus
aplicaciones.
Caṕıtulo 4 Modelos propuestos.
En esta parte describimos las dos aproximaciones propuestas
en este trabajo: el modelo CL-ASA utilizando el diccionario es-
tad́ıstico de Babelnet, y el modelo CL-KGA, que utiliza los gra-
fos de conocimiento de BabelNet para llevar a cabo el análisis de
similitud translingüe. Para el diccionario estad́ıstico propone-
mos diferentes métodos de normalización de pesos, en función
de la longitud del documento y del número de traducciones.
Para el modelo CL-KGA proponemos un método de análisis de
similitud de grafos y un método de normalización de pesos en
grafos tras una intersección.
CAPÍTULO 1. INTRODUCCIÓN 7
Caṕıtulo 5 Evaluación de los modelos.
En este caṕıtulo describimos la competición de detección de
plagio PAN, el corpus utilizado para nuestra evaluación, el
PAN-PC’11, y las unidades de medida que se emplean. A conti-
nuación evaluamos los modelos propuestos contra los modelos
CL-ASA y CL-CNG, utilizando su partición de detección de
plagio externo, la cual comprende particiones de detección de
plagio translingüe español-inglés y alemán-inglés.
Caṕıtulo 6 Conclusiones y trabajos futuros.
En el último caṕıtulo se plantean las conclusiones que se pueden
extraer de los resultados experimentales de nuestra evaluación.
Además se proponen diferentes ĺıneas de investigación para el
futuro relacionadas con nuestro trabajo: utilización de diferen-
tes redes semánticas multilingües para la extensión de nuestro
modelo a más idiomas, y aplicación de las aproximaciones pro-
puestas para detección de plagio o análisis de similitud a nivel
monolingüe. Por último, en vista de los resultados obtenidos,
se proponen ĺıneas de investigación que utilicen grafos de co-
nocimiento para tareas diferentes al análisis de similitud como
mineŕıa de opiniones, clasificación de textos translingüe, adap-
tación de dominios y generación de resúmenes textuales.
Apéndice A Publicaciones y charlas invitadas.
En este apéndice mostramos las publicaciones a las que ha da-
do lugar este trabajo de investigación, además de las charlas
invitadas en las que se ha divulgado su contenido.

Caṕıtulo 2
Estado del Arte
2.1. Detección de reutilización y plagio en texto
El plagio se define como “la acción de copiar en lo sustancial obras
ajenas, dándolas como propias” [13]. A la hora de hablar de plagio,
es importante diferenciar antes la reutilización. La reutilización de
texto se define como copiar en lo sustancial obras ajenas, dándolas
como propias o no, por tanto, la reutilización puede verse como un
hiperónimo del plagio. Si bien ambos tienen una marcada diferencia,
esto no afecta a la hora de su detección, ya que el resultado sobre el
papel es similar, y también lo será el proceso de detección a seguir [9].
Por este motivio, a partir de ahora nos referiremos directamente al
término “plagio” y trataremos únicamente la detección de este.
Dada la gran cantidad de contenidos y obras disponibles actual-
mente, la detección de plagio por parte del ser humano se convierte
en una tarea prácticamente imposible. Por este motivo es necesario
el desarrollo de modelos de detección de plagio automático. Den-
tro de esta clase podemos encontrar el uso de técnicas de detección
de plagio en tres vertientes claramente diferenciadas: lingǘıstica fo-
rense, procesamiento del lenguaje natural (PLN) y recuperación de
información (RI).
La lingǘıstica forense aplica la detección de plagio, sobre todo,
para determinar la autoŕıa de notas de suicidio, amenazas, etc. Da-
da una nota de suicidio escrita “supuestamente” por un fallecido, el
objetivo es analizar si la nota realmente ha sido escrita por él. Den-
9
CAPÍTULO 2. ESTADO DEL ARTE 10
tro de esta tarea se pueden realizar análisis tipográficos, en el caso
de escritura manual, o se puede atribuir la autoŕıa también anali-
zando el estilo y caracteŕısticas propias de la escritura del autor en
el contenido del texto.
El procesamiento del lenguaje natural utiliza la detección de pla-
gio para, mediante un análisis sintáctico y estructural del texto,
determinar su similitud total o parcial con otro texto. Esta práctica
trata de detectar el plagio a pesar de intentar “engañar” al detec-
tor mediante técnicas de paráfrasis, reformulando el fragmento de
plagio, o bien si se ha producido un resumen o redistribución del
contenido. Por otro lado, las técnicas de procesamiento del lenguaje
natural conllevan un alto coste computacional para el análisis tex-
tual.
La recuperación de información se define como la “aplicación de
las técnicas computacionales para la adquisión, organización, alma-
cenamiento, recuperación y distribución de la información” [25]. El
plagio dentro de esta vertiente se utiliza para tareas de clasificación
y categorización de documentos [40], o bien para la detección de
duplicados casi idénticos entre documentos [45]. Las técnicas que
aqúı se emplean suelen implicar un coste computacional reducido
a cambio de una pérdida de precisión, ya que no son capaces de
detectar paráfrasis. Es imporante señalar, que su aplicación para la
detección de plagio es muy válida, ya que en una gran parte de los
casos de plagio que se producen en texto, se han limitado a realizar
una copia exacta de la fuente [47].
De acuerdo al tipo de análisis que se realiza en el texto, la detec-
ción de plagio automática se puede dividir en dos clases: intŕınseco
y externo.
La detección de plagio intŕınseco trata de, dado un documento,
analizar su estructura para determinar las caracteŕısticas del autor y
detectar las secciones que no parecen propias de este. Para ello extrae
las caracteŕısticas y estilo de fragmentos del texto, y las compara con
otros fragmentos del mismo texto para determinar si pertenecen al
mismo autor [8]. Caracteŕısticas que se suelen extraer son: el rango
CAPÍTULO 2. ESTADO DEL ARTE 11
del vocabulario, la longitud de las oraciones y de las palabras. Para
su análisis será necesario el uso de técnicas de PLN o RI, siendo PLN
más común si lo que se desea es una obtención en detalle del estilo
y caracteŕısticas propios del autor. Cabe señalar que esta clase de
detección de plagio es muy utilizada dentro de la lingǘıstica forense,
comparando caracteŕısticas y estilo con otros documentos escritos
por el autor.
La detección de plagio externa trata de, dado un conjunto de
documentos fuente y un conjunto de documentos sospechosos, de-
terminar las secciones concretas de los documentos fuente que están
presentes en los sospechosos. Para llevar a cabo esta clase de de-
tección, se suele realizar un proceso de tres fases [56]: En primer
lugar una clasificación temática de los documentos para descartar
los que no tienen relación; a continuación una comparación entre do-
cumentos de una misma clase para determinar un valor de similitud
entre ellos o fragmentos de ellos; finalmente se realiza un análisis de
todos los valores de similitud obtenidos para descartar los que no
son realmente casos de plagio. Dentro de la clase de detección de
plagio externo se utilizan técnicas de PLN y RI, tanto en conjun-
to (detección de fragmentos sospechosos de plagio con RI y análisis
de similitud con PLN), como por separado según la clase de plagio
que queramos detectar (copy-paste, paráfrasis, resumen...) y de lo
importante que es la velocidad en el proceso de detección.
De acuerdo al lenguaje del texto de los documentos a analizar,
se pueden distinguir dos clases de detección de plagio: monolingüe
y translingüe. La detección de plagio monolingüe, como su nombre
indica, detecta plagio entre documentos pertenecientes a un mismo
lenguaje. En cambio, la detección de plagio translingüe es capaz de
detectar el plagio entre documentos pertenecientes a lenguajes dis-
tintos. En la primera clase, al trabajar en un mismo lenguaje, el pla-
gio es más fácil de detectar y no requerirá de modelos tan complejos.
En la segunda clase se van a requerir técnicas de análisis para poder
trabajar a nivel translingüe, ya sea traduciendo previamente todo el
documento mediante una máquina de traducción estad́ıstica, para
trabajar a nivel monolingüe [39, 19], o bien utilizando modelos que
trabajen directamente a nivel translingüe utilizando análisis de sin-
CAPÍTULO 2. ESTADO DEL ARTE 12
taxis [30], tesauros [21], corpus comparables [43] o alineados [4, 41].
En general, independientemente del tipo de detección de plagio
o de los lenguajes de los documentos, para todo proceso de com-
paración de documentos se suele seguir un proceso de tres etapas:
preproceso, representación de la información y aplicación de una me-
dida de similitud. En el preproceso se suele hacer una tokenización
eliminando signos de puntuación, además de eliminar la capitaliza-
ción del texto. En algunos casos también se aplica una lematización
de las palabras, siendo más común si se trabaja con técnicas de PLN.
También puede resultar conveniente eliminar palabras muy comunes
con poco valor como los art́ıculos o las preposiciones. En la represen-
tación de la información se pueden emplear diferentes técnicas, como
el uso de n-gramas, bolsas de palabras (palabras de un fragmento
de texto agrupadas sin orden), o fragmentos de texto de tamaño de
una o más frases. La medida de similitud viene en función del tipo
de representación que se haya utlizado, siendo lo más común utilizar
modelos probabiĺısticos, o modelos de espacio vectorial [3].
En las siguientes dos secciones vamos a estudiar los modelos de
detección de plagio monolingüe y translingüe para las clases de de-
tección intŕıseco y externo. Para más información sobre el estado
del arte en detección de plagio, la tesis doctoral de Alberto Barrón-
Cedeño [2], también enfocada en la detección de plagio, ofrece una
recopilación muy ampliada del estado del arte y de todo el trabajo
anterior relacionado con la detección de plagio.
2.2. Detección automática de plagio textual
monolingüe
En el trabajo publicado en [42], centrado en las medidas de eva-
luación en detección de plagio, se ha hecho una recopilación de pu-
blicaciones relacionadas con detección de plagio y reutilización en
general. En este trabajo nos vamos a centrar a los modelos más
representativos del estado del arte.
En esta sección trataremos la detección de plagio textual, intŕınse-
co y externo, a nivel monolingüe.
CAPÍTULO 2. ESTADO DEL ARTE 13
2.2.1. Detección de plagio intŕınseco monolingüe
A continuación se muestran las aproximaciones a la detección de
plagio intŕınseco monolingüe que mejores resultados han ofrecido.
Media de frecuencias de clases de palabras
Una de los métodos que mejores resultados ofrece en análisis
intŕınseco a nivel monolingüe es el uso de medias de frecuencias
de clases de palabras (Averaged Word Frequency Class). En el tra-
bajo [31] se analizaron a través de 450 documentos, creados a partir
de un corpus artificial, estad́ısticas y caracteŕısticas como:
La media de frecuencias de clases de palabras proporciona una
estimación de la complejidad y diversidad del vocabulario.
La longitud media de las frases da una medida de la compleji-
dad de las frases en los documentos.
Las caracteŕısticas de la estructura gramatical (Part-of-Speech)
ofrecen una medida de la variedad en el lenguaje.
El promedio del número de palabras de paro (Stopwords) da una
medida del número de art́ıculos, preposiciones, etc, en el texto.
A las anteriores medidas se les aplicó un análisis discriminativo,
buscando caracteŕısticas que generasen una separación entre dife-
rentes clases, siendo la media de frecuencias de clases de palabras la
que mejores resultados ofreció.
Perfiles de n-gramas de caracteres
Esta aproximación [54], haciendo uso de n-gramas, dada su sim-
plicidad, ofrece un buen rendimiento en detección de plagio intŕınse-
co.
Haciendo uso de 3 -gramas, crea perfiles pd de diferentes docu-
mentos d, y perfiles ps de fragmentos de texto s P d, utilizando una
ventana deslizante de tamaño m y desplazamiento n (m  1000
y n  200 en el trabajo original). La disimilitud entre pd y ps, se
estima mediante la d1 normalizada:
CAPÍTULO 2. ESTADO DEL ARTE 14
nd1pps, pdq 
°
tPps

2ptft,ps  tft,pd q
tft,ps   tft,pd
	2
4|ps|
, (2.1)
donde tft,x es la frecuencia normalizada del término t (un n-
grama de caracteres) en x. El resultado nd1pps, pdq viene acotado en
0 ¤ nd1 ¤ 1, siendo 0 el mejor valor posible de similitud.
Medidas de complejidad de Kolmogorov
Las medidas de complejidad de Kolmogorov [29] también han si-
do usadas para detección de plagio intŕınseco en trabajos como [50],
donde se representa el texto como estad́ısticas de caracteŕısticas
sintácticas y gramáticas, sobre una cadena binaria en la que se com-
paran nombres contra no-nombres. También realizan el experimento
comparando palabras largas contra cortas. Las cadenas binarias se
comprimen mediante un algoritmo con un alto porcentaje de com-
presión [29], siendo la codificación y compresión un clasificador de
plagio, ya que permite diferenciar entre diferentes secciones del texto
según los ratios de compresión.
2.2.2. Detección de plagio externo monolingüe
En general, el proceso de detección de plagio externo tiene las
siguientes etapas: preproceso, análisis de similitud y postproceso.
El preproceso puede formar parte, o no, de un sistema de detec-
ción de plagio externo. Tareas t́ıpicas que se pueden realizar en el
preproceso son una tokenización, lematización, eliminación de la ca-
pitalización y eliminación de palabras pertenecientes a determinadas
categoŕıas gramaticales, como las preposiciones o los art́ıculos.
El postproceso es la etapa en la que analizamos todos los valores
de similitud obtenidos por el detector, para determinar cuales se
salen de la media lo suficiente para determinar que es plagio. Por
ejemplo se puede determinar que es plagio si se sale de la media tres
desviaciones t́ıpicas. Otra tarea que se realiza en el postproceso es
CAPÍTULO 2. ESTADO DEL ARTE 15
tomar diferentes fragmentos de plagio di reportadas por un detector
sobre un documento d, y combinarlas como una sola en el caso en
que se solapen o estén lo suficientemente cerca, por debajo de un
umbral establecido. La técnica de análisis detallado que se utiliza
en la competición de detección de plagio PAN a nivel monolingüe es
descrita en la sección 5.1.2.
A continuación se muestran las aproximaciones de análisis de
similitud que mejores resultados ofrecen y pueden utilizarse para la
tarea de detección de plagio externo.
Modelos basados en huella digital
Una huella digital (fingerprint) de un documento de texto es
una representación resumen de su contenido, a modo de firma. Se
suele modelar utilizando funciones hash, que proporcionan núme-
ros únicos a partir de secuencias de caracteres [57]. Las secuencias
de caracteres pueden ser conjuntos de caracteres, palabras o frases
(conocidos como shingles, una secuencia continua de tokens en un
documento).
Algunos modelos utilizando huella digital son los siguientes:
COPS [6] fue uno de los primeros modelos en utilizar huella
digital en texto. El sistema se usaba para controlar los luga-
res en los que un documento pod́ıa ser republicado. El sistema
COPS sigue el siguiente esquema: (i) cuando un nuevo docu-
mento d se crea, es registrado en un servidor; (ii) d se segmenta
en shingles (generalmente frases). Cada shingle se almacena
en una gran base de datos. Cuando un nuevo documento d1 en-
tra en el sistema, utilizamos el algoritmo descrito en la fig. 2.1.
Si un shingle de d1 tiene una coincidencia con un shingle de
un documento d de la base de datos, el sistema alertará de una
coincidencia.
Winnowing [48] hace uso de n-gramas como shingles para
generar un conjunto de valores hash del texto. Los n-gramas
pueden ser a nivel de caracter, palabra o frase. El modelo tra-
baja con una ventana deslizante que guarda siempre el menor
CAPÍTULO 2. ESTADO DEL ARTE 16
1: Given d1 and DBH:
2: break d1 into shingles d1i
3: for each chunk d1i in d
1:
4: Compute Hpd1iq
5: if DHpd1iq in H
6: return d | Hpd1qq P d
Figura 2.1: Algoritmo COPS, donde d1 es un documento sospechoso de ser plagio, H es
una función de hash, y H es la base de datos de hash de shingles generados previamente
de una colección de documentos D.
valor de hash de la ventana en su base de datos, para posterior-
mente detectar similitudes con un nuevo documento entrante.
SPEX [5] compara subcadenas de documentos. Las subcade-
nas son secuencias de n-gramas de palabras presentes en más
de un documento. El algoritmo genera, para cada documento,
n-gramas en un rango [1,l] y los almacena en una base de da-
tos utilizando una función hash. Cada documento sospechoso
de contener plagio será descompuesto en n-gramas del mismo
modo y comparado con las firmas almacenadas en la base de
datos. En la fig. 2.2 se muestra el algoritmo SPEX.
1: Given a collection of documents D:
2: for each d P D:
3: for each 1-gram g P d
4: H1 Ð Hpgq
5: for n  t2, . . . , lu:
6: for each d P D:
7: for each n-gram in g P d
8: if cntpHn1, gr0,n1sq  cntpH

n1, gr1,nsq  2:
9: Hn Ð Hpgq
Figura 2.2: Algoritmo SPEX, donde Hn es la tabla hash de n-gramas de palabra. Para
cada n-grama en Hn se asocia un contador. La función cnt devuelve un contador para un
hash dado.
Modelos de espacio vectorial
Un modelo de espacio vectorial [55] utiliza vectores de carac-
teŕısticas para modelar los fragmentos de documento. En el caso
de plagio en texto las caracteŕısticas pueden ser palabras, n-gramas
o estad́ısticas del documento. Para analizar la similitud entre dos
CAPÍTULO 2. ESTADO DEL ARTE 17
vectores A y B, se puede utilizar el coeficiente de Jacaard 2.2.
JpA,Bq 
|AXB|
|AYB|
, (2.2)
donde JpA,Bq está acotado en [0,1], siendo 1 cuando A y B sean
idénticos.
Expansión de vocabulario con tesauros
Existe una clase de modelos que hacen uso de conceptos de tesau-
ros1 para modelar los documentos. La ventaja de utilizar un tesauro
para buscar las palabras de los documentos es que es un buen méto-
do para detectar plagio cuando se ha utilizado paráfrasis, ya que en
el tesauro podremos encontrar los sinónimos de un concepto y darlo
como válido para una palabra dada.
En el trabajo de [26] utilizan la red semántica WordNet [14] para
realizar una expansión del vocabulario de acuerdo a las relaciones
semánticas de los conceptos originales presentes en un documento.
Los autores utilizan seis métodos diferentes para medir la similitud
entre los conjuntos de vocabulario expandido de dos documentos da-
dos. Entre los métodos encontramos medir la diferencia de vocabu-
larios y medir la convergencia con un mismo concepto de WordNet.
En el presente trabajo, en la sección 4.2 se hace uso de la red
semántica multilingüe BabelNet [33], la cual posee los conceptos de
WordNet además de las entradas etiquetadas de la Wikipedia to-
madas como conceptos, para realizar una expansión del vocabulario
representando los documentos mediante grafos de conocimiento, lo
cual es una técnica relacionada con esta categoŕıa pero desde un
enfoque translingüe.
Búsqueda de similitudes en grandes colecciones de datos
El método de búsqueda de similitudes en grandes colecciones de
datos (BDCSS) [20], fue el ganador de la competición internacional
1Tesauro: “Nombre dado por sus autores a ciertos diccionarios, catálogos o antoloǵıas.” [13]
CAPÍTULO 2. ESTADO DEL ARTE 18
de detección de plagio PAN’112 descrita en la sección 5.1, en su tarea
de detección de plagio externo.
El método utiliza un proceso de tres etapas para la detección:
Preproceso: En primer lugar se convierten todos los documen-
tos a texto plano. A continuación se transforma el texto en una
estructura de datos más eficiente de menor tamaño y más fácil
acceso. Para ello se utiliza un algoritmo de mapeo que traduce
todo el texto al inglés (si fuera necesario), lo lematiza y convier-
te todos los sinónimos en una misma palabra para simplificar
la comparación. Además se transforman todas las palabras del
texto a códigos binarios.
Detección de pasajes sospechosos: Para detectar los casos de
plagio, en primer lugar se utiliza un método para contabilizar
el número de palabras NMW en común (sin repeticiones) entre
dos fragmentos IS e IR, sin importar el órden ni número de
palabras de los fragmentos, mediante la ecuación 2.3.
NMW pIS, IRq  |IS X IR| (2.3)
Dados dos fragmentos a comparar IS e IR, utilizamos los sub-
fragmentos de estos ISi e IRj, siendo i y j el tamaño del subfrag-
mento comenzando desde su primera palabra. Para que un caso
sea plagio tiene que cumplir la ecuación 2.4, siendo qmin  0,5.
Además, cada par de subfragmentos a comparar tienen que
cumplir que NMW pISi, IRjq ¤ 15.
qSi 
NMW pISi, IRq
NMW pISi, ISiq
¤ qmin ^
NMW pIS, IRjq
NMW pIRj, IRjq
¤ qmin (2.4)
Por último, si dos casos de plagio son adyacentes son unidos en
uno solo.
Postproceso: En la última etapa se eliminan los solapamientos
de casos de plagio en un mismo fragmento, además de mejorar
2http://www.webis.de/research/events/pan-11
CAPÍTULO 2. ESTADO DEL ARTE 19
el recall y precision estableciendo tres umbrales debajo de los
cuales tienen que encontrarse los fragmentos de plagio detec-
tados para ser válidos: t1  número de palabras del fragmento
  T1 (cuyo valor óptimo establecen en 70), t2  número de
caracteres de cada palabra   T2 (valor óptimo = 60), y t3 
número de caracteres de los fragmentos de plagio   T3 (valor
óptimo = 200).
Detección de plagio por comparación detallada
El método de búsqueda de detección de plagio por comparación
detallada [27], fue el ganador de la competición internacional de
detección de plagio PAN’123, en su tarea de detección de plagio
externo.
Dado un conjunto de documentos sospechosos y fuentes de con-
tener plago, el método utiliza un proceso de tres etapas para la
detección:
Preproceso: En esta etapa se eliminan los signos de puntua-
ción, las palabras irrelevantes (como los art́ıculos), los espacios
en blanco consecutivos, y se lematiza el texto. Además se pon-
deran las palabras de los documentos utilizando un método de
ponderamiento del software Lucene4.
Comparación detallada: Este método toma como casos a com-
parar fragmentos de una frase de longitud, aśı el primer paso es
separar todos los documentos fuente y sospechosos en frases. A
continuación se seleccionan las frases cuya distancia del coseno
sea superior a un umbral t1  0,42, como se puede ver en la
ecuación 2.5.
simpS,Rq  cos Θ 
ņ
k1
wSk  wRkd
p
ņ
k1
w2Skqp
ņ
k1
w2Rkq
¡ t1, (2.5)
3http://www.webis.de/research/events/pan-12
4http://lucene.apache.org/
CAPÍTULO 2. ESTADO DEL ARTE 20
siendo S una frase sospechosa, R una frase fuente, wSk el peso
de la palabra k de la frase S y wRk el peso de la palabra k de
la frase R.
El siguiente paso es filtrar los casos posibles haciendo que su
comparación estructural T sea superior a un umbral t2  0,32,
como se puede ver en la ecuación 2.6.
T pS,Rq 
2 
¸
tPpSYRq
minpNSptq, NRptqq
|S|   |R|
¡ t2, (2.6)
donde NSptq y NRptq es el número de veces que se repite el
término común t en las frases S y R.
Finalmente se mezclan los casos de plagio que están solapados
o adyacentes mediante un algoritmo de ordenación.
Postproceso: En la última fase se vuelve a pasar la ecuación 2.6
sobre los casos de plagio detectados que ya han sido unidos si
era necesario, estableciendo t2  0,3 en esta ocasión.
2.3. Detección automática de plagio textual
translingüe
En esta sección trataremos la detección de plagio textual, intŕınse-
co y externo, a nivel translingüe.
2.3.1. Detección de plagio intŕınseco translingüe
Si bien a priori prodŕıa parecer que la detección de plagio intŕınse-
co translingüe no tiene sentido, ya que en detección intŕınseca se
trabaja sobre un solo documento para detectar secciones que no son
propias del estilo y caracteŕısticas del autor, y por tanto se traba-
jaŕıa a nivel monolingüe, existen trabajos que detectan secciones de
documento que no son propias del estilo del autor al ser traducciones
de otros documentos.
CAPÍTULO 2. ESTADO DEL ARTE 21
En [1] detectan documentos traducidos desde otro lenguaje, con
la asunción de que la traducción conservará parte de la esencia de
la estructura sintáctica del lenguaje original, y por tanto un conteo
de categoŕıas morfosintácticas, nombres y adverbios seŕıa suficiente
para reverlar secciones impropias del lenguaje.
En el trabajo descrito en [51] se realiza una clase de detección de
plagio intŕınseco translingüe. Los autores estudian la detección del
uso de traductores online, para traducir documentos que deb́ıan ser
traducidos a mano, por parte de estudiantes de lenguas.
En general, para detectar plagio intŕınseco translingüe, todos los
modelos descritos a nivel monolingüe son válidos, ya que son capaces
de detectar secciones impropias del estilo del autor, como serán las
que provengan de documentos traducidos desde otro lenguaje.
2.3.2. Detección de plagio externo translingüe
De acuerdo a su paradigma de resolución, existen cuatro cate-
goŕıas diferentes de modelos de análisis de similitud que pueden ser
utilizados para detección de plagio translingüe: (i) modelos que ha-
cen uso de diccionarios, gazetteers, reglas o tesauros lingǘısticos
para realizar las traducciones de los conceptos desde un lenguaje
origen L a uno destino L1. En esta categoŕıa tenemos por ejemplo
CL-VSM [58] , que utiliza modelos de espacio vectorial [55] o CL-
CTS [21], que usa el tesauro conceptual Eurovoc5 para las traduc-
ciones. (ii) Modelos que se basan en la sintaxis del documento y su
estructura para comparar los documentos. El modelo CL-CNG [30]
está incluido en esta categoŕıa. (iii) Modelos que utilizan corpus
comparables, como CL-ESA [43]. Éste utiliza corpus alineados por
tema y lenguaje, como la enciclopedia de la Wikipedia, y analiza la
similitud con un modelo monolingüe como los modelos de espacio
vectorial. (iv) Los modelos basados en un corpus paralelo alinean
los corpus en diferentes idiomas a nivel de documento y palabra.
Los modelos CL-ASA [4, 2], Cross-language latent semantic indexing
(CL-LSI) [12] y Cross-language kernel canonical correlation analysis
5http://eurovoc.europa.eu/
CAPÍTULO 2. ESTADO DEL ARTE 22
(CL-KCCA) [60], quedan dentro de esta categoŕıa. Además, existen
modelos que pueden utilizar combinaciones de las categoŕıas ante-
riores, para lo cual nuestra aproximación CL-KGA, descrita en la
sección 4.2, es un buen ejemplo de ello, siendo la red semántica mul-
tilingüe BabelNet la unión de (i) un tesauro (WordNet) y de (iii) un
corpus comparable (Wikipedia6).
A continuación se muestran algunas de las aproximaciones de
análisis de similitud translingüe, ordenadas por categoŕıa, que me-
jores resultados han ofrecido y pueden utilizarse para la tarea de
detección de plagio externo.
Análisis de similitud translingüe basado en un tesauro con-
ceptual
El modelo CL-CTS [21], Cross-language conceptual thesaurus ba-
sed similarity, representa los documentos por sus conceptos presen-
tes dentro de un tesauro multilingüe, modelados mediante vectores
conceptuales ~c. Para asignar un concepto e a un documento d, se
tiene que cumplir la regla vpe, dq ¡ 0, siendo vpe, dq el peso asignado
a e en d y se estima en la ecuación 2.7.
vpe, dq 
¸
tPe,Te
fpt, dq, (2.7)
donde Te se refiere al vocabulario de conceptos en Eurovoc y fpt, dq
representa la frecuencia del término t en el documento d.
Para estimar la similitud Spd, d1q entre dos documentos se utiliza
la ecuación 2.8.
Spd, d1q 
α
2


~cd. ~cd1
|d||d1|
  lpd, d1q


  p1  αq  ζpd, d1q, (2.8)
donde ~cx representa el vector conceptual de un documento x, lpd, d
1q
es el factor de longitud definido en 2.9, y α es un factor de normali-
zación para que Spd, d1q esté acotada en r0, 1s. ζpd, d1q es la similitud
6www.wikipedia.org
CAPÍTULO 2. ESTADO DEL ARTE 23
del coseno entre los 3 -gramas a nivel de caracter de los nombres de
entidades en d y d1, para los cuales se da un tratamiento especial
debido al hecho de que no están presentes en el tesauro, pero su-
poniendo similitudes sintácticas entre lenguajes, se puede cubrir la
carencia utilizando n-gramas a nivel de caracter.
lpd, d1q  exp

0,5

|d1|{|d|  µ
σ

2
, (2.9)
donde µ y σ son la media y desviación t́ıpica de la longitud de
caracteres entre traducciones de documentos desde el lenguaje L1 al
lenguaje L2. Mediante esta fórmula se tiene en cuenta el hecho de
que un mismo texto puede ocupar distinto espacio según el lenguaje
en el que esté escrito. Más información sobre la ecuación se puede
encontrar en [46].
En el trabajo original, para la adquisión de los conceptos, utili-
zan el terauro Eurovoc, el cual tiene 6.797 conceptos multilingües
representados en 22 idiomas.
Análisis de silimitud translingüe basado en n-gramas de
caracteres
El modelo CL-CNG [30], Cross-language character n-gram, ha
demostrado ofrecer un rendimiento elevado para lenguajes europeos
con similitudes sintácticas y hace uso de n-gramas a nivel de ca-
racteres para comparar los documentos en diferentes idiomas. En
este modelo se utilizan normalmente trigramas de caracteres (CL-
C3G) [43].
Dado un documento fuente d en un lenguaje L1 y un documento
sospechoso d1 en un lenguaje L2, la similitud Spd, d
1q entre los dos
documentos se mide como se muestra en la ecuación 2.10:
Spd, d1q 
~d.~d1
|d|.|d1|
, (2.10)
CAPÍTULO 2. ESTADO DEL ARTE 24
donde ~d y ~d1 son las proyecciones vectoriales de d y d1 en un espacio
de n-gramas de carácter.
Análisis de similitud translingüe basado en corpus compa-
rable
El modelo CL-ESA [43], Cross-language explicit semantic analy-
sis, se basa en el modelo ESA [17], explicit semantic analysis, el cual
representa dos documentos a comparar d y d1 por sus similitudes con
un conjunto de documentos conocido como colección de ı́ndices CI .
Las similitudes entre los documentos son representadas mediante los
vectores ~d y ~d1 estimados como en la ecuación 2.11.
~d  tsimpd, cq@c P CIu, (2.11)
donde simpd, cq computa las similitudes entre el documento d y el
documento c de la colección CI , siendo el vector resultante ~d de la
siguiente forma:
~d  rsimpd, c0q, simpd, c1q, ..., simpd, cnqs
El análisis de similitud entre vectores se lleva a cabo con un
modelo de detección de similitud monolingüe, como los modelos de
espacio vectorial [55] definidos en la sección 2.2.2.
En un contexto translingüe, CL-ESA, para determinar las seme-
janzas entre documentos en diferentes lenguajes, necesita un corpus
comparable multilingüe alineado por tema y lenguaje en el que exis-
ta una correspondencia tCI , C
1
IupCI P L1, C
1
I P L2q. Generalmente
con este modelo se utiliza el corpus comparable de la enciclopedia
de la Wikipedia.
Análisis de similitud translingüe basado en alineamiento
El modelo CL-ASA, Cross-language alignment-based similarity
analysis, mide la similitud entre dos documentos d y d1, en dos idio-
mas diferentes L1 y L2, alineándolos a nivel de palabra, determinan-
do la probabilidad de que un documento d1 sea una una traducción
CAPÍTULO 2. ESTADO DEL ARTE 25
del documento d. La similitud Spd, d1q se calcula haciendo uso de la
ecuación 2.12:
Spd, d1q  lpd, d1q  tpd|d1q, (2.12)
donde lpd, d1q es el factor de longitud definido en 2.9 y tpd|d1q es el
modelo de traducción definido en la ecuación 2.13.
tpd|d1q 
¸
xPd
¸
yPd1
ppx, yq, (2.13)
donde ppx, yq es la probabilidad de que una palabra x en el lenguaje
L1 sea una traducción de la palabra y del lenguaje L2. Dichas pro-
babilidades de traducción pueden obtenerse mediante un diccionario
estad́ıstico.
Para los experimentos del caṕıtulo 5.2.2 se ha entrenado un dic-
cionario estad́ıstico alemán-inglés y español-inglés haciendo uso del
modelo de alineamiento de palabras IBM M1 [7, 37], sobre el corpus
paralelo multilingüe JRC-Acquis [59], además de probar también
el diccionario estad́ıstico de la red semántica multilingüe BabelNet,
como se explica en la sección 4.1.
Dejando de lado aproximaciones como CL-LSI y CL-KCCA que
ofrecen un buen rendimiento a un alto coste computacional, existen
trabajos [43, 21] que han comparado algunos de los anteriores mo-
delos: CL-ASA, CL-ESA, CL-CNG y CL-CTS. En sus resultados se
refleja como CL-CNG es un buen baseline para tomar como partida
en la detección de plagio translingüe, y CL-ASA ofrece en prome-
dio los mejores resultados. Por esa razón hemos elegido CL-CNG
y CL-ASA como las aproximaciones a comparar, en el caṕıtulo de
evaluación 5, con nuestros modelos.

Caṕıtulo 3
Redes semánticas
3.1. Red semántica
Una red semántica es una forma de representación de conoci-
miento lingǘıstico en la que los conceptos y sus interrelaciones se
representan mediante un grafo, también conocido como base de co-
nocimiento de la red. Las redes semánticas han sido muy utiliza-
das en Inteligencia Artificial para representar el conocimiento, uti-
lizándolas, entre otras cosas, para representar mapas conceptuales
y mentales, e incluso para modelar tesauros lingǘısticos completos
mediante un grafo de grandes dimensiones.
Figura 3.1: Ejemplo de red semántica sobre el mundo animal.
En una base de conocimiento o red semántica, los elementos
semánticos (conceptos) se representan mediante nodos. Dos elemen-
tos semánticos entre los que exista algún tipo de relación, estarán
27
CAPÍTULO 3. REDES SEMÁNTICAS 28
unidos en la red mediante una arista (relación). Dependiendo del co-
nocimiento que se esté representando en la red, los grafos podrán ser
dirigidos, de modo que existan relaciones no simétricas entre concep-
tos. Además, atendiendo a la clase de contenido de la red, habrá di-
ferentes tipos de relaciones, siendo ejemplos de posibles relaciones la
hiponimia, hiperonimia, la meronimia, etc. En la figura 3.1 tenemos
un ejemplo de red semántica. Existen diversas redes semánticas que
modelan tesauros lingǘısticos, como por ejemplo WordNet.
En el año 1985, el profesor de psicoloǵıa George A. Miller, del
Cognitive Science Laboratory de la Universidad de Princeton, co-
menzó la dirección del proyecto WordNet, el cual actualmente es
una enorme base de datos léxica del idioma inglés. WordNet agrupa
las palabras en conjuntos de sinónimos llamados ’synsets’, proporcio-
nando definiciones cortas y generales, y almacenando las relaciones
semánticas entre estos conjuntos de sinónimos. El propósito del pro-
yecto es doble: por un lado producir una combinación de diccionario
y tesauro cuyo uso es más intuitivo, y ayudar al análisis automáti-
co de textos y a las aplicaciones de Procesamiento del Lenguaje
Natural. Además, la base de datos y las herramientas pueden ser
descargadas y usadas libremente1. Por otro lado, la base de datos
puede consultarse online en su sitio Web2.
El proyecto original de WordNet, para la lengua inglesa, se ha
extendido a través de la Asociación Global de WordNet3, la cual
promueve la creación y unión de diferentes WordNets de lenguas y
páıses del mundo. Además de WordNet, existen otras redes semánti-
cas que modelan tesauros, como por ejemplo la que utiliza los mo-
delos de Gellish4 para crear la taxonomı́a-diccionario inglés Gellish,
la cual es una gran red semántica, de código abierto, que representa
y relaciona conceptos de la lengua inglesa.
Existe otra categoŕıa de redes semánticas, conocidas como redes
semánticas multilingües, las cuales fundamentan el trabajo de inves-
tigación de este informe, y de las que hablaremos a continuación.
1http://wordnet.princeton.edu/wordnet/download/
2http://wordnetweb.princeton.edu/perl/webwn
3http://www.globalwordnet.org/
4 http://gellish.sourceforge.net/
CAPÍTULO 3. REDES SEMÁNTICAS 29
3.2. Red semántica multilingüe
Una red semántica multilingüe sigue el esquema de una base de
conocimiento tradicional, y por tanto el descrito en la sección an-
terior. La diferencia principal respecto a una red semántica es que
cada uno de los nodos del grafo, tiene una dimesión multilingüe,
de modo que existe un conjunto de lexicalizaciones del concepto en
diferentes idiomas.
Actualmente están disponibles para su uso diferentes redes semán-
ticas multilingües, como por ejemplo ConceptNet [23], EuroWord-
Net [61], el cual realiza una unión de todos los ’synset’ equivalentes
entre los WordNet de la Unión Europea, o BabelNet [33], el cual
hemos elegido como red semántica multilingüe para la realización
de nuestra experimentación, y del que hablaremos a continuación.
3.2.1. BabelNet
BabelNet [33] está formado por una base de conocimiento de gran
tamaño, con el conjunto de lexicalizaciones de los conceptos dispo-
nibles en los siguientes idiomas: alemán, catalán, español, francés,
inglés e italiano.
Las relaciones y conceptos provienen de WordNet, la mayor red
semántica disponible, y de las entradas multilingüe de la Wikipedia,
aśı BabelNet combina información lexicográfica con conocimiento
enciclopédico. La lista de conceptos está formada por todos los sig-
nificados de palabra en WordNet (’synsets’) y las etiquetas de las
entradas de la Wikipedia, por otro lado las relaciones entre concep-
tos las forman los punteros semánticos entre conceptos en WordNet
y los enlaces entre entradas en la Wikipedia.
Las lexicalizaciones multilingües se obtienen a partir de las en-
tradas en diferentes idiomas de la Wikipedia, utilizándolas como
corpus comparable y combinándolo con traducción estad́ıstica. Por
otro lado, se utiliza el corpus semCor5, el cual está compuesto por
frases en inglés con los conceptos de WordNet etiquetados, de modo
5http://www.gabormelli.com/RKB/SemCor_Corpus
CAPÍTULO 3. REDES SEMÁNTICAS 30
que mediante un traductor estad́ıstico podemos obtener las traduc-
ciones de dichos conceptos en los diferentes lenguajes de BabelNet.
Por último, cabe señalar que cada uno de los conceptos dentro de la
base de conocimiento tiene una de las siguientes categoŕıas gramati-
cales asociadas: adjetivo, adverbio, nombre y verbo. En la figura 3.2
tenemos un esquema de la estructura interna de BabelNet.
Figura 3.2: Ejemplo de la estructura interna de BabelNet (figura tomada
de [33]).
BabelNet puede ser explorado de forma gráfica [35] utilizando la
herramienta online BabelNetXplorer6. El API7 de BabelNet permite
utilizar esta red semántica multilingüe, entre otros usos, como tra-
ductor, como desambiguador del sentido de las palabras [36], como
diccionario estad́ıstico y para construir grafos de conocimiento. Es-
tos dos últimos usos son los que utilizamos en nuestra investigación
y de los que hablaremos a continuación.
Diccionario estad́ıstico de BabelNet
Dada una palabra x escrita en un lenguajeA P L  tCA,DE,EN,
ES, FR, IT u, el diccionario estad́ıstico de BabelNet nos permite ob-
tener el conjunto tpx1, w1q, px2, w2q, ...uB, B P L, de traducciones
posibles de la palabra x en el lenguaje B, siendo wi el peso de la
traducción de la palabra xi.
Las traducciones y sus pesos se toman de la base de conocimiento
de BabelNet del siguiente modo: (i) para una palabra xA dada en
6http://lcl.uniroma1.it/bnxplorer/
7http://lcl.uniroma1.it/babelnet/
CAPÍTULO 3. REDES SEMÁNTICAS 31
un lenguaje A, buscamos dentro de la base de conocimiento la lista
de conceptos CA  txA Y equivalentespxAqu en el lenguaje A, don-
de equivalentespxAq son los conceptos que guardan una relación de
equivalencia de algún tipo (sinonimia, pertenencia, parte-de...) con
xA dentro de la base de conocimiento; (ii) para cada concepto de CA
devolvemos la lista de traducciones CL disponibles en su dimensión
multilingüe para cada uno de los lenguajes L; (iii) el peso wL de cada
traducción xL será el número de relaciones salientes de cada uno de
sus conceptos asociados que se dirija a otro concepto de la lista CL.
Utilizando este método las traducciones más probables serán las de
mayor peso (las más relacionadas), si bien no están normalizadas.
Para comprender mejor como funciona el diccionario estad́ıstico
vamos a poner un ejemplo: dada la palabra xen  “car
2 en el len-
guaje inglés, el sistema busca la lista de conceptos iguales o equiva-
lentes Cen = {car, auto, motor, motorcar, cab...}en. A continuación
obtenemos la lista de traducciones CL = {{coche, automovil, auto,
carro...}es,{auto, wagen...}de,...} a todos los lenguajes L de Babel-
Net utilizando la dimensión multilingüe de cada uno de los conceptos
de Cen. Finalmente obtenemos los pesos de cada una de las traduc-
ciones dentro de CL contando el número de relaciones que existen
dentro de la base de conocimiento de BabelNet entre cada uno de
los conceptos de CL para cada lenguaje L, devolviendo la lista de
traducciones ponderadas CL = {{(coche, 8), (automovil,6), (auto,
5), (carro, 3)...}es,{(auto, 9), (wagen, 6)...}de,...}. Notese que no
tienen porqué ser los mismos pesos para cada lenguaje, ya que se
puede dar el caso de que algún concepto tenga más de una traduc-
ción equivalente en un mismo synset, lo cual será contabilizado como
dos conceptos diferentes que están igualmente relacionados.
Grafos de conocimiento
Un grafo de conocimiento consiste en un grafo dirigido y ponde-
rado, generado a partir de un conjunto de palabras como las de una
frase, que contiene los conceptos originales expandidos y relaciona-
dos entre ellos, dando lugar a un “modelo de contexto” de la frase o
conjunto de palabras original. El peso de un concepto es su número
CAPÍTULO 3. REDES SEMÁNTICAS 32
de relaciones salientes, mientras que el peso de una relación es el
peso original de la relación en la base de conocimiento de BabelNet,
la cual parte de la base de conocimiento de WordNet a la que se le
han añadido los conceptos de la Wikipedia utilizando un algoritmo
de mapping [34].
Figura 3.3: Ejemplo simplificado, sin pesos en nodos y aristas, ni dimensión
multilingüe, del grafo de conocimiento de la frase “la prima de riesgo española
alcanza máximos históricos” (los nombre de las relaciones se incluyen sólo dentro
de la ĺınea discontinua).
Para comprender mejor en que consiste un grafo de conocimiento,
vamos a poner un ejemplo. Supongamos que tenemos la frase “La
prima de riesgo española alcanza máximos históricos”. Los concep-
tos de la frase son:
C = {prima de riesgo, España, alcanzar, máximo, histórico}
Utilizando las herramientas de BabelNet podemos construir un
grafo de conocimiento g a partir de C, el cual contendrá un nuevo
listado de conceptos Cg  (C Y C
1q, siendo la lista de conceptos
expandidos:
C 1  {economı́a, finanzas, historia...}
Además, entre los conceptos de Cg, aparecerán una serie de co-
CAPÍTULO 3. REDES SEMÁNTICAS 33
nexiones R que los relacionan:
R P {relacionado, parte de, pertenece, equivalente, opuesto...}
Como se ha comentado anteriormente, cada uno de los conceptos
y relaciones del grafo tiene una dimensión multilingüe, por lo que dos
fragmentos de texto similares en diferentes lenguajes, debeŕıan tener
unos grafos también similares, lo cual explotaremos en la sección 4.2
para generar nuestro modelo de análisis de similitud translingüe. En
la fig. 3.3 podemos ver el contenido del grafo g en español.
Un grafo de conocimiento se genera en BabelNet del siguiente
modo: (i) dada una lista de conceptos etiquetada morfológicamente,
buscamos caminos para cada uno de ellos, dentro de la base de
conocimiento de BabelNet, hasta el resto de conceptos de la lista8;
(ii) una vez tenemos todos los caminos entre conceptos, estos son
suministrados a un constructor de grafos que los fusiona generando
un grafo de conocimiento, el cual posee en su interior conceptos y
relaciones expandidos respecto a la lista de conceptos original.
El constructor de grafos que utiliza BabelNet es una clase en Java
que, dado un conjunto P de caminos entre conceptos, los fusiona ge-
nerando un grafo g del siguiente modo: (i) en primer lugar tomamos
todos los conceptos presentes en la lista de caminos P y realizamos
su unión C para eliminar repeticiones; (ii) tomamos todas las rela-
ciones entre conceptos presentes en P y realizamos su unión R para
eliminar repeticiones; (iii) finalmente conectamos los conceptos de
C mediante las relaciones de R obteniendo el grafo g  tC x Ru.
8La búsqueda viene delimitada por una profundidad máxima (tres conceptos de profundi-
dad por defecto) y puede filtrar, entre otras cosas, conceptos de longitud inferior a determinado
tamaño.

Caṕıtulo 4
Modelos propuestos
En este caṕıtulo vamos a proponer dos modelos de análisis de
similitud para uso en detección de plagio externo translingüe. En
primer lugar, en la sección 4.1 sobre el modelo CL-ASA como ba-
se, utilizaremos el diccionario estad́ıstico de BabelNet, aplicando
diferentes métodos de normalización sobre los pesos de las traduc-
ciones de palabras. A continuación, en la sección 4.2 presentaremos
el nuevo modelo de análisis de similitud basado en grafos de conoci-
miento, CL-KGA, que expande y relaciona los conceptos originales
de fragmentos de texto, para proporcionar un modelo de contexto
de su contenido y realizando la comparación de fragmentos de texto
a nivel de grafos.
4.1. CL-ASA con el diccionario estad́ıstico de
BabelNet
Como hemos comentado en la sección 3.2.1, el diccionario es-
tad́ıstico de BabelNet (BN-dict) nos proporciona una lista de tra-
ducciones ponderadas para una palabra dada, y aunque dichos pesos
están relacionados con la traducción más probable, no son probabi-
lidades ni están normalizados.
Teniendo en cuenta lo anterior, vamos a proponer diferentes for-
mas de estimar la similitud Spd, d1q entre dos documentos d y d1,
partiendo de la ecuación 2.13 del modelo CL-ASA, que utilizan
diferentes métodos de normalización.
35
CAPÍTULO 4. MODELOS PROPUESTOS 36
En nuestro caso, podemos atender a dos métodos de normaliza-
ción distintos:
Normalización del peso de traducción w(x,y): Dada una
palabra x en un lenguaje L1 y una palabra y en un lenguaje L2,
basta con dividir el peso de traducción wpx, yq por la suma de
todos los pesos de traducción posibles wpxq de la palabra x al
lenguaje L2, para dar lugar a una probabilidad de traducción
ppx, yq:
ppx, yq 
wpx, yq
wpxq
(4.1)
Normalización de la similitud S(d,d’): Dado un documen-
to d con un número total de palabras |d|, podemos normali-
zar su similitud respecto al número de palabras del documento
fuente del siguiente modo:
Snormpd|d
1q 
Spd, d1q
|d|
(4.2)
Los métodos de normalización descritos en las ecuaciones 4.1 y 4.2
son compatibles entre śı y combinados con la ecuación 2.13 se pueden
utilizar para dar lugar a cuatro ecuaciones de similitud diferentes:
BN-dict1: Normalización en función de los pesos de traduccio-
nes y del número de palabras del documento fuente:
Sfull normalizationpd, d
1q 
¸
xPd
¸
yPd1
ppx, yq
|d|
(4.3)
BN-dict2: Normalización en función de los pesos de traduccio-
nes:
Sweight normalizationpd, d
1q 
¸
xPd
¸
yPd1
ppx, yq (4.4)
CAPÍTULO 4. MODELOS PROPUESTOS 37
BN-dict3: Normalización en función del número de palabras
del documento fuente:
Ssize normalizationpd, d
1q 
¸
xPd
¸
yPd1
wpx, yq
|d|
(4.5)
BN-dict4: Sin normalización:
Sno normalizationpd, d
1q 
¸
xPd
¸
yPd1
wpx, yq (4.6)
El método descrito ha sido publicado en [15]. En nuestra evalua-
ción, en la sección 5.2.2, compararemos los cuatro métodos propues-
tos con los modelos estado del arte CL-CNG y CL-ASA, además
de con nuestra otra propuesta, CL-KGA, de la que hablaremos a
continuación.
4.2. Análisis de similitud basado en grafos de
conocimiento
En esta sección vamos a presentar el modelo Cross-language know-
ledge graphs analysis (CL-KGA), el cual utiliza grafos de conoci-
miento generados a partir de una red semántica multilingüe para
obtener una similitud entre dos textos, como por ejemplo documen-
tos o fragmentos de texto.
Dado un conjunto de documentos D en un lenguaje L1 y un
conjunto de documentos D1 en un lenguaje L2, para comparar dos
documentos d P D y d1 P D1 utilizando grafos de conocimiento,
debemos de seguir los siguientes pasos:
En primer lugar debemos realizar un procesado previo del tex-
to para extraer y etiquetar morfológicamente sus conceptos,
eliminando también los tipos de palabra que no aportan mu-
cha información útil para la detección de plagio, como son los
CAPÍTULO 4. MODELOS PROPUESTOS 38
art́ıculos. Además, es conveniente lematizar las palabras. Para
estas tareas en nuestra investigación hemos hecho uso de la he-
rramienta TreeTagger1 [49], la cual es compatible con diferen-
tes idiomas entre los cuales se encuentran el alemán, español e
inglés, que son los que utilizamos en nuestra evaluación. Cabe
señalar que como en BabelNet solo existen cuatro categoŕıas
gramaticales (adjetivo, adverbio, nombre y verbo), todas las
categoŕıas etiquetadas por TreeTagger que se salgan de estas,
serán re-etiquetadas como nombres, la categoŕıa más común en
BabelNet.
Una vez realizado el preprocesamiento del texto, podemos cons-
truir, utilizando la red semántica multilingüe BabelNet, los gra-
fos de conocimiento g y g1 a partir de los documentos d y d1.
Finalmente, para obtener una similitud Spg, g1q entre g y g1,
tomando como base la aproximación de comparación flexible
de grafos conceptuales2 [32], hemos propuesto la ecuación 4.7
para trabajar con grafos de conocimiento.
Spg, g1q  Scpg, g
1q  pa  b  Srpg, g
1qq (4.7)
Scpg, g
1q 

2 
¸
cPgint
wpcq

¸
cPg
wpcq  
¸
cPg1
wpcq
 (4.8)
Srpg, g
1q 

2  ¸
rPNpc,gintq
wprq



 ¸
rPNpc,gq
wprq  
¸
rPNpc,g1q
wprq


(4.9)
1http://www.ims.uni-stuttgart.de/projekte/corplex/TreeTagger/
2Un grafo conceptual es un grafo finito dirigido bipartido con dos clases de nodos: conceptos
y relaciones [52, 53].
CAPÍTULO 4. MODELOS PROPUESTOS 39
Figura 4.1: Proceso de detección de plagio translingüe utilizando grafos de co-
nocimiento.
donde Scpg, g
1q es la similitud entre los conceptos de los grafos,
Srpg, g
1q es la similitud entre las relaciones, gint es el grafo re-
sultante de la intersección de g y g1, c es un concepto, r es una
relación, wpcq y wprq son sus pesos, y Npc, giq es el conjunto de
relaciones conectadas al concepto c en el grafo gi. Las variables
a y b se utilizan en la ecuación 4.7 para dar la apropiada relevan-
cia a los conceptos y relaciones, ya que sus pesos no se calculan
del mismo modo y, por tanto, valores de similitud iguales no
tienen porqué tener el mismo significado. Además, para la re-
solución de determinados problemas, no son igual de relevantes
conceptos que relaciones, por este motivo se suele utilizar la
regla a  b  1, y se toman a y b como porcentajes de relevan-
cia, aunque del modo que están dispuestas las variables en la
ecuación los conceptos siempre serán más importantes que las
relaciones, debido a que estas últimas no podŕıan existir sin los
conceptos. En la sección 5.2.1 analizaremos cuales son los por-
centajes de relevancia adecuados para conceptos y relaciones
en detección de plagio translingüe utilizando BabelNet.
En la fig. 4.1 podemos ver un esquema completo del proceso
de detección de plagio translingüe utilizando grafos de conocimien-
to. Es importante señalar que después de la intersección de grafos
gint  pg X g
1q, los conceptos y relaciones del grafo gint probable-
mente se hayan visto reducidos, y por tanto, sus pesos tendrán que
CAPÍTULO 4. MODELOS PROPUESTOS 40
ser recalculados. El cálculo del peso de un concepto es trivial, pues
es el número de relaciones salientes del mismo. En cambio, recal-
cular el peso de las relaciones requiere de coste cúbico siguiendo su
proceso de creación en BabelNet, ya que para cada relación seŕıa
necesario recorrer todos los conceptos dos veces siguiendo su algo-
ritmo de mapping entre conceptos de la Wikipedia a WordNet3. Por
ese motivo, en la ecuación 4.10 proponemos un algoritmo genérico
de reestimación del peso wpr, c, gintq, siendo r una relación saliente
de un concepto c en el grafo de intersección gint. El nuevo peso se
calcula en función del antiguo y del nuevo valor del peso de c en los
grafos g, g1 y gint.
wpr, c, gintq 
wpc, gq  dpc, g, gintq   wpc, g
1q  dpc, g1, gintq
2
(4.10)
dpx, g1, g2q 
|Rpg1, xq|
|Rpg2, xq|
(4.11)
donde wpc, giq es el peso del concepto c en el grafo gi, y Rpgi, xq es
el conjunto de relaciones salientes del concepto x en el grafo gi.
El método descrito ha sido publicado en [16]. En la evaluación
de la sección 5.2.2 compararemos el uso de grafos de conocimien-
to, en detección de plagio translingüe, con los métodos propuestos
utilizando el diccionario estad́ıstico de BabelNet, además de con los
modelos CL-ASA (utilizando un diccionario entrenado con el modelo
IBM M1) y CL-CNG.
3 donde tpn,mq P Opn2 mq, siendo n el número de conceptos y m el número de relaciones
entre ellos.
Caṕıtulo 5
Evaluación
Este caṕıtulo está dedicado a la evaluación de los modelos pro-
puestos en el caṕıtulo 4. En primer lugar, en la sección 5.1 des-
cribiremos el corpus PAN-PC’11, el cual utilizaremos en nuestros
experimentos. A continuación, en la sección 5.1.1 explicaremos las
unidades de medida que vamos a emplear para medir la calidad de
nuestros resultados. El método de análisis detallado de similitud es
explicado en la sección 5.1.2. Por último, una vez descritos todos
los detalles necesarios para comprender correctamente la evaluación
que se va a llevar a cabo, en la sección 5.2 se realizarán diferentes
experimentos para evaluar nuestros modelos frente al estado del arte
en detección de plagio externo translingüe.
5.1. Corpus PAN-PC’11
Desde el año 2009, en el marco del PAN Uncovering Plagiarism
Authorship and Social Software Misuse (PAN)1, se celebra una com-
petición internacional sobre detección de plagio. En la edición del
año 2013 se presentan y ponen a prueba aproximaciones en los si-
guientes ámbitos: detección de plagio, identificación del autor (dado
un documento, ¿quien lo ha escrito?) y profiling del autor (dado
un documento, ¿qué rasgos caracterizan a su autor?). Para los ex-
perimentos de nuestra evaluación, vamos a utilizar el corpus de su
edición del año 2011: el PAN-PC’11, debido a que es el corpus que se
1http://pan.webis.de/
41
CAPÍTULO 5. EVALUACIÓN 42
Documentos es-en Documentos de-en
Sospechosos 304 Sospechosos 251
Fuentes 202 Fuentes 348
Casos de plagio {es,de}-en
Traducción automática 5.142
Traducción automática + corrección manual 433
Tabla 5.1: Estad́ısticas de la tarea de detección de plagio externo translingüe
del corpus PAN-PC’11
ha utilizado para la comparación de los modelos CL-ASA, CL-CNG
y CL-CTS en [21].
Del corpus PAN-PC’11, tomamos las particiones español-inglés
(es-en) y alemán-inglés (de-en) por las cuales está formada su tarea
de detección de plagio translingüe externo, la cual se describe en
la sección 2.3.2. En la tabla 5.1 podemos ver las estad́ısticas de los
documentos que forman la partición.
5.1.1. Unidades de medida
Para medir la calidad de los resultados experimentales vamos a
tomar las medidas utilizadas en la competición del PAN:
recall a nivel de caracter. La medida nos da un porcentaje de la
cantidad de fragmentos de plagio correctos detectados respecto
al total existente en el corpus. La fórmula atiende al hecho de
que se trabaja con fragmentos de texto de los cuales podemos
detectar solo una parte, por ello la clásica fórmula tp{ptp  fnq
es reescrita, para trabajar a nivel de caracter, del siguiente
modo:
recallpS,Rq 
1
|S|
¸
sPS
|

rPRps[ rq|
|s|
,
siendo
s[ r 
#
sX r si r detecta s.
ø en otro caso.
CAPÍTULO 5. EVALUACIÓN 43
donde S es el conjunto de casos de plagio existentes en el corpus,
R es el conjunto de casos de plagio detectados en el corpus, s
es un caso de plagio de S y r es un caso de plagio de R.
precision a nivel de caracter. La medida da un porcentaje que
mide, de los casos de plagio que se han detectado, cuantos eran
verdaderamente plagio. La fórmula clásica tp{ptp  fpq se mo-
difica para trabajar al nivel de caracter del siguiente modo:
precisionpS,Rq 
1
|R|
¸
rPR
|

sPSps[ rq|
|r|
,
granularity. La medida sirve para detectar el hecho de que
en ocasiones los detectores solapen o deporten multiples de-
tecciones para un mismo caso de plagio, lo cual no es posible
determinar mediante precision y recall. La fórmula es la si-
guiente:
granularitypS,Rq 
1
|SR|
¸
sPSR
|Rs|,
donde SR es el conjunto de casos correctamente detectados en
el corpus y Rs es una ocurrencia de s dentro del conjunto de
casos de plagio detectados R. Dado el modo en que está conce-
bida la fórmula, el valor óptimo de granularity será 1, y este
irá aumentando en caso de que se produzcan solapamientos o
fragmentaciones de casos de plagio en la detección.
plagdet. Con el fin de obtener una medida de detección de pla-
gio global de un detector sobre un curpus, se combinan las tres
medidas anteriores para dar lugar al plagdet, el cual se calcula
mediante la siguiente fórmula:
plagdetpS,Rq 
F1
log2p1   granularitypS,Rqq
,
donde F1 es la media armónica de precision y recall pondera-
das equitativamente. 2
2Una descripcción más detallada de las medidas se puede encontrar en [42].
CAPÍTULO 5. EVALUACIÓN 44
Figura 5.1: Esquema del proceso de comparación de fragmentos de texto entre
dos documentos d y d1 utilizando ventana deslizante, donde s es el tamaño de
la ventana (5 en nuestro caso), y wd es un fragmento de texto del documento d.
5.1.2. Análisis detallado de similitud
Hay que tener en cuenta, que todos los modelos de detección de
plagio descritos, tanto en el estado del arte de la sección 2.3.2 como
en nuestras propuestas del caṕıtulo 4, devuelven un valor de simi-
litud entre pares de fragmentos de texto, y ese valor de similitud
todav́ıa no será un indicativo de que exista plagio hasta que se pue-
dan analizar todos los valores de similitud obtenidos entre cada par
de fragmentos de texto comparados.
En esta sección vamos a explicar el método de análisis detallado
de similitud y post-procesamiento heuŕıstico utilizado en la com-
petición del PAN, el cual también utilizaremos en nuestros experi-
mentos, mediante el que se deciden los fragmentos de texto que son
plagio una vez se tienen todos valores de similitud.
Dado un conjunto de documentos fuente D en el lenguaje L1 y un
conjunto de documentos sospechosos D1 en el lenguaje L2, para po-
der comparar diferentes fragmentos de documento obteniendo una
similitud entre ellos, utilizamos una ventana deslizante de cinco fra-
ses de longitud (lo cual consideramos aproximadamente un párrafo)
y salto de una una frase, sobre pares de documentos (d,d1), d P D
y d1 P D1, y detectamos plagio sobre ellos con los modelos de detec-
ción de plagio translingüe deseados. En la figura 5.1 podemos ver
CAPÍTULO 5. EVALUACIÓN 45
un esquema de como se utiliza la ventana deslizante para comparar
fragmentos de documento.
Una vez se hayan comparado todos los pares de documentos en
el corpus, para cada documento d tendremos un fichero que con-
tendrá un valor de similitud entre cada uno de sus fragmentos de
texto, y cada uno de los del resto de documentos comparados. Para
determinar qué fragmentos son plagio, atendiendo a sus valores de
similitud, en primer lugar nos quedamos con los primeros 50 do-
cumentos d1 más similares para cada documento d. A continuación,
para cada fragmento s, s P d, nos quedamos con los cinco fragmentos
de texto más similares s1, s1 P d1. Si la distancia entre dos fragmentos
de texto de un mismo documento es inferior a un umbral thres1, los
unimos (en nuestro caso thres1  1500q. Finalmente, para decidir
que fragmentos contienen plagio, se considera que solo aquellos frag-
mentos p que estén compuestos por un mı́nimo de thres2 (en nuestro
caso thres2  3) fragmentos son plagio. En la figura 5.2 podemos
ver el algoritmo completo de análisis detallado y post-procesamiento
heuŕıstico.
1: Given d and D1:
// Detailed analysis
2: S Ð tsplitpd,w, lqu S1 Ð tsplitpd1, w, lqu
3: for every s P S:
4: Ps,s1 Ð argmax
5
s1PS1
simps, s1q
// Post-processing
5: until no change:
6: for every combination of pairs p P Ps,s1 :
7: if δppi, pjq   thres1:
8: merge fragmentsppi, pjq
// Output
9: return tp P Ps,s1 | |p| ¡ thres2u
Figura 5.2: Análisis detallado de similitud y post-procesamiento, donde splitpd,w, lq
corta d en fragmentos de longitud w con salto l. argmax5
s1PS1
simps, s1q devuelve los 5 frag-
mentos más similares s P S con respecto a s1. δppi, pjq mide la distancia, en caracteres, entre
los fragmentos fuentes y suspechosos pi y pj . merge fragmentsppi, pjq une los fragmentos de
plagio pi, y pj . thres1 representa la distancia máxima permitida entre pi y pj para que sean
unidos. thres2 es el mı́nimo número de fragmentos de los que tiene que estar compuesto p
para ser considerado plagio.
CAPÍTULO 5. EVALUACIÓN 46
5.2. Experimentos
En esta sección vamos a realizar los experimentos para evaluar
la calidad de los modelos propuestos en el caṕıtulo 4. En primer
lugar, en la sección 5.2.1 vamos a realizar unos experimentos para
determinar cual es la relación de porcentajes adecuados para los
valores de relevancia de conceptos y relaciones con el modelo CL-
KGA. A continuación, en la sección 5.2.2 compararemos los modelos
propuestos con dos de los modelos estado del arte en detección de
plagio translingüe, CL-C3G (CL-CNG con trigramas) y CL-ASA,
además de compararnos contra el propio ganador de la competición
de detección de plagio PAN del año 2011, de la cual utilizamos el
corpus.
5.2.1. Valores de relevancia de conceptos y relaciones
En esta sección vamos a comparar el rendimiento del modelo CL-
KGA utilizando la red semántica multilingüe BabelNet, según sus
valores de relevancia para conceptos y relaciones. Para ello hemos
diseñado un experimento, midiendo solamente el plagdet, utilizando
una porción aleatoria del 20 % del corpus PAN-PC’11, tanto para
la partición es-en como de-en, en el que probaremos los siguientes
porcentajes de relevancia para conceptos (c) y relaciones (r): pc, rq P
tp100, 0q, p80, 20q, p50, 50q, p20, 80q, p0, 100qu.
% (c,r) Plagdet(es-en) Plagdet(de-en)
(100,0) 0.617 0.636
(80,20) 0.616 0.6247
(50,50) 0.655 0.620
(20,80) 0.642 0.581
(0,100) 0.612 0.522
Tabla 5.2: Relevancia de conceptos y relaciones en el modelo CL-KGA utilizando
BabelNet.
En vista de los resultados de la tabla 5.2, podemos deducir que
las relaciones utilizando la red semántica multilingüe BabelNet son
prácticamente igual de importantes que los conceptos para es-en,
CAPÍTULO 5. EVALUACIÓN 47
mientras que para de-en tienen poca o ninguna importancia3. La
diferencia puede estar producida por unos conceptos muy conectados
en grafos es-en, mientras que en de-en podemos estar teniendo un
problema de falta de contexto en los grafos, lo cual se produce si los
conceptos que provienen de un lenguaje aglutinativo como el alemán,
no están preprocesados adecuadamente, y por tanto, al buscarlos
dentro de BabelNet no los encuentra todos. Si este efecto se produce
de forma muy acusada, se acaba perdiendo el contexto de las frases,
del mismo modo que ocurriŕıa si se le suministrasen a una persona
los conceptos incompletos de una oración. En los experimentos que
realizaremos a continuación investigaremos más profundamente este
fenómeno.
Para nuestros siguientes experimentos tomaremos las configura-
ciones de conceptos y relaciones que mejor han funcionado para
ambas particiones.
5.2.2. Detección de plagio externo translingüe
En este experimento vamos a comparar los modelos decritos en
el caṕıtulo 4, CL-KGA [16] y CL-ASA utilizando el diccionario
estad́ıstico de BabelNet [15] con diferentes normalizaciones (BN-
dict1,BN-dict2,BN-dict3 y BN-dict4), con los modelos estado del ar-
te CL-C3G y CL-ASA (con un diccionario entrenado con el modelo
IBM M1) descritos en la sección 2.3.2, para las particiones comple-
tas es-en y de-en del corpus del PAN-PC’11. Además, despues de
comparar nuestros modelos con el estado del arte, también compa-
raremos nuestros resultados con los del ganador de la edición del
PAN 2011.
En la tabla 5.3 podemos observar los resultados de detección de
plagio es-en. Vemos como el modelo CL-C3G ofrece los resultados
más bajos, siendo el baseline para este tipo de experimentos. Por
otro lado, las dos aproximaciones con el diccionario de BabelNet
normalizando los pesos de las traducciones, BN-dict1 y BN-dict2,
3Tengase en cuenta que como se describió en 4.2, del modo que está concebida la fórmula
de similitud de grafos, los conceptos siempre tendrán más relevancia que las relaciones, aunque
los porcentajes aqúı sean los mismos
CAPÍTULO 5. EVALUACIÓN 48
Modelo Plagdet Rec. Prec. Gran.
CL-KGA 0.594 0.518 0.706 1.008
CL-ASA (BN-dict4) 0.563 0.499 0.662 1.015
CL-ASA (BN-dict3) 0.554 0.491 0.663 1.030
CL-ASA (IBM M1) 0.517 0.448 0.689 1.071
CL-ASA (BN-dict2) 0.264 0.205 0.518 1.160
CL-ASA (BN-dict1) 0.254 0.198 0.458 1.132
CL-C3G 0.170 0.128 0.617 1.372
Tabla 5.3: Resultados de la detección de plagio translingüe es-en
pese a haber superado al CL-C3G, no muestran un buen desempeño
comparados con los mejores, que han superado un plagdet de 0.5.
Aśı para futuros trabajos queda descartada la normalización de los
pesos de las traducciones, ya que acotarlos a un rango [0,1] suaviza
demasiado el valor de la similitud Spd, d1q para casos positivos de
plagio. Finalmente, podemos ver como las dos aproximaciones res-
tantes, BN-dict3 y BN-dict4, normalizando la similitud en función
del número de palabras del documento y sin normalización, han su-
perado los resultados obtenidos con el diccionario entrenado con el
modelo IBM M1. En concreto, BN-dict4 (el mejor utilizando dic-
cionario), ha obtenido un 10.31 % más de plagdet, lo cual asociado
a los otros valores de recall, precision y granularity que podemos
observar, indica que se producen más detecciones correctas y me-
nos falsos positivos. En vista de lo anterior, podemos afirmar que el
diccionario estad́ıstico de BabelNet, es una buena alternativa para
la detección de plagio español-inglés. Finalmente, podemos observar
como CL-KGA, utilizando grafos de conocimiento, ha superado en
todos los valores al resto de modelos para la detección de plagio
translingüe es-en. El modelo CL-ASA que más se le ha aproximado
-utilizando el diccionario del propio BabelNet (BN-dict4)- tiene un
plagdet un 4.7 % inferior. Además, aparte de observar el aumento
de los valores de precision y recall, es importante señalar que se
ha alcanzado un valor de granularity muy próximo a 1, lo cual es
el mejor valor posible, e indica que no existen solapamientos en la
detección interpretando una sección de plagio como varias, o vice-
versa.
En la tabla 5.4 tenemos los resultados de detección de plagio
CAPÍTULO 5. EVALUACIÓN 49
Modelo Plagdet Rec. Prec. Gran.
CL-KGA 0.514 0.443 0.631 1.018
CL-ASA (IBM M1) 0.406 0.344 0.604 1.113
CL-ASA (BN-dict3) 0.289 0.222 0.595 1.172
CL-ASA (BN-dict4) 0.219 0.164 0.460 1.152
CL-ASA (BN-dict1) 0.104 0.075 0.246 1.152
CL-ASA (BN-dict2) 0.103 0.074 0.246 1.151
CL-C3G 0.078 0.047 0.330 1.089
Tabla 5.4: Resultados de la detección de plagio translingüe de-en
de-en. Una vez más, tenemos CL-C3G como baseline ofreciendo los
resultados más bajos, y las dos aproximaciones con normalización
de pesos de traducciones, BN-dict1 y BN-dict2, a continuación, en
esta ocasión muy cerca de CL-C3G. Las dos aproximaciones utili-
zando diccionario restantes no han conseguido para de-en alcanzar
al diccionario del modelo IBM-M1. La mejor de las dos, BN-dict3,
ofrece un valor de plagdet un 29 % inferior a éste, como consecuen-
cia de unos valores de recall, precision y granularity peores. Cabe
señalar que observando los valores de recall y precision de BN-
dict3, se puede deducir que está habiendo muchos falsos positivos
en la detección, lo cual nos lleva a pensar en la posibilidad de que
no se estén procesando fragmentos de documentos lo sufientemente
representativos de su contenido como para ser comparables, o dicho
de otra manera, que se estén perdiendo muchas palabras porque el
diccionario de BabelNet no las encuentra, al igual que en los expe-
rimentos de la sección 5.2.1. Para confirmar dicha hipótesis hemos
realizado un nuevo experimento que mida el porcentaje de uso del
diccionario utilizado en cada prueba. Aśı, en la tabla 5.5, vemos co-
mo se confirma nuestra teoŕıa. Mientras que para detección es-en el
porcentaje de uso de ambos diccionarios es similar, en torno al 70 %,
Diccionario ES-EN % palabras encontradas
BabelNet 71.10 %
IBM M1 68.35 %
Diccionario DE-EN % palabras encontradas
BabelNet 49.34 %
IBM M1 69.45 %
Tabla 5.5: Estad́ısticas del uso de los diccionarios
CAPÍTULO 5. EVALUACIÓN 50
siendo BabelNet el que más encuentra, para de-en la utilización de
BabelNet no llega ni a un 50 %, aśı que estamos perdiendo la mitad
de palabras, a diferencia del diccionario entrenado con el modelo
IBM M1, que encuentra un 70 %. Podemos deducir que el proble-
ma es con el lenguaje alemán, el cual requerirá un procesamiento
especial del texto al ser aglutinativo, extrayendo los lemas de las
palabras con un tagger espećıfico4, para poder aumentar el número
de coincidencias dentro de BabelNet. Finalmente, en la tabla 5.4 ve-
mos también unos buenos resultados para de-en en nuestro modelo
CL-KGA, el cual ha superado a todos los otros, superando a CL-
ASAIBMM1 (el más cercano) en un valor de plagdet del 26.6 %, lo
cual supone una excelente mejora respecto al estado del arte actual.
Los otros valores también han mejorado, destacando un incremento
del recall de un 28 %, lo cual indica un considerable aumento en el
número de detecciones positivas.
Llegados a este punto, observando que el corpus PAN-PC’11 exis-
ten casos de plagio creados mediante traducción automática (auto.),
y casos creados mediante traducción automática además de correc-
ción manual (man.), los cuales serán más complicados de detectar
a causa de posibles paráfrasis empleadas, vamos a realizar unos ex-
perimentos midiendo el recall y la precision para observar cómo se
portan los modelos según el caracter de las traducciones.
Modelo
de-en es-en
Recall Precision Recall Precision
auto. man. auto. man. auto. man. auto. man.
CL-KGA 0.538 0.247 0.698 0.098 0.601 0.221 0.774 0.098
CL-ASA (M1) 0.538 0.126 0.642 0.041 0.596 0.180 0.741 0.068
CL-ASA (BN-d*) 0.472 0.092 0.631 0.033 0.599 0.198 0.720 0.076
Tabla 5.6: Resultados de detección de plagio separados por lenguajes y tipo de
traducción del caso de plagio. Nota: CL-ASA (BN-d*) es el mejor método con
diccionario de BabelNet para cada partición de lenguajes: BN-dict3 para de-en
y BN-dict4 para es-en.
En la tabla 5.6 podemos ver separados por lenguajes y tipo de tra-
ducción en la creación del caso de plagio, los resultados de precision
y recall para detección de plagio translingüe. Vemos como los casos
4En nuestros experimentos utilizamos la herramienta TreeTagger para extraer y etiquetar
conceptos.
CAPÍTULO 5. EVALUACIÓN 51
de traducción automática obtienen los mejores valores con todos los
modelos, lo cual es lógico si tenemos en cuenta que se han generado
de forma automática por una máquina de traducción estad́ıstica, sin
realizar ningún tipo de paráfrasis o resumen. Además cabe señalar
que el número de casos con traducción automática es diez veces su-
perior a los de corrección manual, lo cual puede haber influido, ya
que estaŕıamos ante muy pocos casos de plagio manual a encontrar
en un corpus muy grande en comparación, y por tanto el detector
devolverá pocos valores de similitud “relevantes” cuyos valores se
verán paliados por el resto de valores de similitud “no relevantes”,
ya que según el método de análisis detallado de la sección 5.1.2,
tomamos los primeros 50 fragmentos más similares por documento.
Cabe señalar como CL-KGA ha superado en un 96 % el recall de
CL-ASA (IBM M1) en casos de traducción manual para de-en, y un
20 % para es-en. Por otro lado, la precision ha sido un 139 % supe-
rior para de-en y un 44 % para es-en comparando el CL-KGA con el
CL-ASA (IBM M1). Los métodos utilizando el diccionario estad́ısico
de BabelNet han sido ligeramente mejores para es-en, pero como se
hab́ıa visto en los experimentos anteriores, no se ha acercado a los
mejores en de-en.
Por último, una vez hemos compados nuestros modelos con los
modelos estado del arte, solo nos queda compararnos con el ganador
de la competición internacional PAN 2011 en su tarea de detección
de plagio externo translingüe: BDCSS5 descrito en la sección 2.2.2.
La comparación con BDCSS se realiza a continuación del resto ya
que en el overview no se pueden observar los resultados separados
por particiones según el lenguaje, y en su lugar se les ha aplicado
un promedio.
En la tabla 5.7 tenemos los resultados promediados de las parti-
ciones de-en y es-en de nuestros modelos6 frente al estado del arte y
al ganador del PAN-PC’11 en su tarea de detección de plagio externo
translingüe. Cabe señalar que BDCSS ha superado al CL-KGA en
recall un 18 %, precision un 23 % y granularity un 1 %, lo cual ha
5Más información sobre los resultados de la competición se puede encontrar en el
overview [44]
6Solamente hemos promediado el método utilizando el diccinario estad́ıstico de BabelNet
que mejores resultados ha ofrecido en promedio: BN-dict3.
CAPÍTULO 5. EVALUACIÓN 52
Modelo Plagdet Rec. Prec. Gran.
BDCSS 0.64 0.57 0.83 1.00
CL-KGA 0.55 0.48 0.67 1.01
CL-ASA (IBM M1) 0.46 0.40 0.65 1.09
CL-ASA (BN-dict3) 0.42 0.36 0.63 1.10
CL-C3G 0.12 0.09 0.47 1.23
Tabla 5.7: Resultados de la detección de plagio translingüe en promedio com-
parados con el ganador del PAN-PC’11: BDCSS. Nota: redondeamos a dos de-
cimales como en el overview del PAN’11 [44].
llevado a un plagdet un 16 % superior. A pesar de que CL-KGA no
haya superado al ganador de la competición, su rendimiento en com-
paración es notable, ya que para la competición del PAN se dispone
con anterioridad del corpus de la competición, además de conocer
las herramientas de traducción estad́ıstica que se utilizan para crear
los casos de plagio. Por tanto, es posible realizar un estudio concreto
sobre ese corpus para entrenar un modelo espećıfico que sea capaz
de alcanzar altas puntuaciones en ese dominio concreto (de hecho
los valores de configuración que se muestran en la sección 2.2.2 son
los óptimos para el corpus PAN-PC’11). En cambio, nuestros mode-
los están desarrollados para ofrecer la misma calidad de resultados
en cualquier ámbito, y no requieren de ninguna configuración ni en-
trenamiento espećıfico para ningún dominio, lo cual los convierte
en modelos adecuados para trabajar sobre un escenario de contexto
realista como la Web.
En vista de todos los resultados anteriores, podemos afirmar cómo
hacer uso de grafos de conocimiento es una buena alternativa para
la detección de plagio translingüe. Cabe señalar que el coste compu-
tacional de crear un grafo de conocimiento es notablemente más
elevado que el de otros métodos que realizan búsquedas en diccio-
narios. Con las máquinas existentes actualmente es perfectamente
posible el uso de grafos de conocimiento para detectar similitud, pero
es un hecho que hay que tener en cuenta según la tarea y la impor-
tancia del coste computacional. En cambio, los modelos utilizando
el diccionario estad́ıstico de BabelNet ofrecen un coste computacio-
nal reducido, a costa de un rendimiento más reducido (sobre todo
para de-en, sobre cuyos lenguajes habrá que seguir trabajando para
CAPÍTULO 5. EVALUACIÓN 53
mejorar su rendimiento), pero se convierten en una buena opción
para análisis de similitud es-en.
CAPÍTULO 5. EVALUACIÓN 54
Caṕıtulo 6
Conclusiones y trabajos
futuros
6.1. Conclusiones
El campo de la detección de plagio translingüe automática está en
plena expansión. A conocidos modelos de análisis de similitud como
CL-CNG, CL-ESA y CL-ASA [43] que pueden ser utilizados para la
tarea de detección de plagio externo, cada año se le suman nuevas
aproximaciones gracias también a la competición internacional de
detección de plagio: el PAN [42].
En este trabajo se ha hecho un resumen del estado del arte actual
en detección de plagio, tanto a nivel monolingüe como translingüe.
A continuación se ha definido en que consisten las redes semánticas,
haciendo hincapié en su variante multilingüe. Una vez se han intro-
ducido los conceptos necesarios, se han propuesto nuevos modelos
para la detección de plagio translingüe externo. Dichos modelos ha-
cen uso de la red semántica multilingüe BabelNet para llevar a cabo
la detección. Por un lado se han propuesto cuatro modelos que com-
binan el modelo de análisis de similitud CL-ASA con el diccionario
estad́ıstico de BabelNet, ofreciendo cada uno un tipo de normali-
zación en los pesos de las traducciones del diccionario: atendiendo
a la logitud del texto y al número de traducciones posibles de una
palabra. Además, se ha propuesto un nuevo modelo de análisis de
similitud basado en grafos, cross-language knowledge graphs analysis
(CL-KGA), el cual utiliza grafos de conocimiento creados a partir
55
CAPÍTULO 6. CONCLUSIONES Y TRABAJOS FUTUROS 56
de BabelNet, que expanden y relacionan los conceptos originales de
un fragmento de texto, proporcionando un modelo de contexto de
su contenido. La ventaja de dicha aproximación, a parte de la ex-
pansión y relación del vocabulario, es el hecho de que un grafo de
conocimiento tiene una dimensión multilingüe en cada uno de sus
nodos y aristas, de modo que dos grafos creados a partir de dos
textos en diferentes lenguajes que hablen del mismo contenido serán
similares.
En el aspecto del coste computacional, CL-ASA combinado con
el diccionario estad́ıstico de BabelNet resulta igual de eficiente que
el CL-ASA clásico, mientras que CL-KGA tiene un coste superior,
dada la complegidad de elaborar grafos de conocimiento, pero siendo
una dificultad salvable con las máquinas existentes actualmente, y
que no impide que CL-KGA sea un eficiente modelo de análisis de
similitud.
Para la evaluación de los modelos propuestos se ha hecho uso
de un corpus diseñado espećıficamente para la tarea: el corpus de
la competición PAN-PC’11, del cual se ha tomado su tarea de de-
tección de plagio translingüe externo, la cual incluye detección de
plagio de-en y es-en. Toda la metodoloǵıa de la evaluación ha se-
guido estrictamente las pautas que en esta competición se dictan.
En los experimentos se han comparado los modelos propuestos con
los del estado del arte CL-CNG (utilizando trigramas) y CL-ASA
(utilizando un diccionario estad́ıstico entrenado con el modelo IBM
M1), además de compararnos con el ganador de dicha competición.
Los resultados experimentales han resultado clarificadores. Por
un lado los modelos que combinan CL-ASA con el diccionario es-
tad́ıstico de BabelNet han ofrecido resultados dispares. Las pun-
tuaciones utilizando normalización en función del número de tra-
ducciones de una palabra han resultado en un punto medio entre
el CL-ASA (IBM M1) y CL-CNG. Para los modelos que combinan
CL-ASA con el diccionario de BabelNet y normalizan en función de
la longitud del texto o que no normalizan, los resultados han sido
superiores al CL-ASA (IBM M1) y al CL-CNG para detección de
plagio es-en, mientras que para de-en los resultados han sido inferio-
res. El problema aqúı ha sido con en lenguaje aglutinativo alemán,
CAPÍTULO 6. CONCLUSIONES Y TRABAJOS FUTUROS 57
que requiere de herramientas espećıficas para la extracción, lemati-
zación y etiquetado de sus conceptos. Sin embargo, en vista de los
resultados podemos afirmar que el diccionario estad́ıstico de Babel-
Net permite su utilización para una detección de plagio translingüe
eficiente en un contexto es-en.
Por otro lado, el modelo CL-KGA ha ofrecido unos resultados
excelentes en todas sus pruebas, superando a todos los otros mode-
los. Para es-en ha obtenido una puntuación global de detección de
plagio (plagdet) un 14.9 % superior al modelo CL-ASA (IBM M1) y
un 250 % superior al CL-CNG, para de-en ha superado al CL-ASA
(IBM M1) en un 26.6 % y al CL-CNG en un 559 %.
Tras los experimentos anteriores en los que se ha visto la calidad
de los modelos, se ha pasado a un análisis más exhaustivo en el que
se han detectado por separado los casos de plagio en el corpus gene-
rados por una máquina de traducción estad́ıstica y los casos que han
recibido corrección manual. En dichas pruebas hemos podido obser-
var como, si bien se detectan más del doble de casos traducidos de
forma automática, CL-KGA ha superado en todas las pruebas al
resto de modelos, doblando en algunos casos los valores. Por último
se han comparado los modelos evaluados con el ganador de la edición
del PAN del año 2011, BDCSS, para el cual solamente están dispo-
nibles resultados promediados de las dos particiones es-en y de-en.
El modelo CL-KGA ha resultado un 16 % inferior a este, CL-ASA
(IBM M1) un 39 % inferior y el mejor CL-ASA combinado con el
diccionario estad́ıstico de BabelNet un 52 % inferior. Dichos resul-
tados resultan muy positivos, ya que CL-KGA no necesita una fase
previa de entrenamiento sobre un corpus para estimar parámetros,
y es capaz de ofrecer todo su rendimiento desde el primer momento
en cualquier excenario, incluso en un contexto realista como la Web,
cosa que no ocurre con BDCSS.
En conclusión, en este trabajo hemos presentado diferentes mo-
delos de análisis de similitud en un contexto translingüe, resaltando
el modelo CL-KGA, que utilizando grafos de conocimiento a mo-
do de modelos de contexto, ha demostrado ser una alternativa que
ofrece mejores resultados que los modelos estado del arte que se uti-
CAPÍTULO 6. CONCLUSIONES Y TRABAJOS FUTUROS 58
lizan actualmente para dicha tarea, y modelo sobre el cual todav́ıa
quedan muchas v́ıas por explorar.
6.2. Ĺıneas de investigación abiertas
A ráız de las conclusiones que hemos podido extraer de los resul-
tados experimentales, existen diversas ideas para mejorar la investi-
gación actual, además de otras ĺıneas de investigación que nacen tras
los satisfactorios resultados que los grafos de conocimiento han pro-
porcionado en análisis de similitud a nivel translingüe. Estas ideas
podŕıan llevarse a cabo en el futuro en el marco de una tesis doctoral.
Las ĺıneas de investigación abiertas para mejorar los modelos pro-
puestos en el presente trabajo son las siguientes:
Utilización de un tagger para la lematización y etique-
tado de las palabras a buscar en el diccionario estad́ısti-
co de BabelNet: En el trabajo actual las palabras de un texto
a buscar en el diccionario se le proporcionaban directamente a
BabelNet, sin recibir ningún tipo de tratamiento, lo cual pue-
de influir al fallo en la localización de palabras derivadas de
su forma infinitiva, pero que realmente śı existen dentro del
diccionario. Una herramienta que realice un análisis sintácti-
co del texto para etiquetar correctamente las palabras, y que
posteriormente las lematice, nos permitiŕıa un automento con-
siderable del porcentaje de aciertos dentro del diccionario de
BabelNet, además de hacer uso de la búsqueda con categoŕıa
gramatical, que actualmente se omite.
Utilizar el método de construcción de grafos de conoci-
miento solamente para realizar una expansión del voca-
bulario, y buscar luego los conceptos en el diccionario
con el modelo CL-ASA: Esta aproximación seŕıa una com-
binación de los clásicos métodos utilizando diccionario con la
expansión de vocabulario que proporcinan los grafos de conoci-
miento, descartando por otro lado las relaciones entre concep-
tos. Una ventaja de dicho método seŕıa que una vez se tenga la
expansión de vocabulario, el coste seŕıa siempre el mismo que
CAPÍTULO 6. CONCLUSIONES Y TRABAJOS FUTUROS 59
utilizando CL-ASA, en lugar del coste superior de los grafos de
conocimiento.
Utilizar una herramienta espećıfica para la extracción
y etiquetado de conceptos en alemán: Actualmente, en la
elaboración de grafos de conocimiento se hace uso de la herra-
mienta TreeTagger por su capacidad para etiquetar texto de
multiples lenguajes, pero por los resultados vistos en la evalua-
ción, la extracción de conceptos y etiquedado se podŕıa mejorar
notablemente para el alemán, ya que parece que estamos per-
diendo un elevado porcentaje de conceptos por un mal etique-
tado. Dentro de las posibles opciones nos encontramos con las
herramientas del kit OpenNLP1 que incluye, entre otras herra-
mientas, etiquetador, tokenizador, parser y chunker. Por otro
lado, el tagger de la universidad de Stanford2 también podŕıa
ser una buena alternativa para etiquetar el lenguaje alemán.
Mejorar algoritmo de similitud de grafos: Existen diver-
sas mejoras que se podŕıan aplicar al algoritmo de comparación
de grafos propuesto en la sección 4.2. Por un lado se podŕıa ha-
cer una versión que comparase grafos por el método de los X
vecinos más cercanos a un concepto original del texto, descar-
tando el resto. Por otro lado, se podŕıa modificar el algoritmo
actual para que diera más valor a los conceptos originales del
texto, y los que se hayan añadido a la hora de generar el grafo
de conocimiento fueran perdiendo valor conforme se alejasen
de los conceptos originales.
Utilizar otras redes semánticas multilingües para dotar
a CL-KGA de más lenguajes: Existen otras redes semánti-
cas multilingües como ConceptNet [23] o EuroWordNet [61] que
podŕıan ser utilizadas para la creación de grafos de conocimien-
to, dotando al modelo CL-KGA de más lenguajes dentro de su
dimensión multilingüe.
Método h́ıbrido entre CL-ASA y CL-KGA: Para reducir
el coste computacional del CL-KGA, podemos sacrificar pre-
cisión utilizando CL-ASA para localizar las secciones del tex-
1http://opennlp.apache.org/
2http://nlp.stanford.edu/software/tagger.shtml
CAPÍTULO 6. CONCLUSIONES Y TRABAJOS FUTUROS 60
to sospechosas de contener plagio, y a continuación pasar CL-
KGA sobre ellas y determinar si efectivamente existe plagio.
Los grafos de conocimiento han demostrado ser efectivos para su
uso en detección de plagio translingüe, pero su utilidad va mucho
más allá. En mayo de 2012 salió la noticia de que Google comenzaba
a utilizar su propio grafo de conocimiento3 para mejorar las búsque-
das en inglés dotándolas de contexto. Aunque sus herramientas y el
grafo todav́ıa no están disponibles públicamente para el desarrollo,
podemos hacer uso de la red semántica multilingüe BabelNet para
la creación de grafos de conocimiento y su aplicación en nuevas ta-
reas. Las nuevas ĺıneas de investigación que nacen a partir de este
trabajo son las siguientes:
Utilizar CL-KGA para otras tareas diferentes de detec-
ción de plagio translingüe: El modelo CL-KGA puede ser
utilizado para todo tipo de tareas de análisis de similitud, tan-
to a nivel monolingüe como translingüe. Podŕıa ser interesante
evaluar su calidad en detección de similitud y reutilización en
textos a nivel monolingüe en el corpus METER 4 por ejemplo.
Emplear grafos de conocimiento para opinion mining:
Dentro del ámbito del análisis de opiniones [38] en texto, podŕıa-
mos utilizar la expansión de vocabulario que ofrecen los grafos
de conocimiento, para luego buscar sobre dicho vocabulario las
palabras sobre un diccionario de sentimientos [10], lo cual pro-
porcionaŕıa un aumento del vocabulario y contexto más rela-
cionado con los sentimientos que manifieste el texto, y podŕıa
aumentar la precisión del análisis.
Aplicar grafos de conocimiento para la elaboración de
resúmenes: La tarea de elaboración de resúmenes de texto [18]
se podŕıa ver también beneficiada de la información que los gra-
fos de conocimiento aportan. Elaborando grafos de fragmentos
de texto, combinandolo con nuestro método de análisis de si-
militud en grafos, podŕıamos detectar qué fragmentos de texto
3http://www.fayerwayer.com/2012/05/google-presenta-el-grafo-del-conocimiento-
para-darle-sentido-a-las-busquedas/
4http://nlp.shef.ac.uk/meter/
CAPÍTULO 6. CONCLUSIONES Y TRABAJOS FUTUROS 61
son los más representativos de un texto o tema. Por otro lado,
analizando los complementos de los grafos intersección en el al-
goritmo de similitud5, podŕıamos detectar qué partes son más
o menos frecuentes o incluso contrarias entre diferenes resúme-
nes. Finalmente, al tener los grafos una dimensión multilingüe,
el sistema podŕıa trabajar a partir de textos en diferentes len-
guajes de forma nativa.
Utilizar grafos de conocimiento para clasificación temáti-
ca translingüe: El problema de la clasificación temática trans-
lingüe [24] consiste en, dado un conjunto de textos en diferen-
tes lenguajes, clasificarlos según su tema. Utilizando grafos de
conocimiento podemos tomar dos ĺıneas de investigación dife-
rentes: (i) Dado un conjunto de textos de los que conocemos el
tema, podemos crear un grafo de conocimiento para cada uno
de ellos, y combinandolos (bien mediante intersección o median-
te métodos más complejos como la detección de los conceptos
más representativos) obtendŕıamos un grafo prototipo. Si crea-
mos un grafo prototipo para cada una de los temas/clases, para
cada nuevo documento a clasificar en el sistema será cuestión
de crear su grafo de conocimiento y analizar su similitud con
los grafos prototipo de cada clase. (ii) Podemos generar los sub-
grafos comunes más frecuentes [28] de los documentos de cada
clase, y una vez tenemos estos subgrafos, los podemos tratar
como caracteŕısticas para combinarlos con otros métodos de
clasificación como Bayes o máquinas de soporte vectorial. Para
cada nuevo texto a clasificar, podŕıamos extraer los subgrafos
comunes más frecuentes con cada una de las clases y analizar
su similitud mediante un clasificador.
La utilización de grafos de conocimiento para esta tarea podŕıa
comportar dos mejoras sustanciales respecto a otras aproxima-
ciones: (i) Por un lado los grafos de conocimiento tienen una
dimensión multilingüe, y gracias a ello no habŕıa que tratar
con máquinas de traducción estad́ıstica y perder precisión en el
proceso, lo cual es uno de los principales problemas de la tarea.
(ii) Por otro lado, en ocasiones si los textos están hablando de
5Los complementos de un grafo intersección seŕıan aquellas partes del grafo que no se
encuentran presentes en la intersección, al no ser comunes entre los grafos fuente.
CAPÍTULO 6. CONCLUSIONES Y TRABAJOS FUTUROS 62
un tema muy propio de un lenguaje (debido a la cultura de su
páıs de origen), se puede perder mucha precisión, ya que la tra-
ducción del texto llevaŕıa a la pérdida total del contexto, p.e:
un texto en castellano que hable de pelota vasca. En cambio, si
se utilizan grafos de conocimiento, al crear un modelo de con-
texto del contenido del texto, podremos aportar la suficiente
información mediante nuevos conceptos y relaciones, como pa-
ra comprender de qué estamos hablando, a pesar de cambiar
de idioma.
Emplear grafos de conocimiento para domain adapta-
tion : La tarea de domain adaptation [11] se refiere a, dado
un corpus con unas caracteŕısticas concretas sobre un dominio,
adaptar dichas caracteŕısticas para su utilización en otro do-
minio diferente con el que guarde relación, como por ejemplo
adaptar un corpus sobre noticias deportivas de futbol al domi-
nio de noticias deportivas de baloncesto. Las ventajas que apor-
taŕıan los grafos de conocimiento respecto a otras aproximacio-
nes seŕıan similares a las explicadas en el problema anterior de
clasificación temática. Por un lado la utilizació de grafos de co-
nocimiento aportaŕıa una mayor calidad en las traducciones que
otros métodos que utilizan máquinas de traducción estad́ısti-
ca, por otro, para conceptos con los que una simple palabra no
fuera suficiente para comprender su significado, la expansión
de vocabulario en los grafos de conocimiento aportaŕıa una de-
finición más clara de lo que represente dicho concepto en el
texto.
Bibliograf́ıa
[1] M. Baroni and S. Bernardini. A new approach to the study of
translationese: machine learning the difference between original
and translated text. 21(3):259–274, 2006.
[2] A. Barrón-Cedeño. On the mono- and cross-language detec-
tion of text re-use and plagiarism. Ph.D. thesis, Universitat
Politènica de València, 2012.
[3] A. Barrón-Cedeño, A. Eiselt, and P. Rosso. Monolingual text
similarity measures: A comparison of models over wikipedia ar-
ticles revisions. In Proc. of 7th Int. Conf. on Natural Language
Processing, pages 29–38. ICON-2009, 2009.
[4] A. Barrón-Cedeño, P. Rosso, D. Pinto, and A. Juan. On cross-
lingual plagiarism analysis using a statistical model. In Proc. of
the ECAI’08 Workshop on Uncovering Plagiarism, Authorship
and Social Software Misuse, PAN’08, 2008.
[5] Y. Bernstein and J. Zobel. A scalable system for identifying
coderivative documents. In Proc. of the Symposium on String
Processing and Information Retrieval, 2004.
[6] S. Brin, J. Davis, and H. Garćıa-Molina. Copy detection me-
chanisms for digital documents. In Proc. of the 1995 ACM SIG-
MOD Int. Conference on Management of Data, pages 398–409.
ACM Press, 1995.
[7] P. F. Brown, S. A. Della Pietra, V. J. Della Pietra, and R. L.
Mercer. The mathematics of statistical machine translation:
Parameter estimation. Computational Linguistics, 19(2):263–
311, 1993.
63
BIBLIOGRAFÍA 64
[8] P. Clough and M. Stevenson. Developing a corpus of plagiari-
sed short answers. Language Resources and Evaluation: Special
Issue on Plagiarism and Authorship Analysis, 45(1):5–24, 2010.
[9] R. Comas and J. Sureda. Academic cyberplagiarism: tracing
the causes to reach solutions. Digithum, 10:1–6, 2008.
[10] T. Crawford and A. Ellis. A dictionary of rational-emotive
feelings and behaviors. Journal of Rational-Emotive and
Cognitive-Behavior Therapy, 7(1):3–28, 1989.
[11] H. Daumé, III, A. Kumar, and A. Saha. Frustratingly easy
semi-supervised domain adaptation. In Proceedings of the 2010
Workshop on Domain Adaptation for Natural Language Proces-
sing, DANLP 2010, pages 53–59, Stroudsburg, PA, USA, 2010.
Association for Computational Linguistics.
[12] S. T. Dumais, T. A. Letsche, M. L. Littman, and T. K. Lan-
dauer. Automatic cross-language retrieval using latent semantic
indexing. In Proc. AAAI-97 spring symposium series: Cross-
language text and speech retrieval, pages 18–24. Hull & D. Oard
(Eds.), 1997.
[13] R. A. Española. Real academia española. Diccionario de la
lengua española. Vigésima segunda edición. 2008.
[14] C. Fellbaum. WordNet: An electronic lexical database. Bradford
Books, 1998.
[15] M. Franco-Salvador, P. Gupta, and P. Rosso. Cross-language
plagiarism detection using BabelNet’s statistical dictionary.
Computación y Sistemas, Revista Iberoamericana de Compu-
tación, 16(4):383–390, 2012.
[16] M. Franco-Salvador, P. Gupta, and P. Rosso. Cross-language
plagiarism detection using a multilingual semantic network. In
Proc. of the 35th European Conference on Information Retrieval
(ECIR’13). Springer-Verlag, LNCS(7814), 2013.
[17] E. Gabrilovich and S. Markovitch. Computing semantic rela-
tedness using wikipedia-based explicit semantic analysis. In
BIBLIOGRAFÍA 65
Proc. of the 20th int. joint conference on Artifical intelligen-
ce, IJCAI’07, pages 1606–1611, San Francisco, CA, USA, 2007.
Morgan Kaufmann Publishers Inc.
[18] J. Goldstein, M. Kantrowitz, V. Mittal, and J. Carbonell. Sum-
marizing text documents: sentence selection and evaluation me-
trics. In Proceedings of the 22nd annual international ACM
SIGIR conference on Research and development in information
retrieval, SIGIR ’99, pages 121–128, New York, NY, USA, 1999.
ACM.
[19] T. Gottron. External plagiarism detection based on standard
IR technology and fast recognition of common subsequences. In
Lab Report for PAN at CLEF 2010, 2010.
[20] J. Grman and R. Ravas. Improved implementation for finding
text similarities in large sets of data - Notebook for PAN at
CLEF 2011. In V. Petras, P. Forner, and P. D. Clough, editors,
CLEF (Notebook Papers/Labs/Workshop), 2011.
[21] P. Gupta, A. Barrón-Cedeño, and P. Rosso. Cross-language
high similarity search using a conceptual thesaurus. In Proc.
3rd Int. Conf. of CLEF Initiative on Information Access Eva-
luation meets Multilinguality, Multimodality, and Visual Analy-
tics. CLEF 2012, 2012.
[22] P. Gupta and P. Rosso. Text reuse with acl: (upward) trends.
In Proceedings of the ACL-2012 Special Workshop on Redisco-
vering 50 Years of Discoveries, ACL ’12, pages 76–82, Strouds-
burg, PA, USA, 2012. Association for Computational Linguis-
tics.
[23] C. Havasi. Conceptnet 3: A flexible, multilingual semantic net-
work for common sense knowledge. In Proc. of the 22nd Conf.
on Artificial Intelligence, 2007.
[24] A. Hotho, S. Staab, and G. Stumme. Ontologies improve text
document clustering. In Proc. of the ICDM 03, The 2003 IEEE
International Conference on Data Mining, pages 541–544, 2003.
BIBLIOGRAFÍA 66
[25] P. Jackson and I. Moulinier. Natural language processing for on-
line applications: Text retrieval, extraction and categorization.
John Benjamins Publishing Company, 2002.
[26] N. Kang, A. Gelbukh, and S. Han. PPChecker: Plagiarism
Pattern Checker in document copy detection. In Text, Speech
and Dialogue (TSD 2006), volume LNAI (4188), pages 661–667.
Springer-Verlag, 2006.
[27] L. Kong, H. Qi, S. Wang, C. Du, S. Wang, and Y. Han. Ap-
proaches for candidate document retrieval and detailed com-
parison of plagiarism detection. In P. Forner, J. Karlgren,
and C. Womser-Hacker, editors, CLEF (Online Working No-
tes/Labs/Workshop), 2012.
[28] M. Kuramochi and G. Karypis. Frequent subgraph discovery.
In Proceedings of the 2001 IEEE International Conference on
Data Mining, ICDM ’01, pages 313–320, Washington, DC, USA,
2001. IEEE Computer Society.
[29] M. Li and P. M. Vitnyi. An introduction to Kolmogorov com-
plexity and its applications. Springer Publishing Company, In-
corporated, 3 edition, 2008.
[30] P. Mcnamee and J. Mayfield. Character n-gram tokenization
for European language text retrieval. Information Retrieval,
7(1):73–97, 2004.
[31] S. Meyer zu Eissen and B. Stein. Intrinsic plagiarism detec-
tion. In Advances in Information Retrieval: Proceedings of the
28th European Conference on IR Research (ECIR 2006), volu-
me LNCS(3936), pages 565–569. Springer-Verlag, 2006.
[32] M. Montes y Gómez, A. F. Gelbukh, A. López-López, and R. A.
Baeza-Yates. Flexible comparison of conceptual graphs. In
Proc. DEXA, pages 102–111, 2001.
[33] R. Navigli and S. P. Ponzetto. Babelnet: building a very large
multilingual semantic network. In Proc. of the 48th annual
meeting of the association for computational linguistics, ACL
’10, pages 216–225, Stroudsburg, PA, USA, 2010.
BIBLIOGRAFÍA 67
[34] R. Navigli and S. P. Ponzetto. Babelnet: The automatic cons-
truction, evaluation and application of a wide-coverage multi-
lingual semantic network. Artif. Intell., 193:217–250, Dec. 2012.
[35] R. Navigli and S. P. Ponzetto. BabelNetXplorer: A platform for
multilingual lexical knowledge dase access and exploration. In
Companion Volume to the Proceedings of the 21st World Wide
Web Conference, Lyon, France, 16–20 April 2012, pages 393–
396, 2012.
[36] R. Navigli and S. P. Ponzetto. Multilingual wsd with just a few
lines of code: The babelnet api. In Proc. 50th annual meeting
of the association for Computational Linguistics, 2012.
[37] F. J. Och and H. Ney. A systematic comparison of various sta-
tistical alignment models. Computational Linguistics, 29(1):19–
51, 2003.
[38] B. Pang and L. Lee. Opinion mining and sentiment analysis.
Found. Trends Inf. Retr., 2(1-2):1–135, Jan. 2008.
[39] R. C. Pereira, V. P. Moreira, and R. Galante.
UFRGS@PAN2010: Detecting external plagiarism - Lab report
for PAN at CLEF 2010. In M. Braschler, D. Harman, and
E. Pianta, editors, CLEF (Notebook Papers/LABs/Workshops),
2010.
[40] D. Pinto, J. Bened́ı, and P. Rosso. Clustering narrow-domain
short texts by using the kullback-leibler distance. In Compu-
tational Linguistics and Intelligent Text Processing, pages 611–
622, 2007.
[41] D. Pinto, J. Civera, A. Barrón-Cedeño, A. Juan, and P. Rosso.
A statistical approach to crosslingual natural language tasks.
Journal of algorithms, 64(1):51–60, 2009.
[42] M. Potthast, A. Barrón-Cedeño, B. Stein, and P. Rosso. An
evaluation framework for plagiarism detection. In Proc. of the
23rd Int. Conf. on Computational Linguistics, COLING-2010,
pages 997–1005, Beijing, China, 2010.
BIBLIOGRAFÍA 68
[43] M. Potthast, A. Barrón-Cedeño, B. Stein, and P. Rosso. Cross-
language plagiarism detection. Language Resources and Eva-
luation, Special Issue on Plagiarism and Authorship Analysis,
45(1):45–62, 2011.
[44] M. Potthast, A. Eiselt, A. Barrón-Cedeño, B. Stein, and P. Ros-
so. Overview of the 3rd int. competition on plagiarism detec-
tion. In CLEF (Notebook Papers/Labs/Workshop), 2011.
[45] M. Potthast and B. Stein. New issues in near-duplicate detec-
tion. Data Analysis, Machine Learning and Applications, pages
601–609, 2008.
[46] B. Pouliquen, R. Steinberger, and C. Ignat. Automatic linking
of similar texts across languages. In Proc. Recent Advances in
Natural Language Processing III, pages 307–316. RANLP’03,
2003.
[47] P. Scanlon and D. Neumann. Internet plagiarism among college
students. J Coll Student Dev, 43:375–385, 2002.
[48] S. Schleimer, D. S. Wilkerson, and A. Aiken. Winnowing: Lo-
cal algorithms for document fingerprinting. In ACM SIGMOD
Conference, pages 76–85, 2004.
[49] H. Schmid. Probabilistic part-of-speech tagging using decision
trees. In Proc. Int. Conf. on new methods in language proces-
sing, 1994.
[50] L. Seaward and S. Matwin. Intrinsic plagiarism detection using
complexity analysis. In Agirre (Eds.). PAN’09, pages 56–61,
2009.
[51] H. Somers, F. Gaspari, and A. Niño. Detecting inappropriate
use of free online machine translation by language students –
a special case of plagiarism detection. In Proc. of the Eleventh
Annual Conference of the European Association for Machine
Translation, pages 41–48, 2006.
[52] J. F. Sowa. Conceptual structures: information processing in
mind and machine. Addison-Wesley Longman, 1984.
BIBLIOGRAFÍA 69
[53] J. F. Sowa. Knowledge representation: logical, philosophical and
computational foundations. Brooks/Cole Publishing Co., 1999.
[54] E. Stamatatos. Intrinsic plagiarism detection using character n-
gram profiles. In Proc. of the 3rd Int. Workshop on Uncovering
Plagiarism, Authorship, and Social Software Misuse, pages 38–
46, 2009.
[55] B. Stein and M. Anderka. Collection-relative representations:
A unifying view to retrieval models. In Proc. 20th Int. Conf.
on database and expert systems applications, DEXA’09, pages
383–387. A. M. Tjoa & R. R. Wagner (Eds.), 2009.
[56] B. Stein, M. Koppel, and E. Stamatatos. Plagiarism analysis,
authorship identification, and near-duplicate detection. SIGIR
Forum (PAN 2007), 41(2):68–71, 2007.
[57] B. Stein and M. Potthast. Applying hash-based indexing in
text-based information retrieval. In Proc. of the 7th Dutch-
Belgian Information Retrieval Workshop, pages 29–35. M.
Moens, T. Tuytelaars, and A. de Vries, editors, 2007.
[58] R. Steinberger, B. Pouliquen, and C. Ignat. Exploiting multi-
lingual nomenclatures and language-independent text features
as an interlingua for cross-lingual text analysis applications.
In Proc. 4th Slovenian language technology conference, IS’2004.
Information Society, 2004.
[59] R. Steinberger, B. Pouliquen, A. Widiger, C. Ignat, T. Erjavec,
D. Tufis, and D. Varga. The jrc-acquis: A multilingual aligned
parallel corpus with +20 languages. In Proc. 5th Int. Conf. on
language resources and evaluation. LREC’2006, 2006.
[60] A. Vinokourov, J. Shawe-Taylor, and N. Cristianini. Inferring
a semantic representation of text via cross-language correlation
analysis. In Proc. NIPS-02: Advances in neural information
processing systems, pages 1473–1480. S. Becker, S. Thrun, &
K. Obermayer (Eds.), 2003.
[61] P. Vossen. Eurowordnet: A multilingual database of autono-
mous and language-specific wordnets connected via an inter-
BIBLIOGRAFÍA 70
lingual index. In Proc. Int. Journal of Lexicography, volume 17,
2004.
Apéndice A
Publicaciones y charlas
invitadas
Las investigaciones descritas en esta tesis han permitido la pu-
blicación de los siguientes art́ıculos:
M. Franco-Salvador, P. Gupta and P. Rosso. Cross-Language
Plagiarism Detection using a Multilingual Semantic Network.
In 35th European Conference on Information Retrieval (ECIR’13).
Springer-Verlag, LNCS(7814), Moscow, Russia, 2013. (CORE
B)
M. Franco-Salvador, P. Gupta and P. Rosso. Cross-language
Plagiarism Detection Using BabelNet’s Statistical Dictionary.
Computación y Sistemas, Revista Iberoamericana de Compu-
tación, ISSN 1405-5546, vol. 16, num. 4, pp. 383-390, 2012.
(included in the Index of Excellence of CONACyT,
Scopus, Redalyc, E-Journal, Latindex, Biblat, Periódi-
ca, DBLP and SciELO)
M. Franco-Salvador, P. Gupta and P. Rosso. Graph-Based Si-
milarity Analysis: A New Approach to Cross-Language Pla-
giarism Detection. Journal of the Spanish Society of Natural
Language Processing (Sociedad Española de Procesamiento del
Languaje Natural), 2013. (submitted) (included in the Index
of Excellence of RECYT, Scopus, DICE, RESH, Biblio-
71
APÉNDICE A. PUBLICACIONES Y CHARLAS INVITADAS 72
teca.Net, LATINDEX, CARHUS PLUS+, CINDOC-
CSIC, e-Revistas, RUA, Dialnet and INIST)
El contenido de este trabajo de investigación también se ha di-
vulgado mediante las siguientes charlas invitadas:
Graph-Based Similarity Analysis: A New Approach to
Cross-Language Plagiarism Detection.
Centro de Investigación en Computación (CIC). Instituto Po-
litécnico Nacional. México D.F., México. Nov. 2012
Cross-Language Plagiarism Detection using a Multilin-
gual Semantic Network.
Instituto Nacional de Astrof́ısica, Óptica y Electrónica (INAOE).
Puebla, México. Dec. 2012
