S.J. Yang, A.M. Greenberg, and M. Endsley (Eds.): SBP 2012, LNCS 7227, pp. 222–230, 2012. 
© Springer-Verlag Berlin Heidelberg 2012 
Implicit Group Membership Detection in Online Text: 
Analysis and Applications 
Jeffrey Ellen, Joan Kaina, and Shibin Parameswaran 
Space and Naval Warfare Systems Center Pacific 
United States Navy, San Diego, CA, USA 
{jeffrey.ellen,joan.kaina,shibin.parameswaran}@navy.mil 
Abstract. Our thesis is that members of the same group have shared tendencies 
and nuances in communication style and substance, particularly online. In this 
paper, we dicuss some potential applications of accuarate authorship affiliation 
technology. We also discuss related work in similar author identification efforts 
and the research issues that currently exist when trying to perform automated 
authorship affiliation. We provide quantitative results from our recent Machine 
Learning experimenation using Support Vector Machines as some initial 
validation of our theory. In this paper, we applied our work towards the task of 
classifying website forum posts by the affiliation of their author. We discuss in 
detail the stylometric features we used to perform the automated classification 
and split the original features into individual groups to isolate their respective 
contributions and/or discriminating capability. Our results show promise 
towards automating group representation, an important first step in studying 
group formation. 
Keywords: Stylometrics, Text classification, Group detection, Authorship 
affiliation, Group Membership, Deception detection, Natural Language Processing, 
Machine Learning. 
1 Introduction 
As the mechanisms permitting social interactions via computers have become more 
sophisticated, so has community behavior. And as the interfaces and mechanisms 
have become more intuitive and familiar, aspects of online social behavior mimic 
those in offline interactions. According to Communication Accommodation Theory 
formulated by Giles, et al. in 1973[1], aspects of offline communications and social 
interactions include mimicry and adoption of language customs and norms within 
groups, and research shows that this holds for online communications [2]. It should 
therefore be possible to classify online communications according to the author’s 
affiliation with one or more groups. One social pattern of particular interest to 
security and financial applications occurs when individuals attempt to infiltrate a 
group in order to alter the opinion of other group’s members, or simply gain 
credibility from posing as a group member. 
 
 Implicit Group Membership Detection in Online Text: Analysis and Applications 223 
In this paper, we explore the current state of this research (both from the machine 
learning as well as the social science perspective) and potential applications of this 
general technology. For our specific application, we worked towards classifying 
website forum posts based on their authorship affiliation to a particular group.  
1.1 Background and Motivation 
There are many domains where knowing the affiliation of an anonymous/pseudonymous 
author would be of interest.  
For instance, the knowledge of an author’s affiliations (implicit/explicit group 
memberships) can help detect bias in financial opinions and reviews thereby ferreting 
out possible shills. Applying this idea to movie reviews and product reviews could 
result in more effective advertising and better public relations campaigns. Market 
researchers, in particular, could use authorship affiliation, along with sentiment 
analysis, to better ascertain group-wise demographic information of customer reviews. 
Conversely, consumers could use affiliation to help detect spam, when the 
communication belies the author’s affiliation as a marketer. A more effective and 
efficient marketplace is of benefit to all consumers. 
Another potential application is clustering friends in social networking sites based 
on their stylometric similarities in statuses, comments, etc. Identifying an individual 
as a member of a group adds a richer set of features to that individual. Membership in 
multiple groups can also be used to determine an individual’s influence. 
In developing technology for the United States Department of Defense, our main 
goal is assisting intelligence analysis at identifying those who wish to bring harm 
against others. In our first application of this technology, we are seeking to perform 
group affiliation for purposes such as determining whether posts of an inflammatory 
nature within a certain community are being authored by actual members of the 
community, or by infiltrators and propagandists trying to sway a stable population or 
political group. It may then be possible to measure the author’s influence, the 
frequency of the topic discussion, the sentiment, etc. to predict a group tipping point 
that indicates a change in group behavior. Similar to the market research example 
earlier, in combination with sentiment analysis, improved group-wise demographics 
might better guide foreign policy decisions.  
The work in this paper is an important first step towards achieving some of these 
goals, more broadly referred to as “Cognitive Information Operations” [3]. 
1.2 Related Work 
Detection of group membership implicit in an anonymous author’s authorship style 
and word usage is a novel application. To the best of our knowledge, there is a 
shortage of research studies in this particular NLP application. However, there are 
other NLP applications that employ related methods with different objectives. One 
such field that is closely related is authorship attribution [4], which is an attempt to 
identify patterns (‘signatures’ or ‘fingerprints’) to identify a particular author [5][6]. 
There are numerous studies in this area including one which attempts to identify a 
particular forum post author from a pre-determined group of 20 authors [7]. Although 
224 J. Ellen, J. Kaina, and S. Parameswaran 
similar in application area, we feel group affiliation is a more generalized (and hence 
complex) case of where group level stylometric properties and patterns are identified 
instead of individual characteristics to be applied to an individual impostor or 
impersonator. 
Our research has not found many other researchers attempting to experimentally 
validate or apply group stylometrics. A recent survey by Juola suggests that 
authorship properties can be extended to many groups such as native speakers and 
gender [8]. However, Juola only specifically references one study identifying author 
gender [10] and that study specifically targets “formal written documents”.  
Other techniques researched heavily by the Natural Language Processing 
community are written text sentiment analysis, topic discovery, and automatic 
summarization. These topics, although popular with substantial research activity over 
the past 10 years, are hampered if applied to data written to deceive the audience or 
otherwise inauthentic. Group affiliation is tangential to these areas and attempts to 
identify patterns in authorship style that may or may not be a conscious choice of the 
author, which makes our approach potentially more robust to deception. A recent study 
[9] used topic analysis to group scientific papers based on the originating conference 
but in our application area we are specifically trying to differentiate between the 
affiliations of authors discussing unconstrained topics in informal blog postings. In 
addition, the referenced study uses exclusively bag-of-word topics generated by LDA, 
while we are interested in investigating the applicability of other stylistic features in 
addition to term selection. We are investigating not just the tangible output text, but the 
author’s decision process in creating that text. 
1.3  Communication Modeling Research Issues 
Our intuition that linguistic styles and grammatical nuances are shared amongst 
people with a common background (group) and can be detected via textual media is 
shared by social scientists and linguists regarding communication [1] and style [19], 
and algorithms can be developed based on quantifiable aspects of communication 
model and stylometrics. Other researchers have attempted to classify authors based on 
gender [10], age [11] and both [9][12]. The right feature can be very powerful: The 
latter study reported accuracies in the range ~80-90% using only two simple features: 
sentence length and slang word usage.  
It is interesting to note that all previous studies focus on inherent traits that are not 
a voluntary choice of the author, such as age or native language [13], unlike the group 
affiliation which we are targeting. One of the most interesting aspects of group 
affiliation detection is the mixed nature of conscious and unconscious choices in style 
an author makes as a member of a group. There has been success in individual 
authorship identification based on a variety of linguistic features [20][21], but 
regardless of whether or not there is currently a socio-behavioral rationale for why a 
particular linguistic feature is significant, ultimately performance in automated 
algorithms is the most significant criteria for our usage. The problem can be attacked 
from both directions. Some features are trivial to experimentally validate using 
Machine Learning, others such as respect or eccentricity [3] have solid socio-
psychological rationale but are difficult to quantify and utilize algorithmically. 
Comparison of both theory and results can help determine the most worthwhile 
features and achieve the best results. 
 Implicit Group Membership Detection in Online Text: Analysis and Applications 225 
In this investigation we have focused on extracting and testing features that are 
capable of capturing this mixture of conscious and unconscious communication 
decisions. We hypothesize that group affiliations of authors can be predicted through 
their language; their stylistic, structural, and thematic choices, which are 
manifestations of their cognitive model [3] and will have implicit signatures 
representative of their natural inclinations and affiliations. 
2 Feature Extraction 
In our previous publication [22], we started our analysis of group affiliation detection 
which focused on feasibility and reported performance measures on a composite set of 
features. This paper continues our research by decomposing and analyzing the different 
features we used and their contributions as stand-alone representations of the document 
in question.   
• Raw Term Frequency: Much current work on document classification focuses on 
sorting documents by subject, which naturally has a heavy reliance on term 
frequency (TF) or a variant thereof. Usually when using a TF feature set, it is 
conventional to stem or lemmatize the words. We have chosen to use the raw TF 
without these modifications to keep the stylistic features intact. Stop words were 
removed using the list in Natural Language Toolkit (NLTK).  
• Exclusive terms: Usage statistic of terms of exclusion. E.g. but, except, without, 
exclude.   
• Negation terms: Usage statistic of terms of negation. E.g. no, never, not, *n’t etc. 
• Causation terms: Usage statistic of terms showing causation. E.g. due, because, as, 
since, consequently, hence, so, therefore, accordingly, thus, if, unless, lest etc. 
• Function terms: Usage statistic of 303 specific terms that signify function that were 
reported in [14]. 
• Noun referencing: Different types of noun referencing employed. E.g. 
definite/indefinite, article/demonstrative, pronoun immediately preceding noun etc. 
This is an effort to characterize cultural or group styles e.g. respect to an 
individual. 
• Sentence lengths and closures: Percent of sentences falling in a discrete number of 
length ranges and types of sentence closures used (normal/questions/exclamations 
etc.). An attempt to capture and track author-group’s structural decisions and 
syntactic and semantic choices [6]. 
• Parts Of Speech (POS):   Ratio of terms in each of 50 different POS tags provided 
in python NLTK package which is a maximum entropy tagger trained against the 
University of Pennsylvania Treebank data set [15]. 
• Pronoun usage: Ratio of pronouns in each of 9 different categories: 2nd person, 3rd 
person, demonstrative, possessive, etc. Along with stylistic choices, this is a 
simplistic and straightforward effort to capture cultural and other group related 
word preferences in addressing peers, older, higher stature etc. 
The straightforward nature of most of these features (ratios, term-counts etc.) is an 
attempt to give simple mathematical representations to complex properties of 
226 J. Ellen, J. Kaina, and S. Parameswaran 
language, and social norms and interactions in a group which will in turn facilitate 
automation in feature extraction. Features similar to these were also used in a recent 
work by Khosmood which attempted to disguise authorship through camouflage [16].   
3 Experimental Analysis  
3.1 Data Sets 
We used two different data sets for our experiments, one corpus as our control, and a 
second corpus representative of our problem domain. The first is the BitterLemons.org 
corpus. This corpus was released in 2006 [17] and has been used in various linguistic 
studies since, making it a good baseline. The corpus consists of 594 essays from an 
Israeli/Palestinian political discussion website, and is balanced with equal number of 
entries from both sides.  
The second corpus we used consisted of two groups of forum posts. The first group 
consisted of 2636 posts from 9 different websites. These posts were written in Arabic, 
but we translated the posts to English for our experiments. Most posts in this set would 
likely be considered extremist from the current United States Government point of 
view. The other group contained 537 posts from 9 other websites that would most 
likely be considered ‘moderate’ from the current United States Government 
perspective. Most were written in Arabic, with a small number written in Vietnamese, 
Pashtun, Russian or other languages; we experimented on the English translations. For 
our experiments we assigned all entries from a particular forum the same label. We 
selected distinct communities that have some overlap in vocabulary and structure, and 
trained our machine learning algorithms to discriminate between them. 
3.2 Performance Metrics 
Commonly used metrics like accuracy, precision, recall and F-measure are biased by 
the size individual classes and provide reliable evaluations only on balanced datasets. 
To reduce the effect of an unbalanced dataset on our evaluations and to present a 
comparison that is independent of specific performance evaluators, we have compared 
our results under 2 different metrics: Matthew’s Correlation Coefficient (MCC) [18], 
and Balanced Accuracy (BAc). These metrics are frequently used in situations where 
extremely unbalanced datasets are common, such as medical studies of cancer 
incidence rates. BAC values are in the range of [0, 1] whereas MCC scores range 
from -1 to 1.  
3.3 Machine Learning Experimentation 
We evaluated the group detection and discrimination capability of term frequency 
(unaltered), and other linguistic features listed in section 2 as individual feature-sets and in 
combination with each other. For simplicity and clarity, we have chosen linear Support 
Vector Machines (SVM) for classification. It is trivial and reasonable to substitute this 
algorithm with kernelized SVM (RBF, polynomial etc.) or any other classification 
algorithm; we experimented with other algorithms in our previous work [22]. 
 
 Implicit Group Membership Detection in Online Text: Analysis and Applications 227 
 
Fig. 1. Classificatio.n performance of different 
feature-types under Matthew’s Correlation 
Coefficient (MCC). For a two-class problem, 
random classification corresponds to a MCC 
value of 0 which is indicated by the dotted line 
 
Fig. 2. Classification performance of different 
feature-types under Balanced Accuracy 
(BAc). For a two-class problem, random 
classification corresponds to a BAc value of 
0.5 which is indicated by the dotted line 
The performance results obtained by the different feature types on Moderate-
Extreme forum data and BitterLemons.org dataset are presented in Figures 1 and 2 
respectively.  Term frequency, ratio of different POS tags, and ratio of pronoun types 
provide consistent and considerable discrimination across both data sets demonstrating 
suitability to identify distinctive styles of groups. The other four categories of features 
show good performance in our control dataset, while providing only marginal 
improvement over random classification on the Moderate-Extremist dataset. This can 
be explained due to the controlled nature of the posts, especially with respect to topic, 
in BitterLemons.org corpus. 
Finally, the results obtained from the combined feature set on both these datasets 
reveal interesting trends. The fact that the concatenated feature set is able to 
consistently extract improvements under all performance metric indicates gains to be 
realized by improving our feature combination method. Also, the high performance of 
the classification algorithms on both the datasets despite completely different group 
biases is promising. This indicates that more reliable group detection can be achieved 
by developing more linguistically oriented features and intelligently combining them 
with conventional TF-based features. 
4 Conclusion 
We have introduced the use of stylistic features along with term frequency for implicit 
author group affiliation detection from written text, specifically informal and semi-
formal online text. We were pleased with the high accuracy that we were able to 
achieve with our straightforward stylistic and TF features on our primary dataset on 
our target forum data. In some cases this was higher than our benchmark  
 
228 J. Ellen, J. Kaina, and S. Parameswaran 
Table 1. Group affiliation performance obtained from 
TF, and combination of TF and our 8 classes of 
Linguistic Features (TF+LIN) 
 
Metrics  MCC BAc 
Features  TF TF+LIN TF TF+LIN 
Moderate-Extreme 0.92 0.93 0.96 0.97 
BitterLemons.org 0.90 0.91 0.95 0.95 
 
 
BitterLemons dataset (Table 
1). Our simplified feature 
combination scheme 
(concatenation), our results, 
both TF and augmented TF 
(TF+LIN) are extremely 
encouraging. In addition to 
the classification results 
obtained from the complete 
feature set, we have also 
analyzed the contributions of 
individual feature types and their discriminating capability to gain better 
understanding of robustness of feature contributions, if any, in different datasets. 
Based on the small number of datasets analyzed, and the infancy of our linguistic 
features, it is possible our results are in fact classifying based on a confounding factor 
such as sentiment analysis or topic modeling instead of the intended stylistic analysis. 
With respect to our application, final accuracy is the only criteria, and results are 
extremely promising. With respect to advancing the science and providing 
understanding and insight, we feel we have started in the right direction. 
We feel there is untapped potential for even higher performance. There are other 
identifying and quantifying properties of group behaviors known to researchers in 
Social Science which we were not able to evaluate in this round of experimentation. 
Other features we plan to explore include the measurement of topic emphasis, the use 
of hedging words, and the use of elusive, noncommittal, and non-specific 
descriptions. We hope to continue to locate additional Social Science inspired features 
to try, as well as the theoretical underpinnings of the best performing features. Just as 
the medical community attempts to categorize groups based on behavioral 
informatics, we look for predictive features that point to group affiliations and 
authors’ influence on those groups. The ability to quantify or discretize new linguistic 
properties into features will allow researchers to utilize machine learning algorithms 
to automatically detect or classify groups. Large scale execution is possible by 
capitalizing on newly available representations and evolutions of behavior and culture 
online. We outlined numerous potential applications of authorship affiliation besides 
our own Department of Defense focus, all of which we feel would benefit society.  
Acknowledgements. The authors thank the Office of Naval Research and Martin 
Krueger for their support of this work. The authors also thank Dr. Marion Ceruti for 
her tireless contributions. This paper is the work of U.S. Government employees 
performed in the course of employment and no copyright subsists therein. This paper 
is approved for public release with an unlimited distribution. 
 Implicit Group Membership Detection in Online Text: Analysis and Applications 229 
References 
1. Giles, H., Taylor, D., Bourhis, R.: Towards a theory of interpersonal accomodation 
through language. In: Language in Society, vol. 2, pp. 177–192. Cambridge University 
Press (1973) 
2. Postmes, T., Spears, R., Lea, M.: The Formation of Group Norms in Computer-Mediated 
Communication. In: Human Communication Research, vol. 26, pp. 341–371. Sage 
Publications (2000) 
3. Ceruti, M.G., McGirr, S.C., Kaina, J.L.: Interaction of Language, Culture and Cognition in 
Group Dynamics for Understanding the Adversary. In: Proceedings of the National 
Symposium on Sensor and Data Fusion (NSSDF, Nellis AFB, Las Vegas, NV (2010) 
4. Holmes, D.I.: Authorship Attribution. Computers and the Humanities 28(2), 87–106 
(1994) 
5. Zheng, R., Li, J., Chen, H., Huang, Z.: A framework for authorship identification of online 
messages: Writing-style features and classification techniques. Journal of the American 
Society for Information Science and Technology 57(3), 378–393 (2006) 
6. Stamatatos, E.: A survey of modern authorship attribution methods. Journal of the 
American Society for Information Science and Technology, 538–556 (2009) 
7. Abbasi, A., Chen, H.: Applying Authorship Analysis to Extremist-Group Web Forum 
Messages. IEEE Intelligent Systems, 67–75 (2005) 
8. Juola, P.: Authorship attribution. Foundations and Trends in Information Retrieval 1(3), 
233–334 (2006) 
9. Booker, L., Strong, G.: Using Topic Analysis to Compute Identity Group Attributes. In: 
Social Computing, Behavioral Modeling, and Prediction, pp. 249–258 (2008) 
10. Koppel, M., Argamon, S., Shimoni, A.: Automatically Categorizing Written Texts by 
Author Gender. Literary and Linguistic Computing 17(3) (2002) 
11. Izumi, M., Miura, T., Shioya, I.: Estimating the date of blog authors by CRF. In: IEEE 
Pacific Rim Conference on Communications, Computers and Signal Processing, pp. 249–
252 (2007) 
12. Goswami, S., Sarkar, S., Rustagi, M.: Stylometric Analysis of Bloggers’ Age and Gender. 
In: Proceedings of the AAAI International Conference on Weblogs and Social Media 
(2009) 
13. Koppel, M., Schler, J., Zigdon, K.: Determining an author’s native language by mining a 
text for errors. In: Proceedings of Knowledge Discovery in Data Mining, pp. 624–628 
(2005) 
14. Argamon, S., Saric, M., Stein, S.S.: Style mining of electronic messages for multiple 
authorship discrimination: first results. In: Proceedings of Knowledge Discovery in Data 
Mining, pp. 475–480 (2003) 
15. Ratnaparkhi, A.: A Maximum Entropy Model for Part-Of-Speech Tagging. In: 
Proceedings of the Emperical Methods in Natural Language Processing, pp. 133–142 
(1996) 
16. Khosmood, F., Levinson, R.: Automatic Synonym and Phrase Replacement Show Promise 
for Style Transformation. In: Proceedings of the IEEE Ninth International Conference on 
Machine Learning and Applications, pp. 958–961 (2010) 
17. Lin, W.H., Wilson, T., Wiebe, J., Hauptmann, A.: Which side are you on? Identifying 
perspectives at the document and sentence levels. In: Proceedings of the Tenth Conference 
on Natural Language Learning, pp. 109–116 (2006) 
18. Matthews, B.W.: Comparison of the predicted and observed secondary structure of T4 
phage lysozyme. Biochim. Biophys. Acta 405, 442–451 (1975) 
230 J. Ellen, J. Kaina, and S. Parameswaran 
19. Burrows, J.F.: Word patterns and story shapes: The statistical analysis of narrative style. 
Literary and Linguistic Computing 2, 61–70 (1987) 
20. Stamatatos, E., Fakotakis, N., Kokkinakis, G.K.: Automatic Text Categorization in Terms 
of Genre, Author. Computational Linguist 26(4), 471–495 (2000) 
21. Argamon-Engelson, S., Koppel, M., Avneri, G.: Style-based text categorization: What 
newspaper am I reading? In: Proceedings of AAAI Workshop on Learning for Text 
Categorization, pp. 1–4 (1998) 
22. Ellen, J., Parameswaran, S.: Machine Learning for Author Affiliation within Web Forums. 
In: Proceedings of the IEEE Tenth International Conference on Machine Learning, pp. 
100–106 (2011) 
