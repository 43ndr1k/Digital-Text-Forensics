Chapter 13
Behavioral, Cognitive and Virtual Biometrics
Roman V. Yampolskiy
13.1 Introduction to Behavioral Biometrics1
With the proliferation of computers in our everyday lives need for reliable com-
puter security steadily increases. Biometric technologies provide user friendly and
reliable control methodology for access to computer systems, networks and work-
places [1–3]. Biometric methods uniquely identify persons based on intrinsic physi-
cal or behavioral characteristics. Most research is aimed at studying well established
physical biometrics such as fingerprint [4] or iris scans [5]. Behavioral biometrics
systems are usually less established, and only those which are in large part based
on muscle control such as keystrokes, gait or signature are well analyzed [6–11].
We define behavioral biometrics as any quantifiable actions of a person. Such ac-
tions may not be unique to the person and may take a different amount of time to be
exhibited by different individuals. Biometric systems begin by enrolling individu-
als in the system, essentially introducing them to the security system and collecting
personal data necessary for future authentication.
Behavioral biometrics provide a number of advantages over traditional biometric
technologies. They can be collected non-obtrusively or even without the knowledge
of the user. Collection of behavioral data often does not require any special hardware
and is thus very cost effective. While most behavioral biometrics are not unique
1This chapter is based on numerous previous surveys and in particular expands on work in “Be-
havioral Biometrics: a Survey and Classification.” by R. Yampolskiy and V. Govindaraju, which
appeared in the International Journal of Biometrics, 1(1), 81–113 and Taxonomy of Behavioral
Biometrics by same authors, a chapter in Liang Wang and Xin Geng (Eds.), Behavioral Biometrics
for Human Identification: Intelligent Applications, pp. 1–43, 2009. Republished with permission
of copyright holders IGI global and Inderscience.
R.V. Yampolskiy ()
University of Louisville, Louisville, KY, USA
e-mail: roman.yampolskiy@louisville.edu
A.A. Salah, T. Gevers (eds.), Computer Analysis of Human Behavior,
DOI 10.1007/978-0-85729-994-9_13, © Springer-Verlag London Limited 2011
347
348 R.V. Yampolskiy
enough to provide reliable human identification (recognition) they have been shown
to provide sufficiently high accuracy identity verification.
In accomplishing their everyday tasks, human beings employ different strategies,
use different styles and apply unique skills and knowledge. One of the defining
characteristics of a behavioral biometric is the incorporation of time dimension as
a part of the behavioral signature. The measured behavior has a beginning, dura-
tion, and an end [12]. Behavioral biometrics researchers attempt to quantify behav-
ioral traits exhibited by users and use resulting feature profiles to successfully verify
identity [13]. In this section we present an overview of most established behavioral
biometrics.
Behavioral biometrics can be classified into five categories based on the type
of information being collected about the user. The first category is made up of
authorship-based biometrics, which are based on examining a piece of text or a
drawing produced by a person. Verification is accomplished by observing style pe-
culiarities typical to the author of the work being examined, such as the used vocab-
ulary, punctuation or brush strokes.
The second category consists of Human-Computer Interaction (HCI)-based bio-
metrics [14]. In their everyday interaction with computers, humans employ differ-
ent strategies, use different styles and apply unique abilities and knowledge. Re-
searchers attempt to quantify such traits and use resulting feature profiles to suc-
cessfully verify identity. HCI-based biometrics can be further subdivided into addi-
tional categories, first one consisting of human interaction with input devices such
as keyboards, computer mice, and haptics, which is about registering inherent, dis-
tinctive and consistent muscle actions [15]. The second group consists of HCI-based
behavioral biometrics, which measure advanced human behavior such as strategy,
knowledge or skill exhibited by the user during interaction with different software.
The third group is closely related to the second one and is the set of the indi-
rect HCI-based biometrics which are the events that can be obtained by monitoring
user’s HCI behaviors indirectly via observable low-level actions of computer soft-
ware [16]. Those include system call traces [17], audit logs [18], program execution
traces [19], registry access [20], storage activity [21], call-stack data analysis [22]
and system calls [23, 24]. Such low-level events are produced unintentionally by the
user during interaction with different software items. The same HCI-based biomet-
rics are sometimes known to different researchers under different names. Intrusion
Detection Systems (IDS) based on system calls or audit logs are often classified as
utilizing program execution traces and those based on call-stack data as based on
system calls. The confusion is probably related to the fact that a lot of interdepen-
dency exists between different indirect behavioral biometrics and they are frequently
used in combinations to improve accuracy of the system being developed. For exam-
ple system calls and program counter data may be combined in the same behavioral
signature, or audit logs may contain information about system calls. Because they
are indirect measures of behavior, they are outside of the scope of the current dis-
cussion and will not be evaluated in any detail in this chapter. The interested reader
is encouraged to read the survey of indirect behavioral biometrics [16] for additional
information.
13 Behavioral, Cognitive and Virtual Biometrics 349
The fourth and probably the best researched category of behavioral biometrics
relies on motor-skills of the users to accomplish verification [25]. Motor skill is an
ability of a human being to utilize muscles. Muscle movements rely upon the proper
functioning of the brain, skeleton, joints, and nervous system and so motor skills
indirectly reflect the quality of functioning of such systems, making person verifica-
tion possible. Most motor skills are learned, not inherited, with disabilities having
potential to affect the development of motor skills. We adopt here a definition for
motor-skill-based behavioral biometrics, a.k.a. kinetics, as those biometrics which
are based on innate, unique and stable muscle actions of the user while performing
a particular task [26].
The fifth and final category consists of purely behavioral biometrics. Purely be-
havioral biometrics are those which measure human behavior directly (not concen-
trating on measurements of body parts) or intrinsic, inimitable and lasting muscle
actions, such as the way an individual walks, types or even grips a tool [26]. Hu-
mans utilize different strategies, skills and knowledge during performance of men-
tally demanding tasks. Purely behavioral biometrics quantify such behavioral traits
and make successful identity verification a possibility.
The present chapter additionally looks at Behavioral Passwords, Biosignals and
Virtual Biometrics, such as avatar representations of the user. All of the authenti-
cation approaches reviewed in this chapter share a number of characteristics and
so can be analyzed as a group using the seven properties of good biometrics pre-
sented by Jain et al. [5, 27]. It is a good idea to check them before declaring some
characteristics suitable for the automated recognition of individuals.
• Universality Behavioral biometrics are dependent on specific abilities possessed
by different people to a different degree (or not at all) and so in a general popu-
lation, the universality of behavioral biometrics is very low. But since behavioral
biometrics are only applied in a specific domain, the actual universality of behav-
ioral biometrics is a 100%.
• Uniqueness Since only a small set of different approaches to performing any
task exists, uniqueness of behavioral biometrics is relatively low. Number of ex-
isting writing styles, different game strategies and varying preferences are only
sufficient for user verification, and not identification, unless the set of users is
extremely small [28].
• Permanence Behavioral biometrics exhibit a low degree of permanence, as they
measure behavior which changes with time as the person learns advanced tech-
niques and faster ways of accomplishing tasks. However, this problem of concept
drift is addressed in behavior-based intrusion detection research, and systems are
developed capable of adjusting to the changing behavior of the users [29, 30].
• Collectability Collecting behavioral biometrics is relatively easy and unobtrusive
to the user. In some instances the user may not even be aware that data collection
is taking place. The process of data collection is fully automated and is of very
low cost.
• Performance The identification accuracy of most behavioral biometrics is low,
particularly as the number of users in the database becomes large. However veri-
fication accuracy is very good for some behavioral biometrics.
350 R.V. Yampolskiy
• Acceptability Since behavioral biometric characteristics can be collected without
user participation, they enjoy a high degree of acceptability, but might be objected
to for ethical or privacy reasons.
• Circumvention It is relatively difficult to get around behavioral biometric sys-
tems as they require intimate knowledge of someone else’s behavior, but once
such knowledge is available, fabrication might be very straightforward [31]. This
is why it is extremely important to keep the collected behavioral profiles securely
encrypted.
13.2 Description of Behavioral Biometrics
Table 13.1 shows majority of behavioral biometrics covered in this chapter, classi-
fied according to the five categories outlined in the previous section [32]. Many of
the reviewed biometrics are cross-listed in multiple categories due to their depen-
dence on multiple behavioral attributes. In addition, enrolment time and verification
time (D = days, H = hours, M =Minutes, S = Seconds) of the listed biometrics
are provided, as well as any hardware required for the collection of the biometric
characteristic data. Out of all the listed behavioral biometrics only two are believed
to be useful not just for person verification, but also for reliable large scale person
identification. Those are: signature/handwriting and speech. Other behavioral bio-
metrics may be used for identification purposes but are not reliable enough to be
employed in that capacity in real-world applications.
Presented next are short overviews of the most researched behavioral biometrics
listed in alphabetical order [32]. Figure 13.1 provides a visual overview of some of
the presented behavioral biometrics.
13.2.1 Avatar Representation
With the advent of virtual communities such as Second Life, a lot of modern social
interactions take place in cyber-worlds. In such interactions users are represented
by virtual characters known as Avatars, which they design based on personal pref-
erences. Recent work by Yampolskiy et al. [33–37] has shown that visual and be-
havioral aspects of avatars could be profiled for the purpose of user verification or
identification. It is interesting to note that some biometric methods came very close
to avatar development and intelligent robots/software authentication on a number of
different instances. For example, in 1998, M.J. Lyons and his colleagues published
a report: “Avatar Creation using Automatic Face Recognition”, where authors dis-
cussed specific steps and processing techniques that need to be taken in order for an
avatar to be created almost automatically from the human face [38]. In fact, the pro-
cess described in the above article is essentially the process of biometric synthesis,
conceptualized and generalized in the book devoted specifically to this subject [39].
13 Behavioral, Cognitive and Virtual Biometrics 351
Ta
bl
e
13
.1
C
la
ss
ifi
ca
tio
n
an
d
pr
op
er
tie
s
of
be
ha
vi
or
al
bi
om
et
ri
cs
[3
2]
C
la
ss
ifi
ca
tio
n
of
th
e
V
ar
io
us
Ty
pe
s
of
B
eh
av
io
ra
lB
io
m
et
ri
cs
A
ut
ho
rs
hi
p
D
ir
ec
tH
um
an
C
om
pu
te
r
In
te
ra
ct
io
n
M
ot
or
Sk
ill
Pu
re
ly
B
eh
av
io
ra
l
Pr
op
er
tie
s
of
B
eh
av
io
ra
lB
io
m
et
ri
cs
In
pu
t
D
ev
ic
e
In
te
ra
ct
io
n
B
as
ed
So
ft
w
ar
e
In
te
ra
ct
io
n
B
as
ed
E
nr
ol
m
en
t
tim
e
V
er
ifi
ca
tio
n
tim
e
Id
en
tifi
ca
tio
n
R
eq
ui
re
d
H
ar
dw
ar
e
A
va
ta
r
R
ep
re
se
nt
at
io
n
"
M
M
N
C
om
pu
te
r
B
io
m
et
ri
c
Sk
et
ch
"
"
M
S
N
M
ou
se
B
lin
ki
ng
"
M
S
N
C
am
er
a
C
al
lin
g
B
eh
av
io
r
"
D
D
N
Ph
on
e
C
ar
D
ri
vi
ng
St
yl
e
"
H
M
N
C
ar
Se
ns
or
s
C
en
te
r
of
G
ra
vi
ty
"
M
S
N
Sh
oe
Se
ns
or
s
C
om
m
an
d
L
in
e
L
ex
ic
on
"
"
H
H
N
C
om
pu
te
r
C
re
di
tC
ar
d
U
se
"
D
D
N
C
re
di
tC
ar
d
D
yn
am
ic
Fa
ci
al
Fe
at
ur
es
"
M
S
N
C
am
er
a
E
m
ai
lB
eh
av
io
r
"
"
"
D
M
N
C
om
pu
te
r
Fi
ng
er
Pr
es
su
re
"
M
S
N
Pr
es
su
re
Se
ns
or
Fl
oo
r
Pr
es
su
re
"
M
S
N
Fl
oo
r
Se
ns
or
G
ai
t/S
tr
id
e
"
M
S
N
C
am
er
a
G
am
e
St
ra
te
gy
"
"
H
H
N
C
om
pu
te
r
G
az
e/
E
ye
T
ra
ck
in
g
"
M
S
Y
E
ye
T
ra
ck
er
H
an
dg
ri
p
"
M
S
N
G
un
Se
ns
or
s
H
ap
tic
"
"
M
M
N
H
ap
tic
352 R.V. Yampolskiy
Ta
bl
e
13
.1
(C
on
tin
ue
d)
C
la
ss
ifi
ca
tio
n
of
th
e
V
ar
io
us
Ty
pe
s
of
B
eh
av
io
ra
lB
io
m
et
ri
cs
A
ut
ho
rs
hi
p
D
ir
ec
tH
um
an
C
om
pu
te
r
In
te
ra
ct
io
n
M
ot
or
Sk
ill
Pu
re
ly
B
eh
av
io
ra
l
Pr
op
er
tie
s
of
B
eh
av
io
ra
lB
io
m
et
ri
cs
In
pu
t
D
ev
ic
e
In
te
ra
ct
io
n
B
as
ed
So
ft
w
ar
e
In
te
ra
ct
io
n
B
as
ed
E
nr
ol
m
en
t
tim
e
V
er
ifi
ca
tio
n
tim
e
Id
en
tifi
ca
tio
n
R
eq
ui
re
d
H
ar
dw
ar
e
H
um
an
Sh
ad
ow
s
"
M
S
N
C
am
er
a
K
ey
st
ro
ke
D
yn
am
ic
s
"
"
M
S
N
K
ey
bo
ar
d
L
ip
M
ov
em
en
t
"
M
S
N
C
am
er
a
M
ou
se
D
yn
am
ic
s
"
"
M
S
N
M
ou
se
M
ot
io
n
of
Fi
ng
er
s
"
M
S
N
C
am
er
a
Pa
in
tin
g
St
yl
e
"
"
D
D
N
Sc
an
ne
r
Pr
og
ra
m
m
in
g
St
yl
e
"
"
"
H
H
N
C
om
pu
te
r
Si
gn
at
ur
e/
H
an
dw
ri
tin
g
"
M
S
Y
St
yl
us
Sh
ir
tT
er
m
M
em
or
y
"
M
M
Y
M
ou
se
Ta
pp
in
g
"
M
S
N
Se
ns
or
Te
xt
A
ut
ho
rs
hi
p
"
"
H
M
N
C
om
pu
te
r
V
is
ua
lS
ca
n
"
M
M
Y
M
ou
se
V
oi
ce
/S
pe
ec
h/
Si
ng
in
g
"
M
S
Y
M
ic
ro
ph
on
e
13 Behavioral, Cognitive and Virtual Biometrics 353
Users of virtual words have also noted that avatars often take on the characteris-
tics of their creators, and not only their facial characteristics, but also body shape,
accessories and clothes.
But what about other, less obvious resemblances, such as manner of commu-
nication, responses to various situations, nature of work, style of house, leisure/
recreational activities, time of appearing in virtual world, etc.? All of the above
encompasses behavioral characteristics that can be exploited by the fusion of
biometric-based techniques, with methodology tailored to specifics of the virtual
world. Such behavioral characteristics, as the author of this chapter would postu-
late, are even less likely to change than the avatar’s facial appearance and clothes
during virtual world sessions, as users typically invest a lot of time and money in the
creation of a consistent virtual image, but would not so easily change their patterns
of behavior.
13.2.2 Biometric Sketch
Bromme et al. [40, 41] proposed a biometric sketch authentication method based
on sketch recognition and a user’s personal knowledge about the drawing’s content.
The system directs a user to create a simple sketch, for example of three circles, and
each user is free to do so in any way he pleases. Because a large number of different
combinations exist for combining multiple simple structural shapes, sketches of dif-
ferent users are sufficiently unique to provide accurate authentication. The approach
measures a user’s knowledge about the sketch, which is only available to the previ-
ously authenticated user. Such features as the sketch’s location and relative position
of different primitives are taken as the profile of the sketch. Finally a V-go Password
requests a user to perform the simulation of simple actions, such as mixing a cock-
tail using a graphical interface, with the assumption that all users have a personal
approach to bartending [42].
13.2.3 Blinking
Westeyn et al. [43], Westeyn and Starner [44] have developed a system for identi-
fying users by analyzing voluntary song-based blink patterns. During the enrolment
phase the user looks at the system’s camera and blinks to the beat of a song he
has previously chosen, producing a so-called “blinkprint”. During the verification
phase, the user’s blinking is compared to the database of the stored blinked pat-
terns to determine which song is being blinked and as a result user identification
is possible. In addition to the blink pattern itself, supplementary features can also
be extracted, such as: time between blinks, how long the eye is held closed at each
blink, and other physical characteristics the eye undergoes while blinking. Based on
those additional features, it was shown to be feasible to distinguish users blinking
the same exact pattern and not just a secretly selected song.
354 R.V. Yampolskiy
13.2.4 Calling Behavior
With the proliferation of the mobile cellular phone networks, communication com-
panies are faced with increasing amount of fraudulent calling activity. In order to
automatically detect theft of service, many companies are turning to behavioral user
profiling with the hopes of detecting unusual calling patterns to be able to stop fraud
at an earliest possible time. Typical systems work by generating a user calling pro-
file, which consists of usage indicators such as: date and time of the call, duration,
called ID, called number, cost of call, number of calls to a local destination, number
of calls to mobile destinations, number of calls to international destinations and the
total statistics about the calls for the day [45]. Grosser et al. [46] have shown that
neural networks can be successfully applied to such a feature vector for the purpose
of fraud detection. Fawcett et al. [47] developed a rule-learning program to uncover
indicators of fraudulent behavior from a large database of customer transactions.
13.2.5 Car Driving Style
People tend to operate vehicles in very different ways; some drivers are safe and
slow, others are much more aggressive and often speed and tailgate. As a result,
driving behavior can be successfully treated as a behavioral biometric. Erdogan et
al. [48] have shown that by analyzing pressure readings from the accelerator and
brake pedals in kilogram force per square centimeter, the vehicle speed in revolu-
tions per minute, and steering angle within the range of −720 to +720 degrees, it
is possible to achieve genuine versus impostor driver authentication. Gaussian mix-
ture modeling was used to process the resulting feature vectors, after some initial
smoothing and subsampling of the driving signal. Liu et al. [49] in their work on
prediction of driver behavior have demonstrated that inclusion of the driver’s vi-
sual scanning behavior can further enhance accuracy of the driver behavior model.
Once fully developed, driver recognition can be used for car personalization, theft
prevention, as well as for detection of drunk or sleepy drivers. With so many poten-
tial benefits from this technology, research in driver behavior modeling is not solely
limited to the biometrics community [50, 51].
13.2.6 Center of Gravity
Porwik et al. [52] have proposed a system based on analysis of the motion of the
human body’s gravity center. By utilizing specially designed shoe soles with sensors
and asking 15 volunteers to engage in some stationary movement (without lifting
their feet) they were able to collect time series data about the subjects’ center of
gravity.
13 Behavioral, Cognitive and Virtual Biometrics 355
13.2.7 Command Line Lexicon
A popular approach to the construction of behavior-based intrusion detection sys-
tems is based on profiling the set of commands utilized by the user in the process
of interaction with the operating system. A frequent target of such research is the
UNIX operating system, probably due to it having mostly command line nature.
Users differ greatly in their level of familiarity with the command set and all the
possible arguments which can be applied to individual commands. Regardless of
how well a user knows the set of available commands, most are fairly consistent in
their choice of commands used to accomplish a particular task.
A user profile typically consists of a list of used commands together with corre-
sponding frequency counts, and lists of arguments to the commands. Data collec-
tion process is often time consuming, since as many as 15,000 individual commands
need to be collected for the system to achieve a high degree of accuracy [53, 54].
Additional information about the session may also be included in the profile, such
as the login host and login time, which help to improve accuracy of the user profile,
as it is likely that users perform different actions on different hosts [55]. Overall,
this line of research is extremely popular, but recently a shift has been made toward
user profiling in a graphical environment such as Windows, as most users prefer the
convenience of a Graphical User Interface (GUI).
13.2.8 Credit Card Use
Data mining techniques are frequently used in detection of credit card fraud. Look-
ing out for statistical outliers such as unusual transactions, payments to far away
geographical locations or simultaneous use of a card at multiple locations can all be
signs of a stolen account. Outliers are considerably different from the remainder of
the data points and can be detected by using discordancy tests. Approaches for fraud
related outlier detection are based on distance, density, projection, and distribution
analysis methods. A generalized approach to finding outliers is to assume a known
statistical distribution for the data and to evaluate the deviation of samples from the
distribution. Brause et al. [56] have used symbolic and analog number data to detect
credit card fraud. Such transaction information as account number, transaction type,
credit card type, merchant ID, merchant address, etc. were used in their rule-based
model. They have also shown that analog data alone cannot serve as a satisfying
source for detection of fraudulent transactions.
13.2.9 Dynamic Facial Features
Pamudurthy et al. [57] proposed a dynamic approach to face recognition based on
dynamic instead of static facial features. They track the motion of skin pores on
356 R.V. Yampolskiy
the face during a facial expression and obtain a vector field that characterizes the
deformation of the face. In the training process, two high-resolution images of an
individual, one with a neutral expression and the other with a facial expression, like
a subtle smile, are taken to obtain the deformation field [58].
Smile recognition research in particular is a subfield of dynamic facial feature
recognition currently gaining in prominence [59]. The existing systems rely on
probing the characteristic pattern of muscles beneath the skin of the user’s face.
Two images of a person in quick progression are taken, with subjects smiling for the
camera in the second sample. An analysis is later performed of how the skin around
the subject’s mouth moves between the two images. This movement is controlled by
the pattern of muscles under the skin, and is not affected by the presence of make-up
or the degree to which the subject smiles [58]. Other researchers have done research
in this area under such names as: Facial Behavior [60] and Facial Actions [61].
13.2.10 Email Behavior
Email sending behavior is not the same for all individuals. Some people work at
night and send dozens of emails to many different addresses; others only check mail
in the morning and only correspond with one or two people. All these peculiarities
can be used to create a behavioral profile which can serve as a behavioral biometric
characteristic for an individual. Length of the emails, time of the day the mail is sent,
how frequently inbox is emptied and of course the recipients’ addresses among other
variables can all be combined to create a baseline feature vector for the person’s
email behavior. Some work in using email behavior modeling was done by Stolfo
et al. [62, 63]. They have investigated the possibility of detecting virus propagation
via email by observing abnormalities in the email sending behavior, such as unusual
clique of recipients for the same email. For example sending the same email to your
girlfriend and your boss is not an everyday occurrence.
De Vel et al. [64] have applied authorship identification techniques to determine
the likely author of an email message. Alongside the typical features used in text
authorship identification, authors also used some email specific structural features
such as: use of a greeting, farewell acknowledgment, signature, number of attach-
ments, position of re-quoted text within the message body, HTML tag frequency
distribution and total number of HTML tags. Overall, almost 200 features are used
in the experiment, but some frequently cited features used in text authorship deter-
mination are not appropriate in the domain of email messages due to the shorter
average size of such communications.
13.2.11 Finger Pressure
Many modern mobile devices are equipped with touchpad devices capable of de-
tecting pressure. Saevanee et al. [65] have proposed utilizing finger pressure as a
13 Behavioral, Cognitive and Virtual Biometrics 357
Table 13.2 Floor pressure biometric—accuracy rates comparison
Features Recognition
Rate
False Accept
Rate
Researchers Year
Pressure profile over footsteps 50% – Addlesee et al. [67] 1997
Trajectories of center of pressure 64% 5.8% Jung et al. [68] 2003
Pressure over the entire floor area 76.9% 11.6% Pirttikangas et al. [69] 2003
Stride length, stride cadence,
heel-to-toe ratio
80% – Middleton et al. [70] 2005
Compensated foot centers 92.8 – Yun et al. [71] 2003
Points from pressure profile 93% Orr et al. [72] 2000
Patterns of footsteps 92% – Yoon et al. [73] 2005
Pressure and time features 81.9% – Suutala et al. [74] 2008
Mean pressure and stride length 92.3% 6.79% Qian et al. [66] 2010
behavioral biometric and have achieved an impressive 99% accuracy rate. In their
experiments they combine finger pressure defined as the force applied over the finger
position with keystroke dynamics. Specifically Saevanee et al. consider the pressing
area not as a single point, but a group of multiple points on the pad. They utilize the
average value over these multiple pressing points to produce a representative feature
vector: FPi = [Pi,1,pi,2, . . . ,Pi,10] where Pi,j denotes the average value of finger
pressure values at the round i of digit j [65]. They were able to achieve an Equal
Error Rate value of 1% for a group of 10 test subjects and an accuracy rate of 99%.
13.2.12 Floor Pressure
While walking, people exert pressure on the floor surface, which could be analyzed
and used for personal authentication. Different types of floor sensors could be used
to collect floor pressure data; for example load cells, pressure mats, force sensitive
resistor mats and switch sensors have been experimented with. Qian et al. [66] used
a large high-resolution pressure sensing floor to capture a 1D pressure profile and
2D position trajectories for both feet. They later separate data from the two feet
and from those trajectories corresponding to the centers of pressure, extract fea-
tures such as the mean pressure and stride length. Extracted features were classified
with a Fisher’s linear discriminant classifier. Table 13.2 summarizes accuracy rates
obtained by different researchers of the floor pressure biometric [66].
13.2.13 Gaze/Eye Tracking
While viewing an image, a person goes through a sequence of eye fixation-saccade
events necessary to build up a perception of a scene. The spatial and temporal pat-
358 R.V. Yampolskiy
terns associated with eye tracking are widely varied between different people and
could be used to produce a visual attention map of each individual. The position of
gaze locations could be produced deliberately or subconsciously during viewing be-
havior and a simple webcam or a sophisticated eye-tracker device could be utilized
in the data collection process. For a given image, Maeder and Fookes [75] analyze
gaze data sampled at 15 fps using a spatial clustering algorithm to extract any fixa-
tions with an approximate viewing time of 1.0 secs and a tolerance of 0.3 secs. The
approach could be combined with a standard PIN-like authentication mechanism by
mapping locations on pre-labeled regions of the image [76].
13.2.14 Gait/Stride
Gait is one of the best researched muscle control-based biometrics [77–79]; it is
a complex spatio-temporal motor-control behavior which allows biometric recog-
nition of individuals at a distance, usually from captured video. Gait is subject to
significant variations based on the changes in a person’s body weight, waddling
during pregnancy, injuries of extremities or of the brain, or due to intoxication [27].
Typical features include: amount of arm swing, rhythm of the walker, bounce, length
of steps, vertical distance between head and foot, distance between head and pelvis,
maximum distance between the left and right foot [80].
13.2.15 Game Strategy
Yampolskiy et al. [81–83] proposed a system for verification of online poker play-
ers based on a behavioral profile, which represents a statistical model of player’s
strategy. The profile consists of frequency measures indicating range of cards con-
sidered by the player at all stages of the game. It also measures how aggressive the
player is via such variables as percentages of re-raised hands. The profile is actually
human readable, meaning that a poker expert can analyze and understand the strat-
egy employed by the player from observing his or her behavioral profile [84]. For
example just by knowing the percentage of hands a particular player chooses to play
pre-flop, it is possible to determine which cards are being played with high degree
of accuracy.
Ramon et al. [85] have demonstrated the possibility of identifying Go players
based on their style of game play. They analyzed a number of Go specific features
such as type of opening moves, how early such moves are made and total number of
liberties in the formed groups. They also speculated that the decision tree approach
they have developed can be applied to other games such as Chess or Checkers.
In [86], Jansen et al. report about their research in chess strategy inference from
game records. In particular, they were able to surmise good estimates of the weights
used in the evaluation function of computer chess players, and later applied same
13 Behavioral, Cognitive and Virtual Biometrics 359
techniques to human grandmasters. Their approach is aimed at predicting future
moves made by the players, but the opponent model created with some additional
processing can be utilized for opponent identification or at least verification. This
can be achieved by comparing new moves made by the player with predicted ones
from models for different players and using the achieved accuracy scores as an in-
dication of which profile models which player.
13.2.16 Handgrip
Developed mostly for gun control applications, grip-pattern recognition approach
assumes that users hold the gun in a sufficiently unique way to permit user verifica-
tion to take place. By incorporating a hardware sensor array in the gun’s butt, Kauff-
man et al. [87, 88] were able to get resistance measurements in as many as 44× 44
points which are used in the creation of a feature vector. Obtained pressure points
are taken as pixels in the pressure pattern image used as input for verification algo-
rithm based on a likelihood-ratio classifier for Gaussian probability densities [87].
Experiments showed that more experienced gun users tended to be more accurately
verified as compared to first time subjects.
13.2.17 Haptic
Haptic systems are computer input/output devices, which can provide us with infor-
mation about direction, pressure, force, angle, speed, and position of user’s interac-
tions [89, 90]. Because so much information is available on the user’s performance,
a high degree of accuracy can be expected from a haptic-based biometrics system.
Orozco et al. [89, 90] have created a simple haptic application built on an elastic
membrane surface, in which the user is required to navigate a stylus through the
maze. The maze has gummy walls and a stretchy floor. The application collects data
about the ability of the user to navigate the maze, such as reaction time to release
from sticky wall, the route, the velocity, and the pressure applied to the floor. The
individual user profiles are made up of such information as 3D world location of
the pen, average speed, mean velocity, mean standard deviation, navigation style,
angular turns and rounded turns. In a separate experiment Orozco et al. [91] imple-
ment a virtual mobile phone application where the user interacts through a haptic
pen to simulate making a phone call via a touch pad. The keystroke duration, pen’s
position, and exerted force are used as the raw features collected for user profiling.
13.2.18 Human Shadows
Shadow biometrics rely on the use of shadows and shadow dynamics for behavior-
based recognition of persons. In the above-the-head imagery taken from a large
360 R.V. Yampolskiy
distance, direct recognition of humans is not always possible due to limited view
of the observation angle. Shadows provide additional information, which may be
sufficient for person identification. Shadows have a larger observable area and re-
flect well the underlining gait dynamics, making biometric authentication possible.
Potential features of shadow biometrics include: shadow area, parameters for a trian-
gular model formed by extremities of head and the feet, parameters for a pentagonal
model formed by the head, two hands and two feet, correction for the position of the
light source (usually the sun), and dynamic features such as amplitude and period-
icity of movement and deviation from regularity [92]. Iwashita et al. [93] extracted
gait features from manually selected shadows and obtained a Correct Classifica-
tion Rate of over 95%. With automatic shadow area selection, accuracy dropped
to 90%.
13.2.19 Keystroke Dynamics
Typing patterns are characteristic to each person, some people are experienced typ-
ists utilizing the touch-typing method, and others utilize the hunt-and-peck approach
which uses only two fingers. Those differences make verification of people based
on their typing patterns a proven possibility, and some reports suggest identification
is also possible [94]. For verification a small typing sample such as the input of
user’s password is sufficient, but for recognition a large amount of keystroke data
are needed and identification is based on comparisons with the profiles of all other
existing users already in the system.
Keystroke features are based on time durations between the keystrokes, inter-
key strokes and dwell time, which is the time a key is pressed down, overall typing
speed, frequency of errors (use of backspace), use of numpad, the order in which the
user presses shift key to get capital letters and possibly the force with which keys are
hit for specially equipped keyboards [27, 94]. Keystroke dynamics are probably the
most researched type of HCI-based biometric characteristics, with novel research
taking place in different languages, for long text samples, and for email authorship
identification.
In a similar fashion, Bella et al. [95] have studied finger movements of skilled
piano players. They have recorded finger motion from skilled pianists while playing
a musical keyboard. Pianists’ finger motion and speed with which keys are struck
were analyzed using functional data analysis methods. Movement velocity and ac-
celeration were consistent for the participants and in multiple musical contexts. Ac-
curate pianist classification was achieved by training a neural network classifier us-
ing velocity/acceleration trajectories preceding key presses. Gamboa et al. [96] have
used keystroke dynamics in a system they called Webbiometrics, which used web
interaction for user verification.
13 Behavioral, Cognitive and Virtual Biometrics 361
13.2.20 Lip Movement
This approach, originally based on the visual speech reading technology, attempts to
generate a model representing the lip dynamics produced by a person during speech.
User verification is based on how close the generated model fits observed lip move-
ment. Such models are typically constructed around spatio-temporal lip features.
First the lip region needs to be isolated from the video feed, and then significant
features of lip contours are extracted, typically from edges and gradients. Lip fea-
tures include: the mouth opening or closing, skin around the lips, mouth width, up-
per/lower lip width, lip opening height/width, distance between horizontal lip line
and upper lip [97, 98]. Typically, lip dynamics is utilized as a part of a multimodal
biometric system, usually combined with speaker recognition-based authentication
[99–102], but stand-alone usage is also possible [103].
13.2.21 Mouse Dynamics
By monitoring all mouse actions produced by the user during an interaction with
the Graphical User Interface (GUI), a unique profile can be generated which can
be used for user re-authentication [23]. Mouse actions of interest include general
movement, drag and drop, point and click, and stillness. From those, a set of fea-
tures can be extracted, for example average speed against the distance traveled, and
average speed against the movement direction [104, 105]. Pusara et al. [23] describe
a feature extraction approach in which they split the mouse event data into mouse
wheel movements, clicks, menu and toolbar clicks. Click data are further subdivided
into single- and double-click data.
Gamboa et al. [106, 107] have tried to improve the accuracy of mouse-dynamics-
based biometrics by restricting the domain of data collection to an online game
instead of a more general GUI environment. As a result, the applicability of their
results is somewhat restricted, and the methodology is more intrusive to the user.
The system requires around 10–15 minutes of devoted game play instead of seam-
less data collection during normal user-computer interaction. As far as the extracted
features go, x and y coordinates of the mouse, horizontal velocity, vertical velocity,
tangential velocity, tangential acceleration, tangential jerk and angular velocity are
utilized with respect to the mouse strokes to create a unique user profile.
13.2.22 Motion of Fingers
Nishiuchi et al. [108] have proposed a method of identifying individuals using the
bending motion of fingers. The person being authenticated moves a finger over a
solid color background. This allows for easy finger detection and post-processing,
which involves calculation of the curvature defined as a value indicating the level
362 R.V. Yampolskiy
of bending at each point on a curve, or a curved surface. By extracting edge pixels
from a binary image of the forefinger they were able to calculate curvature involved
in the motion of the finger. The correlation coefficient is used for the evaluation of
the curvature profiles. In their experimental setup, Nishuchi et al. use seven angles
of the forefinger (15° to 45° in 5° increments) and utilize six test subjects. With the
decision threshold set at 0.970, the False Reject Rate is 0%.
13.2.23 Painting Style
Just like authorship of literary works can be attributed based on the writer’s style,
so can works of art be accredited based on the style of the drawing. In particular the
subtle pen and brush strokes characteristic of a particular painter can be profiled. Lyu
et al. [109] developed a technique for performing a multi-scale, multi-orientation
painting scan decomposition. This decomposition changes the basis from functions
maximally localized in space to one in which the basis functions are also localized
in orientation and scale. By constructing a compact model of the statistics from such
a function, it is possible to detect consistencies or inconsistencies between paintings
and drawings supposedly produced by the same painter.
13.2.24 Programming Style
With the increasing number of viruses, worms, and Trojan horses, it is often useful
in a forensic investigation to be able to identify an author of such malware programs
based on the analysis of the source code. It is also valuable for the purposes of soft-
ware debugging and maintenance to know who the original author of a certain code
fragment was. Spafford et al. [110] have analyzed a number of features potentially
useful for the identification of software authorship. In case only the executable code
is available for analysis, data structures and applied algorithms can be profiled, as
well as any remaining compiler and system information, observed programming
skill level, knowledge of the operating system and choice of the system calls. Ad-
ditionally, use of predefined functions and provisions for error handling are not the
same for different programmers.
In case the original source files are available, a large number of additional iden-
tifying features become accessible such as: chosen programming language, code
formatting style, type of code editor, special macros, style of comments, variable
names, spelling and grammar, use of language features such as choice of loop struc-
tures, the ratio of global to local variables, temporary coding structures, and finally
types of mistakes observable in the code. Software metrics such as the number of
lines of code per function, comment-to-code ratio and function complexity may also
be introduced [110].
13 Behavioral, Cognitive and Virtual Biometrics 363
13.2.25 Signature/Handwriting
Signature verification is a widely accepted methodology for confirming identity
[111–114]. Two distinct approaches to signature verification are traditionally recog-
nized based on the data collection approach, they are: on-line and off-line signature
verification, also known as static and dynamic approaches [115]. In the off-line sig-
nature verification, the image of the signature is obtained using a scanning device,
possibly some time after the signing took place. With on-line signature verification,
special hardware is used to capture dynamics of the signature; typically pressure
sensitive pens in combination with digitizing tablets are utilized. Because on-line
data acquisition methodology obtains features not available in the off-line mode,
dynamic signature verification is more reliable [116].
With on-line signature verification, in addition to the trajectory coordinates of the
signature, other features like pressure at pen tip, acceleration and pen-tilt can be col-
lected. In general, signature related features can be classified into two groups: global
and local. Global features include: signing speed, signature bounding box, Fourier
descriptors of the signature’s trajectory, number of strokes, and signing flow. Local
features describe specific sample points in the signature and relationship between
such points. For example, the distance and curvature changes between two succes-
sive points may be analyzed, as well as x and y offsets relative to the first point on
the signature trajectory, and critical points of the signature trajectory [116, 117].
Signature-based user verification is a particular type of general handwriting-
based biometric authentication. Unlike with signatures, handwriting-based user ver-
ification/recognition is content independent, which makes the process somewhat
more complicated [118–120]. Each person’s handwriting is seen as having a spe-
cific texture. The spatial frequency and orientation contents represent the features
of each texture [121]. Since handwriting provides a much more substantial biometric
characteristic sample in comparison to a signature, respective verification accuracy
can be much greater.
13.2.26 Short Term Memory
Human sensory input storage receives visual snapshots from the eyes and stores
them briefly in visual cortex to allow for the analysis of the perceived data. Such
analysis involves retrieval of important information from points of interest and fil-
tering out of inapplicable information. Short Term Memory (STM) could be char-
acterized in terms of size and decay, which for visual information is estimated to be
17 letters and an average time of 200 ms. It has been shown in multiple experiments
that the information retrieval capability from STM is different from one subject to
the other [122, 123]. Hamdy et al. [123] proposed an approach for measuring STM
time indirectly via analysis of mouse movements under stressful conditions while
performing a cognitive task. Extracted features included traveled distance decrease
rate as the one-key occurrence increased and fly time improvement rate as the one-
key occurrence increased.
364 R.V. Yampolskiy
13.2.27 Soft Behavioral Biometrics
Jain et al. [124, 125] define soft biometrics as: “. . . traits as characteristics that pro-
vide some information about the individual, but lack the distinctiveness and perma-
nence to sufficiently differentiate any two individuals”. They further state that soft
biometric traits can either be continuous, such as height or weight, or discrete, such
as gender or ethnicity. Authors propose expanding the definition to include soft be-
havioral biometrics, which also can be grouped into continuous and discrete types.
For instance, continuous soft behavioral biometric traits can include measurements
produced by various standardized tests (some of the most popular such tests are IQ
test for intelligence, and verbal sections of SAT, GRE, GMAT for language abili-
ties). Discrete soft behavioral biometrics are skills which a particular person either
has or does not have. Examples of such include the ability to speak a particular
foreign language, knowledge of how to fly a plane, or to ride a motorcycle, etc.
While such soft behavioral biometrics are not sufficient for identification or ver-
ification of individuals, they can be combined with other biometric approaches to
increase system accuracy. They can also be used in certain situations to reject an
individual’s verification claim. For example in a case of academic cheating, a sig-
nificantly fluctuating score on a repeatedly taken standardized test can be used to
suspect that not the same person answered all the questions on a given test [126].
13.2.28 Tapping
Henderson et al. [127, 128] have studied the idea of tapping recognition, based on
the idea that you are able to recognize who is knocking on your door. They concen-
trated on the waveform properties of the pulses which result from tapping a polymer
thick-film sensor on a smart card. Produced pressure pulses are further processed to
extract useful features such as: pulse height, pulse duration, and the duration of
the first inter-pulse interval. The recognition algorithm utilized in this research has
been initially developed for processing of keyboard dynamics, which is a somewhat
similar technology of recognizing tapping with respect to keyboard keys.
13.2.29 Text Authorship
Email and source code authorship identification represent application and improve-
ment of techniques developed in a broader field of text authorship determination.
Written text and spoken word (once transcribed) can be analyzed in terms of vocab-
ulary and style to determine authorship. In order to do so, a linguistic profile needs
to be established. Many linguistic features can be profiled, such as: lexical patterns,
syntax, semantics, pragmatics, information content or item distribution through a
text [129]. Stematatos et al. [130], in their analysis of modern Greek texts, proposed
13 Behavioral, Cognitive and Virtual Biometrics 365
using such text descriptors as: sentence count, word count, punctuation mark count,
noun phrase count, word included in noun phrase count prepositional phrase count,
word included in prepositional phrase count and keyword count. The overall area of
authorship attribution is very promising, with a lot of ongoing research [131–133].
13.2.30 Visual Scan/Search and Detection
This novel biometric is based on the human visual system. In our daily life, as we
examine signs, advertisements or websites for a specific piece of information, we
discriminate a target of interest from surrounding distracters. The idea is to properly
measure the average inspection time of an individual and use that information in
a behavioral signature [122]. The investigators demonstrated an approach for mea-
suring Visual Scan time indirectly via examining mouse movements under stress-
ful conditions. Obtained features included: speed, fly time and distance traveled. In
combination with Short TermMemory cognitive factor this biometrics has been able
to achieve Equal Error Rate of 3.88% on a dataset of 275 test subjects [123].
13.2.31 Voice/Speech/Singing
Speaker identification is one of the best researched biometric technologies [134–
136]. Verification is based on information about the speaker’s anatomical structure
conveyed in amplitude spectrum, with the location and size of spectral peaks related
to the vocal tract shape and the pitch striations related to the glottal source of the
user [80]. Speaker identification systems can be classified based on the freedom of
what is spoken [137]:
• Fixed text: The speaker says a particular word selected at enrolment.
• Text dependent: The speaker is prompted by the system to say a particular
phrase.
• Text independent: The speaker is free to say anything he wants, verification
accuracy typically improves with larger amount of spoken text.
Feature extraction is applied to the normalized amplitude of the input signal,
which is further decomposed into several band-pass frequency channels. A fre-
quently extracted feature is the logarithm of the Fourier Transform of the voice
signal in each band, along with features of pitch, tone, cadence, and shape of
the larynx [27]. Accuracy of voice-based biometrics systems can be increased by
inclusion of visual speech (lip dynamics) [99–102] and incorporation of soft be-
havioral biometrics such as accent [138, 139]. Recently some research has been
aimed at expanding the developed technology to singer recognition for the pur-
poses of music database management [140] and to laughter recognition. Cur-
rently, laughter-recognition software is rather crude and cannot accurately dis-
tinguish between different people [58, 59].
366 R.V. Yampolskiy
Some of the presented approaches are not sufficiently unique, permanent, easily
collectable or difficult to circumvent, but they can be seen as behavioral counterparts
of “soft” physical biometrics well recognized in the field. Soft biometrics are also
not strong enough to be a backbone of a standalone biometric security system, but
are nonetheless valuable in improving accuracy of multimodal systems. Likewise,
we believe that multimodal behavior-based biometric systems will be able to take
advantage of many of the technologies presented in our survey and therefore it is
important to include them to make our survey as comprehensive and as useful as
possible to the largest number of researchers and developers. For example, game
strategy alone may not be sufficient for person identification, but combined with
keyboard dynamics and mouse movements, it might be sufficiently discriminative.
Also, as breakthroughs are made in the field of behavioral biometrics, it is likely
that some of the described technologies will become easier to collect and harder to
circumvent.
Practically none of the behavioral biometrics are strong enough for person iden-
tification, and they are only useful for verification purposes. So, the assumption is
always made that we are dealing with a cooperating subject who wishes to positively
verify his identity. For all behaviors, even for low level ones, an un-cooperating sub-
ject can completely change his behavior in order to avoid being successfully profiled
by the security system. This is an inherent limitation of most behavioral biometric
systems.
13.3 Biological Signals as a Behavioral Biometrics
Because behavioral biometrics is a new and still developing field, even a basic con-
cept as what qualifies as a behavioral biometric is still not universally accepted. In
our detailed survey we have chosen to only cover approaches in which the behavior
in question is under full or at least partial control of the individual exhibiting it. In
this section, we present a number of approaches which have been classified as be-
havioral biometrics by other researchers in the field [141] and which as a rule are
not under the full control of the subject.
A number of biological signals have been classified as behavioral biometrics
in recent literature [141–143]. Numerous examples include the electrocardiogram
(ECG), the electroencephalogram (EEG), and the electrooculogram (EOG) as well
as some emerging technologies, like Brain-Computer Interface (BCI), and Elec-
troencephalogram Interface (EEGI), NHCI (Neural Human-Computer Interface)
and NI (Neural Interface) [144]. In addition to electrical activity, neural activity also
generates other types of signals, for example magnetic and metabolic signals, that
could be utilized in a BCI. Magnetic activity is recordable with magnetoencephalog-
raphy (MEG), brain metabolic activity as mirrored by changes in blood flow can be
measured with positron emission tomography (PET), and functional magnetic reso-
nance imaging (fMRI) [142]. There are also invasive BCI signal recording methods
such as implanted electrodes [143]. Table 13.3 provides known results for biosignal-
based security systems. The following explanations are meant to increase the under-
standing of non-professionals regarding biosignals.
13 Behavioral, Cognitive and Virtual Biometrics 367
Fig. 13.1 Examples of Behavioral Biometrics: (a) Biometric Sketch, (b) Blinking, (c) Calling,
(d) Car Driving, (e) Command Line Lexicon, (f) Credit Card Use, (g) Dynamic Facial Fea-
tures, (h) Email, (i) Gait, (j) Game Strategy, (k) GUI Interaction, (l) Handgrip, (m) Haptic,
(n) Keystrokes, (o) Lip Movement, (p) Mouse Dynamics, (q) Painting Style, (r) Programming
Style, (s) Signature, (t) Tapping, (u) Text Authorship, (v) Voice [32]. Image used with permission
from Interscience Publishers Ltd. © 2008
• EEG [Electro Encephalo Gram]: a graph of the brain’s electrical activity ver-
sus time. The electrical activity is a result of electrical impulses traversing the
neurons in the brain. Numerous studies demonstrate that the brainwave pattern of
every individual is unique and that the EEG can be used for biometric identifica-
tion [142]. The EEG signal changes with variation in types of cognitive activities.
The signal itself can be isolated from the background noise through a series of
filters. The idea behind this approach is to associate a particular EEG signature
with a particular set of thoughts, such as recorded during human–computer inter-
368 R.V. Yampolskiy
Table 13.3 Accuracy rates for utilized biosignal-based biometrics
Biosignal Publication Accuracy Rate
PhonoCardioGram (PCG) [150] 96%
ElectroCardioGram (ECG) [141] 100%
ElectroEncephaloGram (EEG) [145] 80–100%
PassThoughts [143] 90%
action [141]. Correct classification of individual in the accuracy range of 80% to
100% has been achieved in recent experiments [145].
• ECG/EKG [Electro Cardio/Kardio Gram]: a graph of the heart’s electrical ac-
tivity versus time. The electrical activity is a result of the electric current flowing
in both heart muscles and the neuronal network within the heart. Both EEG and
ECG/EKG are extrapolations of the actual electric signals. A series of sensors are
positioned over the heart and pick up the electrical signals produced by various
regions of the heart during the pumping cycle. The recording of the heartbeat
generates a unique and reliable profile for any particular individual. Recent ex-
periments provide sufficient evidence to suggest that it is a highly discriminative
biometric modality in some cases near 100% accurate [141, 146].
• GSR [Galvanic Skin Response]: a measure of the skin’s resistance/conductance.
This is affected by how moist the skin is (varying with the amount of sweat) and
since the sweat glands are controlled by the nervous system this is an indirect
measure of neuronal activity [147].
• fTCD [functional Trans-Cranial Doppler]: any Doppler scan uses ultrasound
waves to visualize underlying organs or tissue. In the case of fTCD, it is used to
visualize the brain. However, since it is functional, it visualizes the brain over time
and shows variations with varying levels of activity (this type is called dynamic
imaging).
• Odor: animals, for example dogs, are perfectly capable of recognizing people
based on odor. Idea behind this type of authentication is to create an Electronic
Nose (ENose) capable of sniffing out a person’s identity. The ENose consists
of a collection of sensors, each one serving as a receptor for a particular odor.
Once a significant number of odors can be profiled by the system, it becomes an
interesting pattern recognition problem to match odor-prints to people. This is a
promising line of research and is still in the early stages of development, with no
functional systems available on the market [148].
• EP [Evoked Potential]: measures brain’s electrical activity generated from ac-
tively stimulating the patient. The stimulus in this case is mostly artificial.
• ERP [Event Related Potential]: also measures brain’s electrical activity result-
ing from a stimulus. However, the stimulus in this case is some actual event rather
than just an artificial factor.
• PCG [PhonoCardioGram]: essentially a recording of a cardiac sound, this
biosignal has been successfully utilized in biometric identification systems after
undergoing frequency analysis. Berittelli et al. [149] have demonstrated biomet-
ric applicability of PCG on a database of 20 subjects and obtained a FRR of 5.0%
13 Behavioral, Cognitive and Virtual Biometrics 369
and a FAR of 2.2%. The main advantage of using heart sound as a biometric is
that it cannot be easily spoofed as compared to other, particularly non-physical
biometric modalities. Preliminary results show that with optimally selected pa-
rameters, an identification rate of up to 96% is achievable for a small database of
seven persons [150]. The heart beat is known as the Inherent Liveness Biometric
because “The way the human heart beats” characteristic is only valid for a living
person [151].
• BVP [Blood Volume Pulse]: uses photoplethysmography to detect the blood
pressure in the extremities by applying a light source and measuring the light
reflected by the skin. As blood is forced through the peripheral vessels by the
heart, it produces engorgement of the vessels, thereby modifying the amount of
light to the photosensor, which could be recorded as a waveform [152].
• PassThoughts: Thorpe et al. proposed using Brain Computer Interface (BCI)
technology to have a user directly transmit his thoughts to a computer. The system
extracts entropy from a user’s brain signal upon reading a thought. The brain
signals are processed in an accurate and repeatable way, providing a changeable
authentication method. The potential size of the space of a PassThoughts system
is not clear at this point, but likely to be very large, due to the lack of bounds on
what composes a thought [143].
13.3.1 Behavioral Passwords
While behavioral passwords are not the same as biometrics, they are authentication
methods based on preferences and psychological predispositions of people, and so
clearly fall under computer analysis of human behavior. Therefore we include a
short overview of the state of the art in this chapter, due to Yampolskiy [153].
13.3.1.1 Text-Based Behavioral Passwords
Text-Based passwords can be subdivided into syntactic, semantic and one-time
methods. The classical passwords and passphrases are examples of syntactic meth-
ods, in which a user is expected to memorize a sequence of characters or words. The
sequence can either be generated for the user, or user selected [42]. The problem is
that a user’s ability to memorize complicated or multiple passwords is limited, and
so authentication may present problems for the user. Alternatively, easy to remem-
ber passwords are also easy to guess and so provide a low level of security. Some
researchers present methods which might be easier for users to remember. For exam-
ple, the Check-Off Password System (COPS) [154] allows users to enter characters
in any order and therefore the users can choose to remember their password in many
different ways. Each user is assigned eight different characters selected from the six-
teen most commonly used letters. The user may use any character more than once
to form words which are easy to remember and so it is claimed that COPS provides
an advantage over regular passwords.
370 R.V. Yampolskiy
Semantic or cognitive passwords typically work by asking the user some ques-
tions and treating the user’s answer as the key to the authentication mechanism. One
approach described by Renaud [42] relies on asking the user clarifying questions
until the answer matches the one expected by the system. An alternative technique
provided a set of questionnaires, asking users to answer some fact-based or opinion-
based questions [155]. These approaches are not very user-friendly, as it might take
a long time for the user to arrive at the desired answer, and since users are very
sensitive to the time component of an authentication protocol, the cognitive-based
methods are not expected to become widely popular.
13.3.1.2 Graphics-Based Behavioral Passwords
Graphical passwords are designed to take advantage of human visual memory ca-
pabilities, which are far superior to our ability to remember textual information.
Two main types of graphical passwords are currently in use: recognition-based and
position-based, respectively. In recognition-based systems, users must identify im-
ages they have previously seen among new graphics.
Probably, the most well known recognition-based graphical authentication sys-
tem is called Passfaces [156, 157]. It relies on the ease with which people recognize
familiar faces. During enrollment, a user is presented with a set of faces from which
a subset is selected, which the user is asked to memorize. During authentication, a
screen with nine faces is presented to the user, with one of the faces being from his
Passface set. User has to select a face, which is familiar from the enrollment step.
This process is repeated five times, resulting in a relatively small space of 59,050
possible face combinations. Obviously, this is not sufficient if the system is open to
an exhaustive search.
Another authentication system, Déjà Vu, is based on random art images. User is
asked to choose five images as his pass set and during authentication needs to select
his pass set from a challenge set of 25 pictures. Since the pictures used are com-
pletely random and are generated by a computer program, it is next to impossible to
share a Déjà Vu password with others. Preliminary research shows that users prefer
real photographs to random art images and that the enrollment phase is more time
consuming than that of alphanumeric passwords [158].
The two systems mentioned above are probably representative of many other
similar recognition-based graphical authentication systems currently in existence.
Visual Identification Protocol [42, 159], Picture Password [160], and Picture-
Pins [161] are all reliant on exploiting the users’ good visual memory and power of
recall to easily authenticate users by making them pick familiar images from a large
set of graphics. A non-visual but also a sensory recall-based authentication approach
utilizing music is presented in the work of Gibson et al. [162] on the Musipass.
The remaining authentication approaches presented in this review are graphi-
cal position-based systems. A typical position-based approach is presented in Pass-
Points, a system based on having the user select points of interest within a single
image. The number of points is not limited and so a relatively large search space pro-
tects against any attempt to guess a PassPoints authentication sequence [163, 164].
13 Behavioral, Cognitive and Virtual Biometrics 371
This is similar to the methodology used in the original patent for graphical pass-
words obtained by Blonder in 1996 [165].
An alternative to having a user select a portion of an image is to have a user input
a simple drawing into a predefined grid space. This approach is attempted in [166]
with a system called Passdoodles and also in [167, 168] with a system called Draw-
a-Secret. Finally, a V-go Password requests a user to perform simulation of simple
actions such as mixing a cocktail using a graphical interface [42].
There is also a separate area of research targeting development of password re-
minder cues based on different psychological and behavioral prompts. Primary ex-
amples of such cue eliciting systems are Inkblot cues [169–172] and Handwriting
reminders [173]. Inkblot-based systems attempt to assist users in better recalling
their passwords by providing implicit information, which users associate with their
password. The idea is based on the concept of a Rorschach test, in which subject’s
perception of inkblots is recorded and analyzed in terms of everyday concepts.
13.3.2 Comparison and Analysis
Behavioral biometrics measure human actions, which can result from human skills,
style, preference, knowledge, motor-skills or strategy. Table 13.4 summarizes what
precisely is being measured by different behavioral biometrics, as well as lists some
of the most frequently used features for each type of behavior. Indirect HCI-based
biometrics are not included as they have no meaning independent of the direct
human–computer interaction which causes them.
Motor-skill-based biometrics measure innate, unique and stable muscle actions
of users performing a particular task. Table 13.5 outlines which muscle groups are
responsible for a particular motor-skill, as well as lists some of the most frequently
used features for each muscle control-based biometric approach.
While many behavioral biometrics are still in their infancy, some very promising
research has already been done. The results obtained justify feasibility of using be-
havior for verification of individuals and further research in this direction is likely
to improve accuracy of such systems. Table 13.6 summarizes obtained accuracy
ranges for the set of direct behavioral biometrics for which such data are available.
Table 13.7 presents accuracy rates for biometric methodologies not reviewed in our
previous surveys.
13.4 Privacy Concerns
An unintended property of behavioral profiles is that they might contain information
which may be of interest to third parties, who have potential to discriminate against
individuals based on such information. As a consequence, intentionally revealing or
obtaining somebody else’s behavioral profile for the purposes other than verification
is highly unethical. Examples of private information which might be revealed by
some behavioral profiles follow.
372 R.V. Yampolskiy
Table 13.4 Behavioral biometrics with traits and features [32]
Behavioral
Biometric
Measures Features
Biometric Sketch Knowledge Location and relative position of different
primitives
Calling Behavior Preferences Date and time of the call, duration, called ID,
called number, cost of call, number of calls to a
local destination, number of calls to mobile
destinations, number of calls to international
destinations
Car driving style Skill Pressure from accelerator pedal and brake pedal,
vehicle speed, steering angle
Command Line
Lexicon
Technical
Vocabulary
Used commands together with corresponding
frequency counts, and lists of arguments to the
commands
Credit Card Use Preferences Account number, transaction type, credit card
type, merchant ID, merchant address
Email Behavior Style Length of the emails, time of the day the mail is
sent, how frequently inbox is emptied, the
recipients’ addresses
Game Strategy Strategy/Skill Count of hands folded, checked, called, raised,
check-raised, re-raised, and times player went
all-in
Haptic Style 3D world location of the pen, average speed,
mean velocity, mean standard deviation,
navigation style, angular turns and rounded turns
Keystroke Dynamics Skill Time durations between the keystrokes, inter-key
strokes and dwell times, which is the time a key is
pressed down, overall typing speed, frequency of
errors (use of backspace), use of numpad, order in
which user presses shift key to get capital letters
Mouse Dynamics Style x and y coordinates of the mouse, horizontal
velocity, vertical velocity, tangential velocity,
tangential acceleration, tangential jerk and
angular velocity
Painting Style Style Subtle pen and brush strokes characteristic
Programming Style Skill, Style,
Preferences
Chosen programming language, code formatting
style, type of code editor, special macros,
comment style, variable names, spelling and
grammar, language features, the ratio of global to
local variables, temporary coding structures,
errors
Soft Behavioral
Biometrics
Intelligence,
Vocabulary, Skills
Word knowledge, generalization ability,
mathematical skill
Text Authorship Vocabulary Sentence count, word count, punctuation mark
count, noun phrase count, word included in noun
phrase count, prepositional phrase count, word
included in prepositional phrase count, and
keyword count
13 Behavioral, Cognitive and Virtual Biometrics 373
Table 13.5 Motor-skill biometrics with respective muscles and features [174]
Motor
Skill-based
Biometric
Muscles Involved Extracted Features
Blinking orbicularis oculi, corrugator supercilii,
depressor supercilii
time between blinks, how long the eye
is held closed at each blink, physical
characteristics the eye undergoes while
blinking
Dynamic
Facial
Features
levator labii superioris, levator anguli
oris zygomaticus major, zygomaticus
minor, depressor labii inferioris,
depressor anguli oris, buccinator,
orbicularis oris
motion of skin pores on the face, skin
folds, wrinkles
Gait/Stride tibialis anterior, extensor hallucis
longus, extensor digitorum longus,
peroneus tertius, extensor digitorum
brevis, extensor hallucis brevis,
gastrocnemius, soleus, plantaris,
popliteus, flexor hallucis longus flexor
digitorum longus
amount of arm swing, rhythm of the
walker, bounce, length of steps,
vertical distance between head and
foot, distance between head and pelvis,
maximum distance between the left
and right foot
Handgrip abductor pollicis brevis, opponens
pollicis, flexor pollicis brevis, adductor
pollicis, palmaris brevis, abductor
minimi digiti, flexor brevis minimi
digiti
resistance measurements in multiple
points
Haptic abductor pollicis brevis, opponens
pollicis, flexor pollicis brevis, adductor
pollicis, palmaris brevis, abductor
minimi digiti, flexor brevis minimi
digiti, opponens digiti minimi,
lumbrical, dorsal interossei, palmar
interossei
3D world location of the pen, average
speed, mean velocity, mean standard
deviation, navigation style, angular
turns and rounded turns
Keystroke
Dynamics
abductor pollicis brevis, opponens
pollicis, flexor pollicis brevis, adductor
pollicis, palmaris brevis, abductor
minimi digiti, flexor brevis minimi
digiti, opponens digiti minimi,
lumbrical, dorsal interossei, palmar
interossei
time durations between the keystrokes,
inter-key strokes and dwell times,
which is the time a key is pressed
down, overall typing speed, frequency
of errors (use of backspace), use of
numpad, order in which user presses
shift key to get capital letters
Lip
Movement
levator palpebrae superioris, levator
anguli oris, mentalis, depressor labii
inferioris, depressor anguli oris,
buccinator, orbicularis oris, risorius
Mouth width, upper/lower lip width,
lip opening height/width, distance
between horizontal lip line and upper
lip
Mouse
Dynamics
abductor pollicis brevis, opponens
pollicis, flexor pollicis brevis, adductor
pollicis, palmaris brevis, abductor
minimi digiti, flexor brevis minimi
digiti, opponens digiti minimi,
lumbrical, dorsal interossei
x and y coordinates of the mouse,
horizontal velocity, vertical velocity,
tangential velocity, tangential
acceleration, tangential jerk and
angular velocity
374 R.V. Yampolskiy
Table 13.5 (Continued)
Motor
Skill-based
Biometric
Muscles Involved Extracted Features
Signature/
Handwriting
abductor pollicis brevis, opponens
pollicis, flexor pollicis brevis, adductor
pollicis, palmaris brevis, abductor
minimi digiti, flexor brevis minimi
digiti, opponens digiti minimi,
lumbrical, dorsal interossei, palmar
interossei
coordinates of the signature, pressure
at pen tip, acceleration and pen-tilt,
signing speed, signature bounding box,
Fourier descriptors of the signature’s
trajectory, number of strokes, and
signing flow
Tapping abductor pollicis brevis, opponens
pollicis, flexor pollicis brevis, adductor
pollicis, palmaris brevis, abductor
minimi digiti, flexor brevis minimi
digiti
Pulse height, pulse duration, and the
duration of the first inter-pulse interval
Voice/Speech cricothyroid, posterior ricoarytenoid,
lateral cricoarytenoid, arytenoid,
thyroarytenoid
logarithm of the Fourier transform of
the voice signal in each band along
with pitch and tone
• Calling behavior: Calling data are a particularly sensitive subject since they
might contain highly personal information.
• Car driving style: Car insurance companies may be interested to know if a driver
frequently speeds or whether he or she is an overall aggressive driver, in order to
charge an increased coverage rate or to deny coverage all together.
• Command line lexicon: Information about proficiency with the commands might
be used by an employer to decide if you are sufficiently qualified for a job involv-
ing computer interaction.
• Credit card usage: Credit card data reveal information about what items you
frequently purchase and in what locations you can be found, violating your ex-
pectation of privacy. For example an employer might be interested to know if an
employee buys a case of beer every day, indicating a problem of alcoholism.
• Email behavior: An employer would be interested to know if employees send
out personal emails during office hours.
• Game strategy: If information about game strategy is obtained by the player’s
opponents, they might be analyzed to find weaknesses in player’s game and as a
result give an unfair advantage to the opponents.
• Programming style: Software metrics obtained from analysis of code may indi-
cate a poorly performing coder and as a result jeopardize the person’s employ-
ment.
Additionally, any of the motor-skill-based biometrics may reveal a physical hand-
icap of a person and so result in potential discrimination. Such biometrics as voice
can reveal emotions, and the face images may reveal information about emotions
and health [181]. Because behavioral biometric indirectly measures our thoughts
13 Behavioral, Cognitive and Virtual Biometrics 375
Table 13.6 Recognition and error rates of behavioral biometrics [32]
Behavioral Biometric Publication Detection Rate FAR FRR EER
Biometric Sketch Bromme 2003 [40] 7.2%
Blinking Westeyn 2004 [44] 82.02%
Calling Behavior Fawcett 1997 [47] 92.5%
Car driving style Erdogan 2005 [175] 88.25% 4.0%
Command Line Lexicon Marin 2001 [176] 74.4% 33.5%
Credit Card Use Brause 1999 [56] 99.995% 20%
Email Behavior de Vel 2001 [64] 90.5%
Gait/Stride Kale 2004 [77] 90%
Game Strategy Yampolskiy 2007 [83] 7.0%
Handgrip Veldhuis 2004 [88] 1.8%
Haptic Orozco 2006 [90] 25% 22.3%
Keystroke Dynamics Bergadano 2002 [177] 0.01% 4%
Lip Movement Mok 2004 [103] 2.17%
Mouse Dynamics Pusara 2004 [23] 0.43% 1.75%
Programming Style Frantzeskou 2004 [178] 73%
Signature Jain 2002 [111] 1.6% 2.8%
Handwriting Zhu 2000 [121] 95.7%
Tapping Henderson 2001 [127] 2.3%
Text Authorship Halteren 2004 [129] 0.2% 0.0%
Voice/Speech Colombi 1996 [179] 0.28%
Singing Tsai 2006 [180] 29.6%
Table 13.7 Accuracy rates for new biometric modalities previously not reviewed
Behavioral Biometric Publication Detection Rate FAR FRR EER
Center of Gravity [52] 50% 18%
Finger Pressure [65] 99% 1%
Floor Pressure [66] 92.3% 6.79%
Gaze/Eye Tracking [75, 76] 100%
Human Shadows [92, 93] 90%
Motion of Fingers [108] 97%
Short Term Memory [122, 123] 90% 0.52% 26.14%
Visual Scan/Search [122, 123] 3.88%
and personal traits any data collected in the process of generation of a behavioral
profile need to be safely stored in an encrypted form.
376 R.V. Yampolskiy
13.5 Summary
This chapter presented an overview and classification of security approaches based
on computer analysis of human behavior. In particular the following broad cate-
gories of behavior-based authentication mechanisms were examined: Behavioral
Biometrics (Authorship based, Human Computer Interaction Based, Motor Skill,
and Purely Behavioral), Behavioral Passwords (syntactic, semantic, one-time meth-
ods and visual memory based), Biosignals (Cognitive and semi-controllable biomet-
rics) and Virtual Biometrics (representations of users in virtual worlds).
We have presented only the most popular behavioral biometrics, but any human
behavior can be used as a basis for personal profiling and for subsequent verifica-
tion. Some behavioral biometrics, which are quickly gaining ground, but are not a
part of this chapter include profiling of shopping behavior based on market basked
analysis [182], web browsing and click-stream profiling [183–185], and even TV
preferences [186]. To make it easier to recognize newly proposed approaches as be-
havioral biometrics, we propose a definition of what properties constitute a behav-
ioral biometric characteristic. We define a behavioral biometric as any quantifiable
actions of a person. Such actions may not be unique to the person and may take a
different amount of time to be exhibited by different individuals.
Behavioral biometrics are particularly well suited for verification of users, who
interact with computers, cell phones, smart cars, or points of sale terminals. As
the number of electronic appliances used in homes and offices increases, so does
the potential for utilization of this novel and promising technology. Future research
should be directed at increasing overall accuracy of such systems, for example by
looking into possibility of developing multimodal behavioral biometrics, as people
often engage in multiple behaviors at the same time, for example, talking on a cell
phone while driving, or using keyboard and mouse at the same time [187–189].
Fields as diverse as marketing, game theory, security and law enforcement all
can greatly benefit from accurate modeling of human behavior. One of the aims of
this chapter was to show that the problem at hand is not unique to any given field
and that a solution found once might benefit many industries without a need for
re-discovering it for each subfield.
Because many of the presented technologies represent behavioral biometrics
which are not strong enough to serve as a backbone of a complete security sys-
tem on their own, we suggest that a lot of research in behavioral biometrics be
geared toward multimodal behavioral biometrics. Successful research in this area
would allow for development of systems with accuracy levels sufficient not just for
identity verification, but also for person identification obtained as a result of com-
bining different behaviors. Breakthroughs in purely behavioral biometrics research
will also undoubtedly lead to improvements in associated applications such as prod-
uct customization, development of tailored opponents in games as well as multitude
of competency assessment tools.
Future of behavioral research looks very bright. The next decade will bring us
technologies providing unprecedented level of security, product customization, so-
cial compatibility and work efficiency. Ideas presented in the section on novel be-
havioral biometrics provide a wealth of opportunities for interesting research and
13 Behavioral, Cognitive and Virtual Biometrics 377
development. A great side effect of such research would be general greater under-
standing of human behavior, personality and perhaps human mind itself.
13.6 Questions
(1) Describe different authentication mechanism categories presented in the chap-
ter.
(2) Which behaviors tend to have the highest degree of uniqueness leading to better
authentication accuracies?
(3) List behavioral biometrics classified in multiple categories and explain under-
lining reasons for that.
(4) What are the issues of concern with use of biometrics based on analysis of
human behavior?
(5) If you were designing a behavioral biometric-based security system, which be-
havior would you select and why?
13.7 Glossary
• Acceptability: Willingness of people to utilize a biometric modality.
• Authentication: The act of confirming identity.
• Biometric: Intrinsic physical or behavioral characteristic.
• Behavioral Biometric: Biometric based on the behavior of a person.
• Circumvention: A way to bypass biometric authentication.
• Collectability: Easy acquisition of biometric data.
• FAR: False Accept Rate, the likelihood that the biometric system will incorrectly
match an individual to the wrong template in the database
• FRR: False Reject Rate, the likelihood that the biometric system will fail to detect
a match between a person and the correct template in the database.
• Feature: A distinguishing characteristic of a pattern.
• Performance: Accuracy, speed, and robustness of the biometric algorithm.
• Permanence: Invariance of a biometric trait with respect to time.
• Recognition: Identification of an individual from a list of known users.
• Uniqueness: Discriminative ability of a biometric modality.
• Verification: Confirmation used to verify that the individual is who he claims to
be.
• Universality: The need for universal availability of a biometric characteristic in
all individuals.
References
1. Angle, S., Bhagtani, R., Chheda, H.: Biometrics: a further echelon of security. In: First UAE
International Conference on Biological and Medical Physics (2005)
378 R.V. Yampolskiy
2. Dugelay, J.-L., et al.: Recent advances in biometric person authentication. In: IEEE Int. Conf.
on Acoustics Speech and Signal Processing (ICASSP), Special Session on Biometrics, Or-
lando, Florida (2002)
3. Lee, K., Park, H.: A new similarity measure based on intraclass statistics for biometric sys-
tems. ETRI J. 25(5), 401–406 (2003)
4. Cappelli, R., et al.: Performance evaluation of fingerprint verification systems. IEEE Trans.
Pattern Anal. Mach. Intell. 28(1), 3–18 (2006)
5. Jain, A.K., Ross, A., Prabhakar, S.: An introduction to biometric recognition. In: IEEE Trans.
Circuits Syst. Video Technol. (2004)
6. Bolle, R., et al.: Guide to Biometrics. Springer, Berlin (2003)
7. Jain, A.K., et al.: Biometrics: a grand challenge. In: International Conference on Pattern
Recognition, Cambridge, UK (2004)
8. Uludag, U., et al.: Biometric cryptosystems: issues and challenges. Proc. IEEE 92(6) (2004)
9. Delac, K., Grgic, M.: A survey of biometric recognition methods. In: 46th International Sym-
posium Electronics in Marine, ELMAR-2004, Zadar, Croatia (2004)
10. Ruggles, T.: Comparison of biometric techniques (2007). Available at: http://www.bio-tech-
inc.com/bio.htm
11. Solayappan, N., Latifi, S.: A survey of unimodal biometric methods. In: Security and Man-
agement, Las Vegas, Nevada, USA (2006)
12. Bioprivacy.org: FAQ. BioPrivacy Initiative (2005). July 22, 2005. Available from: http://
www.bioprivacy.org/faqmain.htm
13. Bromme, A.: A classification of biometric signatures. In: International Conference on Mul-
timedia and Expo (ICME ’03) (2003)
14. Yampolskiy, R.V.: Human computer interaction based intrusion detection. In: 4th Interna-
tional Conference on Information Technology: New Generations (ITNG 2007), Las Vegas,
Nevada, USA (2007)
15. Bioprivacy.org. FAQ’s and Definitions. International Biometric Group, LLC (2005). October
2, 2005. Available from: http://www.bioprivacy.org/bioprivacy_text.htm
16. Yampolskiy, R.V.: Indirect human–computer interaction-based biometrics for intrusion de-
tection systems. In: The 41st Annual IEEE International Carnahan Conference on Security
Technology (ICCST 2007), Ottawa, Canada (2007)
17. Denning, D.E.: An intrusion-detection model. In: IEEE Transactions on Software Engineer-
ing (1987)
18. Ilgun, K., Kemmerer, R.A., Porras, P.A.: State transition analysis: A rule-based intrusion
detection approach. In: Software Engineering (1995)
19. Ghosh, A.K., Schwartzbard, A., Schatz, M.: Learning program behavior proles for intru-
sion detection. In: First USENIXWorkshop on Intrusion Detection and Network Monitoring
(1999)
20. Apap, F., et al.: Detecting malicious software by monitoring anomalous windows registry
accesses. In: Fifth International Symposium on Recent Advances in Intrusion Detection,
pp. 16–18 (2002)
21. Pennington, A.G., et al.: Storage-based intrusion detection: Watching storage activity for
suspicious behavior. Carnegie Mellon University (2002)
22. Feng, H.H., et al.: Anomaly detection using call stack information. In: Proceedings of IEEE
Symposium on Security and Privacy (2003)
23. Pusara, M., Brodley, C.E.: User re-authentication via mouse movements. In:
VizSEC/DMSEC ’04: Proceedings of the ACM Workshop on Visualization and Data
Mining for Computer Security. ACM, Washington (2004)
24. Garg, A., et al.: Profiling users in GUI based systems for masquerade detection. In: The 7th
IEEE Information Assurance Workshop (IAWorkshop 2006), West Point, New York, USA
(2006)
25. Yampolskiy, R.V.: Motor-skill based biometrics. In: Dhillon, G. (ed.) Assuring Business Pro-
cesses, Proceedings of the 6th Annual Security Conference. Global Publishing, Las Vegas
(2007)
13 Behavioral, Cognitive and Virtual Biometrics 379
26. Caslon.com.au: Caslon-Analytics. October 2, 2005. Available from: http://www.caslon.
com.au/biometricsnote8.htm
27. Jain, A.K., Bolle, R., Pankanti, S.: BIOMETRICS: Personal Identification in Networked So-
ciety. Kluwer Academic, Dordrecht (1999)
28. Adler, A., Youmaran, R., Loyka, S.: Towards a measure of biometric information
(2006). Available at: http://www.sce.carleton.ca/faculty/adler/publications/2006/youmaran-
ccece2006-biometric-entropy.pdf
29. Koychev, I., Schwab, I.: Adaptation to drifting user’s interests. In: Proceedings of
ECML2000 Workshop: Machine Learning in New Information Age, Barcelona, Spain
(2000)
30. Tsymbal, A.: The problem of concept drift: definitions and related work. Technical Report
TCD-CS-2004-15, Computer Science Department, Trinity College, Dublin, Ireland (2004)
31. Schuckers, S.A.C.: Spoofing and anti-spoofing measures. Information Security Technical Re-
port (2002)
32. Yampolskiy, R.V., Govindaraju, V.: Behavioral biometrics: a survey and classification. Int. J.
Biom. 1(1), 81–113 (2008)
33. Oursler, J.N., Price, M., Yampolskiy, R.V.: Parameterized generation of Avatar face dataset.
In: 14th International Conference on Computer Games: AI, Animation, Mobile, Interactive
Multimedia, Educational & Serious Games, Louisville, KY (2009)
34. Yampolskiy, R., Gavrilova, M.: Applying biometric principles to avatar recognition. In: In-
ternational Conference on Cyberworlds (CW2010), Singapore, October 20–22 (2010)
35. Ajinal, S., Yampolskiy, R.V., Amara, N.E.B.: Authentification de Visages D’Avatar. In: Con-
fere 2010 Symposium, Sousse, Tunisia, July 1–2 (2010)
36. Yampolskiy, R.V., Govindaraju, V.: Behavioral biometrics for verification and recognition
of malicious software agents. In: Sensors, and Command, Control, Communications, and
Intelligence (C3I) Technologies for Homeland Security and Homeland Defense VII. SPIE
Defense and Security Symposium, Orlando, Florida, March 16–20 (2008)
37. D’Souza, D., Yampolskiy, R.V.: Avatar face detection analysis using an extended set of Haar-
like features. In: Kentucky Academy of Science, Annual Meeting, Bowling Green, Kentucky,
November 12–13 (2010)
38. Lyons, M., et al.: Avatar creation using automatic face recognition. In: ACMMultimedia 98,
Bristol, England, Sept. 1998, pp. 427–434 (1998)
39. Yanushkevich, S., et al.: Image Pattern Recognition: Synthesis and Analysis in Biometrics.
Machine Perception and Artificial Intelligence, vol. 67. World Scientific, Singapore (2007)
40. Brömme, A., Al-Zubi, S.: Multifactor biometric sketch authentication. In: BIOSIG, Darm-
stadt, Germany (2003)
41. Al-Zubi, S., Brömme, A., Tönnies, K.: Using an active shape structural model for biometric
sketch recognition. In: DAGM, Magdeburg, Germany (2003)
42. Renaud, K.: Quantifying the quality of web authentication mechanisms. A usability perspec-
tive. J. Web Eng. (2003). Available at: http://www.dcs.gla.ac.uk/~karen/Papers/j.pdf
43. Westeyn, T., et al.: Biometric identification using song-based eye blink patterns. In: Human
Computer Interaction International (HCII), Las Vegas, NV (2005)
44. Westeyn, T., Starner, T.: Recognizing song-based blink patterns: applications for restricted
and universal access. In: Sixth IEEE International Conference on Automatic Face and Ges-
ture Recognition (2004)
45. Hilas, C., Sahalos, J.: User profiling for fraud detection in telecommunication networks. In:
5th International Conference on Technology and Automation (ICTA 2005), Thessaloniki,
Greece (2005)
46. Grosser, H., Britos, H., García-Martínez, R.: Detecting Fraud in Mobile Telephony Using
Neural Networks. Lecture Notes in Artificial Intelligence. Springer, Berlin (2005)
47. Fawcett, T., Provost, F.: Adaptive fraud detection. In: Data Mining and Knowledge Discov-
ery. Kluwer Academic, Dordrecht (1997)
48. Erzin, E., et al.: Multimodal person recognition for human-vehicle interaction. In: IEEEMul-
tiMedia (April 2006)
380 R.V. Yampolskiy
49. Liu, A., Salvucci, D.: Modeling and prediction of human driver behavior. In: 9th HCI Inter-
national Conference, New Orleans, LA (2001)
50. Oliver, N., Pentland, A.P.: Graphical models for driver behavior recognition in a SmartCar.
In: Proceedings of the IEEE Intelligent Vehicles Symposium (2000)
51. Kuge, N., Yamamura, T., Shimoyama, O.: A driver behavior recognition method based on
driver model framework. In: Society of Automotive Engineers Publication (1998)
52. Porwik, P., et al.: Biometric recognition system based on the motion of the human body
gravity centre analysis. J. Med. Inform. Technol. 15 (2010)
53. Schonlau, M., et al.: Computer intrusion: detecting masquerades. Stat. Sci. 16(1), 1–17
(2001)
54. Maxion, R.A., Townsend, T.N.: Masquerade detection using truncated command lines. In:
International Conference on Dependable Systems and Networks (DNS-02). IEEE Comput.
Soc., Los Alamitos (2002)
55. Dao, V., Vemuri, V.: Profiling users in the UNIX OS environment. In: International ICSC
Conference on Intelligent Systems and Applications, University of Wollongong, Australia
(2000)
56. Brause, R., Langsdorf, T., Hepp, M.: Neural data mining for credit card fraud detection. In:
Proceedings of the 11th IEEE International Conference on Tools with Artificial Intelligence
(1999)
57. Pamudurthy, S., et al.: Dynamic approach for face recognition using digital image skin cor-
relation. In: Audio- and Video-based Biometric Person Authentication (AVBPA), New York
(2005)
58. Mainguet, J.-F.: Biometrics (2006). Available at: http://perso.orange.fr/fingerchip/biometrics/
biometrics.htm
59. Ito, A., et al.: Smile and laughter recognition using speech processing and face recognition
from conversation video. In: Proceedings of the International Conference on Cyberworlds
(2005)
60. Tsai, P., Hintz, T., Jan, T.: Facial behavior as behavior biometric? An empirical study. In:
IEEE International Conference on Systems, Man and Cybernetics, Montreal, Quebec, Octo-
ber 7–10, pp. 3917–3922 (2007)
61. Benedikt, L., et al.: Assessing the uniqueness and permanence of facial actions for use in
biometric applications. IEEE Trans. Syst. Man Cybern., Part A, Syst. Hum. 40(3), 449–460
(2010)
62. Stolfo, S.J., et al.: A behavior-based approach to securing email systems. In: Mathemati-
cal Methods, Models and Architectures for Computer Networks Security. LNCS, vol. 2776,
pp. 57–81 (2003)
63. Stolfo, S.J., et al.: Combining behavior models to secure email systems. CU Tech Report
(2003). Available at: www1.cs.columbia.edu/ids/publications/EMT-weijen.pdf
64. Vel, O.D., et al.: Mining email content for author identification forensics. SIGMOD Rec.
30(4), 55–64 (2001). Special Section on Data Mining for Intrusion Detection and Threat
Analysis
65. Saevanee, H., Bhattarakosol, P.: Authenticating user using keystroke dynamics and finger
pressure. In: 6th IEEE Consumer Communications and Networking Conference (CCNC),
Las Vegas, NV, January 10–13, pp. 1–2 (2009)
66. Qian, G., Zhang, J., Kidane, A.: People identification using gait via floor pressure analysis
IEEE Sens. J. 10(9), 1447–1460 (2010)
67. Addlesee, M., et al.: The ORL active floor. IEEE Pers. Commun. 35–41 (1997)
68. Jung, J., et al.: Dynamic-footprint based person identification using mat-type pressure sen-
sor. In: International Conference of the IEEE Engineering in Medicine and Biology Society,
pp. 2937–2940 (2003)
69. Pirttikangas, S., et al.: Footstep identification from pressure signals using hidden Markov
models. In: Finnish Signal Processing Symposium, pp. 124–128 (2003)
70. Middleton, L., et al.: A floor sensor system for gait recognition. In: IEEE Workshop on
Automatic Identification Advanced Technologies, pp. 171–176 (2005)
13 Behavioral, Cognitive and Virtual Biometrics 381
71. Yun, J., et al.: The user identification system using walking pattern over the ubiFloor. In:
International Conference on Control, Automation, and Systems, pp. 1046–1050 (2003)
72. Orr, R.J., Abowd, G.D.: The smart floor: a mechanism for natural user identification and
tracking. In: Conference on Human Factors in Computing Systems, pp. 275–276 (2000)
73. Yoon, J., Ryu, J., Woo, W.: User identification using user’s walking pattern over the ubi-
FloorII. In: International Conference on Computational Intelligence and Security, pp. 949–
956 (2005)
74. Suutala, J., Röning, J.: Methods for person identification on a pressure-sensitive floor: Ex-
periments with multiple classifiers and reject option. Inf. Fusion 9(1), 21–40 (2008)
75. Maeder, A.J., Fookes, C.B.: A visual attention approach to personal identification. In: Eighth
Australian and New Zealand Intelligent Information Systems Conference, December 10–12
(2003)
76. Maeder, A.J., Fookes, C.B., Sridharan, S.: Gaze based user authentication for personal com-
puter applications. In: International Symposium on Intelligent Multimedia, Video and Speech
Processing, Hong Kong, China, October 20–22 (2004)
77. Kale, A., et al.: Identification of humans using gait. IEEE Trans. Image Proc. 13(9) (2004)
78. BenAbdelkader, C., Cutler, R., Davis, L.: Person identification using automatic height and
stride estimation. In: IEEE International Conference on Pattern Recognition (2002)
79. Nixon, M.S., Carter, J.N.: On gait as a biometric: progress and prospects. In: EUSIPCO,
Vienna (2004)
80. Kalyanaraman, S.: Biometric authentication systems. A report. 2006. Available at: http://
netlab.cs.iitm.ernet.in/cs650/2006/TermPapers/sriramk.pdf
81. Yampolskiy, R.V.: Behavior based identification of network intruders. In: 19th Annual CSE
Graduate Conference (Grad-Conf2006), Buffalo, NY (2006)
82. Yampolskiy, R.V., Govindaraju, V.: Use of behavioral biometrics in intrusion detection and
online gaming. In: Biometric Technology for Human Identification III. SPIE Defense and
Security Symposium, Orlando, Florida (2006)
83. Yampolskiy, R.V., Govindaraju, V.: Dissimilarity functions for behavior-based biometrics.
In: Biometric Technology for Human Identification IV. SPIE Defense and Security Sympo-
sium, Orlando, Florida (2007)
84. poker-edge.com: Stats and analysis (2006). June 7, 2006. Available from:
http://www.poker-edge.com/stats.php
85. Ramon, J., Jacobs, N.: Opponent modeling by analysing play. In: Proceedings of the Com-
puters and Games workshop on Agents in Computer Games, Edmonton, Alberta, Canada
(2002)
86. Jansen, A.R., Dowe, D.L., Farr, G.E.: Inductive inference of chess player strategy. In: Pro-
ceedings of the 6th Pacific Rim International Conference on Artificial Intelligence (PRI-
CAI’2000) (2000)
87. Kauffman, J.A., et al.: Grip-pattern recognition for smart guns. In: 14th Annual Workshop
on Circuits, Systems and Signal Processing (ProRISC), Veldhoven, The Netherlands (2003)
88. Veldhuis, R.N.J., et al.: Biometric verification based on grip-pattern recognition. In: Security,
Steganography, and Watermarking of Multimedia Contents (2004)
89. Orozco, M., et al.: Automatic identification of participants in haptic systems. In: IEEE In-
strumentation and Measurement Technology Conference, Ottawa, Canada (2005)
90. Orozco, M., et al.: Haptic-based biometrics: a feasibility study. In: IEEE Virtual Reality
Conference, Alexandria, Virginia, USA (2006)
91. Trujillo, M.O., Shakra, I., Saddik, A.E.: Haptic: the new biometrics-embedded media to rec-
ognizing and quantifying human patterns. In: MULTIMEDIA ’05: Proceedings of the 13th
Annual ACM International Conference on Multimedia, Hilton, Singapore. ACM, New York
(2005)
92. Stoica, A.: Towards recognition of humans and their behaviors from space and airborne plat-
forms: extracting the information in the dynamics of human shadows. In: Symposium on
Bio-inspired Learning and Intelligent Systems for Security (BLISS ’08), Edinburgh, August
4–6, pp. 125–128 (2008)
382 R.V. Yampolskiy
93. Iwashita, Y., Stoica, A., Kurazume, R.: Person identification using shadow analysis. In:
British Machine Vision Conference, September, pp. 35.1–35.10 (2010)
94. Ilonen, J.: Keystroke dynamics (2006). Available at: www.it.lut.fi/kurssit/03-04/010970000/
seminars/Ilonen.pdf
95. Bella, S.D., Palmer, C.: Personal identifiers in musicians’ finger movement dynamics.
J. Cogn. Neurosci. 18 (2006)
96. Gamboa, H., Fred, A.L.N., Jain, A.K.: Webbiometrics: User verification via web interaction.
In: Biometrics Symposium, Baltimore, MD, September 11–13, pp. 1–6 (2007).
97. Shipilova, O.: Person recognition based on lip movements (2006). Available at: http://www.
it.lut.fi/kurssit/03-04/010970000/seminars/Shipilova.pdf
98. Broun, C.C., et al.: Automatic speechreading with applications to speaker verification. In:
Eurasip Journal on Applied Signal Processing, Special Issue on Joint Audio-Visual Speech
Processing (2002)
99. Luettin, J., Thacker, N.A., Beet, S.W.: Speaker identification by lipreading. In: Proceedings
of the 4th International Conference on Spoken Language Processing (ICSLP’96) (1996)
100. Wark, T., Thambiratnam, D., Sridharan, S.: Person authentication using lip information. In:
Proceedings of IEEE 10th Annual Conference. Speech and Image Technologies for Comput-
ing and Telecommunications (1997)
101. Mason, J.S.D., et al.: Lip signatures for automatic person recognition. In: IEEE Workshop,
MMSP (1999)
102. Jourlin, P., et al.: Acoustic-labial speaker verification. In: Pattern Recognition Letters (1997)
103. Mok, L., et al.: Person authentication using ASM based lip shape and intensity information.
In: International Conference on Image Processing (2004)
104. Ahmed, A.A.E., Traore, I.: Detecting computer intrusions using behavioral biometrics. In:
Third Annual Conference on Privacy, Security and Trust, St. Andrews, New Brunswick,
Canada (2005)
105. Ahmed, A.A.E., Traore, I.: Anomaly intrusion detection based on biometrics. In: Workshop
on Information Assurance, United States Military Academy, West Point, NY (2005)
106. Gamboa, H., Fred, V.-A.: A behavioral biometric system based on human–computer interac-
tion. In: Proceedings of SPIE (2004)
107. Gamboa, H., Fred, A.: An identity authentication system based on human–computer inter-
action behaviour. In: Proc. of the 3rd Intl. Workshop on Pattern Recognition in Information
Systems (2003)
108. Nishiuchi, N., Komatsu, S., Yamanaka, K.: A biometric identification using the motion of fin-
gers. In: International Conference on Biometrics and Kansei Engineering, Cieszyn, Poland,
June 25–28, pp. 22–27 (2009)
109. Lyu, S., Rockmore, D., Farid, H.: A digital technique for art authentication. In: Proceedings
of the National Academy of Sciences (2004)
110. Spafford, E.H., Weeber, S.A.: Software forensics: can we track code to its authors? In: 15th
National Computer Security Conference (1992)
111. Jain, A., Griess, F., Connell, S.: On-line signature verification. Pattern Recognit. 35, 2963–
2972 (2002)
112. Nalwa, V.S.: Automatic on-line signature verification. Proc. IEEE 85, 215–239 (1997)
113. Herbst, B., Coetzer, H.: On an offline signature verification system. In: Proceedings of the
9th Annual South African Workshop on Pattern Recognition (1998)
114. Lei, H., Palla, S., Govindaraju, V.: ER2: an intuitive similarity measure for on-line signature
verification. In: IWFHR ’04: Proceedings of the Ninth International Workshop on Frontiers
in Handwriting Recognition (IWFHR’04). IEEE Comput. Soc., Los Alamitos (2004)
115. Riha, Z., Matyas, V.: Biometric authentication systems. In: FI MU Report Series (2000)
116. Muralidharan, N., Wunnava, S.: Signature verification: a popular biometric technology. In:
Second LACCEI International Latin American and Caribbean Conference for Engineering
and Technology (LACCEI’2004), Miami, Florida, USA (2004)
117. Plamondon, R., Lorette, G.: Automatic signature verification and writer identification: the
state of the art. Pattern Recognit. 22(2), 107–131 (1989)
13 Behavioral, Cognitive and Virtual Biometrics 383
118. Ballard, L., Monrose, F., Lopresti, D.P.: Biometric authentication revisited: understanding
the impact of wolves in sheep’s clothing. In: Fifteenth USENIX Security Symposium, Van-
couver, BC, Canada (2006)
119. Ramann, F., Vielhauer, C., Steinmetz, R.: Biometric applications based on handwriting. In:
IEEE International Conference on Multimedia and Expo (ICME ’02) (2002)
120. Ballard, L., Lopresti, D., Monrose, F.: Evaluating the security of handwriting biometrics. In:
The 10th International Workshop on Frontiers in Handwriting Recognition (IWFHR06), La
Baule, France (2006)
121. Zhu, Y., Tan, T., Wang, Y.: Biometric personal identification based on handwriting. In: 15th
International Conference on Pattern Recognition (ICPR’00) (2000)
122. Hamdy, O., Traoré, I.: Cognitive-based biometrics system for static user authentication. In:
Fourth International Conference on Internet Monitoring and Protection, Venice/Mestre, Italy,
May 24–28, pp. 90–97 (2009)
123. Hamdy, O., Traoré, I.: New physiological biometrics based on human cognitive factors. In:
International Conference on Complex, Intelligent and Software Intensive Systems, Fukuoka,
Japan, March 16–19, pp. 910–917 (2009)
124. Jain, A.K., Dass, S.C., Nandakumar, K.: Can soft biometric traits assist user recognition. In:
SPIE Defense and Security Symposium, Orlando, FL (2004)
125. Jain, A.K., Dass, S.C., Nandakumar, K.: Soft biometric traits for personal recognition sys-
tems. In: International Conference on Biometric Authentication (ICBA), Hong Kong (2004)
126. Jacob, B.A., Levitt, S.D.: To catch a cheat. In: Education Next. Available at: www.
educationnext.org (2004)
127. Henderson, N.Y., et al.: Polymer thick-film sensors: possibilities for smartcard biometrics.
In: Proceedings of Sensors and Their Applications XI (2001)
128. Henderson, N.J., et al.: Sensing pressure for authentication. In: 3rd IEEE Benelux Signal
Processing Symp. (SPS), Leuven, Belgium (2002)
129. Halteren, H.V.: Linguistic profiling for author recognition and verification. In: Proceedings
of ACL-2004 (2004)
130. Stamatatos, E., Fakotakis, N., Kokkinakis, G.: Automatic authorship attribution. In: Ninth
Conf. European Chap. Assoc. Computational Linguistics, Bergen, Norway (1999)
131. Juola, P., Sofko, J.: Proving and improving authorship attribution. In: Proceedings of CaSTA-
04. The Face of Text (2004)
132. Koppel, M., Schler, J.: Authorship verification as a one-class classification problem. In: 21st
International Conference on Machine Learning, Banff, Canada (2004)
133. Koppel, M., Schler, J., Mughaz, D.: Text categorization for authorship verification. In:
Eighth International Symposium on Artificial Intelligence and Mathematics, Fort Laud-
erdale, Florida (2004)
134. Ciota, Z.: Speaker verification for multimedia application. In: IEEE International Conference
on Systems, Man and Cybernetics (2004)
135. Sanderson, C., Paliwal, K.K.: Information fusion for robust speaker verification. In: Proc.
7th European Conference on Speech Communication and Technology (EUROSPEECH’01),
Aalborg (2001)
136. Campbell, J.P.: Speaker recognition: a tutorial. Proc. IEEE 85(9), 1437–1462 (1997)
137. Ratha, N.K., Senior, A., Bolle, R.M.: Automated biometrics. In: International Conference on
Advances in Pattern Recognition, Rio de Janeiro, Brazil (2001)
138. Deshpande, S., Chikkerur, S., Govindaraju, V.: Accent classification in speech. In: Fourth
IEEE Workshop on Automatic Identification Advanced Technologies (2005)
139. Lin, X., Simske, S.: Phoneme-less hierarchical accent classification. In: Thirty-Eighth Asilo-
mar Conference on Signals, Systems and Computers (2004)
140. Tsai, W.-H., Wang, H.-M.: Automatic singer recognition of popular music recordings via
estimation and modeling of solo vocal signals. IEEE Trans. Audio Speech Lang. Process.
14(1), 330–341 (2006)
141. Revett, K.: Behavioral Biometrics: A Remote Access Approach. Wiley, Chichester (2008)
142. Marcel, S., Millan, J.: Person authentication using brainwaves (EEG) and maximum a poste-
riori model adaptation. IEEE Trans. Pattern Anal. Mach. Intell. 29(4), 743–752 (2007)
384 R.V. Yampolskiy
143. Thorpe, J., Oorschot, P.C.V., Somayaji, A.: Pass-thoughts: authenticating with our minds. In:
Workshop on New Security Paradigms, Lake Arrowhead, California (2011)
144. Lawson, W.: The new wave (“Biometric access & neural control”) (2002). November 24,
2008. Available from: http://www.icdri.org/biometrics/new_wave.htm
145. Mohammadi, G., et al.: Person identification by using AR model for EEG signals. In: World
Academy of Science, Engineering and Technology (2006)
146. Gahi, Y., et al.: In: New Technologies, Mobility and Security (NTMS’08), Tangier, Virginia,
November 5–7, pp. 1–5 (2008)
147. Shye, A., et al.: Power to the people: leveraging human physiological traits to control mi-
croprocessor frequency. In: 41st IEEE/ACM International Symposium on Microarchitecture,
Como, Italy, November 8–12 (2008)
148. Korotkaya, Z.: Biometrics person authentication: odor (2003). October 12, 2008. Available
from: http://www.it.lut.fi/kurssit/03-04/010970000/seminars/Korotkaya.pdf
149. Beritelli, F., Serrano, S.: Biometric identification based on frequency analysis of cardiac
sounds. IEEE Trans. Inf. Forensics Secur. 2(3), 596–604 (2007)
150. Phua, K., et al.: Human identification using heart sound. In: Second International Workshop
on Multimodal User Authentication, Toulouse, France (2006)
151. Preez, J., Soms, S.H.: Person identification and authentication by using “the way the heart
beats”. In: ISSA 2005 New Knowledge Today Conference, Sandton, South Africa (2005)
152. Scotti, S., et al.: Quantitative evaluation of distant student psychophysical responses during
the e-learning processes. In: 27th IEEE Annual Conference on Engineering in Medicine and
Biology, Shanghai, China, September 1–4 (2005)
153. Yampolskiy, R.V.: Action based user authentication. Int. J. Electron. Secur. Digit. Forensics
1(3), 281–300 (2008)
154. Bekkering, E., Warkentin, M., Davis, K.: A longitudinal comparison of four password pro-
cedures. In: Proceedings of the Hawaii International Conference on Business, Honolulu, HI,
June (2003)
155. Podd, J., Bunnell, J., Henderson, R.: Cost-effective computer security: cognitive and associa-
tive passwords. In: Sixth Australian Conference on Computer-Human Interaction, Hamilton,
New Zealand, November 24–27, pp. 304–305 (1996)
156. Brostoff, A.: Improving password system effectivness. PhD Dissertation, Department of
Computer Science University College London, September 30, 2004
157. Brostoff, A.: The science behind passfaces. In: Real User Corporation, June 2004. Available
at: http://www.realuser.com/
158. Dhamija, R., Perrig, A.: Deja vu: a user study. Using images for authentication. In: Proceed-
ings of the 9th USENIX Security Symposium, Denver, Colorado, August (2000)
159. Angeli, A.D., et al.: Usability and user authentication: Pictorial passwords vs. PIN. In: Con-
temporary Ergonomics, pp. 253–258. Taylor & Francis, London (2003)
160. Jansen, W., et al.: Picture password: a visual login technique for mobile devices. Retrieved
October 24, 2005. Available at: http://csrc.nist.gov/publications/nistir/nistir-7030.pdf
161. Pointsec. PicturePINs. November, 2002. Available at: http://www.pointsec.com/news/
download/Pointsec_PPC_2.0_POP_PA1.pdf
162. Gibson, M., et al.: Musipass: authenticating me softly with my song. In: New Security
Paradigms Workshop (NSPW’09), Oxford, UK, September 8–11 (2009)
163. Wiedenbeck, S., et al.: Authentication using graphical passwords: basic results. Retrieved
October 23, 2005. Available at: http://clam.rutgers.edu/~birget/grPssw/susan3.pdf
164. Wiedenbeck, S., et al.: PassPoints: design and longitudinal evaluation of a graphical pass-
word system. Int. J. Human-Comput. Stud. 63(1–2) (2005)
165. Blonder, G.E.: Graphical passwords. United States Patent 5559961 (1996)
166. Varenhorst, C.: Passdoodles; a lightweight authentication method. July 27, 2004. Available
at: http://people.csail.mit.edu/emax/papers/varenhorst.pdf
167. Jermyn, I., et al.: The design and analysis of graphical passwords. In: Proceedings of the 8th
USENIX Security Symposium, Washington, D.C., August 23–36 (1999)
13 Behavioral, Cognitive and Virtual Biometrics 385
168. Thorpe, J., v. Oorschot, P.: Towards secure design choices for implementing graphical pass-
words. In: 20th Annual Computer Security Applications Conference, Tucson, Arizona, De-
cember 6–10 (2004)
169. Ross, S.: Is it just my imagination? Retrieved November 4, 2005. Available at: http://
research.microsoft.com/displayArticle.aspx?id=417
170. Renaud, K., McBryan, T.: How viable are Stubblefield and Simon’s inkblots as password
cues? In: PUMP 2010, University of Abertay, Dundee, 6 September (2010)
171. Renaud, K., McBryan, T., Siebert, P.: Password cueing with cue(ink)blots. In: IADIS Com-
puter Graphics and Visualization 2008 (CGV 2008), Amsterdam, The Netherlands (2008)
172. Stubblefield, A., Simon, D.: Inkblot authentication. Microsoft TechReport# MSR-TR-2004-
85 (August 2004). Available at: http://research.microsoft.com/pubs/70086/tr-2004-85.pdf
173. Porter, S.: Stronger passwords through visual authentication: handwing. University of
Glasgow. Retrieved November 4, 2005. Available at: http://www.dcs.gla.ac.uk/~porters/
thesis.pdf
174. Standring, S.: Gray’s Anatomy: The Anatomical Basis of Medicine and Surgery. Churchill
Livingstone, Oxford (2004)
175. Erdogan, H., et al.: Multi-modal person recognition for vehicular applications. Lect. Notes
Comput. Sci. 3541, 366–375 (2005)
176. Marin, J., Ragsdale, D., Surdu, J.: A hybrid approach to the profile creation and intrusion
detection. In: DARPA Information Survivability Conference and Exposition (DISCEX II’01)
(2001)
177. Bergadano, F., Gunetti, D., Picardi, C.: User authentication through keystroke dynamics.
ACM Trans. Inf. Syst. Secur. 5(4), 367–397 (2002)
178. Frantzeskou, G., Gritzalis, S., MacDonell, S.: Source code authorship analysis for support-
ing the cybercrime investigation process. In: 1st International Conference on eBusiness and
Telecommunication Networks—Security and Reliability in Information Systems and Net-
works Track, Setubal, Portugal. Kluwer Academic, Dordrecht (2004)
179. Colombi, J., et al.: Cohort selection and word grammer effects for speaker recognition. In:
IEEE International Conference on Acoustics, Speech, and Signal Processing, Atlanta, GA
(1996)
180. Tsai, W.-H., Wang, H.-M.: Automatic singer recognition of popular music recordings via
estimation and modeling of solo vocal signals. In: IEEE Transactions on Audio, Speech and
Language Processing, January 2006
181. Crompton, M.: Biometrics and privacy: the end of the world as we know it or the white knight
of privacy? In: 1st Biometrics Institute Conference (2003)
182. Prassas, G., Pramataris, K.C., Papaemmanouil, O.: Dynamic recommendations in internet
retailing. In: 9th European Conference on Information Systems (ECIS 2001) (2001)
183. Liang, T.P., Lai, H.-J.: Discovering user interests from web browsing behavior. In: Proceed-
ings of the Hawaii International Conference on Systems Sciences, Hawaii, USA (2002)
184. Fu, Y., Shih, M.: A framework for personal web usage mining. In: International Conference
on Internet Computing (IC’2002), Las Vegas, NV (2002)
185. Goecks, J., Shavlik, J.: Learning users’ interests by unobtrusively observing their normal
behavior. In: Proceedings of the International Conference on Intelligent User Interfaces, New
Orleans, LA (2000)
186. Democraticmedia.org: TV that watches you: the prying eyes of interactive television. A re-
port by the center for digital democracy, June 2001. Available from: www.democraticmedia.
org/privacyreport.pdf
187. Jain, K., Nandakumar, K., Ross, A.: Score normalization in multimodal biometric systems.
In: Pattern Recognition (2005)
188. Dahel, S.K., Xiao, Q.: Accuracy performance analysis of multimodal biometrics. In: IEEE
Information Assurance Workshop on Systems, Man and Cybernetics Society (2003)
189. Humm, A., Hennebert, J., Ingold, R.: Scenario and survey of combined handwriting and
speech modalities for user authentication. In: 6th International Conference on Recent Ad-
vances in Soft Computing (RASC’06), Canterbury, UK (2006)
