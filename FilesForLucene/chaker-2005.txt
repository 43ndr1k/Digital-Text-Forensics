SETIT 2005 
3rd International Conference: Sciences of Electronic, 
Technologies of Information and Telecommunications 
March 27-31, 2005 – TUNISIA 
 
Catégorisation Flexible d’un Document  
 
Jebari Chaker*, Ounalli Habib** 
 
*King Saud University 
College of Computer and Information Sciences 
Computer Science Department 
PO. BOX. 51178 Riyadh 11543, KINGDOM OF SAUDI ARABIA 
jebarichaker@yahoo.fr 
 
**Université  de Tunis El’Manar 
Faculté des Sciences de Tunis   
Campus Universitaire 2092 Tunis, TUNISIE 
 
habib.ounelli@fst.rnu.tn 
  
Résumé: Dans le cadre des travaux de catégorisation automatique de documents, nous proposons dans cet article une 
nouvelle approche de catégorisation flexible de documents électroniques qui se situe à la jonction de l’approche 
d’ingénierie de connaissances et celle utilisant des techniques d’apprentissage automatique. Notre approche permet 
d’assigner un document HTML à une ou plusieurs catégories (dictionnaire, monographie, brevet, thèse, mémoire, 
rapport, article, questionnaire, appel à communication, news, page web, email) et ce en exploitant des attributs d’ordre 
physique, logique et  discursive. Cette approche utilise un ensemble de documents déjà catégorisés pour générer 
ensemble de règles de catégorisation utilisées pour catégoriser de nouveaux documents. La flexibilité de la 
catégorisation est réalisée par l’association d’un poids représentant l’importance de chaque règle dans la discrimination 
entre les catégories possibles. Ce poids est calculé en utilisant la t-norme min de Zadeh, il est modifié dynamiquement 
au fur et à mesure de la catégorisation d’un nouveau document.  
L’approche proposée à été évaluée en utilisant un corpus formé de 615 documents HTML et appartenant aux différentes 
catégories possibles. Les résultats obtenus son satisfaisants et constituent une validation primaire de notre approche. 
Mots clés: apprentissage, catégorisation, document, flexible, règle. 
 
1 Introduction 
 
Devant la croissance extraordinaire de nombre de 
documents qui transitent sur le réseau Internet, nous 
remarquons que, suite à une requête de recherche, les 
systèmes de recherche d’informations actuels  fournit 
une liste très importante de documents. Devant cette 
liste, l’utilisateur ne peut pas sélectionner rapidement 
les documents qui lui sont pertinents.  
La catégorisation automatique de documents est 
considérée parmi les composants les plus importants 
dans un système de recherche d’informations, car elle 
permet d’organiser les documents par catégories. Cette 
catégorisation permet d’accélérer, cibler et améliorer la 
recherche d’informations. 
Plusieurs méthodes de catégorisation automatique 
ont été proposées dans la littérature. Ces méthodes 
peuvent être subdivisées en deux catégories : des 
méthodes se basant sur l’ingénierie des connaissances 
et celles utilisant des techniques d’apprentissage 
automatique.   
Dans ce papier, nous proposons une nouvelle 
approche de catégorisation. Cette approche permet 
d’assigner un document HTML à une ou plusieurs 
catégories prédéfinies (dictionnaire, monographie, 
brevet, thèse, mémoire, rapport, article, questionnaire, 
appel à communication, news, page web, email)  et ce 
en utilisant des attributs d’ordre physique (la taille de 
document en nombre de mots), logique (la structure 
logique de document) et discursive (l’existence de 
certaines expressions linguistiques dans des unités 
logiques bien définies). En utilisant un ensemble de 
documents déjà catégorisés, cette approche permet de 
générer un ensemble de règles de trois types  : des 
règles physiques, logiques et discursives exploitant 
respectivement les attributs physiques, logique et 
discursive. 
SETIT2005 
La flexibilité de notre approche est réalisée en 
associant à chaque règle générée un poids représentant 
son importance dans la discrimination entre les 
catégories possibles.    
L’approche de catégorisation que nous proposons 
répond à plusieurs motivations : 
• La plus part des systèmes de  recherche 
d’informations actuels se basent sur une 
stratégie de recherche exhaustive. Dans cette 
stratégie, une requête donnée est comparée à 
tous les documents de la collection, ce qui 
nécessite un temps énorme de recherche. Le 
regroupement de documents par catégorie 
(dictionnaire, monographie, brevet, thèse, 
mémoire, rapport, article, questionnaire, appel à 
communication, news, page web, email ) permet 
d’accélérer la recherche exhaustive 
d’informations et ce en comparant la requête 
donnée avec le représentant de chaque catégorie, 
ce qui permet d’accélérer la recherche 
exhaustive d’informations. Dans le même ordre 
d’idée, Chanana à proposé un nouveau système 
de recherche d’informations qui se basent sur 
l’identification du type ou du contexte de 
document (Chanana & al., 2004a).  
• Elle permet d’améliorer la qualité de 
classification thématique de documents et ce en 
exploitant seulement les termes contenus dans 
les unités thématiques1 de chaque document. 
Ces unités sont identifiées en utilisant la 
catégorie de document (Jebari & al., 2002). 
• Elle permet de faciliter l’assimilation de la 
masse d’informations disponible. En effet, le 
regroupement de documents par type permet de 
cibler la recherche d’informations en fonction 
des besoins des utilisateurs (Chanana & al., 
2004b). 
• Puisque les différentes méthodes de résumé 
automatique de documents proposées dans la 
littérature dépendent du type de document à 
résumer. Notre méthode permet d’appliquer la 
méthode convenable et ce via la catégorisation 
du document que nous proposons.    
Dans cet article, nous présenterons dans la 
deuxième section un survol des travaux réalisés dans le 
domaine de catégorisation automatique de documents. 
Dans la troisième section, nous présenterons le principe 
de l’approche de catégorisation proposée. Dans les 
quatrième, la cinquième et la sixième section, nous 
explicitons respectivement les trois principales étapes 
de notre approche : Génération des règles de 
catégorisation, catégorisation de nouveaux documents 
et mise à jour des règles de catégorisation. L’évaluation 
de cette approche est également présentée dans la 
                                                 
1Une unité thématique est une unité logique 
susceptible d’annoncer la thématique de document 
entier.  
septième section. Enfin, nous conclurons sur les 
perspectives possibles de ce travail. 
2 Catégorisation de documents : Travaux 
réalisés 
L’apparition de la catégorisation automatique de 
documents remonte aux années 60 avec les travaux de 
Maron (Maron, 1961). Depuis, plusieurs auteurs ont 
attribué des définitions différentes au concept 
catégorisation (Lewis, 1992), (Makoto & al., 1995), 
(Aas, 1999), (Sebastiani, 1999), (Sebastiani, 2002). 
Selon Sebastiani (Sebastiani, 1999), (Sebastiani, 2002), 
la catégorisation d’un ensemble de documents D 
consiste à assigner à chaque document d appartenant à 
l’ensemble D une catégorie c parmi une liste de 
catégories prédéfinies C. Cette catégoris ation se base 
sur une matrice A qui s’appelle matrice de décision , 
dont les lignes représentent les différentes catégories 
possibles et les colonnes représentent l’ensemble de 
documents sujet de la catégorisation. L’entrée aij de la 
matrice A, prend la valeur 0 ou 1 en fonction de 
l’adéquation de document dj  avec la catégorie ci. 
La catégorisation automatique de documents est 
devenue de plus en plus importante dans plusieurs 
applications telles que : l’indexation automatique dans 
les systèmes de recherche documentaire qui se basent 
sur l’interrogation booléenne, l’organisation des 
documents pour accélérer la recherche et ce en 
regroupant ensemble les documents appartenant à une 
même catégorie, la condensation et le filtrage de 
documents pour assimiler et dis séminer l’information 
trouvée (Sebastiani, 1999).  
Dans la littérature, nous distinguons entre deux 
types de catégorisation de documents : thématique et 
contextuelle. La catégorisation thématique permet 
d’identifier le thème de document et ce en utilisant son 
contenu. Par contre, la catégorisation contextuelle 
exploite des informations contextuelles (type, auteur, 
date, …) pour identifier le thème de document. 
La catégorisation automatique de document peut 
être utilisée aussi pour identifier le type de document 
(dictionnaire, article, page web, appel à 
communication, questionnaire, …). Malgré l’utilité de 
ce type de catégorisation dans plusieurs applications 
(voir introduction), peut de travaux ont été proposés 
pour ce type de catégorisation ( pour un survol rapide 
de ces travaux voir ( Karlgren & al., 1994), (Yong-Bae 
& al., 2004), (Kessler & al., 1997), (Marzin & al., 
2004), (Kevin & al., 1997) et (Dimitri & al., 2001)). 
Les méthodes proposées dans ce type de catégorisation 
se diffèrent par le nombre et le type de catégories, ce 
qui rend très difficile, la comparaison de ces méthodes. 
Par exemple Kevin propose 7 catégories pour les 
documents web (rapportage, éditorial, papier de 
recherche, examen, page personnelle, questionnaire, 
autres) (Kevin & al., 1997), Marzin à proposé 4 
catégories pour les pages web (pages de liens, pages 
personnelles, navigateurs et pages de vente) (Marzin & 
al., 2004).          
Les travaux de catégorisation automatique de 
documents ont fait émerger plusieurs méthodes de 
SETIT2005 
catégorisation thématique de documents (Sebastiani, 
1999), (Sebastiani, 2002). Ces méthodes sont de deux 
types : les méthodes qui se basent sur l’ingénierie des 
connaissances et les méthodes utilisant des techniques 
d’apprentissage automatique. 
 L’approche de catégoris ation par ingénierie des 
connaissances a été proposée par Maron aux années 60 
(Maron, 1961). Elle se base sur des règles de 
catégorisation de la forme Si Condition  Alors 
Catégorie (Hayes & al., 1990), (Apte & al., 1994). 
Cette approche a été abandonnée car elle demande un 
effort manuel pour construire et gérer l’ensemble des 
règles de catégorisation.  
Pour remédier à ce problème, la communauté de 
catégorisation a proposé aux années 80 d’utiliser des 
techniques d’apprentissage automatique (Mitchell, 
1997). Le principe de cette approche consiste à générer 
automatiquement à partir d’un ensemble de documents 
d’apprentissage une fonction de catégorisation. Cette 
fonction sera utilisée par la suite pour catégoriser de 
nouveaux documents. Parmi les algorithmes 
d’apprentissage utilisés, nous citons : l’algorithme de 
Rocchio (Joachims, 1997), K plus proches voisins 
(Duda & al., 1973), Simple bayes (Joachims, 1997), 
(Aas, 1999), arbres de décision (Breiman & al., 1984), 
(Quinlan, 1993), machines à support de vecteurs 
(Vapnik, 1995), (Kwok, 1998) et les méthodes 
combinées (Breiman, 1996), (Freund, 1996). 
3 Principe de l’approche proposée  
L’approche de catégorisation que nous proposons 
permet d’assigner un document HTML à une ou 
plusieurs catégories prédéfinies (dictionnaire, 
monographie, brevet, thèse, mémoire, rapport, article, 
questionnaire, appel à communication, news, page 
web, email)  et ce en utilisant des attributs d’ordre 
physique (la taille de document en nombre de mots), 
logique (la structure logique de document) et discursive 
(l’existence de certaines expressions linguistiques dans 
des unités logiques bien définies). 
Cette approche peut être caractériser d’hybride car 
elle se situe à la jonction de l’approche d’ingénierie des 
connaissances et celle utilisant des techniques 
d’apprentissage automatique. Elle permet de générer 
automatiquement à partir d’un ensemble de documents 
d’apprentissage, une fonction de catégorisation. Cette 
fonction est donnée directement sous la forme d’un 
ensemble de règles de catégorisation contrairement à 
d’autres méthodes telles que les arbres de décision 
(Quinlan, 1983), (Breiman, 1984), (Quinlan, 1993), les 
treillis de Galois (Mephu, 2002) ou les graphes 
d’induction (Rakotomalala, 1997), (Zighed & al., 
1992) pour lesquelles une transformation du graphe 
obtenu en règles est nécessaire. Ces règles sont de trois 
types  : règles physiques exploitant l’attribut physique, 
règles logiques exploitant l’attribut logique et règles 
discursives exploitant l’attribut discursive. Chaque 
règle de catégorisation générée est de la forme Si 
Condition  Alors Conclusion. Cette nouvelle approche 
est dite flexible car la partie Conclusion de chaque 
règle est associée à un poids représentant son 
importance dans la discrimination entre les catégories 
possibles. Ce poids est calculé en utilisant la t-norme 
min de Zadeh (Zadeh, 1990), il est modifié 
dynamiquement au fur et à mesure de la catégorisation 
d’un nouveau document.  
La phase de catégorisation exploite l’ensemble de 
règles de catégorisation générées pour catégoriser de 
nouveaux documents et gérer les degrés d’appartenance 
aux différentes catégories possibles.  
La catégorisation de nouveaux documents se base 
sur trois types de discrimination : discrimination 
physique, logique et discursive exploitant 
respectivement les règles physiques, logiques et 
discursives.   
Le principe de notre approche est illustré dans la 
figure 1. 
 
       
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Nouveaux 
Documents 
Documents 
catégorisés 
Documents 
d’apprentissage 
Règles 
physiques 
Génération de règles 
de catégorisation 
Règles 
logiques 
Règles 
discursives 
Discrimination 
physique  
Discrimination 
logique 
Discrimination 
discursive  
2ème Liste de 
catégories possibles 
1ère Liste de 
catégories possibles 
3ème Liste de 
catégories possibles 
Conjonction des trois listes 
de catégories possibles    
Mise à jour de l’ensemble de 
documents d’apprentissage 
Mise à jour des règles 
Pré -traitement  
SETIT2005 
 
 
 
 
 
Figure 1. Principe de l’approche proposée 
 
4 Génération des règles de catégorisation  
 
4. 1 Collection d’apprentissage 
 
Pour générer les règles de catégorisation, nous 
disposons d’un ensemble de documents 
d’apprentissage A formé de 1230 documents HTML. 
Chaque document d’apprentissage dj est représenté 
par : son identifiant didj , sa catégorie Cj, sa taille en 
nombre de mots nmj, sa structure logique slj et une 
unité discursive udj vérifiée par le document en 
question. La répartition de l’ensemble de documents 
d’apprentissage A sur les 12 catégories possibles est 
présentée dans le tableau 1 ci-dessous. 
 
  
 
 
 
 
 
 
 
 
 
Tableau 1. Répartition des documents d’apprentissage par 
catégorie 
 
 
 
 
 
4. 2 Attributs de catégorisation 
4. 2. 1 L’attribut NM 
La prise en compte d’attributs numériques nécessite 
une procédure de discrétisation. Discrétiser un attribut 
numérique consiste à découper son domaine de 
variation en un nombre fini d’intervalles. Ces 
intervalles sont ensuite considérés comme de nouveaux 
concepts symboliques. Dans notre cas, nous disposons 
d’un seul attribut numérique continu à savoir l’attribut 
NM  qui représente la taille de document en nombre de 
mots. Pour discrétiser cet attribut, nous avons choisi de 
découper son domaine de variation en trois sous 
intervalles. Le premier sous intervalle < 5000 
représente une taille en nombre de mots faible. Le 
deuxième sous intervalle [5000, 50000] représente une 
taille en nombre de mots moyenne. Tandis que le 
troisième sous intervalle > 50000 représente une taille 
en nombre de mots élevée. Ce découpage est déduit à 
partir de l’ensemble de documents d’apprentissage A.  
4. 2. 2 L’attribut SL 
Une structure logique est une suite d’unités logique 
ordonnées l’une à la suite de l’autre pour faire 
apparaître une idée quelconque. Pour chaque unité 
logique, nous allons lui affecter un poids appartenant à 
l’intervalle ]0, 1] qui représente son importance dans la 
structure logique en question. Ces poids sont calculés 
en utilisant les documents d’apprentissage. Pour cet 
attribut, nous avons identifié à partir de l’ensemble de 
documents d’apprentissage 9 structures logiques 
possibles sl1, sl2, …, sl9. Le tableau 2 représente les 
différentes structures déduites à partir de l’ensemble de 
documents d’apprentissage A.  
 
 
 
 
 
 
 
 
Tableau 2. Structures logiques prédéfinies 
Notation Catégorie # de documents 
d’apprentissage  
par catégorie 
C1 Dictionnaire 30 
C2 Monographie 40 
C3 Brevet  40 
C4 Thèse 100 
C5 Mémoire 100 
C6 Rapport  100 
C7 Article 120 
C8 Questionnaire 100 
C9 Appel à 
communication 
100 
C10 News 160 
C11 Page web 180 
C12 Email 160 
Notation Structure Logique 
Sl1 Titre (1), édition (1), conventions (0.8), abréviations (0.7), introduction (1), texte (1), 
conjugaison des verbes (1). 
Sl2 Titre (1), résumé (0.2), mots clés (0.2), édition (1), préface et remerciements (0.8), avant 
propos (0.8), table des matières (1), introduction (1), texte (1), conclusion (1), 
bibliographie (1), annexes (0.3), glossaire (0.2), index (0.7). 
Sl3 Titre (1), résumé (1), mots clés (1), abstract (0.5), key words (0.5), dédicaces (0.3), 
remerciements (0.8), table des matières (1), table des illustrations (0.2), introduction (1), 
texte (1), conclusion (1), bibliographie (1), annexes (0.4), glossaire (0.2), index (0.2). 
Sl4 Titre (1), auteur(s) (1), affiliation(s) (1), email(s) (1), résumé (1), mots clés (1), 
introduction (1), texte (1), conclusion (1), remerciements (0.2), références (1).  
Sl5 Titre (1), date et lieu (1), introduction (1), thèmes abordés (1), soumission (1), comité 
scientifique (1), comité d’organisation (1), dates importantes (1), informations (0.8). 
Sl6 Titre (1), question0-réponse0 (1), question1-réponse1 (1), …  
Sl7 Titre (1), agence de presse (1), lieu et date (0.7), texte (1). 
Sl8 Destination (1), sujet (0.8), texte (1). 
Sl9 Titre (1), texte (1). 
SETIT2005 
 
 
4. 2. 3 L’attribut UD 
 
Une unité discursive est représentée par un 
ensemble d’expressions linguistiques et un ensemble 
d’unités logiques. L’unité discursive est dite vérifiée, si 
au moins une de ses expressions linguistiques est 
présente dans l’une de ses unités logiques. Elle est dite 
non vérifiée s’il n’existe aucune de ses expressions 
linguistiques dans toutes ses unités logiques. A partir 
de l’ensemble de documents d’apprentissage A, nous 
avons 
identifié 12 unités discursives possibles nommées ud1, 
ud2, …, ud12 ( voir tableau 3 ).
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Tableau 3. Unités discursives prédéfinies 
 
4. 3 Règles physiques  
 
La génération des règles physiques se base sur les 
valeurs de l’attribut NM. Dans notre cas, nous avons 
dégagé 3 règles physiques. Chaque règle est de la 
forme : 
Si Condition(NM)  
Alors {(C1, α1), (C2, α2), …, (C12, α12)} 
Avec : 
• Condition(NM) est vérifiée si NM ∈ { faible, 
moyenne, élevé  }. 
• α i est le degré d’appartenance à la catégorie Ci. 
Ce degré est la proportion des documents 
d’apprentissage appartenant à la catégorie Ci et 
vérifiant Condition(NM). 
Exemple : 
Si NM = élevée Alors   
{(dictionnaire, 1.00), (monographie, 1.00),    
(brevet, 1.00), (thèse, 0.67), (mémoire, 0.50),  
(rapport, 0.50), (article, 0.25), (questionnaire, 0.00), 
(appel à communication, 0.00), (News, 0.00),  
(page web, 0.00), (e-mail, 0.00)} 
4. 4 Règles logiques  
En utilisant les valeurs de l’attribut SL, nous avons 
dégagé 9 règles logiques. Chaque règle est de la 
forme : 
 
Si Condition(SL)  
Alors {(C1, β1), (C2, β2), …, (C12, β12)} 
Notation Expressions linguistiques Unités logiques 
Ud1 Ce dictionnaire, le présent dictionnaire, le dictionnaire suivant, 
ce nouveau dictionnaire, ce mini dictionnaire 
Préface+introduction 
Ud2 Cet ouvrage, le présent ouvrage, l’ouvrage suivant,  
ce livre, le présent livre, le livre suivant,  
Cette monographie,  la présente monographie, la monographie 
suivante. 
Résumé+préface+remerciements
+avant propos+introduction 
Ud3 Ce brevet, le présent brevet, le brevet suivant. Résumé+remerciements 
+introduction 
Ud4 Cette thèse, la présente thèse, la thèse suivante. Résumé+remerciements 
+introduction 
Ud5 Ce mémoire, le présent mémoire, le mémoire suivant. Résumé+remerciements 
+introduction 
Ud6 Ce rapport, le présent rapport, le rapport suiv ant.  Résumé+remerciements 
+introduction 
Ud7 Cet article, le présent article, l’article suivant, ce papier, 
 Le présent papier, le papier suivant.  
Résumé+introduction 
Ud8 Ce questionnaire, le présent questionnaire,  
le questionnaire suivant, cette enquête, l’enquête suivante, la 
présente enquête, ce FAQ, le présent FAQ,  
Le FAQ suivant.  
Titre 
+question0-réponse0 
+question1-réponse1 
Ud9 Cet AàC, l’AàC suivant, le présent AàC, cet AàP, l’AàP 
suivant, le présent AàP.    
Titre+introduction 
+thèmes abordés 
Ud10 Cet article de journal, l’article de journal suivant,  
le présent article de journal. 
Titre+texte 
Ud11 Ce site web, le site web suivant, le présent site web, cette page 
web, la page web suivante,  
la présente page web. 
Titre+texte 
Ud12 Cet Email, l’Email suivant, le présent Email, ce message, le 
message suivant, le présent message. 
Texte 
SETIT2005 
Avec : 
• Condition(SL) est vérifiée si ArgmaxSL SIM(slj, 
sli) ≥ S0 
• β i est le degré d’appartenance à la catégorie Ci. Ce 
degré est la proportion des documents 
d’apprentissage appartenant à la catégorie Ci et 
vérifiant Condition(SL). 
• SIM(slj, sli) est la similarité de la structure logique 
slj d’un document donné avec la structure logique 
prédéfinie sli ∈ SL ={sl1, sl2, …, sl9}. Cette 
similarité est calculée comme suit : 
SIM(slj, sli) = 
∑
∑
∈
∩∈
ii
iji
slul
i
slslul
i
p
p
 
Avec : 
§ uli : Une unité logique appartenant à la 
structure logique prédéfinie sli. 
§ pi  :  Le poids affecté à l’unité logique uli. 
• S0 est le seuil minimal de similarité de slj avec la 
structure logique prédéfinie sli, au-dessous duquel 
Condition(SL) est n’est pas vérifiée. Dans notre 
cas, nous avons fixé la valeur de ce seuil à 0.5 
Exemple : 
Si SL = sl3 Alors  
{(dictionnaire, 0.00), (monographie, 1.00),  
(brevet, 0.20),(thèse, 1.00), (mémoire, 1.00),   
(rapport, 1.00), (article, 0.15), (questionnaire, 
0.00), (appel à communication, 0.00), (news, 
0.00), (page web, 0.00), (e -mail, 0.00)} 
 
4. 5 Règles discursives  
En exploitant les valeurs prises par l’attribut UD, 
nous avons dégagé 12 règles discursives. Chaque règle 
est de la forme : 
Si Condition(UD)  
Alors {(C1, γ1), (C2, γ2), …, (C12, γ12)} 
Avec : 
• Condition(UD) est vérifiée si UD ∈ 
{ud1, … ,ud12}. 
• γi est le degré d’appartenance à la catégorie Ci. 
Ce degré est la proportion des documents 
d’apprentissage appartenant à la catégorie Ci et 
vérifiant Condition(UD). 
Exemple : 
Si UD = ud7 Alors  
{(dictionnaire, 0.00), (monographie, 0.00), (brevet, 
0.00),(thèse, 0.00), (mémoire, 0.00), (rapport, 0.00),      
(article, 1.00), (questionnaire, 0.00), (appel à 
communication, 0.00), (news, 0.00), (page web, 0.00), 
(e-mail, 0.00) } 
 
5 Catégorisation de nouveaux documents 
A l’arrivé d’un nouveau document dj, le processus 
de catégorisation déclenche un pré-traitement pour 
déterminer la taille de document en nombre de mots 
nmj, sa structure logique slj et ce en utilisant les balises 
<Hn> et vérifier l’existence de certaines unités 
discursives udj. A l’issu de ce pré-traitement, trois 
types de discrimination seront déclenchés : 
discrimination physique, logique et discursive 
exploitant respectivement les règles physiques, 
logiques et discursives déjà générées.  
La discrimination  physique permet de déclencher 
la règle physique vérifiant Condition(nmj). A l’issu de 
cette discrimination, nous obtenons une première 
catégorisation possible : 
E1  = {(C1, α1), (C2, α2), …, (C12, α12)}.  
En deuxième lieu, la discrimination logique nous 
permet de déclencher la règle logique vérifiant 
Condition(slj) pour obtenir une deuxième 
catégorisation possible : 
E2  = {(C1, β1), (C2, β2), …, (C12, β12)} 
Enfin, la discrimination discursive, nous permet 
d’obtenir une troisième catégorisation possible et ce en 
vérifiant Condition(udj) : 
E3  = {(C1, γ1), (C2, γ2), …, (C12, γ12)} 
Pour obtenir une seule catégorisation optimale, 
nous devons combiner ces trois catégorisations 
possibles E1, E2 et E3. Pour cela, nous avons choisi 
d’utiliser la norme triangulaire min de Zadeh.  
Cette catégorisation optimale est calculée comme 
suit : 
E* = E1 ∩ E2 ∩ E3 = {(C1, min(α1, β1, γ1)), (C2, 
min(α2, β2, γ2)), …, (C12, min(α12, β12, γ12))}. 
Les catégories choisies sont celles réalisant le 
maximum de degré d’appartenance.  
 
6 Mise à jour des règles de catégorisation 
Après chaque opération de catégorisation d’un ou 
plusieurs documents, nous devons mettre à jour 
l’ensemble des règles. Cette mise à jour réside dans 
deux points : 
• Suppression des règles dont les parties Conclusion 
sont nulles ( les degrés d’appartenance à toutes les 
catégories sont égaux à 0 ). 
• Puisque les proportions des documents vérifiant 
les parties Condition des règles, vont être changées 
à l’arrivée de nouveaux documents. Nous devons 
donc, recalculer les degrés d’appartenance dans 
toutes les parties Conclusion des règles. 
 
7 Evaluation   
SETIT2005 
Pour évaluer une méthode de catégorisation de 
documents, deux techniques sont possibles : comparer 
la catégorisation obtenue par la méthode proposée avec 
d’autres catégorisations obtenues par d’autres 
méthodes ou comparer la catégorisation obtenue avec 
une catégorisation manuelle ou dite de référence. 
Dans notre cas, la comparaison avec d’autres 
méthodes proposées dans la littérature est impossible, 
car les méthodes proposées dans la littérature 
n’utilisent pas le même nombre et type de catégories. 
La plus part de ces méthodes sont dévouées à des 
catégories thématiques ( sport, science, agriculture, …). 
Pour cette raison, nous avons choisi d’utiliser la 
deuxième technique.   
Pour effectuer l’évaluation, nous avons développé 
le système CFD (Catégorisation Flexible d’un 
Document) implémentant l’approche proposée. Ce 
système est évalué en utilisant un corpus de 615 
documents HTML appartenant aux différentes 
catégories déjà fixées. 
Pour chaque document dj d’évaluation, nous avons 
identifier les trois attributs nmj, slj et udj . En exploitant 
ces trois attributs, nous avons pu dégager les résultats 
suivants ( voir tableau 4 ). 
      
 
Tableau 4. Rappel, précision, exactitude et erreur par catégorie 
 
Avec : 
 
• A : le nombre de documents correctement 
assignés à la catégorie en question. 
• B : le nombre de documents incorrectement 
assignés à la catégorie en question. 
• C : le nombre de documents incorrectement 
rejetés par la catégorie en question. 
• D : le nombre de documents correctement 
rejetés par la catégorie en question. 
 
Dans cette évaluation, nous avons calculé pour 
chaque catégorie Ci quatre mesures qui sont : 
 
• Rappel(Ci) = A ⁄  ( A + C ) 
• Précision(Ci) = A ⁄  ( A + B ) 
• Exactitude(Ci) = ( A + D )  ⁄  ( A + B + C + D ) 
• Erreur(Ci) = ( B + C )  ⁄  ( A + B + C + D ) 
 
En utilisant ces 4 mesures calculées pour chaque 
catégorie, nous avons calculé la moyenne pour chaque 
mesure en utilisant les formules suivantes : 
 
• Rappel = ∑ i = 1, …, 12 Rappel(Ci) ⁄ 12 
• Précision = ∑ i = 1, …, 12 Précision(Ci) ⁄ 12 
• Exactitude = ∑ i = 1, …, 12 Exactitude(Ci) ⁄ 12 
• Erreur = ∑ i = 1, …, 12 Erreur(Ci) ⁄ 12 
 
Pour ces 4 mesures, nous avons dégagé une valeur 
moyenne de 0.87 pour le rappel, une valeur moyenne 
de 0.94 pour la précision, une valeur moyenne de 0.84 
pour l’exactitude et une valeur moyenne de 0.16 pour 
l’erreur. Ces valeurs sont encourageantes. 
 
8 Conclusion et Perspectives  
 
Dans cet article, nous avons proposé une nouvelle 
approche de catégorisation flexible de documents, 
exploitant trois attributs d’ordre physique (la taille de 
document en nombre de mots), d’ordre logique (la 
structure logique de document) et d’ordre discursive 
(l’existence de certaines expressions linguistiques dans 
des unités logiques bien définies). Cette approche 
utilise un ensemble de documents d’apprentissage pour 
générer un ensemble de règles de catégorisation de la 
forme Si Condition Alors Conclusion. Ces règles sont 
de trois types  : physiques, logiques et discursives. La 
partie conclusion de chaque règle représente les degrés 
d’appartenance aux différentes catégories possibles. 
L’évaluation de cette approche fournit des résultats 
encourageants surtout au niveau précision et rappel. 
Dans ce papier, nous avons utilisé des documents 
HTML. Dans le cadre des travaux futures, nous 
proposons : 
 
• L’intégration de nouveaux formats de 
documents électroniques ( SGML, XML, … ) et 
ce pour exploiter les méta données fournit par la 
 
Catégorie 
# de documents  
d’évaluation 
par catégorie 
 
A 
 
B 
 
C 
 
D 
Rappel  
par 
catégorie 
Précision  
par 
catégorie 
Exactitude 
par 
catégorie 
Erreur 
par 
catégorie 
Dictionnaire 10 7 1 3 1 0.7 0.87 0.67 0.33 
Monographie 10 8 1 2 1 0.8 0.89 0.75 0.25 
Brevet  10 6 1 4 2 0.6 0.86 0.62 0.38 
Thèse 30 27 2 3 0 0.9 0.93 0.84 0.16 
Mémoire 35 33 1 2 1 0.94 0.97 0.92 0.08 
Rapport  50 48 0 2 1 0.96 1.00 0.96 0.04 
Article 70 70 2 0 0 1.00 0.97 0.97 0.03 
FAQ 70 66 3 4 1 0.94 0.96 0.91 0.09 
AàC 60 55 1 5 1 0.92 0.98 0.90 0.10 
News 100 90 5 10 4 0.9 0.95 0.86 0.14 
Page web 90 70 5 20 5 0.78 0.93 0.75 0.25 
Email 80 77 5 3 1 0.96 0.94 0.91 0.09 
SETIT2005 
norme Dublin Core 2 qu’on trouve dans ce type 
de documents. 
• L’intégration cette approche de catégorisation 
dans un processus de recherche d’informations 
et ce pour améliorer sa performance.   
 
Remerciements 
 
Je remercie mon encadreur de thèse Mr. Ounalli 
Habib et mes collègues à « College of Computer and 
Information Sciences, King Saud University, KSA ».  
 
Références  
 
(Aas, 1999) K. Aas, L. Eikvil, Text Categorisation: A 
Survey, technical report, Norwegian computing center, 1999. 
(Apte & al., 1994) C. Apte and al., Automated learning of 
decision rules for text categorisation, ACM Transactions on 
Information Systems, 12(3): 233 – 251, 1994. 
(Breiman & al., 1984) L. Breiman and al., Classification 
and Regression Trees , Belmont, CA: Wadsworth, 1984.   
(Breiman, 1996) L. Breiman, Bagging predictors, 
Machine Learning, Vol. 24, pp. 123 – 140, 1996. 
(Chanana & al., 2004a) V. Chanana & al., A new 
context -based information retrieval system, Accepted in 3rd  
WSEAS Int. Conf. On Artificial Intelligence, Knowledge 
Engineering, Data Bases (AIKED 2004), Salzburg, Austria, 
February 13-15, 2004. 
(Chanana &al., 2004b)V. Chanana & al., Assigning 
Context to Documents in a Collection to Improve 
Information Retrieval Effectiveness: Methodology and 
Experiences, 3rd  WSEAS Int. Conf. On Software 
Engineering, Parallel & Distributed Systems (SEPADS 
2004), Salzburg, Austria, February 13-15, 2004. 
(Dmitri & al., 2001) R. Dmitri & al., Genre based 
navigation of the web, In Proceedings of 34th International 
Conference on System Sciences , 2001. 
(Duda & al., 1973) R.O. Duda, P.E. Hart, Pattern 
Classification and Scene Analysis, John Wiley & Sons, 1973. 
(Freund & al., 1996) Y. Freund, R.E. Shapire, 
Experiments with a new boosting algorithm, In Proceeding of 
13th international conference on Machine Learning, pp. 148 – 
156, 1996.  
(Hayes & al., 1990) P.J. Hayes, S.P. Weistein, 
CONSTRUE/TIS: a system for content-based indexing of a 
database of news stories, In Proceedings of IAAI-90, 2nd 
Conference on Innovative Applications of Artificial 
Intelligence, pp. 1 – 5, 1990.   
(Jebari & al., 2002) C. Jebari et al., Une méthode de 
catégorisation d’un document électronique en vue d’une 
meilleure classification thématique, GEI’2002, Hammamet, 
Tunisie, 2002. 
(Joachims, 1997) T. Joachims, Text Categorization with 
Support Vector Machines: Learning with many relevant 
features, Technical report, University of Dortmund, 1997. 
                                                 
2 http://dublincore.org/ 
(Karlgren & al., 1994) J. Karlgren & al., Recognizing 
Text Genres with Simple Metrics Using Discriminant 
Analysis, Proc. Of COLING94, Kyoto, 1994. 
(Kessler & al., 1997) B. Kessler & al., Automatic 
Detection of Text Genre, In Proc. Of 35th Annual meeting of 
the Association for Computational Linguistics, 
ACL/EACL’1997, pp. 32-38, 1997.  
(Kevin & al., 1997) C. Kevin & al., Reproduced and 
emergent genres of communication on the world-wide web, 
In Proceedings of the 30th Hawaii International Conference 
on System Sciences (HICSS-30), Institute of Electrical and 
Electronics Engineers, 1997. 
(Kwok, 1998) J.T. Kwok, Automatic Text Categorisation 
Using Support Vector Machines, Proceeding of International 
Conference On Neural Information Processing, pp. 347 – 
351, October 1998. 
(Lewis, 1992) D.D. Lewis, Feature Selection and Feature 
Extraction for Text Categorisation, Speech and Natural 
Language Conference, New York, USA, pp. 212-217, 1992. 
(Makoto & al., 1995) I. Makoto, T. Takenobu, Cluster-
Based Text Categorization: A Comparison of Category 
Search Strategies, ACM SIGIR’95, Japan, 1995. 
(Maron, 1961) M. Maron, Automatic Indexing: An 
Experimental Inquiry, Journal of the Association for 
Computing Machinery, 8(3): pp. 404 – 417, 1961. 
(Marzin & al., 2004) A. Marzin & al., Classification de 
pages web en genre, Journée d’études ATALA’2004,  
Grenoble, France, Janvier 2004. 
(Mephu, 2002) E. Mephu Nguifo, Treillis de Galois et 
Classification Supervisée, Séminaire LIMOS, Clermont – 
Ferrand, 7 mars 2002.  
(Mitchell, 1997) T. Mitchell, Machine Learning,  
McGraw Hill International editions, Computer Science series, 
ISBN 0-07-042807-7, 1997. 
(Quinlan, 1983) J.R. Quinlan, Learning efficient 
classification procedures and their application to chess and 
games, In R. S. Michalski, J. G. Carbonell and T. M. Mitchell 
editors, Machine Learning: An Artificial Intelligence 
Approach. Vol. 1, pp. 463 – 482, 1983. 
(Quinlan, 1993) J.R. Quinlan, C4.5: Programming for 
machine Learning, Morgan Kaufman, 1993.   
(Rakotomalala, 1997) R. Rakotomalala, Graphes 
d’Induction, Thèse de doctorat de l’université Claude 
Bernard – Lyon I, décembre 1997. 
(Sebastiani, 1999) F. Sebastiani, A tutorial on Automated 
Text Categorisation, Proceeding of ASAI-99, Argentina, 
1999. 
(Sebastiani, 2002) F. Sebastiani, Machine Learning in 
Automated Text Categorisation, ACM Computing Surveys ,  
Pisa, Italy, 2002.   
(Stamatatos & al., 1999) E. Stamatatos & al., Automatic 
Authorship Attribution, In Proc. Of 9th Conf. Of the 
European chapter of the Association for Computational 
Linguistics (EACL’99), pp. 158 – 164, 1999. 
(Vapnik, 1995) V. Vapnik, The Nature of Statistical 
Learning Theory, Springer – Verlag, 1995. 
(Yong-Bae & al., 2004) L. Yong-Bae & al., Automatic 
Identification of Text Genres and Their Roles in Subject-
Based Categorization, In Proceedings of the 37th Hawaii 
International Conference on System Sciences , 2004. 
SETIT2005 
(Zadeh, 1990) L.A. Zadeh, La logique floue et ses 
applications, Editions Addison – Wesley France, SA, ISBN 
2-87908-073-8, 1990. 
(Zighed & al., 1992) D.A. Zighed et al., SIPINA : 
Méthode et logiciel, Editions Alexandre Lacassagne, 
Mathématiques appliquées n°2, 1992. 
 
 
