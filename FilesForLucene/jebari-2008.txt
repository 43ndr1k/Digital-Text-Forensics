 
 Refined and Incremental Centroid-based approach for 
Genre Categorization of Web pages 
Chaker Jebari 
King Saud University 
College of Computer and Information Sciences 
Computer Science Department 
P. O. Box 51178, Riyadh 11543 
Kingdom of Saudi Arabia 
jebarichaker@yahoo.fr
   
ABSTRACT 
In this paper, I propose a refined and incremental centroid-based 
approach for genre categorization of web pages. My approach is 
based on the construction of genre centroids using a set of training 
web pages. These centroids will be used to classify new web 
pages. The originality of my approach is the implementation of 
two new aspects, which are refining and incrementing. My 
approach is based on the combination of three information 
sources, which are the URL address, the logical structure and the 
hypertext structure. Conducted experiments show that the 
proposed approach is very fast and provide micro-average 
accuracy more than 95%, which is better than those obtained by 
other works on genre categorization of web pages and other 
machine learning techniques.   
Categories and Subject Descriptors 
I.2 [Artificial Intelligence]:  Natural Language Processing, 
Learning; H.3 [Information Storage and Retrieval]: 
Information Storage. 
General Terms: Algorithms, Experimentation, 
Measurement, Performance. 
Keywords: Categorization, genre, centroid, refining, 
incrementing, combination. 
1. INTRODUCTION 
In front of the explosive growth of the number of web pages, 
users cannot quickly find desired information among the huge list 
of web pages returned by a search engine. To deal with this 
problem, many recent works have interested with genre 
categorization of web pages [17].  
Generally, the genre reflects the style of the document. Many 
definitions of genre have been proposed, which concerns non-
digital documents. For web pages, the most known definition is 
proposed by Shephered and Watters [20] which characterized the 
genre of web pages, (also called cybergenre) by the triple 
<content, form, functionality>. Content attribute is the topic of 
web page, and the form represents the physical and linguistic 
features of the web page. Functionality attribute is used only for 
web pages and he describes interaction between users and web 
pages.   
Due to the fluidity and the fast-paced evolution of the web, many 
authors studied genre evolution [4, 19, 17].  
Crowston and Williams used a collection of web pages randomly 
selected to study genre evolution [4]. They identified four types 
of genres: reproduced genres, adapted genres, novel genres and 
unclassified web pages. Reproduced genre is often borrowed from 
other media. Adapted genre means the adaptation of a traditional 
genre to the needs and capabilities of a new media. The authors 
report that most web genres are reproduced and adapted. An equal 
number of new genres and unclassified web pages are recorded. 
Shepherd and Watters [19] identified two types of genres: extant 
and novel genres. Extant genres are genres that exist in some 
other medium. Novel genres can be evolved from extant genres or 
they can be completely original.  
Santini combined the genre types obtained in [4] and [19] to 
define a new schema of web genres that contains five types of 
genres: reproduced genres, adapted genres, novel genres, 
spontaneous genres and unclassified web pages [17]. 
To take in account the evolution of web genre over time, I 
propose in this paper a new approach for web page genre 
categorization which based on two new aspects: refining and 
incrementing. Refining means that my approach eliminates noisy 
web pages to construct genre centroids. A noisy web page is a 
web page whose similarity to the centroid of the corresponding 
genre is below some refining threshold value. Incrementing 
consist in classifying web pages one by one. At each web page 
my approach refines current genre centroids. 
This paper is organized as follows: Section 2 presents in 
chronological order recent works on genre categorization of web 
pages; Section 3 describes the principal of centroid-based 
categorization; Section 4 describes the different steps of my 
approach; Section 5 presents conducted experiments and discuss 
obtained results; finally, in section 6, I draw my conclusion and 
outline my future work. 
2. RELATED WORKS       
The feature set and the machine learning technique are two 
factors that distinguish between all studies on genre 
 
Copyright is held by the International World Wide Web Conference 
Committee (IW3C2). Distribution of these papers is limited to classroom 
use, and personal use by others. 
NLPIX 2008, April 21–25, 2008, Beijing, China. 
ACM 978-1-60558-085-2/08/04. 
 
categorization. In this section, I present, in chronological order 
recent works on genre categorization of web pages. 
Meyer Zu Eissen and Stein [14] compiled the KI-041 dataset, 
which contain 1209 web pages distributed over eight genres. They 
used different kinds of features including presentation-related 
features (html tag frequencies), closed word features (names, 
dates, etc.), text statistics (punctuation mark frequencies) and 
syntactic features (part-of-speech frequencies). Using SVM 
technique, they report 70% average classification accuracy. 
Kennedy and Shepherd [10] consider only one genre and its sub-
genres. Using a dataset of 321 web pages and a neural network, 
they attempted to discriminate between home pages from non 
home pages. On a second level, they classify home pages into 
three categories (personal, corporate, and organization). Their 
feature set comprises features about the content (e.g., common 
words, meta tags), form (e.g., number of images), and 
functionality (e.g., number of links, use of Javascript). The best 
reported results were for personal home pages. 
Boese and Howe [1] studied the effects of web page evolution on 
genre classification using KI-04 and WebKB datasets2. They used 
three measurements of change, which are accessibility, last 
modification dates and degree of page similarity. They used 
features including style (e.g., part-of-speech frequencies), form 
(e.g., html tag frequencies) and content (e.g., bag-of-words). 
Using logistic regression technique, they report 79.6% accuracy 
for a new version of WebKB dataset. 
Santini [17] studied web page genre classification based on three 
different feature sets including frequencies of common words, 
part-of-speeches and part-of-speech trigrams, html tags, 
punctuation marks etc. using the KI-04 dataset and the naïve 
bayes technique, she reported 70.2% accuracy.   
Kanaris and Stamatatos [9] used character n-grams extracted from 
both text and structure. Using KI-04 and WebKB datasets and the 
SVM technique, they achieved accuracy between 90% and 95%. 
3. CENTROID-BASED CATEGORIZATION 
Most of machine learning techniques consider each document in 
the training set individually during the training step and consider 
each one every time a new document will be classified. Only, 
SVM technique [21] finds a description for each category to 
distinguish it from other categories. 
Like SVM, centroid-based techniques find a category “prototype” 
that summarizes all documents belonging to the given category, 
which called category centroid. Several models have been 
proposed in the literature to calculate centroids. To identify the 
best model, Cardoso-Cachopo and Oliveira [2] proposed a study 
to compare Rocchio, average, sum and normalized sum models. 
They report that normalized sum model outperform all other 
models. 
Generally, the centroid of a particular category cj is represented 
by a vector Cj, which is a combination of the document vectors di 
belonging (or not) to cj.  
                                                                 
1http://www.itri.brighton.ac.uk/~Marina.Santini/ 
2 http://www.cs.colostate.edu/~boese/Research/Corpora.html 
Using normalized sum model, the centroid Ci is represented by a 
vector, which is the sum of all the vectors of documents belonging 
to the category ci. This is normalized so that it has unitary length. 
Then, the centroid Ci is defined as follow: 
 
 
 
During categorization step, the cosine similarity between each 
new document vector di and each centroid Cj is calculated as 
follow: 
 
 
 
The document is assigned to the category having most similarity. 
Note that, the time and memory required by centroid-based 
models are proportional to the number of categories instead of the 
number of training documents like other machine learning 
techniques, such as Naïve Bayes, K nearest neighbors, decision 
trees, etc. Also, in centroid-based models you can add more 
training documents and easily recalculate centroids [18]. 
4. MY APPROACH 
In this paper, I propose a refined and incremental centroid-based 
approach to classify web pages by genres. My approach is based 
on the combination of three homogenous classifiers, which uses 
three heterogeneous sources of information. These sources are the 
URL, the logical structure (called also internal structure) and the 
hypertext structure (called also external structure). Each classifier 
is based on the generation of genre centroids using a training set 
of web pages. The originality of my approach is the 
implementation of three new aspects: refining, incrementing and 
combination. 
4.1 Representation   
In my approach I performed a pre-processing step to extract the 
features, which are the URL address, the logical structure and the 
hypertext structure. The URL is processed as a one line of text. 
The logical structure is represented by the words  between  <title> 
and </title>, and between <Hn> and </Hn>, where n =1, …, 6. 
The usefulness of this kind of structure is studied in [6]. The 
hypertext structure is represented by the words, which are 
underlined in all hyperlinks contained in the web page. A study of 
the usefulness of different HTML tags is presented in [8]. 
Each feature will be processed to remove special symbols and 
special characters. For example, for the URL feature, the symbols 
‘:’, ‘/’ and ‘.’ are removed because they are founded in all URLs. 
For logical and hypertext structure, I can found some HTML 
characters like ‘&amp;’ or ‘&#38;’. This kind of characters 
should be removed.  
Stop words should be removed to reduce vocabulary size. These 
stop words are automatically identified for each feature using 
frequency threshold technique, which based on Zipf theory [23]. 
In this theory, a word is considered a stop word if its frequency is 
less than a minimum threshold and greater than a maximum 
threshold. The list of stop words depends on each feature. For the 
∑ ∈⋅= ji cd i
j
j dc
1C
( )
ji
ji
ji Cd
Cd
C,dsim
⋅
⋅
=  
 
URL, words that appear more less than twice and more than 5 
times are considered a stop words. For logical and hypertext 
structures, words that appears less than 5 times and more than 10 
times, are considered a stop words.  
The remaining words will be stemmed using the porter stemmer 
[15]. For each term, I calculated its information gain [22]. To 
select terms, I sort all terms by descending values of information 
gain and then select the top n terms, where n is determined 
through an experimental study. 
The selected terms are weighted using the TFIDF technique [16]. 
The TFIDF value increases with the number of times that the term 
occurs in the document and decreases with the number of times 
the term occurs in the collection. This technique favors big 
documents instead of small documents. Recently, Lertnattee and 
Theeramunkong proposed a new approach to ameliorate TFIDF 
term weighting. This approach is based on term distributions 
within a particular class, between classes and within the entire 
collection [13]. In this paper, I have used term distribution 
approach with exponent factors α=0.5, β=-1 and γ=-0.5. 
4.2 Construction of Centroids 
I observed that the training web pages that are far away from its 
genre centroid tend to reduce the performance of categorization. 
My hypothesis is that these kinds of web pages are noisy 
examples and not considered as a useful training examples. So, 
it’s suitable to be excluded during centroid computation.  
In my approach, I first calculate the centroids using all training 
web pages using the normalized sum formula presented in section 
3. Then, I obtain a set of centroids C = {C1, …, Cj, …, Ck}, where 
k is the number of genres. Next, I discarded web pages that have a 
similarity with a centroid less than a predefined threshold s0. For 
each category cj, I calculate a new set of training web pages sj as 
follow: 
 
 
Where pi is a web page and sim is the cosine similarity presented 
in section 3. An experimental study is conducted in the next 
section to discuss the choice of the appropriate refining threshold 
value. 
The sets of training pages obtained after refining, will be used to 
recalculate the centroids using the normalized sum formula as 
follow: 
 
 
 
Finally, the refined centroids are applied to classify new web 
pages. 
Notice, that the complexity of centroids construction is linear in 
the number of training web pages m and the number of predefined 
categories k, hence, learning time is bounded by O(km).  
4.3 Web Page Categorization 
In my approach, the categorization of new web pages is 
performed one by one. For each new web page p, I calculate its 
cosine similarity with all centroids. Then, I refine the centroids, 
which have a similarity with the page p, greater or equal than S0. 
The refining step consists in adding the new page p to the 
normalized centroid of the corresponding genre and renormalizes 
the centroid. For this reason, I maintained with each normalized 
centroid Sj, the non-normalized centroid NSj, so that refining the 
centroid Sj can be performed by the following operations: 
pNSNS jj +=  And then 
j
j
j
NS
NS
S =  
If all similarity values between the new page p and centroids are 
less than the refining threshold S0, then I discard the new web 
page p because it considered as a noisy web page. Note that the 
value of the refining threshold S0 is the same as used to construct 
centroids.  
Classifying a new web page is linear in the number of centroids k 
and the number of new web pages n; hence, running time for 
classification is bounded by O(kn).  
4.4 Combination  
The aim of combining the outputs of several classifiers is to 
achieve a performance better than obtained by each classifier 
individually. Many combining methods were proposed in the 
literature [12].  
In my approach I propose to combine three classifiers. These 
classifiers are based on the same learning algorithm presented in 
the previous section, but they use heterogeneous sources of 
information, which are the URL, the logical structure and the 
hypertext structure. In previous paper, I have used many 
aggregation operators to combine different HTML tags [7]. In this 
paper, I have used decision templates (DT) method [11]. The 
principal of this method is explained below.   
4.4.1 Decision Templates 
Let E = {E1, …,EL} be a set of classifiers. Each of these 
classifiers produces the output Ei(x) = [di1(x), …, dic(x)] where  
dij(x) is the membership degree given by the classifier Ei that x 
belong to the class j. The outputs of all classifiers can be 
represented by a decision profile DP matrix as follow: 
 
   
 
 
Using the training set Z = {Z1, …, ZN}, I compute the fuzzy 
template F of each class i, which represented by a L*c matrix Fi = 
{fi(k, s)}. The element fi(k, s) is calculated as follow: 
 
 
 
 
 
 
( ){ }0jijij SC,psimandcps ≥∈=  
( )
( ) ( )
( )∑
∑
=
=
⋅
= N
1j
j
N
1j
jksj
i
i,ZInd
Zdi,ZInd
s,kf
 
( )
( ) ( )
( ) ( )









=
xd...xd
.........
xd...xd
xDP
Lc1L
c111
 
∑ ∈⋅= ji sp i
j
j ps
1S
 
Where Ind(Zj, i) is an indicator function with value 1 if Zj comes 
from class I and 0 otherwise. 
At this stage, the ranking of classes can be achieved by 
aggregating the columns of DP using fixed rules (minimum, 
maximum, product, average, etc.). Another method calculates a 
soft class label vector with components expressing similarity S 
between the decision template DP and the fuzzy template F. The 
final classification CLV is defined as follows: 
( ) ( ) ( ) ( )[ ]x...,,x...,,xxCLV ci1 µµµ= , Where ( )xiµ  is the 
similarity S(Fi, DP(x)) between the fuzzy template Fi of the class i 
and the decision profile DP(x) of the document x. This similarity 
is calculated using the Euclidean measure as follow:  
( ) ( )( ) ( ) ( )( )∑∑
= =
−−==µ
L
1k
c
1s
2
ksiii xds,kf.c.L
11xDP,FSx  
5. EXPERIMENTS AND RESULTS 
I this section, I presented many experiments to evaluate my 
approach. In the first paragraph I describe the datasets used in my 
experiments. Next, I describe our experimental setup and finally I 
discuss the obtained results. 
5.1 Datasets 
Experiments should be conducted using datasets of HTML web 
pages grouped by genres. To evaluate URL classifier, I should 
know the URL address of the web page. According to these 
conditions, I can use only two datasets, which are KI-04 and 
WebKB3 datasets.  
The KI-04 dataset was built following a palette of eight genres. It 
includes 1205 web pages. These genres were suggested by a user 
study on genre usefulness [14] (see Table 1). 
Table 1. KI-04 dataset 
Genre # Of web pages 
Article 127 
Download 151 
Link collection 205 
Private portrayal 126 
Non private portrayal 163 
Discussion 127 
Help 139 
Shop 167 
 
The WebKB dataset [3] comes from the WebKB project at 
Carnegie Mellon University. It is composed of 8282 web page 
gathered from computer science department web sites of four 
American universities. These web pages are issued from seven 
categories, but I used only six categories (course, department, 
faculty, project, staff and student) as usually done. After 
discarding the category other and empty web pages, I obtained 
only 4249 web page. (see Table 2). 
 
                                                                 
3http://www.cs.cmu.edu/afs/cs.cmu.edu/project/theo-
20/www/data/ 
Table 2. WebKB dataset 
Genre # Of web pages 
Student 1541 
Faculty 1063 
Staff 126 
Department 170 
Project 474 
Course 875 
5.2 Experimental Setup 
In my approach, a web page is assigned to the genre having most 
similarity. The suitable performance measure to this kind of 
classifier is the accuracy [18]. Since, my datasets are unbalanced, 
I used the micro-average accuracy. In my experiments, I used 5*2 
cross-validation methodology, which consists in splitting the 
dataset into two blocs. One bloc is used for training and the other 
for testing. This process is repeated 5 times. For each time, I 
calculated the micro-average accuracy. Then, global accuracy is 
the average accuracy over the 5 times. 
5.3 Results 
To evaluate my approach, I conducted many experiments. The 
aim of these experiments is to measure the effect of vocabulary 
size, refining, incrementing and combination on the global micro-
average accuracy. I proposed also a comparison with other works 
on genre categorization and other machine learning techniques. 
5.3.1 Effect of vocabulary size 
Experiments presented in this paper are conducted using different 
vocabulary’ sizes according to the dataset and the feature used. 
The results are showed in Figure 1. These results are obtained 
when the number of terms is varied between 5 and 3000. 
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
5 10 15 20 25 30 50 10
0
20
0
30
0
50
0
80
0
12
00
16
00
20
00
25
00
30
00
# of  terms
M
ic
ro URL
Logical Struc ture
Hypertex t Struc ture
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
5 10 15 20 25 30 50 10
0
20
0
30
0
50
0
80
0
12
00
16
00
20
00
25
00
30
00
# of  terms
M
ic
ro URL
Logical Struc ture
Hypertext Struc ture
 
Figure 1. Micro-averaged accuracy for each feature and for 
both KI-04 (Left) and WebKB (Right) datasets when the 
number of terms is varied between 5 and 3000 
The curves presented in the Figure 1 show that micro-average 
accuracy depends on the number of terms. I observe that the 
number of terms, which provides better results, is between 30 and 
200. 
5.3.2 Effect of refining 
To measure the effect of refining on genre categorization, I varied 
the refining threshold between 0 and 1 by step of 0.1. Zero value 
means that is no refining. The obtained results for all features and 
datasets are presented in the following figure. 
 
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
Refining Thresholding
M
ic
ro
URL
Logical Structure
Hypertext Structure
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
Refining Threshold
M
ic
ro
URL
Logical Structure
Hypertext Structure
 
Figure 2. Micro-averaged accuracy for each feature and for 
both KI-04 (Left) and WebKB (Right) datasets when the 
refining threshold is varied between 0 and 1 
As illustrate in the Figure 2, the value of refining threshold affects 
the micro-average accuracy of genre categorization. For KI-04 
dataset, I remark that the best results are obtained for the values 
0.4, 0.5 and 0.6 as refining thresholds for respectively the URL, 
the logical and the hypertext structures. For the WebKB dataset, 
the values of refining threshold are less than those of KI-04 
dataset. These values are 0, 0.1 and 0.2 for respectively the URL, 
the logical and the hypertext structures. According to these results 
I notice that in the case of noisy web pages like those contained in 
KI-04 dataset, the refining is very useful. On the other hand, for 
noiseless corpus like WebKB dataset, the refining is useless. So, I 
concluded that refining work very well for noisy datasets and 
affect the global performance of genre categorization.  
5.3.3 Effect of incrementing 
To Measure the effect of incrementing I performed an experiment 
using the best number of terms identified in the first experiment 
and the best refining thresholds identified in the second 
experiment. In this experiment I varied the proportion of testing 
web pages on each feature between 10% and 90% by step of 10%. 
For example, 80% means that I have used 20% of web pages for 
training and the remaining (80%) for testing. The results are 
illustrated in the Figure 3. 
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
10 20 30 40 50 60 70 80 90
% of test w eb pages
M
ic
ro
URL
Logical Structure
Hypertext Structure
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
10 20 30 40 50 60 70 80 90
% of test w eb pages
M
ic
ro
URL
Logical Structure
Hypertext Structure
 
Figure 3. Micro-averaged accuracy for each feature and for 
both KI-04 (Left) and WebKB (Right) datasets when the 
proportion of test web pages is varied between 10% and 90% 
The curves presented in the Figure 3 shows that micro-average 
accuracy depends on the proportion of testing web pages and the 
feature used. According to these curves, I have concluded that 
genre categorization using the KI-04 dataset needs more testing 
web pages that those performed using the WebKB dataset. This 
result is explained according to the number of noisy web pages in 
each corpus as discussed in the previous experiment. Indeed, the 
best proportions of testing web pages for KI-04 dataset are 80%, 
70% and 70 % for respectively the URL, the logical and the 
hypertext structures. For WebKB dataset, the best proportions of 
testing web pages are 30%, 20% and 30 % for respectively the 
URL, the logical and the hypertext structures. 
5.3.4 Effect of combination 
In this experiment I measure the effect of each classifier on the 
final micro-average accuracy. The results of combination are 
presented in the Figure 4. These results show that the combination 
of classifiers using DT technique yields more than 95% of 
accuracy. This result outperforms those obtained using each 
feature separately.  
 
 
 
 
 
 
 
 
 
Figure 4. Micro-averaged accuracy for each classifier and for 
both KI-04 and WebKB datasets 
5.4 Comparison 
In this section, I conducted experiments to compare my approach 
with other known works on genre categorization of web pages and 
with other used machine learning techniques.  
5.4.1 Comparison with other work on genre 
categorization of web pages 
The majority of the previous studies do not provide a reliable 
comparison with other approaches. The main reason for this is 
that, until recently, there were no publicly available and standard 
benchmark corpora for this task. Another reason is that there is 
not agreed sense of web page genres and each study focuses on a 
different set of genres. In this paper, I propose a comparison with 
Meyer Zu Eissen and Stein [14], Kanaris and Stamatatos [9] and 
Santini [17] works. These works are based on KI-04 corpus, 
which is used in my approach. The WebKB corpus is used only 
by Boese and Howe [1]. Notice that these works use accuracy as a 
performance measure. The micro-averaged accuracy for both KI-
04 and WebKB corpora and for each author is presented in Table 
5. According to this table, I remark that my approach outperform 
all other approaches.  Only Kanaris and Stamatatos provide good 
result using KI-04 corpus because they are based on structural 
information as in my approach. 
Table 3. Micro-average accuracy for both KI-04 and WebKB 
and for web page genre categorization 
Author KI-04 WebKB 
[14] 0.70 - 
[1] 0.75 0.80 
[9] 0.84 - 
[17] 0.70 - 
My approach 0.96 0.98 
 
0.7
0.75
0.8
0.85
0.9
0.95
1
URL Logical
Structure
Hypertext
Structure
DT
Combination
M
ic
ro
KI-04 WebKB
 
5.4.2 Comparison with other machine learning 
techniques 
In my experimentation I compare my approach with other 
categorization techniques implemented in the program Rainbow4. 
Among these techniques I have used Rocchio, Naïve bayes (NB), 
K Nearest Neighbors (KNN) with K=30, SVM with Fisher kernel 
and TreeNode because they are widely used in genre 
categorization of documents. Results are presented in Tables 4 
and 5. These results show that my approach outperform all other 
techniques.  
Table 4. KI-04: Micro-average accuracy for each machine 
learning technique and for each feature 
 URL Logical Structure 
 Hypertext 
Structure 
My approach 0.81 0.85 0.83 
SVM 0.79 0.85 0.80 
Rocchio 0.77 0.82 0.82 
NB 0.72 0.80 0.81 
KNN 0.67 0.66 0.80 
TreeNode 0.63 0.62 0.65 
 
Table 5. WebKB: Micro-average accuracy for each machine 
learning technique and for each feature 
 URL Logical Structure 
Hypertext 
Structure 
My approach 0.86 0.87 0.84 
SVM 0.84 0.87 0.81 
Rocchio 0.82 0.86 0.82 
NB 0.81 0.81 0.81 
KNN 0.70 0.74 0.76 
TreeNode 0.62 0.64 0.62 
 
To show that obtained results are really meaningful and not due to 
chance, I used the 5*2 cross-validation t-test [5]. The results are 
illustrated in the following table.  
Table 6. Significance test of the comparison of my approach 
against other machine learning techniques, fore each feature 
and for both KI-04 and WebKB datasets 
KI-04 
 URL Logical Structure 
Hypertext 
Structure 
SVM << ~ << 
ROCCHIO << < << 
NB << << <<< 
KNN << << <<< 
TreeNode <<< <<< <<< 
WebKB 
SVM ~ << ~ 
ROCCHIO << < << 
NB << << <<< 
KNN <<< << <<< 
TreeNode <<< <<< <<< 
 
                                                                 
4 http://www.cs.cmu.edu/~mccallum/bow/rainbow/ 
According to this table, I conclude that SVM approach achieve 
similar results than my approach, especially for WebKB dataset. 
Rocchio provide the nearest results among the other approaches. 
The symbols used in this table are defined as follow:  
• ≈ Indicates no significant differences 
• < Indicates that the row approach achieves a 
significantly lower measurement then our approach with 
0.05 as a significance level  
• << Indicates that the row approach achieves a 
significantly lower measurement then our approach with 
0.01 as a significance level  
• <<< Indicates that the row approach achieves a 
significantly lower measurement then our approach with 
0.005 as a significance level 
5.4.3 Comparing train and test times 
Besides the categorization performance that categorization 
techniques yields, another important aspect to consider when 
comparing classification techniques is the time that they require to 
execute. Time is a very important aspect for comparison, 
especially when you wish to integrate my approach in a search 
engine. Figures 5, 6 and 7 shows a comparison of the time that 
each classification technique needs to execute, in both training 
and classification phases for each dataset and for each feature. 
0
20
40
60
80
100
0 50 100 150
Train
Te
st
Rocchio
NB
KNN
SVM
TreeNode
M y approach
0
20
40
60
80
100
0 50 100 150Train
Te
st
Rocchio
NB
KNN
SV M
TreeNode
M y approach
 
Figure 5. Train and test time spend for URL and both KI-04 
(left) and WebKB (right)  
0
2 0
4 0
6 0
8 0
1 0 0
1 2 0
1 4 0
0 5 0 1 0 0 1 5 0
Tra in
Te
st
R o cchio
N B
KN N
SV M
T r eeN o d e
M y ap p r o ach
0
2 0
4 0
6 0
8 0
1 0 0
1 2 0
0 1 0 0 2 0 0
Train
Te
st
R o cchio
N B
KN N
SV M
T reeN o d e
M y ap p ro ach
 
Figure 6. Train and test time spend for logical structure and 
both KI-04 (left) and WebKB (right) 
0
2 0
4 0
6 0
8 0
1 0 0
1 2 0
1 4 0
0 1 0 0 2 0 0
Tra in
Te
st R o c c hio
N B
KN N
SV M
T r eeN o d e
M y  ap p r o ach
0
20
40
60
80
100
120
140
160
0 100 200
Tra in
Te
st
R o cchio
N B
KN N
SV M
T reeN o d e
M y ap p ro ach
 
Figure 7. Train and test time spend for hypertext structure 
and both KI-04 (left) and WebKB (right) 
 
The X axis represents the time spent during the training phase and 
Y axis represents the time spent during the testing phase, both in 
seconds. By looking at the X and Y axis, I notice that my 
approach is the fastest in both training and testing phases. This 
can be explained by the fact that the time spent is proportional to 
the number of categories instead of the number of training web 
pages as for the other approaches. Among the other approaches, 
Rocchio and Naïve bayes are the fastest. Decision tree is the 
slowest classifier. 
6. CONCLUSION AND FUTURE WORK 
In this paper, I proposed a new approach for genre categorization 
of web pages. My approach uses three new features, namely, the 
URL address, logical and hypertext structures. Moreover, my 
approach implements three new aspects, which not explored in 
previous studies on genre categorization. These aspects are 
refining and incrementing. Also I have conducted many 
experiments to measure the usefulness of each aspect in genre 
categorization. The comparison with other approaches shows that 
my approach is the fastest and outperforms many known 
categorization techniques. In the future, I hope to integrate my 
approach in a web search engine. 
7. REFERENCES 
[1] Boese, E. S., and Howe, A. E. Effect of web document 
evolution on genre classification. Proceedings of the 14th 
ACM International conference on Information and 
knowledge management, pp. 632-639. 2005. 
[2] Cardoso-Cachopo, A., and Oliveira, A. Empirical evaluation 
of centroid-based models for single-label text categorization. 
Technical Report 7/2006, June 2006, INESC-ID. 
[3] Craven, M., DiPasque, D., Freitag, D., McCallum, A., 
Mitchell, T., Nigam, K., and Slattery, S. Learning to extract 
symbolic knowledge from the word wide web. 10th 
conference on artificial intelligence/innovative applications 
of artificial intelligence. 1998. 
[4] Crowstan, K., and Williams, M. Reproduced and Emergent 
Genres of Communication on the World-Wide Web. 30th 
Hawaii International Conference on System Sciences 
(HICSS-30), 1997, Hawaii, USA. 
[5] Dietterich, T .G.  Approximate statistical tests for comparing 
supervised classification learning algorithms. Neural 
Comput. 10(7): 1895-1923. 1998. 
[6] Jebari, C., and Ounalli, H. The usefulness of Logical 
Structure in Flexible Document Categorization.  
International Journal of Information Technology, 2004, vol. 
1, no. 3, pp. 117-121 
[7] Jebari, C. Combining Classifiers for web page genre 
categorization. In "Towards Genre-Enabled Search Engines: 
The Impact of NLP" International Workshop held in 
conjunction with International Conference in Recent 
Advances on Natural Language Processing RANLP07, 
Borovets, Bulgaria. 2007. 
[8] Jebari, C., and Ounelli, H. Genre Categorization of web 
pages, IEEE Computer Society, 2007. ACM Press. 
[9] Kanaris, I., and Stamatatos, E.  Webpage Genre 
Identification Using Variable-length Character n-grams. 
Proceeding of the 19th IEEE Int. Conf. on Tools with 
Artificial Intelligence. 2007. 
[10] Kennedy, A., and Shephered, M. Automatic Identification of 
Home Pages. In Proceeding of the 38th Hawaii International 
Conference on System Sciences, 2005. 
[11] Kuncheva, L.I., Bezdek, J.C., and Duin, R.P.W. Decision 
templates for multiple classifier fusion. Pattern Recognition, 
34 (2), 2001, 299-314. 
[12] Kuncheva, L. I. Combining Pattern Classifiers: Methods and 
Algorithms.  Wiley, 2004. 
[13] Lertnattee, V., and Theeramunkong, T. Effect of term 
distributions on centroid-based text categorization. Journal of 
Information Sciences, 2004, vol. 158, no. 1, p. 89-115. 
[14] Meyer zu Eissen, S., and Stein, B. Genre Classification of 
Web Pages: User Study and Feasibility Analysis. In Biundo 
S., Fruhwirth T. and Palm G. (eds.). KI2004: Advances in 
Artificial Intelligence, Springer. Berlin-Heidelberg-New 
York, pp. 256-269, 2004. 
[15] Porter, M. F. An algorithm for suffix stripping. 1980, 
Program, vol. 14, no. 3, pp. 130–137. 
[16] Salton, G., and Buckley, C. Term-weighting approaches in 
automatic text retrieval. Information processing and 
management, 1988, vol. 24, no. 5, p. 523-523.  
[17] Santini, M. Automatic identification of genre in web pages. 
Ph.D Thesis, University of Brighton, UK, 2007. 
[18] Sebastiani, F. Machine learning in automated text 
categorization. ACM Computing Surveys, 34(1), Pages 1-47, 
2002. 
[19] Shepherd, M., and Watters, C. Evolution of cybergenre. 
Proceedings of the 31nd Hawaiian International Conference 
on System Sciences, Hawaii. 1998. 
[20] Shepherd, M., and Watters, C. The functionality attribute of 
cybergenres. In Proceedings of the 32nd Hawaiian 
International Conference on System Sciences, January 1999, 
Hawaii.  
[21] Vapnik, V. The Nature of Statistical Learning. Springer-
Verlag, 1995. 
[22] Yang, Y., and Pedersen, J. O. A comparative study on 
feature selection in text categorization. In Proceedings of 
International conference on machine learning, 1997, pp. 412-
420. 
[23] Zipf, G. K. Human Behavior and the Principle of Least 
Effort”, 1949, Reading, MA: Addison-Wesley. 
 
