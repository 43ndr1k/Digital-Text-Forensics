Pattern Recognition Letters 42 (2014) 79–84Contents lists available at ScienceDirect
Pattern Recognition Letters
journal homepage: www.elsevier .com/locate /patrecAuthorship analysis based on data compression qhttp://dx.doi.org/10.1016/j.patrec.2014.01.019
0167-8655/ 2014 Elsevier B.V. All rights reserved.
q This paper has been recommended for acceptance by G. Moser.
⇑ Corresponding author. Tel.: +49 8153 28 1496; fax: +49 8153 28 1444.
E-mail address: daniele.cerra@dlr.de (D. Cerra).Daniele Cerra ⇑, Mihai Datcu, Peter Reinartz
German Aerospace Center (DLR), Muenchner str. 20, 82234 Wessling, Germany
a r t i c l e i n f o a b s t r a c tArticle history:
Received 13 May 2013
Available online 6 February 2014
Keywords:
Authorship analysis
Data compression
Similarity measureThis paper proposes to perform authorship analysis using the Fast Compression Distance (FCD), a
similarity measure based on compression with dictionaries directly extracted from the written texts.
The FCD computes a similarity between two documents through an effective binary search on the inter-
section set between the two related dictionaries. In the reported experiments the proposed method is
applied to documents which are heterogeneous in style, written in five different languages and coming
from different historical periods. Results are comparable to the state of the art and outperform traditional
compression-based methods.
 2014 Elsevier B.V. All rights reserved.1. Introduction
The task of automatically recognizing the author of a given text
finds several uses in practical applications, ranging from author-
ship attribution to plagiarism detection, and it is a challenging
one [33]. While the structure of a document can be easily inter-
preted by a machine, the description of the style of each author
is in general subjective, and therefore hard to derive in natural
language; it is even harder to find a description which enables a
machine to automatically tell one author from the other. A litera-
ture review on modern authorship attribution methods, usually
coming from the fields of machine learning and statistical analysis,
is reported in [33,16,21,14,18]. Among these, algorithms based on
similarity measures such as [3,22] are widely employed and
usually assign an anonymous text to the author of the most similar
document in the training data.
During the last decade, compression-based distance measures
have been effectively applied to cluster texts written by different
authors [10] and to perform plagiarism detection [7]. Such univer-
sal similarity measures, of which the most well-known is the
Normalized Compression Distance (NCD), employ general
compressors to estimate the amount of shared information
between two objects. Similar concepts are also used by methods
using runlength histograms to retrieve and classify documents
[13]. Experiments carried out in [27] conclude that NCD-based
methods for authorship analysis outperform state-of-the-art
classification methodologies such as Support Vector Machines. Astudy on larger and more statistically meaningful datasets shows
NCD-methods to be competitive with respect to the state of the
art [12], while [33] reports that compression-based methods are
effective but hard to use in practice as they are very slow.
Indeed the universality of these measures comes at a price, as
the compression algorithm must be run at least n2 times on n
objects to derive a distance matrix, slowing down the analysis.
Furthermore, as these methods are applied to raw data they
cannot be tuned to increase their performance on a given data
type. We propose then to perform these tasks using the Fast
Compression Distance (FCD) recently defined in [6], which
provides superior performances with a reduced computational
complexity with respect to the NCD, and can be tuned according
to the kind of data at hand. In the case of natural texts, only
FCD’s general settings should be adjusted according to the lan-
guage of the dataset, thus keeping the desirable parameter-free
approach typical of NCD. Applications to authorship and plagia-
rism analysis are derived by extracting meaningful dictionaries
directly from the strings representing the data instances and
matching them. The reported experiments show that improve-
ments over traditional compression-based analysis can be
dramatic, and that the FCD could become an important tool of
easy usage for the automated analysis of texts, as satisfactory re-
sults are achieved skipping any parameters setting step. The only
exception is an optional text preprocessing step which only
needs to be set once for documents of a given language, and
does not depend on the specific dataset.
The paper is structured as follows. Section 2 introduces com-
pression-based similarity measures and the FCD, which will be val-
idated in an array of experiments reported in Section 3. We
conclude in Section 4.
80 D. Cerra et al. / Pattern Recognition Letters 42 (2014) 79–842. Fast Compression Distance
Compression-based similarity measures exploit general off-
the-shelf compressors to estimate the amount of information
shared by any two objects. They have been employed for clustering
and classification on diverse data types such as texts and images
[35], with [19] reporting that they outperform general distance
measures. The most widely known and used of such notions is
the Normalized Compression Distance (NCD), defined for any two
objects x and y as:
NCDðx; yÞ ¼ Cðx; yÞ min CðxÞ;CðyÞ
max CðxÞ;CðyÞ ð1Þ
where CðxÞ represents the size of x after being compressed by a
compressor (such as Gzip), and Cðx; yÞ is the size of the compressed
version of x appended to y. If x ¼ y, the NCD is approximately 0, as
the full string y can be described in terms of previous strings found
in x; if x and y share no common information the NCD is 1þ e,
where e is a small quantity (usually e < 0:1) due to imperfections
characterizing real compressors. The idea is that if x and y share
common information they will compress better together than
separately, as the compressor will be able to reuse recurring patterns
found in one of them to more efficiently compress the other. The
generality of NCD allows applying it to diverse datatypes, including
natural texts. Applications to authorship categorization have been
presented by Cilibrasi and Vitányi [10], while plagiarism detection
of students assignments has been succesfully carried out by Chen
et al. [7].
A modified version of NCD based on the extraction of dictionar-
ies has been first defined by Macedonas et al. [24]. The advantages
of using dictionary-based methods have been then studied by Cer-
ra and Datcu [6], in which the authors define a Fast Compression
Distance (FCD), and succesfully apply it to image analysis. The
algorithm can be used for texts analysis as follows.
First of all, all special characters such as punctuation marks are
removed from a string x, which is subsequently tokenized in a set
of words Wx. The sequence of tokens is analysed by the encoding
algorithm of the Lempel–Ziv–Welch (LZW) compressor [36], with
the difference that words rather than characters are taken into ac-
count. The algorithm initializes the dictionary DðxÞ with all the
words Wx. Then the string x is scanned for successively longer se-
quences of words in DðxÞ until a mismatch in DðxÞ takes place; at
this point the code for the longest pattern p in the dictionary is sent
to output, and the new string (p + the last word which caused a
mismatch) is added to DðxÞ. The last input word is then used as
the next starting point: in this way, successively longer sequences
of words are registered in the dictionary and made available for
subsequent encoding, with no repeated entries in DðxÞ. An example
for the encoding of the string ‘‘TO BE OR NOT TO BE OR NOT TO BE
OR WHAT’’ after tokenization is reported in Table 1. It helps to re-
mark that the output of the simulated compression process is notTable 1
LZW encoding of the tokens composing the string ‘‘TO BE OR NOT TO BE OR NOT TO
BE OR WHAT’’. The compressor tries to substitute pattern codes referring to
sequences of words which occurred previously in the text.
Current token Next token Output Added to dictionary
Null TO
TO BE TO TO BE = h1i
BE OR BE BE OR = h2i
OR NOT OR OR NOT = h3i
NOT TO NOT NOT TO = h4i
TO BE OR h1i TO BE OR = h5i
OR NOT TO h3i OR NOT TO = h6i
TO BE OR WHAT h5i TO BE OR WHAT = h7i
WHAT ] WHATof interest for us, as the only thing that will be used is the
dictionary.
The patterns contained in the dictionary DðxÞ are then sorted in
ascending alphabetical order to enable the binary search of each
pattern in time OðlogNÞ, where N is the number of entries in DðxÞ.
The dictionary is finally stored for future use: this procedure may
be carried out offline and has to be performed only once for each
data instance. Whenever a string x is checked against a database
containing n dictionaries, a dictionary DðxÞ is extracted from x as
described and matched against each of the n dictionaries. The
FCD between x and an object y represented by DðyÞ is defined as:
FCDðx; yÞ ¼ jDðxÞj  \ðDðxÞ;DðyÞÞjDðxÞj ð2Þ
where jDðxÞj and jDðyÞj are the sizes of the relative dictionaries, rep-
resented by the number of entries they contain, and \ðDðxÞ;DðyÞÞ is
the number of patterns which are found in both dictionaries. We
have FCDðx; yÞ ¼ 0 iff all patterns in DðxÞ are contained also in
DðyÞ, and FCDðx; yÞ ¼ 1 if no single pattern is shared between the
two objects.
The FCD allows computing a compression-based distance be-
tween two objects in a faster way with respect to NCD (up to
one order of magnitude), as the dictionary for each object must
be extracted only once and computing the intersection between
two dictionaries DðxÞ and DðyÞ is faster than compressing the
concatenation of x appended to y [6]. The FCD is also more accu-
rate, as it overcomes drawbacks such as the limited size of the
lookup tables, which are employed by real compressors for effi-
ciency constraints: this allows exploiting all the patterns contained
in a string. Furthermore, while the NCD is totally data-driven, the
FCD enables a token-based analysis which allows preprocessing
the data, by decomposing the objects into fragments which are
semantically relevant for a given data type or application. This con-
stitutes a great advantage in the case of plain texts, as the direct
analysis of words contained in a document and their concatena-
tions allows focusing on the relevant informational content. In
plain English, this means that the matching of substrings in words
which may have no semantic relation between them (e.g. ‘butter’
and ‘butterfly’) is prevented. Additional improvements can be
made depending on the texts language. For the case of English
texts, the subfix ‘s’ can be removed from each token, while from
documents in Italian it helps to remove the last vowel from each
word: this avoids considering semantically different plurals and
some verbal forms.
A drawback of the proposed method is that it cannot be applied
effectively to very short texts. The algorithm needs to find reoccur-
ring word sequences in order to extract dictionaries of a relevant
size, which are needed in order to find patterns shared with other
dictionaries. Therefore, the compression of the initial part of a
string is not effective: we estimated empirically 1000 tokens or
words to be a reasonable size for learning the model of a document
and to be effective in its compression.3. Experimental results
The FCD as described in the previous section can be effectively
employed in tasks like authorship and plagiarism analysis. We re-
port in this section experiments on five datasets written in English,
Italian, German, Greek, and Spanish.
3.1. The Federalist papers
We consider a dataset of English texts known as Federalist
Papers, a collection of 85 political articles written by Alexander
Hamilton, James Madison and John Jay, published in 1787–88
Fig. 2. Hierarchical clustering of the Federalist dataset, derived by a full distance
matrix obtained on the basis of the FCD distance.
D. Cerra et al. / Pattern Recognition Letters 42 (2014) 79–84 81under the anonymous pseudonym ‘Publius’. This corpus is particu-
larly interesting, as Hamilton and Madison claimed later the
authorship of their texts, but a number of essays (the ones num-
bered 49–58 and 62–63) have been claimed by both of them. This
is a classical dataset employed in the early days of authorship attri-
bution literature, as the candidate authors are well-defined and the
texts are uniform in thematics [33]. Several studies agreed on
assigning the disputed works in their entirety to Madison, while
Papers 18–20 have generally been found to be written jointly by
Hamilton and Madison as Hamilton claimed, even though some
researchers tend to attribute them to Madison alone [16,26,1].
We analyzed a dataset composed of a randomly selected num-
ber of texts of certain attribution by Hamilton and Madison, plus
all the disputed and jointly written essays. Part of a sample dictio-
nary extracted from one of these texts is reported in Fig. 1. We then
computed a distance matrix related to the described dataset
according to the FCD distance, and performed on the matrix a hier-
archical clustering which is by definition unsupervised. A dendro-
gram (binary tree) is heuristically derived to represent the distance
matrix in 2 dimensions through the application of genetic algo-
rithms [8,10]. Results are reported in Fig. 2, and have been ob-
tained using the freely available tool CompLearn available at [9].
Each leaf represents a text, with the documents which behave
more similarly in terms of distances from all the others appearing
as siblings. The evaluation is done by visually inspecting if texts
written by the same authors are correctly clustered in some branch
of the tree, i.e. by checking how well the texts by the two authors
can be isolated by ‘cutting’ the tree at a convenient point. The clus-
tering agrees with the general interpretation of the texts: all the
disputed texts are clearly placed in the section of the tree contain-
ing Madison’s works. Furthermore, the three jointly written works
are clustered together and placed exactly between Hamilton and
Madison’s essays. We compare results with the hierarchical clus-
tering derived from the distance matrix obtained on the basis of
NCD distances (Fig. 3), run with the default blocksort compression
algorithm provided by CompLearn: in this case the misplacements
of the documents is evident, as disputed works are in general clo-
ser to Madison texts but are scattered throughout the tree.Fig. 3. Hierarchical clustering of the Federalist dataset obtained on the basis of the
NCD distance.3.2. The Liber Liber dataset
The rise of interest in compression-based methods is in part due
to the concept of relative entropy as described in [3], which quan-
tifies a distance between two isolated strings relying on informa-
tion theoretical notions. In this work the authors successfully
perform clustering and classification of documents: one of the
considered problems is to automatically recognize the authors of
a collection comprising 90 texts of 11 known Italian authors span-
ning the centuries XIII–XX, available at [28]. Each text x was used
as a query against the rest of the database, its closest object y min-
imizing the relative entropy Dðx; yÞ was retrieved, and x was then
assigned to the author of y. In the following experiment the same
procedure as [3] and a dataset as close as possible have been
adopted, with each text x assigned to the author of the text y whichFig. 1. Subset from a dictionary DðxÞ extracted from aminimizes FCDðx; yÞ. We compare our results with the ones ob-
tained by the Common N-grams (CNG) method proposed by Kešelj
et al. [20] using the most relevant 500, 1000 and 1500 3-grams in
Table 2. The FCD finds the correct author in 97.8% of the cases,
while the best n-grams setting yields an accuracy of 90%. For FCD
only two texts, L’Asino and Discorsi sopra la prima deca di Tito Livio,
both by Niccoló Machiavelli, are incorrectly assigned respectively
to Dante and Guicciardini, but these errors may be justified: the
former is a poem strongly influenced by Dante [4], while the latter
was found similar to a collection of critical notes on the very Dis-
corsi compiled by Guicciardini, who was Machiavelli’s friend [25].
The N-grams-based method also assigns incorrectly Guicciardini’ssample text x belonging to the Federalist dataset.
Table 2
Classification results on the Liber Liber dataset. Each text from the 11 authors is used
to query the database, and it is considered to be written by the author of the most
similar retrieved work. The authors’ full names: Dante Alighieri, Gabriele D’Annunzio,
Grazia Deledda, Antonio Fogazzaro, Francesco Guicciardini, Niccoló Machiavelli,
Alessandro Manzoni, Luigi Pirandello, Emilio Salgari, Italo Svevo, Giovanni Verga. The
CNG method has been tested using the reported amounts of n-grams.
Author Texts FCD CNG-500 CNG-1000 CNG-1500
Dante Alighieri 8 8 6 5 7
D’Annunzio 4 4 4 3 4
Deledda 15 15 15 15 14
Fogazzaro 5 5 4 5 5
Guicciardini 6 6 5 5 5
Machiavelli 12 10 8 10 9
Manzoni 4 4 4 4 4
Pirandello 11 11 5 10 8
Salgari 11 11 10 10 9
Svevo 5 5 4 5 5
Verga 9 9 6 9 8
Total 90 88 71 81 78
Accuracy (%) 100 97.8 78.9 90 86.7
82 D. Cerra et al. / Pattern Recognition Letters 42 (2014) 79–84notes and a Dante’s poem to Machiavelli, among others
misclassifications.
We also compared our results with an array of other compres-
sion-based similarity measures (Table 3): our results outperform
both the Ziv–Merhav distance [29] and the relative entropy as de-
scribed in [3], while the algorithmic Kullback–Leibler divergence
[5] obtains the same results in a considerably higher running time.
Accuracy for the NCD method using an array of linear compressors
ranged from the 93.3% obtained using the bzip2 compressor to the
96.6% obtained with the blocksort compressor. Even though accu-
racies are comparable and the dataset may be small to be statisti-
cally meaningful, another advantage of FCD over NCD is the
decrease in computational complexity. While for NCD it took
202 s to build a distance matrix for the 90 pre-formatted texts
using the zlib compressor (with no appreciable variation when
using other compressors), just 35 s were needed on the same ma-
chine for the FCD: 10 to extract the dictionaries and the rest to
build the full distance matrix.3.3. The PAN benchmark dataset
We tested our algorithm on datasets from the two most recent
PAN [11] competitions, which provide benchmark datasets for
authorship attribution. From PAN 2013 we selected the author
identification task described in [17]. In this task 349 training texts
are provided, divided in 85 problems out of which 30 are in
English, 30 in Greek and 25 in Spanish. For each set of documents
written by a single author it must be determined if a questioned
document was written by the same author or not. Each text is
approximately 1000 words long, which is close to our empirical
estimation of the minimum size for FCD to find relevant patterns
in a data instance (Section 2). For each problem, we consider anTable 3
Accuracy and running time for different compression-based methods applied to the
Liber Liber dataset.
Method Accuracy (%) Running time (sec)
FCD 97.8 35
Relative Entropy 95.4 NA
Ziv–Merhav 95.4 NA
NCD (zlib) 94.4 202
NCD (bzip2) 93.3 198
NCD (blocksort) 96.7 208
Algorithmic KL 97.8 450unknown text to be written by the same author of a given set of
documents if the average FCD distance to the latter is smaller than
the mean distance from all documents of a given language. Com-
pared to the performance of the 18 methods reported in [17], the
FCD finds the correct solution in 72:9% of the cases and yields
the second best results, ranking first for the set of English problems
and fifth for both the Greek and Spanish sets (Table 4), outperform-
ing among others two compression-based and several
n-grams-based methods. It must be stressed that the FCD took
approximately 38 s to process the whole dataset, while the impo-
sters method by Seidman [32], which ranked first in the competi-
tion for all problems excluded the ones in Spanish, took more than
18 h. Furthermore, the latter method requires the setting of a
threshold, while the FCD skips this step. On the other hand, the
contest participants had only a small subset of the available ground
truth to test their algorithms.
We tested FCD also on the largest closed-class classification
problem (task I) from the 2012 PAN competition: open-class prob-
lems were not considered as the simple classification algorithm
adopted does not allow a rejection class. Using a corpus of 14 test
and 28 training texts belonging to 14 different authors, the FCD
(using a simple nearest neighbour classification criterion) assigns
correctly 12 out of 14 documents to their correct authors. Out of
the 25 which took part to the competition, only 4 methods submit-
ted by three groups [31,34,30] outperformed our method (all of
them with 13 documents correctly recognized). As a comparison,
the NCD and trigrams-based CNG (using the most meaningful
1000 trigrams per document, as this setting yields the best results
in Table 2) assigned 2 and 9 documents out of 14 to the correct
author, respectively. The results in Tables 4 and 5 are encouraging,
specially if we consider that the FCD is a general method which is
not specific for the described tasks.3.4. The Guttenberg case
In February 2011, evidence was made public that the former
German minister Karl-Theodor zu Guttenberg had violated the
academic code by copying several passages of his PhD thesis with-
out properly referencing them. This eventually led to Guttenberg
losing his PhD title, resigning from being minister, and being nick-
named Baron Cut-and-Paste, Zu Copyberg and Zu Googleberg by
the German media [2]. Evidence of the plagiarism and a detailed
list of the copied sections and of the different sources used by
the minister is available at [15].
We selected randomly two sets of pages from this controversial
dissertation, with the first containing plagiarism instances, and the
second material originally written by the ex-minister. Then we
performed an unsupervised hierarchical clustering on the distance
matrix derived from FCD distances as described in Section 3.1. First
attempts made by analyzing single pages failed at separating the
original pages in a satisfactory way, as the compressor needs a
reasonable amount of data to be able to correctly identify shared
patterns between the texts. We selected then two-pages longTable 4
Author identification task of the CLEF PAN 2013 dataset. The dataset contains 349
training texts plus 85 test documents of questioned authorship, with problems given
in English, Greek and Spanish. The table reports how the FCD ranks compared to 18
participants to the PAN 2013 contest. The first ranked submission for each problem is
reported as ‘Best PAN’.
Task FCD (%) Best PAN (%) Rank
Overall 72.9 75.3 2
English 83 80 1
Greek 63 83 5
Spanish 72 84 5
Table 5
Classification results on task I of the CLEF PAN 2012 dataset. The dataset contains 28
texts belonging to 14 different authors for training and 14 for testing. The best results
obtained in the PAN 2012 contest are reported as ‘Best’.
Method FCD NCD CNG Best
Correct (out of 14) 12 2 9 13
Fig. 4. Hierarchical clustering of pages extracted from Guttenberg PhD thesis. (For
interpretation of the references to colour in this figure caption, the reader is
referred to the web version of this article.)
D. Cerra et al. / Pattern Recognition Letters 42 (2014) 79–84 83excerpts from the thesis, with the resulting clustering reported in
Fig. 4 showing a good separation of the texts containing plagiarism
instances (in red in the picture). The only confusion comes from
pages starting at 41 with pages starting at 20, in the bottom-left
part of the clustering. This is justified by the fact that page 41 refers
to the works of Loewenstein, who happens to be the same author
from which part of page 20 was plagiarized [23]. Therefore, the
system considers page 20 to be similar to the original style of the
author at page 41.
Even though the described procedure is not able to detect pla-
giarism, it can find excerpts in a text which are similar to a given
one. If instances of plagiarized text can be identified, objects close
to them in the hierarchical clustering will be characterized by a
similar style: therefore, this tool could be helpful in identifying
texts which are most likely to have been copied from similar
sources.4. Conclusions
This paper evaluates the performance of compression-based
similarity measures on authorship and plagiarism analysis on
natural texts. Instead of the well-known Normalized Compression
Distance (NCD), we propose using the dictionary-based Fast
Compression Distance (FCD), which decomposes the texts in sets
of reoccurring combinations of words captured in a dictionary,
which describe the text regularities, and are compared to estimate
the shared information between any two documents. The reported
experiments show the universality and adaptability of these meth-
ods, which can be applied without altering the general workflow to
documents written in English, Italian, Greek, Spanish and German.
The main advantage of the FCD with respect to traditional com-
pression-based methods, apart from the reduced computational
complexity, is that it yields more accurate results. We can justify
this with two remarks: firstly, the FCD should be more robust since
it performs a word-based analysis, focusing exclusively on mean-
ingful patterns which better capture the information contained in
the documents; secondly, the use of a full dictionary allows dis-
carding any limitation that real compressors have concerning thesize of buffers and lookup tables employed, being the size of the
dictionaries bounded only by the number of relevant patterns con-
tained in the objects. At the same time, the data-driven approach
typical of NCD is maintained. This allows keeping an objective,
parameter-free workflow for all the problems considered in the
applications section, in which promising results are presented on
collections of texts in five languages.References
[1] D. Adair, Fame and the Founding Fathers, Liberty Fund, Indianapolis, 1974.
[2] BBC, Germany’s Guttenberg ‘deliberately’ plagiarised, 2011. <http://
www.bbc.co.uk/news/world-europe-13310042>.
[3] D. Benedetto, E. Caglioti, V. Loreto, Language trees and zipping, Phys. Rev. Lett.
88 (4) (2002) 48702.
[4] M. Caesar, Dante, the Critical Heritage, 1314–1870, Routledge, 1989.
[5] D. Cerra, M. Datcu, Algorithmic relative complexity, Entropy 13 (4) (2011)
902–914.
[6] D. Cerra, M. Datcu, A fast compression-based similarity measure with
applications to content-based image retrieval, J. Visual Commun. Image
Represent. 23 (2) (2012) 293–302.
[7] X. Chen, B. Francia, M. Li, B. McKinnon, A. Seker, Shared information and
program plagiarism detection, IEEE Trans. Inf. Theory 50 (7) (2004) 1545–
1551.
[8] R. Cilibrasi, Statistical Inference through Data Compression, Lulu.com Press,
2007.
[9] R. Cilibrasi, A. Cruz, S. de Rooij, M. Keijzer, CompLearn, 2002. <http://
www.complearn.org>
[10] R. Cilibrasi, P.M.B. Vitányi, Clustering by compression, IEEE Trans. Inf. Theory
51 (4) (2005) 1523–1545.
[11] CLEF, PAN Lab 2012 & 2013: Uncovering Plagiarism, Authorship, and Social
Software Misuse, 2013. <http://pan.webis.de>
[12] R. de Graaff, Authorship attribution using compression distances (Master
thesis), Leiden University, 2012. <http://www.liacs.nl/assets/
Bachelorscripties/2012-18RamondeGraaff.pdf>
[13] A. Gordo, F. Perronnin, E. Valveny, Large-scale document image retrieval and
classification with runlength histograms and binary embeddings, Pattern
Recognit. 46 (7) (2013) 1898–1905. <http://www.sciencedirect.com/science/
article/pii/S0031320312005304> .
[14] J. Grieve, Quantitative authorship attribution: an evaluation of techniques,
Literary Ling. Comput. 22 (3) (2013) 251–270. <http://llc.oxfordjournals.org/
cgi/doi/10.1093/llc/fqm020> .
[15] GuttenPlag, Collaborative documentation of plagiarism, 2011. <http://
de.guttenplag.wikia.com>
[16] M.L. Jockers, D.M. Witten, A comparative study of machine learning methods
for authorship attribution, Literary Ling. Comput. 25 (2) (2010) 215–223.
[17] P. Juola, E. Stamatatos, Overview of the Author Identification Task at PAN 2013,
2013. <http://www.clef-initiative.eu/documents/71612/3095ffc3-376b-40eb-
af10-8251c5f107f6>.
[18] P. Juola, Authorship attribution, Found. Trends Inf. Retr. 1 (3) (2006) 233–334.
<http://dx.doi.org/10.1561/1500000005> .
[19] E. Keogh, S. Lonardi, C. Ratanamahatana, Towards parameter-free data mining,
in: Proceedings of the Tenth ACM SIGKDD International Conference on
Knowledge Discovery and Data Mining, ACM, 2004, pp. 206–215.
[20] V. Kešelj, F. Peng, N. Cercone, C. Thomas, N-gram-based author profiles for
authorship attribution, in: Proceedings of the Conference Pacific Association
for Computational Linguistics, PACLING, vol. 3, 2003, pp. 255–264.
[21] M. Koppel, J. Schler, S. Argamon, Computational methods in authorship
attribution, J. Am. Soc. Inf. Sci. Technol. 60 (1) (2009) 9–26. <http://dx.doi.org/
10.1002/asi.v60:1> .
[22] M. Koppel, J. Schler, S. Argamon, Authorship attribution in the wild, Lang.
Resour. Eval. 45 (2011) 83–94, http://dx.doi.org/10.1007/s10579-009-9111-2.
URL <http://dx.doi.org/10.1007/s10579-009-9111-2> .
[23] K. Loewenstein, Verfassungsrecht und verfassungspraxis der vereinigten
staaten, Enzyklopaedie der Rechts-und Staatswissenschaft, 1959.
[24] A. Macedonas, D. Besiris, G. Economou, S. Fotopoulos, Dictionary based color
image retrieval, J. Visual Commun. Image Represent. 19 (7) (2008) 464–470.
[25] N. Machiavelli, J. Atkinson, D. Sices, The Sweetness of Power: Machiavelli’s
Discourses & Guicciardini’s Considerations, Northern Illinois University Press,
2002.
[26] M. Meyerson, Liberty’s blueprint: how Madison and Hamilton wrote The
Federalist Papers, defined the constitution, and made democracy safe for the
world, Basic Books, 2008.
[27] W. Oliveira, E. Justino, L.S. Oliveira, Comparing compression models for
authorship attribution, Forensic Sci. Int. 228 (1–3) (2013) 100–104. <http://
www.sciencedirect.com/science/article/pii/S0379073813000923>.
[28] L.L. Onlus, The Liber Liber Dataset, 2003. <http://www.liberliber.it>
[29] D. Pereira Coutinho, M. Figueiredo, Information theoretic text classification
using the Ziv–Merhav method, Pattern Recognit. Image Anal. 3523 (2005)
355–362.
[30] M. Popescu, C. Grozea, Kernel methods and string kernels for authorship
analysis, in: P. Forner, J. Karlgren, C. Womser-Hacker (Eds.), CLEF, 2012 (Online
84 D. Cerra et al. / Pattern Recognition Letters 42 (2014) 79–84Working Notes/Labs/Workshop). <http://dblp.uni-trier.de/db/conf/clef/
clef2012w.html>
[31] U. Sapkota, T. Solorio, Sub-profiling by linguistic dimensions to solve the
authorship attribution task, in: P. Forner, J. Karlgren, C. Womser-Hacker (Eds.),
CLEF, 2012 (Online Working Notes/Labs/Workshop). <http://dblp.uni-trier.de/
db/conf/clef/clef2012w.html>
[32] U. Seidman, Authorship verification using the impostors method, Notebook for
PAN at CLEF 2013, 2013. <http://www.clef-initiative.eu/documents/71612/
7a4e6a71-46e9-4bb1-ab66-8ea9c42f7416>
[33] E. Stamatatos, A survey of modern authorship attribution methods, J. Am. Soc.
Inf. Sci. 60 (3) (2009) 538–556.[34] L. Tanguy, F. Sajous, B. Calderone, N. Hathout, Authorship attribution: using
rich linguistic features when training data is scarce, in: P. Forner, J. Karlgren, C.
Womser-Hacker (Eds.), CLEF, 2012. (Online Working Notes/Labs/Workshop).
<http://dblp.uni-trier.de/db/conf/clef/clef2012w.html>
[35] T. Watanabe, K. Sugawara, H. Sugihara, A new pattern representation scheme
using data compression, IEEE Trans. Pattern Anal. Mach. Intell. 24 (5) (2002)
579–590.
[36] T. Welch, Technique for high-performance data compression, IEEE Comput. 17
(6) (1984) 8–19.
