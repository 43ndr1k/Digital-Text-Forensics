Abstract
In studies of music performance, rule systems have been
used to model the expressive deviations introduced by musi-
cians. In this work we present a methodology for the esti-
mation of the rule parameters to reproduce a given human
performance as closely as possible. To achieve best fit, a least
square algorithm was used. The estimation can be carried out
on different time scales to improve the fit when the performer
used different expressive strategies during the piece. The
method has been tested on different pieces, recorded both 
in a controlled experiment, and also in ecological settings.
Results confirm this methodology, and allow an objective
comparison of parameter sets already studied in literature.
The model can also be used to compare different rule
systems, both from a numerical point of view, and also by
listening the synthesized performances obtained using the
estimated values.
1. Introduction
The word expressiveness is used, in most studies of music
performance, to indicate a systematic presence of deviations
from the musical notation (Gabrielsson, 1997); these devia-
tions can be viewed as a means of communication between
musician and listener (Juslin, 2001). The analysis of devia-
tions in music performance has led to the formulation of
some models that describe musical structures, with the aim
to understand what the player consciously or unconsciously
adds to the notation of the score. It should be noticed that
under the deviations’ surface there is something deeper and
not directly accessible; however, deviations are quite easy to
measure, and for this reason they are widely used to develop
computational models in scientific research as well as in 
generative models for musical applications.
A large variety of representations of the expressive devi-
ations that musicians apply to the score have been proposed.
They can be grouped according to the approaches that have
been used to generate the models. One of the most relevant
methods is the analysis-by-measurement, which is based on
the analysis of deviations measured in recorded human 
performances. The analysis aims at recognizing regularities
in the deviation patterns and at describing them by means 
of numerical formulas. This approach has been used, for
example, by Todd (1985, 1992, 1995), by De Poli et al.
(1998) and by Clynes (1990). Another approach is to derive
models, which are described with a collection of rules,
through the analysis-by-synthesis method. These rules
describe quantitatively the deviations to be applied to a
musical score, in order to produce a more attractive and
human-like performance than the mechanical one, which is
the result of a literal execution of the score. Each rule tries
to model a musical performance principle used by musicians
in order to predict some of the deviations that human per-
formers are likely to apply. In this approach, first the rules
are obtained on the basis of indications of professional musi-
cians; then, the performances, produced by applying the
rules, are evaluated by listeners, allowing further tuning and
development of the rules. Another way to derive rules is by
learning algorithms such as inductive machine learning
(Widmer, 2000, 2002), neural network techniques (Bresin,
1998), a fuzzy logic approach (Bresin, De Poli, & Ghetta,
1995) or using a multiple regression analysis algorithm
(Ishikawa, Aono, Katayose, & Inokuchi, 2000).
In our work, we focused our attention on rule-based
systems. In musical performances there is a wide range of
expressive nuances which the models have to approximate as
closely as possible. This can be done with a high number of
rules that have to cooperate in some way. There are cases in
Accepted: 2 April, 2003
Correspondence: Patrick Zanon, Dept. of Information Engineering (DEI), Center of Computational Sonology (CSC), University of Padua,
Via Gradenigo 6/a – 35131 PD, Italy. E-mail: patrick@dei.unipd.it 
Estimation of Time-Varying Parameters in Rule Systems for
Music Performance
Patrick Zanon and Giovanni De Poli
Dept. of Information Engineering (DEI), Center of Computational Sonology (CSC), University of Padua, Padua, Italy
Journal of New Music Research 0929-8215/03/3203-295$16.00
2003, Vol. 32, No. 3, pp. 295–315 © Swets & Zeitlinger
D
o
w
n
l
o
a
d
e
d
 
B
y
:
 
[
H
E
A
L
-
L
i
n
k
 
C
o
n
s
o
r
t
i
u
m
]
 
A
t
:
 
1
8
:
0
8
 
1
7
 
A
u
g
u
s
t
 
2
0
0
8
296 Patrick Zanon and Giovanni De Poli
which only one rule is able to explain a rather high number
of variations, see for example (Friberg, 1995). In this case
however, the rule used is complex and have a number of para-
meters that need to be estimated with an ad hoc iterative 
procedure. The most important rule based model is the KTH
rule system (Friberg, 1991). Different rules can be weighted
by the so called k parameters, allowing them to model per-
formances more closely and to adapt the rules to different
situations. Moreover tuning weights could be used to model
some emotional colouring (Bresin & Friberg, 2000).
Weighting parameters are normally estimated by a trial
and error procedure in the analysis-by-synthesis approach.
Friberg, in his work on the Phrase Arch rule (Friberg, 1995),
attempted an automatic estimation of them using an iterative
algorithm able to minimize a custom-made distance measure
between performances; this procedure tries to approximate a
given performance by varying the values of the parameters.
In our previous work (Zanon & De Poli, 2003) we presented
a method for optimal estimation of parameters starting from
a given human performance in order to produce, through the
KTH rule system, a synthetic performance that would be as
similar as possible to the human one. The method uses a 
suitable pre-Hilbert1 space to represent the scores, and then
it exploits the properties of that space to achieve the optimal
estimation in the least-square sense.
However, the performance style or strategy can change
during the piece. Thus, it is interesting to have an estimation
procedure that considers parameters as function of time
(time-varying parameters). In this paper we extend the
method presented in our previous work (Zanon & De Poli,
2003) allowing an optimal estimation of parameters on dif-
ferent temporal scales and thus able to follow their time 
variations.
The paper is organized as follows: in the next section the
background and the general strategy of the static method is
summarized, with particular emphasis on the notion of dis-
tance we used, and some approaches to improve the fit. Then,
we present the extension of the procedure to achieve an esti-
mation of the parameters as function of the time (estimation
of time-varying parameters) and finally, a section is devoted
to experimental results concerning a couple of pieces,
showing how different time scales can be used. At the end of
the paper an appendix briefly describes the KTH rules used
in this work.
2. Static estimation procedure
In this study, the KTH model has been chosen for experi-
ments and tests as implemented in the software Director
Musices (Friberg, Colombo, Frydén, & Sundberg, 2000).
One of its fundamental characteristics is how deviations of
different rules are combined. The rules compute timing and
loudness deviations for each note of the score. Then, the
resulting deviations from the rules are additively combined.
This means that each note may be processed by several rules,
and the deviations computed by each rule will be added suc-
cessively to the parameters of that note according to a weight-
ing factor k. In a more formal way, if the vector rj, which will
be defined more precisely in the following section, represents
the whole set of deviations to each note introduced by the 
j-th rule, then all the rules apply deviations dr to a reference
performance in an additive way:
(1)
where m is the number of used rules and kj is a parameter
that acts as weighting factor of the j-th rule. This represen-
tation is a simplification of the real model; in fact there are
some rules with more parameters than only kj. The estima-
tion of these auxiliary parameters has to be considered in a
different way, particularly those having a non-linear nature.
These latter parameters will be called non-linear parameters.
The details will be not described here; they can be found in
our previous work (Zanon & De Poli, 2003). From now on,
we will refer to models that obey the constraint (1) without
loss of generality.
We want to estimate the parameters kj ( j = 1 . . . m) in
order to fit the deviations of a given human performance dh,
minimizing a suitable distance between dh and dr (that will
be described in a formal way in the next section):
(2)
The mathematical formalization of the distance used in (2)
should, on one hand, take into account, as much as possible,
how a listener perceives sounds and judges deviations: on the
other hand it should have the mathematical properties which
allow the minimization problem of equation (2) to be solved
easily.
As indicated in Figure 1, the KTH model was used in two
different steps of the estimation procedure: in the former with
the aim of preparing a description of the model itself, which
is used in the estimation, and in the latter in order to syn-
thesize the artificial performance according to the found
values. More precisely, the procedure usually starts from the
score, whose mechanic or deadpan interpretation is called the
nominal performance. Other solutions are possible, and will
be investigated in the section devoted to results. Using the
model, we generate a set of synthetic performances, each of
which is based on only one rule weighted by the relative kj
min min .
, . . . , , . . . ,k
m h r
k
m h j j
j
m
km km
k
1 1 1
( )Œ ( )Œ =
- = - Â
 
d d d r
d rr j j
j
m
k=
=
Â
1
1 A pre-Hilbert space is a linear space equipped with an inner
product. A complete pre-Hilbert space is a Hilbert space. In a
Hilbert or pre-Hilbert space, the inner product induces a norm and
the concept of orthogonal projection, which is largely used in many
approximation problems. For example, the least square minimiza-
tion problem is a special case that can be mathematically formalized
in a pre-Hilbert space. The advantage of using such formalization
relies in the direct expression of the best approximation in norm
without need of iterative methods like in the non-linear cases. More-
over, the method remains open to possible extensions that could not
be modeled with the least square problem approach.
D
o
w
n
l
o
a
d
e
d
 
B
y
:
 
[
H
E
A
L
-
L
i
n
k
 
C
o
n
s
o
r
t
i
u
m
]
 
A
t
:
 
1
8
:
0
8
 
1
7
 
A
u
g
u
s
t
 
2
0
0
8
Rule systems for music performance 297
parameter fixed to one. This whole set of these synthetic 
performances is called the set of rule performances. The 
rule performances provide the model description, and are
compared to a sample performance that can be human or 
synthetic. Next sections will mathematically describe this
comparison, which allows the estimation of the rule para-
meters satisfying (2): the parameters are used to generate the
final synthetic performance, which is the best approximation
of the human one. In conclusion, it is possible to relate the
final synthetic (expressive) performance to the sample inter-
pretation and to find differences that may suggest new rules
or corrections of the model (especially if the differences also
occur in comparisons with other human performances).
2.1. The deviation space
The estimation problem (2) was solved exploiting the linear
nature of the equation (1) which expresses the property of
additivity of the rule system. By representing performances
with suitable vectors and formalizing the distance between
them with a special kind of the Euclidean norm, it is possi-
ble to exploit the results of Hilbert space theory, and in par-
ticular the projection theorem, which is in our case the best
approximation in the least-square sense.
Each performance of n notes is represented by a vector of
deviations from a given reference performance. The vector
lies in a space D of dimension q = 3n - 1, and its elements
are: n intensity deviations (Loudness deviations DLi), n dura-
tion deviations (DDi) and n - 1 time intervals deviations
between notes (Inter Onset Intervals or IOI deviations DIi,
where Ii = Oi+1 - Oi and Oi is the onset time of the i-th note).
Notice that In and DIn are not defined.
With these notations, a performance is represented (in
boldface) by the column vector
where [◊]T indicates vector transposition. This allows us to
define in a formal way the deviation space D = {d :d Œ q}.
In the same way the j-th rule is represented by a q-
dimensional vector rj whose components are the deviations
that the j-th rule applies to the given reference performance
when its weighting factor kj = 1.
These definitions clarify the symbols used in (1). This
relation allows defining a vector subspace R of dimension m
obtained by varying the parameters kj:
This subspace of D represents the whole set of possible devi-
ations the model is able to generate and its base R (q ¥ m)
is defined with:
2.2. The norm and the optimal parameters
In order to solve the problem (2) we have to define a suitable
norm to evaluate the distance among performances. In our
case deviations are composed by loudness deviations and
timing deviations that should be combined to produce a
unique measure. Moreover, it is advisable that the norm takes
R = [ ]r r1 . . . .m
R R= = ŒÏÌ
Ó
¸
˝
˛=
Âd d k r kr r j j j
j
m
: , .
1
d = [ ]-D D D D D DL L D D I In n n
T
1 1 1 1. . . . . . . . .
 
˙
˙
˙
˙
˚
˘
Í
Í
Í
Í
Î
È
=
nk
k
k
...
2
1
k
1 0 ... 0
0 1 ... 0
... ... ... ...
0 0 ... 1
È ˘
Í ˙
Í ˙=
Í ˙
Í ˙
Î ˚
I
 
KTH Rule 
System 
 
 
Estimation 
Reference Performance (Score) 
Rule 
Performances 
Synthetic 
Performance 
Error 
Sample 
Performance 
+ 
Evaluation 
Rule 
Parameters 
 
KTH Rule 
System 
- 
 
Fig. 1. Methodology for parameter estimation to fit a sample per-
formance using the KTH rule system. The procedure starts from 
a reference performance (usually a nominal performance) of the
score. By use of KTH rule-system, a set of synthetic rule perfor-
mances, in each of which only one rule is applied with a unitary kj
parameter, is generated. These performances are compared to a
human one, called a sample performance. The comparison allows
the optimal estimation of the rule parameters. These parameters are
used to generate the final synthetic performance that is the best
approximation of the human one. Finally, it is possible to evaluate
the result by comparing the final synthetic performance and the
sample interpretation. This provides feedback (dashed line) to the
author of the rule system in order to improve it with corrections or
new rules.
D
o
w
n
l
o
a
d
e
d
 
B
y
:
 
[
H
E
A
L
-
L
i
n
k
 
C
o
n
s
o
r
t
i
u
m
]
 
A
t
:
 
1
8
:
0
8
 
1
7
 
A
u
g
u
s
t
 
2
0
0
8
298 Patrick Zanon and Giovanni De Poli
into account characteristics of human perception. It is known
(Repp, 1992b) that perception and appreciation of expressive
deviations is context sensitive, and it depends on the location
of the events in the musical structure. Thus, we defined a
general form of the Euclidean norm
(3)
where wLi, wDi and wIi are the weights for each i-th note,
depending on the score and on psycho-acoustic principles.
Thus, the solution of the problem of minimization (2)
can be found as in a classic least square problem using the
QR decomposition after a suitable coordinate normalization
(Björck, 1996), obtaining the set of optimal parameters 
k1, . . . , km. This corresponds to an orthogonal projection into
a suitable pre-Hilbert space. The details are presented else-
where (Zanon & De Poli, 2003), in which a geometrical inter-
pretation of the deviation space is also presented (see Fig. 2).
Moreover, it is possible to measure how much the model
is able to fit the human performance by comparing the norm
of the human deviation to the norm of the synthetic ones,
defining the efficiency coefficient as
The closer its value is to 1, the better is the fit according to
the norm we just defined.
2.3. Estimation of tempo and of intensity
In a real artistic performance, the musician can change the
tempo in different parts of the piece, sometimes adding an
x = -
-
1
d d
d
h r
h
.
min min
, . . . , , . . . ,k
m h r
k
m h j j
j
m
km km
k
1 1 1
( )Œ ( )Œ =
- = - Â
 
d d d r
d = ( ) + ( ) + ( )
= =
-
=
Â ÂÂ w L w D w LLi i Di i
i
n
Ii i
i
n
i
n
D D D2 2
1
2
1
1
1
accelerando and sometimes adding a rallentando, according
to his (or her) expressive strategy; similar considerations
hold for the intensity. When we make an estimation of time
varying parameters, a short fragment of the piece is used. It
is likely that the tempo and the mean intensity in this frag-
ment would be different from the overall tempo and intensity
of the entire piece. Thus, it is advisable to have a fine esti-
mation of tempo and intensity for each fragment. Moreover
this estimation can be useful to detect long term expressive
variations.
In addition, if the tempo is not taken into account an arti-
fact can result from the estimation of some rules. More pre-
cisely, the procedure can detect the presence of a rule even
if it is not used in the sample performance. For example, let
us consider a sample performance obtained from the nominal
one by changing only the tempo, say, by using a faster tempo.
Let us consider the Duration Contrast rule also. When k = 1,
the rule introduces only negative deviations to the nominal
durations, resulting in an overall acceleration of the piece.
For this reason, if the estimation is made with the Duration
Contrast rule on the accelerated nominal performance, then
we would obtain a value for k different from zero, even if
there is not a real presence of the rule in the sample perfor-
mance. In this case, the side effect of the rule is to introduce
a change in the tempo, or, in other words, the average of its
timing deviations is different from 0. Then, the “estimation
problem” arises when the procedure tries to fit the sample
performance using all available rules. In this case, the 
Duration Contrast rule would be “improperly” used to speed
up the piece. The same artifact shows in the case of the 
intensity as well.
It would be possible to normalize the tempo and the inten-
sity to the duration and average intensity of each fragment.
However, this alignment can be problematic when estimating
the weights of the KTH rules that have the deviations’
average different from 0. Thus, we extended our estimation
procedure in order to have an optimal estimation of tempo
and intensity scales, jointly with the rule parameters. This
means that the amount of deviations induced by the tuning
of tempo and intensity scales can be estimated together with
the estimation of the other parameters. The geometric inter-
pretation consists in augmenting the dimensions of the rule
subspace R by adding two vectors representing the axis
along which a nominal derived synthetic performance can
change tempo and intensity. Each performance rule corre-
sponds to a vector in the rule space R , so we will refer to
these two additional vectors as special rules modifying
overall tempo and overall intensity similarly to (Bresin &
Friberg, 2000). Formally, the rules are represented with two
q-dimensional vectors:
where, in the rule rT, the symbols Di and Ii are the nominal
values of duration and interonset interval IOI, and in the rule
r
r
T n n
T
L
T
D D I I= [ ]
= [ ]
-0 0
1 1 0 0 0 0
1 1 1. . . . . . . . .
. . . . . . . . .
The Space D  
The Subspace R  
hd
rd
he
1r
2r
O 
Fig. 2. Best approximation obtained by orthogonal projection of
the human performance ph on the subspace R spanned by the rule
system. This space represents the whole set of possible perfor-
mances that the model is able to generate. For simplicity, only two
rules r1 and r2 are used, resulting in a two dimensional R space. The
vector eh is orthogonal to R and represents the error in the approx-
imation after the projection, dh represents the deviations of the
human performance, and dr represents the deviations computed by
the optimal estimation.
D
o
w
n
l
o
a
d
e
d
 
B
y
:
 
[
H
E
A
L
-
L
i
n
k
 
C
o
n
s
o
r
t
i
u
m
]
 
A
t
:
 
1
8
:
0
8
 
1
7
 
A
u
g
u
s
t
 
2
0
0
8
Rule systems for music performance 299
rL, the first n components are set to 1 and the remaining to
0. The first rule rT introduces deviations only for the timing
components: if its relative weighting parameter kT is equal to
1, then all the durations of the synthetic performance will be
doubled. The second rule rL introduces deviations only for
loudness components; if its relative weighting parameter 
kL = 1, then all intensities will be increased by 1dB. It is
important to underline that kT and kL, after the estimation,
indicate how much the human performance is slower and
louder than the reference performance in the least-square
sense only if no other rule has been employed. For example,
we can use a nominal performance played at 105bpm and at
80dB; if the human performance that we want to analyze was
played at constant 100bpm and at constant 82dB, then the
estimation of the parameters using only the rules rT and rL
produces these results: kT = 105/100 - 1 = 0.05 and kL = 2.
It should be noticed that with the rT and rL rules, we can
obtain a fit of the tempo and the intensity in a weighted least-
square sense. This means that it is not the same as doing the
average of the timing values and comparing it with the
nominal one, because of two reasons: in general durations,
IOIs and intensities have different weights, and the weights
can be different from note to note, since the norm was
requested to be flexible and extensible. Moreover, the values
of the kT and kL parameters describe how much the given
sample performance deviates from the nominal one. In this
sense, they contain information that is related to the nominal
performance we chose. However, it is possible reconstruct
the tempo of the sample performance form the estimated
parameter and the nominal value (even if arbitrarily defined)
using the following formula:
(4)
where TS, TN are the sample and nominal tempos respectively.
In fact, if we would choose another value for the tempo TN
in the nominal performance, then we would obtain from the
estimation a different value of the kT parameter, but the esti-
mated tempo TS would be unaffected. For the validity of the
previous formula, the nominal value is required to be con-
stant in the scope of application of the formula itself. The
same reasoning can not be applied to the sound level, since
there can be different biases in the recording level. Unless
the nominal and the sample performance were derived from
the same recording session with the same recording level, the
estimated mean intensity would be meaningless. However, it
is always possible to compare different sample performances
using an arbitrarily nominal intensity as reference, provided
the sample performances are recorded with the same bias 
for the loudness. This happens for example, when we com-
pare the mean values of the intensity for different phrases of
the same recording.
An observation on the calculation of TS has to be made:
the estimated kT parameter is related to the timing informa-
tion of the nominal performance. More precisely, it is related
to the nominal durations and IOIs, since this is the informa-
tion present in the rT rule. In the nominal performance, the
T T ks N T= +( )1
ratio between durations and IOIs (also called legato degree)
can be different from the same ratio in the sample perfor-
mance. Thus, a change in the legato degree of the sample per-
formance can be reflected in the kT value; more precisely, if
the sample performance is played more staccato than the
nominal, then the estimated kT value will be lower and TS will
be higher than the real value consequently. This is a side
effect due to the presence of both durations and IOIs in the
rT rule. In order to overcome this problem, it is possible to
reduce the weights of all durations (wDi), so that the fitting of
the rT rule will be made taking into account the IOIs only.
However, this can be made if we want to estimate the tempo
only. If we use other rules we cannot neglect the durations,
because it would lead to wrong estimations of the parame-
ters for those rules that change the legato degree (for
example, the Articulation rules, see Appendix).
When the estimation is made using all the rules, we can
not use the values of kT and kL, because some rules have the
above mentioned side effect: they introduce deviations which
change the average tempo and loudness; for this reason the
estimation can produce different values for kT and kL because
the method tries to compensate for this side effect, in order
to obtain a better fitting of the human performance. This 
situation can be expressed in terms of non-orthogonality
between rT (or rL) and all the other rules. Notice that rT and
rL are orthogonal because the non-zero components are 
different in the two rules. Thus, two phases are suggested: 1)
estimation of the average tempo and intensity (kT and kL),
with low weights for the durations, using the rT and rL rules
only: this gives an insight of the long term behavior of 
the performer; 2) estimation of all the kj parameters using all
the rules rj together with rT and rL with equal values of the
weights for the durations and IOIs.
2.4. Context dependent weights
The psycho-acoustic characteristic of human ear and the 
perception of the musical structure are two key points to 
be taken into account in order to make a distance between
performances significant. These are the main reasons why we
introduced a number of weights into it.
The former point lead us to consider the problem of
finding a good compromise when considering different kinds
of contributions into the norm, like time and intensity. There
is clearly a trade off: if we consider only the timing infor-
mation, then we loose the opportunity to fit the loudness
level, and vice versa. How to balance these two contribu-
tions? We weighted the different kind of components on the
base of their JNDs (Zanon & De Poli, 2003): this means that
a timing deviation will be considered of the same importance
of a intensity deviation if their values are equal to their
respective JNDs.
The latter point deals with the context perception, and
interacts with the former point. Many studies of this aspect
have been carried out: the musical structure of the piece
makes some notes particularly important for listeners, and a
D
o
w
n
l
o
a
d
e
d
 
B
y
:
 
[
H
E
A
L
-
L
i
n
k
 
C
o
n
s
o
r
t
i
u
m
]
 
A
t
:
 
1
8
:
0
8
 
1
7
 
A
u
g
u
s
t
 
2
0
0
8
300 Patrick Zanon and Giovanni De Poli
non accurate fit for these notes can compromise the synthe-
sis. In fact, the estimation procedure can produce non-
musical results, because taking into account only the JNDs
leads to a simplified model of human perception. Moreover,
even if we are able to take into account the structural context,
in general, it is difficult to assign the correct weights for each
kind of piece. Thus, it would be advisable to supervise the
estimation by knowing which of the estimation weights of
the expression (3) has to be changed. In this sub-section 
we provide some guidelines to allow this tuning of the 
procedure.
For the above-mentioned reasons, a listening is needed,
after the estimation of the synthetic performance, to check if
the output is musically acceptable. This listening, together
with the analysis of the error vector eh, can reveal if and
where the procedure is not able to fit the human performance:
it is possible to isolate the notes and their parameters, which
deviate too much from the human performance. Thus, we can
increase the weights of these parameters, forcing the rule
system to fit more closely the human performance at specific
points. Then, a new estimation and a new listening can
provide feedback to evaluate the synthesis, and eventually, 
to change other weights. It is possible that the rule system 
is not able to correct the problem if there is no rule, which
can act on the critical notes, or if the rules correct the values
to the detriment of other “sensible” notes. In these cases a
new rule may have to be considered, especially if the problem
repeats for different human performances.
3. Time varying estimation
Due to the complexity of the musical expression, the KTH
rule system was designed to introduce limited deviations in
few controlled parameters and in a restricted set of notes, in
order to not compromise the musical acceptability of the syn-
thesis. This fact is related to the genesis of the rule system
itself, which was developed using as feedback the esthetical
preferences by the musician Lars Frydén who was very sen-
sitive to small variations. Also, it is difficult to design a rule
that produces large deviations and still sounds musical, espe-
cially when interacting with many other rules. The introduc-
tion of rules with wider scopes, such as the Phrase Arch rule,
allowed the authors to make rules that introduce large devi-
ations that can be clearly noticed. The result is that one can
synthesize performances according to the musical practice,
in which different characterizations can be obtained with
small variations of the k parameters.
A synthetic performance with constant k parameters can
sound musically acceptable, but, if we analyze a real artistic
music performance, we can expect long-term variations of
expressiveness, which have to be reflected in variable k para-
meters. In fact, a pianist can use different expressive strate-
gies during the piece according to his interpretation of the
score, so it is possible that different phrases, or different parts
of a performance, can be rendered with slightly different
musical styles. Moreover, the deviations from the score can
be large in amplitude, as an artistic interpretation requires.
Thus, a static estimation on the whole piece may produce
parameters, which are a numerical optimum (with possible
over-fitting problems), but the fit may be inaccurate. In other
words, a static estimation tries to make a compromise among
the different kinds of deviations that the musician introduces
during the performance. These different kinds of deviations
could be obtained using very different settings for the rules,
but if we have to choose only one, then the numerical
optimum will be selected in order to minimize the error.
Thus, this optimum may not be a “good average” in a musical
sense: it can be affected by the variations of the underlying
expressiveness, so if the estimated values are used to syn-
thesize a performance one can obtain non-musical results.
For the above-mentioned reasons, we experimented with
a time varying approach, and we compared it with the static
results. The estimation procedure was extended, allowing
both a phrase-based estimation and also an estimation of
time-varying parameters as function of time; in the latter case
a user-definable sliding window of notes was used. The
window corresponds to a segment of the performance 
containing a certain number of notes, let’s say n. The i-th
segment starts from the i-th note of the entire piece and lasts
to the (i + n - 1)-th note. The estimation procedure is
repeated for each i-th segment, producing a set of k para-
meters relative to that segment. Their values are variable
from segment to segment, and can be interpreted as a time-
varying representation of performance strategy. The window
size can be constant in number of notes, or in duration. The
former approach behaves better from a numerical point of
view: in fact the dimension of the rule space is more likely
to remain constant. Typical values are around 20 notes.
Shorter windows trigger few rules and present over-fitting
problems: the estimated parameters become unstable. Longer
windows smooth the profiles too much. Choosing phrase-
based windows leads to the same problems, due to the vari-
able length of the phrases. Moreover, it can happen that the
phrase length is unknown. Stamatatos (2001) used similar
values of the window size for performer recognition, and he
found that segments of equal lengths measured in terms of
note number provide better training examples in comparison
to phrase based segments. Detailed profiles are obtained con-
sidering every segment (hop size equal to 1). It is also pos-
sible to use windows with hop size greater than 1, including
non-overlapping ones.
In this way the estimations have a local meaning and so it
is possible to see if parameters change over time. For this local
behavior, attention should be paid to the rules, which have to
be included for the estimation: many of them have a global
scope (e.g., the Phrase Arch rule at the higher levels) and, for
this reason, have to be excluded from the sliding window esti-
mation in order to avoid artifacts in the estimation. However,
the phrasing is an important cue for the analysis of musical
performances, and we do not want to lose this information:
in this case rules rT and rL can help us. In fact, if these rules
D
o
w
n
l
o
a
d
e
d
 
B
y
:
 
[
H
E
A
L
-
L
i
n
k
 
C
o
n
s
o
r
t
i
u
m
]
 
A
t
:
 
1
8
:
0
8
 
1
7
 
A
u
g
u
s
t
 
2
0
0
8
Rule systems for music performance 301
are used alone in the estimation, they can reveal, through the
profiles of their parameters, the long-term phrasing, both at
timing and at intensity surfaces: these profiles correspond to
the effect of the Phrase Arch rule at the highest level. It is pos-
sible to compare the shape of the high level phrasing deduced
by this method with the shape computed by the parabolic
profile implemented in the Phrase Arch rule. The comparison
can give hints on different functions used within rule imple-
mentations for phrasing. Notice that, if the estimation of the
rT and rL parameters is done jointly with the other rules, their
parameter profiles cannot be used for the phrasing analysis
and interpretation, because in this case rT and rL tend also 
to compensate for the bias introduced by almost all the rules
(see the previous sub-section, devoted to estimation to mean
tempo and loudness). For this reason, a two-phase estimation
is advisable: in the first one the evaluation is carried out using
only the rT and rL rules with reduced weights for the durations
in order to extract the long term phrasing information. In the
second, all the rules are used jointly with rT and rL (with equal
values for the duration weights and IOIs ones) to get the 
profiles of the rule parameters; in the latter case the inter-
pretation of the phrasing information, through the kT and kL
profiles, is “blurred.”
Another interesting topic is the over-fitting problem which
can be detected in two ways: the former is to make a corre-
lation matrix of the resulting deviations for each rule and to
check if the correlation index is greater than a certain thresh-
old. This approach was not used because it fails to take into
account the weights that we used for different kind of con-
tributions (timing and intensity). To do so, we previously
used the “angles” derived directly from the definition of the
inner product that leads to the definition of the norm (Zanon
& De Poli, 2003). In this way, all the weights that we used
in the norm are taken into account. Thus, if angles between
rules are small, then it means that rules apply deviations in
a similar way, and probably can lead to over-fitting. If angles
are close to 90 deg, then the deviations applied by the rules
are almost uncorrelated (for details see Zanon & De Poli,
2003). The latter method, which was used in this paper, is to
detect over-fitting by looking at the k parameter trends. In
fact, when many rules introduce almost the same deviations
for a particular score, the respective parameter profiles look
similar between them with a high probability: this is a strong
indication of an estimation affected by over-fitting. The
reason lies in the high values of the parameters that over-
fitting produces: in this case, the effect of an over-fitted rule
has to be canceled by the effect of an other over-fitted one,
resulting in a common (or opposite) shape of the respective
parameters.
On the other hand, these similarities in the profiles can be
useful in performance analysis to reveal interdependencies
among rules. This insight provides the opportunity to reduce
the dimensionality of the rule sub-space. This is particularly
useful when the computational cost is critical, as in real-time
applications like the synthesis of expressive performances, in
which all the parameters are changing over time. The reduc-
tion of dimensionality of the sub-space R can be obtained 
by excluding one or more rules in a set of interdependent
ones, avoiding possible over-fitting problems, or devising
meta-rules as a weighted combination of the effect of a set
of related rules (Bresin & Friberg, 2000).
Finally, in some part of the piece the rules may produce
no deviations due to the reduction of the amount of notes
involved in estimation using the sliding window procedure.
Thus, the estimation algorithm must temporarily exclude
such rules to avoid null vectors in the matrix R, whose rank
has to be always maximum. As a consequence of these exclu-
sions, the rule palette changes over time and in some points
the corresponding k parameter can not be evaluated. If one
desires a continuous trend in the profiles, then one can fill
the holes by interpolation.
4. Results
The method has been employed with different musical pieces,
each of which was performed by a pianist several times. As an
example, we present the results obtained with two pieces: the
“Sonatina in G major” by Ludwig van Beethoven and the
Adagio of the “Piano Sonata in F major” K.332 by Wolfgang
Amadeus Mozart. The former piece is part of the “Themati-
cal catalogue list (incipit) of the questionable and false works”
in the Urtext edition of the Beethoven “Klavierstücke” pub-
lished by G. Henle Verlag, 1975, where it is indicated with
“Anh. 5”. The score used for the latter was part of the Urtext
edition of the “Klaviersonaten, Band II” published by G.
Henle Verlag, 1977.
The software Director Musices version 2.2.1 was used 
for the generation of both the rule performances, and the syn-
thetic performances using the estimated values.
In the next sections a detailed description of the analysis
is presented. However, some terms need first to be clarified.
As we stated in the introduction, the musician can convey his
interpretation of a piece to the listener through the musical
performance. The analysis of this communication requires
defining a taxonomy so as to describe different kinds of 
interpretations. In the studies of music performances Juslin
(2001) introduced the concepts of “basic emotions”, which
is largely used in psychology. In several studies on music per-
formance carried out at CSC, a set of sensorial adjectives was
used to indicate to the performer how to play a given excerpt
(see Canazza et al., 1997; De Poli et al., 1998; Canazza 
et al., 2003). In order to generalize the terminology, it 
was found that the term “expressive intentions” could be used
in both the previous cases. In fact, in this study some basic
emotions were used together with some other affective adjec-
tives: Angry, Disgust, Fear, Happiness, Sadness, Indifferent
and Natural. Thus, in the following paragraphs, with “expres-
sive intention” we intend the performer’s attitude, with which
he or she faces the interpretation of a piece.
The selection of the pieces has been made according two
complementary strategies: the former piece was recorded in
a controlled experiment, in which the pianist was asked to
D
o
w
n
l
o
a
d
e
d
 
B
y
:
 
[
H
E
A
L
-
L
i
n
k
 
C
o
n
s
o
r
t
i
u
m
]
 
A
t
:
 
1
8
:
0
8
 
1
7
 
A
u
g
u
s
t
 
2
0
0
8
302 Patrick Zanon and Giovanni De Poli
play according to different “expressive intentions.” Thus, it
was possible to compare the results with those published in
the literature on the same topic. Conversely, the latter piece
is an excerpt of a real performance recorded in ecological
settings, which is part of a commercial audio CD. The piece
was used in an international symposium on the KTH rule
system as a common platform for the comparison of several
studies. The choice of performances may seem divergent. On
the other hand, in this way it was possible to validate the
method of estimation using both recordings made in a con-
trolled environment, where expressive intentions were known
and decided a priori, and also a real performance, in which
a professional pianist played in ecological settings without
any external constraint on the interpretation.
5. Example 1: Sonatina in G major
The first 24 measures of the melody were played without
repeats, for a total of 150 notes, divided in three main
phrases, from the 1st to the 48th note, from the 49th to the
102nd note, and from the 103rd to the 150th note, respec-
tively. The structure of the piece is ABA (see Fig. 3). The
nominal performance was played according to the Moderato
score indication with a constant tempo at 126bpm and the
sound intensity was arbitrarily fixed at 80dB. These values
were intended as a reference point for subsequent com-
parisons, thus without any special meaning. The duration of
the grace notes (acciaccature) was fixed to one 32nd and the
subsequent 8th note was subtracted of this value. For each
recording, the pianist played many performances; then he
chose the most effective one. The use of the pedal was not
permitted.
A first set of performances was played in a “natural” way:
the pianist was asked to play without any expressive inten-
tion, according to the standard musical practice, and to play
all repetitions as similar as possible. The estimated values
(using all the KTH rules and rT, rL with the static estimation
procedure) reflected the constraints imposed on the per-
 
Fig. 3. Score of the Sonatina in G major by L. van Beethoven; lines and letters over the score indicate the phrasing structure; the segmen-
tation was made by the performer.
D
o
w
n
l
o
a
d
e
d
 
B
y
:
 
[
H
E
A
L
-
L
i
n
k
 
C
o
n
s
o
r
t
i
u
m
]
 
A
t
:
 
1
8
:
0
8
 
1
7
 
A
u
g
u
s
t
 
2
0
0
8
Rule systems for music performance 303
former; in fact for each rule, the coefficients were very stable
among these natural recordings (Zanon & De Poli, 2003). A
second group of performances was used, in which the pianist
was asked to play with different expressive intentions: in this
case some parameters presented considerable variations.
As already mentioned in the previous section, we
expected that the performer would change his interpretation
during the piece. Thus, we tried to estimate parameters in
shorter fragments. We decided to divide the score into its
three main phrases: this could improve the fitting because
into these three phrases the actions of the performer should
be more homogeneous than in the whole piece. If so, the
KTH rule system does not have to compensate for different
expressive strategies, and then this “local estimation” should
reflect more closely the musician’s relevant performance
deviations.
Henceforth, the discussion of the results will be carried
out with reference to the “Angry” performance. Similar 
discussions can be done for all the other expressive or 
natural performances.
5.1. Phrase analysis
The estimations were made over the whole piece and over
each phrase (see Table 1). In general, the piece was played
faster (kT < 0) than the nominal performance. In particular,
the two instances of phrase A were played louder than phrase
B in the least-square sense. The three phrases were played
with decreasing values of the tempo (increasing values for
kT). Moreover, from the efficiency x values, we can quantify
the number of deviations that cannot be explained using only
the rT and rL rules; more precisely, the lower values of the
efficiency in the A phrases indicate that these phrases were
played applying a greater number of deviations, which can
not be captured by the rules, than in the B phrase.
5.2. Time-varying analysis
In this sub-section, we present the data coming from a sliding
window estimation. This approach should increase the fitting,
revealing also if the rules are working well: in fact if the esti-
mated parameters reveal a high variability, then it is possible
that the corresponding rule is not working properly. We used
a two phase estimation, as already mentioned in the section
“Time varying estimation”: in the first we used only the rT
and rL rules to explore the long-term phrasing strategy, reduc-
ing to 1/100 the weights of the durations, then the rT and rL
rules with all the KTH rules to estimate their k parameters’
profiles (with equal values for duration weights the IOI ones).
5.2.1. Phase 1
The analysis was carried out using a sliding window of 10
notes (1–2 bars on average) with a hop size of 1. Results of
the estimation are presented in Figure 4, Figure 5 and in
Figure 6. The estimated parameters are plotted in the center
of the window of the original data, and their indices always
start from 1; for this reason the two graphs have non-aligned
scales. We can see in Figure 4, that there is a slight 
increment of the kT parameter over the whole piece (slight
decrement of the tempo). At the end of each phrase there is
a pronounced increment of the parameters, that suggests a
decreasing tempo marking the phrase boundaries. The first
instance of the A phrases has been played without subdivi-
sion in sub-phrases. The B phrase and the second instance of
the A phrase presents a sub-phrase subdivision marked by
increasing values of the kT parameter. This suggests a slowing
down of the tempo. These two subdivisions seem to be un-
correlated with the sub-phrase structure: in the case of the 
B phrase because the rallentando was performed about 15
notes after the sub-phrase boundary, and in the case of the
last phrase because it is divided in three sub-phrases and not
in two.
Figure 5 shows the profiles of the kT parameter and of the
tempo, which was calculated in two ways: in the former, it
was obtained from the kT parameter using (4). In the latter,
the tempo was calculated from the IOI of each note with a
subsequent average in a window of 10 notes; the values of
the IOIs of the grace notes have been added to the sub-
sequent notes. This manual correction was necessary because
the grace notes would introduce very high values of the
tempo (400bpm) that would be reflected in the averages also
(280bpm). It should be noticed that the same problem is
present also in the kT profiles, but in this case it is not 
possible to make a manual correction. From the figure it is
possible to see that the higher the value of kT is, the lower is
the corresponding tempo, in accordance with (4). However
there is no perfect correlation due to the grace notes in the
A phrases, which leads to an over estimated tempo. This is 
a strong indication that the grace notes should be treated 
separately, for example, with an ad hoc rule.
Some considerations can also be made for the profile of
kL parameter in Figure 6: it indicates a softer playing of
phrase B, and in general a louder interpretation marking the
boundaries between phrases. In this case, there is accordance
with the negative values of the Phrase Arch rule parameters
reported by Bresin and Friberg (2000). Noteworthy is also
the absence of loudness modulation in the final phrase.
Finally, as predicted by the efficiency x previously computed,
Table 1. Estimated parameters using only the rT and rL rules, over
the whole piece and over the three phrases for the “Angry” perfor-
mance of the Sonatina in G major. The weights for the durations
were reduced to 1/100 of the weights for IOIs.
Whole piece Phrase 1 (A) Phrase 2 (B) Phrase 3 (A)
(1–150) (1–48) (49–102) (103–150)
kT -0.21 -0.23 -0.21 -0.20
kL -3.78 -3.83 -3.90 -3.58
x 0.64 0.62 0.82 0.54
D
o
w
n
l
o
a
d
e
d
 
B
y
:
 
[
H
E
A
L
-
L
i
n
k
 
C
o
n
s
o
r
t
i
u
m
]
 
A
t
:
 
1
8
:
0
8
 
1
7
 
A
u
g
u
s
t
 
2
0
0
8
304 Patrick Zanon and Giovanni De Poli
20 40 60 80 100 120 140
-1
-0.8
-0.6
-0.4
-0.2
0
0.2
0.4
Note number
D
ev
ia
tio
n 
[1
 =
 n
om
in
al
 v
al
ue
]
Inter-Onset deviations
0 20 40 60 80 100 120 140
-0.3
-0.25
-0.2
-0.15
-0.1
Window number
k T
 v
al
ue
Estimated kT parameters
Fig. 4. Upper panel: IOI deviations measured in terms of nominal values; lower panel: estimation of the kT parameter using the sliding
window of 10 notes. The values were obtained from the “Angry” performance of the Sonatina in G major. The solid and dashed vertical lines
indicate the phrase and sub-phrase subdivisions, respectively.
0 20 40 60 80 100 120 140
-0.3
-0.25
-0.2
-0.15
-0.1
Window number
k T
 v
al
ue
Estimated kT parameters
0 20 40 60 80 100 120 140
140
145
150
155
160
165
170
175
180
Window number
T
em
po
 [b
pm
]
Estimated tempo values
Tempo derived from kT                               
Average of the note-by-note tempo without grace notes
Fig. 5. Upper panel: estimated kT parameter using a sliding window of 10 notes in the upper panel; lower panel: two estimations of the
tempo. The values were obtained from the “Angry” performance of the “Sonatina in G major”. The tempo profiles were calculated from the
IOIs of each note with a subsequent average in a window of 10 notes, and directly from the estimated kT parameter using (4). The differences
between the two tempo profiles are due to a manual correction of the note-by-note tempo, in which the values of the grace notes have been
added to the subsequent notes.
D
o
w
n
l
o
a
d
e
d
 
B
y
:
 
[
H
E
A
L
-
L
i
n
k
 
C
o
n
s
o
r
t
i
u
m
]
 
A
t
:
 
1
8
:
0
8
 
1
7
 
A
u
g
u
s
t
 
2
0
0
8
Rule systems for music performance 305
we can see that in phrase B a lower number of deviations
have been introduced by the musician than in the A phrases.
5.2.2. Phase 2
A restricted set of rules was used with the sliding window
procedure. In this case the window size was increased to 25
notes (3–4 bars on average) to avoid over-fitting problems,
and the hop size was fixed to 1. The rules used in this esti-
mation were the following: rT, rL, Duration Contrast TIME,
Duration Contrast SL, Duration Contrast Art, Harmonic
Charge TIME, Harmonic Charge SL, High Loud, Melodic
Charge TIME, Melodic Charge SL, Phrase Arch Level 6
(Amp = 1.87, Turn = 0.72, Next = 1.71, 2Next = 0.3, Last =
1.1, Acc = 2.77), and Punctuation D0 D1 (Dur = 0, Duroff =
1), where “TIME” refers to the rule’s duration effect and ‘SL’
to the its amplitude effect. After a first analysis, the Punctu-
ation D1 D0 rule was excluded because of the high correla-
tion of its profile with the Duration Contrast TIME profile
(-0.89) producing over-fitting and over-estimation of the
respective k parameters.
The parameters, as shown in Figure 7 and Figure 8, are
quite variable and some of them seem to be related to the
structure of the piece. Moreover, in the second phrase, 
the parameters seem to be more stable than in the other two.
The parameters estimated for the rules rT and rL tend to 
compensate for the bias introduced by the other rules. The
other parameters are reported in Table 2 in which the average
and the variance are shown. Four rules (Duration Contrast
TIME, Harmonic Charge TIME, Melodic Charge TIME, and
Punctuation-D0-D1) exhibit a high variance if compared to
their average value, and they also have the highest estimated
values among all rules.
The Harmonic Charge TIME rule (Fig. 8) shows a graph
that is approximately 0 on all the estimations except in cor-
respondence with the grace notes of the first bar and the 17th:
in these cases the values are around -3. A closer look to the
graphs of the durations and IOIs deviations introduced by the
20 40 60 80 100 120 140
-0.6
-0.55
-0.5
-0.45
-0.4
-0.35
-0.3
-0.25
-0.2
Note number
D
ev
ia
tio
n 
[B
]
Loudness deviations
0 20 40 60 80 100 120 140
-4.6
-4.4
-4.2
-4
-3.8
-3.6
-3.4
-3.2
Window number
k L
 v
al
ue
Estimated kL parameters
Fig. 6. Upper panel: loudness deviations measured in Bell for the “Angry” performance; lower panel: estimation of the kL parameter using
the sliding window of 10 notes: the lower is the estimated value, the softer is the human interpretation. The solid and dashed vertical lines
indicate the phrase and the sub-phrase subdivisions, respectively.
Table 2. Average k parameters and their variance for the “Angry”
performance of the Sonatina in G major.
Rule name Mean Variance
Duration Contrast TIME -1.61 5.01
Duration Contrast SL 0.63 0.08
Duration Contrast Art 0.40 0.06
Harmonic Charge TIME -0.39 2.60
Harmonic Charge SL 0.05 0.03
High Loud 0.13 0.02
Melodic Charge TIME -0.37 3.07
Melodic Charge SL -0.30 0.18
Phrase Arch Level 6 0.04 0.05
Punctuation D0 D1 0.76 3.05
D
o
w
n
l
o
a
d
e
d
 
B
y
:
 
[
H
E
A
L
-
L
i
n
k
 
C
o
n
s
o
r
t
i
u
m
]
 
A
t
:
 
1
8
:
0
8
 
1
7
 
A
u
g
u
s
t
 
2
0
0
8
306 Patrick Zanon and Giovanni De Poli
0 20 40 60 80 100 120
-0.4
-0.2
0
0.2
0.4
0.6
Window number
E
st
im
at
ed
 k
 v
al
ue
s
Estimated k parameters
Harmonic Charge SL 
High Loud          
Phrase Arch Level 6
0 20 40 60 80 100 120
-1.5
-1
-0.5
0
0.5
1
Window number
E
st
im
at
ed
 k
 v
al
ue
s
Estimated k parameters
rT                     
Duration Contrast Art Dr
Melodic Charge SL       
Fig. 7. Estimation of parameters using a sliding window of 25 notes for the “Angry” performance of the Sonatina in G major. The rules
with the smallest estimated parameters are shown.
0 20 40 60 80 100 120
-4
-2
0
2
4
6
Window number
E
st
im
at
ed
 k
 v
al
ue
s
Estimated k parameters
Duration Contrast SL
Puntuation D0 D1    
Harmonic Charge TIME
0 20 40 60 80 100 120
-6
-4
-2
0
2
4
6
Window number
E
st
im
at
ed
 k
 v
al
ue
s
Estimated k parameters
Melodic Charge TIME   
-rL                  
Duration Contrast TIME
Fig. 8. Estimation of parameters using a sliding window of 25 notes for the “Angry” performance of the Sonatina in G major. The rules
with the highest estimated parameters are shown.
D
o
w
n
l
o
a
d
e
d
 
B
y
:
 
[
H
E
A
L
-
L
i
n
k
 
C
o
n
s
o
r
t
i
u
m
]
 
A
t
:
 
1
8
:
0
8
 
1
7
 
A
u
g
u
s
t
 
2
0
0
8
Rule systems for music performance 307
rule (Fig. 9) shows the reason of this behavior: in corre-
spondence with the grace notes at the beginning of the A
phrases, there are two valleys in the timing profile of the
human performance, while there are two peaks in the timing
profile of the rule (black arrows); this fact triggers negative
values for the k parameters for each of the windows that
contain these grace notes: the first two and those from the
80th to the 105th.
Some of the averages listed in Table 2 are in accordance
with values previously found appropriate (Bresin & Friberg,
2000), especially for Duration Contrast Art (1), High 
Loud (0). Less (but still good) accordance was found for
Punctuation D0 D1 (2). Our results for the Duration Contrast
rule are quite different from those mentioned in the work 
of Bresin and Friberg: the estimated values have a high 
variance, and their values seem to be highly related to the
structure of the piece (see Fig. 8). In the first phrase (A, 
notes 1–48), most of the values are negative, and in particu-
lar in the first two sub-phrases (notes 1–26) values are about
-4, suggesting a “Tender” or “Sad” interpretation according
to Bresin and Friberg (2000). In the third sub-phrase (notes
27–48), there is a positive trend which reaches the value of
about 1, suggesting an “Angry” interpretation, in agreement
with (Bresin & Friberg, 2000). In the second phrase (B, notes
49–102) values are on average close to 0 and in particular,
in the first sub-phrase (notes 49–61), they are close to 1,
maintaining the accordance with Bresin and Friberg (2000).
In the second phrase (notes 62–102) values range from -1 to
1 but are on average around 0, suggesting a “Solemn” inter-
pretation. Finally, in the third phrase (A, notes 103–150)
values repeat the same shape of the first phrase, in agreement
with the ABA structure of the piece. It should be noticed that
the sliding window smoothes abrupt changes of the para-
meter values, like for example between phrases A and B, and
between phrases B and A (see Figure 8). More precisely, pos-
itive and negative slopes in the graph mark the boundaries
between phrases, which are characterized by very different
values for the k parameters: from -4 to 1 (notes 40–50) and
from 1 to -4 (notes 90–110) respectively.
A closer look to the deviations introduced by the rule and
by the performer can help to understand the negative values
for the Duration Contrast TIME rule in the A phrases. In
Figure 10 the timing deviation profiles of the “Angry” per-
formance and of the Duration Contrast TIME rule are shown.
In the A phrases the estimated negative values are triggered
by the peaks in the timing profile of the human performance
that correspond to the notes following the grace notes; the
negative values are due to the peaks that correspond to the
valleys in the timing profile of the rule (black arrows). Thus,
the behavior of the estimated parameters for the rule is
affected by the presence of the acciaccature, resulting in an
artifact: again this observation suggests that the grace notes
need to be handled with care, since they cannot be treated 
as usual notes. However, also several other notes trigger 
20 40 60 80 100 120 140
-1
-0.8
-0.6
-0.4
-0.2
0
0.2
0.4
Note number
D
ev
ia
tio
n 
[1
 =
 n
om
in
al
 v
al
ue
]
Duration and Inter-Onset deviations in the Angry performance
Duration   
Inter-Onset
20 40 60 80 100 120 140
0
0.05
0.1
0.15
0.2
0.25
Note number
D
ev
ia
tio
n 
[1
 =
 n
om
in
al
 v
al
ue
]
Duration and Inter-Onset deviations in the Harmonic Charge TIME rule
Duration   
Inter-Onset
Fig. 9. Timing deviations of the “Angry” performance and of the Harmonic Charge TIME rule. In correspondence with the grace notes 
at the beginning of the A phrases the estimated negative quantity values are triggered by the valleys in the timing profile of the human 
performance; in fact, the valleys are related to the peaks in the timing profile of the rule (black arrows).
D
o
w
n
l
o
a
d
e
d
 
B
y
:
 
[
H
E
A
L
-
L
i
n
k
 
C
o
n
s
o
r
t
i
u
m
]
 
A
t
:
 
1
8
:
0
8
 
1
7
 
A
u
g
u
s
t
 
2
0
0
8
308 Patrick Zanon and Giovanni De Poli
negative values: these notes are marked by the valleys in the
duration profiles of the human performance (the performer
played very staccato) and correspond with the peaks of the
duration profiles in the rule (gray arrows).
5.3. An analysis using a “natural” performance 
as reference
A perceptual expressive space was earlier derived by a factor
analysis of perceptual listening tests of various profession-
ally performed pieces (Canazza, De Poli, Drioli, Rodà, &
Vidolin, 2000). This space is a simplified representation of
how listeners might organize different expressive perfor-
mances in their minds. Several adjectives were used to
describe the points which characterize the expressive inten-
tions of the performances: for example, the adjectives
hard/soft and heavy/light, which form bipolar scales (couples
of opposites), were located at the border of the perceptual
space in the analysis, while the natural performance (played
according to standard musical practice) appeared in the
middle of the space. A subsequent sonological analysis
allowed the authors to relate the factors (the coordinates of
the perceptual expressive space) to acoustical parameters.
From these observations, an expressive performance engine
was obtained. The model operates by changing the mean
value and the range of deviations of the sonologic para-
meters of a natural performance to transform it into an
expressive one.
This approach suggested to us to explore the behavior of
the KTH model, using a “natural” performance as a refer-
ence. Thus, in this section, we used the static estimation
again, but we chose to add deviations to an average per-
formance of the Sonatina in G major instead of the nominal
performance. The average was obtained from the set of
Natural performances by averaging all intensities (dB) by
means of the classical arithmetic mean, and all timing values
(IOIs and durations) by means of the geometric mean. The
geometric mean was preferred over the arithmetic mean
because it compensates for any tendency of slower perfor-
mances to show more expressive variability, which would
have dominated in an arithmetic average (see Repp, 1992a).
The results of the estimations are reported in Figure 12.
The first observation is that all parameters are smaller than
those obtained in the static estimation using the nominal per-
formance as reference (see Figure 11). This is probably due
to deviations from the score, which are already present in the
average performance. From the musical point of view, the
synthetic performances are much better than those obtained
from the nominal performance. Moreover, the number of
rules able to differentiate between expressive performances
increased. In fact, in our previous work (Zanon & De Poli,
2003) we found that only a few rules were able to clearly 
20 40 60 80 100 120 140
-1
-0.8
-0.6
-0.4
-0.2
0
0.2
0.4
Note number
D
ev
ia
tio
n 
[1
 =
 n
om
in
al
 v
al
ue
]
Duration and Inter-Onset deviations in the Angry performance
Duration   
Inter-Onset
20 40 60 80 100 120 140
-0.1
-0.08
-0.06
-0.04
-0.02
0
Note number
D
ev
ia
tio
n 
[1
 =
 n
om
in
al
 v
al
ue
]
Duration and Inter-Onset deviations in the Duration Contrast TIME rule
Duration   
Inter-Onset
Fig. 10. Timing deviations of the “Angry” performance and of the Duration Contrast TIME rule. In the A phrases the estimated negative
values are triggered by the peaks in the timing profile of the human performance that correspond to the notes following the grace notes; 
the peaks are related to the valleys in the timing profile of the rule (black arrows). Moreover, there are several notes that were played very
staccato that trigger negative values for the rule quantities too (gray arrows).
D
o
w
n
l
o
a
d
e
d
 
B
y
:
 
[
H
E
A
L
-
L
i
n
k
 
C
o
n
s
o
r
t
i
u
m
]
 
A
t
:
 
1
8
:
0
8
 
1
7
 
A
u
g
u
s
t
 
2
0
0
8
Rule systems for music performance 309
differentiate opposite expressive intentions like, for example,
the “Sadness” and the “Happiness” performances. We found
that only 6 rules were able alone to distinguish these two
expressive intentions: the Harmonic Charge TIME, the
Melodic Charge TIME, the Punctuation D1 D0, Phrase Arch
level 5 and 6, and the Leap Articulation rules (see Fig. 11).
Using the average “natural” performance, we found 17 rules
able to clearly differentiate the same couple of performances:
Duration Contrast TIME, Duration Contrast Art, Final Ritard,
both Harmonic Charge rules, High Loud, Melodic Charge
TIME, both Punctuation rules, all Phrase Arch rules, Faster
Uphill, Leap Articulation, Leap Tone Duration, the first of
the Phrase Articulation rules and the Repetition Articulation
(see Fig. 12). Analogously, the number of rules able to 
differentiate the “Fear” and “Indifferent” performances
increased greatly when using the natural performance as 
reference.
An interesting parallel can be found in (Stamatatos, 2001)
where the author found that if the average performance
among different players is used as reference, better results
were obtained in the performer recognition task than if the
score was used as reference. Moreover, it is possible to make
an interesting comparison between the parameters used by
Canazza and collaborators (Canazza et al., 2000) to synthe-
size a “Soft” or a “Hard” performance. These parameters are
used for the synthesis of expressive performances starting
from a “natural” one. They are divided into classes: the
former ones are used as coefficients in order to modulate the
mean of the acoustical parameters, and the latter ones deal
with the range of deviations around the mean. We can see
from Figure 12 that “Anger” is characterized by small k
values implying a small deviation range, while the “Sadness”
presents large k values implying a large deviation range. If
we associate “Anger” with “Hard” and “Sadness” with
“Soft”, we can find a similar behavior: in fact “Hard” is 
characterized by a low range of deviations from the mean
value of sonologic parameters while “Soft” presents a much
higher range of deviations (Canazza & Rodà, 1999). Simi-
larly, comparing the estimated values of kT and kL we deduce
that Anger is played faster (kT = -0.14) and louder (kL = 2.8)
than the Natural reference performance, while the Sadness
performance is played slower (kT = 0.52) and slightly softer
(kL = -0.94) than the Natural reference performance. A
similar behavior was found for the parameters that deal 
with the mean values of the acoustical parameters of the Hard
and Soft performances, respectively (Canazza, De Poli, Di
Sanzo, & Vidolin, 1998).
6. Example 2: Sonata K.332 (Adagio)
The human recording of the piece was provided by Gerhard
Widmer, Austrian Research Institute for Artificial Intelli-
-10
-5
0
DCt
-2
-1
0
1
DCl
0
0.5
1
DCA
0
0.5
1
FR
-2
-1
0
1
HCt
-0.2
0
0.2
0.4
0.6
HCl
0
0.2
0.4
0.6
0.8
HL
-2
-1
0
1
2
MCt
-0.5
0
0.5
1
MCl
0
1
2
3
Pa
0
5
10
Pb
-0.5
0
0.5
1
Ph4
0
0.5
1
1.5
Ph5
-0.2
0
0.2
0.4
0.6
Ph6
0
2
4
6
FU
-1
0
1
2
LA
-4
-3
-2
-1
0
LT
0
0.2
0.4
0.6
0.8
PAa
-1
0
1
2
PAb
0
2
4
6
RA
Angry      
Disgust    
Fear       
Happiness  
Indifferent
Sadness    
Fig. 11. Estimated parameters for different expressive performances of the Sonatina in G major using the nominal performance as 
reference; all rules were used; DCt: Duration Contrast TIME, DCl: Duration Contrast SL, DCA: Duration Contrast Art, FR: Final Ritard,
HCt: Harmonic Charge TIME, HCl: Harmonic Charge SL, HL: High Loud, MCt: Melodic Charge TIME, MCl: Melodic Charge SL, Pa:
Punctuation (Dur = 0, Duroff = 1), Pb, Punctuation (Dur = 1, Duroff = 0), Phx, Phrase Arch level x, FU, Faster Uphill, LA, Leap 
Articulation dro, LT: Leap Tone duration, PAa: Phrase Articulation (Duroff = 0, Dur = 1), PAb: Phrase Articulation (Duroff = 1, Dur = 0),
and RA: Repetition Articulation dro.
D
o
w
n
l
o
a
d
e
d
 
B
y
:
 
[
H
E
A
L
-
L
i
n
k
 
C
o
n
s
o
r
t
i
u
m
]
 
A
t
:
 
1
8
:
0
8
 
1
7
 
A
u
g
u
s
t
 
2
0
0
8
310 Patrick Zanon and Giovanni De Poli
gence (ÖFAI) and is part of a large database of recordings,
made in ecological settings: the actual piece was played on
a Bösendorfer SE290 computer-monitored concert grand
piano provided with MIDI output and was published in com-
mercial CD (Roland Batik, Gramola 98704, 1990). Johan
Sundberg, Anders Friberg and Roberto Bresin, KTH, pro-
vided the nominal performance, the phrase subdivision and
the chord analysis. A description of the translation of the
grace notes into the nominal performance can be found in
(Sundberg et al., 2003). All material was used as a common
reference for several studies presented at the Stockholm
Music Performance Symposium STOMPS 2002.
We analyzed the first 8 measures of the melody for a total
of 105 notes, divided in two main phrases, from the 1st to
the 50th note, and from the 51st to the 105th note, respec-
tively. The structure of the piece is AB. Figure 13 shows the
score with the phrase subdivisions. There were two versions
of the recording: in one the durations of the notes reflected
what the musician made on the keyboard, and in the other
the information of the pedal was taken into account, expand-
ing the durations of the sounding notes when the pedal 
was down. We decided to use only the first recording, because
the use of the pedal information can produce over-legato
notes that are difficult for the KTH implemented rules to
handle. Moreover, there was an additional choice: whether 
to include in the analysis the grace notes or not. We chose to
include them in order to be faithful to the original recording.
The nominal performance was recorded using a constant
tempo of 45bpm (quarter note) according to the Adagio indi-
cation of the score. The intensity was arbitrarily fixed at 
80dB. Also in this case, these values were used as a 
reference point.
6.1. Static estimation
At first the estimation was carried out using the static pro-
cedure, over the entire fragment of the piece, and using the
default values for the non-linear parameters. In order to
achieve the best fitting, we used a high number of rules:
Double Duration, Chromatic Charge, Duration Contrast
TIME, Duration Contrast SL, Duration Contrast Art, Faster
Uphill, Harmonic Charge TIME, Harmonic Charge SL, High
Loud, Leap Articulation Dro, Leap Tone Duration, Melodic
Charge TIME, Melodic Charge SL, Phrase Arch Level 4
(Amp = 1.0 Turn = 0.5 Last = 1.0 Acc = 1.0), Phrase Arch
Level 5 (Amp = 1.0 Turn = 0.2 Last = 1.0 Acc = 1.0 Next =
1.0), Phrase Arch Level 6 (Amp = 1.0 Turn = 2.0 Last = 1.0
Acc = 1.0 Next = 1.0 2next = 1.0), Phrase Articulation D0
D1, Phrase Articulation D1 D0, Punctuation D0 D1, 
Punctuation D1 D0, and Repetition Articulation Dro. The
results were poor, both regarding the musical quality of the
synthetic performance, and regarding efficiency (0.41).
-6
-4
-2
0
DCt
-1
0
1
DCl
-0.5
0
0.5
DCA
-0.5
0
0.5
FR
-2
-1
0
1
HCt
-0.4
-0.2
0
0.2
0.4
HCl
-0.4
-0.2
0
0.2
0.4
HL
-4
-2
0
2
MCt
-0.6
-0.4
-0.2
0
0.2
MCl
-1
0
1
2
Pa
-2
0
2
4
6
Pb
-0.4
-0.2
0
0.2
0.4
Ph4
-0.2
0
0.2
0.4
0.6
Ph5
-0.2
0
0.2
0.4
0.6
Ph6
-2
0
2
4
6
FU
-2
-1
0
1
2
LA
-3
-2
-1
0
1
LT
-0.4
-0.2
0
0.2
0.4
PAa
-1
-0.5
0
0.5
PAb
-1
0
1
2
RA
Angry      
Disgust    
Fear       
Happiness  
Indifferent
Sadness    
Fig. 12. Estimated parameters for different expressive performances of the Sonatina in G major using the average “natural” performance
as reference; all rules were used; DCt: Duration Contrast TIME, DCl: Duration Contrast SL, DCA: Duration Contrast Art, FR: Final Ritard,
HCt: Harmonic Charge TIME, HCl: Harmonic Charge SL, HL: High Loud, MCt: Melodic Charge TIME, MCl: Melodic Charge SL, 
Pa: Punctuation (Dur = 0, Duroff = 1), Pb, Punctuation (Dur = 1, Duroff = 0), Phx, Phrase Arch level x, FU, Faster Uphill, LA, Leap 
Articulation dro, LT: Leap Tone duration, PAa: Phrase Articulation (Duroff = 0, Dur = 1), PAb: Phrase Articulation (Duroff = 1, Dur = 0),
and RA: Repetition Articulation dro.
D
o
w
n
l
o
a
d
e
d
 
B
y
:
 
[
H
E
A
L
-
L
i
n
k
 
C
o
n
s
o
r
t
i
u
m
]
 
A
t
:
 
1
8
:
0
8
 
1
7
 
A
u
g
u
s
t
 
2
0
0
8
Rule systems for music performance 311
This result was mainly due to the unreliable duration
values of the notes, caused by the missing pedal information.
Thus, a second estimation was carried out reducing the
weights of the durations to a tenth of the weights for the IOIs.
In this case, the efficiency increased to 0.64, and the listen-
ing to the resulting synthetic performance confirmed the
numerical improvement. However the synthesis remained
inadequate from an expressive point of view: in general, the
synthetic piece was played with more staccato than in the
human one, without large dynamic modulation, tempo mod-
ulation, and expressive changes. The grace notes were played
with less rubato than in the human performance, and in 5
notes (the 8th of the third bar, and the 1st, the 4th, the 11th,
and the 12th of the fourth bar) evident “hesitations” occurred.
More precisely, these notes exhibited lower values of IOIs
(about 50% of the nominal value) than in the human perfor-
mance and three of the subsequent notes showed higher
values of IOI (20–50%) than in the human performance. The
musical result in the synthesis is unpleasant, because these
notes seem to be played too early and the subsequent length-
ening of the IOIs tends to underline the “effect”. The results
are reported in Table 3.
The deficiences of the synthetic performance were mainly
due to the performer’s large deviations from the score: the
KTH rule system was designed to produce limited variation
in order to preserve the musical acceptability of the piece,
 
Fig. 13. Score of the Sonata K.332 (Adagio) by W. A. Mozart; lines and letters over the score indicate the phrasing structure; Johan 
Sundberg, Anders Friberg and Roberto Bresin kindly provided the segmentation and the chord analysis.
D
o
w
n
l
o
a
d
e
d
 
B
y
:
 
[
H
E
A
L
-
L
i
n
k
 
C
o
n
s
o
r
t
i
u
m
]
 
A
t
:
 
1
8
:
0
8
 
1
7
 
A
u
g
u
s
t
 
2
0
0
8
312 Patrick Zanon and Giovanni De Poli
since it is difficult to design rules that produce large devia-
tions and still sound musical. Moreover, the human perfor-
mance presents changes of “expressiveness” strategy during
the piece that probably can be accounted for only with 
different setups of the rule parameters; thus, the static 
estimation tried to average these changes in a numerical way,
finding an optimum that was not musically acceptable.
6.2. Phrase analysis
In order to improve the fit of the estimation procedure, we
analyzed separately the two phrases of the piece, according
to the already mentioned two phase strategy: in the first
phase, we used the rT and rL rules only, and we reduced to
1/100 the durations’ weights, in order to explore the mean
tempo and intensity; then we used the rT and rL rules jointly
with some of the KTH rules, using duration weights equal 
to 1/10 of the IOI ones, to estimate their k parameters.
6.2.1 Phase 1
The estimation was carried out in the same way as for the
Sonatina in G major, using only the rT and rL rules, on the
entire piece and on the two phrases separately. The results
are presented in Table 4.
The nominal performance was recorded at a constant
tempo of 45bpm, so on average the human interpretation 
was played slower, more precisely at a Ts = 45/(1 + 0.31) =
34.4bpm; the same value was obtained for both phrases when
separately analyzed. The first phrase was played louder than
the second one. Moreover, we can see from the efficiency
values that in the second phrase the performer introduced
larger deviations than in the first; in fact, in the second phrase
the efficiency is considerably lower than in the first.
6.2.2 Phase 2
The analysis of the two phrases was carried out on a
restricted set of rules. The rules we used were: Duration 
Contrast TIME, Duration Contrast SL, Duration Contrast
Art, Harmonic Charge TIME, Harmonic Charge SL, High
Loud, Melodic Charge TIME, Melodic Charge SL, 
Phrase Arch Level 4 (Amp = 1.0 Turn = 0.5 Last = 1.0 Acc
= 1.0 =, Phrase Arch Level 6 (Amp = 1.0 Turn = 2.0 Last =
1.0 Acc = 1.0 Next = 1.0 2next = 1.0), Punctuation D0 D1
M7n, and Punctuation D1 D0 M7n. The Phrase Arch Level
5 rule was excluded because it was strictly related to the
Phrase Arch 6, causing over-fitting, and because it did not
allow significant efficiency improvements. The results are
presented in Table 5.
The results are really encouraging, especially from the
musical point of view. In fact, the 5 deficiencies of 
the synthesis mentioned above disappeared. Moreover, the 
notes were played more legato, and with more fluency. There
were also slight dynamic modulation and expressive changes,
and the grace note in the seventh bar was played with 
more rubato than in the previous version. However, there
were no significant tempo modulations, and the other grace
notes were still played too slow and staccato. Again, the 
way in which the grace notes are played seems to be hard 
to model, suggesting that such notes should be handled 
separately.
In general, most of the estimated parameters for the
second phrase were greater in absolute value than in the first,
as we expected from the efficiency computed in phase 1. The
efficiency significantly increased in the first phrase, in com-
parison to the estimation carried out over the entire piece,
both using all 21 rules and using the restricted set of rules.
Table 4. Estimated parameters using only the rT and rL rules, over
the whole piece and over the two phrases for the performance of the
Mozart K.332 excerpt. The weights for the durations were reduced
to 1/100 of the weights for IOIs.
Whole piece Phrase 1 (A) Phrase 2 (B)
(1–105) (1–50) (51–105)
kT 0.31 0.31 0.31
kL -6.98 -6.71 -7.22
x 0.55 0.62 0.51
Table 3. Estimated k parameters over the whole Mozart K.332
excerpt using 21 of the KTH rules for the human interpretation.
Rule name Estimated value
Double Duration -1.79
Chromatic Charge -0.07
Duration Contrast TIME 3.70
Duration Contrast SL 0.16
Duration Contrast Art -0.45
Faster Uphill 6.63
Harmonic Charge TIME 0.25
Harmonic Charge SL 0.31
High Loud 0.52
Leap Articulation Dro 4.84
Leap Tone Duration, Melodic Charge TIME -7.93
Melodic Charge TIME 0.08
Melodic Charge SL 0.11
Phrase Arch Level 4 -0.42
(Amp = 1.0 Turn = 0.5 Last = 1.0 Acc = 1.0)
Phrase Arch Level 5 -1.14
(Amp = 1.0 Turn = 0.2 Last = 1.0 Acc = 1.0 
Next = 1.0)
Phrase Arch Level 6 2.28
(Amp = 1.0 Turn = 2.0 Last = 1.0 Acc = 1.0 
Next = 1.0 2next = 1.0)
Phrase Articulation D0 D1 4.27
Phrase Articulation D1 D0 -2.30
Punctuation D0 D1 M7n 0.25
Punctuation D1 D0 M7 2.10
Repetition Articulation Dro 5.62
D
o
w
n
l
o
a
d
e
d
 
B
y
:
 
[
H
E
A
L
-
L
i
n
k
 
C
o
n
s
o
r
t
i
u
m
]
 
A
t
:
 
1
8
:
0
8
 
1
7
 
A
u
g
u
s
t
 
2
0
0
8
Rule systems for music performance 313
In the second phrase the efficiency was lower than in the first:
this suggests two separate estimations for each of the two
sub-phrases. In this case the efficiency increased over 0.7 for
each sub-phrase.
It is possible to try a comparison of the estimated para-
meters and the values indicated by Bresin and Friberg (2000)
for the rendering of basic emotions. In that work a few meta-
rules for selecting a suitable set of values of k parameters
were suggested. Of course, it is naïve to think that we can
draw conclusions on the intentions of the player from rule
quantities. Yet, it is interesting to find out whether the values
we estimated are related to some of these sets. In the first
phrase the estimated values of a set of rules (rT, rL, Duration
Contrast Articulation, Punctuations, High Loud, Phrase Arch
Level 4 and 6) are in agreement with those used in (Bresin
& Friberg, 2000) to synthesize a “Sad” interpretation. The
estimated values of the Duration Contrast rules are used in
the same work for an “Angry” interpretation. The interpreta-
tion of the second phrase is more controversial: a first set of
rules (rT, Duration Contrast Articulation, Punctuations, and
High Loud) use values that Bresin and Friberg suggest for a
“Solemn” interpretation, a second one (Duration Contrast,
Punctuations, High Loud) use values for a “Happy” inter-
pretation, a third set (rT, rL, Phrase Arch Level 6) use 
values for a “Sad” performance, and a fourth set (rT, rL, 
Punctuations, Duration Contrast, and Phrase Arch Level 4)
use values for a “Fear” performance. These results show that
the performer played the piece with an expression that cannot
be captured by the rules.
7. Discussion and conclusions
In this paper a time-varying estimation of parameters was
presented with the goal of approximating a human perfor-
mance through the use of rule systems. It was not our intent
to recognize which was the mood that inspired the performer,
rather to find a way to imitate a performer, in order to syn-
thesize with a rule system a performance that should sound
musically acceptable. Our aim is to understand which are the
strategies that the performers use to color a musical perfor-
mance. The goal of this research is to learn how to use robust
and well-validated rule systems to modify the expressive
content of multimedia objects that otherwise sound static. An
improvement of the actual rule systems, and a better under-
standing on how to use them can lead to audio objects able
to synthesize expressive performances which react to the
modification of the video content in real time, with smoothed
changes, i.e., realizing a morphing between different expres-
sive intentions.
Firstly, the static method of estimation was summarized,
and then we presented the extension of the procedure allow-
ing time-varying estimation on different time-scales. It is
known (Bresin & Friberg, 2000) that rule systems allow the
modeling of many expressive deviations introduced by the
musician. However, the estimations of the parameters can be
a hard task because of the large number of parameters con-
sidered. Moreover, during the execution of a piece, pianists
can change their expressive strategies to communicate struc-
ture, intentions or emotions. The deviations in timing and 
in intensity reflect the different and changeable expressive
intentions which performers use in accordance with their
communication strategies. The results obtained with our
method on some piano performances showed that the
method, when used on different time scales, produces differ-
ent estimations of the parameters: by reducing the time scale
we obtained a better fit, both from a musical and from a
numerical point of view. Moreover, the results revealed that
parameter profiles were related to the structure of the piece.
Finally, we attempted to analyze the expressiveness of a 
performance using the values obtained form the estimation
of parameters on different phrases.
The method was applied to the rule system developed by
KTH of Stockholm, but it can be used with any model that
introduces expressive deviations in an additive way, and can
be a good means to develop and improve rules for modeling
expressiveness in music performance.
The method shares the limitations of additive systems
because it does not properly model interactions found in the
music performance, as for example interaction between loud-
ness and timing. Moreover the mathematical optimum does
not necessarily coincide with the musical optimum. A further
fine-tuning by an expert could be advisable, by changing the
Table 5. Estimated k parameters over the whole piece and over the
two sub-phrases using 12 of the KTH rules for the human inter-
pretation of the Mozart K.332. Values marked with asterisk (*) were
obtained in the previous experiment (using 21 rules) and are
reported for comparison.
Rule name Whole piece Phrase 1 Phrase 2
(1–105) (A) (B)
Old (*) New
(1–50) (51–105)
Duration Contrast TIME 3.70 3.41 3.48 3.55
Duration Contrast SL 0.16 0.24 -1.09 1.00
Duration Contrast Art -0.45 -0.30 0.12 -0.62
Harmonic Charge TIME 0.25 -0.14 1.51 -1.86
Harmonic Charge SL 0.31 0.28 -0.27 1.14
High Loud 0.52 0.59 0.13 0.51
Melodic Charge TIME 0.08 0.10 -0.43 0.94
Melodic Charge SL 0.11 0.16 0.11 0.33
Phrase Arch Level 4 -0.42 -0.73 0.55 -1.68
(Amp = 1.0 Turn = 0.5
Last = 1.0 Acc = 1.0)
Phrase Arch Level 6 2.28 1.73 1.33 2.20
(Amp = 1.0 Turn = 2.0
Last = 1.0 Acc = 1.0 
Next = 1.0 2next = 1.0)
Punctuation D0 D1 M7n 0.25 1.69 1.47 2.16
Punctuation D1 D0 M7 2.10 2.71 0.61 4.80
Estimated x 0.64 0.59 0.67 0.57
D
o
w
n
l
o
a
d
e
d
 
B
y
:
 
[
H
E
A
L
-
L
i
n
k
 
C
o
n
s
o
r
t
i
u
m
]
 
A
t
:
 
1
8
:
0
8
 
1
7
 
A
u
g
u
s
t
 
2
0
0
8
314 Patrick Zanon and Giovanni De Poli
weights in the norm and/or by changing the time-scale in the
time-varying estimation. These procedures are not generally
sufficient, because the rule set might not be adequate to
produce a good approximation of a given human perfor-
mance, for example, if the performer followed a peculiar
interpretation strategy which cannot be modeled by the rule
system. In this case the introduction of new rules should 
be considered. The analysis of the approximation error can
be a guide in developing new rules as well as the profiles of
the parameters. In the latter case if these profiles are too 
variable, then the rule may not be properly working.
Acknowledgement
The authors are very grateful to Gerhard Widmer, Austrian
Research Institute for Artificial Intelligence (ÖFAI) for
kindly providing the Sonata K.332 (Adagio) performance,
and to Johan Sundberg, Anders Friberg, and Roberto Bresin,
KTH, for providing the nominal performance with the phrase
subdivision and the chord analysis used in this study. Special
thanks to Simon Dixon for several English lessons and to
Werner Goebl for his help using “Finale.” Finally, thanks to
the anonymous reviewers who helped improve the paper sig-
nificantly with their observations and useful suggestions.
References
Björck, Å. (1996). Numerical Methods for Least Square 
Problems. Philadelphia PA: SIAM.
Bresin, R. (1998). Artificial neural networks based models for
automatic performance of musical scores. Journal of New
Music Research, 27, 239–270.
Bresin, R., De Poli, G., & Ghetta, R. (1995). Fuzzy performance
rules. In: A. Friberg, & J. Sundberg (Eds.), Proceedings of
the KTH Symposium on “Grammars for music perfor-
mance”, Stockholm: KTH, 15–36.
Bresin, R., & Friberg, A. (2000). Emotional colouring of com-
puter controlled music performance. Computer Music
Journal, 24, 44–62.
Canazza, S., De Poli, G., Di Sanzo, G., & Vidolin, A. (1998). 
A model to add expressiveness to automatic musical per-
formance. In Proceedings of 1998 International Computer
Music Conference, Ann Arbor, pp. 163–169.
Canazza, S., De Poli, G., Drioli, C., Rodà, A., & Vidolin, A.
(2000). Audio morphing different expressive intentions for
multimedia systems. IEEE Multimedia, 7, 79–83.
Canazza, S., De Poli, G., Rodà, A., & Vidolin, A. (2003). An
abstract control space for communication of sensory expres-
sive intentions in music performance. Journal of New Music
Research, 32, 281–294.
Canazza, S., De Poli, G., & Vidolin, A. (1997). Perceptual analy-
sis of the musical expressive intention in a clarinet perfor-
mance. In: M. Leman (Ed.), Music, gestalt, and computing.
Studies in cognitive and systematic musicology, Berlin, 
Heidelberg: Springer-Verlag, pp. 441–450.
Canazza, S., & Rodà, A. (1999). Adding expressiveness in
musical performance in real time. In Proceedings of Con-
vention on Artificial Intelligence and Music Creativity, AISB,
Edinburgh, pp. 134–139.
Clynes, M. (1990). Some guidelines for the synthesis and testing
of Pulse Microstructure in relation to musical meaning.
Music Perception, 7, 403–422.
De Poli, G., Rodà, A., & Vidolin, A. (1998). Note-by-note analy-
sis of the influence of expressive intentions and musical
structure in violin performance. Journal of New Music
Research, 27, 293–321.
Friberg, A. (1991). Generative rules for music performance: 
a formal description of a rule system. Computer Music
Journal, 15, 56–71.
Friberg, A. (1995). Matching the rule parameters of Phrase Arch
to performances of “Träumerei”: A preliminary study. In: 
A. Friberg and J. Sundberg (Eds.), Proceedings of the KTH
symposium on Grammars for music performance, Stock-
holm: KTH, 37–44.
Friberg, A., Colombo, V., Frydén, L., & Sundberg, J. (2000).
Generating musical performances with Director Musices.
Computer Music Journal, 24, 23–29.
Gabrielsson, A. (1997). Music performance. In: D. Deutsch
(Ed.) The psychology of Music, 2nd. ed. New York: 
Academic Press.
Ishikawa, O., Aono, Y., Katayose, H., & Inokuchi, S. (2000).
Extraction of musical performance rule using a modified
algorithm of multiple regression analysis. Proceedings of the
2000 International Computer Music Conference, San 
Francisco: International Computer Music Association, pp.
348–351.
Juslin, P.N. (2001). Communicating emotion in music 
performance: a review and theoretical framework. In: 
P.N. Juslin, & J.A. Sloboda (Eds.), Music and emotion.
Theory and research, Oxford University Press, pp. 279–
309.
Repp, B.H. (1992a). Diversity and commonality in music 
performance: An analysis of timing microstructure in 
Schumann’s “Träumerei.” Journal of the Acoustical Society
of America, 92, 2546–2568.
Repp, B.H. (1992b). Probing the cognitive representation 
of musical time: Structural constraints on the perception of
timing perturbations. Cognition (International Journal of
Cognitive Science), 44, 241–281.
Stamatatos, E. (2001). A computational model for discriminat-
ing music performers. Proceedings of the MOSART Work-
shop on Current Research Directions in Computer Music,
Barcelona, pp. 65–69.
Sundberg, J., Friberg, A., & Bresin R. (2003). Comparison of a
musician’s and a computer’s tone onset timing in Mozart’s
Piano Sonata K 332, 2nd mvt, bar 1–20. Journal of New
Music Research, 32, 317–325.
Todd, N.P. (1985). A model of expressive timing in tonal music.
Music Perception, 3(1), 33–58.
Todd, N.P. (1992). The dynamics of dynamics: A model of
musical expression. Journal of the Acoustical Society of
America, 91, 3540–3550.
D
o
w
n
l
o
a
d
e
d
 
B
y
:
 
[
H
E
A
L
-
L
i
n
k
 
C
o
n
s
o
r
t
i
u
m
]
 
A
t
:
 
1
8
:
0
8
 
1
7
 
A
u
g
u
s
t
 
2
0
0
8
Rule systems for music performance 315
Todd, N.P. (1995). The kinematics of musical expression.
Journal of Acoustical Society of America, 97, 1940–1949.
Widmer, G. (2000). Large-scale induction of expressive perfor-
mance rules: First qualitative results. Proceedings of the
2000 International Computer Music Conference, San 
Francisco: International Computer Music Association, pp.
344–347.
Widmer, G. (2002). Machine discoveries: A few simple, robust
local expression principles. Journal of New Music Research
31, 37–50.
Zanon, P., & De Poli, G. (2003). “Estimation of parameters in
rule systems for expressive rendering in musical perfor-
mance.” Computer Music Journal, 27, 29–46.
Appendix: The KTH rule system
In this appendix, a brief description of the KTH rule system
is presented. Each rule has a quantity parameter k, which con-
trols the general effect. A k value of 1 corresponds approxi-
mately to a normal application of the rule. This is, however,
dependent on the musical context. Negative k values produce
the reversed effect. Some of the rules have auxiliary para-
meters that can be used for additional control of the rules. In
cases where the rule changes several performance variables,
the auxiliary parameters can be used for controlling the
amount of change for each performance variable. The rules
are described in detail in different publications: a complete
list, including a few online papers, is found on the website:
http://www.speech.kth.se/music/publications/
Phrasing rules
Punctuation: automatically locates small tone groups and
marks them with a lengthening of the last note and a fol-
lowing micro pause. Affected parameters: duration and IOI.
Auxiliary parameters: “Dur” and “Duroff.”
Phrase-articulation: inserts micro pauses at phrase and
sub-phrase boundaries; the last note in phrases is lengthened.
The phrase boundaries must be marked in the score. Affected
parameters: duration and IOI. Auxiliary parameters:
“Phlevel,” “Subphlevel,” “Dur” and “Duroff.”
Phrase-arch: each phrase is performed with an arch-like
tempo curve, starting slow, faster in the middle, and ritar-
dando towards the end. The sound level is coupled so that a
slow tempo corresponds to a low sound level. The phrase
boundaries must be marked in the score. Affected parame-
ters: intensity, duration and IOI. Auxiliary parameters:
“Phlevel,” “Power,” “Amp,” “Next,” “2Next,” “Turn,” “Last”
and “Acc.”
Final Ritard: adds a ritardando at the end of the 
piece similar to the velocity decrease of a stopping runner.
Affected parameters: duration and IOI. Auxiliary parameters:
“Q.”
High Loud: applies intensity changes according to 
“the higher the pitch, the louder.” Affected parameters: 
intensity.
Harmonic and Melodic Tension
Melodic Charge: emphasizes notes remote from the current
chord. Affected parameters: intensity, duration and IOI. 
Auxiliary parameters: “Amp” and “Dur.”
Harmonic Charge: emphasizes chords remote from the
current key. Affected parameters: intensity, duration and IOI.
Auxiliary parameters: “Amp” and “Dur.”
Chromatic Charge: emphasizes on notes closer in pitch. It
is intended mainly for contemporary, atonal music. Affected
parameters: intensity, duration and IOI.
Metric patterns and grooves
Double Duration: decreases the duration contrast for two
notes with the duration relation 2 :1 (e.g., a quarter followed
by an eighth). Affected parameters: duration and IOI.
Articulation
Leap Articulation Dro: inserts micro pauses in leaps.
Affected parameters: duration.
Repetition Articulation Dro: inserts micro pauses in tone
repetitions. Affected parameters: duration.
Timing
Duration Contrast: the longer the note the longer and louder,
and the shorter the note, the shorter and softer. Affected para-
meters: intensity, duration and IOI. Auxiliary parameters:
“Amp” and “Dur.”
Duration Contrast Art: the shorter note, the longer the sub-
sequent micro pause. Affected parameters: duration.
Faster Uphill: decreases duration for notes in uphill
melodic motion. Affected parameters: duration and IOI.
Leap Tone Duration: shortens the note initiating an
ascending leap and lengthens the note initiating a descend-
ing leap. Affected parameters: duration and IOI.
D
o
w
n
l
o
a
d
e
d
 
B
y
:
 
[
H
E
A
L
-
L
i
n
k
 
C
o
n
s
o
r
t
i
u
m
]
 
A
t
:
 
1
8
:
0
8
 
1
7
 
A
u
g
u
s
t
 
2
0
0
8
D
o
w
n
l
o
a
d
e
d
 
B
y
:
 
[
H
E
A
L
-
L
i
n
k
 
C
o
n
s
o
r
t
i
u
m
]
 
A
t
:
 
1
8
:
0
8
 
1
7
 
A
u
g
u
s
t
 
2
0
0
8
