Study of social complexity: the case of Wikipedia
A RESEARCH STATEMENT BY
Taha Yasseri
Institut für Theoretische Physik, Universität Göttingen
Friedrich-Hund-Platz 1, 37077 Göttingen, Germany
April 12. 2010
I. INTRODUCTION
“Wikipedia is a free web-based, collaborative, multilingual encyclopedia project sup-
ported by the non-profit Wikimedia Foundation” [1]. It is the most famous “Wiki” among
all wiki-based projects which all work on the basis of WikiWikiWeb technology invented by
Cunningham [2].1 Wikipedia was first launched in 2001 by Jimmy Wales and Larry Sanger
and until now has about 15 million articles in 271 different languages, written and edited
by Wikipedians (voluntary editors from all around the world). It is a “free” encyclopedia
in two senses: (i) it is free of charge and available for everyone and (ii) every internet user
can edit almost all of its articles and content.2 This makes Wikipedia the most popular and
the largest on-line encyclopedia3 . The accuracy of Wikipedia content always has been a
debate topic. Although there are serious criticisms, an investigation by Nature shows that
correctness of articles in Wikipedia is to some good extent comparable to Britannica [3].
Growth of Wikipedia is very fast. Number of words, number of articles, number of internal
links and number of Wikipedians are all growing exponentially [4, 5]. The total number of
registered4 Wikipedians is about 23 Million, therefore Wikipedia is a very good example
of a large web-based cooperation project and proper for sociological studies. Generally,
Wikipedia is so large that every kind of statistical analysis can be performed based on its
datasets. In recent years, research efforts have increased tremendously in Wikipedia-related
topics (see Fig. 1). The research coverage is mainly focused on growth of Wikipedia and
the topology of articles network [4, 5, 6, 7, 8]. Most of the results show that the topology
of hyperlink network of Wikipedia articles is very similar to the whole www network, i.e.
scale invariance in degree distribution of in- and out-links. Evaluation of content quality
is another topic, addressed using different approaches [3, 10, 9]. Finally a very practical
branch of studies is to use structure and content of Wikipedia for developing and evaluating
classification and taxonomy methods [11, 12, 13].
In this statement I try to raise some rather novel questions related to Wikipedia as
well as new ideas on how to use the large data store of Wikipedia for non-encyclopedic
applications, i.e., social and linguistic studies.
II. PROBLEMS AND OBJECTIVES
A. Linguistic Analysis
Wikipedia is a multilingual project. Versions in different languages are mainly indepen-
dent. Containing texts on the same topics in more than 271 different languages written by
common individuals makes Wikipedia a unique linguistic database. Interlanguage relations
are restricted to users, who can operate in all Wikipedia sub-projects, rules, which are
mostly the same in all Wikipedias, common Medias, e.g., pictures, audios and other media
files, commonly used in different Wikipedias. If there are articles on exactly the same topic,
in two or more Wikipedias, there will be a hyperlink in the article page to its sisters in
1“Wiki” means quick in Hawaiian and the term WikiWikiWeb is first used by Cunningham to name the
first user editable website and in analogy to WorldWideWeb.
2An edit is meant to be a single action ending by a press of “save” button. It can be a small amendment
like rectifying a single character, or a large modification like adding or removing large amount of content
and finally deleting the whole of a pre-existing article, uploading a photo, creating a new page and putting
an article in a specific category, etc.
3Ranked 6th worldwide and 5th in USA among all websites in respect to number of visitors:
www.Alexa.com
4a large fraction of edits are performed by non-registered users
1
Fig. 1: Growth of number of scientific pub-
lications about Wikipedia. Data is extracted
from Wikipedia page: “Academic studies of
Wikipedia”. It is not ensured that the data
concerns all publications.
other Wikipedias. So, different Wikipedias are not translations of English Wikipedia or
any other, although to edit an article in one Wiki, users may use the content of the sister
articles with their own translation partially or completely. There are no rigid linguistic
restrictions on Wikipedians, although there are a few general rules and advices concerning
standard writing in each Wiki. Since every single word of an article can be added or edited
by a different user, the out-coming language of an article is an integrated language which
may not have a “standard language profile”. But it is a good ensemble of the practical
form written by speakers of a specific languages. To identify a language profile, there are
different features referring to vocabulary, lexical patterns and semantics. This features can
be quantized statistically through a text [15]. Seeing Wikipedia as a large database of
linguistic contribution from 23 M individuals, the following questions can be addressed:
Q1 How do the language profile of Wikipedias change from one branch of topics to
another one and from one language to others?
Q2 How does language profile of Wikipedia differ from other web-based text resources
(e.g., weblogs, twitters, chat and forums) and how universal is this difference among all
languages?
In the sense of language, English Wikipedia is an exception as compared to other lan-
guages. A large fraction of editors in English Wikipedia are not natives5. In addition,
English is the only language, in which there are tow versions of Wikipedias: the main En-
glish Wikipedia and the Simple English Wikipedia (abbreviated to “simple”). Simple is
meant to be useful for non-native English speakers and people who has middle or weak
grasp in English. Editors of simple are supposed to use simple grammar and vocabulary.
Here, the questions concerned are:
Q3 How does the diversity of editors affect the language profile in English Wikipedia
compared to others?
Q4 How simple is “simple” English Wikipedia compared to the main English Wikipedia
and how does simplicity appear when editors are asked to write simple?
5This may apply also for other international languages.
2
B. Taxonomy; Content vs. Context
Wikipedia articles are categorized by users into categories. The Wikipedia category
system (WCS) is implemented as a guide for Wikipedia readers; The articles comprising
categories are listed in either topmost or bottommost of the article page. Theretofore
readers of a specific article can simply navigate to other articles at the same category by
clicking on the category link and look for its belonging articles. Each article can be classified
into different categories which are then assigned into larger ones. Thus, hierarchal WCS
forms an acyclic directed network which can be seen as overlapping trees too (see Fig. 2
(a)). The categorization is performed by users and it is as reliable as the rest of Wikipedia
content. Note that information provided by WCS is not only useful for easier navigation
between articles but it can also be used as a database for classification and taxonomic tasks
in other projects. For example, Muchnik et al. used WCS for evaluating the accuracy of
different classification methods [12]. In the same approach, Strube and Ponzetto defined a
relatedness measure named “WikiRelate” and applied it to the conference resolution data
and showed that the results are even more accurate than judgments based on Google counts
and some other methods [11]. Capocci et al. compared size of categories (in term of number
of articles) to the size of clusters in the hyperlink network of articles and found the same size
distribution for both [13]. They also showed that there is no correlation between categories
structure and clusters structure, i.e. two articles which belong to the same category do
not necessarily belong to the same cluster in hyperlink network. This is not surprising,
since WCS is based on context of articles and hyperlink clustering is based on content (for
an example see Fig. 2 (b)). However, there are other ways for semantic classification of
texts, for example, Cointet and Roth recently used a semantic relatedness measure which
counts for the common keyword used in two different articles and upon this they measured
the semantic distance of articles in weblog networks [16]. By a precise investigation on
Wikipedia articles and calculation of different relatedness measures, i.e. distance in context
(in category network), distance in hyperlink networks and finally the semantic distance, the
following question can be addressed:
Q5 How can scientific texts be classified upon context or content differently? and how
correlated are the distances of two different articles in context space and content space?
C. Social Hierarchy and Authority
Wikipedia is neither democratic nor is it meant to be. Although all internet users can
access and edit almost all of the content, there is a hierarchal structure among all the
Wikipedians. Starting from an unregistered editor (which is identified as its IP address)
hierarchies to the highest level are registered users, established users, system operators,
bureaucrats, stewards and members of Arbitration Committee (in English Wikipedia there
is a last topmost level called Founder group). For some statistics of user classes see Table. 1.
Users belonging to different levels have different accessibility to edit, move to new title, page
protection, page deletion, block other users, etc. Promotion to higher levels mostly occurs
with consensus of the users community. Parallel to that, in a non-official manner there
are members of Mediation Cabal who are asked for judgment in the case of considerable
disagreements between users. All this hierarchal system is established for higher protection
of Wikipedia content and to ease and speed up the decision making process. For example,
if someone tries to change a single character in an article without a good justification, then
the edit will be reverted immediately by other users (usually from higher levels) and if two
3
Fig. 2: (a) A sample slice of category system in English
Wikipedia. Blue boxes are categories and each subcategory is
pointed by an arrow from the parent categories. Green boxes
are articles and green lines attach articles to the comprising cat-
egories. To make the figure apparent, many of subcategories and
articles are excluded. (b) An example of connection between two
articles in context space. Two terms “Menarche” and “Snow-
man” which are very far in semantic space, originated from the
same category (Periodic phenomena). Here the distance between
these two reduces to zero by going up only two generations.
or more users from the same level disagree about a topic, a user from higher level usually
try to conclude the undergoing discussion .The conclusion is not necessarily performed in
a democratic way, e.g., suppose n users believe an article X should be deleted and m > n
users do not, then a system operator may decide to delete X. The author (and probably the
funders of Wikipedia) believes that If Wikipedia had been a democratic web-based project
(like link-sharing community websites e.g., Digg6, reddit7 and Newsvine8) some of its “hot”
articles would never converge to a rather steady-state length and a commonly accepted
content. Willkinson and Huberman have shown that, in the currents system of editing,
the articles which are edited more frequently increase in quality by time. That means the
quality of an article would never become worse than before and a global improvement in
Wikipedia quality is ensured[10].
Parallel to the established hierarchal system for user access which is implied by the
Wikipedia software, a non-official authority is appointed to any member of the society
(here Wikipedians) by other members (like any other social system). The criteria and
requirements can be based on the quality of user edits, number of edits performed, the
frequency of appearance as an active user, etc., in a nontrivial way. The authority is
independent of age, gender, professional profile and education to some good extent. Hu
et al. introduced a method to calculate the authority of users depending only on their
contribution to the articles content. Authority of user i, Ai, is a weighted sum over quality
6http://www.digg.com/
7http://www.reddit.com/
8http://www.newsvine.com/
4
of the articles contributed, and quality of article j, Qj, is a weighted sum over authority of
the users who contributed:
Ai =
∑
j
cijQj, Qj =
∑
i
cijAi. (1)
where, cij is the amount of contributions of user i in article j in number of words. Starting
by an initial guess for Ai and Qj , one calculates iteratively quality and authority for every
article and user. In this model contributions in discussion pages, number of uploaded media
by the user and other affecting parameters to authority are neglected. Using similar or more
generalized models, one can assess the following questions:
Q6 How authority is distributed among all users and how this distribution changes in
Wikipedias in different languages?
Q7 Does the authority calculated for every user by the model matches to the official
hierarchal level assigned to him by the community decision?
In another approach, one can present a more complex agent-base model, in which a
single user is identified by its authority, contribution volume in time, hierarchal level, and
finally its opinion direction about a topic or a voting. Having such a model one can make
a comparison to a simple democratic system, in which every user has the same power and
access as others and address questions like:
Q8 What is the outcome of collective cooperation of users, i.e. length of articles, con-
vergence of their direction in opinion space, existence or deletion decisions, etc, compare to
ones for a democratic system?
Q9 Is Wikipedia emerging to a steady-state, fair, and generally accepted content and
how long does it take for that?
The author believes that not only the quality of Wikipedia content is increasing by time,
but also the editing efficiency of Wikipedians is developing. This is not trivial, given the
fact that the number of new amateur users joining to Wikipedian is growing exponentially.
An evidence for this is the number of article deletions per day (see Fig. 3). Although
the number of newly created articles is still growing exponentially9, the number of deleted
articles after an initial exponential growth tends to saturate for Wikipedias with different
size. Such observations can be easily tested and explained by the mentioned sort of models.
D. Information Diffusion and News Impact
Development of Wikipedia in different languages is inhomogeneous. Number and length
of articles, topical coverage and how up-to-date they are, depend on users’ function and
interests. In one Wiki, articles could be more concentrated about political issues, whereas in
another one more on geographical topics. Holloway et al. presented a method to visualize
the topical coverage of different Wikis by using their category network [5]. Comparison
of Wikipedia coverage in different languages (cultures and nationalities) may bring very
interesting information about the corresponding societies. Apart from the Wikipedia articles
which are about “settled” topics (topics which are solid and there is no rapid progress in
9with an exception for English Wikipedia [14].
5
Language Wiki Sizea Bureaucrats Adminsb Reg-usersc Act-usersd
English en 3 263 837 36 1 716 12 160 968 153 267
German de 1 056 209 6 287 975 344 2 4567
French fr 939 116 6 186 815 075 16 375
Polish pl 691 602 7 163 356 521 6 383
Italian it 679 263 6 102 502 387 8 356
Japanese ja 670 092 6 61 410 913 12 224
Dutch nl 598 617 6 69 308 854 5 251
Spanish es 589 810 136 140 1 447 194 16 319
All Wikis - 15499930 - 4 701 23177673 -
Table 1: Article and user statistics of the 8 largest Wikipedias. In addition, there are 34 global
“stewards” supervising all the Wikipedia projects.
aIn number of articles
bEquivalent to system operators
cNumber of registered users
dNumber of active users, who have contribution in the last 30 days
Fig. 3: Number of article deletions per
day versus time for 5 different Wikis
with different size. en: English with 3.2
M, de: German with 1 M, es: Span-
ish with 588 k, bl:Bulgarian with 95 k
and hr: Croatian with 79 k articles. An
initial exponential growth followed by
saturation seems to be universal among
languages.
6
Place Date Death toll en es de pl 10 h 2 w
Léogâne, Haiti 12.01 230000 0:40 1:08 4:41 2:15 14 55
Chile Maule region, Chile 27.02 486 0:48 1:15 4:06 4:32 10 45
Turkey Elâziğ, Turkey 08.03 50 2:49 12:13 - 14:59 4 13
Mexico Baja California, Mexico 04.04 3 0:13 1:46 14:44 - 3 10
Chile Pichilemu, Chile 11.03 2 0:52 0:25 2:52 - 3 6
Table 2: Appearance of an article about significant earthquakes of 2010 in different Wikipedias.
In middle columns the waiting time for 4 sample Wikis, en: English, es: Spanish, de: German and
pl: Polish and in the last two columns number of containing Wikis after 10 hours and 2 weeks are
reported. Note that the latter earthquake in Chile has a rather high impact, despite its small strength
and death toll. This might be due to an enhanced sensitivity stimulated by the first earthquake at
the same country.
them, e.g., historical or classical scientific topics), there are articles about daily events,
e.g., “2010 Chile earthquake”, which can not be created before a specific time. And as the
topic is born, it starts to appear and grow in different Wikis gradually. Depending on the
impact of the topic, appearance and growth might be fast or slow. For example, the article
about “2010 Haiti earthquake’ was created in English Wikipedia just 40 minutes after the
earthquake happened. This “delay” is 1:08 in Spanish and 4:41 in German Wikipedias.
After 10 hours, there were articles about the earthquake in 14 Wikipedias and this has now
increased to 62 Wikipedias within 14 weeks. In comparison, articles about “2010 Elâziğ
earthquake” (Turkey) were created after 2:49 in English and 12:13 in Spanish Wikipedias.
Subsequently, only 4 Wikis contain the corresponding article after 10 hours and no article
has appeared in German Wiki yet. There is a simple reason for this difference; Haiti
earthquake was 7.0 Mw strong and led to ∼ 230000 death, whereas the one in Turkey was
6.1 Mw and killed 50 people. See Table 2 for a more complete data set on all significant
earthquakes in 2010. A clear relation between the earthquake magnitude (and damage)
and its impact in Wikipedia can be seen. Analog to this, one can follow the usage of
“common media files” in different Wikis. Most of the media files in Wikipedia are uploaded
to a common database among all Wikis (www.commons.wikimedia.org) and can be used by
calling their names in Image Templates in each Wikipedias. Now suppose that a picture
uploaded at a specific time to Commons, proportional to its significance it can be used
(called) in different Wikis with different rates. Now we can ask the following questions:
Q10 How does the editing interests of users differ from one language (culture) to others?
Q11 How can we use Wikipedia impact as a measure for significance of a topic or event?
Note that due to the proper data store mechanism in Wikipedia, extracting historical
data of pages (including creation, deletion and evolution time-line) can be performed very
easily. For more detail see the next section.
III. TECHNICAL REMARKS
Nothing is lost in Wikipedia! All different revisions of an article, changes performed in
any single edit and logs corresponding to moves in title, creation and deletion of articles
are all stored and easily accessible. Even when a page is deleted, its history and all deleted
7
reversions can be accessed by users with “system operator” accessibility. All contributions
of each user is stored and visible for other users. The entire content of Wikipedia is free to
use under the Creative Commons Attribution-ShareAlike License. The MediaWiki software
(written in PHP, originally for use on Wikipedia) is free and open source. Therefore the
availability of any Wiki-related data is extremely eased. Snap shots of Wikipedia are taken
regularly and provided to download in www.download.wikipedia.org.
To extract and handle on-line information from Wiki pages one can use robots. For
example the author currently runs a robot (a pack of Python scripts) on 15 different Wikis
to add inter-language hyperlinks (connecting articles with identical topic from different
Wikis), correct misspells, delete pages which are confirmed for deletion, create pages upon
templates, extract data, etc. Such robots can navigate over all pages and gather desired
information from content and structure of pages. Another alternative is to take data from
www.toolserver.org databases that are in ownership of a service of Wikimedia Deutschland
e.V. Specific statistics of Wikipedia are stored in this website and can be accessed by running
SQL queries (for example data shown in Fig. 3). However to run a code a membership is
required.
IV. CONCLUSION
Wikipedia, the free encyclopedia, is not only unique among online encyclopedias due
to its coverage and availability, but also very proper to carry out studies on social systems
and especially issues like language characteristics, semantic analysis and taxonomy, social
hierarchy, diffusion of information, etc. Wikipedia is a multilingual project and so far has
spreaded over 271 languages. It contains ∼ 15 million articles about a wide range of topics,
therefore it is to treat as a rich database of linguistic samples. Here the crucial point is that
there is no global supervision on linguistic content of Wikipedia and therefore the emerging
profile of Wikipedia language is self-averaged over all contributing individuals. To study
the problem of hierarchy in social systems, the main barrier is lack of empirical data and
therefore most of the existing models can not be proven experimentally. The hierarchal
system of Wikipedia among its users is very touchable and easy to handle. Agent based
models to describe hierarchal issues can be simply organized and tested relying on Wikipedia
data. Extracting taxonomic information from Wikipedia is another side-applications of it.
Spreading of information in language-space of Wikipedia also should be mentioned as a very
accessible phenomenon to study. Well organized and opened source Wikipedia structure and
content ease all the mentioned potential studies in the sense of technicals. Data sets can
be extracted either by online-running robots or from available online statistics, however the
whole Wikipedia content is downloadable and can be treated offline.
ACKNOWLEDGMENT
I would like to thank Dr. Andrea Scharnhorst (Amsterdam) for interesting comments
and Amir Sarabadani (Tehran) for technical advices.
8
BIBLIOGRAPHY
[1] Wikipedia contributors, ”Wikipedia,” Wikipedia, The Free Encyclopedia, (accessed
April 15, 2010).
[2] B. Leuf and W. Cunningham, The Wiki Way. Quick Collaboration on the web. Reading,
Mass.: Addison Wesley (2001).
[3] J. Giles, Nature 438, 900, (2005).
[4] J. Voss, Proc. 10th ISSI, 221 (2005).
[5] T. Holloway, M. Bozievic and K. Börner, Comlexity 12, 30 (2006).
[6] A. Capocci, V. D. P. Servedio, F. Colaiori, L. S. Buriol, D. Donato, S. Leonardi and
G. Caldarelli, Phys. Rev. E 74, 036116 (2006).
[7] V. Zlatić, M. Božičević, H. Štefančić and M. Domazet, Phys. Rev. E 74, 016115 (2006).
[8] V. Zlatić and H. Štefančić, arXiv:0902.3548v (2009).
[9] M. Hu, E.-P. Lim, A. Sun, H. W. Lauw and B.-Q. Vuong, Proc. CIKM, 243, November
(2007).
[10] D. M. Wilkinson and B. A. Huberman, First Monday, April (2007).
[11] M. Strube and S. P. Pnzetto, Proc. AAAI (2006).
[12] L. Muchnik, R. Itzhack, S. Solomon and Y. Louzoun, Phys. Rev. E 76, 016106 (2007).
[13] A. Capocci, F. Rao and G. Caldarelli, Europ. Phys. Let. 81, 28006 (2008).
[14] B. Johnson, ”Wikipedia approaches its limits”. The Guardian, London (2009-08-12).
[15] Stamatatos, E, J. American Soc. Info. Sci. Tech. 60, 538 (2009).
[16] J.-P. Cointet and Camille Roth, IEEE SocialCom Intl Conf on Social Computing,
Vancouver, Canada (Aug 2009).
9
